Page1基于属性提升与局部采样的推荐评分预测郑麟朱福喜姚杏(武汉大学计算机学院武汉430072)摘要评分预测问题是推荐系统研究的一个分支.在上下文感知推荐(Context-AwareRecommendation,CAR)中,常常需要考虑上下文因子(或称属性)对评分预测效果的影响.现有模型大多是捕捉单个属性的特征并加上多个属性间的相互作用(简称属性交互)实现评分预测.然而,有些算法在捕捉属性间的相互作用时没有针对性,使一些属性交互对预测结果没有帮助,甚至降低模型性能;而且,在实现属性交互时,很多算法只是单纯地使用固定的属性值,没有从某个方面挖掘出它们的潜在特征.为了解决这些问题,文中提出了属性提升(AttributeBoosting,AB)框架,从用户、物品与属性类型3个方面分别与属性进行交互.这种更精细的建模方式使属性能够自动地适应用户偏好、物品关联与类型特征,并能在评分预测中充分地发挥作用.在此基础上,文中结合概率图模型的低秩近似能力和随机梯度下降(StochasticGradientDescent,SGD)的快速训练优势,在算法性能和训练效率上进行权衡,设计了局部采样(PartialSampling,PS)方法学习属性提升框架的参数,最终构成完整的属性提升与局部采样(AttributeBoostingwithPartialSampling,ABPS)模型.实验证明,ABPS模型通过有针对性的属性交互,能有效地挖掘出属性有用的隐含特征,从而减少盲目交互带来的消极影响;利用局部采样,该模型能使用更低的特征维度描述个性化信息,取得比其他模型更好的效果.关键词推荐系统;上下文感知推荐;评分预测;属性提升;局部采样;数据挖掘1引言推荐技术从早期的协同过滤(CollaborativeFiltering,CF)发展而来,CF主要处理的是评分预测问题.随着信息量的增大,用户对智能推荐的需求越来越强烈,CF逐渐从单纯的利用用户和物品预测评分发展到加入辅助信息来提高模型的性能.这导致了推荐领域的另一个方向,上下文感知推荐(Context-AwareRecommendation,CAR)的产生[1].CAR考虑了除用户编号和物品编号之外的更多信息,比如用户的辅助信息、物品的说明和社会网络等,这些信息统称为上下文因子(contextualfactors).在实际应用中,上下文因子主要表现为用户和物品的各种固有信息,比如用户的年龄、电影的类型等.一些文献[1]把上下文因子称为特征(feature),为了把实体的固有信息和隐含特征区分开来,本文使用“属性(attribute)”来表示实体的固有信息.如何利用属性与属性之间的相互作用来辅助评分预测是CAR研究的一个分支.一种方法是将CAR看成在传统的CF中加入附加信息协助预测[2];另一种是把CF中的用户-物品矩阵扩展为高维张量进行处理,得到用户的潜在特征[3]或用户的行为偏好[4].而最直接的方法,是将用户编号和物品编号也看成属性的一种,嵌入到模型中统一进行学习,从而更好地反映出属性间的联系[5].对于更加复杂的上下文信息,学者们倾向于用集成的方法来解决评分预测问题[6].无论模型是如何构建的,属性都在其中起着决定性的作用,因为对属性的处理会极大地影响到结果[7].上述几种模型捕捉的是全部属性之间的交互,但是在实际应用中,很多交互是没有必要的,例如用户的性别和电影的放映时间、电影的类型和电影的发行日期等等.另一个方面,参与交互的属性是(值)固定的,也就是说,属性的值从模型的开始训练到结束都是不变的.而这个固定的值显然无法满足不同用户的需求,比如用户A对纯棉的衣服比较喜欢,而用户B却对纯棉提不起兴趣,这说明“纯棉”只是“衣服质地”这一属性的客观反映,难以衡量不同用户间的兴趣差异.因此在训练过程中可以使属性的值自适应于用户偏好,以满足不同的用户需求;另一方面,可以选择对评分预测影响较大的几个方面来进行属性交互,从而提高模型性能.本文的主要贡献如下:(1)提出一种在上下文感知推荐中进行评分预测的方法.该方法以因子分解模型为基础,通过类型、用户和物品3个层面与属性进行交互,挖掘出更多的潜在信息,并提升属性交互的积极影响.这个过程称为属性提升(AttributeBoosting).(2)在属性提升框架的基础上,我们从概率图的角度来描述因子模型.针对不同的因子(或参数),设计不同的训练方法:对数量相对固定的因子使用采样学习法,而对数量变化较大的因子使用随机梯度下降和交替最小二乘法实现快速学习.这种混合的训练方法称为局部采样(PartialSampling),它能够使模型在效率和性能上得到平衡.(3)属性提升与局部采样(AttributeBoostingwithPartialSampling,ABPS)模型能使算法性能随着属性增加而总体呈提升趋势,并能使其用更低特征维度的方法比其他代表性的方法取得更好的效果.本文第2节介绍相关的研究工作;第3节描述属性提升的动机;模型的细节和算法实现流程将在第4节给出;第5节实现在真实数据集上的实验和比较;最后第6节是对本文的工作进行总结.2相关工作推荐中的评分预测问题在协同过滤(CF)中得Page3到了充分的研究,基于CF的评分预测包括邻域(neighborhood)模型和潜在因子(latentfactor)模型.在邻域方法中,用户和物品的联系被显式的建模,而在因子模型中,用户和物品都由特征向量所表示,这些特征向量的交互反映了用户和物品间的关系.矩阵分解(MatrixFactorization,MF)是因子模型的一种,广泛应用于CF中,它又被称为SVD,是早期评分预测的主要方法.SVD++[8]是SVD的改进版本,它利用了邻域模型的优势,将其融入因子模型中,取得比SVD更好的效果.SVD这类模型一般使用随机梯度下降(StochasticGradientDescent,SGD)进行学习,其适用于数据量较大时进行逐条记录的学习,但缺点是需要调节较多的参数.文献[9]从概率的角度来做矩阵分解,提出PMF模型,并在此基础上通过贝叶斯方法自动控制模型的超参数和参数,从而得到改进版的BPMF模型[10].该模型通过马尔可夫链蒙特卡洛(MarkovChainMonteCarlo,MCMC)方法进行高效训练,可以得到比PMF更小的误差.相对于单纯使用用户和物品特征进行矩阵分解,上下文感知推荐中的矩阵分解更多地利用了额外属性来做评分预测.时间是上下文信息(属性)的一种,对时间的处理是学者们在上下文推荐中研究的一个方向,TimeSVD++[11]通过对时间轴进行建模,捕捉用户偏好与动态时序间的关系,能够比无时序模型取得更好的效果.BPTF模型[12]是BPMF模型的时间扩充版本,它通过加入时间维度,把二维的用户物品矩阵扩展为三维的张量进行分解,从而把时间因子与用户和物品因子同等对待进行学习,效果比BPMF更好.除了时间因素,地理位置也属于上下文因子的一种,CACF-GA模型[13]通过遗传算法把地理位置信息融入协同过滤中,使评分预测的误差相对于时序模型来说更小.相对于时间和位置属性,社会网络更倾向于描绘用户之间的联系,在CF中融入社会网络(或称信任网络)信息,对提高预测的精度是有很大帮助的,TrustMF[14]把信任矩阵(TrustMatrix)嵌入用户-物品矩阵进行分解,有效地学习了用户之间的隐含联系,从而提高了模型性能.比“上下文信息辅助协同过滤”更直接的方法是将所有上下文信息(包括用户和物品)一起建模.张量分解(TensorFactorization,TF)是其中一种方法,它的优势是可以直接表示高维的上下文因子.文献[3]提出了用TF解决上下文推荐评分预测的泛化模型,对“用户-物品-上下文因子”形成的张量进行分解,具有普适性.TF对嵌入上下文信息进行评分预测是直接而有效的,但是它的训练开销随着上下文信息的增加而快速增长,从而有可能导致“维度灾难”(curseofdimensionality)[15].另一种更好的解决方法是捕捉属性间的交互,SVDFeature[16]集成了所有上下文信息,通过全局分量、用户分量和物品分量与其他属性产生交互,更好地利用了属性的特征.合理利用属性并挖掘它们之间关系的另一个有效模型是因子分解机(FactorizationMachine,FM)[17],它捕捉了属性间的二路交互,并通过交替最小二乘法(AlternatingLeastSquare,ALS)进行快速学习[18],在评分预测上效果显著.它的另一个优点是其通用性,通过特征变换,它可以模拟其他的模型,比如TF和SVDFeature.但是,它的不足之处是捕获了一些没必要的属性交互,而且和其他属性交互模型类似,该方法把属性当成静态的信息进行学习,不能让属性动态地适应用户偏好和属性类型,从而在个性化建模方面有较大的扩展空间,而这也是本文的研究重点与创新之处.3属性提升的动机FM的优势在于捕捉了属性间的点对交互,如式(1)所示,y^(狓)=w0+∑其中w0是全局偏移,{w1,…,wp}是属性集合狓={x1,…,xp}的回归因子.而{v1,1,…,vp,k}表示的是属性间的点对交互因子,它们的值由属性间的交互xjxj得到.对于一条包含了p个属性的记录,如果所有属性都进行两两交互,则所需要的计算量是p(p-1)/2次.显然,并不是所有属性都需要交互,如果能从中提取有用的交互,则可以提高算法效率.用户和物品是需要首先考虑的两个因素,因为许多推荐方法主要都是对它们建模,而在上下文推荐中,需要更多地考虑用户、物品和上下文信息间的关联.属性是没有偏好特征的,而用户与物品是有针对性的,某个用户可能对某个物品表现出独特的感情色彩;反过来,某个物品可能对某个用户有特殊的作用.这启发我们可以利用它们的这种针对性,作用于属性上,也就是说,除了传统的用户和物品交互,可以让用户和属性交互,让物品和属性交互,使属性对不同的用户或物品表现出不同的倾向性,这就是Page4属性提升的主要思想.除了用户和物品,属性的类型也是很重要的一个方面,比如“1月”的类型是“月份”,“汤姆·克鲁斯”的类型是“演员”等.如果要在类型方面对属性进行提升,可以通过模型训练,把属性的固有本质(比如时间特性、位置特征等)提取出来.因为不同类型的属性对用户和物品的影响力是不同的,即通过属性类型提升,可以更好地挖掘属性的潜在含义,下面我们给出属性提升的一般定义.定义1(属性提升).指通过用户、物品和属性类型3个层面对属性进行精确建模,来提升推荐评分预测的效果.例如,考虑标签作为电影的一种属性,已知电影A《拯救大兵瑞恩》的标签为:动作、剧情、战争、历史;电影B《达·芬奇密码》的标签是:惊悚、悬疑、动作;而电影C《幸福终点站》的标签是爱情.我们又知道用户U对电影A和B打出了很高的分数,要预测其对电影C的评分.普通的协同过滤算法可能会挖掘出用户U喜欢动作片的隐含特征,而难以预测他对爱情片的态度.基于属性建模的方法会充分利用属性来提高预测精度,比如这3部电影的主演都是汤姆·汉克斯.然而这类方法对属性的利用方式有的是线性回归,有的是两两交互(比如FM),并没有从某个角度对属性进行针对性的建模.例如从用户U的角度来说,他有可能是喜欢汤姆·汉克斯从而对电影A和电影B有较高的评价,即他不一定喜欢动作片.这说明从用户角度来对属性建模能更好地反映他的喜好;同理,从物品角度和属性类型角度来深层次地刻画属性也能取得更好的效果.另一方面,如果数据集中没有用户U对爱情片的评分记录,则普通的属性交互会失效.更抽象地,将标签“爱情片”表示为xj,观察式(1),当xj缺失时,xj和xjxj无法发挥其作用,即它们对应的因子wj和vj,fvj,f无法学到相应的特征,这对于稀疏性较高的推荐数据集来说是普遍存在的现象.解决的方法是可以通过包含xj的记录间接地学习,但是我们希望对当前记录做提升,因为这样更能反映当前用户和物品的关系.采用的方式是把xj表示为泛函的形式,如式(2)所示,x^j是xj经过函数F变化后的新值,Bj称为xj的提升项.F和Bj可以根据属性xj的不同而有多种可变的形式.这样,属性在学习的过程中不再是静态的,而是动态地改变以适应不同的用户物品组合.而且,当xj缺失时,x^j仍可以由Bj通过F来模拟,这时可以把Bj看成xj的潜在特征,所以,在属性缺失状态下,模型学到的是属性的潜在特征.从上述讨论可知,属性的提升方法要比单纯用属性值来训练更有针对性,也可以实现更精细的建模.在模型的构建过程中,本文从概率的观点出发,使用概率图模型来描述和实现算法,并采用局部采样的方法使得F和Bj中的参数可以根据训练集自适应的调节,提高算法效率.另外,通过有针对性的对部分模型参数进行采样,既利用了采样方法的低秩模拟能力,又避免了其效率过低的问题.在第4节描述模型的细节时,将对采样方法作详细的讨论.4模型和算法流程本节先介绍基于属性提升的评分预测框架,然后使用概率图模型给出局部采样方法的细节,最后描述算法的具体实现.4.1属性提升框架从第3节的讨论可知,模型主要从用户、物品和类型3个方面来进行属性提升(AttributeBoosting).对用户来说,每个用户对同样的属性有着不同的观点,因此,正确的属性提升应该客观地反映用户的偏好,并且能够区分不同用户对属性的影响程度.定义pu为用户u的偏好,vj为用户u对属性xj的影响程度,我们把属性xj的提升项Bj表示为狏T泛函形式具体化为x^j=xj+Bj,则可以把xj重构成xj+狏Tjpu的形式.属性提升函数x^j=xj+Bj的提升项Bj与常用经典模型中的偏移(bias)项类似,区别在于传统模型中的偏移项是单个变量,只能反映单方面的特征,比如物品偏移或用户偏移.而这里的提升项是两个向量的内积,即把用户偏好和属性关联起来,从而能表达更丰富的信息.本文的3个属性提升层面都将采用这种框架来表示,下面从用户提升角度举例分析提升项的作用.结合第3节定义1下方的例子,如果xj表示的是“动作片”,那么狏T的隐含态度(例如喜欢汤姆·汉克斯演的电影).这样,固定的属性值通过提升项被动态地调整,达到个性化推荐的目的.假设xj表示的是“爱情片”,而且数据集中没有用户u对爱情片的评分记录,我们仍Page5然可以用狏T汤姆·汉克斯的电影,得到他也喜欢汤姆·汉克斯演的爱情片这一结论.这和式(2)的初衷是一致的.属性提升之后,我们需要从3个方面与属性做交互,下面给出交互的具体定义.定义2(交互).指用因子变量(标量或向量)表示用户、物品或属性类型3个方面,并分别用这3种因子与提升后的属性(向量)做乘积运算;如果因子是标量,则与属性(向量)做标量与向量的乘法运算;如果因子是向量,则与属性(向量)做两个向量的内积运算.从用户角度来看,不同用户相对于属性有着不同的重要程度,把这种重要性定义为用户u的权重,用标量βu来表示,将因子βu与所有上下文属性进行交互,并将交互的结果相加,可以得到用户角度的属性提升函数:式(3)表示用户角度的评分预测部分,用户u提升除了自己之外的a个属性.t(u)表示用户类型,实际上在一条评分记录中,只有用户自己属于该类型,而与自己交互是没有必要的.从物品角度来看,物品i相对于属性来说也是具有可变的权重,用标量γi表示.而除了物品本身的重要性,它对属性的影响力ej也必须考虑.用qi表示物品与属性的关联程度,则它们共同决定了属性的提升项犲T品因子γi与属性的交互给出:同样地,物品并不与自己进行交互.可以观察到用户和物品对属性的提升具有相似的形式,因为它们是评分记录中的两个实体,而且这种提升是非对称的,即用户和物品只是简单地用权重来控制,而属性却有一个更细致的提升项.原因是本算法更强调对属性的提升效果,希望更精确地对属性进行建模,这是对FM中对称的属性交互形式的改进.除了用户和物品,属性类型作为另一种有用的信息,直接反映了属性的内在特征.因此,在评分预测的第三部分,我们将动态的类型因子αt(j)嵌入到模型中进行学习,表示属性xj所属的类型.和用户物品不同,类型在提升属性方面表现为全局的作用,因此不使用个性化的提升项,而是用一个偏移量wj来表示提升效果.类型提升的评分预测部分如式(5)所示:向量αT单个属性间的交互,它们是相互作用的.3个方面的属性提升一起构成了评分预测的框架:y^(狓)=这里Z是3个部分加起来的正规化项,用来限制预测值的范围.因为y^user(狓)、y^item(狓)和y^type(狓)这3个预测值都采用了属性连加的结构,这样得到的预测值会很大,而真实值通常只是1到5分,造成梯度很大从而加大训练的难度,即需要很小的学习速率来适应很大的梯度.经过规范化后,y^(狓)变小了,从而对学习速率不会太敏感.在实际的数据集中,某条用户评分记录一般不会拥有所有属性(稀疏性),如果直接将Z设为a,会导致y^(狓)过小;通过实验观察与统计预测值,我们将Z取值为槡a,其中a为属性个数,这样能使总体的规范化效果最好.4.2小节将用概率局部采样、随机梯度下降和交替最小二乘法相结合的方式来训练ABPS模型.4.2局部采样方法概率图模型和因子分解模型相结合之后,充分发挥其参数自适应学习与低秩近似的优势,并保留了因子分解的优点,因此得到了广泛的应用.以BPMF[10]为例,该类方法首先假设用户对物品的评分服从高斯(Gaussian)独立同分布:p(R|U,V,α)=∏其中用户数量是N,物品数量为M,Rij表示第i个用户Ui对第j个物品Vj的评分,Iij为指示器函数,如果Rij存在,则Iij值为1;否则为0.每个分数服从均值为犝T品特征向量的先验概率设为其中μU,ΛU和μV,ΛV为超参数,方差矩阵Λ-1V服从自由度为υ0、共变异矩阵为犠0(D×D维)Λ-1的Wishart分布:(Λ|犠0,υ0)=p(μU,ΛU)和p(μV,ΛV)则服从Gaussian-Wishart分布,因此在已知用户或物品特征的情况下,超参数Page6能进行自适应更新.已知似然(式(7))和先验概率(式(8)和(9)),通过极大化对数后验概率(等价于极小化平方误差[9]),可以得到用户和物品最终的特征.由贝叶斯推断,后验概率的分布可由先验概率乘以似然概率得到,因此后验概率是另一个高斯分布,以用户特征Ui为例:p(Ui|R,V,μU,ΛU,α)=M∏j=1如果直接推导并计算出后验概率是相当复杂的,根据MCMC原理,可以由吉布斯采样(GibbsSampling)得到其均值μ似地模拟后验概率,最终实现评分预测.该方法在超参数需要人工调节时优势明显,因为超参数可以通过采样从训练集中得到;而且,通过近似模拟,可以用比其他模型更少的维度来表示特征向量.但是当模型中的因子数量(特征向量的个数)过多时,采样会变得效率低下,因为吉布斯采样对某个因子的采样过程就是固定其他因子计算条件概率.所有因子必须被采样一次才能完成训练,这相对于随机梯度下降(SGD)和交替最小二乘法(ALS)来说是低效的.结合属性提升模型的实际情况,我们发现用户对属性的偏好pu、物品与属性的关联程度qi和属性类型αt(j)的数量是相对固定的.而且这3个因子的数量远少于属性影响力vj、ej和类型偏移wj,因为数据集中用户和物品的数量是相对固定的,而属性类型在一开始就是确定的,如果增加属性,类型也只会缓慢增长.例如原有的“时间”类型包含“年”和“月”2个属性,如果增加“小时”和“分钟”2个属性,“时间”这一类型也不会改变;又如在记录中加入100名演员进行训练,则多了100个属性,而属性类型只是多了1个“演员”.在上下文属性较多的情况下,pu、qi和αt(j)的数量相对固定这种现象更加明显.所以本文设计了局部采样(PartialSampling)学习法,只对pu、qi和αt(j)进行采样,而对其他因子使用SGD和ALS来训练.这3个因子刚好是与属性交互的3个方面,通过采样可以用更少的特征维度(即低秩)来表示三方面的特征.其他因子除了用户权重βu和物品权重γi外,都是对属性特征的描述,而βu和γi不需要特征向量来表示,即不需要低秩近似.所以,可以对剩下的因子使用SGD和ALS进行更新来提高训练速率,与采样配合能平衡算法的性能和效率.模型的学习过程如图1所示.设采样时记录评分的方差为λ-1,则图中3个矩阵Λp、Λq和Λα由Wishart分布的参数υ0和犠0配合采样得到.均值μp、μq和μα由初始值μ0结合采样后的方差矩阵得来.完成pu、qi和αt(j)的采样后,可以通过SGD来学习vj、ej和wj,然而,βu和γi的梯度计算相对其他因子来说更耗时,所以在训练时使用ALS,即固定其他变量对βu和γi进行快速更新.所有参数训练完后,第k条记录的评分预测值y^(k)由属性x(k)4.3算法细节和流程j代入3个评分预测函数由式(6)获得.第1、2节介绍了ABPS模型的主要思想,本节说明算法的细节.为统一讨论,将超参数集合{Η}={μp,Λp,μq,Λq,μα,Λα}的初始值表示为Η0={λ,μ0,υ0,犠0},而模型参数集合记为{Θ},即pu={p1,p2,…,pj,…},qi={q1,q2,…,qj,…}等均用Θ={θ1,θ2,…,θj,…}表示.由前面的假设可知,θj的先验概率服从高斯分布:设狔={y集合,y(k)对应的评分预测函数(式(6)),其中狓(k)为第ky条记录的属性集合.则n条记录的评分预测概率为n个独立的高斯分布:p(狔|{Θ},λ-1)=∏Page7给定参数集合{Θ}和方差λ-1,其均值为预测函数y^(狓(k)).则式(13)为参数集合{Θ}的似然分布,结合式(12),θj的后验概率可表示为p(θj|狔,{Θ}\θj,λ-1)=其中{Θ}\θj表示除θj以外的其他参数集合,求解μ的关键是对y^(狓(k))与θj的关系作分析,由和Λθj式(3)~(6)可知,对任意θj,y^(狓(k))都可以表示成以下两种形式:其中y^(狓(k))无关的项,即y^(狓(k))是θj的线性函数,结合高斯边缘分布和条件分布的关系[15],可得θj=Λθj+λ·∑Λθj=[Λμθj在实现时,可以由式(16)和(17)计算出μp,Λα,Λμ斯采样求得,即θj的特征向量可由μ到.完成采样之后算法使用SGD和ALS对其他参数做快速更新.在进入下次迭代前,需要使用新的{Θ}值并配合预设值Η0,通过Gaussian-Wishart分布自适应地更新超参数集合{H},然后进入下一轮的迭代,流程如算法1所示.算法1.基于局部采样的属性提升评分预测算法.输入:初始值H0,超参数{Η},模型参数{Θ}输出:狔的预测值y^(狓)1.统计犡得到用户个数N,物品个数M,类型个数L2.初始化模型参数集合{Θ}3.FORt=1TOT4.自适应更新超参数{H}={μp,Λp,μq,Λq,μα,Λα}5.FORu=1TON6.对μ7.ENDFOR8.FORi=1TOM9.对μ10.ENDFOR11.FORl=1TOL12.对μ13.ENDFOR14.FOR狓(k)IN犡15.su=∑16.si=∑17.y^user(狓(k))=βu·su//用户提升18.y^item(狓(k))=γi·si//物品提升19.y^type(狓(k))=∑20.y^(狓(k))=21.用su和si对βu和γi做ALS更新22.对v,e和w进行SGD更新23.ENDFOR24.ENDFOR该算法在完成对pu,qi和αl的采样后,开始进行评分预测,用于更新其他参数.在预测的过程中,存储临时变量su和si来对βu和γi做快速ALS更新,因为su和si是βu和γi的梯度,而且在更新时,其他参数是固定的.5实验和结果5.1数据集和评价标准实验使用4个数据集来检验ABPS模型,其中3个来自GroupLensResearch的著名推荐评分数据集MovieLens(ML)①,另一个是Yahoo!Research发布的用于上下文推荐研究的电影数据集②.4个数据集的统计信息如表1所示.表1表MovieLens与Yahoo!数据集的统计信息数据集ML-1mML-latestYahoo!ML-10m4个数据集中的上下文信息表现为用户属性和物品属性,这些属性被分为不同的类别.例如,Yahoo!数据集中的用户属性包括“编号”、“出生年”和“性别”3类,而电影的属性则比用户更多.在ML-1m数据集中,用户有着5种属性,但是物品却①②Page8只有“编号”和“类别”两种属性.与前面两个数据集不同,ML-latest数据集中用户和物品的属性都较少,但是它有用户标注(打标签)信息作为补偿.最后一个数据集ML-10m拥有10000054条评分记录,包含71567个用户和10681部电影上的95580个标签,非常接近实际应用的大数据量,所以我们使用它来考察模型的实际性能.在4个数据集中,上下文信息的多样化有助于在实验时进行比较,实验使用的主要评价标准是在推荐评分预测中常用的RMSE(RootMeanSquareError)和MAE(MeanAbsoluteError).实验过程首先研究属性提升的影响和局部采样的效果;然后进行不同方法间的比较;最后考察算法的实际表现.我们还加入召回率Recall来测评模型的Top-N推荐性能,这是对评分预测功能的扩展,3种评价指标的计算方式由式(18)~(20)给出.其中T是测试集,T是测试集的记录数,i表示测试集的第i条记录,yi是其真实值,y^i是模型对该记录的预测值.在召回率中,hit(i)表示是否命中第i条记录,如果命中,则hit(i)=1;否则hit(i)=0.图2属性数量与属性提升的关系5.2属性提升的影响第3节讨论了属性提升的目的,主要是要让属性对不同的用户、物品或类型表现出不同的倾向性,以便更好地预测评分.在实践中,越多的属性并不一定能取得越好的效果,因为有些对A用户来说可称为“好”的属性,对B用户来说却可能是“坏”属性,增加某个“坏”的属性可能会对评分预测产生负面效果.而ABPS模型因为有了属性提升项,可以充分地描述用户或物品的个性化倾向,当增加属性时,便能使属性更好地发挥其潜在作用.本文选取表2中的属性集合来调查属性提升的影响.在上下文推荐中,用户编号和物品编号也被当成属性,所以至少必须取这两个属性进行训练.与基本的CF算法一样,首先只取用户编号和物品编号进行评分预测,然后逐渐增加属性数量直到表2中的属性全部被使用,来观察预测的效果.实验采用5折交叉验证,将ABPS的特征维度设为20,并使用随机梯度下降(SGD)进行训练.图2显示了在3个数据集上,算法运行30次迭代得到的实验结果.数据集ML-1mML-latest{用户编号,评分时间}Yahoo!Page9从图2中可以看出,通过不断增加属性的数量可以发现属性提升有提高性能的效果.在只有用户编号和物品编号(即属性数量为2)的情况下,上下文推荐退化为协同过滤,即所有除用户和物品外的属性都缺失了.但是,ABPS中的提升项仍然描绘了用户和物品的偏好特征,所以仍然能有较好的结果.在缺失值不断填补,即属性数量不断增加的情况下,效果的提升是显而易见的.ML-1m虽然记录数很多,但是其提升效果并没有Yahoo!那么显著.原因在于除了属性数量,属性的特性(比如“粒度”)对结果也是有影响的,例如表2中ML-1m的属性是“粗粒度”的,而Yahoo!中的属性是“细粒度”的.具体地,ML-1m中只有7个年龄段、21种职业和18种电影类别,如果把6040个用户按这些属性来分,得到的每个组里面的用户数量(“粒度”)还是很多(大)的,即其捕捉单个用户偏好的潜力是有限的.反之,Yahoo!的属性如“导演”、“演员”、“发行日期”等都种类繁多,按不同属性区分出来的用户组中的用户数量(“粒度”)是极少(小)的,说明其描述个性化的能力是较强的.同样地,ML-latest中,“电影标签”也是“细粒度”的,可能某个标签只被1个用户打过,所以其性能提升的空间也比ML-1m大.在某些情况下,比如ML-1m使用4个属性、Yahoo!使用6个属性时,效果有轻微的下降,但RMSE和MAE总体呈下降的趋势.这说明属性提升能够平衡属性对预测结果的影响,即通过对属性的精细建模来充分挖掘属性有用的隐含特征,从而减少盲目交互带来的消极影响,最终使预测值更接近真实值.因此,随着属性的增加,ABPS算法可以充分发挥属性对评分预测的积极作用,使整体效果呈上升趋势.在属性提升的基础上,5.3小节将讨论局部采样的效果.5.3局部采样的效果在考虑局部采样的影响时,由上节的实验结果可知,使用最多的属性可以得到最佳的性能,因此采用表2中的全部属性进行实验.在这个过程中,为了比较采样对结果的影响,设计了无采样属性提升(AttributeBoostingwithNoSampling,ABNS)、局部采样属性提升(AttributeBoostingwithPartialSampling,ABPS)和全局采样属性提升(AttributeBoostingwithAllSampling,ABAS)3种方法,对它们在性能和运行时间上做了对比.无采样指的是在模型的训练过程中使用SGD配合ALS使其收敛;局部采样就是对p、q和α做Gibbs采样,而其他参数仍使用SGD和ALS;全局采样即对所有参数进行采样,从而使模型全部通过概率的角度来表达.将ABNS、ABPS和ABAS的特征维度都设置为20,采用5折交叉验证,运行50次迭代来比较3种方法得到的效果.其中ABNS的初始学习速率(针对ABNS而言)在两个ML数据集上设置为0.018,在Yahoo!上设置为0.028.在训练过程中,通过考察本次迭代与上次迭代损失函数的绝对值变化,来动态调整学习速率.如果两次迭代的损失绝对值很接近,则收敛;若绝对值变小,则增大学习速率;若绝对值变大,则减小学习速率.在实验中,由于对预测值做了规范化处理(4.1节),模型对学习速率不敏感,所以3个数据集上的学习速率波动不大.对于没有进行采样的参数,设置它们的规范化因子为0.00008.实验效果如图3所示.在3个数据集上,ABAS均取得了最好的性能,ABPS仅次于ABAS,而没有采样的ABNS效果要差于采样的方法,表明在低秩(特征维度为20)近似上采样方法占有较大的优势.而SGD或ALS学习法通常需要更多的特征维度来表示实体(用户或物品)的特点,才能达到较好的效果.在个性化标注信息较多的ML-latest和属性数量较多的Yahoo!数据集上,ABPS的表现比ABNS有明显的提升.这说明采样因子p、q和α能够很好地模拟用户偏好、物品关联和类型特征,从而满足评分预测的个性化需求.因此局部采样对模型性能的提高是显著的.另一方面要考虑的是模型的效率(运行时间),如图4所示.Page10图4不同采样方式的耗时图4显示了3种方法各运行30次迭代所消耗的时间.可以看出无论迭代次数如何变化,无采样的ABNS方法都会有较快的速度,因为采样方法在更新某个参数时需要固定其他参数,所以会比SGD和ALS慢.而ABPS由于是部分采样,只对用户偏好、物品关联和类型特征作采样,因此运行速度会比全采样的ABAS有大幅度的提高.特别是在属性数量相对于用户、物品和类型个数较多的Yahoo!数据集上,ABPS的效率接近于ABNS;而在ML-1m数据集上,记录数量较多,所以也让ABAS耗时更多;在ML-latest上,属性数量和记录数都较少,所以ABAS与其他两个方法的差距没有另外两个数据集大.这说明在记录数多或者属性数量多的情况下,使用全采样方法都面临着运行效率低下的问题,而使用局部采用的ABPS虽然没有ABNS高效,但是从上面对图3的讨论可知,它比ABNS的性能要好.如果在模型性能和运行效率上做权衡,ABPS更适合实际应用,因此在下一节采用ABPS与其他的方法作比较.5.4方法比较实验选择BPMF[10]和FM[17]来与ABPS作比较,因为BPMF是因子模型结合采样方法的代表模型,FM是属性交互建模的典型模型,并且在实践中被广泛应用.而ABPS不仅使用了属性提升,从新的角度描述属性交互,又采用了局部采样的训练方式,所以本文将3种方法放在一起评测.实验中,BPMF的评分方差α-1和ABPS的评分方差λ-1在两类数据集ML和Yahoo!上的值分别设置为1/1.8和1/2.5.两个模型的Wishart分布的自由度υ0取它们的特征维度数20,共变异矩阵犠0设为20×20维.相对于这两个模型,FM的特征维度设置为32,该模型其他参数(如w和v)的规范化因子取0.0000018,以防止过度拟合.实验结果如图5所示.在标准的协同过滤数据集ML-1m上,BPMF表现良好,甚至在MAE上超过了FM.无论是RMSE还是MAE,上下文推荐模型FM和ABPS都没有大的优势,因为该数据集的属性相对来说是通用的,比如职业、年龄等.而ML-latest则不同,其中有一个重要的属性是标签,标签是反映个性化信息的一个属性类型,两个上下文推荐模型在该数据集上则比BPMF有了更多的提升.对Yahoo!数据集来说,多样化的属性非常有利于评分预测,因此FM和ABPS也有较大的优势.这种优势突出表现在RMSE上,因为RMSE利用平方来衡量误差,所以离真实值更远的预测值会被赋予更大的权重.而两种上下文方法都充分利用了属性,通过属性优化预测值从而显著地避免了大误差的发生,最终减小了总体误差.相对地,MAE是没有权重的误差估计,能客观地反映用户的绝对误差平均值,ABPS因为做了属性提升,在表达用户偏好或物品特点方面比FM更Page11有针对性,所以在降低RMSE的同时,FM和ABPS也在MAE测评中表现良好.实验结果表明对用户、物品和属性类型的建模可以反映更多有用的信息,这是普通属性点对交互所不具备的.而且,ABPS使用的特征维度(20)比FM(32)少,这是局部采样的低秩近似优势,可以用更少的维度来表达同样的信息.虽然FM的普适性较好,可以用于其他推荐任务,但是在上下文推荐中,ABPS对属性交互的精细建模使其在评分预测方面更有优势.5.5实际应用在实际的推荐应用中,往往都是需要面对大量数据,所以我们选取拥有1000万条记录的ML-10m数据集来模拟实际的情况.该数据集的7万多个用户和9万多种标签使得其具备数据量大、稀疏性的特点,因此也更能验证ABPS的实际性能.由于该数据集的上下文信息丰富,在考察ABPS时我们选择FM作为比较,因为它们都是对属性建模的上下文推荐模型,这使得它们具有可比性.评分预测的性能(包括RMSE、MAE和运行时间)是首先考察的内容.实验通过改变模型的特征维度(因子数量)来观图6ML-10m上的评分预测效果图7ML-10m上的评分预测与物品推荐运行时间察它们的表现,因为特征维度代表了模型的空间复杂度,即模型需要多少维度来存储,这是实际中需要考虑的问题之一.图6展示了两个模型的评分预测性能,无论模型特征维度如何变化,ABPS在两个指标上都比FM有明显的优势.特别是在低秩(维)部分(5~25维),ABPS的优势更加显著,主要是因为ABPS从用户、物品和类型3个层面对属性建模,能够学习到属性的潜在特征(即式(2)中的提升项),从而避免了因属性(这里主要是标签)缺失而造成难以预测的问题,所以20维的ABPS在性能上已超过30维的FM.在运行时间方面,实验记录了两个模型在评分预测和物品推荐上的耗时,由于Top-N物品推荐有其实际的应用价值,所以我们将评分预测的结果排序后进行物品推荐.从图7可以看出,如果对比相同的因子数量,FM只需要相当于ABPS算法2/3的时间,但是,前面已讨论过,20维的ABPS比30维的FM表现更好,观察时间轴(纵轴)可以发现,20维的ABPS只比30维的FM多耗时一些,而损耗的时间从性能那Page12里得到了补偿.物品推荐比评分预测稍微耗时一些,因为在推荐前需要做排序,这也导致了时间损耗不像评分预测那样随着维数的增加而线性增长,即有图8ML-10m上的Top-10推荐召回率(Recall)与评分预测不同的是,Top-10推荐在一开始(Factor=5和Factor=10)时结果非常接近,ABPS并没有表现出更好的性能,这是因为评分预测关注的是显式反馈(预测结果是否接近测试集中物品的分数),而物品推荐关心的是隐式反馈(推荐的物品有没有在测试集中存在).换句话说,不管给被推荐的物品打1分还是5分,只要它出现在测试集中(即命中),Top-N推荐的性能就会提升.所以,虽然ABPS在Factor=5和10时评分预测更精确,但是小幅度的波动.为了更好地评价Top-N推荐,我们取N=10,即推荐10个物品,用召回率(Recall)来衡量模型的性能,结果如图8所示.它的命中率与FM是接近的.在Factor=15~25时,ABPS的优势体现出来,而FM的提升空间不大,这是属性提升给个性化推荐带来的积极影响.在更高的维度,比如Factor=35和40时,ABPS的优势主要表现在Top-5至Top-10部分.总体来说,ABPS的长处在于评分预测,而在物品推荐方面也表现良好,它的性能来源于精细的属性建模与更耗时的局部采样,这也决定了它能用更低的维度(更少的空间)来构建模型,这是具有实际意义的.Page136结论本文提出的属性提升与局部采样方法(ABPS),从用户与属性的交互、物品与属性的交互、属性与自身类型的交互三方面有针对性的建模.从而避免盲目的属性交互带来的负面效果,模型的框架也因此由这3个方面组成.在参数训练中,仅对这3个方面的特征因子进行采样,从而使模型能在属性数量较大或记录数较多的情况下,仍能保持较高的效率与性能.在未来的研究中,我们将把重点放在与“冷启动”有关的主题上,即用户缺失或物品缺失.这种情况下,如果用ABPS来描述,应考虑到如何通过用户关系或物品关联来解决评分预测的问题,这也是研究小组下一步要改进的方向.
