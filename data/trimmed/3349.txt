Page1单遍数据读取的GPU上的多片元效果绘制谢国富1),2)王文成1)1)(中国科学院软件研究所计算机科学国家重点实验室北京100190)2)(中国科学院研究生院北京100049)摘要在GPU上进行多片元效果的绘制,已有的方法往往需要对模型进行多遍的数据读取,以进行片元的有效排序.由于往GPU传输数据的带宽限制,多遍的数据读取严重制约了绘制效率的提高.虽然,随着CUDA的出现,已有方法可将数据完全装入GPU进行多片元效果的绘制,但受存储空间的限制,难以处理大规模的模型.对此,文中提出一种只需要单遍数据读取的绘制方法,即将模型进行凸多面体方式的组织,并依据绘制的需求逐个地将凸多面体传输到GPU中,以实现片元的正确排序.在这过程中,及时地进行同像素片元的色彩混合操作,以大幅降低片元排序的空间需求,由此可使用更多的光照参数来增强绘制效果.实验表明,新方法优化了模型的数据读取,可有效提高绘制速度,即便与基于CUDA的一次性装载数据的方法相比,也能提高速度,且能方便地处理大模型和深度层次大的模型.关键词图形处理器(GPU);片元处理;凸多面体;透明;半透明1引言图形处理器(GraphicProcessingUnit,GPU)的高效运算能力得到了越来越多的重视.其中,利用GPU进行多片元效果的绘制是当前图形学方向的重要研究内容,即在GPU中如何高效地进行需要片元深度排序操作的3维模型绘制,如透明或半透明绘制、反走样、体绘制、碰撞检测等.由于GPU不便进行动态的空间分配及它自身计算方式的限制,片元深度排序操作很难在GPU中完全实现.为此,人们提出了多种方法以解决深度排序的问题,如深度剥离方法[1]、双面深度剥离方法[2]、K-Buffer方法[3]、桶深度剥离方法[4]及基于CUDA的深度剥离方法[5]等.对深度层次复杂的模型,这些方法需要进行多遍的数据读取,才能得到有效的片元深度序列.由于实际应用中的模型一般都很大,也有较多的深度层次,而往GPU中传输数据又很费时,因此数据读取成了制约GPU上多片元效果绘制效率的瓶颈之一.本文提出一种方法,只需单遍读取模型数据就能在GPU中完成多片元效果的绘制.其工作思路是将模型进行基于凸多面体方式的组织,以便绘制时可根据视点方位快速地决定往GPU传送凸多面体的顺序,以保证多片元绘制所需的片元深度排序能在GPU中得到正确的实现.新方法基于GPU的Shader实现,处理简单,占用显存小,特别方便处理大模型.实验表明,相比于已有先进方法,我们方法能有效提高效率,并可使用更多的光照参数增强绘制效果.比如2010年发表的基于CUDA的深度剥离方法[5],虽然只需要将数据装入GPU一次,但新方法依然要比它快,并能方便处理它不能处理的大模型,特别是深度层次大的模型.由于实践中的模型一般都比较复杂,有较多的深度层次,因此我们的方法更便于实践应用.本文在第2节对相关工作进行简要的介绍;在第3节讨论基于凸多面体方式的模型组织方法;然后在第4节介绍针对GPU的单遍数据读取的片元深度排序;最后给出实验结果并进行讨论和总结.2相关工作很多绘制效果是依赖于模型面片的深度排序的,即对应于一个像素的光线与面片相交的顺序对该像素的色彩有很大的影响,比如反走样、半透明绘制及体绘制等.这方面的工作一直是图形学中的重要研究内容,比如早期的基于CPU的A-Buffer方法[6],它为每个像素建立一个列表以顺序地存储相关的片元,以有效进行反走样处理.但是,每个像素对应的片元数难以事先确定,因此需要存储空间的动态分配,而这难以在GPU中实现.为有效利用硬件加速,在A-Buffer方法的基础上,R-Buffer方法[7]用一个基于FIFO队列的再循环帧缓存来排序及存储像素相关的所有片元;Z3方法[8]则使每个像素存储固定数目的片元,一旦片元数达到一个固定值,就混合两个最邻近的片元.但这些方法需要对现有硬件架构进行修改,它们目前只是进行了软件方式的模拟,而没有在当前硬件上实现.为能在当前图形硬件架构上实现基于深度排序的绘制效果,深度剥离方法[1]提出将模型进行多次的绘制,每次绘制时获得最靠近视点的一层片元,并且这层片元不参加后续的深度比较,由此可实现片元的排序.该方法的复杂度与深度层次有关,对于深度层次为N的模型,它需要进行N次的数据读取与绘制及N2次的深度比较.为减少数据读取的遍数,双面深度剥离方法[2]使用GPU中的MAX/MIN混合拓展,每遍绘制可同时剥离最近和最远的2层片元;而文献[9]利用GPU中多个MultipleRenderTargets(MRT)可同时剥离多个层次的片元.但它们依然要多遍地读取模型数据.另有一些方法提出新的排序对象,以提高排序计算的效率,比如Vis-Sort[10]就针对物体对象进行可见性的深度排序,而不是片元;Z-Batches[11]将模型离散化为像素大小的微多边形网格(Grid),并将这些网格单元划分到不同的深度层次,以便在各个深度层次并行地使用深度剥离方法;而文献[12]则提出在GPU中对模型进行均匀的体素化划分,以便根据规则数据场的性质进行便捷的排序计算.但为绘制高质量的多片元效果,这些方法还是要对模型数据进行多遍的读取.在一些情况下,只有前若干层次的片元对多片元效果的绘制有较大作用,后面层次的片元对绘制效果的作用可忽略不计.为此,一些研究者提出了只进行一遍模型数据读取的绘制方法.但这些方法将排序计算放到GPU中进行,往往会出现排序失误而影响绘制质量.比如K-Buffer算法[3]力图使用Read-Modify-Write(RMW)操作来实现前K层片元的排序,但在进行片元插入操作时,一个像素相关Page3的多个片元可能同时对一个存储位置进行读写操作而引起排序失误.为避免RMW的读写冲突,文献[13]提出利用MultisampleAntialiasing(MSAA)缓存和StencilRouting操作来进行排序,但由于MSAA缓存的限制,它至多只能处理前8层片元.为提高排序的效率,文献[4]利用GPU中的MRT缓存为每个像素分配一个包含32个单元的桶结构,然后将模型深度分为32个区间,再根据片元的深度将其放入桶结构中的适当单元,但这样会将同一深度区间的片元插入同一存储单元而引起排序失误.这些方法除了可能引起排序失误外,一般只能处理前若干层次的片元.当需要绘制较多深度层次的模型时,它们依然要对模型进行多遍的数据读取.特别是,为化解排序失误,它们也会增加数据读取的遍数,如文献[4]提出多遍桶深度剥离及自适应桶深度剥离,以减少排序冲突,但这样的改进至少需要两遍读取.为解决RMW读写冲突及片元排序失误,文献[5]提出把多片元效果绘制流程完整映射到CUDA编程模型上,以便灵活控制Blending操作和显存分配.对于片元排序,它提出两种策略:第1种为Multi-DepthTestScheme(MDTS),第2种为A-BufferScheme(ABS).在第1种策略中,它预先在CUDA全局内存中为每个像素分配固定大小的整型数组,以便片元能根据深度信息插入到此数组中的相应位置.由于CUDA不支持64位原子操作,故MDTS不能同时更新深度及颜色信息,于是,它把深度及颜色信息打包在一个32位的数中,但这样会导致深度精度的损失.同时MDTS在全局内存进行插入排序的时间复杂度为N2(深度为N).为缓解上述问题,第2种策略提出预先为每个像素分配固定大小的结构体(存储深度及颜色),并按处理的先后顺序将片元存入到数组中,之后对数组进行插入排序操作.此策略仍然需要打包深度及颜色,但排序是在寄存器级别上进行,排序计算很快.虽然该方法取得了不错的加速效果,但由于空间的限制,它所处理的模型不能很大,模型的深度层次不能太多.与已有工作相比,本文方法只进行模型数据的一遍读取,就能对所有片元进行正确的深度排序,且没有深度层次的限制,故能有效提高多片元效果绘制的速度,且方便处理大模型.由于新方法可及时进行合并计算以节省空间,所以可使用更多的光照参数增强绘制效果,这是已有基于GPU进行多片元绘制的方法所不具备的.3基于凸多面体方式的网格化组织一个凸多面体的面片,从任一视点观察,只会有前后2层的深度关系,它们的排序可以在GPU中方便地实现,详情将在第4节介绍.据此,我们对3维模型进行凸化组织,生成凸多面体集并对它们进行网格化的组织;由此,在绘制时,可根据当前视点方位快速地确定将凸多面体逐个地传入GPU的序列,以保证片元的深度层次关系能得到正确的处理,以完成多片元效果的绘制.在此,我们并不要求每个凸多面体都是一个封闭的整体,只是将位于一个凸多面体上的所有面片当作一个整体进行计算.在这过程中,所有面片只会传输到GPU中1次,有利于化解数据读取对GPU上多片元绘制效率的瓶颈影响.模型的凸多面体化及网格化组织只需预计算一次,可进行反复的绘制计算.下面我们先介绍模型的凸多面体分解,再介绍凸多面体的网格化组织及传输顺序的处理方法.3.1凸多面体的生成在此我们使用以下的方法来生成凸多面体:将一个三维模型分解成凸多面体的工作很多,(1)导入模型,计算面片的法向量并记录每个面片相邻的面片.(2)对任一还没被处理的面片,将其作为种子点进行逐步的扩展,以得到一个新的凸多面体.此时,剔除位于此面片所在的平面正面之上的面片,并将与其邻接的位于其平面正面之下的面片加入该凸多面体中;然后,对新加入的面片,也依次进行上述的剔除操作,并加入新的面片.如此迭代进行,直至没有新的面片加入,就完成了一个凸多面体的生成.(3)反复进行步(2)的计算,直至模型的所有面片都被划分到某一个生成的凸多面体中.3.2网格化组织及排序将模型分解成一些凸多面体后,我们对模型的包围盒进行网格化划分,即生成正交网格,并使得每个网格中只有数目不多的几个凸多面体(我们的实现中一般生成均匀网格,以减少网格化的开销,且不会影响凸多面体处理顺序的判定).根据规则数据场体绘制技术的研究,这些正交网格可根据坐标轴方向形成一层层的组织,而每层网格可形成一行行的组织.由此,根据视点方位,可确定这些网格层的处理顺序,以保证先处理的层一定位于后处理的层前面;而在处理每层时,也可类似地确定网格行处理的Page4顺序,以保证先处理的行一定位于后处理的行前面.对于一行中的网格单元,也容易获知它们处理的前后顺序.因此,借助于正交网格的帮助,我们可确定凸多面体的传输顺序,以保证先传送的凸多面体一定位于后传送的凸多面体前面.具体的计算如下:按照网格处理的前后顺序,依次检测各个网格中是否有凸多面体.如果有,就将该网格中的凸多面体处理完以后,再继续检测后续的网格.如果一个凸多面体覆盖多个网格,就要使位于这些网格前面的网格均被处理完以后,才能处理这个凸多面体.对于网格化组织中的网格层和网格行,由于它们均可各自独立地进行其局部的前后顺序排列,因此,我们就可正确地得到凸多面体传输的顺序.不失一般性,我们以一个2维例子进行说明.在图1中,有5个凸多面体.根据视点V,我们知道由前往后处理这些网格的顺序是,沿着y坐标降低的顺序依次处理网格行,在每行中沿着x坐标增加的顺序依次处理各个网格.因此,凸多面体A被最先处理;当顺序检测到网格(2,3)时遇到凸多面体B,由于它覆盖多个网格,因此要转而检测下一行网格,即从网格(0,2)开始检测.由于网格(0,2)中有凸多面体C,且也覆盖多个网格,因此也要检测它前面的网格(0,1).此时,凸多面体C就可处理了.处理完以后,就根据迭代处理的顺序,再继续检测网格(1,2),(1,1),(1,2),(2,2),至此,就可处理凸多面体B了.依此类推,再处理凸多面体D,最后是凸多面体E.这样,就完成了这些凸多面体传输顺序的判断,保证先处理的凸多面体一定是位于后处理的凸多面体前面,使得多片元效果能得到正确的绘制.图14×5的二维网格(圆表示凸多边形,V表示在左上方位的视点位置,它的主观测方向为(Vx,Vy))在以上例子的说明中,每个网格所包含的凸多面体最多只有一个.如果网格组织中的凸多面体之间不存在循环遮挡关系,则按照上面的遍历算法总能得到凸多面体序列.对凸多面体之间存在循环遮挡的情况,可以采用文献[14]中的方法先去除循环遮挡,然后再使用上述方法遍历.当一个网格中包含多个凸多面体时,则要将该网格中的凸多面体进行有效的处理,以保证与一个像素相关的片元能得到正确的前后排序.下面我们分几种情况对此进行讨论.3.2.1嵌套多面体对于一个凸多面体内部包含其它凸多面体的情况,我们要进行如下的处理,以保证这些凸多面体的面片得到正确的排序.首先,在建立网格化组织时,我们要探测是否有凸多面体包含其它的凸多面体的情况.如果有,就将该凸多面体及其包含的凸多面体作为一个整体处理(只包含部分的,就将所包含的部分分割进来).处理它们时,只有当其所包含的凸多面体都被处理了以后,才能处理这个凸多面体.这样,就根据凸多面体之间的包含关系形成了一种嵌套组织的处理方法.具体情况,详见第4节.3.2.2相邻凸多面体的分离对于3维空间中相邻的两个凸多面体,很难用一个平面将两者分离.为保证它们的面片的正确处理顺序,我们提出一种slab结构将它们分离.如图2中的2维例子所示,slab是由两个平行平面组成的一个夹层结果,保证这2个凸多面体只能位于该slab结构的两侧,而slab内部包含有这2个凸多面体的面片.沿着slab结构的平行平面的法向,将这两个凸多面体往slab的平行平面上投影,就能得到slab结构的大小,一般是将其生成一个薄的长方体形状.图2将相邻的两个凸多边形进行分离的slab结构不失一般性,我们以一个例子来说明一个slab结构的生成方法.对于相邻的两个凸多面体为A、B,先计算A中与B相邻的面片集Sa,并对Sa进行主元分析(PCA),得到其最短轴所对应的法向犖犪;根据犖犪生成一些平行平面,从中找到两个平面,使得它们形成的夹层可将这两个凸多面体分开.这就Page5形成了一个可能的slab结构.对于B中与A相邻的面片集Sb,我们进行类似的计算,也得到一个可能的slab结构.比较这两个结构的厚度,即相关平行平面的间距,选择其中较小的作为这两个凸多面体的slab结构.基于这样的slab结构,就可将两个凸多面体分离,使得它们之间的排序容易进行(此时,它们各自要舍弃位于slab结构中的面片).由于一个slab结构中只含有2个凸多面体的面片,它们最多形成4个深度层次,因此可方便地在GPU中排序,这将在第4节介绍.3.2.3凸多面体密集的网格对于包含较多凸多面体的网格,我们将采取下面的方法进行处理,以便绘制时能对它们进行高效的排序.首先,对于这些凸多面体中相邻的情况,通过生成slab结构进行分离,而对不相邻但比较靠近的2个凸多面体,则找到一个平面片进行分离.然后,根据这些平面片和slab结构的分布情况,进行相应的处理.由于它们的分布可分为向心分布(此针对二维情况,三维则是楔形分布)与非向心分布2种情况,我们可采用2种方式进行分别的处理.图3一个网格中slab结构及分离平面的分布(1)当它们的分布呈现向心分布时,如图3(a)所示,我们就根据这些平面片及slab结构的平行平面,将它们的包围球(图中2维情况下是包围圆)进行剖分,然后,对于剖分的每个球面部分,记录当视点位于该球面部分对应的相位时,这些凸多面体被处理的前后顺序.这样,在绘制时,就只要调用这个记录,就可对这些凸多面体及slab结构进行正确的顺序处理.由于这种结构一般不多,因此这样记录的信息不会占用太多空间.(2)对于非向心分布的情况,如图3(b)所示,我们可对该网格进行更小尺寸的子网格划分,使得每个子网格中不包含多于2个凸多面体的情况.当然,对于分布疏密不均衡的情况,可以进行多分辨率的子网格创建.由此,可用前面所述的方法对凸多面体进行排序.对于向心分布的探测,我们可用以下方法进行:对于这些slab结构的平行平面与分离面片所在平面,从中任意选一作为考察平面,然后求取其它平面与该考察平面的交线情况,如果这些交线的交点位于一个较小的范围内,则说明是向心分布的.4GPU上的片元前后排序多片元效果的绘制,根本的是要保证每个像素的片元能正确地前后排序.在本节,我们先讨论单个凸多面体情况下的片元排序,然后介绍网格组织方式下的片元前后序列的正确实现,由此实现数据单遍读取情况下的GPU上的多片元效果绘制.4.1单个凸多面体对于一个凸多面体,其靠近视点的那层面片是朝向视点的,而远离视点的那层面片是背离视点的.因此,根据视线方向与片元法向的点乘,即可将片元分成前后两层.对于一个封闭的凸多面体,所有被它覆盖的任一像素,其相关的视线只会有2层片元.为此,我们使用MRT的两块纹理缓存保存前后面的片元信息,在对它们分别进行光照计算后,再对它们进行合并运算.如图4(a)所示,纹理缓存T1保存凸多边形C1的前向面片元,而T2保存其后向面的片元.具体实现时,我们不采用MRT默认的REPLACE合并操作模式,因为在更新某个纹理单元时,它会并发更新同像素位置的所有纹理单元,导致一些已处理的片元信息丢失.为此,我们采用32比特浮点型MAX合并操作,并先将两块纹理缓存的值都初始化为0(该值在透明绘制时将保存色彩信息,而在半透明绘制时是深度信息,这些值都不会小于0).当处理一个片元时,先判断其是前向还是后向.若是前向片元,就将在T1中存储其颜色、深度等值,而在T2中对应位置置0;反之,就将在T1中置0,而在T2中对应位置存储其颜色、深度等值.当然,实际写入前,要进行值的比较,即只有将写入的值大于已在Page6图4单个凸多面体的面片的前后排序及合并计算该位置存储的值的时候,才会有真正写入.由此,前后2层片元的情况就能得到真实的反映,然后将它们进行合并操作,就完成了该凸多面体的绘制.对于不完全封闭的凸多面体,我们的算法也可同样地处理,因为对于只有1层片元覆盖的像素,其另一层对应的纹理单元值一直是0,并不会影响混合的绘制效果.如图4(b)所示,C2为不完整的凸多边形,纹理缓存T4保存了它后向面的片元,而T3只保存了一些片元信息,在色彩混合计算时,这并不会影响最终的结果.4.2凸多面体序列在绘制一个模型时,根据预计算得到的凸多面体的网格化组织和当前视点的方位,我们按照第3节的方法,先对网格结构进行遍历,计算出凸多面体的传输顺序,然后逐个地传送凸多面体到GPU中处理.对于送到GPU中的凸多面体,我们先将其按照4.1节介绍的方法进行绘制,然后将其结果与已绘制的凸多面体的结果进行合并绘制,就能在GPU中完成整个模型的多片元效果绘制.对于不包含凸多面体嵌套的情况,我们直接将凸多面体按照可见性的前后顺序进行传输.此时,刚传入的凸多面体一定与已处理的凸多面体形成前后排列的情况,于是,在GPU中使用合并操作即可.而对于包含嵌套凸多面体的情况,我们的处理如下:对于一个嵌套的情况,先将最外层的凸多面体进行绘制,并将其前后两层的情况分别存放在2个纹理缓存中;然后对其所包含的凸多面体进行绘制和合并操作,将所形成的一个纹理图像,插入该嵌套的最外层凸多面体所形成的2层纹理之间,并进行这3个纹理层的合并操作,就完成了该嵌套的绘制.对于嵌套层次比较深的情况,我们要先处理最里面的嵌套结构,再逐步处理较浅的嵌套结构,以减轻GPU中的空间需求.Slab结构是一种特殊的情况.由于它最多可形成4个深度层次,因此,我们采用文献[13]的方法就可完成一个slab结构的处理.文献[13]一次可以对8个片元进行排序,且没有RMW的读写冲突,故此方法可对slab进行完整的处理.当所有凸多面体都送入GPU中绘制后,我们就完成了整个模型的多片元效果绘制.在此过程中,模型的所有面片都只被读取了一遍.5实验及讨论我们用OpenGL2.0及GLSL1.20实现了本文提出的方法,并与基于CUDA方法的两种策略(MDTS和ABS)[5]、桶深度剥离算法及其拓展的两遍桶深度剥离算法(BDP2)和自适应桶深度剥离算法(ADP)[4]、双面剥离算法(DDP)[2]及深度剥离算法(DP)[1]等进行对比实验.实验在一台微机上进行,该机器装有一个IntelQuadCoreQ6600CPU,3GB内存和一个带有1024MB显存的NVIDIAGTX280GPU.实验中,我们选择了两种有代表性的多片元效果绘制,即透明和半透明效果的绘制.透明绘制时,主要是片元的光照色彩和透明度根据片元的前后顺序进行混合计算,不必考虑片元的深度值;而在半透明绘制时,还要考虑光线在模型内部行走路径长度对光照的影响,因此需要计算各个片元的深度信息.在我们的方法中,因为各个凸体元的色彩信息进行了及时的混合,在GPU中对纹理空间的要求不高,因此可以有更多的空间用于存储片元的材质信息,以进行更好的光照计算.而目前计算速度较快的桶深度剥离方法[4]和基于CUDA的深度剥离方法[5]要在GPU中保留多层的片元深度信息,使用了大量的显存.半透明绘制时,我们主要考虑了两种光能衰减Page7的影响因素,其一是光线穿越模型路径的长度的影响,按照Beer-Lambert法则,其衰减系数的计算公式是exp(-σtl),在此σt为吸收系数,l为光线穿越模型路径的长度,可由相邻两层片元之间的深度差获得;其二是关于折射的Fresnel效果所引起的光能衰减,我们在此使用Schlick公式近似Fresnel效图5透明与半透明绘制效果图5.1性能分析由于不同方位观察模型时,深度层次的差异比较大,对绘制效率有比较大的影响.为此,测试时我们在这些模型的周围比较均匀地分布一些视点,然后求其平均绘制速度以进行比较,统计结果在表1中列出(在此所绘制的图像都是512×512像素.表1测试模型的透明绘制速度比较绘制速度/(帧·s-1)模型(面片数)(凸体个数/层次)Teapot(6320)Person(12936)Hourglass(38141)(12/6)1083.34348.43(2.11)703.32(0.54)412.24(1.63)215.4(4.03)923(0.17)625.45(0.73)(28/14)909.35246.34(2.69)653.45(0.39)378.45(1.4)218.34(3.16)366.45(1.48)212.77(3.27)(19/12)423.4378.34(4.41)324.34(0.31)215(0.97)142.34(1.97)219.57(0.93)212.31(0.99)Desk(56340)(24/12)243.3236.34(5.7)139.34(0.75)317.35(-0.23)214.34(0.14)160.24(0.52)141.46(0.72)Horse(96966)(68/8)403.25178.34(1.26)394.56(0.02)212.77(0.9)128.21(2.15)75.79(4.32)51.18(6.88)Hand(654666)(103/10)273.4697.36(1.81)263.43(0.04)141.42(0.93)106.45(1.57)44.29(5.17)26.60(9.28)注:表中对比方法的速度数据后面括号中的数字,是新方法相比于它们的加速率.果的计算[15],相关的衰减系数计算公式为1-(1-cosθ)5,这里,θ为片元上所绘制位置相关的入射光线与视线的夹角的一半角度.图5中的(a)、(b)为透明绘制效果图,(c)、(d)、(e)、(f)为半透明绘制效果图.显然,这些图都具有很高的质量.MDTS及ABS为基于CUDA的深度剥离方法的两种策略,BDP2及ADP为两遍桶深度剥离算法和自适应桶深度剥离算法,DDP及DP为双面深度剥离及深度剥离方法.凸多面体生成和网格化组织等都属于预处理阶段的操作,故没有把这些操作的处理时间加入到绘制时间中).从表中可见,当模型较简BDP2Page8单、深度层次不大时,新方法的加速效果不是很明显,比如处理Desk模型时,新方法相对于ADP方法的加速率只有14%,甚至比BDP2方法还略慢;但当模型复杂,深度层次较大时,新方法的加速幅度很大,比如处理Hand模型时,可提高速度多倍.由于新方法是逐个地传输凸多面体进行绘制,凸多面体数目较大时,新方法的速度也会受影响.但总的来说,新方法相比于已有方法都能提高速度,即便与基于CUDA的一次性装载数据的方法相比[5].为了评估深度层次对各类方法的绘制效率影响,我们使用图6中的场景进行测试.各类方法的绘制速度如表2所示(在此所绘制的图像都是1024×1024像素.层次16~96分别对应的“面片数/凸多面体个数”为1267200/32,2534400/64,3801600/96,表2不同深度场景的绘制效率比较深度层次163248648096注:“”表示由于空间需求过大,MDTS方法不能运行;表中对比方法的速度数据后面括号中的数字,是新方法相比于它们的加速率.5.2内存分析对于分辨率为512×512的场景绘制,我们的方法只需要2MB显存来存储前后面的片元,同时使用2MB显存存储中间绘制结果,与双面深度剥离方法相当.而对于MDTS及ABS这两种基于CUAD的方法及桶剥离的方法,它们需要消耗非常大的显存,表3不同图像分辨率及场景深度下的各对比方法的显存使用情况216181241层次(分辨率)20层(512×512)60层(512×512)20层(1024×1024)60层(1024×1024)6结束语在GPU上进行多片元效果的绘制,已有方法往往要进行多遍的数据读取,以对片元进行排序.对此,本文提出一种只需单遍读取模型数据的方法,以有效降低数据读取对绘制效率的影响,提高绘制速度,同时,能使用更多的材质信息进行复杂的光照计算,提高绘制效果.该方法主要是对模型进行凸多面体化的组织,逐个地将凸多面体送入GPU中以有效5068800/128,6336000/160,7603200/192).从中可见,新方法是最快的,即便与基于CUDA的MDTS方法相比,新方法的加速效率也是随着深度层次的增加而更好的.图6评估深度层次对绘制效率影响的16层测试场景(沿着球面层叠方向平行观察,此场景深度为16层.其它深度的测试场景列数不变,深度依次加深到32至96层)场景深度越高,消耗的越大.相关统计数据在表3中列出.从中可见,当绘制分辨率达到1024×1024时,我们只需16MB显存,而MDTS方法在分辨率为1024×1024、层次为60层时,所需的内存为240MB.显然,在实际应用中如此大的空间需求是难以处理的.显存需求/MB处理片元的排序,由此实现单遍数据读取的目的.实验表明,新方法相比于已有工作都能提高速度,特别是在处理深度复杂性高的模型时,其加速效果更好.本文方法的效率是与凸多面体个数相关的.个数越少,加速效果越好.因此,在将来的工作中,我们将进一步研究模型的凸多面体生成方法,尽量减少模型分解的凸多面体个数.致谢感谢LouisBavoil和KevinMyers的开源测试代码.感谢刘芳博士和黄梦成博士的讨论与帮助!Page9
