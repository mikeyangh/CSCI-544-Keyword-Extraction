Page1一种网络话题的内容焦点迁移识别方法周亚东1)刘晓明1)杜友田1)管晓宏1),2)刘霁1)1)(西安交通大学智能网络与网络安全教育部重点实验室西安710049)2)(清华大学自动化系智能与网络化系统研究中心北京100084)摘要随着网络信息技术的迅速发展,互联网已经成为人们获取和发布信息的最重要平台之一.在互联网的信息传播过程中,话题相关文本不断更新,而其内容焦点也随着话题发展发生着迁移.识别话题内容焦点有助于有效地挖掘与分析网络信息,是网络舆情分析领域的重要研究问题.文中针对网络流文本,提出了一种网络话题内容焦点的识别方法,首先对话题焦点特征在流文本中的分布情况进行分析,基于分析结果介绍了焦点识别方法3个主要步骤的算法模型,分别是基于时间属性的焦点特征词提取、内容焦点特征词的合并和内容焦点的表示.文本基于来自于真实网络的实际数据,对所提方法进行了实验验证,实验结果表明文中所提方法可有效获取话题发展过程中的内容焦点,并能以关键词集和语句集的形式对内容焦点进行表示.关键词网络话题;焦点识别;舆情分析;话题模型;社交网络;社会计算1引言在阅读和发布着大量网络文本,例如每天不断更新的网络新闻,博客、微博、论坛用户发布的博文网贴,连续收发的电子邮件等,并且在这些网络文本中蕴随着网络和信息技术的迅速发展,人们每天都含着大量有关舆论热点的有价值信息.从时间的角Page2度分析,这些网络文本形成了一种随时间分布的流文本数据.在阅读这些网络流文本数据时,人们会发现,关于某个热点话题的网络流文本的内容焦点随着时间的变化在动态演变迁移,例如:关于某个事件的网络新闻报道在不断更新,但报道内容侧重不同;针对某个网络话题的网络评论不断被发布,但其关注重点在逐步变化.及时识别和发现网络热点话题的内容焦点的迁移,可以更全面地了解网络话题信息组成结构及其演变趋势,对于分析网络舆情态势、判断舆论预期走向具有十分重要的价值,也是网络舆情分析研究领域中的一个重要研究问题.但在实际数据中,无论是网络新闻文本还是博客、论坛文本都具有文本冗余信息量大、内容焦点特征提取难度大等难题,为识别网络话题的内容焦点提出了较大挑战.本文以网络流文本为对象,通过分析网络话题内容焦点的迁移特性,提出了网络话题内容焦点的识别方法.网络话题内容焦点可由引发网络话题的热点事件、事件对社会的影响、用户对该话题的评论、后续相关事件发展等组成,也包括关于某话题的焦点起始、达到高峰、逐渐消亡的演变过程以及各个焦点之间的影响关系等内容.方面内容:结合以上分析,本文所做研究主要分为以下几(1)针对内容焦点识别的需要,分析焦点特征词在网络话题流文本中的分布情况,归纳分析焦点特征词的主要分布特点,为后续方法提供基础.(2)针对网络话题流文本数据,提出基于时间属性的焦点特征词提取算法,可提取语义具有代表性且在时序分布上能覆盖全文的焦点特征词,以达到保留原流文本集的内容焦点的主要关键信息和降低处理复杂度的目的.(3)任一内容焦点可由若干个特征词共同描述,需将同属一项内容焦点的特征词合并,本文借鉴了概率话题模型的建模思想,提出了焦点特征词的合并模型,通过计算任意两个特征词间的相似度,并结合文本时序特性,将描述同一个关注焦点的特征词合并.(4)根据合并的特征词集合数据,结合流文本数据,将网络话题的各阶段内容焦点表示,提取出各个内容焦点的起始时间、关键词和内容摘要等信息.文本研究数据来源为“新浪博客”网站和“新浪新闻”网站中的2009年和2010年两年的网络流文本数据,共人工标定114组热点话题的内容焦点数据用于分析研究,后续为叙述便利和篇幅限制,将以2009年发生的“杭州飙车案”话题为例介绍算法流程和实验结果.本文首先分析国内外相关研究工作现状,然后提出网络话题内容焦点的识别方法,接着基于实际网络流文本数据实验验证所提方法的有效性,最后给出结论.2相关工作本文研究了网络话题内容焦点的识别方法,与之相关的研究主要包括话题检测与跟踪、网络话题动态演变特性分析等.以下介绍国内外相关研究的发展现状与趋势.2.1话题检测与跟踪研究现状话题检测与跟踪(TopicDetectionandTracking,TDT)[1-2],起源于美国国防高级研究计划署(DARPA)1996年展开的一项计划.TDT研究的数据大多数是真实的新闻报道,新闻报道的事件主要包括时间、地点、人物、事件这几个要素.Carthy等人[3]利用WordNet建立语义链,将文本表示成语义链的集合,通过比较两个文本语义链之间的相似度来判断文本是否属于同一话题,并通过实验得出实体名词有利于提高文本分类精度的结论.Makkonen等人[4]通过定义语义向量,在TDT中引入简单的语义,来提高文本检测的准确率.Pons-Porrata等人[5]提出了一种新的层次化的文本聚类算法,它以网络新闻文本为研究对象,将文本中的所有与时间表述有关的词都提取出来,并利用这些词重新定义了文本相似度比较函数,并通过实验证明该方法能提高聚类效果.国内学者在这方面也有较多研究成果.贾自艳等人[6]提出了基于时间距离的相似度计算模型,以文本的创建时间为时间起始点,统一文本中的时间表述方式,通过比较两篇报道间的时间差值,来削弱基于内容获得的相关度.宋丹等人[7]则改进了原有的向量空间模型,将文本表示成四个独立的向量空间,分别为地点向量、时间向量、人物向量和内容向量,同时提出了通用的向量相似度衡量方法,时间向量相似度方法以及地点向量衡量方法,最终将文本的分类问题转化为相似度的计算问题.但是文章中没有介绍如何正确分辨并提取对应的时间类词、地点类词等.话题模型的层次化和结构化研究是目前TDT领域的重要方向,其中,层次化主要指将同一话题下的新闻报道组织为具体的层次结构;结构化侧重挖掘同一话题的不同侧面.国内相关研究在方法上注重自然语言处理技术和统计学相结合,在趋势上,逐Page3步与数据挖掘、事件抽取以及篇章理解等相关技术相融合.2.2信息检索相关领域研究现状在特征提取方面,Yang等人[8]比较了几种常用的特征提取方法:文档频率法(DF)、信息增益法(InformationGain)、互信息法(MutualInformation)、C2统计方法[9]和TermStrength方法[10].并通过实验表明,在KNN和LISF分类器下,在保证相同分类精度的前提下,信息增益法和互信息法降维的力度最大.之后,代六玲等人[11]在中文特征抽取问题上也对这些方法进行了比较,并得到了相似的结论.Mei等人[12]提出了一种在多维话题模型中,自动且客观的生成标签的方法.Mei[13]还基于PLSA[14]模型提出了CPLSA(ContextualProbabilisticLatentSemanticAnalysis),该模型通过对文本的诠释资料(例如:作者、出版社和发表时间等)进行分析,从而判断两个文本主题是否相同.在话题演变问题上,Pui[15]从文本分类的角度提出文本主体变化的检测方法,通过DCM(Discrimi-nationCategoryMatching)方法来建立该主题变化过程的模型.Jure[16]以网络博客为研究对象,分析社会网络,得到了信息传播、话题演变的规律.Jure[17]还以网络新闻文本和博客中的小短句为研究对象,通过分析发现博客帖子达到关注的峰值总要比新闻文本达到关注峰值的时间晚2.5h.Myra[18]提出了MONIC(ModelingandMonitoringClusterTransitions)框架,通过研究文本聚类中各个子类在不同时刻的不同数据集之间的交并比例关系,分析子类之间的演化过程,包括新生、消亡、吸收和分散.2.3其他相关方法研究现状在自然语言处理领域,向量空间模型(VectorSpaceModel,VSM)[19]是目前使用最为广泛的文本模型,该模型基于词袋假设把文本表示成由特征权值构成的向量,这种方法已经成功应用在文本自动分类和静态文本聚类等方面.目前,国内外学者重点对话题模型展开了研究,通过分析话题模型来达到识别话题的目的.话题模型(TopicModel,LanguageModel)是信息检索领域中普遍使用的一种文本模型,这种方法构造了一个可以描述文本生成的随机过程,通过EM[20]算法、蒙特卡洛马尔可夫[21]等参数估计算法反推模型参数,得到描述文本深层主题信息的统计量.在文本表示中,向量空间模型和话题模型都有应用,例如Aggarwal等人[22-23]使用的是基于词频-反向文档频率(TermFrequencyandInverseDocumentFrequency,TFIDF)的向量空间模型表示法,Liu等人[24]则使用基于语义平滑模型的话题模型表示法,Walker等人[25]使用概率话题模型文本表示法.3网络话题的内容焦点的识别方法本节首先对话题焦点特征词在网络流文本集合中的分布情况进行分析,并以此为基础,介绍网络话题内容焦点识别方法中的3个主要步骤,分别包括特征提取、特征合并和焦点识别,并将介绍各步骤的理论模型和实现算法.3.1话题焦点特征词在流文本中分布特点的分析为了能够正确识别网络话题内容焦点的特征词,需要从特征候选词集中,选择具有前文提到的语义明确、与话题相关、能反应话题的某个焦点以及能与其他话题区别等4个特点的词作为特征词.以话题“杭州飙车案”为例,随着话题讨论的发展,通过人工分析发现其关注内容迁移分为6个焦点(见图1).本文绘制了4组典型的特征词和噪声词的词频-文档分布图,如图2~图5所示.图1话题“杭州飙车案”的内容焦点迁移情况Page4噪声词.指与话题内容无显著关联(可称为无关噪声词),或者对话题焦点相关内容识别会产生干扰的词语(可称为干扰噪声词).特征词.是能够描述事件的最恰当的词语,是代表事件中焦点的标准化术语.在这些图中,横轴代表流文本集中的各个文本编号(按照文本发布时间先后进行排序),范围从0~195,表示该话题相关的196篇网络文本;纵轴代表所示词在各个文本中出现的次数.通过分析图2~图5可以发现,特征词和噪声词在文档分布上存在较大差异,特征词的分布特性归纳如下:(1)频度较高.作为话题内容焦点的特征词,其语义是话题发展过程中某个阶段的重点,因此该词应该在这个阶段具有较高的词频,而在其他阶段不具有高词频.(2)分布持续.话题内容焦点存在一定生命周期.因此话题内容焦点的特征词若在t时刻出现,那么也很可能在t+1时刻出现,呈现出持续性.(3)持续时间适中.特征词用于描述某个内容焦点,则其持续时间与该焦点的生命周期相近,并且小于话题的生命周期.(4)同焦点的特征词时序分布重合.在话题发展变化过程中,同一项焦点的若干特征将同时出现的,他们共同表达了这个阶段的主要焦点.这4项特性中,前3项可用于特征词提取评估函数的建立,第4项可用于特征词合并方法的设计.对于无关噪声词和干扰噪声词,无关噪声词主要是一些常用词,可用于描述话题的个别内容,但与话题主要内容关系不大.如图3中列举的“对不起”,该词语在话题文本中有一定出现频度,但由于与杭州飙车案的焦点内容关系较小,在文档词频上不符合“频度较高”和“分布持续”等特性.干扰噪声词是与话题内容有关,但含义较为宽泛,会对识别话题焦点造成干扰的词语,但一般在话题相关文本中长时间存在,在文档词频分布中不符合“持续时间适中”特性.如图2中列举的“杭州”,该词语与话题的全部内容均有较大关系,无法用于准确表征某单项焦点,则会对各项焦点的识别产生干扰.需要注意的是特征词的分布存在一些噪声,如特征词“113万”在文档138之后还有少量出现,这对于评估特征词存在干扰,因此可采用均值滤波法对词频-文档分布进行过滤,以增强特征词与噪声词间的差异.3.2基于时间属性的焦点特征词提取算法通过提取可表征焦点内容的词作为特征,一方面降低了文本表示的维度,使得算法的复杂度降低;另一方面减少了噪声对话题内容焦点识别的影响,提高了识别准确度.网络话题内容焦点识别针对的数据为带有时间属性的网络流文本集合,其与普通静态文本集合的最大区别在于具有时间属性,因此本文提出了一种基于时间属性的特征提取算法.该算法主要包括文本预处理和特征提取两个部分.Page5得到文档词集;重,生成词频文档矩阵;分别提取该文本的标题、正文和发布时间;在文本预处理部分,主要的算法步骤为:(1)对关于某话题的流文本集中的每个文本,(2)对每个文本的标题和正文分别进行分词,(3)计算文档词集中每个词在流文本集中的权(4)根据标题的分词结果,生成特征候选词集.在特征提取部分,主要的算法步骤为:(1)分析特征词的特点,并建立评估函数;(2)根据评估函数,计算每个候选词的权重;(3)将特征候选词按照权重值大小排序,并设以下,本文将详细介绍特征提取部分中的评估定合理阈值,提取特征.函数和特征筛选方法.3.2.1评估函数的建立根据特征词分布的前3项特点,假设某个话题的流文本集为Dz={d1,d2,…,dMz},则对于特征候选词集中的任意一个词wk∈C,给出如下的评估函数:f(wk)=∑Nk式中,Nk为包含词wk的文本的个数;di为包含词wk的第i个文本;freqi,k为采用均值滤波法对词频-文档分布平滑去噪后的文本di中词wk的出现频度;time(di)表示文本di的发布时间;μ,σ为函数中的经验系数.该式可体现本文上面提到的焦点特征词分布的几项特点.评估函数的值与freqj,k即词频成正相关;与(time(di)-time(di-1))反相关,即出现特征词的两个文本间的发布时间差距越近,评估函数值越大,体现特征词的分布持续性;e-约束词的持续时间,从该函数的增减性可体现候选词的持续时间应该在一个合理的范围内,由于大部分情况下话题的单个焦点持续时间为2~3天,因此通常μ可取值为2.5.3.2.2特征提取利用评估函数值确定话题内容焦点的特征词,即特征提取.本文采用TopM原则,该方法的核心思想是把候选特征词按照其评估函数值大小进行排序,然后从中选择M个词,成为焦点特征词集合.3.3内容焦点特征词的合并方法网络话题的关注焦点需要若干特征词共同描述,因此需要在提取出的焦点特征词集的基础上,合并描述同一项内容焦点的特征词.本文借鉴概率话题模型的方法和原理[26-27],提出了内容焦点特征的合并方法.3.3.1特征合并模型的建立概率话题模型的思想是通过引入隐变量,描述一个文本的生成过程,并且建立了话题与文本间的关系.本文借鉴其思想,通过引入一个二维隐变量,建立了特征合并模型,可描述网络流文本集的生成过程,并可描述焦点特征词与焦点相关流文本集的关系.假设包含某一内容焦点特征词gi的网络流文本集Di由文本di1,di2,…,diNi构成,且每个文本都包含一个或多个该焦点的特征词.因此,可认为网络流文本集Di可由两部分信息组成:一部分信息fi与焦点特征词gi相关;另一部分信息珚fi与焦点特征词无关,称为背景噪声.并且可认为文本集Di是由这两部分线性混合组成.因此,引入一个二维隐变量表示为设V为在关于某话题相关的所有网络流文本集中出现过的所有词的集合,如果需要生成一个焦点流文本集Di,则步骤如下:(1)以p(fi|Di)的概率从F中选择组成焦点文本集Di的一个部分fi;(2)以p(w|fi)的概率从词集V中选择与fi有关的词w;(3)以p(珚fi|Di)的概率从F中选择组成文本集Di的另一个部分珚fi;(4)以p(w|珚fi)的概率从V中选择组成与珚fi有关的词w.经过上面4个步骤,可生成一个文本集Di.从该文本集的生成过程中,可以得出本文特征合并模型的核心公式:p(w|Di)=p(w|fi)p(fi|Di)+p(w|珚fi)p(珚fi|Di)因为p(fi|D)+p(珚fi|D)=1(4)令p(珚fi|Di)=λ,则p(fi|Di)=1-λp(w|Di)=(1-λ)p(w|fi)+λp(w|珚fi)(5)其中,λ表示背景噪声部分信息占文本集Di总信息的比例,根据经验和实验结果分析通常可取值为0.8.式(5)为本文特征合并模型的最终表达式.通过该式中的p(w|fi)可建立特征词gi与文本集V中的任一词w之间的关系.Page6此时,判断文本集的特征词gi和gj的语义内容是否描述了同一项内容焦点,可通过计算由特征合并模型建立的两个关系p(w|fi)和p(w|fj)是否相近,如果gi和gj描述了同一项内容焦点,则与其相关的其他词集将会有较大的重叠.因此,求解式(5)中的p(w|fi)是非常重要的问题,其计算方法在下节详细介绍.需要注意的是,对于每一个特征词gi,我们需要为其构建一个文本集合Di,但由于特征词由TopM准则选择,因此一个话题的特征词数量最多只有M个(在基于实际数据的分析中,我们选取M值为40),因此在这种情况下,为每一个特征词构造文本集产生的计算量是可以接受的.3.3.2合并模型中的参数估计方法数估计问题的似然函数,表示为L(fi)=L(p(w|Di))对于式(5)中p(w|fi)的估计问题,可建立该参式(6)的似然函数又被表示为令n(w,d)为词w在文本d中出现的次数,则L(fi)=∑d∈Dk∑w∈V式(7)的似然函数过于复杂,是和函数的对数,用传统的极大似然估计法进行参数估计比较困难,因此,本文采用EM算法进行参数估计.基于式(5)所示的模型,本文引入了一个隐变量z,对于任何一个文本中的词wij(w∈V,文本di中的第j个词)都有一个变量zij,用于指出该词是由背景噪声产生,还是由特征词相关内容产生.因此,zij具体表示为又因为所以,根据式(5)、式(8)和式(9)进一步得到p(z=0|w,d)=λp(w|珚fi)p(z=1|w,d)=(1-λ)p(w|fi)引入隐变量后,该参数估计问题的似然函数变为Lc(fi)=logp(w,z|d)定义Q函数为似然函数Lc(fi)对隐变量z的条件期望,则该参数估计问题的Q函数表示为Q(fi)=Ep(z|w,d)[Lc(fi)]=∑z因此得出如下优化问题:maxp(w|fi)Q(fi)因此,可得拉格朗日函数如下:到以下方程:对函数h(fi)求一阶偏导数,并令其等于零,得p(w|fi)=∑d∈Dk从上式中可以发现,p(w|fi)和∑d∈Dk1|w,d)成正比.因此,针对该参数估计问题,得到其EM算法迭代式如下:E-Step:p(z=1|w,d)=M-Step:p(w|f(n+1)从中可以发现,在计算E-Step时不需要精确地计算Q函数的值,可以通过计算隐含变量的概率分布代替.3.3.3特征合并特征合并是针对焦点特征词集合,两两比较它们的时序分布和相关词集是否都有较大重叠,只有两个条件都满足的特征词,才能够合并.以下分别给出特征词的时序分布和相关集词的合并条件.(1)特征词时序分布的合并条件对于任一特征词g,其时序分布Tsf的具体形式为式中,ts(g)征词的时序分布可能会出现不连续情况),t(g)具体的时刻.对于任意两个特征词gi和gj,一般情况下其时序阶段合并条件为Page7i∈Tsfiandts(gj)ts(gi)min{(t(gi)max{t(gi)其中,threshold为阈值,在本文中取值0.5.当条件式(21)不满足时,考虑特殊情况:(2)特征词相关词集的合并条件对于任一特征词g通过p(w|f)可找到文本词集中与之最相关的N个词,记作对于任意两个特征词gi和gj,其相关词集的交集满足下式时,可以合并.其中,N值可变,在本文中取N=10.G,最终可得到特征词的合并结果U,表示为通过上面给出的两个条件,对于焦点特征词集式中U代表对某话题所有焦点的特征词合并结果,ui代表其中某一项焦点的特征词集合.3.4网络话题内容焦点的表示网络话题内容焦点的表示是一个从特征词扩充到摘要的过程,核心步骤有两点:(1)提取可描述关注焦点s内容的关键词集合,以及这些词的权重;(2)检索可描述关注焦点s内容的语句,作为该焦点的摘要.对于提取能描述关注焦点s的关键词集合terms,已有存在特征合并后的关于某焦点的特征词集合ui={gi1,gi2,…,gik},目标是提取与ui最相关的关键词并计算权重.在前文的参数估计和特征合并中,已经知道根据每个特征词的p(w|fi),就能找到与特征词gi相关的词,同理,只要找到与ui相对应的p(w|ui),就能找到与ui最为相关的关键词.又因为ui是特征词的集合,所以本文给出如下结论:p(w|ui)≈∑M此时,假设ui中的特征词都是同等重要的,即αj值都相等,则若p(wj|ui)wj∈V越大,则词wj就与ui越相关.如果假设需要用10个关键词表述一个焦点,那么将p(wj|ui)按大小顺序排序并取最前的10个词作为关键词,则此时关注焦点s的terms可被表示为对于检索与关注焦点s最相关的语句作为该焦点的摘要abstract,可通过检索该话题相关网络流文本语句中包含关键词集terms最多的语句获得.至此,焦点的关键词集terms与语句摘要abstract都可以分析得到的,即可对网络话题的内容焦点进行表示.4实验结果与分析4.1基于时间属性的焦点特征词提取算法实验结果本实验首先通过人工标注出114组热点话题的内容焦点数据中每组热点话题的特征词集合,然后将本文所提的基于时间属性的特征词提取方法与经典的TF-IDF方法以及FSBIFDR方法[28]和STFS方法[29]进行特征词提取的性能对比,对比所用指标包括平均的准确率、召回率和F值,具体如下所示:准确率=正确识别的特征词总数/召回率=正确识别的特征词总数/F值=正确率×召回率×2/(正确率+召回率).以话题“杭州飙车案”为例,人工从话题文本的词汇集共8271个词(标题词641个)中标注出最能表征网络话题内容焦点迁移的24个特征词,接着分别采用基于时间属性的焦点特征提取算法(采用TopM原则,且M=40)和经典的TF-IDF特征提取算法进行实验对比,如表1所示.由于实验所用分词软件采用了基于知识库的分词算法,因此部分非常见的特征词未能正确划分,为了更好地贴近网络文本的处理流程,本文在做特征词人工标注时直接对分词软件处理后的分词结果进行标注,一些原属于特征词但被错误分词的单字也被标注为特征词.如“欺实马”被分为了3个单字,因此在人工标注中将这3个单字分别标为3个特征词(其他单字同属这种情况).对于被错误分词的单字特征词,由于其原属同一个特征词,在时序分布和相关词集两方面相关性较大,因此可在本文3.3.3节所介绍的特征合并算法中,被正确合并到同一个话题焦点的特征词集合.Page8表1网络话题“杭州飙车案”特征提取对比实验结果序号ID词17撞28死路39人4128车速5142欺680实7143马8184701049175码10196时速11181鉴定17512241报告42813310双方14442签订15443113万9816445元17104赔偿34918453获19526一审13020491321149年2225刑23559替身31324571出庭55925262728293031323334353637383940对所有114组话题数据的特征词提取实验结果如表2所示,可以看到本文所提特征提取方法的准确率、召回率和F值均明显优于3种对比方法,更是达到了传统的TF-IDF方法的2倍.0.005218胡斌0.005118鉴定0.004993安全0.003626网友0.0035680.003548谭卓0.003527赔偿0.003409公里0.003367事故0.0032940.0032790.0030900.003082公共0.003070改装0.003036危害0.0030160.002957车辆0.0029060.002883法院0.002859700.0028370.002835交通0.002731替身0.002725警方0.002721肇事者0.002719肇事0.002611法律0.002592公众0.002568部门0.002557交警0.002557超速0.0025170.002472记者0.0024420.002438司法0.002422行为0.002416社会0.002412肇事罪0.002406专家0.002403表2114组网络话题的特征提取对比实验统计结果TF-IDF33.416.30.22FSBIFDR54.126.30.35STFS基于时间属性的特征词提取69.233.80.454.2话题内容焦点识别的实验结果本文中的网络话题内容焦点的表示主要由两部权重分组成,分别是关键词terms和摘要abstract.表3展示了话题“杭州飙车案”的内容焦点的这两部分信息.从表3可以看到,对网络话题“杭州飙车案”,运用本文提出的网络话题内容焦点的识别方法,可识别出6个阶段性关注焦点,分别为“男子飙车撞死路人”、“车速70码成网络新名词”、“悼念死者谭卓”、“签订赔偿113万元协议”、“胡斌一审获刑3年”以及“胡斌替身出庭”.可见,该结果与人工标注的结果(见图1)在第3个焦点上出现分歧,但总体上结果吻合.因此,本文提出的网络话题内容焦点的识别和分析方法是有效的.Page9表3话题“杭州飙车案”的内容焦点对应的关键词、摘要与人工标注对比表焦点123456由于本文所研究的话题焦点迁移识别问题是随着网络舆情发展而产生的新问题,尚未发现有其他的焦点迁移识别算法,难以进行与类似算法的实验对比.由于较难量化说明关键词和摘要提取的准确率,我们分析了本文所提方法在114组热点话题数据上识别的焦点数量结果,如图6所示,对于绝大多数的热点话题,本文所提方法均能正确识别出焦点数量.图6114组热点话题中的焦点数量识别结果4.3方法中经验参数对实验结果的影响分析本文所提方法中主要有3项经验参数,分别是μ、σ和λ,其中参数μ的作用是约束话题焦点的持续摘要abstract遭刑拘新名词欺实马公共事件络新名词决定共安全万获接受113万均认为不公平身门调查置若罔闻时间(单位为日),其取值对特征词提取的性能有较大影响,因此为了进一步分析经验参数的选取对焦点识别方法结果的影响,我们选取了不同的参数μ取值,分析其对特征词提取的影响.如表4所示,参数μ的取值对特征词提取的影响较为明显,考虑到大部分情况下话题的单个焦点持续时间为2~3天,当选择μ=2.5时,特征提取的性能最好.当参数μ过小时,如取0.2的时候,无关噪声词就会出现较高的权值;当参数μ过大时,取到5天的时候,干扰噪声词会得到较高的权值.表4114组网络话题中参数μ对特征提取影响统计结果μ=0.212.7μ=148.9μ=2.569.2μ=543.05结论在互联网的信息传播过程中,随着话题事件的演变关于话题的流文本不断更新发布,而其内容焦点也随着话题发展发生着迁移,因此对网络话题动Page10态演变特性的分析和理解已成为目前国内外研究的一个热点问题.但由于自然语言问题的复杂,以及目前自然语言处理技术发展的相对不足,为解决这一问题提出了很大挑战.本文在总结和分析前人对网络话题动态特性分析和文本挖掘研究的基础上,通过大量实际数据的分析,发现话题焦点的特征词具有频度较高、分布持续、持续时间适中和同焦点的特征词时序分布重合等特点,并且提出了解决这一问题的主要步骤和相关算法,包括基于时间属性的焦点特征词提取算法和内容焦点特征词的合并方法等.基于实际数据的实验结果验证了所提的特征提取方法相比于其他方法更适合于解决话题焦点特征词提取问题,并且验证了所提的焦点识别方法可有效识别网络话题的内容焦点迁移情况.
