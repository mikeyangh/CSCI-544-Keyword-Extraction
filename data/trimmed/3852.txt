Page1数据中心应用请求级行为特征分析文雨1),2)孟丹1)詹剑锋1)1)(中国科学院计算技术研究所国家智能计算机研究开发中心北京100190)2)(中国科学院研究生院北京100039)摘要请求级行为分析有助于数据中心应用管理.已有研究中,一类方法要求了解应用内部细节和源代码,因此不适用于数据中心场景,另一类方法基于外部观测应用行为,不能得到精确的分析结果.该文提出一种新的面向数据中心应用的请求级行为分析方法.该方法不要求应用内部细节能够分析请求细粒度性能指标和多项资源消耗.该文贡献主要是:(1)提出了一个结合模型驱动和轻量内核行为跟踪的请求行为分析方法,适用于由黑盒模块构建的数据中心应用;(2)提出了一种利用应用行为预测误差衡量请求分析精度的评价方法.实验表明该方法具有好的分析精度,平均误差小于10%.关键词数据中心应用;请求级行为分析;负载模式;最小二乘;排队论1引言理解应用行为有助于管理系统(如操作系统)优化应用性能、分配系统资源和调试应用异常等任务.研究在线交互式应用的请求级行为特征是其中的一个热点问题.用户通过发送请求访问和使用在线服务.当一个用户请求到达后,系统根据该请求类型进Page2行相应的处理操作,过程中可能执行多个软件模块和访问多项物理资源,完成后将处理结果返回给用户.如果知道请求的服务时间和资源消耗,那么根据当前负载状况,例如请求到达率,就能够估计应用当前行为.总之,这类研究显示,请求级的系统行为分析被用于系统管理任务的许多方面,如请求调度[1-2]、应用性能预测[3]、应用异常诊断[4]和系统资源供应[5].本文面向数据中心应用的请求级行为分析问题.数据中心应用采用多层服务器结构.每层服务器面向不同功能需求,运行不同软件系统并访问多项资源.因此,请求行为分析包括多个层次,如功能层级和资源级.同时,数据中心应用包含许多第三方软件,这些软件系统分别由不同团队在不同时期开发完成.因此软件内部细节需要通过可用源代码甚至专家干预才能获得,增加了细粒度请求行为分析的难度.近期典型的请求分析研究分为两类方法.以文献[6]为代表的方法面向特定系统分析请求行为.该类方法基于应用细节在应用级或系统级关键路径上植入程序片段,主动或被动捕获请求执行中各种活动并记录为事件,如过程调用、资源访问等.然后使用特定算法分析事件,发现请求执行路径或计算资源消耗结果.这类方法虽然能够细粒度地分析请求行为,但是要求了解程序细节甚至专家介入和复杂的请求跟踪机制.因此,这类面向专用系统的方法缺乏通用性,不能适用于基于第三方软件构建的数据中心应用.另一类以文献[7]为代表的方法面向由黑盒软件模块构建的系统分析请求执行路径.该类方法在系统级或处理器级被动收集少量请求信息,然后基于特定算法分析粗粒度的请求执行路径和大致性能特征,通常将请求在执行路径上的延迟作为请求性能特征.虽然此类方法不要求了解应用细节和复杂的请求跟踪机制,但是只适用于分析精度要求不高的场合.行为分析方法.本文贡献主要是:(1)提出了一个适用于由黑盒模块构建的数据中心应用的请求行为分析方法.该方法结合了模型驱动的请求分析和轻量内核级应用行为跟踪机制,不要求应用内部细节能够分析请求细粒度性能指标和多项资源消耗.首先,基于请求行为特征,我们构建了应用聚合性能模型和应用资源消耗模型.基于模型,我们通过系统涌现行为分析请求行为,避免要本文提出一种新的面向数据中心应用的请求级求精密的请求行为跟踪和应用内部细节.为了保证基于模型分析的精度,在建模中我们量化了不同请求类型和并发请求竞争对应用行为的影响.然后,我们设计了一个轻量内核级应用行为跟踪算法,测量应用在各层的性能分布.在系统级观察应用行为,也避免要求应用内部细节和侵入应用.(2)提出了一种评价请求分析精度的方法.我们通过请求分析结果预测应用各层性能和各项资源消耗,然后使用预测误差衡量请求服务时间和资源消耗分析的精度.实验中,我们在一个机群系统中使用TPC-W基准测试和RUBiS系统作为测试应用,验证了本文方法.我们将本文方法的精度分析与一个代表目前已有方法的Baseline方法进行对比.Baseline方法与目前面向黑盒系统的分析方法[7-9]类似,在建模中不区分请求类型,并忽略并发请求对请求行为的影响.实验发现,我们方法在请求分层服务时间、各项处理器资源消耗、各项磁盘输入输出资源消耗和各项网路资源消耗的分析误差平均小于10%,而Baseline方法的分析误差平均在23%.这说明我们的请求分析方法相比目前已有方法具有更高的分析精度.本文第2节给出本文的研究问题、假设和目标;第3节给出基于请求行为特征建模描述数据中心应用行为的方法;第4节介绍通过最小二乘估计系统模型计算请求行为特征;第5节给出基于系统级插桩跟踪应用行为的应用分层聚合性能的测量方法;第6节是本文方法精度评价实验;第7节介绍请求分析相关工作;最后一节是本文结论和未来研究方向.2问题描述数据中心应用通常采用多层结构,每层面向某种特定功能需求,并且被部署在不同的服务器上.不失一般性,本文以3层应用为例.如图1,应用分布图1数据中心应用系统模型((1)应用内部细节不可见;(2)Web层、App层和DB层分布在3台服务器,每台服务器包含处理器、磁盘输入输出和网络带宽等资源;(3)将请求处理路径抽象为在每层或每项资源上最多经历或访问一次.本文目的是获得请求在每层的总共服务时间和各项资源总的消耗)Page3在3个物理服务器上,前端是Web服务器(Web层),中间是服务器部署应用逻辑(App层),而后端是服务器放置存储系统(DataBaseSystem,DB).其中每台服务器包括多种资源,这里我们主要考虑3项资源:处理器、磁盘输入输出和网络带宽.本文的目的是分析数据中心应用各类请求服务时间在Web层、App层和DB层的分布特征(本文简称请求分层服务时间),以及分析它们在各项处理器、磁盘输入输出和网络带宽的资源消耗.实际上当应用处理一次请求时,可能引发某层多次参与和多次访问某项资源.本文不考虑分析请求处理的详细路径,我们主要分析请求处理在每层的总服务时间和每项资源的总消耗.如图1,我们抽象请求处理路径为在每层或每项资源上最多经历或访问一次.请求执行路径分析在一些工作中已被提到[7],这些方法与本文请求行为分析形成互补.数据中心应用包含第三方软件,这些系统由不同团队在不同时期开发完成,所以内部细节不可知,通常称为黑盒系统.因此,请求分析不适合采用类似[6]的精细的监测机制.本文方法仅利用已有的或易获得的应用级指标和系统级指标,完成请求分层服务时间和各项资源消耗的分析任务.3系统建模本节我们分别基于请求分层服务时间和资源效用描述应用聚合性能和系统资源效用指标.3.1Baseline模型首先我们考虑最简单的情况.假如请求没有类型差异,即负载由相同请求组成,则应用聚合响应时间和系统资源效用,可简单地表示为两个线性模型:其中,y表示应用聚合响应时间;ur表示r资源效用;at是请求在第t层的服务时间;br是请求r资源效用;N表示请求数目.需要注意,与响应时间模型不同的是,我们在资源效用模型中加入一个截距项b0,r,因为在系统中即使负载为零时资源也不会完全空闲.通过请求资源效用br可计算请求的r资源消耗.设cr为请求的r资源消耗,则有cr=brT,这里设T是资源效用测量时间长度.实验中,我们将基于以上两个模型的请求分析方法作为Baseline方法,与本文方法比较.在面向黑盒系统的请求分析相关研究中,通常粗略地将请求在执行路径上的延迟作为请求性能特征[7-9],甚至将每类请求看作具有类似的性能特征[7,9].而Base-line模型不区分请求类型,并且忽略并发请求对系统行为的影响,与这些方法实质上相似并且具有代表性.因此在实验中Baseline方法作为与本文方法的对比方法.在实验部分(见第6.4节),给出了本文方法与Baseline方法的分析精度比较.3.2基于负载特征扩展模型实际中,数据中心应用接收不同类型请求,不同请求混合状况下应用性能不同[3].我们定义负载模式描述数据中心应用负载的成分特点,定义如下:这里犠是系统在某时刻的负载成分元素向量,元素Ni表示i类型请求在该时间的强度,例如到达率.基于负载模式,式(1)中应用聚合响应时间模型和系统资源效用模型可扩展成:其中,ai,t表示i类型请求在第t层的服务时间;bi,r表示i类型请求的r资源效用;n表示请求类型数目;Ni表示i类型请求数量;Ti表示该类请求访问的所有层的集合,本文中Ti=3.3.3基于排队理论扩展模型前面的应用聚合响应时间模型隐含假设了系统部署在能力无限的服务器上.实际情况是服务器资源不可能无限.当大量并发请求到达后,由于资源缺乏导致大部分请求不能立即被处理而必须等待.请求处理过程如图2所示,请求可能被滞留在任意等待队列中.因此,应用实际性能相比理想状态有所下降,在模型中需要考虑这点.图2基于排队网络模型的多层应用资源级请求处理结构(其中每项有限资源一个等待队列,请求处理可能因并发请求竞争资源被滞留在任意队列中)根据Little法则[10]描述请求等待时间,我们扩展应用聚合响应时间模型如下:Page4y=∑n这里模型右项描述了请求在多项资源队列中的平均等待时间.Ri表示i类型请求的资源集合,λr表示r资源的请求访问率,它可通过bi,r得知,bi,r值的意义表示i类型请求是否访问r资源,如果为0则表示否定.实际上,考虑到bi,r值不可能完全精确被计算出来,我们可以通过设置阀值来判断.进一步,应用聚合响应时间在各层的分布可表示为(yt=∑n其中,n表示进入t层的请求种类数目,与计算λr的方法类似,通过bi,r值可以得出访问该层任何资源的请求集合.这里我们将等待资源空闲耗时相关的项具体到处理器、磁盘输入输出和网络带宽资源上.4计算请求行为特征i上面给出请求分层服务时间(ai,t)和资源效用(bi,r)与应用分层聚合性能(yt)和系统资源效用(ur)的量化关系.如果我们获得多组这些应用级和系统级指标,则可通过模型参数估计得到这两个请求级行为特征.负载模式和资源效用可通过直接测量获得,但是应用分层聚合性能却不能直接测得,在第5节中将详细说明如何从应用外部获得该项指标.模型参数估计最常采用的是最小二乘[11]方法.下面就以式(4)模型为例来描述最小二乘方法.4.1最小二乘估计模型估计的目的是找出使模型准确度最大的参我们取最小平方误差作为目标函数,即在实际系统中,要确定一组θ使之精确地满足所有方程是不可能的.联立方程组只有取L>2i,才有可能确定一组“最优”的模型参数,而且为了保证模型精度,L必须充分大.J(θ)=∑L=(yL-Lθ-ωLNL)τ(yL-Lθ-ωLNL),展开得到(τLL)θ^LS=τL(yL-ωLNL).当(τLL)存在数值.而参数估值的优良与否很大程度上取决于参数估计方法.理想的估值应当与真值(系统的真实参数)完全一致,而实际是不可行的.有很多方法可被用于由测量值得到模型参数,其中采用最多的方法是普通最小二乘(OrdinaryLeast-Squares,OLS)回归.如果y是某时刻实测的应用性能,y^是该时刻模型在某参数集上的拟合值,则e=y-y^表示模型残差,即模型误差.OLS寻求与真值方差尽可能小的无偏估计量,也就是说寻找能使残差e平方和最小的模型参数集.OLS回归已在很多统计软件和商业报表软件中被实现.我们假设在实验中包括多个测量周期,任意测量周期用j表示.我们可将式(4)写成最小二乘的格式:其中,(j)=[N1,j…Ni,jN1,j…Ni,jN1,j…Ni,j];θ=[a1a2…a3i]τ;ω(j)=1N(j)=∑n对于j=1,2,…,L,式(5)进一步可构成线性方程组:其中,逆矩阵时,有θ^LS=(τLL)-1τL(yL-ωLNL).这里的θ^LS即为模型参数的最小二乘估计值.5测量应用分层聚合性能我们通过跟踪应用各层模块交互活动测量应用分层聚合性能.如果直接利用请求处理过程进入每层的开始时刻计算每层耗时,则需要所有服务器时钟保持一致.因此,我们利用请求处理过程的嵌套结Page5构测量应用分层聚合性能.实验中我们发现,在一次请求处理中各层模块的交互如图3所示,App层向Web层提供具体应用的请求处理结果,并向DB层提出数据访问请求.因此,应用在App层性能是App层请求响应时间与DB层请求响应时间之差.这里某层请求响应时间是从接收到其它层请求后到返回处理结果的耗时.通过此方法,不要求所有服务器必须具有严格一致的时钟.图3请求处理过程嵌套结构和各层处理时间计算(请求分层处理时间是某层所有请求分层响应时间与所有嵌入层响应时间之差.其中,一次请求分层响应时间是该层从接收请求到返回处理结果的耗时)由于应用是黑盒系统,不能直接在其内部实现测量,所以我们通过在系统内核插入断点捕获应用通信活动.基于Kprobe①工具,在4个TCP核心函数中插入记录操作,它们是sys_accept函数、sys_shutdown函数、tcp_sendmsg函数和tcp_recvmsg函数.sys_accept函数接收连接请求,创建一个TCP连接,sys_shutdown函数主动关闭一个TCP连接,tcp_sendmsg函数和tcp_recvmsg函数分别是内核TCP协议栈中发送和接收消息的函数.当应用调用内核TCP通信操作时,执行到插入代码,触发对通信活动的记录.记录信息包括:时间戳、处理器号、进程号、线程号、程序名称和事件名称.事件主要分两类:消息发送事件和消息接收事件.收集完系统通信事件后,采用两个步骤计算应用分层聚合性能:(1)通过过滤操作找出所有与应用相关的通信事件,然后使用关联操作发现这些事件之间的逻辑关系,最后得出所有请求处理的流程结构;(2)基于事件关系计算每层请求响应时间,并基于计算结果和请求处理流程计算每层请求处理时间,最后所有请求处理在该层处理时间之和则是应用在该层的聚合性能.在我们已有工作[7]中实现了一个请求跟踪工具,该工具通过关联请求活动事件发现请求执行路径.它定义和分析两类事件关系:进程上下文关系和消息上下文关系.在同一进程上下文中发生的事件属于进程上下文关系,在不同进程间由一次通信产生的多个事件属于消息上下文关系.因为本文方法需要,在这两类关系基础上又新增两类逻辑关系:开始-结束关系和嵌套关系.对于属于进程上下文关系的消息接收事件R和消息发送事件S,如果S的目的地址与R的源地址一致,则认为属于开始-结束关系,否则,两者是嵌套关系;如果R和S的关系是消息上下文关系,则与S具有嵌套关系的接收消息事件也与R是嵌套关系.以图3为例,在此请求处理过程中,开始-结束关系的事件对有R1和S8、R2和S7、R3和S4、R5和S6;嵌套关系的事件对有R1和R2、R2和R3、R2和R5.当发现请求处理结构后,基于开始-结束关系可计算请求处理在每层的响应时间.图3中,此次请求处理在Web层响应时间是tS8-tR1,在App层响应时间是tS7-tR2,在DB层响应时间是tS4-tR3+tS6-tR5.这里tR表示事件R发生时的时间戳.然后基于处理流程嵌套结构和各层响应时间,请求处理在App层的处理时间是tS7-tR2-(tS4-tR3+tS6-tR5).最后,所有请求处理在App层的处理时间之和即是应用App层聚合性能.6实验6.1实验环境我们在一个刀片服务器机群系统上实现和测试了本文方法.每台服务器配有双路AMDOpteron1.6GHz处理器、2GB内存、146GB磁盘和千兆网卡,并运行内核版本2.6.22.5-31的Linux系统.我们选用20台此类服务器作为实验平台,其中18台服务器构成基准测试应用的运行环境,其它服务器分别作为测试应用客户端和独立的请求分析平台.机群内部通过自适应千兆交换机连接.实验采用RUBiS②系统和TPC-W③基准测试作为测试应用.RUBiS系统是一个由Rice大学基于EJB开发的Internet应用程序,模拟类似Ebay商业模式的在线拍卖网站,具备在线拍卖网站的核心功能.该系统采用3层结构:前端是Web服务器,后端是MySql数据库系统,中间层是Java语言实现的应①②③jectweb.orgPage6用逻辑.RUBiS共支持22类请求,主要包括浏览、竞标和查看用户竞标历史等操作.RUBiS官方网站提供了两种标准负载:Browsing和Bidding,分别模拟用户浏览和竞价行为.TPC-W基准测试是另一个由Java语言实现并用于模拟事务型电子书店的测试基准系统.与RUBiS类似,该基准测试也是3层结构,应用层包括Image应用服务器和WebCache服务器.TPC-W共支持14类请求,主要包括书籍搜索、用户注册和价格更新管理等操作,并提供了3种标准负载:Browsing、Shopping和Ordering,分别模拟用户浏览、采购和订购行为.6.2实验设计本文实验的目的是验证本文请求分析方法的精度,包括每类请求的分层服务时间和各项资源消耗以及评价使用Kprobe工具测量应用分层性能的开销.第6.3节是使用本文方法分析RUBiS系统和TPC-W基准的请求行为的实验结果.第6.4节评价了本文方法的分析精度.第6.5节评价了Kprobe工具对应用性能的影响.我们设计了以下3个实验:实验1.分析RUBiS系统和TPC-W基准的请求级行为特征,包括每类请求分层服务时间和各项资源消耗.在前面第4节提到,请求分层服务时间通过式(6)中方程组计算得到.求解方程组需要足够多不同的负载模式,通常至少是请求种类数目的两倍.因此在实验中,我们通过配置请求转换概率为TPC-W基准和RUBiS系统又分别模拟了6种不同的负载.通过调整客户端数目,改变六种负载在合成负载中的比例,分别为TPC-W基准合成了30个负载模式,为RUBiS系统合成了50个负载模式.为了避免请求分析实验与后面精度评价实验使用相同的负载,在这里没有使用应用的标准负载.实验2.评价实验1的请求分析结果的精度,包括每类请求的分层服务时间和各项资源消耗.目前精确的请求分析方法大多面向特定系统,并且需要特制的请求跟踪机制,如文献[6,12-14]等,所以难以使用这类方法的实验结果作为请求分析结果的参考.因此,我们通过使用请求分析结果预测应用级行为的误差,即应用性能和各项资源消耗,来作为衡量分析方法精度的指标.具体上讲,我们使用应用分层性能的预测误差作为分层服务时间分析的精度评价指标,即珋et=yt-∑i验所有类型请求的分层服务时间分析结果的平均误差.这里yt是应用在t层的实际性能,而∑i示相对应的应用在该层的预测性能.当应用负载较轻时,请求并发影响可以忽略不计,此时应用性能主要由应用服务时间主导,应用分层性能yt可近似代替应用分层服务时间.例如实验中有150个并发客户端时,系统各项资源效用均在10%以下,此时请求并发影响基本可以忽略不计.同样的,我们使用系统资源消耗的预测误差作为资源消耗分析的精度评价指标,即珋er=ur·T-b0,r·T-∑i它评价所有类型请求的资源消耗分析结果的平均误差.这里T表示一次实验的时间长度.需要注意的是,与前面评价指标不同的是,这里需要考虑系统额外资源开销b0,r.为了比较本文方法与已有方法的分析精度,我们使用第3.1节的Baseline方法作为对比方法.Baseline方法与目前已有的面向黑盒系统的请求分析工作[7-9]类似,不区分请求类型,并忽略并发请求对系统行为的影响.使用这个Baseline方法作为比较对象,能够间接得到本文方法与已有方法的比较结果.我们在多种合成负载下,检验了本文方法与Baseline方法的分析精度,合成负载见表1.这些合成负载有3类:极轻负载(150个客户端)、轻负载(300个客户端)和重负载(1500个客户端).为了避免偶然性,每类合成负载又包含了多个标准负载混合比例不同的合成负载.负载#1至负载#4是极轻负载,用于评价请求分层服务时间分析的精度.而负载#5至负载#12用于评价请求资源消耗分析的精度.同样为了避免偶然性,其中#5至#8是轻负载,表1TPC-W基准和RUBiS系统合成测试负载负载TPC-W客户端个数#15050507575#2100252512525#3251002525125#42525100--#5100100100150150#6200505025050#7502005050250#85050200--#9500500500750750#1010002502501250250#1125010002502501250#122502501000--注:表中包括12种不同负载并发客户端数目组合(客户端数目单位:个).负载#1到负载#4用于评价请求分层服务时间分析精度;负载#5到负载#12用于评价请求资源消耗分析精度,包括轻负载和重负载两种情形Page7而#9至#12是重负载.实验3.评价Kprobe工具带来的系统开销.我们通过比较应用分别在Kprobe工具关闭状态和开启状态的端到端聚合性能,即平均响应时间,来评价Kprobe对应用性能的影响.6.3请求分析结果表2给出了使用本文方法分析TPC-W基准和RUBiS系统的请求行为的部分结果.从这些典型结果可以看出:(1)请求性能的差异性.不同类型请求在每个分层的服务时间不同.例如:TPC-W基准测试的SearchResult请求和AdminConfirm请求在App层有较其它请求更大的服务时间,而在DB层,OrderDisplay请求和AdminConfirm请求服务时间较其它请求大.同样,RUBiS的ViewbidHistory请求在DB层有较其它请求更大的服务时间.(2)请求性能分布的差异性.每类请求在不同分层的服务时间不同.例如:TPC-W基准测试的AdminConfirm请求和Home请求服务时间在App层和DB层分布明显大于Web层,最大差别接近一个数量级,同时OrderDisplay请求的DB层服务时间大于Web层和App层,差异也将近一个数量级.同样在RUBiS系统中,Home请求在App层有较其它两层更大的服务时间,同时ViewbidHistory和BrowseRegions请求在App层有较Web层更大的服务时间,最大差异也将近一个数量级.表2使用本文方法分析得到的TPC-W基准和RUBiS系统的请求分层服务时间和资源消耗的部分结果请求AdminConfirm0.3120.00030.00003.2380.0750.0191.0340.00240.0019Home0.2740.00050.00011.5630.0090.0540.8740.00170.0008OrderDisplay0.3770.00060.00010.2390.0060.0263.6280.00380.0037SearchResult0.7350.00110.00002.7980.0260.0430.4680.00310.0013请求Home0.1780.00020.00001.8360.00250.00000.1470.00050.00020BrowseRegions0.1910.00030.00002.0490.00170.00010.7480.00120.00040ViewbidHistory0.1870.00030.00011.9280.00210.00001.7450.00900.00011注:表中,aWeb表示请求Web层服务时间,cApp,CPU表示请求App层处理器资源消耗,以此类推.(3)请求资源消耗的差异性.不同类型请求对每项的需求不同.例如:在App层,TPC-W基准测试的AdminConfirm请求,对处理器资源需求大于其它请求,而Home请求和SearchResult请求则比其它请求消耗更多的磁盘输入输出资源.(4)请求资源需求分布的差异性.每类请求对不同资源的消耗不同.例如:TPC-W基准测试的Home请求和SearchResult请求,在App层的磁盘输入输出消耗大于其它资源消耗.RUBiS系统的ViewbidHistory请求,在App层的处理器资源需求大于其它资源需求.6.4分析精度评价6.4.1请求分层服务时间分析图4对比了本文方法与Baseline方法在请求分层服务时间方面的分析精度.其中,图4(a)是TPC-W基准分别在负载#1、负载#2、负载#3和负载#4下(见表1),两种分析方法的精度对比.以应用分层性能的预测误差珋et作为精度指标.在第6.2节提到,珋et是分析结果的平均误差.该指标值越小,则分析方法的精度越高.实验结果可以看到,本文方法TPC-WRUBiS的分析误差不超过14%,要明显好于Baseline方法,而Baseline的分析误差大多数在20%以上.其中在TPC-W基准的App层,本文方法在4种负载下的平均误差是12%,而Baseline方法则为29%.图4(b)是RUBiS系统分别在负载#1、负载#2和负载#3下(见表1),两种方法的精度对比,可以得到与图4(a)一致的对比结果.需要注意的是,图4显示每种分析方法在TPC-W基准和RUBiS系统的分析精度存在明显差异,都是在RUBiS系统的分析精度较在TPC-W基准的要高,尤其是Baseline方法.本文方法在RUBiS系统的误差平均小于8%,而在TPC-W基准的误差平均是13%;而Baseline方法在RUBiS系统的误差平均在21%,在TPC-W基准的误差平均在28%.这主要是因为,虽然RUBiS系统的请求类型(22类)多于TPC-W基准(14类请求),但是TPC-W基准不同类型的请求具有更大的性能差异.因此分析方法在RUBiS系统的误差普遍小于在TPC-W基准的误差.Page8图4本文方法与Baseline方法在请求分层服务时间分析方面的精度对比(以请求分层服务时间分析结果预测应用分层性能的误差珋et作为分析精度指标.极轻负载情形(表1中负载#1、负载#2、负载#3和负载#4),因为应用性能由服务时间主导,所以应用分层性能近似于应用分层服务时间.因此,珋et就是请求分层服务时间分析结果的平均误差)6.4.2请求各项资源消耗分析图5和图6分别在轻负载和重负载情形下,对比了本文方法与Baseline方法在请求资源消耗方面的分析精度.其中,图5(a)是TPC-W基准分别在负载#5、负载#6、负载#7和负载#8负载下(见表1),两种分析方法的精度对比.与服务时间分析的精度评价指标类似,这里珋er也表示分析结果的平均误差.可以看到,本文方法在各项资源消耗的分析误差平均在9%,而Baseline方法则在21%.其中在TPC-W基准的app层,本文方法在4类负载下的平均误差是11%,而Baseline方法则是22%.图5(b)、图6(a)和图6(b)分别是RUBiS系统分别在负载#5、负载#6和负载#7下,TPC-W基准分别在负载#9、负载#10和负载#11下和RUBiS系统分别在负载#5、负载#6和负载#7下(见表1),两种分析方法的精度对比.它们得到与图5(a)基本一致的对比结果.这里与前面服务时间分析的精度结果类似,分析方法分别在两种应用的分析精度也存在差异,同图5轻负载情形下,本文方法与Baseline方法在资源消耗分析方面的精度对比(以请求资源消耗分析结果预测应用资源消耗的误差珋er作为分析精度指标,珋er即为请求资源消耗分析结果的平均误差)图6重负载情形下,本文方法与Baseline方法在资源消耗分析方面的精度对比(以请求资源消耗分析结果预测应用资源消耗的误差珋er作为分析精度指标,珋er即为请求资源消耗分析结果的平均误差)Page9样是在RUBiS系统的分析精度好于在TPC-W基准的分析精度.这同样是因为TPC-W基准不同类型请求之间较RUBiS系统有更大的差异.值得注意的是,两个方法在Web层CPU消耗分析的精度差异小于其它层CPU消耗分析精度.图5(a)中,本文方法在Web层CPU消耗分析误差上与Baseline方法的差异平均在4%,而在App层和DB层的差异平均是11%和14%.图5(b)、图6(a)和图6(b)类似.这主要因为不同请求在Web层的CPU消耗差异相对其它层较小的原因.另外,相比于轻负载情形(图5),在重负载情况下(图6),两种方法的分析误差都表现出增加,本文方法的分析误差平均增加了4%,而Baseline方法则增加9%.这主要是因为在重负载情况下,系统产生了更多的额外资源开销,例如操作系统的开销.6.5Kprobe工具开销图7是考察Kprobe工具对应用性能影响的实验结果.实验在所有负载下(见表1),测量了RUBiS系统和TPC-W基准分别在Kprobe工具关闭和开启状态下的平均响应时间.图7给出了这些测量结果的平均值.从结果看,Kprobe机制带给RUBiS系统和TPC-W基准的额外开销较小,分别是1.3%和2.7%.因此,Kprobe对请求分层性能分析精度的影响也在可接受的范围内.图7Kprobe工具对应用平均响应时间的影响7相关工作目前的请求级行为分析工作,主要依赖请求跟踪技术提取请求执行路径和分析请求的性能.它们主要分为两类方法:一类方法基于复杂监测机制,面向特定系统分析请求行为.这类方法的典型工作是Barham等人提出的面向Windows环境的细粒度请求分析和负载建模方法[6].该方法利用Windows系统的插桩框架在操作系统级插入断点,在运行时产生事件记录各种请求活动.并设计了一套事件处理和关联的工具,提取请求执行路径和分析请求各项资源消耗信息.Reynolds等人[12]提出一个请求路径分析工具Pip,该工具要求直接在应用源代码中记录应用行为.Chanda等人[13]的方法类似,也要求了解请求执行上下文和应用细节.Arkles等人[14]的方法同样需要在多层服务中插入代码.虽然此类方法能够获得详细的请求行为信息,但是要求了解和侵入系统内部,降低了方法的通用性.本文方法基于模型分析请求行为,不要求了解应用细节和复杂的插桩框架,更适用于包含大量第三方软件的数据中心环境.另一类方法基于系统外部观察推断请求行为.Agarwala等人[9]和Zhang等人[7]分别提出通过分析网络包和系统级进程间通信活动发现请求因果路径关系.进一步,Shen等人[8]提出一种启发式的请求行为预测方法.该方法挑选能够区分请求行为的底层硬件计数器指标来辨识请求.当新请求被识别后,利用该请求所属类型的历史信息预测该请求的行为.虽然这类方法较前一种方法有更好的通用性,但与第6节实验中的对比方法Baseline方法一样,不区分请求类型,并忽略并发请求对系统行为的影响.因此这类方法只能获得粗略的请求性能信息,例如请求延迟,同时缺乏请求资源消耗分析.而本文提出一个提高请求分析精度的方法,即通过在模型中考虑并量化请求行为的不确定性部分来最大化地消除分析误差.8结论和未来工作本文提出一种基于模型驱动的数据中心应用请求级行为分析方法.该方法不需要了解应用内部信息能够分析应用每类请求在各层的服务时间和各项资源消耗.相比于已有方法,本文方法更适合于数据中心应用.我们首先利用请求分层服务时间以及各项资源效用作为模型参数,建立描述应用分层聚合性能和系统资源效用的两个模型.模型主要量化了负载模式变化对应用行为造成的影响.负载模式是某时刻负载中请求类型混合状况.此外,应用聚合性能模型还考虑了因并发请求带来的应用行为不确定,我们通过排队理论量化此不确定性,消除了潜在的分析误差.基于模型,利用最小二乘方法和多组实测数据便可通过模型参数估计计算出请求分层服务时间和各项资源效用.在实测指标时,我们利用内核探测工具Kprobe通过记录应用模块之间的通信活动,并设计了一个测量算法用于计算应用分层聚合性能.实验中,我们使用TPC-W基准和RUBiS系Page10统,在一个机群系统中评价了本文方法.在实验1中,使用多个合成负载模式供模型参数估计方法分析请求分层服务时间和各项资源效用.实验2基于实验1的分析结果,预测测试应用在标准负载下的性能和资源消耗,通过预测的误差来评价分析方法精度.并且将实验结果与Baseline方法做了比较.Baseline方法没有考虑负载模式和并发请求影响,与目前面向黑盒系统的请求分析方法类似,具有代表性.实验结果表明,相比Baseline方法,我们的方法具有更高的分析精度.也同时说明负载模式和并发请求影响在基于模型驱动的请求分析方法中是不可忽略的不确定因素.实验3检验了Kprobe工具对应用性能的影响.实验结果表明Kprobe工具对应用平均响应时间的影响较小.因此,它的使用对请求分析精度的影响也在可接受的范围内.本文方法基于同构系统,我们假设应用部署在相同服务器上,或者很少在异构服务器之间迁移.实际中,数据中心通常由异构服务器组成.因此,在不同的服务器上应用具有不同的行为.在未来工作中,我们将考虑这个因素,并增强本文方法在异构数据中心环境的适用性.致谢诚挚感谢所有对本文提出了修改建议和意见的审稿人和编辑!
