Page1基于分布式文件系统HDFS的节能算法廖彬1),2)于炯1),2)张陶2)杨兴耀2)1)(新疆大学软件学院乌鲁木齐830008)2)(新疆大学信息科学与工程学院乌鲁木齐830046)摘要与传统数据中心节能算法不同,MapReduce计算任务的数据依赖性使得设计HDFS(HadoopDistributedFileSystem)节能算法时必须保证集群中所有数据块的可用性,即任意数据块或其副本中的至少一块处于活动状态.根据HDFS集群结构与数据块存储等特点建立了DataNode节点矩阵、节点状态矩阵、文件分块矩阵、数据块存储矩阵与数据块状态矩阵,为后续研究建立了基础模型.结合数据块状态矩阵与数据块可用性之间的关系设计了DataNode节点休眠验证算法.概率分析了由于机架感知的存储策略带来数据块分布的随机性,使得在不改变数据块存储结构与存储策略的情况下并不能通过休眠DataNode节点达到节能的目的.进而设计了数据块存储结构配置节能算法与基于对称数据块存储策略下的节能算法,分别从改变数据块的存储结构与存储策略两方面对HDFS进行节能改进.实验结果表明:两种节能算法都能解决HDFS集群的能耗低利用率问题,并且集群负载越低节能效率越高.关键词云计算;分布式文件系统;节能计算;副本策略;绿色计算1引言低碳节能已经成为全球热点问题之一,而信息与通信技术行业的高速发展也带来了高能耗、高二氧化碳排放量的问题.据统计①,目前IT领域的二氧化碳排放量占全球的2%,而到2020年这一比例将翻番.2008年路由器、交换机、服务器、冷却设备、数据中心等互联网设备总共消耗8680亿度电,占全球总耗电量的5.3%.根据文献[1]的预测,到2025年IT行业的平均能耗将达到2006年的5倍,而网络设备的能耗更会达到13倍.与此同时,Barroso等人在文献[2]中对Google内部5000多台服务器进行长达半年的调查统计结果表明:服务器在大部分时间里利用率都在10%~50%之间,完全没有达到高效利用的要求.造成Google服务器利用率低的主要原因是传统的负载均衡算法专注于将用户请求平均分发给集群中的所有服务器以提高系统的可用性的同时没有考虑到系统负载率与能耗利用率之间的关系,导致用户的服务请求被分发到了过量的而不是适量的服务器上,由此造成了大量电能的浪费.通过图1可以看出服务器在负载很低(小于10%)的情况下电能消耗也超过了峰值能耗的50%,并且能耗利用率随着系统负载的增加而增加.由此可见,IT设备的高能耗、高二氧化碳排放量与能耗的低利用率问题已经成为信息与通信技术行业亟待解决的问题.图1服务器能耗利用率与负载率之间的关系[2]Hadoop②作为新的分布式存储与计算架构,由于能够部署在通用平台上,并且具有可扩展性(scal-able)、低成本(economical)、高效性(efficient)与可靠性(reliable)等优点使其在分布式计算领域得到了广泛运用,并且已逐渐成为工业与学术界事实上的海量数据并行处理标准.Hadoop作为分布式系统基础架构,用户可以在不了解分布式系统底层细节的情况下,充分利用集群的高速运算和存储能力,开发分布式应用程序.Hadoop参考Google的分布式文件系统GFS(GoogleFileSystem)[3],实现了分布式文件系统HDFS;参考MapReduce[4]计算模型实现了自己的分布式计算框架;参考BigTable[5]实现了分布式数据库HBase.虽然Hadoop拥有诸多优点,但是由于Hadoop底层的分布式文件系统HDFS基于机架感知的数据块存储策略使得数据块在集群中的分布具有随机性,并且MapReduce的移动计算理念使得计算任务与数据块依赖紧密,这使得系统必须保证所有数据块的可用性.Hadoop通过副本策略与节点失效处理等等方法保证数据块可用性的同时并没有考虑集群负载率与系统能耗之间的关系,即使在Hadoop集群利用率很低的情况下,集群中所有的DataNode节点都保持活动状态以保证系统中数据块的可用性,其高能耗低效率的情况与Google服务器集群类似,并由此造成了大量电能的浪费.为解决HDFS分布式集群高能耗低效率的问题,本文主要做了以下工作:(1)通过分析HDFS集群节点结构、文件分块与存储机制建立了DataNode节点矩阵、节点状态矩阵、文件分块矩阵、数据块存储矩阵与数据块状态矩阵.用矩阵表达的集群结构、节点状态、文件分块、数据块存储、数据块状态规范了HDFS集群的建模并为后续研究打下了基础.(2)通过休眠闲置节点进行节能的方法在HDFS集群中受到数据块可用性的挑战.为了验证特定DataNode节点的休眠是否影响数据块的可用①②tectureandDesign.http://hadoop.apache.org/common/Page3性,结合数据块状态矩阵与数据块可用性之间的关系设计了DataNode节点可休眠验证算法.通过概率分析证明了在不改变数据块存储结构与存储策略的情况下并不能通过休眠DataNode节点达到节能的目的.(3)在原机架感知的存储策略基础上设计了数据块存储结构配置节能算法与RACK区域划分算法.RACK区域划分算法将RACK划分成Active-Zone与Sleep-Zone两个区域,根据数据块的访问规律将数据块存储在不同的区域中,在保证数据块可用性的前提下通过休眠Sleep-Zone区域中DataN-ode节点达到节能的目的.(4)设计了对称数据块存储策略,并设计了该存储策略下的节能算法.在不影响原HDFS可靠性、高效性与可扩展性的前提下,对称数据块存储策略使得具有相同存储结构的DataNode节点之间能够实现任务的转移与替换,算法通过任务调度产生并休眠空闲节点从而达到节能的目的.本文第2节对相关工作进行介绍;第3节定义DataNode节点矩阵、节点状态矩阵、文件分块矩阵、数据块存储矩阵与数据块状态矩阵的建立并给出示例;第4节提出DataNode节点可休眠验证算法、数据块存储结构配置节能算法、RACK区域划分算法与基于对称数据块存储策略下的节能算法;第5节对相关算法建立数学分析模型;第6节通过模拟实验验证算法的有效性;最后一节对全文进行总结并提出未来研究工作的方向.2相关工作传统的IT系统一方面通过超额资源供给与冗余设计来保障QoS与系统可靠性[6],另一方面负载均衡算法专注于将用户请求平均分发给集群中的所有服务器以提高系统的可用性,这些设计原则都没有考虑到系统的能耗因素,这使得IT系统的能量利用日益暴露出高能耗低效率的问题.学术与工业界分别从硬件、操作系统、虚拟机、数据中心4个层次去解决IT系统的能耗问题.硬件层次上主要采用DCD[7-10](DynamicComponentDeactivation)与DPS[11-14](DynamicPerformanceScaling)两种节能技术,其中DCD通过在一段时间内关闭或休眠系统硬件的某些部件,而DPS通过调节适应于当前负载的CPU频率与电压从而达到节能的目的.文献[7-10]研究了DCD节能技术将关闭或休眠后的部件重新启动的时间延迟影响用户QoS与休眠部件初始化时的高能耗等关键问题.DPS通过降低CPU工作频率与电压进行节能的同时也带来了CPU性能降低的问题,由此文献[11-14]对CPU能耗与性能之间的平衡点问题进行了相关研究.操作系统层面上,文献[15-18]研究了NemesisOS、Linux、ECOsystem等系统采用系统资源管理、任务调度与适应、硬件节能技术等方法对操作系统进行节能处理的相关问题.虚拟机层面上,Xen、VMware、KVM等虚拟机VMM(VirtualMachineMonitor)利用DPS或者DCD等技术控制系统资源的使用来达到节能的目的.文献[18-29]对数据中心层面上的节能技术进行了大量研究,数据中心层面上的节能技术通常采用合并任务的方法,即在满足用户QoS约束的前提下将任务分配到较小的资源集上,将空闲下来的节点资源休眠以达到节能的目的.本文即是基于数据中心的节能思想,并假设所有的DataNode节点都具有DPS能力以便根据当前负载动态调节服务器能耗,在满足HDFS集群数据块可用性的前提下,通过休眠空闲DataNode节点达到节能的目的.现阶段针对MapReduce、HDFS节能方面的研究较少,文献[30]对基于MapReduce与HDFS框架的数据中心能耗进行了测量,提出了存在的能耗问题,并通过优化系统配置参数来提高能源利用率.文献[31]提出了数据块子集subset的概念,将数据块与其副本中的至少一个数据块放入该子集中以保证所有数据块的可访问性的前提下,通过关闭与该数据块子集无交集的DataNode节点以达到节能的目的.文献[32]设计了HDFS集群数据块配置算法,该算法根据当前HDFS集群的工作负载动态配置数据块的存放.当节点负载达到设定阈值时,通过算法自动地打开与关闭某些DataNode节点以达到节能的目的.文献[33-34]通过对Yahoo公司HDFS集群内部数据块访问规律的研究发现数据块的访问具有较强的规律性,根据数据块的访问次数将其放在Cold-Zone与Hot-Zone两个DataNode节点区域中,通过将Cold-Zone中DataNode节点进行节能处理从而达到整个集群节能的目的.本文与以上工作不同之处在于通过建立分析矩阵对HDFS集群结构、节点状态、文件分块、数据块存储、数据块状态进行建模,为后续研究建立了基础.本文设计的节能算法以保证数据块的可用性为前提,而已有研究则很少考虑到HDFS集群这一特点.数据块存储结构配置节能算法与基于对称数据块存储Page4策略下的节能算法分别从数据块存储结构与数据块存储策略两方面对HDFS集群能耗进行改进.其中数据块存储结构配置节能算法结合了文献[31-33]的思想,首先RACK区域划分算法将RACK划分成Active-Zone与Sleep-Zone两个区域,并通过休眠Sleep-Zone区域中DataNode节点达到节能的目的.而对称数据块存储策略下的节能算法首先重新设计了数据块的存储策略,在保证HDFS可靠性、高效性与可扩展性等优点的同时,使得DataNode节点的休眠摆脱了数据块可用性的约束,从而达到通过休眠空闲节点实现节能目标.3HDFS集群节能问题建模及示例3.1节能问题建模本节将对HDFS集群节能问题的相关概念进行建模,具体包括DataNode节点矩阵、DataNode节点状态矩阵、文件分块矩阵、数据块存储矩阵、数据块状态矩阵、HDFS集群节能问题定义等等.HDFS集群一般由多个机架RACK组成,而一个RACK内部又由多个服务器组成,并且HDFS集群通常由一个NameNode和多个DataNode节点构成,因文本考虑的是将DataNode节点休眠以达到节能的目的,所以不考虑NameNode节点的节能问题.定义1(DataNode节点矩阵).设某个HDFS集群由集合Cluster={〈rack1,s1〉,〈rack2,s2〉,…,〈racki,si〉}组成,其中元素〈rack1,s1〉表示编号为rack1的RACK机架中有s1台DataNode服务器,该集群由i个RACK组成,即|Cluster|=i.用dn表示DataNode节点服务器,那么可将HDFS集群中的所有DataNode节点表示为矩阵犮sm×i:犮sm×i=其中矩阵犮sm×i中的列表示编号为racki的RACK中的si个DataNode服务器,其中sm表示RACK中节点数量集合{s1,s2,…,si}中的最大值.设集群中DataNode节点的数量为k,那么k=∑si,而DataNode节点矩阵犮sm×i可以表示sm×i个元素,当sm×i>∑si时,用sm×i-∑si个0填充犮sm×i矩阵,表示RACK中该位置没有DataNode节点.定义2(DataNode节点状态矩阵).HDFS集群中的DataNode节点可能存在多种状态,设状态标识集合为state={0,1,2,3},其中0表示该位置没有服务器,而1、2、3分别表示DataNode节点处于活动、休眠、宕机状态.宕机有可能是因为系统故障、电源中断、硬件故障等等原因造成;休眠与宕机的共同点都是此时DataNode节点不可用,但是休眠可以通过唤醒机制将DataNode节点转化为活动状态.在DataNode节点矩阵犮sm×i的基础上,HDFS集群中的DataNode节点状态矩阵表示为其中smn∈{0,1,2,3}(1msm,1ni).定义3(文件分块矩阵).HDFS集群中文件的存储都被拆分成一系列的数据块存放在DataNode节点中,并采用在同一个集群中存储多个副本的策略来提高数据的可靠性.设HDFS集群中有k(k>3)个DataNode{dn∈犮sm×i},文件F数据块副本系数为m,数据块大小为bs,则HDFS中大小为n×bs的F会有n×m个数据块随机存储在这k个DataNode中,其文件分块可由犉n×m矩阵表示.其中,原文件F由数据块{b11,b21,…,bn1}组成,而矩阵犉n×(m-1)表示该文件的副本,n表示文件犉的原始数据块数量.犉n×m=HDFS机架感知的数据块存储策略如图2所示,当用户向HDFS集群上传数据时,第1个数据块b11随机存放在某个DataNode节点中,第2个数据块b12(b11的副本1)存放在与b11不同的机架上的Page5DataNode节点中,第3个数据块b13(b11的副本2)存放在与b12相同的机架但不同的DataNode节点中.如果副本系数m>3,其余的数据块就随机的存放在除b11、b12、b13存储节点以外的任意DataNode节点中,由此可见基于机架感知的数据块存储策略使得数据块的存储具有随机性.定义4(数据块存储矩阵).文件F首先根据矩阵犉n×m对文件进行分块,然后根据机架感知的数据块存储策略将数据块存储于HDFS集群中的DataNode节点上,即文件分块矩阵犉n×m中的n×m个数据块bij(1in,1jm)存储于矩阵dn∈犮sm×i中的k个DataNode服务器中,并遵循一个数据块bij只能存储在一个DataNode节点中,bij与其副本数据块不能存储在同一个DataNode节点中的规律.那么,可将数据块与存储该数据块的DataNode节点之间的对应关系转化表示为数据块存储矩阵犛n×m:其中,dij∈犮sm×i(1in,1jm)且犛n×m中任意一行不能存在相同的元素.定义5(数据块状态矩阵).存储于不同状态的DataNode节点中的数据块可用性不同,根据Da-taNode节点状态矩阵犇犛sm×i与文件数据块存储矩阵犛n×m之间的DataNode节点关联可得到文件数据块状态矩阵犅犛n×m:其中bsij∈{1,2,3}(1in,1jm),状态1表示该数据块存储在活动的DataNode节点中,数据块处于可用状态;2表示该数据块存储在休眠的DataNode节点中,3表示该数据块存储在宕机的节点中,状态2与3都表示数据块处于不可用状态.定理1.HDFS集群中的任意文件F处于可用状态的条件是该文件数据块状态矩阵犅犛n×m中的每一行至少存在一个状态为1的数据块.证明.用反证法证明.假设文件F的数据块状态矩阵犅犛n×m中存在第i(1in)行{bsi1,bsi2,…,bsim}中不存在状态为1的数据块,即{bsi1,bsi2,…,bsim}∈{2,3}(1in).根据定义3与定义5可知此时文件F的n个分块中第i个数据块与其副本都处于休眠或宕机的DataNode节点中,数据块{bi1,bi2,…,bim}都处于不可用状态.用户读取文件F时,因为数据块{bi1,bi2,…,bim}都处于不可用状态,n个数据块中的第i个数据块将读取失败,造成不能将文件F组合成功返回给用户.此时,文件F对于读取用户不可用.证毕.定义6.将HDFS中的节能问题定义为四元组p=〈犮sm×i,SD,files,flag〉.其中犮sm×i为HDFS集群DataNode节点矩阵,表示集群中所有k个DataNode节点的集合.SD={dn1,dn2,…,dnu}表示处于不可用状态的DataNode节点的集合,u=|SD|表示不可用节点的数目,其中包括休眠与宕机状态的DataNode节点,由于本文讨论的范围为通过休眠DataNode节点节能,所以不考虑宕机情况,将所有不可用的DataNode节点统一考虑为休眠状态.files={F1,F2,…,Fw}表示集群中存储的所有文件的集合,其中w=|files|表示文件的个数.flag∈{0,1}表示集群中所有文件的可用性标识,当集群中所有文件files={F1,F2,…,Fw}满足定理1时,flag=1;当集群中存在文件不满足定理1时,flag=0.此时通过休眠HDFS集群中的DataNode节点以达到节能目的问题转化为在保证四元组p=〈犮sm×i,SD,files,flag〉中flag=1的前提下,怎样使得SD={dn1,dn1,…,dnu}集合最大的问题.其中sp=u/k的值表示集群中休眠DataNode节点的比例,sp值越大,节能效率越高.定理2.在不改变任意数据块原始存储结构的前提下,四元组p=〈犮sm×i,SD,files,flag〉中flag=1的概率为A(k,m1(1-A(u,m1)A(k,m3(1-A(u,m3)其中(n1,n2,n3,…,nw)分别表示集群中的w个文件files={F1,F2,…,Fw}的原始分块数,(m1,m2,m3,…,mw)分别表示w个文件的副本系数.证明.在拥有k个DataNode节点的HDFS集群中有u个不可用的节点,根据定理1,当同一数据块的m个备份同时存储于不可用节点集合SD={dn1,dn1,…,dnu}中时,该数据块不可用,此事件发生的概率为Page6所以,该数据块可用的概率为文件F由n个数据块组成,当n个数据块都可用时,文件F可用,此事件发生的概率为由定义6,p=〈犮sm×i,SD,files,flag〉中flag=1表示集群中任意文件files={F1,F2,…,Fw}都满足定理1,即集合files={F1,F2,…,Fw}中所有文件都可用,此事件发生的概率为A(k,m1(1-A(u,m1)A(k,m3(1-A(u,m3)3.2HDFS集群与数据块矩阵示例如图3所示为一个由4个RACK,每个RACK中分别由3,4,2,5个DataNode节点服务器组成的HDFS集群,其中节点dn31与dn44处于休眠状态,dn32与dn41处于宕机状态.根据定义1该集群DataNode节点矩阵表示为犆5×4,根据定义2集群DataNode节点状态矩阵表示为犇犛5×4.熿犆5×4=燀.图3HDFS集群中文件数据块存储与状态示例设F1是分块为n=2、副本系数m=3,F2是分块为n=3、副本系数m=2的文件存储于犆5×4集群中,那么根据定义3,F1、F2文件分块矩阵为犉12×3、犉23×2,根据定义4数据块存储矩阵为犛犉12×3、犛犉23×2,根据定义5数据块状态矩阵为犅犛犉12×3、犅犛犉23×2.犉12×3=b11b12b13犅犛犉12×3=111[]111,犉23×2=犛犉23×2=假设DataNode节点dn13状态转化为2、dn24转化为3时,HDFS集群DataNode节点状态矩阵犇犛5×4、文件F1、F2数据块状态矩阵犅犛犉12×3、犅犛犉23×2改变为犇犛5×4=犅犛犉23×2=从数据块状态矩阵犅犛犉12×3与犅犛犉23×2我们可以看出,节点dn13与dn24的状态改变并没有影响文件F1数据块的可用性,但是使得文件F2第2个数据Page7块变得不可用.由此可见节点dn13与dn24不能同时进入休眠状态,否则将影响文件F2的数据块可用性.通过定理2的证明过程与上述示例可以看出,当集群中处于不可用状态的节点数量大于等于文件副本系数,即um时,该文件都有可能处于不可用状态.在不改变数据块原始存储结构的情况下,最多能休眠u=m-1个DataNode节点,在k值较大时达到的节能效果甚微.所以,本文下面设计了数据块存储结构配置算法,根据文件的访问规律动态配置数据块的存储结构,RACK区域划分算法将RACK分成Active-Zone与Sleep-Zone两个区域,通过休眠Sleep-Zone中的DataNode节点达到节能的目的.对称数据块存储策略与该存储策略下的节能算法在不影响原HDFS可靠性、高效性与可扩展性的前提下,对称数据块存储策略使得具有相同存储结构的DataNode节点之间能够实现任务的转移与替换,算法通过任务调控产生并休眠空闲节点从而达到节能的目的.4HDFS节能算法4.1DataNode节点休眠验证算法输入:待验证的节点ID,datanodeID;算法1.DataNode节点休眠验证算法.初始化:Setblocks←newList〈Block〉();block←newBlock();file←newFile();rowNum←0;cloumnNum←0;activeNumInRow←0;rowValue[]←newint[];blockStatusMatrix←newBlockStatusMatrix();updatedBlockStatusMatrix←newBlockStatusMa-trix();1.blocks←getBlocks(datanodeID);2.fori=0toblocks.size()-1do3.block←blocks.get(i);4.file←getFile(block);5.blockStatusMatrix←getBlockStatusMatrix(file);6.updatedBlockStatusMatrix←7.rowNum←updatedBlockStatusMatrix.getRowNum();8.cloumnNum←updatedBlockStatusMatrix.getCloumnNum();9.forj=0torowNum-1do10.rowValue[cloumnNum]←updatedBlockStatusMatrix.getRowValue(j);11.fork=0tocloumnNum-1do12.ifrowValue[k]==1then13.activeNumInRow++;14.endif15.endfor16.ifactiveNumInRow==0then17.returnfalse18.endif19.endfor20.endfor21.returntrue定理1可用于验证一个DataNode节点由活动状态转化为休眠状态是否影响数据块的可用性.当任意DataNode节点由活动状态转化到休眠状态时,使得该节点上所有的数据块不可用,通过更新并验证休眠DataNode节点上所有数据块所属文件的数据块状态矩阵犅犛n×m,是否违反数据块可用性原则来验证该节点能否进入休眠状态.DataNode节点可休眠验证算法如算法1所示.算法第1行通过输入参数datatnodeID得到DataNode节点上所有数据块的集合,遍历所有数据块并通过数据块信息得到数据块所属文件的file对象,通过file对象可以得到该文件的数据块状态矩阵.算法第6行更新DataNode节点上所有数据块状态由1(活动)转化为2(休眠)后的数据块状态矩阵.循环数据块状态矩阵的每一行,验证新的数据块状态矩阵行是否能满足数据块可用性的要求.如果有任意数据块变得不可用,第17行返回false,表示该DataNode节点不能进入休眠状态;如果循环结束,验证所有的数据块可用性并没有受到DataNode节点休眠的影响,返回true,此时可将该节点休眠节能.4.2数据块存储结构配置节能算法文献[32-33]通过对Yahoo公司HDFS集群内部数据块访问日志的分析,得出90.26%的数据块都会在其上传2天内进行第一次访问,89.61%的数据块都会再其上传后的10天内进行最后一次访问,40%的数据块最后一次读取时间到最后删除的时间跨度都不会超过20天.由此可见HDFS集群内部数据块的访问具有较强的规律性,数据块访问的热点期大多集中在其上传后较短的一段时间内,过后则进入空闲期.根据数据块这种访问规律并结合数据块矩阵本文设计了数据块存储结构配置节能算法.如图4所示,RACK区域划分算法将RACK分成Active-Zone与Sleep-Zone两个区域,Active-Zone中的DataNode节点用于存放状态为1的数据块,而Sleep-Zone中的节点用于存放状态为2的数据块,并通过休眠处于Sleep-Zone的节点来达到节Page8能的目的.算法在保证数据块可用性的前提下,在算法执行时间周期T内根据文件的访问频率调整该文件的数据块状态矩阵犅犛n×m中处于活动状态数据块的数量.如果一个文件在时间周期T内访问次数小于阈值sleepCount,算法则会减小该文件的活动数据块的数量,相反如果访问次数大于阈值active-Count,则增加活动数据块的数量;算法在达到节能目的的同时保证了数据块的可用性.算法如算法2所示.输入:算法2.数据块存储结构配置节能算法.HDFS集群中所有数据文件:List〈File〉allFileInHDFS;算法执行周期:T;将数据块从Active-Zone移动到Sleep-Zone的阈值:将数据块从Sleep-Zone移动到Active-Zone的阈值:初始化1.ifexecutionTime(T)then2.acitveAllSleepDataNodes();3.fileNumInHDFS←allFileInHDFS.size();4.fori=0tofileNumInHDFS-1do5.file←allFileInHDFS.get(i);6.visitCount←getVisitCountFromLog(file);7.blockStatusMatrix←getBlockStatusMatrix(file);8.cloumnNum←blockStatusMatrix.getCloumnNum();9.activeBlockNumInRow←blockStatusMatrix.getAcitveNum();10.ifvisitCount<sleepCountthen11.ifactiveBlockNumInRow>1then12.reduceActiveBlockNum(blockStatusMatrix);13.moveBlockToSleepZone(block,2);14.endif15.endif16.ifvisitCount>activeCountthen17.ifactiveBlockNumInRow<cloumnNumthen18.increaseActiveBlockNum(blockStatusMatrix);19.moveBlockToActiveZone(block,1);20.endif21.endif22.updateBlockStoreMatrix(file);23.updateBlockStatusMatrix(file);24.endif25.endif算法输入参数T为算法执行时间周期(如一天、一周等),可根据不同的HDFS集群的特点设置不同的T值并最好选择在HDFS集群较为空闲时执行算法;sleepCount与activeCount为减小与增加文件活动数据块数量的阈值,参数allFileInHDFS表示集群中所有文件的集合.算法第1行表示达到执行时间周期T条件时开始执行算法,代码行2首先唤醒所有的休眠节点,以便后续操作的顺利进行.代码行4循环遍历HDFS集群中所有的文件数据块状态矩阵,并根据文件的访问日志得到数据块的访问次数,与阈值参数sleepCount、activeCount进行比较判断该文件是减小还是增加活动数据块的数量,并将状态改变后的数据块转移到相应的区域中,最后22、23行更新该文件的数据块存储与状态矩阵.数据块存储结构配置节能算法需要RACK区域划分算法的支持.RACK区域划分算法如算法3所示.算法3.RACK区域划分算法.输入:初始化:Setrack←newRack();block←newBlock();dataNode←newDataNode();dataNodesInRack←newList〈DataNode〉();blocksInDataNode←0;blocksInRack←0;activeBlocksInRack←0;dataNodeNum←0;activeDataNodeNum←0;Page9sleepDataNodeNum←0;1.fori=0toracks.size()-1do2.rack←racks.get(i);3.dataNodeNum←rack.getDataNodeNum(i);4.dataNodesInRack←rack.getDataNodes(i);5.forj=0todataNodeNum-1do6.dataNode←racks.get(j);7.blocksInDataNode←dataNode.getBlockNum();8.blocksInRack+=blocksInDataNode;9.fork=0toblocksInDataNode-1do10.block←dataNode.getBlock(k);11.ifblock.status==1then12.activeBlocksInRack++;13.endif14.endfor15.endfor16.activeDataNodeNum←17.sleepDataNodeNum←dataNodeNum-18.returnactiveDataNodeNum,sleepDataNodeNum19.endforRACK区域划分算法解决了RACK中Active-Zone与Sleep-Zone区域节点分配问题,算法采用与Hadoop原balancer相同的策略,即将RACK中的所有数据块平均分配到该RACK所属节点中,按照RACK中活动与休眠数据块的比例计算活动与休眠节点的数量,算法伪代码如算法3所示.算法首先遍历RACK中所有的DataNode节点与节点中的数据块,算法第12行计算RACK中活动数据块的数量,算法第16行通过计算活动数据块与总数据块的比值来计算Active-Zone区域中节点的数量,代码第17行通过RACK中总的节点数量减去Active-Zone区域中节点的数量便得到Sleep-Zone区域节点的数量.RACK区域划分算法应选择在数据块存储结构配置节能算法第13行代码前执行.4.3对称数据块存储策略下的节能算法机架感知的数据块存储策略下集群中数据块的存储具有随机性,任意两个DataNode节点存储结构不可能完全相同,此种情况下只能通过4.2节重新配置数据块存储结构以达到节能的目的.假设存在相同数据块存储结构的DataNode节点dn1与dn2,即dn1与dn2之间的任务可以相互转移与替换.当dn1,dn2负载率都较低时,将dn1与dn2其中之一进行休眠处理,此时dn1,dn2中的数据块可用性将不会受到任何影响.基于这种思想本文设计了对称数据块存储策略如图5所示.按照数据块分块矩阵犉n×m对称地存储于HDFS集群中,其中Rack1中存放着文件F的原始数据块,Rack2到Rackm都存放原始数据块的副本,即为矩阵犉n×(m-1)中表示的数据块.DataNode节点矩阵为犆r×m:当数据块上传到集群中时按照对称数据块存储策略进行存储,该存储策略使得犆r×m矩阵中每一行中的m个DataNode数据块存储结构完全一致,互为备份.对称数据块存储策略简化了HDFS集群数据块可用性的判断条件,只要犆r×m中的每行保证至少一个节点处于活动状态,HDFS集群中所有数据块都可用.由于副本系数m为一可变因子,设不同m值的犆r×m矩阵为一组,一个HDFS集群可由多个组构成,其结构表示为对称数据块存储策略使得犆r×m组中每一行m个DataNode节点数据块存储结构完全一致,m个DataNode节点之间的任务可以相互转移与替换,节能算法通过控制任务的调度分配产生空闲节点,将空闲节点休眠以达到节能的目的.图6表示了对称图6对称数据块存储策略下的节能算法架构图Page10数据块存储策略下的节能算法架构图,DataNode通过心跳向NameNode发送负载信息,能耗控制器PowerController用于接收与处理NameNode发送过来的节点负载信息,PowerController根据不同的负载情况进行处理,将处理后的配置信息传送回图7当m=3时DataNode负载状态示意图算法4.对称数据块存储策略下的节能算法.1.初始化.设置DataNode最大负载阈值Umax与休眠负载阈值Umin,算法执行时间周期T.2.DataNode节点定期向NameNode节点发送heart-beat心跳信息,心跳信息包括DataNode节点负载状态信息.当达到算法执行时间周期T时,NameNode将负载介于Umin与Umax之间的节点视为正常节点,当有节点负载小于Umin或者大于Umax时,NameNode将该DataNode节点与其同行所有的DataNode负载状态信息放入List〈RowDataNodeStatus〉中并发送给PowerController节点进行处理.3.当PowerController接收到如row2所示负载信息,即有DataNode节点负载均超过Umax时,PowerController向NameNode节点返回配置信息:在时间周期T内停止向dn11,dn12,dn13节点分配数据写入操作,新写入数据任务分配到其它组;转向执行步16.4.当PowerController接收到如row2所示负载信息时,PowerController向NameNode节点返回配置信息:唤醒休眠节点dn23并将dn21与dn22部分任务转移到dn23节点执行;转向执行步16.5.当PowerController接收到如row3所示负载信息时,PowerController向NameNode节点返回配置信息:在时间周期T内将分配任务到节点dn31与dn32的任务转移到dn33节点;转向执行步16.6.当PowerController接收到如row4所示负载信息NameNode节点,最后由NameNode执行Power-Controller发出的节能控制信息.本文以m=3时为例阐述对称数据块存储策略下的节能算法的步骤,设其DataNode负载状态如图7所示.7.当PowerController接收到如row5所示负载信息时,PowerController向NameNode节点返回配置信息:在时间周期T内将dn51部分任务转移到dn52执行,如果在周期T内出现row2所示情况,则执行步4;否则转向执行步16.8.当PowerController接收到如row6所示负载信息时,PowerController向NameNode节点返回配置信息:在时间周期T内将dn61任务转移到dn63执行;转向步16.9.当PowerController接收到如row7所示负载信息时,PowerController向NameNode节点返回配置信息:在时间周期T内将dn71任务转移到dn72与dn73负载较轻的节点;转向执行步16.10.当PowerController接收到如row8所示负载信息时,PowerController向NameNode节点返回配置信息:在时间周期T内将dn81任务转移到dn82节点,如在时间周期T内出现row2情况,转向步4,否则转向步16.时,PowerController向NameNode节点返回配置信息:唤醒dn42与dn43中休眠时间较长的节点并在时间周期T内停止向dn41分配任务;转向执行步16.11.当PowerController接收到如row9所示负载信息时,PowerController向NameNode节点返回配置信息:在时间周期T内将dn91,dn92,dn93中负载最低的节点(假设为dn92)任务转移到其它两个节点(dn91,dn93),当dn92负载降为0时进入休眠状态;转向执行步16.12.当PowerController接收到如row10所示负载信息Page11时,PowerController向NameNode节点返回配置信息:在时间周期T内将dn10_1负载转移到dn10_2(假设dn10_1负载小于dn10_2),当dn10_1负载降为0时进入休眠状态;转向执行步16.13.当PowerController接收到如row11所示负载信息时,PowerController向NameNode节点返回配置信息:在时间周期T内将dn11_1负载转移到dn11_2,当dn11_1负载降为0时进入休眠状态;转向执行步16.14.当PowerController接收到如row12所示负载信息时,PowerController向NameNode节点返回配置信息:在时间周期T内将dn12_1负载转移到dn12_2与dn12_3中负载较低节点,当dn12_1负载降为0时进入休眠状态;转向执行步16.15.当PowerController接收到如row13所示负载信息时,不作任何处理;转向执行步16.16.执行List〈RowDataNodeStatus〉队列的next()方法执行下一行DataNode状态,如果队列中所有的行都处理完成,算法结束.5算法分析模型本节给出HDFS下数据库存储结构配置节能算法与对称数据块策略下的节能算法的分析模型,其中符号定义说明如表1所示.符号F文件表示符号n文件分块原始数据块的数量m数据块副本系数kHDFS集群中DataNode节点的数量u集群中处于不可用状态的DataNode节点的数量sd集群中休眠的DataNode节点的数量wHDFS集群中所有文件的个数z组成HDFS集群的犆r×m组数r犆r×m中DataNode节点的行数PDataNode节点服务器功耗EDataNode节点服务器能耗aDataNode节点服务器电路翻转频率CDataNode节点服务器负载电容fDataNode节点服务器时钟频率V电压SDataNode节点服务器服务速率Pro数据块可用概率服务器中系统能耗主要由处理器、内存、磁盘I/O、散热设备等等组成,据文献[35]服务器功耗由静态功耗与动态功耗组成:其中Pdynamic可表示为其中,a为电路翻转频率,C是负载电容,f为时钟频率,V为电压.电压V与时钟频率f成正比,f时钟频率与系统性能成正比.文献[35]将服务器系统功耗简化表示为其中,σe为空闲功耗或者静态功耗;s为服务器服务速率,与式(5)中f成正比;μe和a为常数,与具体的设备相关.文献[36]指出a的取值通常在3之间波动,而文献[35]对IntelPXA270、PentiumM770与TCP/IPOffloadEngine进行了研究并得出三者a值分别为1.11、1.62、1.66.由于能耗与功耗是完全不同的概念,能耗为服务器在一段时间内所消耗的总能量,单位为焦耳(J),在Δt时间内的能耗定义如式(8)所示:数据块存储结构配置节能算法靠休眠Sleep-Zone区域的DataNode节点达到节能的目的,设所有RACKSleep-Zone中休眠节点数量为sd,那么Active-zone中的节点数量为k-sd,节能算法执行前集群中k个节点都处于活动状态,此时集群功耗为k个节点功耗的总和:当休眠sd个节点后,剩余k-sd个节点消耗能量,此时集群功耗为那么由数据块存储结构配置节能算法节省的功耗为Psave=∑k其中,s1为算法执行前的服务器速率,s2为算法执行后的服务器速率,一般情况下有s1<s2.由数据块存储结构配置节能算法在Δt时间内节省的能量可表达为Esave_Δt=∫t+Δt对称数据块存储策略下的节能算法进行Data-Node之间任务转移与替换时将改变DataNode服务速率s,即减少了任务转移节点的功耗而增加了任务转移目标节点的功耗,特别的当某一个DataNode节点进入休眠状态后,其功耗可忽略不计,即Pserver=0.所以在HDFS集群某副本系数为m组的某一行中,由节能算法带来的功耗节省可表示为Page12Psave_row=∑m其中,P表示该行中第i个DataNode节点节能算法执行前的功耗,P表示该节点节能算法执行后的功耗.那么一个犆r×m组功耗节省为Psave_group=∑r其中r表示犆r×m组中DataNode节点行数.假设HDFS集群由z个犆r×m组组成,那么整个HDFS集群功耗节省可表示为Psave_HDFS=∑z由于HDFS集群是负载不断变化的系统,所以其功耗也在不断变化,由节能算法在Δt时间内节省的能量为Esave_Δt=∫t+Δt(t∑zk=1∑r6评价与比较基于第5节所述数学分析模型,本文使用MatlabCloudsim[37]对本文算法进行模拟分析,通过实验评价与比较,验证数据块的可用性、存储结构配置节能算法与对称数据块存储策略下的节能算法的有效性.其中Cloudsim模拟产生的DataNode节点配置参数如表2所示.CUP(cores/MIPS)6.1数据块可用性实验如图8所示为在不改变数据块原始存储结构前提下不可用DataNode节点数与HDFS集群数据块可用性之间的关系,其中横轴表示不可用节点的数量,纵轴表示集群中所有数据块可用的概率.其line1表示集群中节点数k=100,副本系数m=3,集群中原数据块个数为10000时,不可用状态的节点数量与整个系统可用性概率之间的关系.line1与line2比较,当k与n条件相同时,副本系数m值越大,HDFS集群可用概率越高;line2与line3比较,当m与n条件相等时,DataNode节点数越大,HDFS集群可用概率越高;line1与line4比较,当m与k条件相等时,n越小,HDFS集群可用概率越高.但是无论HDFS集群有多少DataNode节点,其中有多少原始数据块,当集群中不可用的节点数大于等于副本系数m时,都有可能引起数据块的不可用,意味着在不改变数据块存储结构与存储策略的情况下并不能通过休眠节点达到节能的目的.图8不可用节点数与集群可用性之间的关系6.2存储结构配置节能算法通过第5节的数学建模分析,数据块存储结构配置节能算法通过休眠Sleep-Zone区域的DataN-ode节点达到节能的目的,节能效率由Sleep-Zone中休眠节点数量sd与算法执行前后的服务器速率s1与s2决定.而sd、s1与s2三个变量的值又与HDFS中数据块的负载、算法执行周期T、阈值sleepCount与activeCount相关.利用Cloudsim模拟产生10个RACK且每个RACK中有10个DataNode节点即k=100的HDFS集群,数据块副本值随机产生m=random[2,5],原始数据块数n取2~10的随机数,初始化10000个文件存储在该集群中.为了模拟出文献[32-33]数据块访问规律,设文件在上传到集群后第1天的访问次数取0~100的随机数,第2天取0~90的随机数,第3天为0~80的随机数,依次类推,10天及以后访问次数取0~10的随机数.如图9Page13所示为设算法执行周期T=1天、阈值参数sleep-Count分别取值5与10,阈值参数activeCount分别取值30与50时算法模拟的结果.由图9可以看出sleepCount取值越小,active-Count取值越大时相同集群与负载条件下产生的休眠节点数越多;即相同条件下sleepCount参数越小,节能效率越高,sleepCount是平衡数据块访问频率与集群节能效率的参数;而activeCount越小,节能效率越低,但同一数据块备份数越多时,数据块响应效率越高,即activeCount是平衡数据块响应与节能效率的参数.不同的HDFS集群具有不同的负载情况与用户QoS协议,应根据实际的情况设定算法执行周期T、阈值参数sleepCount与activeCount.当集群中所有数据块与其副本中只有一个数据块存储在Active-Zone区域中时,休眠节点数量达到最大,此时休眠节点数量达到珡m-1示集群中所有文件的平均副本系数;此时节能效率达到最高的(1-1/珡m).当空闲功耗参数σe=100,能耗常数μe=300,如图10为在k=100的HDFS集群中不同休眠节点图10不同休眠节点与a值下集群功耗与平均负载之间的关系数量与常数a取不同值时集群功耗与集群平均负载的关系示意图.如图10可以看出,相同集群平均负载率条件下,休眠节点数越大,集群功耗越小;相同集群休眠节点数与集群平均负载条件下,常数a值越小,集群功耗越小.由此可见存储结构配置节能算法不仅能够通过增加休眠节点数来提高节能效率,也可以通过选取常数a值较小的系统硬件来提高系统节能效率.6.3对称数据块存储策略下的节能算法利用Cloudsim模拟产生的m=3,r=10的DataNode节点犆10×3组(节点配置如表2所示),为了测试不同负载情况下节能算法的效率,分别向该集群在限定范围内施加低负载、随机负载与高负载3种情况.表3为3种不同负载情况下节能算法执行前后节点负载比较,其中低负载初始平均负载为0.1403,节能算法执行后平均负载为0.1453;随机负载初始平均负载为0.4442,节能算法执行后平均负载为0.4473;高负载初始平均负载为0.7083,节能算法执行后平均负载为0.7093.犇犖r×m低负载算法dn110.160.210.220.540.590.59dn120.190.160.720.670.450.65dn130.120.320.620.480.870.87dn210.290.210.920.510.690.69dn220.0200.130.690.920.92dn230.320.220.0600.880.78dn310.0700.440.550.760.76dn320.170.260.570.340.080dn330.150.180.0800.750.75dn410.310.220.310.880.970.97dn420.0400.570.420.930.63dn430.250.210.910.360.770.77dn510.0100.360.430.650.65dn520.0200.280.220.640.64dn530.130.240.240.380.880.88dn610.210.280.0900.620.62dn620.0700.590.780.840.54dn630.170.340.770.660.330.63dn710.0600.890.860.810.81dn720.150.190.460.530.890.89dn730.250.320.130.340.740.74dn810.0300.140.080.990.99dn820.230.160.610.350.810.81dn830.120.080.230.410.360.46dn910.120.120.650.680.530.53dn920.0600.0700.860.86dn930.290.250.610.780.380.48dn10_10.0300.940.650.520.62dn10_20.160.390.020.450.980.98dn10_30.0100.450.380.760.77平均负载0.14030.14530.44420.44730.70830.7093Page14如图11表示低负载状态下节能算法执行前后负载对比,在平均负载为0.1403的情况下,节能算法执行后将编号为dn22、dn31、dn42、dn51、dn52、dn62、dn71、dn81、dn92、dn10_1、dn10_3共11个节点都进行了休眠处理,休眠率为37%,并且节能算法执行后平均负载变为0.1453.如图12表示随机负载状态下节能算法执行前后负载对比,在平均负载为0.4442的情况下,节能算法执行后将编号为dn23、dn33、图11低负载状态下节能算法执行前后负载对比图12随机负载状态下节能算法执行前后负载对比当空闲功耗σe取值100,常数μe与a分别取值70与1.5时,低负载、随机负载与高负载3种负载状态功耗如图14所示.其中图14(a)表示低负载状态下节能算法执行前后节点的功耗;图14(b)表示dn61、dn92这4个节点进行了休眠处理,休眠率为13.3%.节能算法执行后平均负载相比之前变为0.4473,平均负载在节能算法的执行前后变化不大.如图13为高负载状态下节能算法执行前后负载对比,在平均负载为0.7083的情况下,节能算法执行后将编号为dn32的唯一节点进行了休眠处理,休眠率为3.3%.节能算法执行后平均负载相比之前变为0.7093.随机负载状态下节能算法执行前后节点的功耗;图14(c)表示高负载状态下节能算法执行前后节点的功耗;图14(d)表示3组负载状态下节能算法执行前后节点的平均功耗对比.Page15图13高负载状态下节能算法执行前后负载对比图143种负载状态下节能算法执行前后DataNode节点功耗对比Page16如图14所示,低负载状态下DataNode节点平均功耗在节能算法执行后由120.81转化为80.54,功耗节省率为33.3%;随机负载状态下DataNode节点平均功耗在节能算法执行后由146.71转化为132.35,功耗节省率为9.8%;高负载状态下Data-Node节点平均功耗在节能算法执行后由172.19转化为168.33,功耗节省率为2.2%.由此可见功耗节省率与HDFS集群负载状态相关,HDFS集群平均负载越低,功耗节省率越高;相反,HDFS集群平均负载越高,功耗节省率越低.除此之外,同一集群在相同平均负载率下,功耗节省率还受到节点不同负载率分布的影响,节点负载率分布越均匀,功耗节省率越低,相反则越高.在副本系数为m的DataNode节点组中,当所有行中有m-1个DataN-ode节点处于休眠状态时功耗最低.但是由于任务的转移与替换会加大目标节点的负载,即提高了该节点的功耗,所以每组的最大功耗节省率不会超过(1-1/m).7结论及下一步工作由于传统IT系统超额的资源供给与冗余设计以及负载均衡算法对能耗因素的忽略导致了高能耗低效率问题的日益突出.在HDFS集群节能问题上,由于存在数据块可用性的要求,使得HDFS并不能简单地采用传统数据中心合并任务与休眠空闲节点的方法解决能耗问题,保证数据块的可用性成为设计HDFS集群下节能算法的前提.本文通过研究HDFS集群结构、节点与数据块状态与数据块存储机制建立了DataNode节点矩阵、节点状态矩阵、文件分块矩阵、数据块存储矩阵与数据块状态矩阵,为研究数据块可用性、节能算法等提供了基础模型.利用数据块状态矩阵与数据块可用性之间的关系设计了DataNode节点休眠验证算法,算法能够确认DataNode节点的休眠是否对数据块的可用性造成影响.通过文件可用性概率分析与证明得出在不改变数据块存储结构与存储策略的情况下并不能通过休眠DataNode节点达到节能的目的.所以本文分别从改变数据块的存储结构与存储策略两方面着手对HDFS进行节能改进.设计了数据块存储结构配置节能算法与RACK区域划分算法,将处于Sleep-Zone区域的节点休眠从而达到节能的目的.设计了对称数据块存储策略,解决了节点休眠对数据块可用性的影响问题,对称数据块存储策略下的节能算法将任务转移与替换产生的空闲节点休眠,从而达到节能的目的.通过实验表明两种节能算法都能解决HDFS集群的能耗低利用率问题,并且集群负载越低算法节能效率越高.下一步工作主要集中在以下3个方面:(1)节能算法参数的优化问题.由于不用的HDFS集群在负载、应用特点等方面存在很大的差异,需要探寻不同环境下节能算法参数的优化方法.(2)分布式文件系统在数据可用性、性能、能耗之间存在相互联系与制约的关系,如何在这三者之间找到合理的平衡点是将来研究的一个方向.(3)分布式文件系统节能的标准化问题.分布式文件系统在节能方面并没有统一的标准与模型,制定统一的节能标准与模型是将来研究的另一个方向.
