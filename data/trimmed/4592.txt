Page1增量式迭代计算模型研究与实现1)(东北大学软件学院沈阳110819)2)(东北大学计算中心沈阳110819)3)(东北大学信息科学与工程学院沈阳110819)摘要不动点迭代广泛存在于数据挖掘和机器学习算法中,这些算法已应用到诸如社会网络分析、高性能计算、推荐系统、搜索引擎、模式识别等诸多领域中.在云计算环境中,利用MapReduce编程模型所带来的便利,通过普通的PC集群运行相应的迭代算法,可以提高迭代算法的执行效率.但由于数据的快速变化,每当数据发生改变,整个迭代算法也需要重新运行,这将会导致大量的运算资源浪费和性能损失.文中研究基于原始迭代结果和新增数据的增量迭代计算DELTA(DeltadatabasedincrEmentaLiTerAtivecomputing),并提出DELTA模型以解决上述问题.文中理论证明了DELTA模型的正确性,阐述了其适用范围,并列举了PageRank、K-means和DescendantQuery算法在DELTA模型中的运用.文中还扩展HaLoop为ΔHaLoop框架,使其支持增量式的迭代计算.通过一系列的测试用例,对DELTA模型功能、性能进行了分析和讨论,实验结果表明DELTA模型在获得准确的迭代结果的基础上性能优势明显.文中提出的DELTA模型能够适应多数迭代算法,对云计算环境下的迭代计算的应用和优化起到推动作用.关键词云计算;大数据;MapReduce;迭代计算;增量迭代1引言不动点迭代广泛存在于数据挖掘和机器学习算法中,这些算法已应用到诸如社会网络分析、高性能计算、推荐系统、搜索引擎、模式识别等诸多领域中.例如:著名的PageRank算法根据网页之间的链接关系,从任意迭代初始值开始,根据迭代函数更新每个网页的PageRank值直至收敛[1];类似迭代算法还包括最大期望(Expectation-Maximization)算法、K-means算法[2]、协同过滤(CollaborativeFiltering)算法[3]、SVM算法[4]等.由此可见迭代算法有着非常广泛的应用范围.随着人类进入到信息化时代,互联网、传感器和生物信息学等领域的快速发展,数据量呈现爆炸型增长.当今时代是一个数据量爆发的时代[5-6],在大数据环境下,迭代算法出现诸多不适用性,其中由于普通服务器的计算能力有限,算法运行时间往往令人无法接受.大数据上的迭代算法的运行消耗完全超出了单服务器的承受极限,因此学术界开始寻找分布式的迭代算法执行环境[7].基于Hadoop①MapReduce[7]的HaLoop框架[8]是目前为止较为成熟的迭代计算框架.利用HaLoop框架和MapReduce编程模型所带来的便利,可通过廉价的PC集群获得强大的计算能力,支持大数据环境下众多迭代算法.然而,我们注意到,时变性是大数据的一个特点.大数据是数据量庞大且高速增长的数据,当数据量增加后,原始数据的迭代结果将不再适用,整个迭代算法也需要在数据全集上重新运行,这将浪费大量的时间和资源.若能够通过新增数据集和已知的迭代结果完成增量式的迭代计算,则可以很大程度上提高迭代计算的效率.而就我们目前的知识,现存少量模型和算法层面的增量式迭代计算研究,成熟的增量式迭代框架也屈指可数,文中将在相关工作部分加以分析和比较,此外较相关的工作是以增量的方式更新元数据或维护索引等.例如Google的Percolator[9]系统可以以增量的方式更新索引,Incoop本文研究增量式的迭代计算模型以及其实现框架,而非迭代算法本身,旨在提出适用于大部分算法的,基于原始迭代结果和新增数据的增量迭代计算(DeltadatabasedincrEmentaLiTerAtivecomputing,DELTA)模型和框架.DELTA模型基于新增数据集和原始迭代结果,进行新一轮迭代,在不损失精度的前提下提升迭代性能.本文采用复合函数和集合抽象迭代过程,定义了DELTA模型,阐述其适用范围,设计了DELTA模型中的关键算法,证明了其性能优势和迭代结果的正确性,并示例性地给出了其在PageRank、K-means、DescendantQuery迭代算法中的应用;本文还扩展HaLoop使其支持DELTA模型;最后本文通过实验验证DELTA模型的正确性和性能优势.本文第2节介绍相关工作;第3节定义DELTA模型,并详述模型的正确性证明和适用范围以及在PageRank、K-means和DescendantQuery算法上的应用;第4节简要介绍支持DELTA模型的HaLoop扩展框架的结构以及在其他框架上的实现分析;第5节通过实验验证DELTA框架的功能和性能;最后,在第6节对本文的研究进行总结并提出进一步的工作.2相关工作迭代算法,例如PageRank[1]、HITS[11]、神经网络计算[12],都有一个共同的特点:数据的计算过程是迭代的,直至满足一个确切的收敛条件.国内外已有较多针对迭代算法的研究成果,相关技术上也比①http://hadoop.apache.org/Page3较成熟.部分研究将迭代算法等价于图的相关算法,并给出理论证明.部分文献也涉及了增量式的迭代算法研究.例如,文献[13]给出了增量式的迭代计算的相关条件,同时给出了相关增量式的迭代计算的例子以及反例.文献[14]研究当迭代结构发生改变时,如何继续进行迭代.上述文献虽然对不动点迭代算法进行了深入的研究,但由于发表时间较早,尚未采用分布式计算环境,而且均针对特定算法.此外,若使用上述文献中的方法进行大数据迭代计算,会由于数据量以及运算量超过单服务器承受能力而无法即时获得准确的迭代结果.然而,MapReduce对于迭代计算并没有提供直接的支持.一种变通的方法是编程人员通过程序设计,精心地布置MapReduce任务,同时编写一些特殊的算法来支持迭代算法,例如,用于检测收敛条件是否满足的相关算法.这样做将会导致编写迭代算法的过程异常复杂,一些简单的作业也需要采用多个Map和Reduce任务来实现,且大量中间结果的存储和传递导致I/O资源和网络资源的浪费.Bu等人[8]在提出了HaLoop框架,基于云计算技术提供迭代算法的运行框架,使得迭代计算更高效.HaLoop扩展了Hadoop,以更适合迭代计算,包括:(1)编程接口更加适用于迭代算法;(2)框架实现迭代终止条件的检测;(3)任务尽量满足数据本地计算的特性,两次迭代任务尽量使用相同的数据;(4)采用缓存和索引两种优化机制.但是HaLoop的动态和静态数据无法分离,且没有一个客观的停止迭代的标准[5].此外,还存在一些迭代计算框架的实现.Twister[15]是一个基于流,支持迭代算法的MapReduce框架,它将全部数据存放在分布式缓存中,采用独立模块传递所有的消息和数据.但是数据驻留内存的限制使其难以实用,且其计算模型的抽象程度不高,支持的算法也很有限.iHadoop分配器提供一种数据定位机制,从而减少数据的冗余传输以及I/O和网络资源的浪费.PrIter[17]是基于Hadoop的,支持带优先级的迭代计算框架,能够保证迭代的快速收敛,适合实时查询需求.iMapReduce[18]是一种基于MapReduce的迭代计算模型,它尽量地减少MapReduce作业的数量,通过缓存的方法除去Shuffle阶段中的静态数据,并允许Map任务的异步执行,以此优化迭代计算过程.但是它的静态调度策略和粗粒度的任务可能会导致资源利用不佳和负载不均衡.REX[19]结合了大数据环境中的计算平台和传统的RDBMS技术,提出了RQL在大数据环境中模拟SQL的特性如连接、聚集、子查询、递归查询等.其主要创新点在于:对于迭代计算而言,可以仅传递迭代步骤间的变化,从而大幅度的优化迭代(递归)查询.在上述迭代计算框架中均提供基于云计算技术的迭代算法执行环境,但都没有考虑增量数据的迭代问题,当新数据产生时,上述框架均需要重新进行迭代.此外,支持迭代计算的分布式框架还有HaLoopNaiad[21]等,后文会提及.本文基于HaLoop实现了支持DELTA模型的ΔHaLoop,HaLoop又是基于Hadoop分布式文件系统的,而其他主流的迭代框架,如Spark、Twister和Naiad,或基于其他文件系统,或基于分布式缓存.但理论上,这些框架都可以扩展以支持DELTA模型.此外我们也参考了特定算法的增量式迭代优化,本节以K-Means算法为例.文献[22]基于FGKA(FastGeneticK-meansAlgorithm)提出了IGKA(IncrementalGeneticK-meansAlgorithm),用于基因数据的聚类;文献[23]提出基于图割理论的KernelK-means算法,同时进一步提出了增量式加权KernelK-means算法;文献[24]研究了K-means收敛的情况,并基于DistortionsReduction提出增量式K-means算法,解决了K-means收敛到局部极值问题;文献[25]提出了基于手机轨迹数据的紧凑表示法和轨迹相似性度量,基于上述理论该研究又提出了增量式的聚类方法用于发现空间中相似的移动终端;文献[26]基于现有的增量式神经网络(IGNG)提出了其改进算法I2GNG用于证券分类(InvoiceClassification);文献[27]提出了增量式分类方法用于在线文档分类,但是其研究重点是相似性度量和文档结构的抽取.本文提出的DELTA模型并非针对K-means算法,并且和上述研究也有较大的区别:一部分算法是单机算法,难以扩展到分布式环境,即使用MapReduce成功改写这些算法,其执行性能也很低,如文献[22-23];另一部分算法采用“增量迭代”技术,其目的是为了研究算法收敛性,或特定领域的聚类算法,与本文所定义的DELTA目标不同,如文献[24-27].在相关文献中,文献[28]属于增量式的K-means算法,且可以移植到MapReduce框架中,且移植后的算法与本文实验中所采用的K-means全量迭代算法是一致的,本文5.4节对其进行性能比较.通过分析可以看出,大多数的迭代计算框架都Page4优化迭代算法的执行过程,从而提高计算效率.具体的措施如下:(1)使用缓存和索引的方法,尽量地减少数据传输过程中本地和网络I/O代价;(2)使用内存优化的相关技术,加速迭代算法的执行;(3)使用缓存技术优化迭代计算中终止条件判定操作,从而减少迭代算法执行时间;(4)优化Map任务和Reduce任务之间的通信方法,从而实现异步迭代;(5)引入RDBMS的递归查询技术支持迭代更新.在迭代框架的研究方面,当前研究基于算法运行流程角度更新迭代结果,但现有研究均未涉及基于原始迭代结果和新增数据的DELTA模型和框架.DELTA作为迭代计算的一种重要的优化手段,能够利用原始迭代结果以及新增数据在较短时间内得到新的迭代结果.本文从算法和迭代框架层面出发,研究内容与现有研究有着本质不同.3增量迭代计算模型DELTA模型是迭代算法和计算过程的抽象,该模型利用已有迭代结果以及新增数据集,计算新的迭代结果,该模型是增量迭代计算框架的基础.在本节中,首先定义迭代、迭代轮、增量迭代等相关概念;随后给出DELTA模型的形式化表达;最后介绍模型证明、差集算法和模型应用.3.1模型定义定义1.迭代.迭代是用计算机解决问题的一种基本方法.计算机对一组指令或一定步骤重复执行,在每次执行这组指令或步骤时,由变量的原值推出它的新值.根据定义1,一个迭代算法实际上是函数的重复执行,在执行过程中对一组变量进行更新,直到达到某种终止条件为止,由此可得迭代算法的3个要素为迭代变量、迭代函数和迭代的终止条件.(1)迭代变量.在迭代算法中,至少存在一个直接或间接地不断由旧值递推出新值的变量,这个变量就是迭代变量.(2)迭代函数.由迭代变量的前一个值推出其下一个值的函数.(3)迭代终止条件.当迭代终止条件满足时,迭代算法运行结束,输出迭代结果,此时也称之为迭代算法收敛.定义2.迭代轮.迭代变量通过迭代函数更新一次的过程称之为一次迭代轮,或一轮迭代.整个迭代算法可以由n(n1)个迭代轮(n轮迭代)组成,记作t1,t2,…,tn,i∈[1,n-1],ti的输出是ti+1的输入,t1的输入定义为初始化迭代变量以及参与迭代的数据,tn的输出即为最终的迭代结果.设迭代算法x=fn(x0,L):根据某迭代初始变量x0和迭代数据L,经过迭代计算得到迭代结果x.f(x,L)是迭代函数,亦可视为某轮迭代.f(x,L)的参数为迭代变量的初始值x0以及迭代数据L.记函数f(x,L)的n次自身复合函数f(f(…f(f(x,L),L)…,L),L)为fn(x,L).fn(x0,L)表示迭代函数作用于迭代数据L上,经过n轮达到收敛状态.当基于迭代数据L的迭代计算完成后,由于业务增长而产生的新的迭代数据ΔL即为增量数据.例如,PageRank算法的网页链接关系数据和社会网络的图状态数据每天都会增加,于是,需要根据全量数据更新迭代结果.在后文3.2节会详细描述,我们定义L为原始数据,ΔL为增量数据,ΔL-L为差集数据,ΔL/L为关联数据,ΔL∪L为全量数据,一般的,|ΔL||L|.在原始数据上的迭代称为原始迭代,在全量数据上的迭代称为全量迭代.两者算法相同但针对的数据不同.全量迭代能够得到更新后的迭代结果但消耗大量资源.本文的DELTA模型将依赖定义3中“增量迭代”的定义.后文将证明增量迭代结果与全量迭代结果相同,但性能优于全量迭代.定义3.增量迭代.增量迭代是根据新增数据ΔL和原始迭代结果获得新的迭代结果的迭代方法,且可由式(4)表达.所以R=fγ[fα(R0,L)∪fβ(ΔR0,ΔL-L),L∪ΔL]根据式(1)~(3),增量迭代的步骤定义为:(1)原始步.在原始数据L上进行α轮迭代直至收敛,初始迭代变量集为R0,收敛后得到原始数据上的迭代结果集R,如式(1)所示,该步骤在增量数据ΔL到来时已经完成;(2)增量步.在差集数据ΔL-L上进行β轮迭代直至收敛,初始迭代变量为ΔR0,收敛后得到差集数据上的迭代结果集ΔR,如式(2)所示;(3)合并步.在全量数据L∪ΔL上继续γ轮迭代直至收敛,初始迭代变量集为R∪ΔR,收敛后得到最终迭代结果集R,如式(3)所示.定义3即定义了DELTA模型采用的迭代方法,且定义3同样适用于原始迭代的情况.按式(4),Page5在初次迭代时,原始的迭代结果R=,原始数据L=,这时所有的迭代数据被当作增量数据ΔL处理,α=γ=0.3.2迭代数据迭代数据是由数据以及数据间的关系所组成的集合.如PageRank算法中迭代数据是由页面和页面之间的链接关系所组成的集合.设迭代数据符合图关系L.在L中节点的集合为V(L),边的集合为E(L),其中E(L)是节点所组成序偶的集合.在L中,u,v∈V(L),如果u,v是有关系的,则有〈u,v〉∈E(L).图关系ΔL同理.如图1所示,将图L和ΔL使用邻接矩阵的方式表示.在图1中,V(L)={A,B,C,D},V(ΔL)={E,F,G}.如果任意两个节点有关系,则在矩阵中标识为1,否则为0.矩阵被分为4个区域,如图所示编号分别是M1,M2,M3,M4.其中,原始数据L=M1;增量数据ΔL=M2+M3+M4;全量数据ΔL∪L=M1+M2+M3+M4;定义差集数据(ΔL-L=M4)为ΔL的与L无关的最大子图;定义关联数据(ΔL/L=M2+M3)为ΔL的与L关联的最大子图,ΔL=(ΔL-L)∪(ΔL/L),差集数据和关联数据计算方法如下:ΔL-L=〈V(ΔL-L),E(ΔL-L)〉,V(ΔL-L)=V(ΔL)-V(L),E(ΔL-L)={〈u,v〉|〈u,v〉∈E(ΔL)∧u,v∈V(ΔL-L)}(5)ΔL/L=〈V(ΔL/L),E(ΔL/L)〉,V(ΔL/L)=V(ΔL)∩V(L)∪{v|〈u,v〉∈E(ΔL)∧u∈V(ΔL)∩V(L)},E(ΔL/L)={〈u,v〉|〈u,v〉∈E(ΔL)∧u,v∈V(ΔL/L)}本文更多地考虑式(5)的差集计算,我们称为差集算法.在图1中,M1和M4是相互独立的,M4是增量数据中与原始数据独立的部分,增量迭代分别对M1和M4运行迭代算法,对应式(1)和(2).然而还需要考虑增量数据和原始数据的关联部分M2+M3,因此需要将M1的迭代结果R和M4的迭代结果ΔR合并,并在全量数据上继续迭代直至收敛.3.3迭代函数迭代函数f的设计取决于迭代算法,且f需满足以下条件:f在迭代轮中保持不变,且可以分解为若干变换函数h的代数运算.针对某一个迭代变量xi,有形如:f(xi,L)=h1(x1,L)h2(x2,L)…hn(xn,L)(i∈[1,n],n为迭代变量个数),其中为代数运算,h函数是某迭代变量对当前迭代变量的变换函数,h函数对运算是分布的,h(ab)=h(a)h(b).为描述简便,我们将L视为常量,在f函数和h函数中省略.若仅考察一个迭代变量r在整个迭代过程的变化,在一轮迭代中,该迭代变量吸收了其他迭代变量对它的变换,将这些变换聚集起来改变自身.如果在某轮迭代中某变量由r0变换为r,其他变量为r1和r2,迭代函数为f,而变换函数为h,聚集运算为,那么一轮迭代可以表达成r=f(r0,r1,r2)=h(r0)h(r1)h(r2),一个变量的多轮迭代可以看n作∑i=1h(ri)递归调用.因此,有如下定义.定义4.迭代计算的分解描述.迭代计算可以分解为每一个迭代变量的变化,而一个迭代变量的变化可以分解为该变量每一轮变化的积累,而每一轮变化的积累又可以分解为其他变量对该变量的变换的代数聚集.在这种分解描述下,某个迭代变量的收敛条件为变化为零,整个迭代计算的收敛条件为所有的迭代变量均收敛.为描述简单,令迭代变量变化为零时仍可以继续迭代,以此保证所有变量同时收敛.定义4中,“变化”表示某迭代变量自身的改变,这种改变来源于其他迭代变量对该变量的“变换”,h函数则为“变换函数”.对于某一轮迭代,设由n个迭代变量所组成的集合为R={r1,r2,…,rn}.其中迭代函数为可以分解为f1,f2,…,fn.迭代变量ri第k轮(k为自然数)迭代可以表示为rk2,…,rk-1rk-1式(7)形式:rkPage6式(7)可以解释为迭代变量rki(rk-1量对其的变换,累积这些变换,并变化自身值.式(7)中函数hj的初始值为{r0值,那么,当i≠j时hj时,hj迭代变量变换的聚集操作,例如在PageRank算法中为加法(+),K-means算法中为集合并(∪).本文提出的DELTA模型要求其迭代函数能按定义4和式(5)分解描述,且为代数运算,h函数对运算是分布的.3.4理论证明本节将从理论上证明DELTA模型在性能上的优势,并证明增量迭代和全量迭代的迭代结果是一致的.(1)性能优势证明我们首先假设迭代算法的执行时间仅与迭代数据大小有关,则原始迭代的执行时间为τ(|L|);增量迭代的执行时间为τ(|ΔL-L|)+τ(|ΔL∪L|),而全量迭代的执行时间为τ(|ΔL∪L|),显然增量迭代的性能无法优于全量迭代.分析知迭代算法的执行时间还与迭代变量初始值和迭代数据有关.根据定义4,一个迭代轮可以分解“迭代变量吸收其他迭代变量对它的变换,将这些变换聚集起来改变自身”这一过程,因此,若迭代变量初始值越不合理,迭代数据越紊乱,变量间相互变换越多,迭代轮数越大,迭代时间越长.增量迭代增量步增量迭代合并步表1迭代的执行定性比较迭代轮数n0n1n2n3n2<n0≈n1≈n3进一步分析知,影响增量迭代性能优势的因素有两个:①增量数据更新原始迭代结果的程度,称为更新度.更新度影响增量迭代性能优化效果,更新度越小,优化效果越好,反之则反.按h函数的定义h(r,L)(L在前文公式中省略),增量数据对原始迭代结果的更新程度体现在两个方面:一是增量数据中的迭代变量对原始数据中的迭代变量的变换,即h函数的r部分;二是增量数据对原始迭代结果的变换,即h函数的L部分;②原始数据量大小,由于原始迭代,增量迭代的原始步、增量步、合并步,以及全量迭代都是迭代计算.对于迭代计算的性能,取决于迭代轮数和每轮迭代代价(I/O代价和运算量).按定义4,我们从“迭代轮数”和“每轮迭代代价”两个角度定性分析各种迭代方法的执行时间,以原始迭代执行时间为参照,具体分析如下:①对于增量迭代的增量步,ΔL-L虽然远小于L,但ΔL-L中迭代变量尚未吸收其他变量对它的变换,因此,增量迭代的增量步迭代轮数与原始迭代的迭代轮数大体相同,α≈β(参见式(1)和(2)),但是由于数据量很小,因此增量迭代的增量步的每轮迭代代价要远小于原始迭代的每轮迭代代价,进而增量迭代的增量步执行时间远小于原始迭代时间;②对于增量迭代的合并步,由于迭代数据仅需要收集关联数据(ΔL/L)对其变换,迭代轮数小于原始迭代,γ<α(参见式(1)和(3)),因此增量迭代合并步迭代时间小于原始迭代时间;③对于全量迭代,由于ΔL-L的存在,全量迭代轮数和原始迭代轮数大致相同,但是由于全量数据略大于原始数据,全量迭代的每轮迭代代价略大于增量迭代的每轮迭代代价,因此全量迭代的迭代时间略大于原始迭代的迭代时间;此外还考虑一种特例,增量迭代的迭代变量初始值是原始迭代结果,当迭代算法对初始值敏感时,全量迭代性能会优于原始迭代性能.综上所述,增量迭代的迭代时间小于全量迭代的迭代时间.表1定性比较了3种迭代的迭代轮数、每轮执行代价和执行时间.增量迭代的增量步和全量迭代的迭代轮数相同,但前者是在小数据集上执行,而后者在大数据集上执行,数据量越大,每轮迭代代价就越大.全量数据由增量数据和原始数据两部分组成,当增量数据增加时,增量迭代的增量步每轮迭代代价和全量迭代每轮迭代代价都增加,因此相互抵消;当原始数据增加时,增量迭代的增量步每轮迭代代价不变,全量迭代每轮迭代代价增加,因此增量迭代的增量步优势明显,增量迭代的性能优势增大.Page7(2)迭代结果一致性证明我们利用定义4迭代计算的分解描述来证明增量迭代和全量迭代的结果一致性,证明思路如下:根据迭代的分解表示,由于该迭代变量的初始值是相同的,若证明两种方法迭代结果一致,只要证明任意一个迭代变量在两种方法的所有轮迭代中积累()的变换一致.我们可以证明:①全量迭代中某迭代变量的积累变换要大于该变量在增量迭代的原始步中的积累变换;②当增量迭代进入合并步,该变量的积累变换逐渐变大,最终会等于全量迭代中该变量的积累变换.由①和②可知,采用这两种方法迭代,同一迭代变量会收敛到同一状态.在证明过程中增量和全量迭代采用一致的序列{1,2,…,k,…,n}来表示每一轮迭代.不失一般性,设:①增量迭代和全量迭代同时开始;②增量迭代的原始步和增量步同时开始(实际原始步在增量数据到来时已经结束),且当原始步和增量步都收敛后开始合并步,先收敛的迭代变量则执行空轮;③增量迭代原始步收敛于k1轮;④增量迭代增量步收敛于k2轮;⑤增量迭代合并步开始于km+1轮,由于无法确定k1和k2的大小,因此令km=max(k1,k2);⑥k3轮是增量迭代合并步中任意一轮,以及对应的全量迭代中迭代轮,k3>km.k1>k2时迭代计算的示意图如图2所示,当k2>k1时同理.证明.若为代数运算,h函数对运算是分布的,则增量迭代的迭代结果等同与全量迭代的迭代结果.因为h(ab)=h(a)h(b)因为符合交换律、结合律和零律;又因为参照定义4和式(7),迭代变量ri的第k轮迭代可以表示为式(8).rki=h1所以某一迭代变量ri从第1轮迭代至k轮的值如式(9).r1i=∑r2i=∑r3i=∑=∑…rki=∑=H式(10)中xk表示第k轮任意一个迭代变量的下标.符号H表示函数的复合.第k轮的迭代中,任意一个迭代变量都是k轮积累变换的聚集.设:在原始数据L中含有m个迭代变量,全量数据L∪ΔL中含有n个迭代变量,则差集数据ΔL-L中含有n-m个迭代变量.k1,k2,k3轮的关系见图2,km=max(k1,k2).所以第k1轮,全量迭代下L中的任意迭代变量rp,式(11)成立.因为第k1轮,增量迭代原始步中L内与rp所对应的迭代变量rq,式(12)成立.又因为n>m,rp每一轮积累变换大于每一轮rq积累变换.所以r又因为L中与ΔL完全没有关联的迭代变量其变换始终为0,即h=0,所以r所以r同理,第k2轮,全量迭代下L中的任意迭代变量rp和增量迭代增量步下ΔL-L中与rp所对应的迭代变量rq,由于n>n-m,rp每一轮积累的变换大于每一轮rq积累的变换.所以r结论①,在增量迭代合并步开始之前,r所以第k3轮,全量迭代下L中的任意迭代变量rp,式(13)成立.Page8因为1至k3轮可以分解为1至km轮和km+1至k3轮,且迭代变量仍然为n个.所以式(13)可以变换为式(14)k3p=Hrj=1∑因为式(14)的km+1至k3轮(后项),迭代变量的rp积累变换又来自于又来自于L中m个迭代变量和ΔL中n-m个迭代变量.所以式(14)可以变换为式(15)k3rp=H式(15)中,第1行是前km轮迭代全量数据中迭代变量对rp的积累变换;第2行是km+1轮至k3轮迭代原始数据L中迭代变量对rp的积累变换;第3行是km+1轮至k3轮迭代增量数据ΔL中迭代变量对rp的积累变换.所以第k3轮,增量迭代下合并步中与rp所对应的迭代变量rq,若rq∈L,则式(16)成立.k3rq=H式(16)中,第1行是原始步下L中各迭代变量对rq的积累变换;第2行和第3行是合并步下L中各迭代变量对rq的积累变换,其中各迭代变量的积累变换又来自于L中m个迭代变量(方括弧中前项)和ΔL中n-m个迭代变量(方括弧中后项);第4行和第5行是合并步下ΔL中各迭代变量对rq的积累变换,其中各迭代变量的积累变换又来自于ΔL中n-m个迭代变量(方括弧中前项)和L中m个迭代变量(方括弧中后项).与式(15)对比,根据结论①,式(15)第1行小于式(16)的第1行;式(15)第2行等于式(16)第2行中方括弧中前项部分;式(15)第3行等于式(16)第3行中方括弧中前项部分;式(16)的第2和第3行比式(15)的第2和第3行均多出了方括弧中后项.因此,当k3足够大时,式(16)的值大于等于式(15)的值.结论②,增量迭代合并步下,rΔL-L,结论②同理可得.所以根据结论①和结论②,在合并步开始后,k3p和rr那么最终会有r终收敛到同一点.所以增量迭代的迭代结果等同于全量迭代的迭代结果.3.5差集算法根据3.4节分析,增量迭代对比全量迭代的性能优势在于增量迭代的增量步的每轮迭代代价小,而增量迭代的合并步迭代轮数小.此外,增量迭代需要求取增量数据和原始数据的差集,差集算法也会引入额外的时间开销.对于迭代数据结构较为简单的迭代算法而言,差集算法并不复杂.例如K-means算法,所有的数据均为记录的形式,记录是数据点的名称和其坐标所组成的序偶.而求取差集的过程则看作是求取在增量数据中距离当前所有中心点最小距离超过阈值的点的集合.但是对于关系较为复杂的算法而言,求取的差集和原始数据集应不存在公共的数据和关系,即无论是数据还是关系,差集与原始数据集是相互独立的.例如PageRank算法中,数据为网页,关系为网页间的连接关系,L,ΔL和ΔL-L如图3所示.图3中节点表示网页,边表示网页间的连接关系.当数据关系较为复杂时候,差集的求取将变得复杂,在本节给出一个包含二元关系的数据集的差Page9集算法.在算法1中,使用两个MapReduce作业完成差集运算.算法1.差集算法输入:〈α,β〉:数据项和数据项所组成的关系,以Key-输出:Reduce2输出结果:〈α,β〉Map1阶段:1.Initβ.Eandβ.Δ//初始化数据的E和Δ属性2.out.collect(α,β)Reduce1阶段:1.original=false,new=false;2.result=newList();3.Foreachβinβs//对于同一个α的所有β4.Ifβ.E5.original=true6.ElseIfβ.Δ//如果β是增量数据7.new=true8.result.add(β)9.EndIf10.Iforiginalandnew11.Return;12.EndIf13.EndFor14.Foreachβinresult//对于结果集中所有β15.β.R=true;16.out.collect(α,β);17.EndForMap2阶段:1.out.collect(β,α)//将α和β调换,输出给Reduce2Reduce2阶段:1.Reduce2=Reduce1//重复执行Reduce1算法1的核心思想是通过过滤数据项的方式,过滤掉数据间的关系.在Map1中按照〈key,value〉序列正常输出,在Reduce1的values中如果均出现了原始数据和增量数据标记,则表示该数据点重复出现在了两个数据集中,故将其过滤掉.而Map2将〈key,value〉序列反向输出,从而使得Reduce2过滤掉关联数据ΔL/L.3.6模型应用迭代算法均可满足定义4的分解描述,但若适用于本文提出的DELTA模型,则要求迭代函数f满足3.4节首段的描述;此外,根据3.4节迭代性能定性分析,当数据量越大,或增量数据对原始迭代结果的更新越少,增量迭代较全量迭代的性能优化效果越好.在前文形式化表达的基础上,本节举例描述常用的迭代算法PageRank、K-means和DescendantQuery的DELTA模型实现.(1)PageRank算法PageRank是Google用来标识网页等级(重要性)的一种方法.设网络的链接关系存于集合中,该集合每个元素是二元组〈url_source,url_dest〉,表示在URL为url_source的页面中,有一个指向url_dest页面的超链接.初始化的迭代变量集为R0,每个迭代变量u为二元组〈url,rank〉,表示每个页面的URL和其PageRank值.若原始数据L中共有n个页面,则初始化时R0内共有n条数据.PageRank的迭代函数为fp如式(17)所示.在式(17)中u指任意url,i,j均为页面下标,其中B(ui)为指向ui链接的页面的集合,|B(ui)|为集合B(ui)的大小,R(uj)为uj当前的PageRank值,N为页面总数,q为阻尼常数,取值为0.85.fp的终止条件为Ri不发生变化,或者Ri和Ri+1的差值小于某个阈值,算法收敛,通常阈值可以取得0.2.PageRank算法满足DELTA模型:当uj有指向ui的链接时h函数为式(18),当uj没有ui的链时h为0;运算为加法运算,表示PageRank值的增长,满足代数运算要求;h函数在“+”运算上是分布的,及每个网页对目标网页PageRank值的贡献之和等同于网页集对目标网页的PageRank值的贡献;采用算法1可与求取ΔL-L.按式(18),R和ΔR中分别包含了L以及ΔL-L内所有网页的PageRank值,显然R∩ΔR=,因为在L和ΔL-L中并没有公共网页存在.若简单的将R和ΔR合并,则丢失了关联数据集ΔL/L对PageRank值的贡献,这是因为在背景数据ΔL有可能包含指向L中页面的超链接,但是这些链接在ΔL-L中都被过滤掉了.R和ΔR分别可以看作背景数据L和ΔL-L的局部极值,因此增量迭代的合并步可以看作是求全局极值的过程,所以合并步会很快收敛.(2)K-means算法K-means算法是典型的基于距离的聚类算法,采用距离作为相似性的评价指标,即认为两个对象Page10的距离越近,其相似度就越大.设所有数据经过格式化并转化为坐标的形式,存于集合P中,P内任意元素p是元组〈id,x,y〉,id为数据的唯一标识,x和y为数据经过转换后的坐标.初始化的迭代变量为k个簇S0集有一个中心点c.通过迭代后求得最终的迭代结果{S1,SK-means的迭代函数fk如式(19)所示.fk(Si,P)={p|p∈P,Sj∈R,dis(p,ci)dis(p,cj)}在式(19)中,P为所有数据点的集合,p为某数据点,R是当前迭代结果,包含了k个簇,第i个簇Si的中心点为ci,dis(p,ci)为p和ci间的距离.fk的终止条件为Si不发生变化,算法收敛.K-means算法满足DELTA模型:对于某轮迭i发生移动,对应的h为0,当Ski重新计算;运算为集合并运算,表示Sk代,原属于簇Sk-1据点,h函数如式(20)所示,若簇Sk-1向簇Sk据Sk充,满足代数运算要求;h函数在“∪”运算上是分布的,及每k-1轮每个簇移动到某簇的数据点等同于所有数据点集合移动到该簇的数据点;采用算法1可以求取ΔL-L.i(Sk-1hj{p|p∈Sk-1j)=∑p∈Scki=K-means算法的增量迭代实现中:原始步在原始数据集L中初始化k个中心点并获得k个簇;定义差集为在增量数据中距离这k个簇的中心点最小距离均大于某一阈值的数据点;增量步在差集数据ΔL-L中初始化k个中心点并获得k个簇(kk);合并步之前将L中k个中心点和差集数据ΔL-L中k个中心点视为数据点,执行一次微缩的K-means算法并获取k个新的中心点;合并步将采用这k个新的中心点重新迭代.R和ΔR分别可以看作背景数据L和ΔL-L的预先聚类,因此增量迭代的合并步可以看作是初始点良好的聚类过程,所以合并步会很快收敛.(3)DescendantQuery算法DescendantQuery算法用于计算社交网络中与某人相识的所有人的列表,用以分析用户的交友信息等情况.设社交网络信息存于集合F中,F即为迭代数据,F中每个元素为序偶〈px,py〉,px和py均为人名,表示名字为px的人与名字为py的人是朋友关系.迭代变量为集合R,初始R仅包含一条数据,即查询对象.通过迭代计算找出与查询对象相关的所有人.DescendantQuery的迭代函数为fd如式(21)所示.fd(R)=R∪{py|〈px,py〉∈F,px∈R}(21)在式(21)中R是唯一的迭代变量,fd的终止条件为R不发生变化.DescendantQuery算法满足DELTA模型:当R和对R自身的h函数为式(22);运算为集合并运算,表示R的扩充,满足代数运算要求;h函数在“∪”运算上是分布的,h(R)=h(R)h()=h(R).h(Rk-1)={py|〈px,py〉∈F,px∈Rk-1}(22)DescendantQuery算法的特点导致其增量迭代和全量迭代相同,但前者有略微的优势.全量迭代会以原始迭代结果作为初始迭代变量,在全量数据上迭代.增量迭代实现中:原始步在原始数据集L查找与当前查询对象有关系的所有人,最终迭代结果集为R;定义差集为在增量数据中与原始对象中所有人均没有关系的人,根据算法(1)可以求得ΔL-L,根据该差集定义可以知道ΔR=,无须增量步迭代;合并步以R为初始迭代变量,只需在原始数据集和关联数据上迭代,最终当收敛后得到新的迭代结果.增量迭代合并步数据量少于全量迭代数据量,因此增量迭代合并步每轮迭代代价小于全量迭代每轮迭代代价,又因为两者迭代轮数相同,因此,DescendantQuery算法增量迭代性能略优于全量迭代.4增量迭代计算框架我们对HaLoop框架进行修改和扩展,使其支持DELTA模型,称为ΔHaLoop框架.本小节将简述ΔHaLoop框架的系统架构,介绍各个部分的用途和相应的改进.我们选择Hadoop-0.20.2版本实现ΔHaLoop,在该版本仅包含3个模块,即MapReduce、HDFS和Common,代码结构较为简单,且易于扩展.ΔHaLoop系统架构如图4所示.图3中的软件模块可以分为4类:①Hadoop模块,这些模块是与HDFS相关的文件系统模块以及任务队列模块;②HaLoop模块,这些模块是HaLoop对原始HadoopPage11图4ΔHaLoop系统架构图的修改或者扩展部分,主要实现了迭代计算、缓存、任务调度等相关功能;③本文对HaLoop的修改模块,这些模块根据DELTA模型和HaLoop现存缺陷,对HaLoop模块进行了修改,主要包括LoopControl(迭代控制)和TaskTracker模块;④ΔHaLoop新增模块,用于支持DELTA模型.ΔHaLoop各个模块的简要描述如下:(1)FileSystem.沿用Hadoop的文件系统,支持计算框架对分布式文件系统以及每个节点的本地文件系统的读写操作.(2)Cache.HaLoop支持迭代计算中的缓存策略,并设计了3种缓存,分别为Map输入缓存、Reduce输入缓存、Reduce输出缓存.在DELTA模型中,缓存信息不仅有益于原始迭代,也有益于增量迭代的差集求取和结果合并过程,且在下一次增量数据到来时,上一次迭代的缓存仍有效,因此ΔHaLoop新增了CacheUpdater模块用于支持在增量迭代中更新缓存,尽量延长缓存的生命周期.(3)TaskScheduler.沿用HaLoop系统任务调度功能,任务调度支持迭代缓存功能.为了使用上一轮迭代的缓存数据,任务调度器将当前迭代轮中任务数据调度到上一轮迭代计算所在的节点,以便读取上一轮迭代所缓存的数据,从而解决静态数据的冗余传输问题和重复计算问题.(4)TaskTracker.TaskTracker监督并执行某个任务(MapTask或ReduceTask),同时与JobTracker通信,时刻汇报任务的执行情况,并获取新任务.在HaLoop中,TaskTracker根据任务配置创建缓存数据和索引,同时维护缓存数据.在ΔHaLoop中对TaskTracker进一步进行了完善,加强了TaskTracker缓存数据的能力,使得缓存数据的管理粒度更细致,生命周期更长,适用于DELTA模型的要求.(5)LoopControl.提供迭代控制功能,使得整个迭代算法可以重复地执行直至收敛.在ΔHaLoop系统中对HaLoop原有的LoopControl功能进行扩展,支持“针对于每轮迭代输出数据特点”的迭代收敛条件.(6)IncrementalIterativeControl.提供增量迭代支持,包括基本的编程接口、执行流程、差集算法、增量迭代流程控制等.其中:①增量输入模块用以区分增量数据,完成增量输入和原始数据差集的计算过程.同时增量输入模块还对当前节点所包含的缓存信息进行扫描,如果可用缓存数据,则使用缓存数据进行求差集操作;②增量控制模块是ΔHaLoop为了支持增量迭代所引入的独立模块,模块又可以分为MapReduce作业的创建和增量迭代的流程控制两个子模块.前者完成增量迭代的参数初始化工作,后者则按第3节描述的模型和方法执行迭代算法.理论上,本文所提出的DELTA模型适用于其他大数据下的计算框架,如Spark、Naiad等.由于本研究没有逐一在这些框架中实现DELTA模型,因此本节以Spark为例给出实现方法的分析.首先,我们将DELTA模型的实现划分为3个不同的任务,包括计算差集(数据筛选)、增量迭代(在差集上运行Page12迭代算法)和迭代合并(在全量数据上运行迭代算法).计算差集的本质为数据筛选的过程,主要用于删除增量数据和原始数据间的关系,本文所提出的差集算法基于数据连接技术,连接算法也是计算框架中常见算法.如Spark可以通过Map和Broadcast的组合实现Map端连接算法,也可以通过Join算子实现Reduce端连接算法.增量迭代和迭代合并实质上都是迭代算法的实例.现存迭代框架均可以支持迭代算法,只是性能有所差别.如MapReduce可以通过任务的组合,将迭代算法的迭代步骤拆分成不同的Map任务和Reduce任务,从而执行迭代算法;Spark中可以通过使用RDD(ResilientDistributedDataset)的不断变化来实现迭代算法.增量迭代和迭代合并区别在于以下两点:(1)增量迭代的数据来源于计算差集步骤所得到的差集,迭代合并的数据为全量数据;(2)增量迭代的初始点为随机值或符合迭代算法要求初始值,迭代合并的初始点来源于原始的迭代结果和增量迭代的迭代结果.能够支持迭代计算的框架均可以灵活的控制迭代数据范围和迭代初始点的选择.综上所述,DELTA模型适用于常见的分布式计算框架,但仍然需要对框架的部分模块加以扩展.表2分析了常见的分布式计算框架实现DELTA而需要的扩展.表2常见分布式计算框架实现DELTA模型的分析框架名称YarnSparkPrIterTwister重新定义主节点的流程控制和任务调度,将多个MapReduce任务视为一个整体,实现增量迭代流程控制功能.增加增量迭代流程控制模块,以控制计算差集、增量迭代和迭代合并任务中的执行顺序切换.5实验分析本节对ΔHaLoop框架进行测试和评价,以证明本文提出的DELTA模型的正确性.本节首先描述了实验的测试环境以及测试用例.随后验证了PageRank和K-means两种算法的DELTA模型的正确性和性能优势,并加以分析.5.1实验环境我们在真实的集群环境中对ΔHaLoop进行测试,实验集群由同构的13台PC机所组成,具体的实验环境如表3所示.项集群操作系统CentOS6.3,Linux2.6.32节点平台版本基于HaLoop-1.0JVM版本Java7-updated-u9网络带宽1000Mbps开发IDEEclipse4.2由于ΔHaLoop基于HaLoop实现,而HaLoop是基于Hadoop-0.20.2版本实现.所以在ΔHaLoop运行过程中,其运行参数与Hadoop-0.20.2版本是一致的.表4列出部分参数.HDFSblocksizeHadoopinternalmemory4GBHadoop运行过程中可用内存NumberofmapslotNumberofreduceslot2单一节点Reduce的任务最大数量Heartbeatinterval5.2测试用例为简化描述,本节使用Si(i∈{1,2,3})表示数据集的大小,Uj(j∈{1,2,3,4})表示增量数据对原始迭代结果的更新度,则Si和Uj可以组合成多组实验数据.我们用T1(SiUj)表示原始迭代时间,T2(SiUj)表示增量迭代时间,T3(SiUj)表示全量迭代时间.为了探究增量迭代的性能,将使用[T3(SiUj)-T2(SiUj)]/T3(SiUj)作为增量迭代优化程度的度量,记作函数ω(SiUj).PageRank测试数据集采用文献[17]的数据集.数据集中节点的入度服从对数正态分布(μ=-0.5,σ=2.3),其中参数来自于真实图数据集①.设增量数据对原始数据迭代结果的更新程度为U.在增量数据生成过程中,增量数据中网页链接原始数据中网页的概率为U,链接增量数据中网页的概率为1-U.PageRank测试数据的相关信息如表5所示.①http://snap.stanford.edu/dataPage13名称S1U3S2U3S3U3S3U1S3U2S3U4K-means数据集采用DBPedia数据集①.从DBPedia数据集中抽取其中经度和维度字段组成了K-means基础数据集(20MB),并通过随机抽取的方式,将其分解成K-means种子数据集(18MB)和K-means增量数据集(2MB),以上两个数据分别用于生成K-means测试中的原始数据和增量数据.为适应大数据,在数据生成过程中,遵循文献[29]中数据模拟方法,在基础数据集点周围生成多倍的额外数据点来扩展数据集,其扩展倍数根据K-means测试用例选取.设增量数据对原始数据迭代结果的更新程度为U.由于K-means将数据点分为k簇,新增数据若能够归入到原始k簇,则更新度小,新增数据全部无法归入到原始k簇而需要对原始簇改变,则更新度大.数据生成时,设原始数据的值域为[α,β],在增量数据生成过程中,增量数据中的数据点值域在[α,β]的概率为U,在[α+102,β+102]概率为1-U.K-means测试数据的相关信息如表6所示.名称S1U1S2U1S3U1S2U2S2U3S2U4需要指出的是,当U=0时,理论上,增量数据不会对原始聚类产生影响时,可以认为增量数据自成k簇,由于全量迭代的初始点是原始数据的k簇,因此理论上在全量迭代中这k个簇不需要变换,只需要找出增量部分的k簇即可.但实际上由于K-means算法始终要保持聚类个数为k,即使U=0时全量迭代也需要将k+k个簇聚成k个簇.因此,尽管U=0,增量数据对原始迭代结果也会产生更新.在本实验用例中,我们取k=12,k=2.此外,在K-means算法执行过程中,本文使用“迭代变量变化小于某阈值”这一条件作为迭代终止条件,且阈值设为极小的10-6,确保迭代结果的精确性.并且为了对比各用例的迭代结果,各用例初始化的k个中心点是相同的,确保迭代结果能够合理地进行比较.5.3PageRank算法根据3.4节的理论证明,无论是通过增量迭代还是全量迭代,最终的结果数据是一致的.由于PageRank迭代算法的运行结果本身不具有唯一性,因此即使同样数据下多次计算PageRank,其计算结果也会存在微小的差异.令每个网页误差为每次迭代PageRank值的差距,即|rank-rank|/rank,然后以所有网页的误差均值作为误差评价标准.分析实验结果知,多次全量迭代结果的平均误差在[0.101,0.201]区间内,而增量迭代和全量迭代之间的误差在[0.117,0.209]区间内.为进一步证明迭代结果的一致性,我们参考文献[30],计算增量迭代结果和全量迭代结果的均方根误差.均方根误差是常用的统计分析方法,用于分析预测值和真实值间的差距,其值越接近于0,差异越小,其计算方法如式(23)所示,S和T分别表示增量迭代结果和全量迭代结果,si和ti分别表示增量迭代结果和全量迭代结果中编号为i的页面的PageRank值,n为页面数量.计算得增量迭代和全量迭代结果的均方根误差平均值为4.08×10-10,该值小于文献[30]的实验结果1.24×10-9.基于误差对比和均方根误差分析,我们可以认为,对于PageRank算法增量迭代和全量迭代的结果是一致的.我们首先验证了本文提出的基于MapReduce的差集算法,用于求取原始数据和增量数据的差集.表7给出了3组实验数据的增量数据集的大小,所求的差集大小以及差集占增量数据的比率.S3U1S3U2S3U4为了方便表述,差集所占增量数据集的比率使用函数p进行表述.根据5.2节的数据生成算法,则理论上p(S3U1)=1,p(S3U2)=0.6,p(S3U4)=0.2.在表5中的差集比例与更新度定义一致.同时按大数定律,随着数据集的增大,p(SiUj)的值也越①http://dbpedia.orgPage14接近理论值.实际值和理论值的极小差异证明了差集算法的正确性.我们测试了相同更新度,不同数据量下的3种迭代计算的性能.选用数据集为S1U3、S2U3和S3U3,实验结果如图5所示.图5PageRank在不同数据量的数据集下实验结果由图5可知,Ti(SxU3)<Ti(SyU3)(x,y,i∈{1,2,3}且x<y),即同种迭代方法的迭代时间随迭代数据集大小单调递增.文献[11]指出大部分数据集上的PageRank算法都会在10轮内收敛,但每轮的迭代代价不同,数据量不会影响迭代轮数,但会影响每轮迭代时间.此外,T2(SiU3)<T1(SiU3)<T3(SiU3),增量迭代的性能优于原始迭代,而前两者均优于全量迭代.T2(SiU3)<T3(SiU3)是我们研究的重点,增量迭代对比全量迭代的性能优势在于:增量迭代增量步的每轮迭代代价小于全量迭代的每轮迭代代价,而增量迭代的合并步迭代轮数小于全量迭代.对于前者,全量迭代和增量迭代增量步的迭代轮数相同,当原始数据量增加时,全量迭代每轮迭代代价增加,而因为增量数据未发生变化,增量迭代的增量步每轮迭代代价不变,性能优化效果增加.对于后者,当数据量增加而数据特征不变时,增量迭代和全量迭代的合并步的迭代轮数差距不变,即使每轮迭代代价增加,性能优化效果不变.由于|ΔL||L|,因此ΔL-L是一个更小的数据,增量迭代增量步的代价在整个增量迭代代价中所占比例很小,因此,增量步的优化效果很小.综上所述,在数据特征不变的情况下增加数据量,增量迭代的优化效果会有较小的提升.图5中优化比例折线清晰地展示了上述特征.ω(S1U3)<ω(S2U3)<ω(S3U3),折线斜率很小,略有上升.随后,我们测试了相同数据量,不同更新度下的3种迭代计算的性能.选用数据集为S3U1至S3U4,实验结果如图6所示.图6PageRank在不同更新度的数据集下实验结果由图6可以看出,对于全量迭代,无论更新度如何,T3(S3Ui)(i∈{1,2,3,4})均相差不大;对于增量迭代,除了T2(S3U1)很小,其他均相差不大;对于性能优化比例,ω(S3U1)>ω(S3U2)>ω(S3U3)>ω(S3U4),但ω(S3U1)优势明显,其他数据集下增量迭代的优化效果随更新度增大而略微减小,折线下降缓慢.增量迭代对比全量迭代的性能优势在于增量迭代的合并步迭代轮数小于全量迭代.S3U1的更新度为零,因此增量迭代的合并步仅执行了1轮,而全量迭代执行了7轮,因此增量迭代明显优于原始迭代;但由于|ΔL||L|,无论更新度为多少,关联数据集都很小,不足以影响增量迭代合并步的轮数,因此,S3U2,S3U3和S3U4下增量迭代的合并步迭代轮数均为4轮,因此从合并步迭代轮数角度优化比例不变.ω(S3U2)>ω(S3U3)>ω(S3U4)的原因是:当关联数据集增加,增量迭代的合并步的每一轮参与计算的数据增加,因此每轮迭代代价增加,增量迭代执行时间增加,因此优化比例减少.综上所述,通过多组数据实验,我们可以认为PageRank算法增量迭代较全量迭代的性能优化比例达到15%.5.4犓-means算法首先,我们验证K-means算法增量迭代结果和全量迭代结果的一致性.实验证明,两者的迭代初始点相同,迭代后的k个簇内包含的数据也相同.进一步地,我们判断增量迭代后k个簇的中心点与全量迭代k个簇的中心点是否重合.我们对k个中心点进行比较,并计算对应簇的中心点间的欧氏距离.经过分析,全量迭代聚类结果和增量迭代聚类结果中心点距离均值为2.135×10-7,该值小于迭代终止阈值10-6,即误差的控制范围.因此,可以认Page15为K-means算法增量迭代和全量迭代的结果是一致的.我们测试了相同更新度,不同数据量下的3种迭代计算的性能.选用数据集为S1U1、S2U1和S3U1,实验结果如图7所示.图7K-means在不同数据量的数据集下实验结果可知对于相同更新度且不同数据量的数据集,K-means算法(图7)和PageRank算法(图5)在3种迭代方法下的迭代时间规律类似:同种迭代方法的迭代时间随迭代数据集大小单调递增;增量迭代的性能优于全量迭代;在数据特征不变的情况下数据量增加,增量迭代的优化效果有所提升.但K-means算法全量迭代执行时间平均为原始迭代的35%.增量迭代较全量迭代的优化效果明显提高,在大数据量下性能优化达22%,且当原始数据增加时,增量迭代性能有所提升.这是因为K-means算法迭代轮数对初始点的选择非常敏感,良好的初始点选择可以极大地减少迭代轮数:(1)原始迭代的初始中心点是随机选取,因此迭代轮数很大;(2)对于增量迭代的增量步,采用较少的随机初始点进行迭代,且差集数据很小,因此迭代代价较小;对于增量迭代的合并步,由于初始点来自于原始数据的k个中心点和差集数据的k个中心点(求k+k个点的k个中心点),因此中心点选择良好,迭代轮数很小;(3)对于全量数据,采用原始数据k个中心点作为初始点,初始点选择较好,迭代轮数少于原始迭代轮数;(4)当数据量增加时,增量迭代合并步和全量迭代的迭代轮数差距更加明显,优化效果越好;(5)增量迭代增量步每轮迭代代价的优势对性能的影响不明显,而迭代轮数起决定性影响,迭代轮数则与初始点的选择相关.随后,我们测试了相同数据量,不同更新度下的3种迭代计算的性能.选用数据集为S2U1至S2U4,实验结果如图8所示.图8K-means在不同更新度的数据集下实验结果图8的规律和图6基本一致:ω(S2U1)>ω(S2U2)>ω(S2U3)>ω(S2U4),但ω(S2U1)优势明显,其他数据集下增量迭代的优化效果随更新度增大而减小.首先,我们分析S2U1(U=0)的情况.由于全量迭代的初始点是原始迭代结果,理论上其迭代次数也受初始点是否良好的影响.当U=0时是增量迭代最佳情况,却是全量迭代的最坏情况.前者会在增量步将增量数据(差集数据)聚成簇,并在合并步调整原始聚类结果,减少簇个数;后者则要将原始聚类结果不断变化以适应独立成簇的增量数据.后者的迭代轮数大于前者的迭代轮数,因此,增量迭代性能优化效果很好.其次,我们分析S2U4(U=1),此时因为差集数据为空,增量迭代已经退化为全量迭代,两者的性能应该相差无几,图中优化4.8%的结果具有偶然性.综上所述,通过多组数据实验,我们可以认为K-means算法增量迭代较全量迭代的性能优化比例平均为22%.6结论和进一步工作本文提出了一种基于新增数据的增量迭代计算模型,又称DELTA(DeltadatabasedincrEmentaLiTerAtivecomputing)模型,利用原始迭代结果和增量数据求解新的迭代结果,避免在数据全集上进行全量迭代.本文将增量迭代分为3个步骤,即“原始步(已完成)”、“增量步”和“合并步”.本文定义了DELTA模型、描述了其计算步骤,证明了DELTA模型的性能优势和结果正确性,同时列举了PageRank、K-means和DescendantQuery算法在DELTA模型下的例子.本文还描述了DELTA框架的实现,重点阐述了迭代框架ΔHaLoop中对HaLoop所作出Page16的改进.本文对DELTA模型进行了评价,分别从功能正确性和性能优势两个角度进行阐述,最终得出如下结论:DELTA模型及其实现能够很好的适应大数据的迭代分析,当数据发生变化后,DELTA模型能够利用已知迭代结果和增量数据快速获得新的迭代结果,迭代结果准确.增量迭代明显优于全量迭代性能.进一步工作包括研究通过更多的迭代算法来验证DELTA模型,以及讨论适用于增量迭代的迭代变量初始化算法.此外,目前的增量迭代中还包括一些数据预处理操作,如差集算法以及作业调度时间,我们拟通过提高并行性等方式减少这些操作的时间,探讨是否存在“增量迭代和原始迭代的执行时间之和能够接近全量迭代的执行时间”的可能性.
