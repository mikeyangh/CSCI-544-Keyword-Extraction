Page1一种新颖的基于颜色信息的粒子滤波器跟踪算法李培华(黑龙江大学计算机科学与技术学院哈尔滨150080)摘要传统的基于直方图的粒子滤波器算法常常需要在准确表达颜色分布和计算效率之间做出妥协,从而影响跟踪算法的性能甚至导致跟踪算法失败.针对这一问题,文中提出一种新颖的基于颜色信息的粒子滤波器跟踪算法.该算法采用自适应剖分颜色空间的概率模型,能够用较少的子空间准确地表达目标的颜色分布.文中进一步提出一种推广的积分图像,通过在该积分图像上进行数组索引操作得到每一个子空间的像素数目、均值向量和协方差矩阵,从而能够快速地计算出颜色模型.然而在CPU上计算积分图像十分耗时,为此文中提出一种基于GPU的并行算法快速计算积分图像.该并行算法在显卡的GPU上创建3个线程网格,分别顺序执行3个Kernel函数,依次完成创建原始积分图像以及对它的行和列执行前缀求和算法的任务.同传统的基于直方图的粒子滤波器算法相比,新算法每帧平均跟踪时间显著减少,同时跟踪准确性和鲁棒性都有较大提高.关键词目标跟踪;粒子滤波器;颜色模型;积分图像;并行算法1引言基于颜色的粒子滤波器(particlefilter)跟踪近年来得到了越来越多的研究者的关注,在视频监控、智能人机交互、医学图像处理、视频编码以及智能机器人等许多研究领域得到了广泛的应用.这种持续增长的研究兴趣是因为在复杂的环境中目标跟踪一般是非线性非高斯问题,而粒子滤波器能够提供一种统一的理论框架解决这类问题;另一方面是因为颜色信息是一种最常见而且重要的信息,它具有平移、旋转不变性和对遮挡及姿态变化不敏感的优点.粒子滤波器跟踪的基本思想是将目标跟踪问题抽象为系统的状态估计问题,其中系统状态的后验概率密度迭代地通过一组具有权重的离散采样(称为粒子)来近似[1].由于粒子滤波器的本质是蒙特卡洛(MonteCarlo)模拟,为了准确地表达后验概率密度需要几百甚至上千个粒子.在跟踪过程的每一帧图像中,需要对每一个粒子的状态进行观测,因此粒子滤波器跟踪的计算代价通常很大[2].为了使算法能够达到实时,研究者们一般采用粗略地表达目标颜色信息的方法来减少每个粒子的计算代价,同时采用尽可能少的粒子数.Nummiaro等[3]在RGB颜色空间中用8×8×8的加权直方图对目标进行观测,采用粒子数为200的粒子滤波器进行目标跟踪.Perez等[4]在HSV颜色空间中用H、S通道的均匀10×10联合直方图加上V通道的均匀10bin直方图建模颜色特征,用100个粒子进行跟踪.自适应剖分颜色空间的模型一般来说比均匀剖分颜色空间的模型能够更准确地刻画目标的颜色分布.Jacquot等[5]提出了一种自适应的均匀直方图模型,他们利用Akaike模型选择理论自动地确定直方图的区间个数,并结合粒子滤波器进行跟踪.他们的实验表明自适应直方图模型比传统的均匀剖分整个颜色空间的直方图模型能够得到更好的跟踪结果.Town[6]使用K-均值聚类算法分析目标的颜色分布,在聚类分析的基础上自动地确定目标直方图区间以及区间个数,并将该颜色模型作为粒子滤波器的观测模型进行目标跟踪.Viola和Jones[7]提出了一种积分图像的概念,利用积分图像仅仅使用数组索引和加法运算能够快速计算出图像中任意矩形区域的均值和方差.在这一思想的启发下,Yang等[8]选取多个矩形作为特征,利用积分图像分别计算这些矩形区域中每一个颜色通道中的均值来表达目标的颜色信息,其中特征的相似性用欧式距离来度量.文献[9]同样选取一组矩形特征表达目标的表观模型,使用费舍尔分析在线地选择具有最大分辨能力的前景和背景特征,在粒子滤波器框架下进行跟踪.在粒子滤波器跟踪算法中,从图像中得到目标的观测信息,即观测概率密度计算,是最耗时的过程,是粒子滤波器能否实时实现的关键[2].因此在准确表达目标的颜色分布和快速算法之间需要做出妥协:如果要更准确地表达目标的颜色分布,例如在传统直方图中采用较多的颜色区间数,那么对每个粒子计算观测概率所需的时间将会大大增加,从而影响算法的实时性;反之,如果粗略地表达目标的颜色分布,算法的跟踪速度会提高,然而由于无法准确地刻画目标的颜色密度,很容易导致跟踪误差增大甚至跟踪失败.本文提出了一种新颖的算法来解决这一问题.我们采用一种自适应剖分颜色空间的模型,该模型能更准确地表达目标的颜色分布.在Viola和Jones的积分图像的基础上,我们提出了一种推广的积分图像,利用该积分图像通过简单的数组索引能够快速地计算颜色模型.在CPU上构造积分图像是一个十分耗时的过程,为此我们提出了一种基于NVIDIAG80GPU的并行算法,该算法能够快速地将积分图像计算出来.这样我们就得到了一种新颖的基于颜色信息的粒子滤波器算法,该算法在跟踪时间和跟踪性能上都要优于传统的基于直方图的算法.2基于颜色的粒子滤波器算法2.1自适应颜色模型本文使用文献[10]提出的颜色模型,该模型在聚类分析的基础上自适应地划分直方图区间,能够使用数量很少的区间准确地表达目标的颜色概率密度.下面对这一模型进行简要介绍.首先应用Comaniciu等提出的算法[11]对目标的颜色分布进行聚类分析,该算法能够自动地确定聚类数d.在聚类分析的基础上,根据如下的方法对目标的颜色空间进行剖分.令狕-Cu(u=1,2,…,d)包含的像素狕u的均值向量和协方差矩阵.将矩阵犛u进行分解犛u=犞uΣu犞Tu,其中Σu是按降序排列的犛u的特征值λu,i(i=1,2,3)组成的对角矩阵,犞u是相应的归一化的正交向量组成的矩Page3阵.对颜色空间进行标准正交变换这样狑u的不同分量wu,i彼此正交,其标准差是λu,槡i.因此在变换空间中聚类Cu可以用一个中心在坐标原点3条边分别平行于3个坐标轴的三维矩形来表示,该三维矩形的边长分别是4λu,槡i,i=1,2,3.根据等式(1)进行如下的反变换能够在原来的颜色空间中确定表征聚类Cu的三维矩形.通过这种自适应剖分,整个颜色空间按照目标颜色分布被分成了d个颜色子空间,没有颜色分布的子空间将不予考虑.每一个子空间对应一个颜色聚类,相应地对应直方图的一个区间.对于每一个这样的直方图区间,我们的思想是不但考虑落入子空间的像素的个数,而且进一步用高斯分布建模每一个子空间的颜色分布.给定由N个像素组成的目标的参考图像犇(x,y),目标的模型表达为狆=[p1,…,pu,…,pd]T,pu=buGμu,犚()u其中,bu=nu/N,nu是落入第u个颜色子空间(直方图区间)的像素的数目,G(μu,犚u)表示均值向量为μu、协方差矩阵为犚u的高斯分布.注意到式(3)与文献[10]有所不同:由于我们不需要MeanShift移动,同时为了能够快速计算nu,我们未考虑每个像素的加权距离.考虑一个由N个像素组成的候选图像区域的颜色分布狆′=[p1,…,pd]T,其中pu=buG(μ′u,犚′u).两个分量分布pu和pu之间的相似性根据Bhatta-charrya距离来度量ρ(pu,pu)=2nunu犚u1exp-1因此狆和狆′之间的相似性定义如下2.2构造推广的积分图像快速计算颜色模型基于Viola-Jones的积分图像[7],我们在文献[12]中提出了“积分直方图图像”的概念,能够快速计算图像中任意矩形区域的直方图.注意到Porikli等提出了类似的方法并分析了算法的计算复杂性[13].将这一思想进一步推广,我们可以构造相应的积分图像,基于这些积分图像能够快速计算图像中任意矩形区域的每一个聚类的均值向量和协方差矩阵,因而能够快速计算颜色模型(3).给定原始的三通道彩色图像犇(x,y)=(Di(x,y),i=1,2,3),其中i是通道索引.通过一次扫描原始图像,我们能够构造出积分图像Ibu(x,y),Iμu,i(x,y)和Iσu,i,j(x,y),u=1,2,…,d,i=1,2,3,ji,用于计算每个子空间的像素数目、均值向量和协方差矩阵.考察积分图像Ibu(x,y),该积分图像在位置(x,y)的值等于原图像中(x,y)左上的子图像中落入到第u个直方图区间的像素的个数,即其中δu(x,y)=1,如果犇(x,y)属于第u个直方图区间;否则δu(x,y)=0.令Ibu(x,0)=0,Ibu(0,y)=0,通过下列方程可以构造出积分直方图图像Ibu(x,y)Ibu(x,y)=Ibu(x-1,y)+Ibu(x,y),Ibu(x,y)=Ibu(x,y-1)+δu(x,y)(7)令图像中某一矩形区域的左上角的坐标是x,()y,长和宽分别为w和h,该矩形区域的直方图可以通过4d次数组索引和3d次加法运算计算出来:nu=Ibu(x+w,y+h)-Ibu(x+w,y)-类似地,我们可以通过定义如下的积分图像计算均值向量和协方差矩阵Iμu,i(x,y)=∑xx,yyIσu,i,j(x,y)=∑xx,yy通过类似于式(7)的方程,每个直方图区间的均值向量和协方差矩阵的分量可以通过数组索引快速计算出来:μu,i=(Iμu,i(x+w,y+h)-Iμu,i(x+w,y)-σu,i,j=(Iσu,i,j(x+w,y+h)-Iσu,i,j(x+w,y))-其中u=1,2,…,d,i=1,2,3,ji.因此我们得到第u个直方图区间的均值向量和协方差矩阵如下μu=Page4当积分图像Ibu(x,y),Iμu,i(x,y)和Iσu,i,j(x,y)计算完之后,我们可以通过式(8)和式(10)将颜色模型(3)快速计算出来.表1给出了对于256×256、256×128和128×128的图像用CPU计算积分图像所用的时间,其中聚类数d分别是4和8.由表中可见在CPU上计算积分图像是一个十分耗时的过程,会影响跟踪任务的实时性,对此我们提出了基于NVIDIAG80GPU的并行算法计算积分图像.2.3基于GPU的并行算法快速计算积分图像NVIDIA公司推出的G80系列GPU的硬件体系结构和软件架构(CUDA)与以前的系列相比发生了根本的变化(http://www.nvidia.com/object/cuda_home.html),是真正意义上的桌面并行计算设备.G80GPU是由一组多处理器组成的,每个多处理器具有单指令、多数据体系结构(SIMD).从软件层面上来说,G80GPU能够并发执行数量很大的多个线程,这些线程在不同的数据上执行相同的被称为“Kernel”的函数.执行同一Kernel函数的线程按照线程网格的方式组织:线程网格由连续编号的线程块组成,而每个线程块又包含连续编号的一系列线程.同一线程块中的线程可以访问16K的片上共享高速缓存,每32个线程组成一个Warp,每half-Warp的16个线程在物理上同时得到执行.我们的积分图像计算基于并行处理算法中经典的前缀求和问题(prefixsum)[14],即给定一组有序元素[a0,a1,…,am-1],按顺序计算这些元素的部分和[0,(a0+a1),…,(a0+a1+…+am-1)].这一算法构造一个log2m层的平衡树,包括从根节点向叶节点的向上扫描过程和相反的向下扫描过程.在向上扫描阶段,将每一层两个相邻叶节点相加并将值存在后一个叶节点中;而在第2阶段,在每一层将两个相邻节点值互换,然后将二者的和存在后一个叶节点中.这一算法共需要m/2个线程,计算复杂性是O(n).值得注意的是,G80的片上高速共享缓存组成16个内存池(memorybank),两个相邻的32-bits字被分配到两个相邻的内存池中.因此将待处理的数据载入共享内存后,每16个字应填充一个冗余字.否则,同一half-warp的线程会访问同一内存池,造成共享内存访问冲突从而使并发线程串行化,从而大大地降低运行效率[14].我们提出的积分图像算法首先在CPU上完成数据的预处理,即通过直方图的Lookup表得到新的四通道图像犇(x,y)=[u,D1(x,y),D2(x,y),D3(x,y)]T,其中u表示该像素属于第u个子空间,并将数据从CPU内存拷贝到GPU的全局内存中.在GPU上的算法创建3个线程网格,分别执行3个Kernel函数.其中第1个网格的输入数据是犇(x,y),包括h个线程块,每个线程块包括w个线程,每个线程处理一个像素,其中w和h分别是原始图像的宽和高,为了计算方便,取w和h是2的整数次幂.第1个网格的Kernel函数计算如下的原始(Raw)积分图像第2个网格的输入数据是原始(Raw)积分图像,包括10dh个线程块,每个线程块包括w/2个线程,每个线程完成两个相邻叶节点的处理.其Kernel函数首先将原始积分图像的每一行数据读入片上高速缓存,然后对该行数据执行前缀求和算法从而得到中间结果积分图像.第3个网格的输入数据是第2个网格计算的输出,包括10dw个线程块,每个线程块包含h/2个线程,其Kernel函数将中间结果图像的每一列数据读入片上高速缓存,然后对该列数据执行前缀求和算法.最后我们得到了存储在GPU的全局内存中的积分图像Ibu(x,y),Iμu,i(x,y)和Iσu,i,j(x,y).表1给出了在GPU上和CPU上计算积分图像所需要的时间.从表中可见,在d=4时在GPU上所需的时间约为CPU上所需时间的1/3.7,在d=8时在GPU上所需的时间约为CPU上所需时间的1/3.表1使用GPU和CPU计算积分图像的时间比较(单位:ms)图像尺寸2.4跟踪算法描述同大多数论文相同[3-4,6,8-9],目标的形状用矩形描述,该矩形允许在图像平面内平移、其长度和宽度允许以相同的尺度发生变化.目标的运动模型(先验概率密度)p(狓k|狓k-1)建模为随机行走,其中狓k是目标在k时刻的状态.目标的观测模型表达为π(狔k狓k)=1Page5我们提出的跟踪算法简略地描述如下,关于粒子滤波器跟踪算法的详细描述可参阅文献[2].1.初始化2.采样和更新阶段Iμu,i(x,y),Iσu,i,j(x,y).Fori=1,2,…:End3.输出和重采样4.k=k+1,goto步23实验程序在VisualC++2005编程环境中,使用主频为3.2GHz内存为1.5GB的台式机HPCompaqdx6128MT调试通过,并行算法在配备Geforce8800GTSGPU的影驰显示卡上调试通过.程序使用RGB颜色空间,初始化是在第1帧中用手工完成的,真值(Groundtruth)也是用手工标注得到的.我们使用所提出的算法(简称新算法,粒子数:500)在3个图像序列中进行了实验,并与传统的基于直方图(8×8×8)的粒子滤波器算法(简称传统算法,粒子数200)进行了比较.论文采用跟踪结果的x坐标误差、y坐标误差和非重叠区域比来度量跟踪结果的准确程度.令M和T分别为跟踪结果矩形和真值所包围的像素组图2新算法对人脸的跟踪结果(从左至右、从上到下依次为第1、50、90、140、200、280、360和490帧)成的集合,非重叠区域比r定义如下r=MT其中表示两个集合的对称差,∩表示两个集合的并集,|·|表示集合包含的元素个数.r的值介于0和1之间,r越小跟踪结果越准确.如果跟踪结果完全准确,即M=T,则r=0;如果跟踪结果M与T无交集,则r=1.图1表示了非重叠区域比的3种情况:0<r<1,r=0,r=1.3.1跟踪实验第1个实验是关于办公室环境中的人脸跟踪,图像序列是在典型的办公室环境中采集得到,共500帧,图像尺寸是256×192.由于目标和摄像机都在运动,因此目标帧间位移较大.基于新算法的典型的跟踪结果如图2所示,从左至右、从上到下依次为第1、50、90、140、200、280、360和490帧的结果.可以看到目标存在各种姿态变化,在第200帧附近、280帧附近分别存在短时遮挡,在第360帧附近存在光照变化.新算法和传统算法都能够在整个序列中稳定地跟踪目标.图3给出了两种算法在每一帧中的x坐标、y坐标误差和非重叠区域比,其中实线表示新算法,虚线表示传统算法.表2给出了两种算法的平均跟踪误差和每帧平均跟踪时间.可以看出新算法的x坐标误差、y坐标误差和非重叠区域比比传统算法小.传统算法和新算法的每帧平均跟踪时间分别为30ms和24(10)ms,其中括号中的数据表示在新算法中GPU计算积分图像所用的时间.Page6图3人脸序列中传统算法(虚线)和新算法(实线)的跟踪误差比较表2人脸序列中跟踪误差(均值±标准差)和平均跟踪时间传统算法5.79±5.976.32±5.190.19±0.1130新算法5.56±5.195.77±4.670.18±0.0924(10)注:表示括弧中的数据表示在平均跟踪时间中GPU计算积分图像需要的时间.图4新算法对车辆的跟踪结果(从左至右、从上到下依次为第1、160、350、520、560、610、840和910帧)第2个实验是关于街道上的车辆跟踪.图像序列是用手持式摄像机(hand-heldcamera)SonyDCR-PC1000E拍摄到的,共包括930帧,图像尺寸是704×576.由于手持式摄像机的抖动,图像中目标经常发生突然的运动和显著的图像模糊,如在第282、445、497、560、785、818帧附近均发生了显著的运动模糊.图4给出了基于新算法的典型跟踪结果.Page7从第550帧至第710帧,一辆与目标颜色相似的汽车从后面开过来,逐渐并几乎完全遮挡了目标车辆.这辆位于目标附近的、颜色与目标相近的汽车对于目标的跟踪构成了很大的威胁.新算法和传统算法图5车辆序列中传统算法(虚线)和新算法(实线)的跟踪误差比较表3车辆序列中跟踪误差(均值±标准差)和平均跟踪时间传统算法7.63±10.5816.11±15.430.26±0.1841新算法7.01±7.9613.24±9.640.23±0.1233(13)注:表示括弧中的数据是在平均跟踪时间中GPU计算积分图像需要的时间.第3个实验是关于马路上的行人跟踪.图像序列也是用手持式摄像机拍摄到的,共包括350帧,图像尺寸是704×576.在该场景中背景非常复杂,行人摩肩接踵,存在非常严重的遮挡,光照变化也很大.即使如此,新算法能够在整个序列中稳定地跟踪目标———穿红色衣服的行人(图中方框所示).基于新算法的典型跟踪结果如图6所示.由于背景非常复杂,需要在相应的软件中将图像放大(zoomin)才能更清晰地看清整个场景和目标.传统算法在第24帧附近就无法跟踪目标而发散;在第180帧我们在每一帧中的跟踪误差和平均跟踪误差分别如图5和表3所示,可见新算法的x、y坐标误差和非重叠区域比都要小于传统算法.新算法和传统算法的平均跟踪时间/帧分别为41ms和33(13)ms.将传统算法重新初始化,然而该算法在连续跟踪103帧后又发散了.因此图7和表4只给出了新算法的跟踪误差.新算法的每帧平均跟踪时间是22(4)ms,其中括号中的数据表示在新算法中GPU计算积分图像所用的时间.表4行人序列中跟踪误差(均值±标准差)和平均跟踪时间传统算法-新算法6.82±5.3110.57±8.000.31±0.1922(4)注:表示括弧中的数据是在平均跟踪时间中GPU计算积分图像需要的时间.表示传统算法不能对目标进行跟踪,解释请见论文.3.2性能分析就跟踪准确性而言,从人脸跟踪和车辆跟踪的实验可知,新的跟踪算法无论x坐标误差、y坐标误差还是非重叠区域比都比传统算法小.实验结果表Page8图6新算法对行人序列的跟踪结果(从左至右、从上到下依次为第1、50、150、195、210、240、300和325帧)图7行人序列中新算法跟踪误差明新的跟踪算法在跟踪准确性方面优于传统算法,这主要是由于论文中采用的新的颜色模型能更好地描述目标的颜色分布.就跟踪时间而言,新算法的跟踪时间显著地少于传统算法:人脸跟踪实验中比传统算法少6ms,车辆跟踪实验中比传统算法少8ms.这是由于论文提出的基于GPU的并行算法能快速地计算出颜色模型,从而在粒子滤波器算法中最耗时的观测概率密度(见式(5)、式(13))能够快速计算出来.行人跟踪实验主要测试算法的鲁棒性.在行人序列中严重的遮挡和剧烈的光照变化使目标跟踪变得非常困难.在这种情况下,传统的基于颜色直方图的粒子滤波器算法完全失效,无法对目标进行跟踪;而论文中提出的新算法尽管跟踪误差有所增加,仍然能够在整个序列中稳定地跟踪目标.这说明新算法在鲁棒性方面优于传统算法.Page9在实验中传统算法的粒子数取为200,如果进一步增加粒子数,例如增加到与新算法的粒子数相同,即500,传统算法在人脸实验和车辆实验中跟踪准确性有所改善,但仍然无法跟踪行人目标.与此同时传统算法的跟踪时间大大增加,人脸跟踪和车辆跟踪时间分别是76ms和103ms,远远多于新算法的跟踪时间(分别是24ms和33ms).4结论粒子滤波器能够以统一的理论框架处理非线性非高斯问题,因而成为目标跟踪领域一种强有力的跟踪算法.然而由于粒子滤波器的蒙特卡洛性质,它一般要求大量的粒子才能准确地表达目标的概率分布,因此算法的计算代价很大.为了改善计算效率,在基于颜色的粒子滤波器跟踪中研究者不得不以粗略地表达目标的颜色分布和/或减少粒子数目为代价,因此会影响算法的跟踪性能甚至使跟踪失败.本文提出的算法在解决这一问题方面前进了一步.我们的算法采用了一种自适应剖分颜色空间的模型,能够准确地表达目标的颜色分布.为了能够快速地计算颜色模型,提出了一种推广的积分图像,利用该积分图像我们能够通过简单的数组索引操作快速地计算出每一个子空间的像素数目、高斯分布和协方差矩阵.然而构造积分图像本身是一个耗时的过程,为此提出了一种并行算法,该算法能够在NVIDIAG80GPU上快速地计算出积分图像.我们提出的新的目标跟踪算法不但计算速度快,而且跟踪性能也得到了较大的提高,通过同传统的基于直方图的粒子滤波器算法的比较验证了我们的结论.由于粒子滤波器算法估计目标状态的后验分布,能够通过大量的粒子保持对目标状态的多种假设,因此对光照变化、短时遮挡等具有较强的处理能力.即使如此,剧烈的光照变化或长时间的遮挡仍然可能使跟踪失败.我们将来的工作是进行多传感器或多信息融合,除了颜色信息,进一步考虑其他信息如声音信息、目标的结构知识等,以便能够进行更为鲁棒的目标跟踪.致谢感谢审稿专家中肯的审稿意见!
