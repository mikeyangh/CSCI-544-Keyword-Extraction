Page1存储级并行与处理器微体系结构谢伦国刘德峰(国防科学技术大学计算机学院长沙410073)摘要随着处理器和主存之间性能差距的不断增大,长延迟访存成为影响处理器性能的主要原因之一.存储级并行通过多个访存并行执行减少长延迟访存对处理器性能的影响.文中回顾了存储级并行出现的背景,介绍了存储级并行的概念及其与处理器性能模型之间的关系;分析了限制处理器存储级并行的主要因素;详细综述了提高处理器存储级并行的各种技术,进行了分析比较;最后分析讨论了该领域研究存在的问题和进一步的研究方向.关键词存储级并行;微体系结构;Runahead;检查点;值预测1引言从1980年开始,微处理器性能以每年60%的速度增长,而存储器访问性能的提高每年不到10%,处理器和存储器之间的性能差距还在不断增大,存储器性能瓶颈,即“存储墙”问题[1],已经成为提高计算机系统性能的主要制约因素.为了缓解“存储墙”问题,人们在减少访存延迟和隐藏访存延迟两个方面进行了大量的研究.除了不断改善存储器访问性能之外,使用cache层次存储结构是最主要、也是最有效的减少访存延迟的体系结构方法.只要程序呈现良好的时间和空间局部性,大部分访存请求都可以在Cache中得到满足,从而减少处理器对主存的访问.然而,一方面对于局部性较差的程序,Cache的效率将会大大降低.另一方面,随着处理器和存储器之间性能差距的不断扩大,由Cache失效引起的外部访存操作延迟,即从Load失效到数据可用(Load-Use)的时间,目前已达上百个处理器时钟周Page2期,例如,Intel2.933GHzNehalem处理器访问本地DDR3-1333存储器延迟达65ns[2],折合190个处理器时钟周期.预计,未来可能增加到数百个处理器时钟周期[3].有模拟实验结果表明,当外部访存延迟由200延长到1000个处理器时钟周期时,程序执行时间将增加一倍,最多可达三倍以上[4].因此,访存延迟隐藏技术变得更为重要.传统的访存延迟隐藏技术包括软硬件预取[5]、超标量乱序执行和多线程技术.预取通过计算和访存操作重叠,将数据在实际使用前先行取到离处理器较近的地方,关键是预取数据和预取时机的选择.超标量乱序执行旨在提高单线程内指令级并行(InstructionLevelParallelism,ILP)度,并以此隐藏长外部访存延迟,但这需要大指令窗口的支持,而大指令窗口通常受系统设计复杂度和芯片面积及功耗的严格限制.多线程技术则通过线程级并行(ThreadLevelParallelism,TLP)来隐藏访存延迟,如果一个线程因访存指令引起Cache失效,处理器切换到另一线程执行,从而提高处理器的ILP.多线程技术也同时提高了系统资源的利用率.这些技术的基本思想都是通过指令级并行,特别是计算指令和长延迟访存操作重叠来隐藏访存延迟.长期以来,处理器设计者一直致力于提高处理器的指令级并行,也包括线程级并行,但遗憾的是,指令级并行虽然有效地减少了处理器的计算时间,但对因外部访存延迟造成的处理器停顿时间的减少却作用不大,并且随着处理器和存储器之间性能差距的不断扩大,单纯依靠快速计算(依赖于寄存器和Cache命中数据的计算)的指令级并行来隐藏长延迟的外部访存已经变得很不现实.因此,人们提出了利用长延迟外部访存隐藏长延迟外部访存的方法,这就是存储级并行.Glew于1998年在他的文章“MLPyes!ILPno!”中第一次提出了存储级并行(MemoryLevelParal-lelism,MLP)的概念[6],他认为:在处理器和存储器性能差距不断扩大的情况下,人们更应关注微体系结构的存储级并行,而不是指令级并行.所谓存储级并行,就是处理器以重叠的方式并行执行多个因Cache失效导致的外部访存的能力.存储级并行揭示了长外部访存延迟隐藏技术的关键,人们开始从存储级并行的角度重新审视微处理器体系结构,对提高处理器存储级并行的方法进行研究,存储级并行正在逐渐成为处理器微体系结构研究的热点技术.定性地说,存储级并行就是处理器并行执行外本文将对处理器存储级并行技术进行综述,第2节介绍存储级并行的概念及其对系统性能的影响;第3节指出传统乱序执行、超标量处理器体系结构限制存储级并行的主要因素;第4节重点介绍当前提高处理器存储级并行的研究进展;最后第5节探讨了存储级并行今后的研究方向.2存储级并行的定义2.1存储级并行的定义部访存操作的能力或方法.Chou在文献[4]中首次定量地给出了存储级并行(MLP)的形式化定义及MLP与系统性能之间的关系模型,有效地揭示了存储级并行的特征.Chou将时钟周期t时有效外部长延迟访存的个数定义为瞬时存储级并行MLP,用MLP(t),所有不等于零的瞬时存储级并行MLP(t)的平均值,即所有至少存在一个有效外部长延迟访存的时钟周期内每个时钟周期访存操作的平均个数定义为平均MLP,用MLP表示.这里特别限定的“有效外部长延迟访存”意指因处理器片内Cache失效导致的对片外存储器的有效访问,不包括因误预测等造成的无效片外存储器访问,即访存的数据要被程序真正使用.按照该定义,有效外部长延迟访存包括指令Fetch,Load和硬件/软件预取.在图1所示的示例中,外部访存延迟为200周期,MLP(t)=1的周期为90~100、290~300、350~550,MLP(t)=2的周期为100~290,MLP=(10+10+200+2×190)/410=1.463.2.2存储级并行对程序执行性能的影响性能的影响如式(1)所示.在外部访存延迟固定情况下,MLP对程序执行式中,Cycles为程序执行总时钟周期数;Cyclesperf为计算执行时钟周期数;OverlapCM为计算与片外访存Page3重叠执行所占计算执行周期数的百分比;NumMisses为Cache失效导致的片外访存次数;MissPenalty为每次片外访存延迟时钟周期数;MLP为平均存储级并行.式(1)的结论是显然的,第1项表示计算执行周期数减去与存储器操作重叠的周期数;第2项表示外部访存的周期数.随着处理器和存储器之间性能差距的不断扩大,处理器片外访存延迟时钟周期数将越来越大,通过计算执行与片外访存重叠隐藏访存延迟的作用将越来越小,以至于Chou在建立MLP模型时假设OverlapCM≈0.在外部访存延迟固定情况下,减少Cache失效、提高存储级并行度将是提高程序整体执行性能最有效的方法.2.3MLP的提升空间根据Chou的平均MLP定义,YangZhen等人[7]对SPEC2000和Olden应用中的9种实际负载进行了模拟研究,比较了在存在数据相关实际条件下的基本MLP和不考虑数据相关、Cache失效Load指令无任何延迟流出情况下的理想MLP,模拟结果如图2所示.结果表明,基本MLP和理想MLP之间存在着较大差距,即MLP存在较大的提升空间.3限制处理器存储级并行的主要因素尽管微处理器体系结构在不断的发展,从超标量乱序执行处理器到多线程、同时多线程处理器,再到目前的多核、众核处理器,但是其基础仍然是超标量乱序执行处理器,因此对传统的乱序、超标量处理器限制存储级并行的主要因素进行分析仍具有普遍的指导意义.3.1指令流出队列和重定序缓冲的大小指令流出队列(IQ)和重定序缓冲(ROB)是乱序超标量处理器指令窗口中实现指令乱序执行最重要的两个硬件结构.只有存入IQ的不相关指令才有可能乱序流出,IQ越大,存入IQ的不相关访存指令的可能性越大.指令在存入IQ的同时存入ROB,用以记录进入IQ的指令原来在程序中的取指顺序,确保指令在完成时能按原来的顺序提交,同时为精确中断提供支持.ROB是一个FIFO队列,只有当队列中前面所有的指令全部正确提交(完成)后,当前指令才能从ROB移出.当ROB头是一条长延迟外部访存指令时,如果在这条访存指令完成之前,ROB已经被占用满,将会造成后面访存指令的阻塞,因此存储级并行受限于ROB的长度.增加ROB的长度将有利于提高MLP.与指令窗口相关的其它系统资源还包括寄存器文件、StoreBuffer等,这些资源必须与指令窗口同步增长.3.2串行化指令几乎所有的指令集结构(ISA)都包含用于实现同步原语或维持存储一致性的指令,例如SPARCISA中的CASA和MEMBAR[8]指令.因这类指令在流出之前,必须清空处理器的流水线,即这类指令之前的所有指令必须执行完毕,所以称之为串行化指令.这意味着,串行化指令之后的外部访存指令,即使和之前的所有外部访存指令不相关,也不可能并行流出.4.2.1小节和4.2.2小节介绍的两种技术可以减少串行化指令对存储级并行的影响.3.3取指失效和分支预测失败取指失效意味着指令Cache中没有指令可提供给IQ,此时必须到外部存储器取指令.分支预测失败或分支预测错误意味着在分支预测判定之前,处理器在按照一条错误的路径取指和执行指令,通常这些指令的执行都是无用的.而且,分支预测判定依赖于与Cache失效相关的外部访存返回的值.因此分支预测的精度和延迟对处理器的MLP具有较大的影响.3.4Load指令流出策略对于乱序执行的处理器而言,虽然不同类型指令之间的指令可以乱序流出,但是某些类型指令之间仍然存在不同的限制,特别是Load指令.Load指令相对于其它的Load指令和Store指令,它们之间存在3种不同的流出策略:全部顺序流出;Load指令之间乱序、Load与Store指令之间顺序;全部乱序.这类指令流出策略涉及访存指令的流出和存储一致性,指令流出约束越松,对提高MLP越有利.Page43.5Cache失效处理机制当代通用微处理器几乎无一例外地使用Cache层次存储结构,Cache存储器参数的选择、Cache失效处理机制允许处理Cache失效的个数将直接影响Cache失效次数和MLP.Cache失效处理结构(MHA)对存储级并行的影响最大,一般地,Cache失效处理结构的入口数目越大越有利于MLP的提高.具体细节将在4.3.1节介绍.以上仅对传统的乱序、超标量处理器微体系结构限制存储级并行的主要因素进行分析.随着半导体工艺的进步,微处理器体系结构正在向多核、众核单芯片多处理器(CMP)方向发展,片外存储器的带宽及带宽的有效利用越来越成为微处理器存储级并行的重要限制因素.此外,应用程序的访存特征,特别是数据相关性也是限制处理器存储级并行的重要因素.本文将主要从处理器微体系结构的角度探讨提高处理器存储级并行的方法.4提高处理器存储级并行的技术近10年来,人们从软件到微处理器结构,从指令流出到片内存储系统,对处理器存储级并行技术进行了广泛深入的研究,提出了许多新型微体系结构和新技术,如千条指令处理器KIP(Kilo-InstructionProcessor)[9-10]、检查点处理和恢复CPR(CheckpointProcessingandRecovery)体系结构[11]、连续流流水线CFP(ContinualFlowPipeline)处理器[12]等.存储级并行就其本质而言,仍属于指令级并行,只不过存储级并行强调的是因片内Cache失效导致的外部访存指令的并行.所以,传统的用于提高指令级并行的方法,包括扩展指令窗口、数据预取、提高Cache利用率等,原则上都适用于提高存储级并行.同时存储级并行是一个系统性课题,它不仅依赖于微处理器体系结构,也依赖于和处理器配套的存储子系统,依赖于使用处理器的软件.下面将就提高处理器存储级并行的主要微体系结构技术进行介绍.4.1扩展指令窗口从理论上讲,只要指令窗口足够大,允许足够多的与长延迟访存指令不相关的指令在长访存延迟时间内并行执行,就能消除因长延迟访存造成的处理器停顿,隐藏长访存延迟.基于此,KIP、CPR、CFP等都能支持一千条飞行(未完成)指令并行执行,从而隐藏长达到1000个处理器时钟周期的外部访存延迟.勿容置疑,指令窗口越大,存储级并行的可能性越高.影响指令窗口的主要数据结构包括指令流出队列(IQ)、重定序缓冲(ROB)、Load/Store队列(LSQ)和物理寄存器文件(PRF).在实际实现中,由于实现复杂度、芯片面积、温度、功耗及时钟频率等诸多因素的限制,仅仅简单地通过按比例增加与指令窗口相关的系统结构资源来扩展指令窗口是不切实际的.为了有效扩展指令窗口,人们通常采用两类方法:(1)层次式指令窗口;(2)积极的资源回收机制.下面将分别予以讨论.4.1.1层次式指令窗口所谓层次式指令窗口,就是在原有的单个指令窗口的基础上,增加一个二级指令窗口,专门对长延迟指令进行处理.原指令窗口(主指令窗口)处于指令执行流水线的关键路径上,当处理器检测到长延迟指令,例如Cache失效Load指令时,长延迟指令及其与该长延迟指令直接或间接相关的其它指令被送入二级指令窗口,使长延迟及其相关指令移出指令执行关键路径,允许主指令窗口流出更多的指令.当长延迟指令服务得到满足时,长延迟及其相关指令返回主指令窗口优先执行.针对长延迟相关指令的检测、缓冲和处理,近年来人们提出了许多层次式指令窗口结构,如等待指令缓冲器WIB(WaitingInstructionBuffer)[13]、Slice指令处理部件SPU(SliceProcessingUnit)[12]、慢车道指令队列SLIQ(SlowLaneInstructionQueue)[9]等.WIB使用现有的小的流出队列,通过对源操作数增加一个“等待”位标记该操作数处于“伪就绪”状态,目前尚不可用.凡是操作数被标记为“伪就绪”的指令即为“伪就绪”指令,以此来检测Cache失效Load指令及其相关指令.伪就绪指令按真就绪指令一样从流出队列流出,只是它们不是流出到功能部件,而是流入等待指令缓冲器WIB.当Cache失效Load指令的数据从主存中返回时,WIB中的相关指令重新并优先插入指令流出队列.WIB设计的与指令活动列表一样大,允许重新插入流出队列的指令因与另一个Cache失效Load指令相关而重新流入WIB.CFP结构[12]将长延迟Load失效及其相关指令定义为Slice指令.与WIB类似,CFP动态识别Slice指令,Slice指令从调度器流出直接送入Slice指令处理部件SPU,同时释放Slice指令对应的全部指令调度资源,供后续指令使用.SPU比WIB功能更为强大,除了缓存Slice指令外,SPU还保存有Page5执行这些Slice指令所需的所有信息,包括源寄存器数据和数据相关信息.当长延迟数据返回时,SPU根据保存的Slice指令的源寄存器数据和数据相关信息为Slice指令重新分配物理寄存器,然后重新插入指令流水线调度执行.KIP[9]在指令重命名后送入IQ和伪ROB,当检测到长延迟指令及其相关指令到达伪ROB头时,长延迟指令及其相关指令从伪ROB流入慢车道指令队列SLIQ,同时作废IQ中的相应指令.当SLIQ中的长延迟指令操作完成后,该长延迟指令及其相关指令重新插回IQ队列执行.由于SLIQ不在指令流水线的关键路径上,因此,在不扩大IQ条件下有效实现了大IQ的功能.虽然KIP在长延迟指令及其相关指令到达伪ROB头时才送入SLIQ,但这种延迟策略为准确判断L2Cache失效长延迟指令提供了时间.为了支持大指令窗口,物理寄存器文件(PRF)和Load/Store队列(LSQ)需要按指令窗口大小成比例地增长.为了适应这种增长,人们同样采用了层次式结构.典型地,CPR[13]利用Store队列向Load指令转发数据的局部性设计了一个两级Store队列STQ.一级Store队列L1STQ类似于通常处理器的Store队列,循环缓冲处理器最近的n条Store指令,新指令进入L1STQ的尾.当L1STQ存满时,最老的指令从L1STQ的头溢出,存入二级Store队列L2STQ,直至指令提交.Load指令地址同时送往L1STQ、L2STQ和DCache,根据地址命中情况,分别由L1STQ、L2STQ和DCache向Load指令转发或提供数据.4.1.2积极的资源回收机制除了采用层次式结构扩展指令窗口外,如何提高重定序缓冲(ROB)、Load/Store队列(LSQ)和物理寄存器文件(PRF)这些结构资源的利用率,减小对这些资源的需求,是另一种扩展指令窗口的重要方法.下面仅就ROB和PRF的资源回收机制作一介绍.4.1.2.1检查点技术与提前释放ROB在传统的超标量处理器中,ROB保持所有飞行指令的状态,以确保所有指令能乱序执行、顺序提交,同时支持精确中断和例外,包括分支预测错误、图3物理寄存器生命周期支持寄存器重命名和回收.飞行指令越多,指令占用ROB时间越长,ROB越可能成为性能瓶颈.即使ROB可以做得很大,与其相关的机制,如分支误预测恢复机制等却限制了其性能的发挥.检查点(Checkpoint)技术通常用于系统修复.检查点是程序执行时某一特定指令点处理器系统结构状态的快照,包含着系统从该点继续执行所需的所有信息.系统出错时,回滚到上一个检查点,系统就可从该检查点继续正确运行.文献[13]提出,采用选择性的检查点技术,可以将ROB所有功能卸载到其它可扩展机制,从而取消ROB.CPR结构根据对分支预测可信度评估,对低可信分支点建立检查点,通过维护映像表检查点的踪迹,实现了快速分支误预测恢复机制,8个检查点就足以支持基于ROB分支误预测恢复机制的2048个入口的指令窗口.使用相同的机制,可以实现精确中断、例外以及与系统结构相关的串行化指令的处理.虽然使用选择性检查点技术可以取消ROB,但是KIP[9]并未完全取消ROB,而是在使用多检查点技术的同时,使用了一个小的伪ROB.伪ROB具有和ROB同样的功能,不管指令是否完成,处理器以固定的速率移出到达伪ROB头部的指令.由于处理器状态可以从伪ROB恢复,所以只有当没有完成的指令离开伪ROB时才有必要生成检查点.因为超过90%的分支误预测的指令仍旧保留在伪ROB中,这就意味着大部分的分支误预测不必回滚到检查点来恢复系统状态.这种使用伪ROB延迟生成检查点的方法减少了分支误预测恢复对性能的影响.4.1.2.2物理寄存器文件当指令进入IQ和ROB时,传统的超标量处理器为体系结构寄存器分配一个物理寄存器,直到后来写同一体系结构寄存器的指令完成确认.这样,一条指令将在整个飞行时间内保留它的物理寄存器.物理寄存器的生命周期如图3所示,从图3可以看出,物理寄存器的生命周期长于分配它的指令的生命周期.由于大多数飞行指令都需分配物理寄存器,因此,物理寄存器文件的大小需要与指令窗口的大小成比例增加.Page6物理寄存器虽然分配很早,但是写入却很晚.期间,其主要功能是跟踪数据相关性.因此,实际上物理寄存器资源很长时间是没用的;唯一重要的是它的名字.基于此,人们提出了基于虚拟寄存器(VR)的物理寄存器晚分配技术,对每条重命名指令仅分配一个虚拟标志,用以跟踪数据相关性,而不分配实际物理寄存器,直到产生结果时,才分配物理寄存器.传统的释放物理寄存器的规则也过于保守.理论上,只要没有后续指令再读该物理寄存器的值,该物理寄存器就可释放.早释放物理寄存器的一种可行的实现方法是,为每个物理寄存器关联一个使用计数器,用来跟踪读该寄存器的未执行指令.指令寄存器重命名后,将会读这个寄存器的指令加“1”使用计数器;读完之后减“1”使用计数器.当使用计数器为“0”时,释放该物理寄存器.CPR基于多检查点机制实现了寄存器早释放策略,因为检查点提供了恢复正确体系结构状态的能力.只要对应的检查点不释放,属于该检查点的寄存器就不应该释放.CPR在创建检查点时,将属于该检查点的所有寄存器的使用计数器加“1”,释放时减“1”,寄存器的使用计数器为“0”时释放该寄存器.文献[12]提出了“后端重命名”的概念.CFP在将cache失效及其相关指令(Slice指令)送入Slice指令处理部件SPU的数据缓冲器SDB的同时,将Slice指令的源寄存器数据和物理寄存器映射等信息一并存入SDB,在Slice指令返回指令流水线之前,使用物理寄存器到物理寄存器的重映射为前端已重命名的Slice指令分配新的物理寄存器.这使得CFP可以在Slice指令送入SPU后立即释放Slice指令的物理寄存器.和CPR类似,KIP也是基于多检查点机制,提出的一种称之为“短暂(ephemeral)”寄存器的技术[9],将寄存器释放与指令提交分离、寄存器分配与指令重命名分离,结合了上述寄存器早释放和晚分配两种技术,有效缩减了物理寄存器的生命期.Cherry[14]则结合ROB和单检查点技术,将ROB分为两个区:前瞻区和非前瞻区,仅对非前瞻区内指令的物理寄存器和LSQ入口实施早释放策略,利用检查点提供精确处理.对前瞻区的指令仍然依赖ROB恢复正确的系统结构状态.4.2数据预取与推测执行如果说,扩展指令窗口是通过提高ILP间接提高MLP的话,数据预取则是通过数据预取访存操作直接提高MLP.数据预取的通常方法是,通过硬件或软件的方法启发式地识别应用程序的寻址模式,预测未来最可能被请求的Load指令的存储器地址,在数据实际使用之前对数据提前读取.然而,由于应用的复杂性,程序的寻址模式有时很难预测,例如指针追踪(pointer-chasing)应用;而且,随着访存延迟越来越大,预取地址预测也越来越困难;加之无效预取将加大存储器访问流量的浪费,因此,提高预取的精度已成为数据预取的关键.4.2.1Runahead执行Runahead执行[15]或预执行[16]模式是一种硬件精确预取方法.当处理器由于长延迟L2Cache失效指令停顿时,当前状态进入检查点,处理器从正常执行模式转入Runahead执行模式,使用空闲的执行逻辑执行后续不相关指令,实现对未来数据的精确预取.当L2Cache失效指令完成时,处理器返回正常执行模式,回滚到检查点,重新执行L2Cache失效后的指令.Runahead执行模式如图4所示.处理器由于Mem1指令停顿以后,建立检查点,进入Runahead执行模式,向前执行与Mem1无关的指令.这些无关指令中包括Mem2指令,使得Mem2得以提前执行,实现了为Exe3精确预取的目的.Mem1完成后,处理器回到正常模式,回滚到检查点,重新执行停顿后的指令.由于Mem2已完成,处理器不会因为Mem2造成停顿.在图4所示的例子中,假设Exe2全部为与Mem1无关的指令,在不改变指令执行顺序情况下,MLP将由图4(a)的1提高到图4(b)的1.48.Runahead执行模式利用处理器空闲逻辑资源向前执行Runahead指令,返回正常模式后,Runahead执行结果无论正确与否,全部被丢弃,其优点是不需要多线程的支持,结构简单.但同时也存在两大不足:(1)由于Runahead模式执行完毕后,总要回滚到检查点重新执行,执行了大量无效的指令,执行的Page7总指令数甚至达到程序本身指令数的两三倍以上[17],大大浪费了处理器性能和功耗;(2)由于不能执行与停顿相关的指令,特别是相关的长延迟存储指令,不利于存储级并行,影响了Runahead的预取效果.4.2.2基于值预测的推测执行针对Runahead模式的上述两点不足,人们结合值预测技术提出了许多改进方法.CAVA[18]和CLEAR[19]等采用基于检查点的值预测方法,在长延迟Load失效到达ROB头时设置检查点,提交Load指令,并预测Load值,使用预测值推测地继续执行.当失效Load指令最终从存储器返回数据时,返回数据和预测Load值进行比较,如果预测正确,就不进行回滚,程序继续正常执行.如果预测不正确,就回滚到检查点重新执行.与CAVA不同的是,CLEAR采用了多检查点的Runahead设计,在推测执行模式下,如果出现另一个Load失效,硬件可根据预测器的可信度决定是否创建另一个检查点.显然,CAVA和CLEAR通过值预测,能够推测执行与长延迟Load失效指令无关和相关的指令;当预测值正确的时候,不需要回滚,推测执行的指令正常提交,处理器继续正常执行;当预测值错误的时候,处理器回滚到检查点重新执行,但仍旧实现了精确预取,从而提高了Runa-head执行模式的效率.这里重要的是允许与长延迟Load失效指令相关的指令、特别是相关的Load指令推测执行,提高了处理器的存储级并行.虽然值预测允许其它相关指令预先执行,较之预取更能有效提高MLP,但是实现值预测需要复杂的硬件支持,包括预测检验和误预测恢复.Zhou和Conte[20]提出了一种提高MLP的无恢复值预测方法,该方法在指令流水线的前端设置一个值预测器,并为每个物理寄存器增加一位“值预测就绪(vp-ready)”标志,为每个指令流出入口增加一位“值预测/推测(vp)”标志.指令分派阶段,Load预测值写入物理寄存器,并置位vp-ready标志.指令流出阶段,如果指令源寄存器“就绪(ready)”,指令非推测(正常)流出;如果指令源寄存器“未就绪”,而vp-ready置位,指令推测流出.推测流出保存在指令队列中,直到它们使用ready源寄存器非推测流出为止.这里,值预测/推测执行的结果仅用于数据预取,所有被推测执行的指令都将再次被值预测执行,因而避免了复杂的预测检验和误预测恢复机制,硬件改动很小.4.3片上存储系统本文定义的处理器存储级并行是指处理器支持多个因最末一级Cache失效导致长延迟外部存储器访问并行执行的能力.而要提高处理器的存储级并行能力,一方面需要处理器采取上述技术提高CPU流出更多的访存请求,另一方面则需要处理器存储子系统,包括片内Cache存储器和片外Cache存储器,能够支持CPU流出的访存请求并行执行.当前对于片上存储子系统的改进主要有两方面:第一增大Cache失效处理结构,提高对存储级并行的支持;第二采用面向MLP优化的Cache替换策略.4.3.1Cache失效处理结构(MHA)存储子系统中不同层次存储器支持的存储级并行度是不同的,越里层存储器的存储级并行需求越高.Ceze等人对3种处理器类型的并行L1Cache读失效数目分布进行了模拟分析[21],结果表明,常规处理器90%应用的并行L1Cache读失效数小于等于16;而基于检查点和使用大指令窗口的高MLP新型处理器,某些应用的并行L1Cache读失效数大于等于120,并占有较大比例.新近提出的CPR和CFP微体系结构也都假设同时支持128个L1Cache失效.而现在的处理器,即使是高端微处理器也远不能支持这个级别的需求,例如Pentium4仅同时支持8个L1Cache失效[22].Cache失效处理结构MHA(MissHandlingArchitecture)是Cache中处理Cache失效的逻辑.失效信息/状态保存寄存器MSHR(MissInforma-tion/StatusHoldingRegister)[23]是实现非阻塞MHA的关键数据结构,用于保存Cache失效请求地址、请求大小和请求类型等信息.Ceze等人评估了上述3类处理器对MHA的需求[21],假设一个MSHR保存同一L1Cache行所有失效的状态信息,对大多数应用,要覆盖95%的L1Cache读失效,常规处理器需要8个MSHR,基于检查点的处理器需要32个MSHR,使用大指令窗口的处理器需要更多的MSHR.Ceze等人同时提出了一种新型的可扩展MHA设计[24],采用层次式MSHR文件扩展MHA的大小,同时使用Bloom过滤器缩减MSHR文件的搜索时间,可实现接近于无限大小的理想MHA的性能.4.3.2Cache替换策略对于每个Cache失效的访存操作,有些可以和其它失效访存并行执行,比如读取数组,有些则无法和其它失效访存并行,如指针追踪,它们的系统性能Page8成本是不同的.无法并行执行的独立失效访存的性能成本远大于并行失效访存的性能成本.据此,Qureshi等人提出了一种存储级并行敏感的Cache替换策略[25].通过实时计算每个Cache失效的基于存储级并行的性能代价mlp-cost,优先替换mlp-cost低的Cache块,以达到尽量减少无法并行执行的独立Cache失效的数目,提高系统性能的目的.4.4多线程处理器前面介绍的提高存储级并行技术主要着眼于提高传统处理器单线程流出与停顿指令相关和非相关访存指令的能力,而实际上,由于受到设计复杂性、时钟频率、面积有效性和能耗有效性等因素的限制,单线程MLP的提高是有限的.多线程处理器则是通过硬件线程维护每个线程的系统结构状态(Context),支持线程切换和并行来提高处理器流出更多访存指令的能力,提高处理器的存储级并行.多线程处理器提高存储级并行如图5所示.同时多线程(SMT)利用乱序执行机制,允许每个时钟周期流出多个线程的指令,同时支持活跃线程占用其它因长延迟指令而导致流水线停顿线程的流出窗口,多个线程可同时执行,线程间无需文本切换,从而进一步提高了多线程处理器的存储级并行,同时提高了处理器的资源利用率.不同线程的访存并行执行,虽然看起来不会提高单线程的MLP,但是,多线程处理器使利用辅助线程[26]协助主线程的预取成为可能,从而可以提高单线程的MLP.现有的同时多线程处理器取指策略主要包括两类.一类选择流水线中指令数最少的线程取指,试图平衡流水线中各线程的指令数;一类检测或预测到线程长延迟Load指令时暂停该线程的取指,甚至清除该线程长延迟Load指令后的指令,以释放暂停线程分配的资源,提高其它非暂停线程的性能.但是它们都未考虑长延迟Load指令的存储级并行,由于暂停被阻塞线程的取指,可能使原本可以并行执行的不相关长延迟Load指令串行化.Eyeman等[27]提出了一种存储级并行感知的取指策略,通过预测给定线程长延迟Load指令的存储级并行数,按预测的存储级并行数控制取指数目,使得存在存储级并行的线程可以获得与存储级并行数相适应的执行资源,达到进一步提高性能的目的.Ramírez等[28]将Runahead技术与SMT相结合,在一个线程因长延迟Load指令而停止时,进入Runahead执行模式,尽量使用最少的资源来推测执行,在解决SMT资源竞争的同时,提高MLP.为了减少Ramírez方法在Runahead执行周期中线程可能执行的无效指令数目,VanCraeynest等[29]使用MLP预测器来决定线程是否进入Runahead模式,如果无法产生有效的存储级并行,线程将不进入Runahead模式,从而减少能量的浪费.4.5多核处理器多核(MultiCore)、众核(Many-Core)处理器,或者片上多处理器(ChipMultiProcessor,CMP)在单芯片上集成多个处理器核,每个处理器核拥有各自的CPU和私有Cache,它们可以是单线程的,也可以是多线程的.多核处理器可以理解为多线程处理器的自然延伸,不同的是,多核处理器的处理器核比多线程处理器的硬件线程更独立,它们仅共享片上最末级Cache(Last-LevelCache,LLC)和互连网络,其工作方式仍然是线程级并行.目前,多核处理器已经成为现代高性能微处理器发展的主流.多核处理器通过在多个处理器核上并行运行多个线程来提高处理器的存储级并行能力,多核处理器存储级并行如图6所示.4.5.1高存储级并行顺序处理器核由于多核处理器芯片面积和功耗的限制,顺序(in-order)处理器再度受到人们的关注.某些设计强调吞吐量计算,而不是单线程的性能,如SunUltra-SPARCT1,采用较多的简单的顺序处理器核取代较少的复杂的乱序处理器核.像IBMPower6这样的高性能处理器也放弃了乱序执行,转而采用顺序处理器核.为了弥补顺序处理器核带来的单线程性能的不足,人们试图将前面介绍的乱序超标量处理器提高存储级并行的方法应用于顺序流水线,提高顺序处Page9理器核的存储级并行,改善单核单线程的处理性能.IBMPower6[30]首先将Runahead执行模式应用于顺序处理器核,Power6称之为LoadLookAhead(LLA)模式.处理器的每个核可以同时执行两个线程,当一个线程发生Cache失效时,该线程进入LLA模式,预取后继不相关指令的数据,同时降低该线程的优先级,以减少对正常执行线程资源的竞争,当Cache失效数据返回时,该线程回复到初始的优先级.LLA模式所有的执行结果都会被丢弃,但如果处理器核处于单线程模式,执行结果会写入空闲线程的寄存器中,使更多的后继指令可以执行,以提高预取的效果.SunROCK[30-32]处理器同样吸取了Runahead的思想,Sun称之为ExecuteAhead(EA)模式.当线程遇到长延迟指令时,建立检查点,启动EA模式.长延迟指令的目标寄存器标记为不可用(NA),长延迟指令送入推迟执行队列DQ,至少有一个源操作数标记为NA的后续指令的目标寄存器也标记为NA,指令送入DQ.没有操作数标记为NA的后续指令继续执行,结果写入目标寄存器的推测拷贝.当长延尺指令完成时,线程从EA模式转换到重执行模式,从DQ中读出被推迟指令重新执行.当DQ中的指令执行完毕,处理器执行合并操作,并将目标寄存器的推测拷贝中的结果更新到体系结构寄存器中,处理器恢复到正常执行模式.SLTP(SimpleLatencyTolerantProcessor)[30]和iCFP(in-orderCFP)处理器[33]将CFP[12]技术应用于顺序处理器核中.SLTP在Load指令Cache失效时建立第一个检查点,失效指令及其相关指令移出流水线,失效指令及其相关指令连同它们的输入寄存器的值按程序顺序存入SDB,失效无关指令与失效指令并行执行.当失效数据返回时,SLTP建立第二个检查点,执行切换到SDB指令.当SDB中所有指令被执行,执行结果从第二检查点与失效无关指令执行结果合并,然后取消检查点,恢复到正常执行状态.SLTP和iCFP通过将非阻塞流水技术应用于顺序处理器核,既保证了处理器核的简单性,又提高了单处理器核的性能,以便在单芯片中集成更多的处理器核.4.5.2面向存储级并行的异构多核处理器Patsilaras等人[34]首次设计了一个结合高ILP处理器核和定制高MLP处理器核的非对称多核处理器AMP(AsymmetricMulticoreProcessors),定制高MLP处理器核采用类似于CAVA[18]和CLEAR[19]设计思想的CLP+VP(CheckpointedL2MissProcessingwithValuePrediction)结构.作者提出了一种细粒度的硬件调度算法,根据应用的L2Cache失效行为即时地将具有MLP潜能的应用段切换到MLP处理器核上执行,将不具MLP潜能的应用段放在通用处理器核上执行,以此提高多核处理器的性能.灵活异构多核处理器FMC(FlexibleHeteroge-neousMulti-CoreProcessor)[35]由快速的Cache处理器和存储处理器组成.Cache处理器用于处理数据来自寄存器和Cache的指令,存储处理器则用于处理与主存相关的指令.小型顺序存储处理器以类似runahead执行的方式将Cache失效数据读取到Cache中,使得Cache处理器可以高速地执行指令,而不发生Cache失效.FMC中存储处理器的预取能力及多个存储处理器的可配置能力有效提高了FMC的存储级并行.4.5.3面向存储级并行优化的Cache管理多核处理器的Cache划分大部分基于减少失效次数或者系统公平性,而没有考虑存储访问的并行性.单个的Cache失效和成“簇”的Cache失效对处理器性能的影响是不同,单个Cache失效由于无法并行,对系统性能影响更大.因此Moretó等人[36]提出了一种存储级并行敏感的Cache划分方法.通过修改MSHR来记录Cache失效发生的时机,并且根据MSHR记录的信息计算不同程序的实际失效开销,并据此开销进行共享Cache的划分.最后一级Cache的MSHR通常是多核处理器的共享资源,多个线程的存储访问会互相影响,使得线程的性能难以预测.尤其当部分处理器核恶意地发出大量的存储器访问请求时,会完全占用MSHR的入口,从而形成拒绝服务攻击.针对这个问题,Jahre等[37]在最后一级CacheMSHR的分配时加以管理,限制一个线程过多地占用MSHR入口,在提高存储级并行的同时保证不同任务之间的公平性.5今后的研究方向上面介绍了存储级并行概念的提出及其定义,分析了传统乱序执行、超标量处理器体系结构限制存储级并行的主要因素,重点介绍了当前提高处理器存储级并行的新型微体系结构技术.下面简要介绍针对存储级并行需要深入开展的工作,并对今后的研究方向进行探讨.Page10存储级并行作为一个新的研究课题,虽然对其研究内容已经有了一定的共识,并提出了很多不同的解决方案,但由于许多研究才刚刚起步,很多工作还有待进一步的深入研究,主要包括以下几个方面:(1)进一步研究应用程序的存储级并行特性以及存储级并行对处理器应用性能和执行方式的影响,建立存储级并行执行模型和测试工具,系统性地指导处理器体系结构存储级并行优化.(2)目前存储级并行的研究对浮点应用非常有效,而对整数程序的性能提高不明显.整数程序性能提高的主要限制是分支难以预测和指针追踪数据加载难以并行化.虽然目前针对指针追踪加载提出了一些预取方法,但仍有待进一步研究.(3)目前存储级并行研究大多集中在存储器读操作上,对存储器写操作并行研究很少,如何克服StoreBuffer对处理器性能的限制需要进一步研究.(4)以往的存储级并行研究主要集中在传统乱序超标量处理器体系结构基础上,对多核多线程处理器的存储级并行研究刚刚开始.如何利用存储级并行技术平衡多核处理器吞吐量计算与单线程性能是未来的一个研究重点,同时多核多线程处理器的存储系统明显不同于超标量单处理器系统,私有或分布共享多层次片上存储系统MHA实现机制、存储级并行与Cache一致性的协同、存储控制器及存储访问调度等均需要进一步研究.(5)编译如何根据存储级并行对指令进行调度,这部分研究工作尚未得到足够的重视.
