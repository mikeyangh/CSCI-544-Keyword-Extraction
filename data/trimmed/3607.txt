Page1普适计算环境中防护策略的信任决策机制研究魏志强1)周炜2)任相军1),3)魏青4)贾东宁1)康密军5)殷波1)丛艳平1)1)(中国海洋大学信息科学与工程学院山东青岛266100)2)(青岛理工大学计算机工程学院山东青岛266033)3)(青岛广播电视台山东青岛266000)4)(中国电信股份有限公司广州研究院广州510630)5)(南昌航空大学信息工程学院南昌330063)摘要普适计算信任模型中,存在自私用户为最大化自身利益而故意策略性谎报推荐信息的问题.文中提出了一种基于VCG(Vickrey-Clarke-Groves)机制的防护策略信任机制,用以获得用户的真实推荐.该机制实现了交互结果观测前的快速支付.一种基于连续多数加权算法的加权VCG防护策略机制被用于调整推荐权重.该文还给出了一般形式的信任决策机制并研究其激励相容特性以便可以构造更多的信任机制,这些信任机制结合已有的信任模型可以实现真实推荐.模拟结果显示,提出的信任机制有效,能保证自私用户提供诚实推荐.关键词防护策略;信任决策机制;机制设计;VCG机制;普适计算1引言由于移动设备的普遍应用,普适计算的设想已经变得越来越真实.普适计算应用中,用户以自组织方式聚集在一起,用户间并不存在先验知识,信任模型在动态构建用户关系中起了关键作用.在获知用户信任值的情况下,交互操作可被限制在具有良好信誉的用户间.当请求用户想从另一未知用户获得服务时,会向邻居用户征求有关服务提供者的推荐信息.如果计算得出服务提供者信誉度低于安全访问阈值,请求者将决定远离服务提供者,不与其进行交互.然而在普适计算开放环境中,移动设备及用户属于不同的所有人或组织,大量应用的激增更加剧了这种趋势.大部分实体仅关注自身的利益,其唯一目标就是最大化自身的利益,普适计算环境中这种实体的自私性导致信任模型在获取推荐信息时遇到了困难.一是由于不愿消耗自身有限的资源,自私用户不愿意提供推荐信息;二是推荐信息可能不真实,用户可能为“同伙”提供较高的推荐值或为潜在的竞争者提供较低的推荐值.这两种问题被称为被动攻击安全问题,极大地影响了信任模型的正常功能运作,而传统的安全解决方式并不能解决此类问题.为达到促使推荐者积极提供真实推荐信息的目的,需要对自私用户采取激励措施.考虑以下场景:在一个大型的电子消费展览会上,来自世界各地的参展者在整个大会期间时不时地随机相遇并交换最新歌曲、游戏以及消息等.由于一些用户可能在分享数据时传播病毒或者木马,信任模型被安装在参展者的移动设备上并从以往的直接交互记录及他人的推荐信息中计算每个用户的信任值.信任模型的作用是决定可以同哪些用户交互以及拒绝同不信任用户交互.以往很多普适计算环境中的信任模型往往假定推荐信息是真实的,这将导致用户在采纳很多虚假推荐后做出错误的交互决定并遭受巨大的损失.因此,非常有必要将激励机制应用于信任模型中促使推荐者给出真实信息.此外,参展用户共处交互的时间并不长,往往交换完数据或信息后就分开.此种情况下,很难让推荐者长时停留、等到观测实际交互结果与推荐信息是否一致时再给其激励积分.这就要求激励机制必须具有快速支付能力,推荐用户的激励积分须在实际交互结果可被观测前获得.为解决以上问题,本文借鉴经济学和政治学研究领域中的防护策略概念予以解决.在选举或者拍卖时,每个选举者(或者拍卖者)展现个人偏好,即给出优先的候选者(或者出售物品)的报价.基于所有个人偏好,机制进行公共决策,得到一个被称为社会选择的全局结果.防护策略特性是指机制做出的社会选择不能被某些用户通过策略性虚假展现个人偏好随意更改.实现防护策略特性的一种方法是设计鲁棒性机制,即使用户谎报个人偏好,社会选择仍无法改变,这样的机制被称作不可篡改或抵抗篡改的.另一种实现方法是通过提供用户激励以促使用户报告其真实信息,用户只有在展现真实个人偏好时才能实现个体利益的最大化.这种机制被称作激励相容机制.一般地,针对自私用户多采用设计激励相容机制的方法实现策略防护特性.本文中,通过将信任决策过程看作公共决策过程,提出一个信任机制用以获得自私用户的真实推荐信息.该机制是一种基于具有防护策略特性的VCG(Vickrey-Clarke-Groves)机制.在决策过程中,推荐请求者向若干推荐者征求意见,这些意见反应出推荐者对服务提供者的信任值,该信任值被看作是用户的私有信息.当获得推荐意见后,请求者给予推荐者一定的激励积分并依据所有推荐意见做出是否同服务提供者交互的最终决策.推荐者的收益包括两部分:一是估值,表示对决策过程结果的评估;二是来自请求者的激励积分.VCG机制保证推荐者只有在提供真实推荐信息时才能最大化自身的利益,因此对推荐者而言最好的选择就是暴露自己的真实信任值.推荐者在自己获取推荐过程中也可以使用积分激励其他用户提供真实推荐信息.文中提出的机制可以应用于连续信任值信任模型,也可以应用于二元离散信任值信任模型.此外,该机制也是一种快速机制,即积分是在交互结果可被Page3观测前支付.即使所有推荐者都提供真实推荐信息,也可能由于不同用户存在不同信任评价标准导致对服务提供者的信任值不如预期一样精确.本文应用连续多数加权算法(weightedmajoritycontinuousalgo-rithm)来调整不同推荐值的权重从而减轻由于评价标准不同而导致的不精确问题.本文还从博弈论的角度研究了一般性的信任决策机制,讨论了当信任模型导出的社会选择函数满足何种特性时存在激励相容的信任机制.应用该机制,原有的信任模型可以保证用户真实给出推荐信息.本文提出的基于VCG机制的防护策略信任机制可以被应用在很多已有的信任模型中,促使推荐者给出真实推荐信息.本文第2节简要介绍相关工作;第3节概述机制设计和VCG机制;第4节对基于VCG机制的信任机制进行详细的阐述;第5节对一般信任决策机制进行讨论;第6节通过模拟结果显示机制的有效性;第7节总结全文.2相关工作类似如何从推荐者处获得真实推荐信息,获得真实私有信息的问题还出现在在线评分系统、拍卖系统和专家预测系统领域当中.这里主要介绍在没有中心服务器的分布式环境中,信任模型方面的相关工作.文献[1]的信任模型采用可传递信任的概念,即提供优质服务的实体也被认为提供真实的推荐信息.然而,当其推荐被认为真实无误时,优秀的服务提供者也可能给其竞争者较低的评价.为了解决这种问题,许多信任模型将推荐信誉度同服务信誉度区分开,但仍无法从根本上改变推荐信息不真实的情况.当前有3种方式来解决推荐信息不真实的问题.第1类解决方法的目的是减轻虚假推荐造成的偏差.Yu等人[2]提出一种应用多Agent系统的信任模型,该模型应用D-S理论处理推荐反馈并应用连续多数加权算法调整虚假推荐的比重,从而将虚假推荐的影响降至最低.虚假推荐的判定是通过比较推荐信息与实际直接交互结果得出的.然而,该信任模型假定恶意推荐者始终保持相同的行为模式并且仅考虑4种欺骗方式.第2类解决方法通过识别恶意推荐者并对其惩罚或隔离的方法实现真实推荐激励.Liu等人[3]提出普适计算环境中的激励相容的beta信誉模型,该模型应用beta分布计算二元事件的后验概率.beta信誉模型同时考虑服务信誉度与推荐信誉度,前者通过服务提供者的声明与实际经验的一致程度计算,后者反映出推荐信息的帮助程度.通过这两种信誉度,实体被分成真实推荐者、恶意推荐者、懒惰真实推荐者、懒惰恶意推荐者和新用户几类.所有真实推荐者对待不同类推荐请求者的操作都是不同的,从而实现懒惰和恶意推荐者不能获得足够多且有效的推荐信息.尽管该机制十分有效,但仍然需要经历一段时间,懒惰和恶意推荐者才能被隔离,并不是真正意义上的激励相容,即用户必须每次给出真实推荐信息才不会被处罚.此外,该机制仅对二元信任模型有效.Chang等人[4]也提出了一种同时包含服务信誉度与推荐信誉度的模型.同文献[3]中一样,不同用户也被分类并接受区别对待,如针对恶意推荐者采用以概率形式提供推荐信息.该信任模型的问题是新用户容易被识别为懒惰用户并难以获得其他用户的推荐信息.前两类方法我们称之为启发式方法.启发式方法是有效的,但未必是最优的,即系统设计者无法通过形式化证明给出特定时刻的系统状态,只能保证经过一段时间后,系统趋向一个理想的较优态(大部分恶意节点被隔离或遭受惩罚).最后一类解决方法应用经济学中博弈论与机制设计的方法对自私用户进行分析并规范其行为操作.Papakonstantinou等人[5]提出一种基于恰当得分法则的机制从多个提供者处获取并融合评价值.该机制具有两个阶段,实现了激励相容与个体理性约束.然而,该机制需要中心服务器的存在而且支付是发生在实际结果观测之后的.Abrams等人[6]提出一种机制可以保证用户不提供虚假推荐信息,然而该机制仅能保证用户欺骗时不会获得更大的收益,不能保证用户诚实推荐时可以实现利益最大化.Jurca等人[7]提出了一种基于二元信任值的信誉模型,该模型也满足激励相容约束.一个被称作R实体的特殊代理者,向实体出售有关服务提供者的评价信息,并从其它实体那里购买其它的评价信息.购买时,代理仅在观察并获得到与报告一致反馈时才付给出售实体报酬.该方案的问题是实体可以因为服务提供者的表现改变而被认为报告不实.另外一个主要问题是仅适用于二元信任系统.Wang等人[8]提出了一种类VCG机制的信誉系统用以激励对等实体给出真实评价.该方案使用参考推荐网络来推断终端节点的可信度,网络既包含功能信任也Page4包含推荐信任.推荐的真实程度是由类VCG机制保证的,但该方案仅仅适用于可传递信任系统并且需要推荐网络支持.此外,文献[9]提出一种基于VCG机制的防策略攻击的信任模型,但该文献仅提供了概念模型,并没有给出实现细节,也没有对防策略攻击的性质进行证明.综上所述,在信任模型中的真实推荐信息获取方面,已有的研究成果仍存在一定局限性和依赖性,或者仅适用于二元信任系统,或者需要推荐网络的支持,或者不具有激励支付的快速性,并不能完全满足普适计算信任模型的策略防护性要求.3机制设计与VCG机制概述本节简要介绍机制设计与VCG机制的相关概念,更多内容说明可参考文献[10].机制设计研究的是如何设计一个博弈机制以实现期望的社会选择.社会选择是指整个社会群体性的选择结果,此结果由诸多独立博弈者通过表达各自偏好而聚集得出.社会选择结果反过来会影响每个独立博弈者的收益.如政治选举中,每个选民表达自己的意愿偏好,选择一位候选者当选,所有选民的偏好聚集在一起共同决定了哪位候选者当选,候选者上任后政策的实施会反过来影响选民的切身利益.从社会全局角度而言,希望达到所有个体成员利益之和最大.而从个体角度而言,只希望实现自己利益的最大化,个体可能通过谎报他人无法知道的私有偏好信息的方式达到操纵社会选择结果并获取更大自身利益的目的.激励机制中使用支付来促使个体用户真实报告其私有偏好信息.定义1.机制(mechanism).机制由两部分组成,一是社会选择函数(socialchoicefunction)f:V1×…×Vn→将个体偏好映射为社会结果,二是支付函数向量(p1,…,pn),其中pi:V1×…×Vn→代表个体付给机制的支付数额.定义2.估值函数(valuationfunction)、效用(utility)、支付(payment).个体偏好使用估值函数vi:A→表示,函数值vi(a)∈表示个体i在社会结果为a∈A时获得的价值.个体的利润用效用ui表示,是个体想要最大化的目标.效用的计算为ui=vi(a)-pi(vi,v-i),其中pi(vi,v-i)表示个体给机制的支付,由个体自身偏好和他人偏好v-i共同决定,也记作pi(v1,…,vn)或pi.定义3.激励相容(incentivecompatible)约束、个体理性(individualrationality)约束、防护策略(strategy-proof)约束.对于每个个体i及每个偏好v1∈V1,…,vn∈Vn,个体i报告真实偏好vi时社会结果为a=f(vi,v-i),报告虚假偏好vi时社会结果为a=f(vi,v-i),如果机制(f,p1,…,pn)对所有个体i满足vi(a)-pi(vi,v-i)vi(a)-pi(vi,v-i),则该机制满足激励相容约束.如果所有个体的效用始终非负,即ui0,则该机制满足个体理性约束.如果机制同时满足激励相容约束与个体理性约束,该机制被称为满足防护策略约束.在机制设计领域中,一个有名的激励相容机制是VCG机制,该机制的社会选择目标是最大化社会福利,即全体参与个体的价值估值之和∑i定义4.VCG(Vickrey-Clarke-Groves)机制.如果一个机制的社会选择函数和支付函数满足以下两个条件,就被称作VCG机制:(1)社会选择函数最大化社会财富,即(2)对所有社会成员偏好vi∈V1,…,vn∈Vn,支付函数满足以下形式:其中hi:V-i→是与个体偏好vi无关的函数.通过将支付函数定义成与个体偏好声明无关的形式,VCG机制实现了个体效用与整体社会财富的一致性,即个体仅在真实报告其私有偏好时才能实现个人效用最大化,同时实现社会财富最大化.如果社会选择函数允许赋予不同偏好权值,则被称作加权VCG机制.Clarke枢轴规则定义了hi(v-i)=maxb∈A∑j≠i付函数的形式为定义5.Clarke枢轴规则(Clarkepivotrule).pi(v1,…,vn)=maxb∈A∑j≠iClarke枢轴规则规定了每个个体必须支付当它参与和不参与时的社会财富之差,即它对其它参与者造成的损失.Clarke枢轴规则保证了VCG机制满足个体理性约束且支付值非负,即ui0和pi0.4基于VCG机制的防护策略信任机制4.1防护策略的信任机制本小节给出防护策略信任机制并证明其是Page5VCG机制.以共享音乐信息的普适计算应用为例,每个用户的移动设备运行信任模型,从直接交互与他人推荐结果计算出用户的信任值.信任值ti∈[0,1],是从区间[0,1]中任意取值的连续变量.由于信任值被当作私有信息,如无明确请求,个体用户间不会传递复制信任信息.当请求者向推荐者询问其对服务提供者的信任值时,推荐者将包含其私有偏好(即信任值)的推荐信息返给推荐者并获得一定的积分.基于从邻居用户获得的推荐值,推荐者做出基于服务提供者信任值的交互决策.当同服务提供者交互时,请求者分享所有其他用户对服务者的信任值以便服务提供者可以依据这些反馈意见进行服务改进.值得注意的是,文献[5]中推荐信息同时包括服务提供者的积极与消极观察结果,从多个推荐者获得的评估被认为是相互关联的并且不适合应用VCG机制.与其不同,本文中尽管推荐信息都与同一个服务提供者相关,但被看作不同推荐者的主观意见,因此这些推荐意见之间是相互独立的.在决策过程中,请求者合计自己对服务者的信任值tr与n个推荐值,得到一个总体信任值T,当总体信任值大于某信任等级时,请求者决定同服务提供者交互,反之不然.信任等级以λ表示,总体信任值的计算方式为其中ki,p,q分别是每个推荐、总推荐和自己信任值的权重,并且∑n由于请求者进行交互时,服务者会获得所有对它的评价.推荐者所给的推荐信息,尤其当其为较低信任评价时,会使自己面对由于服务交互而产生的风险损失,如服务提供者不共享音乐、对推荐者恶意低评或收取相应额外积分的报复.这种损失被看作一种成本,由线性成本函数表示其中μi,ηi用来描述推荐者对这种风险损失的重视程度.成本函数意味着推荐值越低,成本越高.这个假设是基于文献[8]中观测的事实:(1)较高的推荐并不会惹恼服务提供者,因此推荐者倾向于提供较高的评价;(2)真实的低分评价往往基于长期交互,需要较多经历才能获得;(3)给出低评时会有较高概率遭受报复打击.本文假设每个用户都采纳相同给定推荐的成本函数,每个推荐用户的推荐意的成本函数且为共同知识,即μi=μ,ηi=η.愿可用推荐意见vi表示,其计算方式为请求者获得的推荐信息实际指其推荐意见vi,而非原始的信任值.推荐者的估值函数vi(a)在请求者决定同服务者交互时等于vi,在决定不交互时等于0.由于推荐会给推荐者带来成本,请求者会付给推荐者一定的积分作为补偿,此时,作为由推荐者付给机制执行者(即请求者)的支付(payment)应为负值.推荐者的效用可以表示为ui=vi(a)-pi(v1,…,vn),pi(v1,…,vn)0当决定交互时,请求者的估值是固定值-C,C<0,当决定不交互时为0,C值的确定将稍后讨论.此时,包括请求者和推荐者在内的所有参与者的社会财富为∑i情况下分别等于∑i整个信任决策过程可被看作一个社会选择过程,其中所有推荐者表达个体推荐意见vi,并由请求者产生一个社会选择结果a,即同服务提供者交互或者不交互.将个体推荐意见映射成为社会结果的社会选择函数,表示为其中,I表示社会选择结果为交互,NI为不交互.为简化问题,假设请求者为每个推荐赋予同样的权值,即ki=k=1/n.值得注意的是,即使没有这个假设,该信任机制也是VCG机制.定理1.社会选择函数f(v1,…,vn)实现了社证明.将式(1)代入到社会选择函数f的条会财富的最大化.件中,得到依据式(3),条件可变为令Page6则考虑社会财富在交互与不交互两种情况下分别等于∑if选择交互的结果,达到更大的社会财富∑i当∑ivi-C<0,社会选择函数f选择不交互的结果,得到了较大的社会财富0.因此,式(5)中的社会选择函数实现了社会财富的最大化.证毕.在获得推荐信息做出决定后,请求者在与服务者交互前就将积分作为激励返给推荐者.由于不需要观测与服务者的交互结果,快速支付使得推荐获取效率大为提高,更适合于普适计算环境用户移动性的特点.给予的积分数值等于支付的绝对值,积分被存储起来用于推荐者以后从其他用户处获得真实推荐信息.由于估值及支付都是负值,Clarke枢轴规则不能直接应用于信任机制,根据其原理,支付函数定义如下:pi(v1,…,vn)=maxb∑j≠i其中K=C保证支付是负值.基于不同的意见声明(v1,…,vn)并考虑到vi<0,一共存在3种支付情形,如表1所示.支付类别用户i的角色Ⅰ非枢轴用户∑j≠iⅡ非枢轴用户∑j≠iⅢ枢轴用户∑j≠i支付类别估值vi(a)支付函数值pi(v1,…,vn)效用uiⅠⅡviⅢ依据不同个体声明意见间的关系判定每种情形.只有在第Ⅲ种情行下,推荐者i称为枢轴用户,如没有其参与,决策结果是进行交互,则maxb∑vi(b)=∑j≠ivj-C,如果其参与评价,请求者将决定不进行交互,则∑j≠ipi(v1,…,vn)=∑j≠i其支付为C.考虑到∑i者永远不会成为枢轴用户也不对自己进行支付.值得注意的是,在支付函数中,第n+1个用户指请求者,并且a=I,vn+1(a)=-C.定理2.信任机制(f,p1,…,pn)满足防护策略约束.证明.(激励相容约束)对于信任值为ti,推荐意愿为vi的参与者i,须证明其声明真实推荐意见vi时获得的效用大于声明虚假推荐意见vi时的效用.这种情况下社会结果为a=f(vi,v-i)和a=f(vi,v-i).给予真实推荐时效用为ui=vi(a)-pi(vi,v-i)=vi(a)-maxb∑j≠i∑ivi(a)-C-maxb∑j≠i为ui=vi(a)-pi(vi,v-i)=∑imaxb∑j≠i者的社会财富∑i立无关,所以ui>ui.(个体理性约束)考虑3种支付情形,注意到C<0和vi0,则在第Ⅰ和第Ⅲ种情形中效用是非负的.对第Ⅱ种情形,∑i∑j≠ivj-∑j≠i该机制满足个体理性约束.对于激励相容的信任机制,个体理性约束意味着如果一个推荐者做出推荐,不管决策结果如何,它都能从请求者处获得积分.这有别于标准拍卖机制中,如果竞标失败,不会发生任何支付.该性质可以激励推荐者分享其信任信息.4.2基于加权VCG机制的防护策略信任机制由于只有报告真实推荐值时才能最大化自身利益,推荐者的最佳选择就是诚实推荐,则请求者可认为所有理性推荐者所做的推荐都是真实的.然而,对于提高决策预测准确率而言仅仅满足真实性要求还不够,仍须考虑推荐者和请求者对服务者的信任判断标准.某些请求者认为不好的服务者从推荐者信任的标准来看可能是可信的,这就会出现这样的情况,即使所有推荐者都给出真实信息,信任预测结果对请求者而言还是不理想的.Page7为此,须考虑请求者与推荐者的信任判定标准的相似性并调整不同推荐信息的权值.这里采用多数加权算法(WeightedMajorityAlgorithm,WMA)的变型算法连续多数加权算法(ContinuousWeightedMajorityAlgorithm,WMC)来调整权值.WMA算法首先定义一次实验,在其中对于同一个实例,每个被称为目标函数的个体预测算法产生一个预测结果,一个设计的主算法为每个预测分配权值并将所有预测合计为一个总体预测.通过实际观测或计算,主算法得到一个结果,称作标签.所有权值通过乘上一个由个体预测和标签差异计算得出的因子实现更新.与WMA算法中个体预测与总体预测仅能取二元值不同,WMC算法允许从[0,1]区间进行取值.对于信任机制,每个推荐者的信任值可被看作个体预测,实例即特定的服务提供者,也叫做上下文.每次信任决策是一次实验,主算法是请求者计算总体信任的函数,标签是同服务者进行交互后观测计算的对服务者的直接信任值.令tsi表示第i个用户在实验s中的预测,ρs表示实验s的标签.由于每次涉及到的推荐者不同,主算法会不时发生改变,因此需引入绝对权值的概念,记作珔ω(i,k)(i=1,…,n),表示独立于主算法的推荐者i对服务者k预测的权值.初始时,所有绝对权值都设置为1.对于固定的主算法,令ωsi(i=1,…,n)表示相对权值或标准权值,主算法可表示成T=ωsit()si+qtr.在上下文k下,相对权值的计算为p∑ni=1令珔ω(s)(i,k)(i=1,…,n)表示实验s后的绝对权值.如果珔ω(s+1)请求者交互后得出的标签为ρs,则绝对权值以以下方式进行更新其中,θ是任何满足以下条件的因子βtsβ(0β<1)是固定因子.这里选择下界作为更新因子θ的值.由新的总体信任值计算方式T=p∑n得出的机制被叫作基于加权VCG的防护策略信任机制.可以看出,前面介绍的基于VCG的防护策略信任机制是当仅存在一次实验且对于任何主算法没对于加权VCG信任机制,式(5)中定义的社会有权值更新的特例情况.选择函数最大化的社会财富为∑i中C=μqtr-λμ着最大化那些较多推荐贡献(权值较大)的推荐者的估值之和.加权VCG信任机制中支付函数的定义为pi(v1,…,vn)=maxb加权VCG信任机制也是策略防护的,其证明请求者的估值是-C,而它付给所有推荐者的其中K=C为负值.过程与VCG信任机制一样,故此省略.4.3支付特性积分总和为-∑i付的积分总和一定不会小于其估值.-∑i定理3.当有不少于2个推荐者时,请求者支证明.考虑情行Ⅲ中两者间的大小pi-(-C)=-∑i∑j≠i考虑到此种情形下∑i两个推荐者时大于0.在情形Ⅰ和Ⅱ时,当有不少于两个推荐者时,-∑i此结论成立.支付的积分总和与估值之差可被看作推荐获取过程的成本.该差值实际是由支付函数的形式决定.实际上,由于支付函数是由社会选择函数唯一决定的,不存在可以消除差值的支付函数.在文献[10]中证明了如果社会选择函数最大化了社会财富,则使机制满足防护策略约束的支付函数一定等同于依据Clarke枢轴规则得出的支付函数.5一般信任决策机制5.1信任决策机制的一般形式下面从博弈论的角度给出信任决策机制的一Page8般形式.定义6.信任决策机制(TrustedbasedDeci-sionMechanism,TDM).对于n个参与人,信任决策机制包含以下部分:Xn→A;(1)参与人的私有信任值空间T1,…,Tn;(2)参与人的意见空间X1,…,Xn;(3)参与人的判别策略函数si:Ti→Xi,该函数决定当信任值为ti时所要报告的意见;(4)决策集A包含所有可能的决策结果;(5)参与人的估值函数vi:Ti×A→;(6)用于做出决策的决策结果函数a:X1×…×(7)支付函数p1,…,pn,其中pi=X1×…×Xn→.需要注意的是,TDM的一般形式中,参与人意见空间为k维的欧几里德空间,即xi=(pi1,…,pik),pi1,…,pik∈,其中pi1,…,pik代表k个相互独立的信任评估参数.例如,2维意见定义为xi=(Si,NSi),其中Si表示同特定服务提供者的成功交互次数,NSi为不成功次数.定义7.推荐游戏.对于给定的一个TDM,其对应的推荐游戏由信任值空间Ti、意见空间Xi、判别策略si和效用函数ui:Ti×Xi×…×Xn→共同组成,其中意见xi可看作参与者i的私有信任值为ti时采取的行动.如果对于所有的ti、si和x-i,ui(ti,si(ti),x-i)ui(ti,si(ti),x-i)都成立,则判别策略si叫做占优策略.如果每个参与者的判别策略都是占优策略,则策略组合s=(s1,…,sn)被称作占优(策略)均衡.定义8.信任决策函数(TrustbasedDecisionFunction,TDF).信任决策函数g:T1×…×Tn→A合计个体的信任值并做出一个(交互)决策.TDF是信任合计函数h与决策决定函数ψ的复合函数,其中信任合计函数h:T1×…×Tn→T将个人信任值合计为总体信任值,决策决定函数ψ:T→A依据总体信任值做出决定并给出社会结果.定义9.实施.给定一个TDF,如果在一个TDM对应的推荐游戏中,存在某个占优均衡s=(s1,…,sn),使得对于所有的信任值t1,…,tn,g(t1,…,tn)=a(s1(t1),…,sn(tn)),则称TDM实施了TDF,或TDF可由TDM实施.信任决策机制设计的目的就是构造一个TDM,使其以下列方式实现TDF的实施:令n个参与人加入推荐游戏,报告各自的意见并接受支付.具有私有信任值的理性参与人选择一个合适的判别策略以实现效用的最大化.如果所有参与人选择占优策略并导致占优均衡,基于报告的意见,一个预定义的结果函数导出一个结果.那么,该结果一定同TDF以私有信任值为输入得出的结果完全一致.下面以基于VCG的防护策略信任机制为例阐明信任决策机制的设计.在信任信誉系统中,需被实施的TDF定义如下:信任合计函数如式(1)中所示,是一个加权求和函数,决策决定函数是一个简单的二元决策函数,当总体信任大于阈值时选择二元中的一个结果,否则选择另一个结果.此外,还可以类似的方式构造多元决策决定函数.根据上节的描述,实施式(12)中TDF的基于VCG的信任决策机制可以如下构造:信任值空间Ti和意见空间Xi都是取值范围为[0,1]区间的一维参数,意见xi的值等于式(3)中计算的vi值.每个参与人的判别策略si都相同且为共同知识,也由式(3)定义.值得注意的是,基于VCG的信任决策机制中,判别策略是基于内源的风险成本给出的.在其它信任决策机制中,可以由其它的策略或者机制实现.参与者可以选择欺骗判别策略si而非真实判别策略si,就其私有信任值欺骗请求者,比如si(ti)=si(0.9ti).结果函数等同于以下社会选择函数:最后,支付函数如式(7)中所示.一般形式的信任决策机制是一种非直接显示机制,这是因为仅有参与人的行动可以被观测到,而不是其内部状态,即私有信任信息.而满足激励相容约束的信任机制是一种直接显示机制,因为报告的估值直接表示其内在状态.但当对于一般形式的信任决策机制存在占优均衡时,每个参与者可以不考虑其他人的内部状态而进行选择.这就意味着在一般形式的TDM实施TDF与信任决策满足激励相容约束间存在着对应性,这种对应性称作信任机制的显示原理.定义10.社会选择函数.当判别策略si对每个参与人是公共知识时,对应的社会选择函数定义为TDF与逆函数s-1i的符合函数,即f=gs-1i:V1×…×Vn→A,f(v1,…,vn)=(gs-1i)(v1,…,vn)=g(s-11(v1),…,g(s-1n(vn)).Page9由于信任机制显示原理同普通机制显示原理的命题1.信任机制显示原理.如果存在一般性的TDM以占优策略实施了TDF,那么就存在一个满足激励相容约束的信任机制实施了对应的社会选择函数.激励相容信任机制中的支付函数与TDM均衡中得到的支付函数等同.证明[10]十分相似,故此省略.5.2激励相容信任机制特性本节讨论信任决策机制的特性,特别的,考察哪些TDF可被TDM以占优均衡的方式实施,这样的TDF被称作是可实施的.根据信任机制显示原理,这个问题等同考察哪些对应的社会选择函数可以被激励相容信任机制实施.社会选择函数的可实现性取决于函数的输入域,即偏好Vi的取值域.对于不同的偏好取值域,可实施的特性是不同的.对一个k维偏好狏i=(pi1,…,pik),如果pi1,…,pik可取任何实数值,偏好取值域Vi被称作非限制域并记为Vi=限制条件,偏好取值域被称作受限域.如果整个偏好向量狏i完全由一个参数决定,偏好取值域称为单维域,单维域是一种受限域,因为仅有一个保留参数,其它参数不允许取任何值并都被TDF忽略.在基于VCG的激励相容信任机制及其它很多信任机制中,参与人的偏好是单维域,也称为单参域.定义11.单参域.令集合IA表示共知的交互集合,该集合中的结果元素表示同服务提供者进行交互.单参域Vi由集合I与取值范围[s0,s1]定义.Vi是满足如下条件的vi的集合:对所有a∈I,vi(a)=s,s0ss1,对所有的aI,vi(a)=0,即Vi={v1|vi(a)=s∧a∈I∨vi(a)=0∧aI}.由于信任决策机制与普通机制的特性是等同的,这里引用普通机制中的可实施特性理论加以说明.单参域的可实施特性由文献[10-11]给出,特性包括对社会选择函数与支付函数的要求:信任机制(f,p1,…,pn)满足激励相容约束的充要条件为:(1)对每个vi社会选择函数f满足单调性要求;(2)如果结果a∈I,每个枢轴用户须给予关键值数量的支付.非限制领域上的可实施特性由Robert规则[12]给出,值得注意的是,Robert规则考虑的拍卖与选举的场景下,社会结果的基数与个人偏好的基数需相同,而信任决策机制中,不存在这种要求.对于非限制域与单参域间的受限域的特性,依据偏好取值域的不同,特性也随之不同,普通机制特性的部分结果可以在文献[13-14]找到.通过研究可实施特性,如果社会选择函数满足这些要求,则可以设计出一个实施其的激励相容信任机制.因此,如果以特定的信任模型为目标,希望信任模型的推荐者都真实报告其私有信息,首先依据目标信任模型中的信任合计函数与决策决定函数构造TDF,其次检验TDF对应的社会选择函数是否满足可实施特性,如果满足,则可以构造一个满足激励相容约束的信任机制,将其与目标信任模型结合以实现真实信任推荐的目的.6模拟验证较以往无法确定特定时刻系统状态、有效但未必最优的启发式解决方法而言,基于机制设计的VCG信任机制可以保证对自私用户,系统始终处于最优状态,即任意时刻系统内所有诚实用户实现占优均衡,且社会财富始终最大化,理论上说明了机制的最优性.限于篇幅,本节主要通过模拟实验结果显示机制的最优有效性.验证应用JIST/SWANS[15]模拟器对普适计算环境底层的移动自组织网络(MobileAdhocNetworks,MANETs)进行模拟.模拟面积为400m×400m的场所中包含40个用户节点,移动性以最低速2m/s、最高速10m/s的随机路径点模型表示.节点都被编号,21号节点和30号节点为服务提供者,19号节点为请求者,1号到10号节点都是推荐者且只有1号为欺骗节点,策略性地给出虚假推荐.所有虚假推荐意见的偏差类型总结在表2之中,如2型偏差指节点1的汇报意见比其真实信任值高0.1.节点的汇报意见比真实信任值高的偏差叫做积极偏差,比真实信任值低的偏差叫消极偏差.模拟中各种参数的取值分别为μ=-1,η=1,λ=0.6,p=q=tr=0.5和n=10.类型123456首先评估信任机制对应不同类型推荐偏差时的情况.每次实验中,请求者向所有推荐者咨询服务提供者的信任值,欺骗节点选择一种偏差类型给出虚假推荐.一组共11次实验,在第1次中随机产生推Page10荐者的信任值并保持该值在其后的每次实验中不变.如图1显示,欺骗节点在采取积极偏差策略时,其获得的效用减少而遭受损失.在这组实验中,当节点真实推荐时,是第Ⅲ种支付情形且判定条件为∑ivi-C<0,积极偏差策略使判定条件变成∑iC0从而变成第Ⅱ种支付情形.图2显示另一组实验,在这组实验中欺骗节点在采取消极偏差策略时,因其获得的效用减少而遭受损失,采取消极偏差策略使支付情形由第Ⅱ种变成第Ⅲ种.这两组实验表明无论欺骗节点采用积极还是消极的偏差策略,效用都可能由于虚假推荐而减少.由于支付情况的判定还依赖于其他推荐用户的意见,对于节点用户,最好的选择就是进行真实推荐.在每一次推荐中欺骗节点都不可能通过虚假推荐获得更多的效用,因此它也不能通过在多次推荐中进行策略性的欺骗(如时高时低)获得更大的利益.下面评估欺骗节点采取组合策略多次欺骗时的情况.欺骗节点对相同的服务者采取相同的偏差策略.在每次实验中,欺骗节点进行10次推荐,并计算获得的总效用.一组共11次实验,在第k次实验中发生k次欺骗,且每组信任值随机产生并在11次实验中保持不变.一共进行了10组实验以获得平均值,图3中显示多次策略性欺骗时获得总效用的平均值,结果显示,欺骗节点虚假推荐的次数越多,获得总效用的平均值越少.考察与请求者估值相关的C值随其它参数如信任等级λ和推荐权值p的改变而变化的情况.C值会影响推荐者在第Ⅰ和第Ⅱ种支付情形下的效用以及请求者推荐获取过程的成本.为保证请求者的效用为正,C值必须为负,这限制了参数λ和参数p的取值范围.以下实验中n等于10,tr等于0.5,即请求者对服务提供者采取中立态度.首先,固定除信任等级λ外的其它参数.从图4中的结果中可以看出,C值与λ值成正比且当p为0.5时λ的上限值为0.75.固定除推荐权值p外的其它参数,从图5中可以看出,C值随着p值的增加而逐渐减少且当λ为0.6时p的下限值为0.2.在C值为负的限制下同时改变参数λ和参数p,从图6的结果中可以看出,当p值减小时,由于λ的上限越来越小而下限不变,λ的取值范围变小了.相反,当参数λ值增加时,p的取值下限取值范围变大而上限不变,p的取值变小.当参数λ和参数p都取值为1时,C值取得最大值0,当λ值为0时,p值越小C值也越小.图4C值随参数λ变化的演化情况(p=0.5)图5C值随参数p变化的演化情况(λ=0.6)Page11图6C值随参数λ与参数p变化的演化情况7结论本文提出了一种基于VCG机制的防护策略的信任机制,该机制可使连续或离散二元信任值信任模型中的推荐者实现真实信任推荐.该机制中,信任决策过程被看作一个社会选择过程,自私用户只能在提供真实推荐时实现自身效用的最大化.一种基于WMC算法的加权VCG信任机制被用于实现更精确的信任预测.本文从博弈论的角度给出了一般形式的信任决策机制,并研究机制设计者如何构造一个信任决策机制.通过研究激励相容信任机制的可实施特性,如果从目标信任模型中得到的社会选择函数符合特性要求,那么就可以设计出一个满足激励相容约束的信任机制,结合目标信任模型实现推荐者的真实推荐.模拟验证表明信任机制对积极偏差和消极偏差及策略性欺骗都有效可行.下一步的工作目标包括在实际普适计算应用环境中验证机制的有效性及找到更多种类的激励相容信任机制,由于本文的信任机制仅对存在单个欺骗用户时有效,研究团体防护信任机制也是下一步的研究方向.
