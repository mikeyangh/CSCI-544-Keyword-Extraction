Page1云服务传递网络资源动态分配模型史佩昌1)王怀民1)尹刚1)刘雪宁2)袁小群3)史殿习1)1)(国防科技大学计算机学院并行与分布处理国家重点实验室长沙410073)2)(清华大学计算机科学与技术系北京100084)3)(华中科技大学电子与信息工程系武汉430074)摘要云服务传递网络(CloudServicesDeliveryNetworks,CSDN)在Internet之上构建了一层分布式服务器网络,以就近和按需的方式向用户提供云传递服务.面对互联网规模化和多样化云服务的资源需求特点,CSDN形成了针对不同类型云服务传递的逻辑子服务器网络.CSDN的很大一部分服务器和带宽资源用于流媒体和下载类云服务的传递,该类型云服务传递资源的动态分配问题是该文的研究重点.根据该类型业务内存资源和带宽资源同为瓶颈资源以及该类型热点内容可采用P2P机制的两个特点,文中首先将该问题建模为多维设备选址模型.然后在对该建模分析及其NP完全性证明后,提出了一种启发式模型求解算法.最后以服务传递开销节省作为性能评价指标,以实际系统的运行数据为输入,全面评估了该模型求解算法的有效性.关键词云服务;传递网络;协同;对等网络;动态分配1引言云服务是指以服务的形式在互联网中传递的各种应用[1].云服务传递网络(CloudServiceDeliveryNetworks,CSDN)由内容分发网络(ContentDeliveryNetworks,CDN)演化而来[2].CSDN兼具传统CDN和云计算的双重优势,即就近服务和按需服务[3-4].CSDN在因特网之上以多个独立异构CDN协同的方式[2]构建了一层全局虚拟覆盖网,覆盖网中的元素是地理分布的服务器.用户在请求云服务时,CSDN将用户请求重定向至最靠近用户且具有足够服务能力的服务器节点,由其就近向用户提供按需服务.不同类型的云服务所表现出的用户访问行为以及资源需求特点各不相同.CSDN将物理服务器网络划分为针对缓存类应用、流媒体和下载应用以及动态应用等多个逻辑子服务器网络[3],如图1所示.其中缓存应用网络(CacheApplicationNetworks,CAN)包括静态页面、大小图片等的分发;流媒体和下载应用网络(StreamingandDownloadApplica-tionNetworks,SDAN)包括流式和下载式流媒体以及各种软件升级包的下载等;动态应用网络(DynamicApplicationNetworks,DAN)包括网络购物、网络游戏和社交网站等需要与源服务器交互的网络应用.图1中源服务器负责存储并依据策略向CSDN节点传输源内容,逻辑服务器覆盖网根据不同类型云服务需求从物理服务器覆盖网络中动态选择和构建而成.每个逻辑子服务器网络中服务器位置和数量如何选择,即CSDN资源的动态分配,主要依据所传递业务的用户访问请求分布以及CSDN系统对性能和开销等的需求.其本质属于服务器选择问题[5].从理论层面看,服务器选择与服务器部署[6-10]的模型类似.服务器部署一直以来都是学术界和工业界关注的热点和难点,现有的研究也产生了众多有价值的成果.但随着云服务种类和规模的飞速增长,CSDN的基础架构、用户访问规模和行为、服务分发模式、性能和开销需求以及CSDN的瓶颈问题等都发生了复杂的变化.传统服务器部署的理论研究成果难以完全满足目前条件下CSDN的服务器选择需求.本文按照问题建模、模型分析、模型求解和评估的思路对服务器选择问题进行了建模并提出了求解算法,同时以服务传递开销节省作为性能评价指标,以实际系统的运行数据作为输入验证了该求解算法在解决CSDN中资源动态分配的有效性.本文主要贡献体现在如下4个方面:(1)通过分析多种互联网传递业务资源需求特点,从与CSDN传递业务类型的特点相关联(如DAN中计算和带宽是瓶颈资源、SDAN中内存和带宽是瓶颈资源等)的特殊视角,以SDAN为研究对象展开对CSDN中SDAN类业务服务器资源动态分配问题的研究;(2)通过分析SDAN类热点内容传递中内存资源是瓶颈以及SDAN中内容可P2P的双重特点,从理论层面将CSDN中资源动态分配问题(如不做特别说明,本文的资源动态分配问题主要指面向CSDN中SDAN类业务的资源动态分配问题),即服务器的动态选择问题建模为多维设备选址模型(Multi-dimensionalFacilityLocationModel,MFLM);(3)通过对MFLM模型的分析和NP完全性证明,提出了针对SDAN类业务的一种启发式求解算法;(4)提出了针对MFLM的性能分析模型,并对MFLM求解算法的有效性进行了全面的评估分析.因此本文综合了CSDN服务器选择问题的本质变化,并以设备选址模型为基础,建立了解决这类问题的模型并给出了启发式求解算法.本文第2节提出和定义服务器选择问题,并对两种代表性理论模型进行综述;第3节对问题建模,提出云服务传递网络资源动态配置模型———多维设备选址模型,并对模型复杂性进行分析;第4节根据对多维设备选址模型的NP完全性分析,提出针对该特定类型云服务传递的启发式求解算法;第5节提出针对MFLM的性能分析模型,并以实际系统运行数据为输入,对MFLM启发式求解算法进行全面的评估分析;最后总结本文并展望下一步的研究工作.Page32服务器选择问题和相关理论模型2.1问题的提出和定义传统服务器部署问题是CDN领域的研究热点和难点,也是一个学术界和工业界普遍关注和公知的经典问题.服务器部署侧重于物理服务器的选址[10-11]研究,其中如何选择地址和如何确定在哪个地址部署多少服务器等是相对静态的问题,因为物理服务器拓扑网络一旦形成,再次改动的复杂度和开销都非常高.如CDN领域最具代表性的Akamai网络中服务器规模2010年已达73000台,并且跨70多个国家和1000多个网络[12],已经有了相对稳定和成熟的拓扑结构,很难大规模改动或重新部署.因此逻辑层面服务器的动态选择,即服务器资源的动态分配和物理服务器的增量部署更有研究价值.所谓物理服务器的增量部署是指如何根据现有的物理服务器网络,通过适当增加部分服务器的方式大幅提高分发网络性能.如文献[2]中提到Huang等人认为与Akamai具有不同物理服务器覆盖网络的Limelight系统,如果在合适的位置增加9个大服务器节点,其性能从平均响应时间来看可以与Akamai接近.本文重点研究服务器的动态选择,即以当前的物理服务器网络拓扑为前提约束条件,根据CSDN分发业务的动态需求,从物理服务器网络中动态选择部分地理位置分布的服务器形成一个专门针对该服务分发的逻辑子服务器网络.该子分发网络可依据业务需求的动态变化而演化.因此服务器选择问题可定义如下.定义1(CSDN的服务器选择问题).CSDN根据不同类型云服务的资源需求,以服务性能和开销等为指标,从物理部署的服务器覆盖网络中动态选择部分地理分布的服务器形成逻辑子服务器网络.服务器选择问题的实质是从何处选多少服务器资源构造逻辑子网络.难度体现在:服务器的选择如何在性能和开销之间取得一种很好的均衡.服务器选择也可看成是一个资源动态分配的过程,选择或分配的结果是在物理部署的CSDN有限服务器网络资源约束下,针对不同类型的应用构建若干个分布式的逻辑子服务器网络.如图1所示,针对当前各种类型分发业务资源需求的不同特点,物理CSDN服务器网络在逻辑层面被划分为多个逻辑子服务器网络.如对延迟和丢包敏感的缓存应用类;带宽和缓存资源容易成为瓶颈资源的流媒体和文件共享;实时性要求较高的动态应用等.子逻辑覆盖网的动态构造问题,即服务器选择问题.其中根据经验,将被请求内容按其热度降序排序,则Zipf分布中”非长尾部分”的高热点内容大约是CSDN单服务器节点缓存能力的数倍至几十倍,实际系统中存在单个热点文件的大小超过单台服务器内存资源4倍的现象①.因此为了确保不会发生频繁的缓存不命中而影响用户的访问延迟(Patterson等人[13]认为硬盘的延迟大约在5ms~35ms,内存的延迟大约在52ns~225ns,两者之间的差距高达5~6个数量级)和进一步引发磁盘I\O瓶颈,我们将缓存资源作为瓶颈参数之一.2.2相关理论模型从理论层面服务器选择问题和服务器部署问题类似.文献[11]从数学建模角度,将服务器部署模型划分为基于确定信息、基于概率模型和基于博弈论等多种模型.本节重点综述与本文问题最密切相关的两种基于确定信息的经典模型,以帮助我们理解后面的问题建模、模型分析以及模型求解和验证.2.2.1设备选址模型[7,10-11]设备选址问题定义如下:给定一个地址集合L={i}和用户集合U={j},地址i表示设备可能被放置的位置.在位置i处放置一个设备引发的成本为fi.每个用户j必定会被指派给离其最近的一个设备,这将引发的成本标记为dj×cij,其中dj表示来自用户j的需求,cij表示位于地址i处的设备和用户j之间的网络距离.目标是:发现一种解决办法(如确定所选择的位置和部署在位置中的设备数),在服务所有用户的情况下使上述成本总和最小,即其中∑i∈L∑j∈Udjcij表示边际运营成本,与动态变化的用户需求和采用设备选址模型系统的映射算法[3]等相关.2.2.2最小K中值模型[7,11]最小K中值问题定义如下:给定n个设备,用集合F={i1,i2,…,in}表示,从其中选出k个设备组成集合S={s1,s2,…,sk}.用户用集合U={j1,j2,…,jm}表示,然后指派用户j到离其最近的设备.如果用户j已经被指派给设备i,则引发开销dj×cij,其中dj表示来自用户j的需求,cij表示设①ChinaCache.http://www.chinacache.com/Page4备i和用户j之间的网络距离.目标是选择k个设备,最小化分配代价总和,即找一个集合S,其中SF,且|S|<k,使得上述两个模型之间的区别体现于两点:(1)最小K中值模型中设备无初始化成本;(2)最小K中值模型对所选择的设备个数增加了一个上限k.2.3其它相关研究近年来有关服务器选择或部署等服务器资源分配的研究有很多:Li等人[6]从用户体验角度,提出一种基于结构树的节点部署模型,并设计了一种复杂度为O(N2M)的搜索算法.其中,M和N分别为选择节点和被选节点数.该模型只考虑了节点与用户之间的流量和延迟;Qiu等人[7]将无Peer辅助的静态服务器部署问题建模为最小K中值问题,并提出了很多简单高效的贪心算法,部署决策的依据主要有用户延迟、请求速率和负载等.文献[10]将该类问题提炼为经典的设备选址模型,以用户的连接开销作为主要衡量指标并部分地考虑了物理服务器的一次性投入成本.并在文献[14]中证明了该问题为NP完全问题.此后围绕这类NP完全问题的启发式求解算法展开了很多研究.由于本文解决多维设备选址问题的思路基于SDAN特例,因此本文暂不对大量的启发式求解算法进行综述.Presti等人[15]综合考虑了用户请求重定向问题和服务器动态部署问题,依据分布式和局部机制以较低开销和复杂度实现了服务器的动态部署.针对服务器数量,服务器的利用率以及最优服务器和新增或新删除服务器间的距离等之间给出了一种有效的折衷方法.文献[5]提出了一个分布式系统DONAR,传统服务器选择方法或者基于高可靠和低可扩展的集中式协同方法,或者依赖于次优的甚至不稳定的请求分配的分布式启发式方法.而在DONAR中,通过在分布式节点中运行简单、高效的局部协同决策机制,为客户请求做出服务器选择决策.DONAR的优势不仅在于稳定和高效,而且综合考虑了用户的性能和服务器的负载.上述相关研究有两个鲜明的特点:(1)有效解决了不考虑Peer辅助情况下的服务器选择问题;(2)不适用于Peer辅助下引入新瓶颈参数的服务器选择问题.有关P2P场景中服务器选择问题和考虑计算资源瓶颈参数的相关研究有:文献[16-17]提出了非CDN架构下P2P系统中服务器的部署算法;Oppenheimer等人[18]在非Peer辅助的真实系统中对服务器部署算法进行验证,指出CPU应该作为服务器部署问题中除带宽资源之外的重要瓶颈参数;Relan等人①对非Peer辅助情况下引入CPU瓶颈参数的服务器部署模型进行了研究.在CSDN中动态应用类逻辑子服务器网络构造适用于引入CPU瓶颈参数.但SDAN的瓶颈更在于内存资源.DONAR[5]基于CoralCDN提出将服务器负载考虑在内,但仅考虑了服务器的带宽负载,没有考虑内存成为瓶颈时多参数服务器选择.综上现有相关研究,尚没有适合针对SDAN这种需要Peer辅助和引入内存瓶颈参数的CSDN服务器部署问题的理论模型和求解算法.本文剩余部分如不作特别说明,CSDN资源的动态分配等同于针对SDAN类特定云服务的逻辑子服务器网络的动态构造,即服务器选择.3CSDN资源的动态分配问题本节我们将CSDN服务器资源的动态分配问题建模为多维设备选址问题.如图1,CSDN的3个逻辑子服务器网络分别负责3种不同类型云服务的传递.其中SDAN有3个不同于其它逻辑子服务器网络的特点,使得优化其资源动态分配,对整个CSDN显得尤为重要.特点1,SDAN所分发的流媒体和大文件下载占据了互联网的大部分流量,一些机构如思科预测此类流量2014年在互联网流量中的比例将达到91%②;特点2,SDAN类业务可以采用P2P的方式降低服务器的负载,这与其它根据用户需求线性增加服务器资源的分配模式有本质不同;特点3,SDAN所分发内容中的热点内容大小远超过某CSDN服务器节点中多台服务器的内存总和.本文将服务器内存使用作为CSDN的新瓶颈参数引入到设备选址模型中,该参数的引入改变了传统的CDN调度机制:如果用户请求热点内容,但该热点内容并没有被缓存在内存中,而且该节点的内存资源已经不够用,这种情况下,即使带宽资源有剩余,也会将当前的部分用户请求指派给临近缓存有该热点内容的服务器节点,目的是避免频繁的缓存不命中,从而降低CSDN的服务质量和效能.①②Page53.1问题建模本节我们将CSDN的资源动态分配问题建模为多维设备选址模型MFLM.MFLM在经典设备选址模型[10]基础上,将内存资源作为CSDN资源动态分配的新增参数.同时鉴于SDAN所分发业务可采用Peer-to-Peer方式,热点文件对服务器资源的需求并不与用户请求数成正比.MFLM问题定义如下.定义2.多维设备选址问题.给定CSDN服务器节点集合L={l1,l2,…,lT}和服务器集合S={s1,s2,…,sN}.其中每个服务器节点中包含S中的若干台服务器,任一服务器j的额定带宽能力为Nj,额定内存大小为Cj.所有地理分布的用户用集合U表示.根据用户的分布和用户的请求,从地理分布的CSDN各个服务器节点中自适应地选择数目不等的服务器,来响应用户的请求.CSDN大文件的传递中,缓存命中率是影响传输性能的一个重要因素,现实中缓存高热点内容的内存资源已经成为瓶颈资源之一.因此缓存的使用参数cj已经被整合到了服务器选择的成本中,即有时即使服务器带宽资源有剩余,也可能会将用户请求重定向至其它缓存所请求文件的节点.选择一个服务器的运行成本为fj,假设用户i被指派给服务器j,则用dij表示用户与服务器之间的网络距离.MFLM的目标是:发现一种资源动态分配方法,在服务用户和控制成本开销之间给出一种均衡,即在保证用户服务质量的前提下,最小化总的资源分配成本:Min∑j∈L其中|Sj|表示在节点j处选择的服务器数目,bi表示用户i的带宽需求,因采用P2P机制引起的用户资源需求削减因子为γi(0γi1).多维设备选址模型与设备选址模型之间的本质不同在于前者引入了内存参数,并且针对热点文件用户采用P2P机制,导致用户对服务器资源需求的下降.P2P的引入对MFLM模型而言没有本质的影响,仅对用户数和资源需求之间关系的影响较大.引入P2P的方法和采用P2P后对CSDN系统性能和开销等方面产生的影响等细节问题在后续工作中进行深入研究和探讨.3.2MFLM模型分析定理1.CSDN中MFLM问题是NP完全问题.证明.下面分两步来证明MFLM问题是NP完全的,首先证明MFLM是NP问题,再证MFLM是NP难的.算法.步1.MFLM问题属于NP问题.给定一个带权重的图G=〈V,E〉,其中顶点由n个服务器和m个用户构成.每个用户i的带宽需求为band(i),内存需求为cache(i),每个用户i都需要被指派给某个服务器j.这个指派带来的连接成本为band(i)×cache(i)×dij,其中dij表示用户i与服务器j之间的网络距离.每个服务器j的内存上限为Cj,带宽上限为Bj.并且部分请求热点文件的用户,由于采用P2P机制的原因,需在原有的基础上按比例减少其带宽和内存需求,假设削减因子为γ(0γ1),则总成本降低为原来的γ倍.A是将所有用户指派给服务器后的总开销.问题是给定的指派中是否存在总开销为A的方案?假设T=“非确定性图灵机”,输入为n个服务器构成的集合S、m个用户组成的集合U和A的猜测函数f.函数f可确认给定的指派方案的总开销是否为A.如果确定成功,则停止;否则继续.因此至少在给定一个用户到服务器指派的情况下,可以在多项式时间内确定其总开销是否为A.因此MFLM问题属于NP问题.步2.MFLM问题属于NP难.假设存在可求解MFLM问题的多项式时间算法T.那么一定可将上述算法简化后用以解决FLP(FacilityLocationProblem)[14]问题.即将内存约束去掉,用户到服务器的指派仅依赖于带宽和距离两个限制条件.因此FLP问题能用MFLM的多项式时间算法T在多项式时间内求解.然而文献[14]中证明FLP是NP难的,因此MFLP也是NP难的.综上步1和步2可知,MFLP是NP完全问题.推论1.CSDN中的MFLP问题无任何近似证明.因为MFLP问题是NP完全问题,因此MFLP有近似算法的前提是P=NP.然而P是否等于NP是非确定性的多项式复杂程度问题.因此CSDN中的MFLP问题无任何近似算法.解决NP完全问题的途径有5种,本文考虑针对SDAN中peer有贡献,且内存资源成为继带宽资源之外的瓶颈参数这一特定问题进行启发式求解.4MFLM模型启发式求解算法MFLM是NP完全问题,因此没有针对该问题的一般性方法.本节我们通过增加一些前提假设和Page6约束改变,针对SDAN逻辑子服务器网络动态构造的特例,给出相应的求解方法.本节求解算法所涉及的假设,均建立在CSDN系统实际运行状况的基础上.4.1算法求解的相关基础网络资源可动态配置的相关基础.为了便于理解问题,本节我们首先介绍CSDNCSDN物理服务器的分布信息.MFLM的目的是在当前物理服务器网络中按需动态选择服务器构造逻辑子服务器网络,因此CSDN的服务器节点地理位置信息、每个节点中服务器的数量、服务器节点间网络距离等有关信息是解决MFLM问题的必要条件之一.CSDN用户的分布信息.通过查询用户的IP地址,确定用户所在的区域.这是用户请求重定向的基本依据.一般在确定用户所在区域和负责该区域的CSDN服务器节点后,理论上重定向机制会将所有属于该区域的用户重定向至该区域的CSDN服务器节点.即由最靠近用户的服务器服务用户,符合CSDN就近服务的原则.如果该节点有足够的服务能力,则该区域所有用户都由该节点的服务器服务.如果该节点没有足够的服务能力响应该区域中的所有用户请求,则在其它一些调度机制的作用下,该区域的部分用户将被重定向至其它服务器节点.重定向机制.直观而言,重定向机制就是确保用户请求总是被最靠近用户的服务器响应.实际系统中重定向的依据主要包括用户和服务器之间的网络距离是否最近,服务器可用的带宽资源是否可满足当前的用户需求.在MFLM中,内存的使用也成了重定向的依据,即在请求热点文件时,仅有足够的带宽资源和用户与服务器之间的网络距离这两个参数还不足以决定用户会被某服务节点中的服务器服务.提高缓存命中率的内存资源也被作为重定向的一个瓶颈参数.同时在特例SDAN中,由于P2P机制被引入到高热度文件的分发,因此重定向的依据参数变的更加复杂.此外还有其它一些不确定变量,如单个服务器的带宽服务能力和内存服务能力、单个用户的需求、热点文件的界定、热点文件的大小等相关信息.在后续算法中会对这些变量进行讨论.4.2多内存协同算法MFLM在经典设备选址模型中引入了内存使用作为热点文件分发的一个瓶颈参数,因此如何进行多个服务器节点的内存资源协同是MFLM求解算法的重要部分.多节点内存资源协同的基本思想是在当前服务器节点的内存资源不足以缓存所有热点内容时,可以临近服务器节点的内存作为补充.假设SDAN中有M个文件,用集合F={f1,f2,…,fM}表示,集合中文件按其热度降序排列.其中文件fi的大小为size(fi).文件的热度服从Mandelbrot-zipf(k,N,q,s)分布[19],即文件热度函数hot(fi)服务如下关系:hot(fi)=1(k+q)s×∑N其中k表示次序,N表示文件总数,s和q为分布参数.文件的热度越高,文件被请求访问的次数就越多.设置一个文件热度阈值hot_thred,热度超过hot_thred的文件被称为热点文件,热点文件用集合F={f1,f2,…,fM}表示,则所有热点文件的总大小用size(F)表示.CSDN的内存协同有两种:一是CSDN节点内多内存协同,一般情况下由于单个服务器内存缓存热点内容的能力十分有限,因此CSDN采用节点内所有内存资源协同的方式提供缓存服务,确保高缓存命中率;二是节点间内存协同,当size(F)大于一个服务器节点的内存总容量时,为了确保热点文件的缓存命中率,CSDN将几个邻近CSDN节点的内存资源以节点间内存协同的方式提供高缓存命中服务,即利用邻近CSDN节点的内存资源缓存当前CSDN节点缓存不了的内容,如图2所示.图2中CSDN节点1中所有的内存资源合作缓存的内容包括热点文件集合F1和F2.但当前节点1中用户访问请求所涉及的热点内容集合为F1∪F2∪F3∪F4,由于节点1的内存资源不足以缓存所有的热点文件,而邻近节点2缓存热点文件F1和Page7F3,邻近节点3缓存热点文件F1和F4.因此在均衡缓存不命中开销和非就近访问开销的基础上,节点1中请求访问热点文件F3和F4的用户可被重定向至节点2和节点3,实现多内存协同.及多内存协同的细节见算法1.如何均衡缓存不命中开销和非就近访问开销以算法1.多Cache协同算法.1.Forlj∈L,whileL={l1,l2,…,lT}2.CollectingtheinformationaboutserversFt3.Computingtheavailablebandwidthabjandcache4.CollectingusersinformationUtoriginallyserved5.DeterminethehotfilesetF;6.Collectingthedistanceinformationbetweenthe7.CollectingthehotfileindexinthecacheofLk8.Ifsize(F)<thecachecapacityinsideljthen9.Allusers’requestsfromljareservedbyservers10.Else11.do{12.LetUdenotetherestuserswhoserequestis13.Selectsomeservernodesneartoljwhocaching14.Pre-evaluatingtheadditionalconnectioncost15.Computingthemissingcostmis_cost(U);16.Ifadd_con_cost(U)<mis_cost(U)17.{RedirectUtothenearestservernodeswhose18.Else19.{RejectUorusingothercachereplacealgo-20.U=U-U;21.}until(U=)22.EndIf23.EndFor这是一个分布式算法,运行于每个CSDN服务器节点.算法1的第2~7行,表示对任一个CSDN服务器节点均需要收集其辖域内的服务器资源、用户数量、热点文件、邻近CSDN服务器节点与当前节点的距离以及这些节点缓存的热点内容索引等信息,为后续用户请求的重定向和多内存协同等提供依据.第8、9行表示如果当前的服务器节点lj具有足够服务其辖域内所有用户请求的能力,即节点lj有足够的带宽资源响应用户的服务传递需求,同时具有足够的内存资源缓存所有的热点文件以确保高缓存命中率.第11~21行的递归过程表示对于节点lj,部分用户U对热点文件的请求在lj中缓存不命中,CSDN通过预评估将U中部分用户U重定向至邻近节点的连接开销和U对lj请求的缓存不命中开销,决定是将U重定向至其邻近节点还是拒绝用户U请求或通过采用其它缓存算法[20]实现热点文件的缓存替换,直到所有用户的请求为空.鉴于篇幅限制,所涉及的其它问题:如何预评估连接开销、缓存不命中开销、进行内存协同的服务器节点数量和集合的确定等细节暂不详述.由于该分布式算法的时间复杂度取决于对热点内容缓存不命中的请求处理,显然其时间复杂度与集合U中用户个数|U|相关.由第11~21行可知,多内存协同算法的时间复杂度为O(|U|).4.3Peer辅助的服务器选择算法构成SDAN逻辑子网络由被选择的服务器集合S={s1,s2,…,sN}构成,在任一CSDN服务器节点lt处构成SDAN网络的子服务器集合记为St={s1,s2,…,sN}.同时根据热点文件的流行性,不失一般性可假设节点lt处理论上所需缓存热点文件的总大小应该和当前网络中所有热点文件总大小size(F)相同,实际中某个CSDN服务器节点所在地区的用户一般也会对所有的高热点内容发出次数不等的访问请求.但根据经验,lt处的内存资源往往不足以缓存所有热点内容,即它们之间有如下关系:SDAN的用户集合U={u1,u2,…,uP},在CSDN节点lt处的用户集合为Ut={u1,u2,…,uP}.由于用户请求服从λ泊松分布[15],lt处用户数占用户总数的百分比为pt,则lt处用户请求速率为λt=λ×pt,其中pt满足∑T务器也是分布的.且位于不同地理位置的CSDN服务器节点中的服务器数量并不相同.考虑到CSDN需多家企业协同,因此构成CSDN的服务器异构的比重较大.但从资源分配的角度,所有服务器本身只是个资源实体,不失一般性我们可假设粒度大小不一的CSDN服务器节点中的服务器同构.任一服务器sj的带宽能力用Nj表示,内存大小用Cj表示.用Page8num(λt)表示节点lt处用户数,即num(λt)=|Ut|,假设平均每个用户的带宽需求为α,则节点lt处用户对服务器带宽资源的需求nj表示为假设节点lt处可缓存的热点文件大小为cj,其中cj<size(F),则MFLM模型中如某服务器未被选中,则称该服务器处于闲置状态,否则任一被选中节点的服务器j都有运行成本fs开销和购买入网带宽等边际开销构成.用户i与服务器j的连接成本表示为用户到为其提供服务的服务器之间的距离dij.模型MFLM的优化目标是在保证性能的前提下,最小化系统开销:式中前者表示从CSDN物理服务器网络选择服务器构建SDAN逻辑子服务器网络引起的运行成本,后者表示CSDN系统运行的边际成本.该目标的物理含义是,给定带宽资源、内存资源和用户需求的情况下,尽量用较近的资源服务用户.MFLM引入内存作为新的瓶颈参数是指,即使带宽资源仍有剩余,只要现有内存大小比热点文件小,CSDN服务器节点也会拒绝当前用户访问某文件的请求.然后选择将用户请求重定向至离用户次近的服务器节点,并将用户所访问的热点内容以推的方式部署到该节点的内存中,即分配服务器带宽资源和内存资源.SDAN逻辑子网络有其特殊性,与另外两类业务相比,该类业务的多用户间可采取P2P的方式降低对服务器的资源需求.如图3所示,SDAN可采用用户辅助的模式进行内容分发,而CAN和DAN的服务分发则多采用C/S模式.考虑到SDAN进行内容分发可采用P2P模式的特殊性,我们假设某CSDN节点lt处k个用户中有t个用户,其中0<t<k+1,分别具有不同的上载能力ρ1,ρ2,…,ρt,则在大量用户发出请求时,用户对服务器的带宽资源需求并不会随着用户需求的上升而上升.假设此时内存资源和带宽资源一样按比例降低,则lt处的需求则变为鉴于文献[21-22]等认为资源满足用户需求即代表云服务传递质量有保障,因此我们可得到如下有关性能和开销的一种折衷,即MFLM的目标函数:Peer辅助方式对多内存协同的影响等见算法2.如何采用Peer辅助的方式进行服务器选择和算法2.Peer辅助服务选择算法.1.Forlj∈L,whileL={l1,l2,…,lT}2.AnalyzeandrankthehotfileF;3.Foreachhotfilefj,i=1,2,…,|F|withde-4.Givenhot(fj),size(fj)andhot_thred;5.If(hot(fj)>hot_thred)6.Theusersaccessingfjwithnumberof7.Computingthebandwidthreducedby8.ThecachereducedbyΔci9.nj=nj-Δni10.Else11.Stopandcheckwhethermulti-cachecoordi-12.EndIf13.Observetheparametersofhot_thred,ρandλac-14.EndFor15.EndFor算法2的第2行首先对热点文件进行了分析,以当前CSDN服务器节点lj为研究对象,统计出某个时间窗口内不同热点文件的访问用户数.第3行将所有热点文件按其访问用户数(热度)降序排列,第4行给出了其中某热点文件的热度、该文件的大小以及当前文件热度的阈值等.第5、6行首先判断热点文件的热度是否超过热度阈值,然后使热点文件fj的所有用户相互共享彼此拥有的内容形成P2P覆盖网.第7、8行计算所有请求访问文件fj的用户在采用P2P方式后对带宽资源需求的降低量j和缓存资源需求的降低量ΔciΔni热点文件fj所有用户的平均上载能力.算法2的第Page99行和参数hot_thred的调整可影响算法1中多内存协同的临界条件.同算法1一致,该分布式算法的时间复杂度取决于对针对热点文件构造P2P覆盖网络的处理,显然其时间复杂度与集合F中的文件数|F|相关.因此算法2的时间复杂度为O(|F|×|Fu|),其中|Fu|表示需要进行内存协同的低热度文件的用户数.5性能分析本节,我们提出了评估MFLM启发式算法的性能指标和性能分析模型,并对MFLM求解算法的性能进行了全面的评估分析.5.1性能指标和分析模型为了建立MFLM性能分析,我们需要建立包含CSDN服务器节点集合、每个节点内存资源、可进行内存资源协同的邻近CSDN节点集合、本地缓存命中访问连接延迟、本地缓存不命中访问延迟、访问邻近CSDN节点缓存命中内容的延迟和文件热度分布等多参数的分析模型.模型假设与当前节点邻近的可进行内存协同的CSDN服务器节点有m-1个.由于P2P分发系统一般将待分发文件分割为大小相等的文件片段,不失一般性本文假设此类待传递的热点内容由N个热度服从MandelbrotZipf分布f(i)[23]的文件片段组成.并且对于任意CSDN节点而言,热点文件的热度分布均一致.每个节点内存资源的缓存能力为k个文件片段.其中一个用户从其所属本地CSDN节点内存中获取单位热点内容的访问延迟和缓存不命中的访问延迟分别为lcache和lcache+ldisk.如果用户所访问的热点内容本地缓存不命中,则依据MFLM算法用户以1/m的概率从其邻近m-1个CSDN节点中任意一个的缓存中下载,且从邻近CSDN节点缓存中下载内容的延迟统一设置为lcache+ecache,同时,不失一般性,本文假设ldisk>ecache.MFLM启用P2P机制后,分析模型中做如下假设:首先,可进行内存协同的m个CSDN节点中热度排名前M的文件的所有用户进行P2P,根据前面的假设每个CSDN中可进行P2P的热点文件的概率同样也为1/m;其次,在高热度文件采用P2P后,热度排名次序紧邻在mk之后的M个热点文件同理也将以1/m的概率分别缓存在m个CSDN服务器节点的内存中,同时M+mk<N;文献[21-22]等研究表明云服务的传递质量与用户访问延迟之间具有一定的负相关关系.因此本文将获取云服务传递中各种因素产生的用户访问延迟作为衡量服务质量的指标.性能分析的目的是分析采用MFLM算法后对云服务传递性能的提高,即采用MFLM算法后所降低的用户访问延迟.用Dsingle表示未使用多CSDN节点内存资源协同的用户访问总延迟,由于单个CSDN节点的缓存能力是k个文件片段,则即所有超过本地CSDN节点缓存能力的文件均为缓存不命中,与所有访问均缓存命中的情况相比,会额外多引入ldisk∑N机制的情况下采用多CSDN节点内存协同意味着,mk个热点文件本地缓存命中的概率为1/m,从其它m-1个CSDN节点中缓存命中的概率为m-1/m.用Dmulti表示此种情况下所需的用户访问总延迟,则Dmulti=lcache∑N由于MFLM包含多CSDN节点内存协同和P2P机制,且定义文件热度阈值fthred,在文件热度高于该热度阈值时,系统启动P2P机制.假设采用P2P的热点文件为M个,且这M个文件原来均匀分布于m个CSDN节点.在M个文件采用P2P之后,另外M个未在任何内存中缓存的剩余热点文件将以1/m的概率分别缓存于m个内存中,用Dmulti-P2P表示采用P2P机制后所节省的总延迟,则Dmulti-P2P=lcache∑Ni=M+1当M=0时,Dmulti-P2P=Dmulti.根据系统实际的运行情况和经验,可知M<N-mk.用Gainmulti-P2P=(Dsingle-Dmulti-P2P)/Dsingle表示采用多内存协同和P2P机制后所节省的用户访问总延迟比率,则Gainmulti-P2P=lcache∑M与其它延迟ldisk和ecache相比,lcache的值相对较小,因此为了简化上述方程式,我们将lcache设置为Page100,定义θ=ecache/ldisk,其中有关fi的定义可参见式(4)中hot(fi),则Gainmulti-P2P=∑mk+M进一步定义F(x,y)=∑yGainmulti-P2P=F(k+1,mk+M)-θm-15.2性能评估5.2.1实际系统的日志数据根据相关研究[19,23],我们认为SDAN逻辑子服务器网络中可P2P的大文件和视频等热点文件服从MandelbrotZipf分布.文献[19]以被动测量的方法针对Gnutella文件共享系统进行了为期8个月的测量.Gnutella中有两类结点:超结点和叶结点.测量中部署了一个超级结点,并使其并发连接数达到500,其中约350个连接为超级结点间的连接.同时350个超级结点中每个结点平均可连接10个超级结点.以此类推,收集7跳以内路由所覆盖的所有用户的流量.并从数千自治域中挑选出9个自治域作为研究对象,分析了P2P系统中文件热度的概率密度分布服从MandelbrotZipf分布.本文以某代表性自治域中热点文件的概率密度分布Mzipf(4,0.78)(分布参数q=4,s=0.74)为后续性能评估分析的依据,如图4所示.并给出了在q取不同值时MandelbrotZipf分布的变化趋势.后续算法评估分析中将以Gnutella该实际数据为输入,分析式(17)中采用多CSDN节点内存协同和采用P2P对访问开销的影响.对于不同CSDN节点间延迟,CDN实验室①通过NetClust工具,对约6万~12万在线用户(电信用户占约60%,教育网用户约33%,其它网络运营商用户约为7%)进行了抽样测量.测量时间为2010年5月18日~5月26日,并从5GB监控数据分析了周末和非周末时间某CSDN节点到其它CSDN节点间的网络延迟.图5为一次覆盖全中国31个省、直辖市和自治区的CSDN节点间延迟的测量,其中某CSDN节点与其它节点间延迟小于120ms的仅为个位数.5.2.2参数设置和性能分析在如下性能评估分析中,CSDN节点数设置为300.依据中国互联网中不同CSDN节点间的网络延迟,将可进行内存协同的节点数设置为4.根据文献[13],外部缓存命中访问延迟和本地缓存不命中访问延迟的比例θ为0.3,并可在合理范围变动.热点文件总个数为N,而每个节点的内存可缓存的内容占热点文件总数的比例为0.2.我们在基于实际系统运行数据对MFLM启发式求解算法进行全面评估分析时,考虑一次只变动一个参数,假设其它参数均已设置了合理值.图6(a)为不使用P2P机制且q分别取值4,14,24,s在区间[0.2,1]内变化时节约的访问延迟比率.其中Gainmulti-P2P随s增大而降低,且q取值越大降低的速度越慢;图6(b)为不使用P2P机制且s分别取值0.2,0.4,0.6,q在区间[0,100]内变化时节约的访问延迟比率.其中Gainmulti-P2P随q增大而增大,且s越大变化越剧烈.图6(c)为使用P2P机制且q分别取值4,14,24,s在区间[0.2,1]内变化时节约的访问延迟比率.与图6(a)相比,图6(c)为使用P2P机制(M取值为0.1N)后,Gainmulti-P2P增加幅度特别大,随着s值的增大而增大,对q值的影响①CDNResearchInstitute.http://lab.cdnlab.org/Page11不是非常敏感,并且系统的整体性能在采用P2P机制后有较大幅度提高的访问延迟比率.图6(d)为使用P2P机制且s分别取值0.2,0.4,0.6,q在区间[0,24]内变化时节约的访问延迟比率.图中采用P2P机制后s取值越大,系统性能越好,即s取值为0.6时比s取值为0.2时系统的性能约高出4个百分点,并且与图6(c)反映出的规律一致:系统性能的提高受q值的变化影响不大.同理与图6(b)相比,图6(d)使用P2P机制后,系统性能约有20个百分点的提高.图7(a)为未使用P2P机制且q和s分别取特定值时节约的访问延迟比率与θ的关系.图7(b)为使用图6在q和s变化时使用和不使用P2P所节约的访问延迟比率图7在θ变化时使用和不使用P2P所节约的访问延迟比率P2P机制且q和s分别取特定值时节约的访问延迟比率与θ的关系.通过分析图7(a)中Gainmulti-P2P随θ变化的规律可知,外部缓存命中访问延迟和本地缓存不命中访问延迟θ越大,多内存协同带来的延迟降低就越小,尤其是θ在超过0.5之后多内存协同几乎不会给系统性能带来任何提升.与图7(a)相比,图7(b)在此基础上启用了P2P机制,两者主要的不同在于所节约的访问延迟比率的程度不同.后者在q和s取特定值时,带来的系统性能提升在20%~80%之间,并且s和q值的微小变化对系统性能的提升几乎没有影响.Page12图8(a)为未使用P2P机制,s=0.74和θ分别取特定值时节约的访问延迟比率与θ的关系.图8(a)中Gainmulti-P2P随着q值的增大而略有增大,且q越大Gainmulti-P2P越小.图8(b)为使用P2P机制,s=0.74和θ分别取特定值时节约的访问延迟比率与θ的关系.图8(b)在图9(a)基础上启用了P2P机制,整体上对Gainmulti-P2P的贡献增大了,但在P2P机制启用后基本对q的变化没有影响,且θ值越小图8在q和s变化时使用和不使用P2P所节约的访问延迟比率通过上述评估分析可知:在仅采用多CSDN节点内存协同方法的前提下,Gainmulti-P2P与参数s具有一定的反比关系和高相关度,与参数q具有一定的正比关系和低相关度;采用P2P机制对解决内存瓶颈方面效果十分明显,但与参数θ成反比;同时,外部缓存命中访问延迟和本地缓存不命中访问延迟之比越大,多内存协同效果就越小,而且对s变化敏感度随θ值增大而增大.该评估分析结果验证了MFLM算法对CSDN中SDAN逻辑子服务器网络即资源动态分配的效果,并且多邻近CSDN节点内存协同和P2P机制是SDAN整体性能提升的两个主要因素.也是针对SDAN特例求解MFLM模型算法中的两个核心问题.同时性能评估分析通过评估q,s和θ等参数变化(即需求变化)情况下,MFLM求解方法的有效性,从一定程度上间接说明了多邻近CSDN节点内存协同和P2P机制对于解决复杂的MFLM问题具有一定的普适性.Gainmulti-P2P越大.图8(c)为未使用P2P机制,q=4和θ分别取特定值时节约的访问延迟比率与s的关系.其中Gainmulti-P2P随着s值的增大而略有减小,且θ越大Gainmulti-P2P越小.图8(d)为使用P2P机制且θ和q分别取特定值时节约的访问延迟比率与s的关系.图8(d)在图8(c)基础上启用了P2P机制,整体上对Gainmulti-P2P的贡献增大了;并且在P2P机制启用后对s变化敏感度随θ值增大而增大.6总结及展望云服务传递网络CSDN以就近和按需的方式向用户提供云传递服务.由于CSDN覆盖不同类型业务的传递,因此其物理服务器网络被划分为针对缓存类应用、流媒体和下载应用以及动态应用等多种不同类型业务的逻辑子服务器网络.不同类型业务资源需求特点各不相同,其中用于流媒体和下载类云服务传递的逻辑子服务器网络SDAN,消耗了CSDN的大部分资源.与动态应用类业务不同:SDAN中内存资源是除带宽资源之外的另一种瓶颈资源,而动态应用逻辑子服务器网络DAN中计算和带宽资源是瓶颈;与DAN中内容需要回源[2]不同,SDAN中内容具有可P2P的特性.本文重点研究和解决该类型云服务传递的资源动态分配问题.因此根据该类型业务内存资源和带宽资源同为Page13瓶颈资源以及该类型热点内容可采用P2P机制的两个特点,我们将该问题建模为多维设备选址模型.在对该模型NP完全性分析的基础上,提出了一种针对SDAN特例的启发式求解算法,并对MFLM求解算法的有效性进行了全面的评估分析.服务器资源动态分配问题一直都是学术界研究的重点和难点,未来围绕该问题我们将对如下几个基本问题展开研究:(1)互联网业务用户访问请求分布和流量行为统计特点;(2)互联网多种类型业务的分类方法和分类结果;(3)在上述两点研究结果的基础上,研究针对不同类型业务间服务器资源的动态分配问题.致谢作者在此感谢为本文贡献有价值思路、讨论和数据的各位专家及工程师:清华大学CDN研究所所长尹浩教授,ChinaCache公司运维部宋裔智副总裁,富媒体下载组的李政工程师和P2P部张玮经理等!
