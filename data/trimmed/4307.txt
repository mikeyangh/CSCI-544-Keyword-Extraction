Page1分布式key-value系统错误污染检测郭晓林1)舒继武2)易乐天1)1)(清华大学计算机科学与技术系北京100084)2)(清华大学信息科学与技术国家实验室北京100084)摘要随着key-value存储系统的广泛使用,越来越多的研究开始关注分布式系统中的可信问题,其中一个重要的问题是,如何在系统被入侵或者管理员配置错误并运行一段时间后,检测出受污染的数据,从而可以在恢复错误数据的同时保留系统的合法更新.文中提出了一种基于key-value存储系统的错误污染检测方法,该方法允许在客户端不可信的前提下,检测客户端之间的污染扩散.文中设计了一种基于各服务器逻辑时钟的向量时钟,该时钟以用户关联操作为更新规则,记录了跨服务器的读写请求逻辑关系,用以进行错误污染跟踪;同时为了减少大规模系统中污染检测的开销,基于该向量时钟,文中进一步提出了一种在分布式系统中由操作序列构成有向无环图的污染分析方法.基于广泛使用的Voldmortkey-value系统,文中实现了一个错误污染检测系统,TrackerStore.在集群测试环境下,文中对引入新的检测系统后产生的额外延迟开销进行了测试.关键词污染检测;分布式key-value系统;向量时钟1引言互联网新一轮的爆炸性增长,给数据存储带来了巨大的挑战.据Facebook统计,目前其服务器共存储了超过2600亿张图片[1],并且图片的数量正在以每周新增10亿张(约合60TB)的速度在增长.Twitter则在2010年8月份便已经有超过2000亿Page2条用户记录.数据增长的速度是如此之快,以至于传统的存储方法已经无法满足当前需求对于存储节点可扩展性的要求.为了获得更高的可扩展性,许多大型的互联网服务提供商使用NoSQL数据库来作为后端数据存储与查询系统.NoSQL系统通常不支持传统RDBMS(RelationalDataBaseManagementSystem)的连接操作,提供弱一致性(如最终一致性),并采用key-value存储的形式,如基于内存的分布式key-value缓存(如Memcached、Velocity),提供最终一致性的分布式key-value存储系统(如Amazon的Dynamo[2]、Cassandra[3]、Voldemort①).由于这类系统中所存储的用户数据尤为重要,提高数据的安全性成为亟待处理的问题.目前这类系统的数据安全性研究主要包括两个方面:(1)错误防范(proactive),这些研究假定在某些节点不可信的情况下,用户如何防范这些节点混淆或者窜改存储内容[4-6];(2)错误恢复(reactive),另一些关于安全性的研究则关注在系统被非法访问者入侵后,如何发现由于入侵者的窜改而导致的内容污染的扩散,从而将系统恢复至正确状态[7].大量的研究表明[7-9],入侵和管理员配置错误在实际部署中很难避免,因此本文的研究主要针对于key-value存储系统的错误检测恢复技术.在key-value系统出现错误之后,传统的恢复方法是将整个系统回溯到一个先前的时间点,这种方法潜在的缺点是,从当前时间点到恢复时间点之间的数据将全部丢失.为了尽可能地保留不受污染扩散影响的内容更新,减少数据的丢失量,本文提出一种基于分布式key-value系统的错误污染检测方法.该方法通过为用户操作记录关联对应的向量时钟,来跟踪跨服务器的读写请求之间的逻辑关系.由于数据访问模式往往具有局部性的特征,使用该污染检测方法,能够高效地检测错误污染和扩散,避免全系统的整体恢复.本文实现了一个错误污染检测系统TrackerStore,首次在分布式存储系统中引入污染检测机制.在实验室的集群测试环境下,引入新的检测系统在读写比例为955的负载下会带来26%左右的额外延迟开销,而国际上最新的单机污染检测恢复系统在引入检测机制后会产生24%~27%的性能开销[9].2背景及相关工作2.1分布式key-value系统分布式key-value系统已经被广泛应用到了大规模工业系统中,Amazon的Dynamo[2],开源的分布式key-value系统ApacheCassandra[3]和Volde-mort也已经被运用在实际产品的运营中.这些系统的共同特点是无中心节点,使用DHT(DistributedHashTable,分布式哈希表)技术进行key划分,并且提供最终一致性(EventuallyConsistent[10]).与传统的存储系统相比,分布式key-value系统具有较为良好的可扩展性,并且通过提供弱一致性,达到较高的可用性.同时,这些系统提供了较高的容错能力,以适应在大规模集群系统中频繁出现的节点失效的问题.由于越来越多的产品系统使用分布式key-value存储作为后端的数据存储引擎,本文的工作基于这类key-value存储系统,提供高效的错误污染检测和恢复能力.2.2分布式存储系统中的可靠可信问题数据的安全可靠性一直是人们对云存储的最大担忧之一.许多研究均围绕着这一方面展开:Depot[11]假定在一个分布式存储系统中,客户端和服务器均可能有恶意行为,两者均可以混淆数据更新的顺序.因此Depot的目的在于保证所有正确节点看到的数据更新顺序一致.SPORC[4]假设在云存储系统中服务器不可信,因此在服务器上保存加密的数据,且每个客户端在本地保存数据拷贝,服务器仅负责确定操作的顺序及提交.客户端可以通过哈希链等技术检测服务器是否会混淆更新提交顺序,从而达到fork一致性.在SPROC之前,BFT2F[5]同样实现了fork一致性,与其相比,SPORC还加入了OT(OperationalTransformation,操作转换)技术,使其除了可以检测出用户更新之间的冲突及服务器混淆版本顺序的行为,还能将数据自动恢复到一致的状态.2.3污染检测及入侵恢复在系统被入侵,文件系统遭到污染后,管理员往往需要将系统恢复到一个合法的状态.使用文件系统快照是系统恢复的一个常用手段,但这个方法会使发生在快照之后入侵之前的合法操作被消除,同时其他未被入侵影响的合法操作也会被消除.为了解决这一问题,Taser[6]入侵恢复系统记录了所有的系统调用以及数据操作,管理员在发生数据污染后可以对日志进行因果关联的分析,选择性地恢复因入侵而被污染的数据文件以及受影响的其他文件.Taser会将文件恢复到最后一个合法操作之后的状态,这样就尽可能多地保留了合法的操作.Retro[7]的目标与Taser相同,但其通过操作历史图以及预测,①Voldemort.http://project-voldemort.comPage3重新执行等技术,消除了Taser中存在的大量假阳性(正确数据被错判为污染数据)及假阴性(污染数据被检测系统漏过).WARP[8]将Retro的功能拓展到了Web应用上,将Retro中基于文件和进程级别的关系检测进一步细化至单条SQL查询的粒度,因此可以进行单数据行级别的回滚.同时管理员无需找出每一次入侵的根源,只需要安装补丁修复入侵所利用的系统漏洞,或者纠正错误的系统配置,系统就可以重新执行合法操作,消除入侵产生的影响.WARP还通过记录用户浏览器中的DOM(DocumentObjectModel)操作,来重新播放用户浏览器DOM级别的行为.这样可以在不需要任何用户输入的前提下保留用户之前的合法操作.这些系统研究的数据污染关系均是在本地文件系统中,本文则是在分布式的存储系统中研究污染的检测问题.传统系统中经常会出现多人以及多个组织协作编辑同一文件的情形,由此也引发了追踪数据来源的需求[9].即找出数据创建以及修改的一系列操作链条.PASS系统[12]实现了这一功能,通过PASS系统,用户可以由数据来源信息查找出数据错误的产生位置.这对于发现系统入侵时点,界定错误责任来源都有很大的帮助.另一方面,版本文件系统提供了将文件从可能的数据损坏中恢复的能力,但如果由人工来判定恢复到何种版本需要大量的时间精力,因此基于PASS系统和版本文件系统,有研究者实现了基于因果关系的版本记录[13].其目的与Taser相似,希望通过分析进程对于文件的读写关系,确定因数据污染而受影响的文件.因为使用了版本文件系统,系统不需要像Taser一样重新执行被污染文件上的合法操作,也不需要额外记录操作对于数据内容的改动,节省了时间和空间.基于云存储的数据起源系统[14]研究了如何将云存储系统(如Amazon的S3)作为PASS系统的存储后端的问题.这一研究的主要挑战来自于分布式存储系统的最终一致性特征,这一特征使得起源(Provenance)信息和数据文件会出现不一致的情况,因此该研究的重点是如何扩展原有的起源信息协议,但并没有就如何进行污染检测进行深入探讨.本文研究在分布式key-value存储系统中如何进行错误污染的检测.讨论了如何应用改进的向量时钟,来分析存储记录间的因果联系.与Taser、Retro、WARP只是检测单机系统的错误相比,本文将错误污染的检测扩展到了分布式系统中,着力解决跨服务器间的错误污染传播.与追踪数据来源的系统相比,本文的研究假定用户不可靠,因此不依赖客户端记录来源信息,而是通过服务器上的用户操作记录,来判断用户操作之间的逻辑联系.3原理概述3.1威胁模型与假设一般对安全性的研究首先需要提出威胁模型以及相关的假设.本文假定服务器是可信的,即服务器不会在未经用户许可的前提下对用户存储内容进行非法窜改,也不会使用过时的数据来混淆用户的内容,同时不会窃取用户内容.本文做出这样的假设的理由在于,基于现有研究,用户可以通过签名和数据版本来防范服务器的窜改与混淆,同时通过对内容加密来保证内容的私密性,因此服务器不可信的威胁可以被降低到一个可以容忍的程度.本文还假设,服务器是可靠的,即服务器不会因断电,软硬件错误等故障而产生数据丢失.在这方面,对于副本、备份、恢复的研究已经十分充分,所以本文在威胁模型中将这个因素排除在外.在本文的研究中,威胁来自于不可信的用户,包括授权的用户由于被入侵(如账号被窃取)转变为不可信用户并且对服务器数据进行窜改;或者管理员由于软件配置错误,对服务器端数据造成污染.用户由于被入侵或者管理员配置错误导致的对服务器上存储的数据的污染可能不能被及时发现,因此合法的用户会读取这些不正确的数据,从而造成错误污染的扩散.本文假设,在因用户被入侵或者配置错误而产生数据错误后的某个时点,入侵或者配置错误的行为可以被系统管理员发现,并且可以推断出一个离现在最近的正确时点.从该特定时点之后,对应的用户被认为是不可信的,因此其所有数据修改行为均被认定为不可信的,即其写入的数据均为错误的.在错误数据得到纠正之前,其他可信用户如果在另一时点读取了该错误数据,则认为可信用户在该时点之后也将变得不可信.系统的目标是检测出该类型所有错误,并最终达到恢复正确数据的目的.以图1为例可以说明以上所描述的威胁模型.如图,系统中存在3个服务器以及3个用户,假设已知用户A在向服务器1写入Foo1(Set操作)时已经不可信,用户B在用户A写入后,从服务器1读取Foo1(Get操作),之后向服务器2写入Foo2(Set操作).由于用户B读取了不可信用户写入的值Page4Foo1,其读取Foo1之后的所有写入都应该视为不可信的行为.因此Foo2是不可信的写入值,这也导致用户C读取Foo2后变得不可信,进而使得其向服务器3写入的值Foo3也被标记为不可信.3.2污染检测目标及原理本文研究的目标是,在确定污染起点之后,检测出所有不可信的写操作,包括由直接污染源造成的不可信写操作和由于读取不可信的写入值产生的错误污染扩散.污染扩散的定义如下:(1)可以确定一个时刻T0,从该时刻起,某个用户写入的任意值均不可信.(2)假设从T1(T1>T0)时刻起用户A不可信,则该时刻后其向服务器写入的〈key,value〉对均被视为错误值.若T2时刻(T1<T2)用户B从同一服务器读取key对应的值,则T2时刻后B向任意服务器写入的值均不可信,也即B被污染.(3)上述时刻均为全局同一时间.检测系统应该最大程度找出上述污染,允许存在少量的假阳性(falsepositive),即系统将某一用户误认为被污染.但不应产生真阴性(truenegative),即不应漏过根据定义可以判定的污染扩散.根据以上定义,要在读写日志中检测出错误污染,需要依赖于全局时钟.但实际上,在分布式系统中实现全局时钟较为复杂,而且会给系统强加不必要的开销.目前大部分key-value分布式系统均不依赖于全局时钟,因此检测系统使用了向量时钟来处理这一问题.由于在威胁模型中,系统假定了用户是不可信的,因此这里只使用每个服务器的逻辑时钟来构成向量时钟.服务器的逻辑时钟定义为:(1)Get操作不改变服务器逻辑时钟的数值.(2)服务器每完成用户的一个Set操作请求,本地逻辑时钟的值加1.所有服务器的逻辑时钟构成了系统的向量时钟.使用系统向量时钟,就可以判定一个用户从一个服务器读取内容的Get操作和其向另一个服务器写入内容的Put操作之间的逻辑关系.3.3向量时钟更新规则每个服务器均保存着一个系统向量时钟Veci.其中,Veci(k)即为服务器i上保存的服务器k的逻辑时钟值.Veci(i)即为服务器i自己的本地逻辑时钟值.服务器在特定事件发生时会与其他服务器同步逻辑时钟.根据3.2节中定义可知,逻辑时钟只有在Set操作发生时才会产生变化,因此一种策略是在每次Set操作发生后,服务器立刻与其他服务器同步,更新自己保存的其他服务器的逻辑时钟,同时将自己的逻辑时钟更新到其他服务器上.这种策略可以最大程度确保每个服务器的向量时钟与其他服务器同步,但也带来较为严重的性能开销.在这里每一个Set操作都会导致一个系统广播的出现,这就加重了服务器与网络的负载.考虑一种新的策略,由于Set操作写入的值在没有被Get操作读取之前并不会对系统造成污染,因此可以考虑将Set操作产生的向量时钟同步推后至相应的值被Get操作读取之时.这一改进可以降低向量时钟同步的频率,而且可以保证错误污染关系仍可检出.但由于Set操作对应的向量时钟被推迟了,发生在Set操作之后的Get操作可能会被标记上一个早于Set操作的向量时钟.假如Get操作是被污染的,那么Set操作也会被误判为被污染,也即系统出现假阳性的概率上升.综合起来,服务器的本地逻辑时钟和其保存的其他服务器逻辑时钟的更新规则如下:分析操作之间的联系,可以从最基本的情况出(1)服务器i接收到一个Set操作,本地逻辑时钟自增一个单位,本地记录的其他服务器逻辑时钟不变.(2)服务器i接收到一个Get操作,若读取了之前Set的值,则进行一次与其他服务器的时钟同步操作.向量时钟的意义在于作为每一个发生的Get与Set操作的时间标记.对于服务器i上的Set操作,最后记录的向量时钟的值按如下方法确认:(1)向量时钟的时钟分量i为Set操作发生时(2)向量时钟的其他时钟分量为发生Get读取事件后进行时钟同步得到的值.对于服务器i上的Get操作,以其发生时服务器i上保存的各服务器逻辑时钟值(包括服务器i自己的逻辑时钟)构成该操作的向量时钟值.若发生了前述的与其他服务器同步的操作,则各服务器的逻辑时钟使用的是同步之后的值.3.4不同类型操作之间的因果关联服务器i本地逻辑时钟自增后的数值.Page5发.对于任意两个操作来说,可能出现的组合有Get-Get、Set-Set、Get-Set、Set-Get4种.第1种对数据无影响,第2种前后的两个操作之间不会出现污染扩散.会产生污染扩散的两类操作是Get-Set和Set-Get组合,下面将分别详细介绍.对于Get-Set组合来说,只有两个操作同时属于一个用户才会产生污染扩散的联系.也就是说,如果通过记录下来的向量时钟可以判定用户进行的某个Get操作在其进行的另一个Set操作之前(无论是在同一服务器之上还是在不同服务器上),且Get操作已经被判定为不可信操作,则根据本文的威胁模型,Set操作也会被标记为不可信,也即其写入的为错误值.对于Set-Get组合来说,两个操作必须针是对同一服务器上同一key才会产生污染扩散的联系.也即,当一个已经被污染的用户通过Set操作写入某个〈key,value〉对时,后续通过Get操作读取该key的另一用户会被污染.由于是在同一服务器上,对同一key的访问会由读写锁保护,因此Set和Get操作之间的精确顺序很容易确定.一个不可信的Set操作将导致其后读取Set操作写入值的所有Get操作均被污染.从上面分析看,向量时钟最重要的作用是分析同一用户在两台服务器(相同服务器是一个特例,可以使用同样的时钟向量判定方法)的Get操作和Set操作之间的逻辑关系.本文的目标是保证所有逻辑上在Get之后的Set操作都能用向量时钟的方法检测出来.假设有服务器i与j,用户在服务器i进行了Get操作,并且在Get操作完成之后才在服务器j进行了Set操作.比较服务器i的Get操作与服务器j的Set操作分别对应的向量时钟,根据3.3节中的定义,服务器j的Set操作所进行的时钟向量同步在服务器i的Get操作之后,而逻辑时钟又是单调递增的,因此对j以外的分量,可以确定Veci(k)Vecj(k),k≠j,而Veci(j)<Vecj(j).这里的严格小于关系是可以证明的:服务器j收到Set操作后会自增其本地逻辑时钟,Set操作所对应的向量时钟的逻辑时钟分量j使用的是自增后的值,而Get操作使用的必定是自增前的值,因此严格小于的关系成立.对于每一个操作组合,系统都将依照上面的规则判断因果联系,最后根据污染源头的位置,就可以判断出系统中哪些内容已经不可信,哪些虽然是在出现污染后才写入的数据但依然可信.3.5因果关系有向图构造要分析所有操作之间的因果关系,达到错误污染检测的目标,就需要以3.4节中的判断方法,由点及面,从操作序列中构造出所有操作之间的联系图.由于时序上的单调性,最后构造出来的图必定是一个有向无环图.这样,从操作序列中检测错误污染的问题,也自然转化为有向无环图的遍历问题.为了构造有向无环图,每一个操作都是图中的一个节点,因此操作序列最后会转化为Get和Set两类节点.对于Get节点,其与那些同属一个用户且逻辑上发生在Get节点之后的Set节点之间存在一条从Get节点到Set节点的有向边.对于Set节点,其与前述的访问同一key且发生在同一服务器之上的Get节点之间存在一条从Set节点到Get节点的有向边.通过这样的转换操作,操作序列转化为一个有向图.在有向图中,进行污染检测等价于从某节点开始进行有向图的广度优先搜索.遍历的起点是污染源,遍历中访问到的每个节点都是不可信的节点.这样就完成了污染检测算法的设计.4系统实现本节主要描述我们如何实现错误污染检测方法.错误污染恢复方法的原型实现,TrackerStore,是基于被广泛使用的Voldmort系统.与其他key-value存储系统类似,Voldmort系统主要向用户提供get和put接口.由于TrackerStore的实现仅与Voldmort提供的用户接口相关,在此我们不再敷述Voldmort的具体实现.4.1系统组成如图2所示,组成系统的部分包括,基本的key-value存储模块,在客户端和服务器端中间新添的追Page6踪模块TrackerStore、缓存模块以及日志模块.版本监控模块维护本地的逻辑时钟并且在必要的时刻与其他服务器的版本监控模块进行通讯,进行逻辑时钟同步.上述模块与日志系统共同组成系统的监控子系统.为了降低本地IO负载,日志系统可以设置在独立的服务器上.系统另一个重要的组成部分则是监控日志分析模块,如图3所示.每个服务器均有自己的监控日志记录,在分析系统的错误污染时,需要将所有日志整合,构造出相应的关系图并进行分析.尽管可以直接将所有日志同步到一台服务器上并将日志进行合并,排序,但是这样会给网络带来较高的瞬时负载.同时,计算负载也将集中在某一台服务器之上.通过仔细检查错误污染的分析流程,可以发现,错误污染的检测算法具有分布式计算的潜力.运用类似于MapReduce在页面排序算法上的思想,本文将分析模块分解为主节点与分析节点.错误污染的分析由主节点发起,每个服务器均有分析节点负责归约本地的监控日志记录,并将结果返回给主节点,主节点合并所有分析节点归约的结果,根据需要向各服务器的分析节点分配新的分析任务.4.2向量时钟延后更新技术追踪记录模块由TrackerStore,日志系统和服务器版本监控模块组成.TrackerStore会把接收到的所有请求都提交给真正的KeyValueStore,并将相应的信息传递给日志系统.TrackerStore中最重要的技术是根据3.3节所阐述的原理实现的向量时钟延后更新技术.每个被TrackerStore截获的Set操作并不会立刻传递到日志系统进行记录.系统会将Set操作的key值和对应的本地逻辑时钟先存放在缓存中.当TrackerStore截获Get操作时,同样先检查本地缓存中是否存放了Get操作要获取的key值,若无则直接从服务器版本监控模块获取一个当前服务器保存的向量时钟,作为Get操作的时钟并传递给日志模块进行记录.否则说明本次Get操作要获取的key对应的值是之前未被记录的Set操作所设置的.因此需要首先处理缓存中所有未被记录的Set操作,再记录本次的Get操作.在处理缓存中的Set操作之前,版本监控系统会进行一次时钟同步,其将自身最新的本地逻辑时钟发送给其他服务器的版本监控系统,同时获取其他服务器最新的逻辑时钟值.同步结束后,发起同步的服务器i得到当时最新的时钟向量,而其他服务器则更新了其本地时钟向量中服务器i对应的分量的值.根据更新后向量时钟,Get与Set操作按3.3节中所述确定各自对应的向量时钟并传递至日志模块进行记录,记录完毕后清空缓存.TrackerStore,本地缓存和版本监控模块一起,实现了延后更新时钟向量的策略.但事实上,如前所述,延后更新策略并非没有缺陷.时钟向量更新的周期越长,出现假阳性的概率就会越大.可以通过缓存定时清洗进一步改进延后更新技术.也即,定期进行服务器向量时钟的同步并且处理缓存中所有未被记录的Set操作.系统频繁进行时钟同步导致的负载上升与降低假阳性概率之间的取舍,可以通过设置缓存清洗的时间周期来达到.缓存清洗周期越短,则负载越接近于实时的时钟同步,周期越长,则越接近于完全的延后更新时钟向量策略.在本文进行的实验中,周期取1s.4.3操作关系有向图的分布式构造技术基于TrackerStore提供的日志记录,分析模块可以按3.5节中所述方法构造一个操作关系图,并进行污染检测.但在实际中,每台服务器均有自己的TrackerStore,因此会产生独立的日志文件,要分析这些文件最直接的方法是指定一个服务器,将所有日志均传输至该服务器,由该服务器进行一次日志的合并操作,之后再构建操作关系图.这种方法简单易行但效率低下,不仅传输日志会造成较大的网络负载,通过单一节点来进行计算也无法充分利用分布式系统的资源.因此这里应该使用各服务器自行构造关系图并计算出受污染的内容,然后再将结果与其他服务器交换并进行迭代运算.然而如果服务Page7器之间交换的是完整的关系图,同样会产生较大的网络负载,所以在具体实现中本文对算法进行了改进:首先将关系图中的节点分为操作节点及用户节点两类.对于每一个Get操作或Set操作,系统均会构造一个操作节点,同时对于在日志中出现的每一个用户,同样构造一个用户节点.本文假设用户一旦读取了一个被污染的值,其之后的所有操作也将会被视为不可信,因此对于用户节点来说,需要保存的是其最早被污染的时刻(被入侵或者因读取被污染的值而受到影响).这样各服务器本地的关系图就可以构造出来:对于同一服务器上操作同一个key的Set和Get操作,若Set操作的逻辑时钟小于Get操作的逻辑时钟,则增加一条从Set操作节点到Get操作节点的有向边,表示Set操作节点会影响Get操作节点.对于同一用户发出的Get和Set操作,前面章节提出需要根据向量时钟判定先后顺序.但是这两个操作节点可能位于不同的服务器,所以为了能在不同步日志内容的前提下构造本地关系图,需要以用户节点作为同一用户发出的Get和Set操作的中介.对于每一个Get操作节点,均增加一条从Get操作节点到对应用户节点的有向边,对于每个Set节点,则增加一条从用户节点到Set节点的边,由此本地关系图构造完成.在进行错误污染分析时,首先要确定用户变得不可信的时点,这部分数据由管理员在主节点输入,并由主节点为每一个分析节点指定.分析节点进行本地的错误污染检测:首先设置不可信用户节点最早被污染的时刻,其次分析节点会遍历用户节点的所有出边,找出在污染时刻后用户产生的Set操作节点并将其标记,之后从Set操作节点的出边遍历所有受Set操作影响的Get操作节点并做标记.对于每一个标记为“被污染”的Get操作节点,更新其指向的用户节点的向量时钟,使得用户节点向量时钟的每一分量均小于或等于Get操作节点的向量时钟的对应分量.若用户节点向量时钟被更新,则其需要找出新的受影响的Set操作节点并重复前述过程.每一个分析节点完成图的遍历后,也就完成了一次本地错误污染的检测,产生了所有用户节点最早被污染的向量时钟.所有的分析节点均会将自己分析得出的用户节点数据传回主节点,由其合并不同分析节点的用户节点并重新更新分析节点的用户节点信息.分析节点得到更新的数据后再一次进行错误污染检测.经过数次迭代,当所有分析节点都不再更新用户节点数据时,整个分析过程完成,分析节点向主节点输出被污染的key值.5性能评测为key-value存储系统增加污染检测组件会给整个系统带来额外的开销.因此本文通过测量系统添加污染检测组件前后的请求延迟来衡量污染检测给系统整体带来的开销.实验环境中,本文使用了5台配置AMDOpteron4核处理器,16GB内存的服务器来部署分布式key-value存储系统,每台机器均使用本地的SATA磁盘.同时使用10个客户端连接到服务器.节点间通过GB交换机互联.我们首先使用Voldmort标准的Benchmark进行测试,该Benchmark工具是Linkedin公司根据其key-value负载需求开发的.在工作负载上,Bench-mark预先装载5000组key-value对,并使用不同大小的值进行测试,包括1KB、10KB、128KB.客户端向服务器发出一系列Get和Set请求,每个客户端读写的key都是从key空间中随机均匀选取.为了模拟不同的key-value工作负载,本文在测试中使用不同的读写比例.比如在读延迟测试中,100%读和80%读20%写的负载用来模拟典型的互联网应用负载,50%读50%写是用来模拟如删冗,会话连接等工作负载.在延迟测试中,客户端会向服务器发出100000个请求,本文分别测量读写操作的平均延迟.在平均读延迟图4中,基准100%和Tracker100%分别表示在100%读的负载中,未添加检测模块的Voldemort系统以及添加了检测模块的TrackerStore的性能情况.其他以此类推.而在平均写延迟的图5中,基准100%和Tracker100%代表的是100%写操作的负载.Page8从实验的结果看,引入污染检测后系统读写延迟都产生了一定程度的上升.同时,在本文的系统的设计中,当用户的Get操作读取了一个最近Set操作写入的值时,需要进行一次版本同步以及记录Set操作的信息,因此当Set操作的比例上升时,Get操作需要进行这种额外操作的概率也会相应上升.可以预期,新检测组件给Get操作的延迟时间带来的额外开销将随着Set操作比例的上升而增加.而在原来的系统中,Get操作的延迟随着Set操作比例的上升也会有一定提高(主要是读写锁的争用),但幅度相对新系统较小.从具体的数值比较上,在1KB、10KB、128KB,读比例100%的实验中,引入污染检测后,系统的读延迟分别上升了0.02ms、0.2ms、0.8ms,系统额外开销较小,而在读比例下降到80%的实验中,系统读延迟则分别上升了0.09ms、0.3ms、1.5ms.因此当写操作在系统负载中比例较高时,污染检测会给系统带来一定的额外开销.同时,随着请求操作的大小的增加,额外开销在总延迟中占比逐渐减少.为了估计系统在真实负载下的性能开销,本文另外使用Yahoo!的云存储测试框架Yahoo!CloudServingBenchmark[15](YCSB)中的不同模拟负载进行了评测.该Benchmark是Yahoo!根据其生产环境中的工作负载进行的抽象,其典型负载包括A-密集更新负载(读与更新操作的比例为50/50,典型应用为用户会话存储),B-密集读负载(读与更新操作的比例为95/5,如读取图片标签),C-只读负载(如用户信息缓存),D-读取最新值负载(读与插入操作的比例为95/5,如读取用户最新状态),E-读取-修改负载(读以及读-修改的操作比例为50/50).所有负载的记录大小都为1KB,每一种负载都包含50万条测试记录,结果如图6、图7所示.从测试结果看,当写比例上升时(对于YCSB的5类负载来说,写比例从高到地依次为A、E、B、D、C.其中C负载是只读负载,因此无写延迟数据)系统的读延迟开销有明显上升.在较为常见的以读操作为主的负载B、C、D中,引入污染检测会使读操作增加26%左右的延迟开销.国外类似的系统WARP在单机环境下引入污染检测会增加24%~27%的额外性能开销,因此本文提出的检测系统性能开销与国外类似工作相同,但将检测能力从单机扩展到了分布式网络中.另外,从测试结果中可以看出,A类及E类负载的额外开销明显高于B、C、D类,其中A类又高于E类.这里的主要原因与标准Benchmark里出现的现象相同,即写操作(Set操作)比例上升后,读操作(Get操作)需要进行版本同步的概率也随之提高,因此读操作的额外开销也会增加.对于A类负载来说,读操作与更新操作的比例为5050,而每个更新操作中需要进行一次读和一次写,因此整体读写比例为7525;对于E类负载来说,读与“读-修改”操作的比例同样是5050,但一次“读-修改”实质由一个读和一个更新操作组成,因此E类负载整体读写比例为8317,新系统在E类负载下产生的额外开销应低于A类负载.5类负载所体现出的性能变化趋势与理论估计情况一致.Page96小结目前NoSQL类数据系统尤其是key-value系统日益流行,由此带来一系列对于数据安全可靠性的隐忧.本文通过将传统系统中污染检测引入分布式key-value系统中,为这类系统提供了一种新的数据可信验证工具.同时,通过合理安排对系统的追踪记录行为,只需要付出较低的性能代价,就可以为分布式key-value系统引入污染检测的能力,具有较高的效率.
