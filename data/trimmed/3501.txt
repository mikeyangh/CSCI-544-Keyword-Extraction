Page1云环境下优化科学工作流执行性能的两阶段数据放置与任务调度策略刘少伟1)孔令梅2)任开军1)宋君强1)邓科峰1)冷洪泽1)1)(国防科学技术大学计算机学院长沙410073)2)(中国人民解放军78046部队成都610011)摘要云环境中跨数据中心科学工作流的高效执行通常面临数据交互量大的问题.文中给出基于相关度的两阶段高效数据放置策略和任务调度策略:即在工作流建立阶段根据数据依赖关系图把关系紧密型数据集尽可能放置到同一数据中心;而后任务调度策略在运行阶段将任务调度到数据依赖最大的数据中心执行,并将新产生数据集放置到相关度最高的数据中心.实验表明,该策略能有效减少跨数据中心科学工作流执行时的数据传输量,从而能有效提升科学工作流的执行效率,并能减少资源的租赁费用.关键词云计算;科学工作流;数据放置;数据相关;任务调度1引言在众多科学研究领域中,例如高能物理学、生物信息学、大气科学等,科学计算过程往往由成千上万个步骤构成,这往往需要对TB甚至PB量级的数据进行分析和处理.在过去,科学家通常使用简单的方法(例如Perl脚本语言)编排任务以及管理数据,但是这种方式不仅耗时而且容易出错.针对这一问题,科学工作流系统[1]开始受到关注并被用来进行自动化科学任务的编排、执行、监控以及追踪[2].随着问题求解规模的增大,当今大型科学工作流通常需要在复杂的分布式计算机系统上执行,例如超级计算机、分布式集群系统以及网格系统等.然而,构造这样的系统往往需要付出异常昂贵的代价,申请访问这些系统也需要复杂耗时的过程.云计算[3]技术提供共享基础架构的方法,它通过虚拟技术将分布在不同地理位置的计算资源和存储资源虚拟成一个资源池,用户需要使用时申请资源,使用完成后释放资源,从而使得资源可以重复利用.通过这种方式,云计算中心可以提供高性能的计算资源和海量的存储资源,而且成本低廉,使用简单.随着云计算技术的深入发展和不断成熟,其高效、灵活、可定制的特点为解决科学工作流运行过程中遇到的难题提供了一种新思路.许多地理上分离的科学研究机构都有单独的私有云,每个私有云都可以提供一部分存储资源和计算资源,可以将它们看作是独立的数据中心,这些数据中心通过互联网技术形成更大的云计算平台.研究人员使用该平台时,需要将数据集上传到云计算平台.由于数据集规模可能非常庞大、数据中心之间存在带宽限制且部分数据集只能存放于指定的数据中心,研究人员不可能将所有数据集上传到同一数据中心或为每个数据中心上传所有数据集,而需要将不同数据集分别上传到不同数据中心,从而使得科学工作流的多个子任务可以并行执行.由于科学工作流任务间存在较强的数据依赖关系,其执行往往需要频繁对跨数据中心的数据集进行传输和访问,不合理的数据放置和任务调度策略容易导致数据中心间数据传输量和访问量过大,一方面增加用户使用云资源的费用外,另一方面也严重影响了科学工作流的执行效率,因此研究基于云环境的高效数据放置策略和任务调度策略对减少跨数据中心数据传输量、提升科学工作流执行性能、减少用户费用等方面具有重要意义.但是,现阶段已有方法还不能很好解决这一问题,我们在相关工作中给予了详细分析.本文通过分析科学工作流数据集之间的依赖关系、数据集和数据中心之间的相关度以及任务和数据中心之间的相关度,提出了一种云平台下基于相关度的两阶段高效数据放置策略.该策略首先根据数据依赖关系图在工作流建立阶段将关系紧密的数据集放置到同一个数据中心,将关系松散的数据集放置在不同数据中心,这样保持了不同数据中心数据集之间的低耦合性和同一数据中心数据集之间的高内聚性;之后任务调度策略在运行阶段将任务调度到数据依赖最大的数据中心执行,并将新产生数据集放置到相关度最高的数据中心.实验表明,本文提出的策略不但极大地减少了数据中心间的数据移动量,提高了工作流任务的并行执行效率,同时也节省了用户的云资源使用费用.本文的贡献主要表现在以下几个方面:在科学工作流建立阶段,提出了基于数据依赖的初始化数据布局方法,充分挖掘数据相关性,使得数据布局尽可能的符合使用规则,同一个任务所需数据集最大规模地聚集在一个数据中心;在科学工作流运行阶段,提出一种相应的任务调度策略,将任务调度到所需数据集规模最大的数据中心上,减少数据中心之间的数据传输量,加快科学工作流执行速度.针对任务执行过程中产生的中间数据集,本文利用数据集之间的关系,通过量化计算将它们放置到合适的数据中心,使得后续的任务调度与执行能够快速展开.本文第2节介绍相关工作,说明本研究的意义以及与相关工作的差异;第3节介绍科学工作流在云环境下的执行流程,并给出相关的符号定义,然后分析数据放置策略需要考虑的各种因素;第4节详细阐述基于相关度的两阶段数据放置策略;第5节通过模拟实验将本策略与其它数据放置策略进行了对比,并对结果进行了详细分析;第6节对全文进行总结并对以后的研究方向进行展望.2相关工作科学工作流的数据放置是一个非常重要且富有挑战性的问题,目前已有部分学者对此进行了研究与探索.现有科学工作流一般都有自身所属的数据管理系统,如Pegasus工作流系统使用的数据放置Page3策略[4-5]:它首先预先分配数据到执行任务的计算单元,这样可以加快任务的执行速度,降低任务等待时间;然后动态地删除那些不会被后续任务使用的数据,以减少存储开销.但这种策略只是保证了数据传输的可靠性和有效性,并没有考虑到云计算环境下因为数据交互引起的跨数据中心之间的传输开销.为了减少数据传输开销,文献[6]采用副本机制,它使用改进后的贪婪算法和经过优化的遗传算法计算副本的最佳放置策略,并利用基于Web服务的数据网络系统ADPPS(AstronomyDataProcessingPipelineSystem)产生工作流来进行实验验证.但数据集副本机制增加了存储开销,该策略主要针对网络环境下多节点之间的数据传输而非针对云计算平台上多数据中心之间的数据传输,并没有考虑到数据之间存在相关性和依赖关系.另外一些研究对数据依赖进行了分析,如BitDew[7]由用户定义数据间的依赖关系,但并没有利用数据间的依赖关系减少传输开销.Gu等人[8]设计和实现一种分布式文件系统Sector/Sphere,系统中数据集是规模庞大的若干未分块(non-block)的文件集合;Sphere通过设置目录和文件树将文件按照数据局部性原则聚合起来,同时使用高速传输协议UDT[9]和文件副本减少传输延迟,实验结果表明,该系统比Hadoop①处理数据要快2~4倍,但Sphere只是根据任务来聚集数据,并没有对数据之间的关系进行仔细分析利用.Nephele项目[10]是现有的第一个数据处理框架,注重发掘在任务的调度、执行过程中IaaS云环境下资源的动态分配,有效地减少了资源使用开销,却没有减少数据传输开销.值得注意的是,以上的几种数据管理策略均不适用于云计算环境下数据密集型的工作流.针对云计算环境下数据密集型科学工作流问题,Yuan等人在文献[11]中提出了一种基于聚类矩阵的数据放置策略,用于多数据中心之间数据集的放置.该方法的数据放置策略分为两步,在科学工作流建立阶段,先利用所有数据集之间的关系构建一个相关度矩阵,然后通过BEA算法对相关度矩阵进行变换得到聚类矩阵,然后通过该矩阵将所有数据集划分为K个集合,每一个集合内部的数据集都是高内聚的,集合之间的数据集则是低耦合的;在科学工作流执行阶段,在考虑存储条件满足的情况下,新产生的数据集被放置在与它相关度最大的数据中心上.实验表明,该方法可以有效减少跨数据中心之间的数据移动次数.但这种方法并未考虑移动的数据大小,如果移动次数较少,但所移动的数据太大,传输开销不一定降低,导致科学工作流的执行效率反而下降.3科学工作流形式化描述和问题分析3.1相关模型和符号定义和参数模型.我们首先形式化定义了科学工作流的运行环境定义1.数据中心设为DC=∪i=1,2,…{dci},其中,dci=〈capi,csi,λini〉表示编号为i的数据中心,capi表示dci的计算能力,并用执行同一任务所需的时间的倒数来量化表示,并假设该值保持不变;csi表示dci的存储空间大小;λini表示在科学工作流建立阶段,数据中心可以使用的存储空间的比例[11].因为科学工作流执行过程中产生的中间数据有可能规模庞大,因此在原始数据分配阶段要留有一定的空间来存储中间数据,所以0<λini<1.λini是一个经验值,它的大小取决于科学工作流的性质.定义2.原始数据集设为DSini={d1,d2,d3…}表示在科学工作流建立时所存在的数据集,即所有原始输入.中间数据集设为DSgen={d1,d2,d3…},表示在科学工作流执行过程中所产生的数据集.固定数据集和非固定数据集分别设为FD和NFD.FD表示必须放置在固定数据中心的数据集,这是因为某些数据需要特定数据中心的特定设备才能处理,或者某些数据具有私有性和产权性.NFD表示没有固定数据中心的数据集,这是相对FD而言的.定义3.T={t1,t2,t3…}表示在科学工作流上运行的任务集,每一个任务执行都需要若干数据集作为输入.定义4.di=〈Ti,si,dci,fix_flag,depLink〉表示科学工作流中编号为i的数据集.其中Ti={t1,t2,t3…}表示使用di的任务集合;si表示数据集的大小;dci表示di所对应的数据中心;fix_flag为true表示di是固定数据,反之则为非固定数据;depLink是一个链表,将在定义5中详细解释.3.2实例分析与问题说明科学工作流在云平台中的运行过程可以分为以①Hadoop,http://hadoop.apache.org/(accessed2011.07.04)Page4下几步:(1)地理上分布在不同地区的若干数据中心构成了科学工作流运行的云计算环境;(2)使用者运行科学工作流时,需要向云平台申请资源,并对云平台进行定制;(3)使用者获取了所需要的运行平台后,上传输入数据并设置科学工作流的运行方式;(4)在科学工作流的建立阶段,按照特定的数据放置策略将使用者的输入数据集放置在合适的数图1一个简单的科学工作流以图1为例,科学工作流的数据放置策略需要考虑以下几点:(1)数据相关对科学工作流的影响.科学工作流运行中数据集和任务之间并不是一对多或者多对一的关系,而是多对多的关系,即一个数据集可能会被多个任务同时使用,一个任务也可能调用多个数据集.从图1(a)中可以看出,{d1,d2}同时被任务{t1,t2,t3}使用,{d3,d4_f,d6}同时被任务{t4}使用,{d5}被任务{t5}使用并且任务执行完毕后会产生一个中间数据{d6}.由于移动数据比调度任务代价更大,即相比之下调度任务的开销几乎可以忽略,所以需要将关系紧密的数据集尽量放置到同一个数据中心.(2)数据集大小对科学工作流的影响.图1(b)是按照文献[11]中的数据放置策略对产生的中间数据集{d6}进行放置.因为{d6}和{d1,d2}同时被两个任务{t2,t3}使用,{d6}和{d3,d4_f}同时被任务{t4}使用,所以{d6}产生后放置在dc1上,科学工作流总据中心,然后根据一定的任务调度策略将科学工作流中的子任务调度到合适的数据中心执行;(5)在科学工作流的执行阶段,大量的任务可能产生大量的中间数据集,这些中间数据集也需要放置到合适的数据中心,直到科学工作流运行完毕.图1(a)给出了一个科学工作流的例子,该科学工作流包含5个子任务{t1,t2,t3,t4,t5},5个输入数据集{d1,d2,d3,d4_f,d5}和一个中间数据集{d6},其中{d4_f}是dc2上的固定数据集,不能移动.的数据移动次数是两次.图1(c)使用的数据放置策略则将{d6}放在dc2上,科学工作流总的数据移动次数是5次.但如果考虑数据大小,比如{d1=1MB,d2=1MB,d6=30MB},那么图1(b)中数据移动次数虽然是两次,但数据移动量是60MB,而图1(c)的数据移动次数是5次,但数据移动量是34MB,总的数据移动量大幅减少.所以数据集大小对于科学工作流的数据放置策略和任务调度有着很大影响.(3)固定数据集对科学工作流的影响.因为固定数据集只能放置在特定的数据中心,无法向外传输,一旦任务使用到固定数据集,该任务一定会被调度到这个数据中心上执行.如图1(b)、(c)所示,t4使用了固定数据集d4_f,所以只能在dc2上执行,这不仅影响了原始数据集d3的放置,还影响了中间数据集d6的放置.所以固定数据集通过影响任务调度间接地影响了其它数据集的放置.(4)数据中心的计算能力、存储能力对科学工Page5作流的影响.由于各个数据中心隶属于不同的组织机构,其计算能力、存储能力可能差异较大.合理的数据放置策略也要也要将这两个因素考虑到,即在存储空间足够的前提下,向计算能力强的数据中心放置尽量多的数据集,以加快科学工作流的执行速度.由于数据移动开销对科学工作流性能影响较大,因此合理的数据放置策略应该努力减少数据移动量,本文针对这种情况提出了一种基于相关度的数据放置策略,该策略综合考虑了数据相关度(即数据之间被相同任务使用的多少)、数据大小、固定数据集、数据中心的计算能力和存储能力,有效提升了科学工作流的执行效率.4基于相关度的两阶段数据放置与任务调度策略基于相关度的数据放置策略包括建立阶段的数据放置策略和运行阶段的数据放置策略两部分.4.1建立阶段数据放置策略在科学工作流建立阶段,该策略对所有的原始输入数据集在逻辑上进行预分配,这样做可以优化数据分配方案,防止前期出现不合理分配的情况.预分配主要从局部性考虑,使得子任务在调度后,所需使用的数据集都尽量在本地数据中心上存储.预分配首先把所有的数据集分为两类:固定数据集(有固定数据中心的数据集)和非固定数据集(无固定数据中心的数据集),然后对非固定数据集中的数据属性进行研究,考虑数据集大小的前提下分析它们之间的数据相关度,然后根据数据中心的计算能力和存储能力对数据集进行预分配.所有原始数据集预分配完成以后,根据结果把数据集物理上分配到相应的数据中心.在这种方式下,数据相关度大的数据集原则上会分到同一个数据中心,拥有较强计算性能的数据中心原则上能分到更多的数据集.假定科学工作流总共使用m个数据中心.定义5.数据集相关度[12]设为depij=count(Ti∩Tj)×min{si,sj},di,dj∈NFD烄count(Ti∩Tj)×si,di∈NFD,dj∈FD烅count(Ti∩Tj)×si,di∈FD,dj∈NFD0,烆表示数据di和数据dj的相关度大小,其中count(Ti∩Tj)表示共同使用di和dj的任务数量.depij与数据集大小有关.由定义4知,数据集di有一个属性depLink,此处定义为depLink(i)={〈di,depij〉|j≠i},根据depij大小形成一个降序链表.定义6.预分配数据中心设为DCk,k=1,2,…,m,假定DCk的存储空间值为相应的dck存储空间大小.在科学工作流建立阶段,需要先将原始数据集逻辑上分配到DCk,k=1,2,…,m,然后按照DCk→dck的映射原则,将逻辑上的分配方案在物理的数据中心上实现.定义7.待分配数据集集合设为DCwait.在科学工作流建立阶段,该集合中存放的是与其它任何数据集相关度均为0的数据集;在科学工作流运行阶段,该集合中存放在后续过程中需要分配的数据集.有的原始数据进行预分配,其流程大致如下:如图2所示,在科学工作流建立阶段需要对所第1步(语句1~5).算法首先将所有的原始数据分为两类,固定数据集FD和非固定数据集NFD,由于固定数据集的数据中心是不能变更的,因此可以将它们预分配到相应的逻辑数据中心DCk.而对于在NFD集合中的每一个di,按定义5计算与其它所有数据集的相关度,并按照相关度的Page6大小降序排列,加入到它的属性链表depLink中,链表中第一个元素即是相关度最大的数据集.第2步(语句6~22).判断di的depLink中相关度最大的数据集dj是固定数据集还是非固定数据集.如果dj是固定数据集且对应的数据中心为DCj,若存储空间足够则将di预分配到DCj上,否则dj=di.depLink→next,然后重新分析计算.如果dj是非固定数据集并且已经分配到数据中心DCj,则处理方法同上;如果dj是非固定数据集并且还没有分配到数据中心,则根据各个数据中心的计算能力属性capi,找出计算能力最强的数据中心DCk,若存储空间足够则将di预分配到DCk上,不足则查找下一个计算能力强的数据中心,直到将di放置.如果与di相关度最大的数据集不存在,即所有的数据集和它的相关度都为0,则将di放置到DCwait上,等到最后阶段分配.第3步(语句23~27).对DCwait中的数据集进行预分配.对于每一个di∈DCwait,根据各个数据中心的计算能力属性capi,找到计算能力最强的数据中心DCk,存储空间足够则将di预分配到DCk上,不足则查找下一个计算能力强的数据中心,直到将di放置为止.预分配完成后,将逻辑数据中心DCi中的数据集映射到相应的物理数据中心dci,这就实现了科学工作流建立阶段的数据放置.4.2运行阶段数据放置与任务调度策略在科学工作流执行阶段,子任务执行可能会产生大量的中间数据集,这些数据集可能被其它或后续的子任务使用,由于这些中间数据集规模可能非常庞大,且数据中心之间存在带宽限制,因此仍需要对这些数据集进行合理放置.基于相关度的数据放置策略将中间数据集放置到与它相关度最大的数据中心上,如果该中心存储空间不足,则按照该策略中的Adjustment算法对全局数据集进行调整.dc_depmk=∑N据中心dcm上数据集di所需使用的任务集,N表示dcm上数据集的个数,Tk指使用数据集dk的任务集集合,sk表示数据集dk大小.定义9.调度任务tk在数据中心dcm上执行引起的传输开销设为transCostmk=[size(DSk)-size(DSk∩DSm)+size(DSgen-DSm)],其中size(DS)表示集合DS中所有数据集大小之和,DSk是任务tk所需使用的数据集,DSm包含数据中心dcm上的所有数据集,DSgen表示任务tk执行完毕后产生的数据集,DSm表示DSgen中应该放在dcm上的数据集.定义8.数据集dk和数据中心dcm的相关度传输开销中[size(DSk)-size(DSk∩DSm)]表示tk在dcm上执行需要从其它数据中心调入的数据集大小,size(DSgen-DSm)表示tk在dcm上执行完毕后产生的中间数据集向其它数据中心发送的数据集大小.如果transCosthk=mink到dch上执行所引起的传输开销是最低的.科学工作流运行阶段数据放置与任务调度算法如图3所示.科学工作流运行的时候,从任务集合中选取任务ti,根据定义9将ti调度到合适的数据中心执行,执行完毕后若产生新的任务和新的数据集,则首先更新任务集合,然后给新产生的数据集选择合适的数据中心放置.对新产生的中间数据dk,根据定义8计算其与所有数据中心的相关度dc_depmk,选择相关度最大的数据中心分配,如果该数据中心存储空间不足,表明科学工作流已经运行了一段时间,出现了负载不均衡,因此需要对所有数据集进行重新调整.调整算法如图4所示,详细过程如下:第1步(语句1~31).对所有数据中心上的数据集进行预分配.预分配过程和科学工作流建立阶段算法相似,只在两种特殊情况下略有不同.一种情况如语句19~23所示,如果与非固定数据集di相关度最大的数据集dj未分配,且di归属物理数据中心dck,则将di放置在DCk上,若di也未分配,则按照数据中心的计算能力为di寻找合适的数据中心放置;另一种情况如语句27~30所示,对于DCwait中的每一个数据集,处理方法和前一种情况相同.第2步(语句32~38).预分配完成以后,对所有逻辑数据中心DCi和物理数据中心dci上的每个数据集dk进行对比:若dk∈DCi且dk∈dci,则不需要移动;若dk∈DCi且dk∈dcj(j≠i),则将dk从dcj移动到dci.Page75实验分析5.1实验环境和设置为了验证基于相关度的数据放置策略效果,在“天河”集群上建立了一个包含80个节点的测试平台,每一个节点包含一个IntelXeonE55402.53GHz的四核CPU.为了模拟云计算平台,在每个节点上安装Xen并在上面创建了虚拟集群以模拟数据中心;为每一个CPU核创建一个带有存储空间的计算实体,每个数据中心包含16个计算实体,于是共有20个数据中心;为了对数据进行管理,在每个数据中心上安装了ApacheHDFS,并运行SwinDeW-C(SwinburneDecentralisedWorkflowforCloud)[13]用来解释和执行工作流.由于实际的科学工作流(如大气科学工作流)不能全方位检测基于相关度的数据放置策略策略的效果,只能部分验证,因此本文将采用模拟的、可定制的科学工作流来测试基于相关度的数据放置策略.通过分别改变科学工作流的数据集和任务的数量来控制科学工作流的复杂度;通过改变上界与下界来控制数据集大小的取值范围;同样,固定数据集的比例和数据中心的数量也可以进行调整.实验过程中,为了保证结果的可靠性,每一个科学工作流在保持配置和云平台环境不变的情况下,运行300次后取平均值作为测试结果.为了说明本文所提数据放置策略的效果,实验对比了3种数据放置策略,分别是Random、Cluster和本文所提出的基于相关度的数据放置策略.Random策略:输入数据集在建立阶段随机的放到其中一个数据中心,如果是固定数据集则放置到指定的数据中心;运行阶段,如果空间足够,产生的中间数据集则存放在本地数据中心,否则随机放置到其中一个数据中心.在网格、集群系统中,产生的中间数据集就是存放在本地或者随机放在存储空间富余的结点上.Cluster策略:在文献[11]中提到的数据放置策略.在建立阶段,把所有的输入数据分为K个数据集合,把这K个数据集合放置到合适的数据中心;在运行阶段,把新产生的数据集放置到合适的数据中心.基于相关度的数据放置策略:本文所提的数据放置策略,在文章后续部分所有图示中用Data-dependence表示该策略5.2测试结果及分析5.2.1数据集数量变化对结果的影响图5显示的是当数据集数量增加时,数据移动图5数据集数量变化对数据移动次数和移动量的影响Page8次数和数据移动量的变化趋势.实验设定如下:科学工作流任务量N和数据集数量N取相同的值,数据集的变化范围设为1~500MB,固定数据集比例为20%,数据中心为15个.实验结果表明,随着数据集数量的增多,本文所使用的策略和Cluster策略在数据移动次数上相差无几,相比Random策略,数据移动次数明显减少;数据移动量方面,3种策略随着数据集规模增加而呈现出近似的线性增长,Random策略效果最差,Cluster策略次之,基于相关度的数据放置策略则比Cluster策略在数据移动量少约10%.原因分析:Cluster策略按照最大数量的原则将数据集聚集在同一个数据中心,而基于相关度的数据放置策略按照最大流量的原则将数据集聚集在同一个数据中心;同时,在运行阶段Cluster策略将任务调度到包含数据个数最多的数据中心,基于相关度的数据放置策略则将任务调度到数据量最多的数据中心,所以任务执行时,基于相关度的数据放置策略引起的数据传输量就会明显减少.5.2.2数据集大小取值范围变化对数据移动量的图6表示数据集大小幅度改变时数据移动量的变化趋势.实验设定如下:科学工作流任务量为80,数据集数量为80,固定数据集比例为20%,数据中心为15个,数据集大小的平均值是250MB.图6数据集大小变化幅度对数据移动量的影响实验结果表明,当数据平均值相同时,Random和Cluster策略的数据移动量变化幅度很小,在某一平均线上下浮动,而基于相关度的数据放置(Data-dependence)策略则不同,数据集大小的变化幅度越大,数据移动量越少.原因分析:若数据大小变化幅度很大,则Data-dependence策略在大多数情况下会选择移动规模小的数据集,这样就降低了数据移动量.5.2.3固定数据集比例的改变对数据移动量的影响图7表出的是固定数据集比例改变时数据的移动量的变化趋势.实验设定如下:科学工作流任务量为80,数据集个数为80,数据中心为15个,数据集的变化范围是1~500MB.实验结果表明,随着固定数据集比例上升,3种策略的数据移动量都是先增后减.从图7中可以看出Random策略数据移动量最大,Cluster比起Random策略性能有很大提高,而相比Cluster,当固定数据集比例超过15%后Data-dependence策略又有较大提高.原因分析:随着固定数据集比例的上升,因为固定数据集的因素,某些任务只能调度到特定数据中心执行,如果这些任务使用了非固定数据集,那么非固定数据集的移动次数会不断上升,导致传输的开销逐渐增大,导致3种数据放置策略的数据移动量都呈上升趋势;当固定数据集达到一定比例后,非固定数据集的数量越来越少,3种数据放置策略传输开销都在减少.在Data-dependence策略中,若任务中存在固定数据集,则该任务中使用的非固定数据集很有可能与固定数据集放置在同一个数据中心,相比Cluster明显减少了数据移动量.5.2.4数据中心数量变化对数据移动量的影响图8给出的是当数据中心数量改变时数据移动Page9量的变化趋势.实验设定如下:科学工作流任务量为80,数据集数量为80,固定数据集比例20%,数据集的变化范围是1~500MB.实验结果表明,随着数据中心数量的增多,3种策略的数据移动量都在逐步上升.可以明显看出,Random效果最差,Data-dependence策略比起Cluster也有很大的性能提升.原因分析:随着数据中心数量的增多,平均每个数据中心分得的数据集将减少,任务执行时调用其它数据中心数据集的可能性增加,导致数据传输量上升.Data-dependence策略要优于Cluster策略,再次表明考虑数据集大小的计算调度方式可以减少数据传输流量.5.3小结当数据集的变化范围为1~500MB、固定数据集比例为20%及数据中心为15时,随着数据集数量的增多,本文所使用的基于相关度的数据放置(Data-dependence)策略相比Cluster策略在数据移动量方面减少约10%;当任务量为80、数据集数量为80、固定数据集比例为20%、数据中心为15及数据集大小的平均值是250MB时,Random策略和Cluster策略的数据移动量分别在50GB和40GB上下浮动,而基于相关度的数据放置策略的数据移动量则呈递减趋势,数据集大小上下限之差每增大100MB,数据移动量减少2%~3%;当任务量为80、数据集个数为80、数据中心为15及数据集的变化范围是1~500MB时,Cluster比起Random策略数据移动量有了大幅度减少,而相比Cluster策略,基于相关度的数据放置策略在固定数据集比例在15%~40%时,数据移动量减少约10%~11%;当任务量为80、数据集数量为80、固定数据集比例20%及数据集的变化范围是1~500MB时,随着数据中心数量的增加,基于相关度的数据放置策略比起Cluster策略在数据移动量上减少7%~11.5%,而且随着数据中心数量的不断增多,这个比率将持续增长.综合以上实验结果,基于相关度的数据放置策略在降低数据传输开销方面要明显优于Cluster策略和Random策略.所以,基于相关度的数据放置策略可以有效提高科学工作流的执行效率.6结论与展望本文首先对科学工作流在云平台上的执行过程做出了分析,指出了多个数据中心之间的数据传输开销是制约科学工作流执行性能的一个瓶颈,并在此基础上提出了一种基于相关度的数据放置策略,该策略综合考虑数据相关、数据集大小、固定数据集比例及数据中心计算能力.通过与其它数据放置策略进行实验对比,结果表明这种数据放置策略可以有效提升科学工作流的执行效率,减少跨数据中心之间的数据传输流量.下一步准备在本文工作的基础上进行副本机制的研究.注意到云计算平台收费的特点,在综合考虑计算代价和存储代价的基础上加入副本机制,进一步提升科学工作流的执行性能.
