Page1数据密集型科学与工程:需求和挑战宫学庆1)金澈清1)王晓玲1),2)张蓉1)周傲英1),2)1)(华东师范大学软件学院上海市高可信计算重点实验室上海200062)2)(复旦大学上海市智能信息处理实验室上海200433)摘要科学研究在经历了实验科学、理论科学、计算科学阶段后,进入了数据密集型科学阶段,与之相伴的是大数据时代的到来.大数据泛指规模达到几百TB,甚至PB级的数据①,其典型的特征是分布、异构、低质量等.尽管传统数据库管理技术(特别是商业关系型数据库)在过去40年间取得了巨大成功,但是这些技术和系统无法有效管理支持数据密集型科学与工程(Data-IntensiveScienceandEngineering,DISE)的大数据.文中探讨数据密集型科学与工程的具体需求和现实挑战.它涵盖的内容表现在4个层面,包括数据存储与组织、计算方法、数据分析以及用户接口技术等.同时,数据质量、数据安全、数据监护等内容也需要在各层面得到重视.文中尝试梳理了数据密集型科学与工程的整体架构,回顾了相关领域的新近发展,分析了面临的挑战,探讨了未来的研究方向.关键词大数据;数据密集型科学与工程;需求;挑战1引言大数据管理技术业已成为当前和未来一段时间内计算机领域的重要研究课题之一.美国的总统科学顾问委员会于2010年底提出一份报告,认为“数据规模呈指数增长,……各联邦机构都需要制定应对‘大数据’的策略”①.所谓大数据,泛指规模达到几百TB,甚至PB级的数据,广泛出现在科学研究、Web集成、多媒体等诸多领域中.JimGray(图灵奖获得者)认为,当今时代已是数据密集型科学研究时代(即eScience时代),科研人员的工作重心多已转向如何分析海量数据,并获取知识[1].例如,天文望远镜是重要的天文观测工具,正在建设中的LSST天文望远镜(LargeSynopticSurveyTelescope)在服役后每天将会产生30TB数据②.Web数据的规模增长也非常迅猛,根据中国互联网络信息中心(CNNIC)的调查报告,截至2010年底,我国网民规模为4.57亿人,网页数目约60G,总内容超过1.8PB③,而国内网页的内容量仅占整个互联网的一小部分.多媒体数据(包括视频、音频、图片等)也非常庞大.据2008年数据统计,Facebook公司存储着10亿张照片,约1PB规模④.其它领域例如医疗、金融、电子商务、物流等也产生并使用大数据.大数据除了规模庞大之外,还兼具分布式、异构、不准确、不一致等特性,因而管理难度加大.以海洋观测科学研究为例,为了监测较大海域的洋流变化情况,需在海水中、海平面、海床分别部署大量传感设备和工业机器人,这些设备(或者机器人)通过无线网络将数据传回服务器,分析人员结合现有资料(例如文档、图片、视频等)分析数据.在此过程中,数据由分布在不同地理位置上的多个节点产生;受传感设备精度、海洋环境、人工操作等因素的影响,所采集数据可能并不准确;数据来源多样,因而可能存在不一致性,需要采用多种手段提升质量.大数据管理已经得到了国内外学者的极大关注.《自然》杂志的2008年9月专刊提出的观点是,人类已经进入拍字节时代(petabyteera),大数据在各领域广泛出现.该杂志还预测下一个IT巨头的主营业务将会是大数据管理[2].微软研究院出版的《Thefourthparadigm》一书以科学研究为切入点,阐述了如何在eScience时代做数据密集型的科学研究[1].《科学》杂志的2011年2月份专刊讨论如何管理大数据[3].我国学者也密切关注大数据领域.《中国计算机学会通讯》2011年7月刊的专题《数据密集型计算》从不同角度阐述了数据密集型计算(Data-IntensiveComputing)的相关技术,也介绍了几位专家正在开展的工作[4].以上论著侧重于从一些具体方面介绍、分析大数据对传统数据管理技术的强烈冲击.事实上,大数据的出现已经在数据管理的各个层面产生了深刻的影响,数据密集型科学与工程(Data-IntensiveScienceandEnigeering,DISE)已经成为目前国内外的一个研究热点.本文尝试梳理了DISE的整体架构,回顾了相关领域的新近发展,探讨了DISE的研究方向和所面临的挑战.DISE的基本框架如图1所示,包括数据存储和组织、计算方法、数据分析、用户接口等4个方面,以及在整个数据管理过程中需重视的数据质量、数据安全、数据监护等问题.首先,需要合理地存储与组织各种大数据,如科学数据、Web数据、多媒体数据等.鉴于集中式存储策略无法提供良好的I/O访问效率,需要设计分布式存储策略.在数据存储和组织过程中还需要考虑数据世系(dataprovenance)和数据集成(dataintegration)因素.数据世系是指数据产生及演化的整个过程,在数据质量评价、数据核查、数据恢复和数据引用等方面都具有重要意义[5].数据集成将不同来源的数据有效地集成在一起,提供统一的数据访问模式.其次,需要设计高效的计算方法来管理海量数①ites/ostp/pcast-nitrd-report-2010.pdf②③④Page3据,包括分布式计算、数据流技术、新硬件技术、高性能计算等.分布式计算方法将整个计算任务分摊到不同计算机上执行,大大降低了查询与分析的时间,其挑战性在于如何执行任务的分解和归约操作.目前用的比较多的任务分解方式是数据分解.与分布式计算方法不同,数据流管理技术强调如何提升单台计算机的计算效率,它一般仅仅使用少量内存空间,以单遍扫描方式访问数据集合,并获得较高质量的近似结果;若给予更多的内存空间,查询结果的质量可以进一步提升.另外,开发新型计算不可忽视硬件技术的革新.近几年来,嵌入了多个“核”的多核处理器得到长足发展,每个“核”都具有独立的计算能力,因而其计算能力大大超过单核处理器.但是传统的串行算法无法发挥多核处理器的计算能力,需要重新开发多线程并行算法.图形处理单元(GPU)和现场可编程逻辑器件(FPGA)等硬件设备也得到了越来越多的关注,这些器件都具备并行处理能力,适合解决特定问题.还有,超级计算机具有不可比拟的计算能力,因而高性能计算也是大数据管理的重要内容.再者,数据分析层需要挖掘隐藏在海量数据背后的知识和规律.语义分析和数据挖掘是两种较为常用的技术手段.语义分析技术从海量数据中找出对象的具体特征,并以这些特征来描述对象.数据挖掘技术也是典型的知识抽取技术.用户接口层是用户与计算机系统之间的接口,主要包括海量数据可视化、数据库服务(DaaS)和云计算(Cloud)等.海量数据可视化以图形化界面形式呈现数据,使用户更深刻地理解数据本质,该技术可视为是计算机技术、设计美学、领域知识的完美结合.DaaS是指企业(数据拥有者或数据库拥有者)将自身的数据库创建、访问、维护、升级、管理等任务委托给专门的第三方(服务提供者或数据库服务提供者)进行管理和维护.云计算是近期兴起的一项新技术,以云的方式向用户提供服务.大数据的内容丰富,包含高价值的信息和知识,经常是在云计算平台上通过服务的方式提供给用户.最后,数据质量、数据安全和数据监护贯穿DISE的各个层面.数据质量高低会严重影响数据管理的成败.产生低质量数据的原因很多,包括设备精度、外部环境、人工操作等;低质量数据的表征也有多种形式,包括冗余、不一致、不准确、缺失等.在大数据应用中,数据来源更广,因而数据质量问题也更为严重.数据清洗技术可以提升数据质量,但无法完全解决数据质量问题,因此仍需在数据质量较低的情况下进行查询分析,并获得查询分析结果.由于大数据应用往往涉及诸多用户和机构,数据安全的重要性不言而喻,典型应用包括军事、金融、电子商务、保险等.在数据存储与组织层,需要考虑以密文方式存储;在计算方法层和数据分析层,需要考虑设计数据存取策略,分权限访问数据;在用户接口层,需要制定服务执行的访问策略.数据监护是指对数据资产的选择、维持、维护、收集和打包的整个过程.本文第2~6节分别介绍DISE的4个层面的基本内容(即:数据存储与组织、计算方法、数据分析、用户接口)以及贯穿各个层面的数据质量、数据安全和数据监护相关技术,并分析所面临的挑战;第7节列举2个典型的大数据应用,即社会计算和信息-物理融合网络;最后,第8节总结全文.2数据存储与组织2.1分布式数据存储策略为了提高数据吞吐效率、降低故障率,一般采用分布式策略存储海量数据.基本策略如下:所有数据被放置在多个存储设备之中;存储设备通过高速网络相互连接;为各数据准备多个副本,分别放置在不同存储设备之中;仅当数据块的所有副本均无法被访问时,该数据块才无法被读取;建立分布式索引,当系统接收到数据访问请求时,能够快速决定从哪些存储设备中读取数据.谷歌公司的GFS(也被称为GoogleFS)[6]和Hadoop项目的HDFS[7]是两个最知名的分布式文件系统.GFS将集群内的节点划分成两类,包括一个主服务器(master)和多个块服务器(chunkserver).主服务器维护文件系统的元数据信息,但不存储文件内容;块服务器存储文件内容.块服务器的最小读写单位是块(chunck),缺省为64MB.每个文件首先被划分成若干个块,分别放置在不同的块服务器中.主服务器记录各块的存储细节.当用户试图获取某个文件时,需向主服务器发送请求;主服务器搜寻该文件的元数据信息,并反馈给用户;用户再与相应块服务器通讯以获取数据.HDFS也采用类似方式存储数据:namenode节点(和辅助namenode节点)存放文件的元数据信息,datanode节点放置文件信息[7].GFS和HDFS系统能有效管理无结构数据,也能管理简单结构的数据,如码-值对(key-valuepairs)结构的数据.此后,为了管理复杂结构数据,科研人员又纷纷基于这两种文件系统推出新的数据Page4存储策略.谷歌公司提出了基于GFS的BigTable技术[8],它维护多张表(table),每个表是一个多维的稀疏图;表由行和列组成;各行和列指定的存储单元均包含值和时间戳信息.当表规模太大时,可将表根据行分割成若干个子表,即Tablet.基于HDFS文件系统的有结构存储方法很多,包括Hive、HBase、HadoopDB等[7].这些系统增加了数据格式,可提供类似SQL语句的查询表达能力.行存储(row-store)和列存储(column-store)是两种典型的数据库物理存储策略.行存储方式较为传统,它在磁盘中依次保存每条记录,比较适合事务操作;列存储方式垂直划分关系表,以列为单位存储数据,列存储还具有数据压缩(compression)、延期物化(latematerialization)、块循环(blockiteration)等特性[9].由于数据分析任务往往仅使用较少字段,因此列存储方式的效率更高.数据分析任务在大数据应用中更为常见,因此许多系统尽管无法完全实现列存储的所有特性,但也或多或少地借鉴了相关概念,包括BigTable、HBase等.BigTable在逻辑上提供了列族(columnfamily)的概念,在物理存储上仍旧是按照行方式存储[8];HBase将每一个列存储在独立的文件之中①.分布式数据存储策略对于大数据应用来说非常关键.但是现有研究成果仍然具有一些局限性:(1)未能充分满足应用需求,特别是针对复杂数据结构的要求.倪明选等人[10]认为,现有工作并未延伸到时空数据,特别是移动对象数据领域,没有考虑到时空数据的复杂结构和查询处理的复杂性;(2)正如廖小飞等人[11]所认为,应该重视数据的放置和调度,不合理的数据放置策略会增加网络和存储I/O开销,降低系统性能;(3)数据的存储与组织还应该关注列存储技术,设计优化措施.正如文献[9]提到的那样,仅仅将数据按列存储并不充分,还需要引入其它一些优化措施.2.2数据世系数据世系一般出现在包含多数据集的应用中,用于描述数据的产生并随着时间推移而演化的整个过程[5],其价值在于可评价数据质量并在发生故障时恢复数据.若缺乏外部辅助信息,评估数据集合的质量比较困难,但是当充分了解数据进化过程时,就较易做出判断.以食品安全监督为例,菜品从田间到超市经历多道环节,仅凭人工观察无法正确判断菜品的质量,而当菜品从生产、物流、批发、零售等各环节均可溯源时,则可以更全面地反映出菜品的安全状况.数据世系也可用于数据恢复,当某一个中间环节被检验出错误时,可以利用前序过程恢复数据.数据世系一般有两类基本方法:非注解的方法(nonannotation-basedapproach)和基于注解的方法(annotation-basedapproach).前者采用模式映射方式,使用数据处理函数和其相对应的反向函数.例如,令R表示关系S1和S2的连接结果,则R中的每条记录均可在S1和S2中找到对应记录.在更复杂的例子中,可能并不存在集合之间的可逆函数,必须使用注解描述世系.事实上,基于注解的方法的应用范围要远远高于非注解的方法.数据世系可针对多种数据类型,包括关系型数据、XML数据、不确定数据等.加州大学圣克鲁兹分校的DBNotes项目主要研究关系型数据库的世系,采用的主要手段是增加注释信息②;Buneman则尝试研究针对XML数据的世系工作[12].斯坦福大学的Widom将不确定性和世系结合起来,研究针对不确定数据的世系管理③.在大数据时代,数据世系的研究工作需关注以下几个方面:(1)如何有效整合工作流世系(workflowprovenance)[13]和数据世系.工作流世系和数据世系的粒度、侧重点均不相同.工作流世系强调数据集合的演化过程,数据世系则记录各个元组的演化过程.在大数据时代,仅强调数据世系意味着产生海量注解信息;仅强调工作流世系则无法得到数据的具体演化信息,因而有必要探寻二者的结合点;(2)如何解决异构世系标准的融合问题.大数据应用将涵盖更多的原本可能相互隔离的数据集合.例如,大型医疗保健系统需要结合医疗机构、卫生部门、民政部门的数据,如何将适用不同标准的数据世系信息整合在一起就很关键;(3)还需要关注数据世系的可视化问题.图形化界面是最好的描述数据演化过程的方式,探讨如何将数据世系以友好的方式呈现给用户也是亟待解决的问题.2.3数据集成数据集成的目标是把不同数据源整合在一起.大数据应用往往涉及诸多数据源,并且它们的数据模式也可能不一致.造成这种状况的原因是多方面的.首先,这些数据源在设计或收集阶段相对独立,并未预计到在将来可能会整合在一起;其次,各数据源的应用目标不尽相同,客观上无法采用相同的数据模式;最后,各数据源的相关说明文档可能并不全①②③Page5面或者已经丢失.图2描述了数据集成的过程,包含3个阶段.在第1阶段,将不同数据源的数据模式映射为一个中间模式,以该中间模式描述所有数据源;在第2阶段,通过重复数据检测技术检测出位于不同数据源但描述真实世界的同一对象的数据(这些数据可能并不一致);最后,数据融合(datafusion)技术综合各数据源的数据,找到恰当的形式来描述真实世界的各个对象[14].DeepWeb数据集成就是一个典型案例.所有Web数据按照所包含的信息的深度大致划分为两大类,即SurfaceWeb(也称为VisibleWeb)和DeepWeb,其中SurfaceWeb包含可以被搜索引擎索引的页面,而DeepWeb则是指传统搜索引擎无法索引的Web内容,例如私有Web页面、动态内容、未链接的内容、脚本产生的内容等.DeepWeb的规模非常大,有调查显示,仅在2000年,DeepWeb的规模就已经达到7.5PB①.文献[15]综述了在DeepWeb数据集成方面的工作.在大数据应用中,数据集成仍有许多问题值得探讨:(1)如何在一个系统中集成不同类型的数据源.例如,Halevy认为,在SurfaceWeb中包含很多表格,将这些表格与DeepWeb相融合将能更好地管理Web②;(2)如何设计自动化方法实现从数据源到中间模式的映射.当数据源数目众多且数据模式差异较大时,仅靠人工手段无法高效完成这项任务,需要制订一些规则自动生成中间模式;(3)如何获得完整、简明、一致的数据融合方案,即方案不仅可以包含数据源中所有相关对象和属性,也可以包含相关的描述,这些描述既不赘述也不相悖[14].3高效的计算方法3.1分布式计算架构对于计算量大的任务来说,一个很自然的方案就是采用分布式计算架构,分解整个任务,并在不同硬件设备上运行子任务,以减少总计算时间.分布式数据库系统就是如此.然而,如前所述,分布式数据库系统保留了许多集中式数据库管理系统的特性,管理开销较大,当数据规模持续增大时,过大的管理开销最终导致无法有效地管理数据.因此,研究人员转而尝试设计更简洁的分布式计算架构来管理大数据,例如MapReduce技术(特性比较见表1).数据大小GB访问更新结构完整性高横向扩展非线性MapReduce是谷歌公司提出的分布式计算框架,比分布式数据库系统简洁[16].该架构包含两个核心概念:Map和Reduce.Map函数将整个任务划分成若干子任务,并在不同硬件节点执行子任务;Reduce函数整合Map函数产生的中间结果,生成最终查询结果.Map任务之间相对独立,当某一个Map任务出现故障时,可重新启动运行该任务而不会影响其它正在运行的Map任务.用户可以根据任务量大小调整执行Map和Reduce函数的主机数量.Hadoop项目也实现了MapReduce架构.表1比较了关系型数据库和MapReduce的主要区别,可以看出,MapReduce所管理的数据规模更大,可扩展性更佳[7].Dryad是微软公司提出的分布式计算架构,它使用无环图(DAG)描述任务的分解,支持数据并行的应用③.尽管MapReduce和Dryad框架已经得到了广泛研究与应用,但是研发新分布式计算架构的脚步并未停滞.从某种意义上讲,与分布式数据库系统相比,MapReduce、Dryad只是从一个极端(至繁)走向了另外一个极端(至简).分布式数据库系统倾向保留数据库系统的更多特性,而MapReduce和Dryad则希望尽量简化数据管理步骤.正如文献[1]指出的那样,尽管这些简化版的分布式计算架构已经显示出管理大数据的巨大潜力,但这并不意味着它们已经是最优选择了,适当引入某些新特性(例如,合适①②③Page6的索引)之后,系统性能还可能显著攀升.此外,过敏意等人[17]认为应该将GPU引入到框架中,以满足计算密集和数据密集混合的需求.3.2数据流技术如前所述,分布式计算架构利用更多硬件设备来降低计算时间,而数据流技术则侧重提升单台主机的处理能力.令N表示数据流大小,ε表示误差参数,数据流算法在内存中维护一个大小为poly(logN,ε)的概要数据结构,在必要时也可以根据该数据结构计算查询结果.数据流算法一般仅能够返回近似查询结果,但是当内存资源增加时,查询结果的质量会相应上升.重要的概要数据结构包括AMSsketch[18]、Bloomfilter[19]、FM-sketch[20]等,其中,AMSsketch能估算频数矩阵;Bloomfilter可判断指定元素是否存在于一个集合之中;FM-sketch可估算相异元素的个数.典型的模型有界标模型、滑动窗口模型和衰减窗口模型,其中,界标模型考虑所有的数据元素;滑动窗口模型仅考虑最新的W个元素(W是指窗口的大小);在衰减窗口模型中元组的重要性会随着时间推移而降低.数据流技术仅需单遍扫描数据,从而可以显著降低磁盘I/O开销.分布式数据流管理技术可在分布式网络拓扑环境下管理多数据流.典型的网络拓扑结构有星形结构和树形结构.在星形结构中,所有客户端节点均与一个服务器通过(无线)网络相连接;在树形结构中,所有节点组成一棵树,非叶节点既作为数据中转站,也可以采集、处理数据.在分布式环境下,内存和CPU资源则相对丰富,而网络传输带宽资源可能成为瓶颈.分布式数据流技术的目标在于尽量降低网络传输开销,并保证查询结果的质量.但是,现有数据流研究成果仍旧无法有效管理大数据,需要开发新技术.原因之一在于现有的单数据流解决方案仅利用有限硬件资源(一般指单台计算机),能够在较短时间内处理完“较大”规模数据,却无法快速处理“大规模”数据.原因之二在于现有的分布式数据流技术以降低网络通信开销为主要目的,而网络带宽并不总是系统的资源瓶颈.目前,一些学者已经在探索将数据流技术与MapReduce框架相结合,以降低查询处理时间[21];还有一些学者则尝试使用多核处理芯片来加速处理数据流问题[22].总体来说,这些研究均刚刚起步.3.3新硬件技术3.3.1多核处理器在过去几十年间,业界主要通过提升时钟频率、优化指令执行、使用缓存等方式来提升处理器的性能.但是当处理器的主频已经达到一个高点且指令执行策略已经比较复杂时,再大幅度提升单个处理芯片的性能就会非常困难.因此,工程师们将研发重点转向多核处理器,即在一个处理器内部嵌入多个“核”,每个“核”都有计算能力.一般来说,每个核的运算能力可能弱于最先进的单核处理器,但是多核的总运算能力则会远高于单核处理器.目前已经出现了8核芯片,在未来几年间,单个处理器的核芯片数目还会进一步增加.例如,龙芯3B处理器已经集成了8个64位超标量处理核①.从某种意义上讲,一个配备了多核处理器的计算机可被视为共享内存的并行处理系统.多核芯片的出现对软件开发产生了深远的影响.传统的串行算法无法发挥多核芯片的潜能,必须设计并行算法,将计算任务均匀分摊到各个核之中.多核编程一般采用多线程开发模式.目前主要有两种分解模式,即任务分解和数据分解.任务分解是指依据任务执行的先后次序制定工作流程,再将整个工作流程划分成若干个子任务,相互独立的子任务可以划归不同核来执行,整个任务的完成时间等价于工作流程的最长路径长度.数据分解将待处理的数据集合划分成若干个小数据集合,由不同线程进行管理,最后将所产生的中间结果聚集起来,生成最终结果.加速比(speed-up)是衡量并行算法优劣的重要度量,它描述指定并行算法相对于最佳串行算法的性能提升程度.近期也有一些工作针对多核计算进行了优化.文献[22]提出了一种在多核芯片上挖掘频繁元素的方法,这种基于合作机制的设计模式优于传统的基于竞争机制的设计模式.文献[23]提出了两种利用多核架构来计算skyline的方法,即pskyline方法和并行BBS方法.实验结果表明,pskyline方法优于并行BBS方法.在海量数据情况下,多核技术仍然面对一些挑战:(1)如何分解任务和整合中间结果.不同数据管理任务的处理难度不尽相同,例如,整体型聚集函数(holisticaggregatefunction)的结果依赖于全部数据;(2)如何解决负载均衡问题.不同线程所处理的任务量可能并不均匀,从而导致一部分线程空闲而另一部分线程满负荷运转.出现这种情况时,需要动态调整负载,使各核的使用情况相当;(3)需要考虑①http://www.loongson.cn/Page7超多核情况.在未来,单个处理器的核数目可能会远远高于现阶段,各个核之间的资源竞争更为剧烈,如何设计更优的编程模式成为一个重要问题.3.3.2GPU和FPGA除了通用处理器CPU外,GPU(图形处理单元)、FPGA(现场可编程逻辑器件)等也频繁用在科学计算上.GPU可以被看作是一类遵循单指令流多数据流(SingleInstructionstream,MultipleDatastream,SIMD)架构的并行处理器.当需要在大批量数据上执行相同指令时,能够显著提高执行效率.目前有多种GPU编程模型,包括NVIDIA的CUDA、AMD的流SDK和OpenCL等.文献[24]提出了一种利用GPU集群对海量文档进行聚类的算法,该算法也可以计算文档集合的TF-IDF矢量.实验结果表明,与单独采用CPU的技术相比,同时使用CPU和GPU之后能将性能提升十倍以上.GPU也常被用于执行海量数据挖掘任务,例如聚类[25].现场可编程逻辑器件(FPGA)芯片包含大量逻辑门(比如AND、OR、XOR、NOT等),逻辑门之间的配线可以通过软件编程实现.合理设置逻辑门之间的配线可以实现并行计算.文献[26]演示如何基于FPGA实现任务级、数据级和流水线级的并行计算,并综述了新近的研究成果.现有研究成果表明,合理使用GPU和FPGA等非传统型处理器能够有效提升数据管理效率.但是,熟练使用这些设备并不容易,需要深入理解相关的硬件知识.GPU面向SIMD并行架构,需要从待解决的问题中提取出数据并行的步骤,并进行优化.3.4高性能计算高性能计算使用超级计算机和计算机集群来解决复杂计算问题,尤其是针对科学与工程应用中出现的数据处理问题.当前,高性能计算机每秒能进行超过千万亿次的浮点运算,它集成了网络与安全系统管理、并行处理技术,综合了数字电子、计算机体系结构、系统软件、程序语言、算法和计算技术.高性能计算是高技术科技和基础科研领域的工作顺利开展的基石.这些领域通常要对处理对象进行数值模拟、动态显示和结果预测及验证.在过去的几十年中,模拟计算是科学研究的重要内容,用于验证一些未知或者很难分析的理论、模拟一些难以实际操作或代价昂贵或太危险的实验.传统上,计算性能提升的一大途径是商业计算硬件的快速发展,比如处理器、存储器和数据存储系统.如前所述,大数据不仅仅来源于科学与工程应用,还包括网络数据以及电子商务数据.为适应网络时代的数据存储、分析工作,近几年,部分高性能计算系统的研究工作已经转向计算机集群和网格计算———通过增加系统规模(如增加组件)来扩充性能.例如,采用集群计算机来支持商业数据处理,包括数据仓库、在线交易处理等.性能指标不仅仅指FLOPS(每秒浮点计算能力),还包括图操作处理速度、处理响应速度、高带宽和低延迟等.数据密集型计算和集群密不可分,而数据分析工作往往不可能完全分割成独立的模块,因此,在集群上的高性能计算与独立的超级计算机相比要面对更多的挑战性任务,其中一个最主要的问题是传输瓶颈:大规模数据在不同处理器间的传输以及在节点间的传输;还有并行处理中的错误检测和处理.为了支持高效的数据密集型计算,还需要继续在硬件、软件系统和算法上做基础研究,而大规模并行算法是必需的技术之一.硬件研究主要包括设计新型的IC(IntegratedCircuit)用于集成大规模处理器、新的芯片通信框架、系统级的宽带互联网络等.综合考虑软硬件的设计有助于实现可靠的并行计算系统、面向特定应用(如特别数据结构、特别算法)的机器设计.软硬件设计的新方法必须满足数据密集型计算的要求,包括针对非数值型应用,如图形操作.特别需要提及的是,这些算法、软件系统和框架必须适应超大规模数据高性能处理的需求,如PB数量级[27-28].4数据分析4.1语义实体语义实体是利用机器学习方法从数据中获取的实体,该类实体在一段时间内具有稳定的语义.语义实体可以是人、物、时间日期、事件、产品等,例如“iPad2”、“上海世博会”、“三鹿”等[29].从概念上来讲,语义实体不同于命名实体(NamedEntity).命名实体识别是基于已知实体集合(包括人名、地名、机构名、时间、数值、货币、百分比等)进行实体抽取,而在语义实体研究中却没有预先定义的实体,需要发现和挖掘未知的新实体.语义实体的识别与检测对于海量数据分析非常重要.例如,在管理Web数据时,传统挖掘技术返回一些相关的网页链接,但是需要用户去甄别这些网页链接的意义;而语义实体挖掘则可以直接返回待Page8挖掘实体的一些相关信息,节省了用户参与的工作量,提高了用户体验程度.微软在Web挖掘和Libra学术搜索①中已经采用了语义实体概念.语义实体识别主要需要解决以下几个问题:(1)待处理文档的规模庞大且数据类型丰富,包括图像、视频、音频、文本、博客数据和论坛数据等新型应用产生的数据;(2)语义实体内部结构比较复杂,无明显特征;(3)大量语义实体属于新出现的对象,比如“三鹿”和各种突发事件等.因而传统的基于统计学习的命名实体识别算法(例如最大熵模型、决策树、支持向量机、隐马尔可夫模型、条件随机场)用于语义实体识别时遇到困难,或者无法使用,或者准确度不高.在海量数据应用中,语义实体技术面临如下挑战:(1)海量数据的来源多种多样、数据结构复杂化、数据类型也是多样化的,目前的语义实体识别技术仅限于在某个领域进行数据分析与实体识别,如何实现跨领域、跨类型的、自适应的语义实体的研究,是一个崭新的课题;(2)如何结合多种语义实体识别方法处理一项任务,实现多种语义实体识别方法的相互补充,也是值得探讨的一个研究方向;(3)如何设计高效的语义实体识别技术,以实时方式识别出有意义的语义实体或者事件,对于某些舆情分析、论坛监测等应用比较关键;(4)如何结合数据挖掘、统计学习方法和语义Web(SemanticWeb)来识别和管理语义实体,也是一个值得探讨的研究方向.4.2数据挖掘数据挖掘技术是从纷繁芜杂的数据集合中抽取出有用的知识,以辅助决策支持.典型的数据挖掘算法包括关联规则、分类、聚类、离群点检测等.随着大数据的广泛出现,有些学者开始关注针对大数据的挖掘技术.Han等人[30]认为,必须开发数据密集型挖掘技术,以有效处理大数据(特别是TB级别或者PB级别规模的数据).数据密集型挖掘技术的应用背景很广阔,包括信息网络分析、移动对象数据分析等诸多领域.自然界中互相关联的数据会构造成信息网络,包括因特网、交通运输网、无线通信网络、蛋白质网络和社交网络等.这些网络的规模已经非常庞大,而且仍然在不断进化、扩大之中.信息网络中各个节点或者链路包含一些多维信息,节点重要性(依据入度与出度)的差异可能很大,链路权重的差异性也可能非常大.以因特网为例,各主页被视为节点,超链接被视为链路,从而构成一个信息网络.该信息网络随着时间推移不断进化,节点的重要性可用PageRank[31]等多种方法计算得到.信息网络的主要研究内容包括基于链路的对象排序分析(Link-BasedobjectRanking,LBR)和图挖掘等.前者关注对象排序,以返回最关键的若干个对象,广泛应用在搜索引擎等领域;后者注重挖掘图中隐藏的知识,例如挖掘频繁子图模式等.随着基于位置的服务(Location-BasedServices,LBS)的普及,亟需发展海量移动对象数据分析技术和轨迹分析技术.现有定位技术大致可以分为两类,即室外定位技术和室内定位技术,其中室外技术主要是指GPS技术,而室内定位技术则比较多样化,包括蓝牙、红外、RFID、Wi-Fi等.近年来,越来越多的设备可以通过上述定位技术实时采集移动对象的位置,再经由无线网络发送给服务器进行分析.移动对象数据具有很强的时空特性,通常要求获得实时应答.移动对象分析的内容很多,包括移动模式挖掘、周期性模式挖掘、聚类、预测、分类和离群点检测等[32].为了应付超大规模数据,Yang等人[33]采用MapReduce框架管理轨迹数据,获得了较好的实验结果.数据密集型挖掘技术需要关注如何提升计算效率.与一般查询处理问题相比,数据挖掘问题的复杂度往往更高,其计算复杂度往往并不与数据规模成线性增长,而是增长更快.可以充分利用第3节中所提到的分布式计算方法、数据流方法、新硬件以及超级计算等方式提升计算效率.ApacheMahout是一个基于ApacheHadoop的项目,它使用了MapReduce模式,集成了一批典型的大数据挖掘和机器学习算法,包括聚类、分类、频繁模式挖掘等②.此外,知识的表示方式并非一成不变,需要关注在新领域中出现的新的挖掘问题.5用户接口5.1海量数据可视化数据可视化利用图形化手段分析和呈现数据,其呈现方式可以是诸如直方图、饼图、柱状图、折线图等统计图表,也可以是许多复杂度更高的图形.数①②Page9据可视化技术需要综合利用计算机技术、专业领域知识和设计美学,其中计算机技术是实现基础,专业领域知识能够深入理解数据,而设计美学有助于美化图形显示界面.数据可视化技术并不过分追求绚丽的界面,而要在功能性与美观之间达到一个平衡点.数据可视化的最终目的是呈现数据的内涵,并挖掘出隐藏在大数据内部的规律.换句话说,数据可视化是手段,挖掘知识或规律才是目的.海量数据可视化是对海量数据的可视化.随着海量数据的应用越来越多,海量数据可视化也得到了越来越多的关注.这里仅列举几个项目.犹他大学的Vistrails项目面向工作流和世系管理,集成了良好的可视化界面,可以显示数据演化步骤信息①.Visus项目开发面向海量数据流的可视化技术,以处理美国LLNL实验室产生的海量数据②.“我们感觉很好(Wefeelfine)”项目采集互联网的博客信息,从中抽取出表达情感的关键词,并维护一个包含数百万人情感的数据库,在图形界面上以不同颜色和大小的圆形表达用户的情感③.目前,海量数据可视化仍然存在诸多挑战:(1)海量数据可视化需要丰富的想象力,这既包括美学想象力,也包括计算机实现技术想象力.前者设计出具有美感的界面,后者能高效地呈现该界面;(2)当数据规模逐步增加时,无法在显示器(或电视墙)上显示所有数据以及所有信息,因而需要深入分析和理解数据内涵,合理划分数据的重要程度,在界面显示时更具有层次感;(3)时间维度往往是数据的重要特征,可以依据该维度动态地淡入和淡出显示内容;(4)海量数据可视化需要把握“全局”与“局部”的关系,不仅可以显示数据的全貌,还可以显示数据的局部特征.5.2DaaS数据库服务(DatabaseasaService,DaaS)[34]是数据库外包(DatabaseOutsourcing)在云计算环境中的一种崭新的数据库应用形式[35].DaaS是指企业(数据拥有者或数据库拥有者)将自身的数据库创建、访问、维护、升级、管理等任务委托给专门的第三方(服务提供者或数据库服务提供者)进行管理和维护.目前已经存在很多数据库服务,如MySQL-Hosting④、IBMDataCenterOutsourcingServices⑤等.云计算中的多租户数据库也是一种典型的对多用户提供DaaS服务的应用.图3用面向服务(SOA)的观点刻画了数据库服务的架构.该架构包含三个角色(分别是数据拥有者、数据库服务提供者和数据请求者)和数据流(分别是数据源、查询与结果等).体系结构可以是统一客户模式(UnifiedClientModel)、多查询者模式(Multi-QuerierModel)和多数据拥有者模式(Multi-OwnerModel)等[36].DaaS的主要研究内容包括委托数据库的可用性、可靠性、数据加密、分布式存储、备份机制、多版本管理、数据更新机制、基于隐私保护的查询、访问控制等.在面向数据密集型的应用中,DaaS存在以下问题和挑战:(1)查询的高效性和有效性.从查询性能上看,传统的数据外包中的查询主要是对数值型数据的检索,数据量比较小.而在数据库服务提供者的数据中心的数据量很大,需要考虑如何降低数据网络传输量.从查询有效性方面,目前只有在基于数据分布的数值型数据上实现了精确匹配查询,而数据中心所存储的数据类型多种多样,需要对多种类型数据进行有效查询;(2)隐私数据管理.目前大多数研究工作主要关注如何保护委托数据库中用户的敏感信息,较少考虑数据被存放在数据库服务提供方,用户可能需要查询私有信息,因而需要考虑隐私数据查询技术,保护查询者的身份和隐私数据;(3)访问控制技术.由于数据库服务提供方不可信,因而DaaS的数据访问控制非常重要,它是控制用户执行合法授权的第一步骤.需要探索灵活、有效的访问控制机制,将访问控制和保证数据安全和隐私的方式结合起来,以增强DaaS的可用性;(4)多版本数据的备份和更新机制.多版本技术能保证查询效率和数据的高可用性,也是目前的一个研究热点.①②③④⑤Page105.3云计算云计算是一种典型的网络计算方式,是以数据为中心的一种超级计算,具有在虚拟计算环境下的可扩展性和可用性.目前,亚马逊、微软、谷歌、IBM等公司都提出了“云计划”,如亚马逊的AWS(Ama-zonWebServices)、IBM和谷歌联合进行的“蓝云”计划等.学术界也纷纷对云计算展开了深层次的研究,如谷歌、华盛顿大学以及清华大学开展的云计算学术合作计划,卡内基梅隆大学等对数据密集型的超级计算的研究,本质上也都是对云计算的相关技术展开研究.实践证明,全球财政在云计算的各种服务上的投入以每年约30%以上的速度递增.本节主要讨论云计算环境给软件开发和演化带来的影响和挑战.云计算从3个方面融合了现有技术,包括使用方式、计算方式以及基础设施的部署方式等.使用方式采用服务的形式,即SaaS、IaaS、PaaS和DaaS;计算方式是分布式的,即网格计算和SOA;基础设施的部署方式即虚拟化,如集群计算.互联网平台为软件行业的发展带了新的机遇,如高生产率、快速反馈、便于在线升级等[37],但是网络软件组织使用模式(如任务协作性、模块并行性、业务装配化等)和网络数据生成的特性(如数据的分散性和多样性、资源的异构性、规模庞大性等)使得人们把目光从对单机的软件开发与演化系统的研究转向了与社会网络以及分布式大规模并行系统紧密关联的相关问题的探索和研究,如社会软件工程[38]、软件自适应演化[39]、软件可信评估[40]与选择以及超大规模系统的演化[41]等.在云计算环境中,软件开发和演化的挑战课题主要有以下几个方面:(1)软件系统的可扩展性.软件使用环境的变化,包括软件系统的网络化,(异构的、非数值型的)数据量的激增,社会协同的分布式作业的产生(网络社区)等等,使得各种软件组件有必要实施同时作业,而这样一种工作模式极大地增加了软件创建、测试和维护的复杂度.异构设备和操作环境加剧了解决这类问题的难度.目前解决这类问题的主要手段是人工作业,需要花费大量精力并且通过不断地下载和安装补丁来保证系统的可信性;(2)提高软件生产力.网络发展推动了协同工作,加大了软件任务的复杂度,因而增加了软件开发的难度.在软件行业的发展过程中,由于协作性工作任务的增多,以人为中心的软件设计和开发模式变得非常重要,即软件开发将更侧重与人密切相关的上层抽象设计而不是那些底层的系统软件.从而使得软件开发者可以快速理解和掌握开发以及维护过程;(3)由于新的分布式应用的出现,如物联网等,这些新的应用要求我们针对这些异构的系统设计出新颖的软件系统,要求在编程语言、算法、分析工具和系统软件上下功夫从而简化软件开发人员的工作增加工作效率.6数据质量与隐私保护6.1数据质量数据质量极大地影响到海量数据的管理过程.低质量的数据集合可能无法使用,或者产生质量低下的查询分析结果.影响数据质量的因素很多,包括仪器精度、外部环境、人工误操作、历史因素等.例如,在传感网络中产生的数据的精度往往受到传感器本身精度的制约,周围环境的复杂度也会影响数据传输质量.数据质量的具体表征有:数据不准确、数据缺失、数据不一致等.据报道,大型机构所产生的数据中60%都是冗余的[42].此外,RFID技术现已广泛应用到物流等多个行业之中,而RFID数据的准确度仅达到60%~70%[43].提升原始数据质量的措施很多,包括提高物理仪器精度、简化运行环境、加强人员培训、提升设计质量等.这些措施能够提升数据质量,但却无法消除数据质量问题.待处理的数据质量可能仍然不高,有待进一步的提升.在此过程中,自动检测与修复技术就显得非常关键,即以常识和专业知识为基础和前提,通过分析和理解数据内容以及数据之间的联系来实现问题数据的自动检测和修复.强调自动化具有两层含义,首先,对海量数据进行人工干预的成本非常高昂,其次,自动检测和修复能够提高时效性.一般有两类方法可以进行自动检验.一种是与应用无关的检验技术(普适的技术),包括缺失值处理、去除重复等.另一种是与特定应用相关的检测技术,需要借助相关领域的具体知识才能够做到[42].数据世系也是一种提升数据质量的手段.数据世系保存了数据从产生开始不断演变的整个过程.追溯这个过程即可显示数据质量变化的历程,从而帮助提升数据质量.敖莉等人[42]回顾了重复数据删除技术,认为主要有两类技术手段:相同数据的检测技术和相似数据的检测与编码技术.而相同数据的检测又分为相同文件以及相同数据块两个层次.这方面的处理比Page11较简单,可以通过散列或者滑动块技术进行管理.而相似数据的查找则稍显困难一点,需要定义相似度距离,以编码技术进行求解.事实上,在大多数情况下无法获取完美质量的数据集合,更何况这个数据集合本身是海量规模.即使在应用了高级的数据质量提升技术之后,也是如此.因此,一个比较重要的任务即在于如何从弱质量数据上执行数据管理任务.不确定数据管理技术是一种在弱质量数据上执行查询分析任务的手段.数据质量不高时,以概率密度函数的形式表征数据,而非某一个特征值.6.2数据安全数据的安全和数据所涉及到的隐私保护是数据管理需要解决的重要问题之一.数据安全和隐私保护技术涉及各种应用领域,例如教育、医疗、能源、交通、国土安全、数字化民主、经济等.这些数据(如销售数据、工资信息、医疗记录、身份信息、证券交易信息)在一定程度上涉及到个人的私密信息,例如,销售记录反映出消费者的个人购买兴趣,医疗记录反映了患者的身体状况,银行记录透露了储户的财产信息,这些信息的安全保护措施非常重要.如2005年6月4亿多Master信用卡持有者的姓名和信用卡号被泄露①,2006年5月存放2亿多老兵姓名、社会安全号码和出生日期的信息的硬盘被盗,都造成了大量隐私信息泄露②,对个人以及社会造成巨大损失.因此,数据安全和敏感数据的隐私保护是数据管理中贯穿数据获取、数据存储、数据维护、数据查询、数据分析等整个数据生命周期的一个重要研究内容.可信系统和信息安全的研究是基础研究.传统数据库系统所提供的各项技术手段能较好地解决封闭应用环境下数据的安全和隐私保护问题,但随着互联网技术和应用的普及,给在开放的、分布的互联网上面向信息共享的敏感数据隐私保护技术提出了新的挑战,也成为多租户数据库、数据服务外包等应用的重要问题.面向信息共享的敏感数据隐私保护技术主要包括以下几个方面:(1)完善的数据安全机制,保证数据的内容不(2)数据内容不会被破坏(数据的完整性[45]);(3)数据是正确的,返回客户的结果是完备的(4)服务提供者无法察觉客户查询数据的目的(5)数据的可用性.会泄露(数据的机密性[44]);(数据的完备性[46]);(查询隐私保护[47]);现有很多数据安全技术大多属于被动防守技术,例如加密、防火墙、锁等.随着新型应用(例如社交网络)的广泛出现,需要设计更多主动和被动技术,以防范内、外攻击者的攻击.内部攻击包括即使某些不被信任的用户可能共享了一部分社交网络空间,也要能保护整个应用的数据安全.这方面的崭新研究方向包括:(1)分析海量数据,利用群体智慧来发现系统攻击、过滤垃圾信息、检测社会工程攻击;(2)建立信息安全基础,包括安全的硬件、软件和网络.目前应用工业实践的方法仍不充分,针对基础架构和过程控制系统的信息安全需要完备的理论基础,有必要建立在传统和量子理论基础上的认证、授权和可信管理的基础机制;(3)隐私保护需要行为学和认知科学的支持;(4)安全和隐私政策的形式化定义和应用③.6.3数据监护数据监护(datacuration)[48]来源于图书馆领域的“digitalcuration”④,是指对数据资产的选择、维持、维护、收集和打包的整个过程,主要目的是解决数据的保管和使用问题.据OCLC统计⑤,1998年、1999年和2000年存在的网站IP到2002年时分别仅剩13%、19%和33%,因此,Web数据的保存问题很严峻.对于科学家、研究者和学者花费了大量时间和精力所产生的大量科学数据,保管和使用非常重要.一旦数据遗失,将使科研成果不完整,并且严重影响其使用价值和创新价值,然而目前的现状是往往一个项目产生的数据在项目结束后就很难再继续使用.学术界开始研究数据监护,尝试解决数据的有效存储和使用问题.英国JISC(JointInformationSystemsCommittee)对数据监护给出的定义是:为了确保数据的当前使用目的,并能用于未来再发现及再利用,从数据产生开始就对其进行管理和完善的活动.数据监护意味着需要进行持续性补充和更新,以使数据符合用户需求,发挥其使用价值.目前,数据监护逐渐成为国外图书馆界科研和实践的新热点.2007年美国NSF启动了DataNet计划⑥,以图①②③④⑤⑥ites/ostp/pcast-nitrd-report-2010.pdfPage12书馆为主体,用1亿美元、5年时间资助数据监护的研究.伊利诺伊大学的DCEP(DataCurationEducationProgram)①计划把数据监护的教学包含的课程定义为:数据采集与管理、知识表达、数字资源保护与存档、数据标准、数据政策等,课程包括信息组织、信息建模、本体论和元数据理论和实践等.在数据库领域,国际知名的数据库系统和数据库理论专家PeterBuneman于2004年最早在爱丁堡大学成立了英国数据监护中心(UKDigitalCurationCenter)②,是数据监护技术从数据库领域进行探索的第一个科研机构.Peter教授在数据监护的基础上,提出了监护数据库(CuratedDatabase)概念[49].从数据管理系统的角度看,监护数据库的挑战包括:数据的标注、数据模式的演化、数据内容的正确性、数据世袭的管理、数据的灵活访问、数据的发布和引用等.在最新的工作中[50],他们实现了Database+Wiki=CuratedDatabase的原型系统,并在SIGMOD2011上演示,这个系统通过XML模型来管理演化的数据库模式、利用Wiki实现了简洁的版本管理和世系管理、提供了对结构化数据的SQL的关系查询.目前监护数据库还刚刚起步,如何监护海量数据库,是一个挑战性的问题.由于数据量大、数据内部的结构多元化、数据之间的关联错综复杂,由此带来的数据标注的工作量巨大,而且数据的一致性、完整性很难维护,数据世系的分析也成为一个难点.从数据模式的演化来看,虽然XML可以建模数据模式的演化问题,但是,针对海量数据的XML数据管理以及高效的数据检索和查询,都是目前需要解决的问题.7新型应用分析本节举例分析两个新型大数据应用,即社交计算和信息-物理融合网络.7.1社交计算社交计算(socialcomputing)③是当前网络应用中的一个热点技术,其主要研究对象是社交网络.社交网络的主要特点是拥有个性数据(包括爱好和经历)的用户参与到合作式的信息交互中(人际关系网络化),从而使互联网从门户网络发展到社交网络.社交计算的相关概念包括社交网络(socialnetwork)、社交媒体(socialmedia)、社交网络服务(socialnet-workservice)等.从结构上看,可以将每个用户视作一个节点,且附加一些个人信息,如住址、邮件等;可以将用户之间的各种社会关系视作边,这类边往往可以加上权重,从而构成了一个复杂的社交网络图.在社交网络图中,用户直接或者间接地产生网络信息.提供社交计算功能的网站称为社交媒体.相对于以往的Web应用,这些社交媒体除了传统的文本和多媒体外,还带有标记、注释、评分、评论等信息,可以向用户提供更加个性化和社会性的信息服务———社交网络服务.典型的社交媒体包括Facebook、Twitter、Wikipedia等.社交计算是典型的大数据应用.社交计算涉及的用户量非常巨大,数据量也很大.据最新统计④,全球互联网用户数已经达到20亿,Facebook的用户数在2010年末已经达到6亿,互联网上博客的数量约为1.52亿,2010年的Twitter帖子数达到250亿.因此,根据用户发布的消息、所作的评论、评分等数据抽取出知识(例如用户的兴趣等)就显得极为重要,需要综合采用数据管理、自然语言处理、机器学习和信息检索等技术.社交计算的挑战性在于每个用户作出的决定既受到他人的影响,也影响到他人,从而在整个网络内产生“聚集”效果;此外,社会计算通常含有“博弈论”思想,因此相关的社会学问题都属于社交计算的范畴,例如圈子的动态进化、信息与利益的形式化描述等.在社交计算中,互联网的大量用户、海量数据会带来如下挑战:(1)在复杂系统和互联网环境下产生的“collectiveintelligence”[51],需要对用户协作行为和解决问题的方法进行深入探讨.在给定目标、任务的情况下,如何更好地组织分布的大量用户、海量数据形成的复杂网络,实现不同的应用需求?从经济模型来看,针对一个合作的任务,需要研究参与该任务的用户兴趣动机、激励机制和经济模型等.从计算技术来讲,针对一个复杂任务,如何实现利用分布的人力来共同完成一个子任务间的协调?(2)传统搜索引擎是基于信息网络(InformationNetwork),而在社交网络的框架下,如何做知识抽取和信息挖掘,以及用户隐私的保护和信任关系的衡量.事实上,除搜索引擎和问答站点外,已经有越来越多的人将Twitter作为信息获取的一种方式[52],除了实时、广泛的特点外,这种模式是在与真实的人交流,而不①②③④Page13是提交问题给某个算法/机器系统.综上所述,探索面向大数据的数据管理技术和观点挖掘技术,利用复杂网络技术解决社会学问题、实现计算机的自动识别、理解、管理大量分布的自由的人和设备,成为目前非常值得探讨的研究课题.7.2信息-物理融合网络因特网的出现使得人们可以在计算机之间共享信息,促进了整个信息产业的发展.时至今日,更多物理设备(不仅仅是计算机)具备了数据传输功能(有线传输或者无线传输),融入到因特网之中,从而扩大了因特网的内涵和范畴,典型案例包括智能家电、车载系统、手持设备、野外观测设备等.这个融入了诸多物理设备的网络系统被称为信息-物理融合系统(CPS),其宗旨在于通过3C(Computation、Communication、Control)技术来有效融合整个系统之中的物理设备,实现实时感知、动态控制和信息服务,如图4所示[53].CPS系统管理大量数据,它们来源不同、结构各异且并不一致,既包括各种传感器实时采集的环境数据,也包括其它渠道产生的动态数据集合,例如Web信息、生产日志等.CPS系统中的数据也需要考虑时间-空间属性,分析历史时间,预测未来走势.例如,许多车辆内置了GPS通信模块,可以实时采集位置信息.用户可据此获得基于位置的服务,即:当用户的位置改变时,所得到的服务是与他的位置信息紧密相关的.传感器是CPS的重要组件之一,它采集周围环境的各类信息,从而实现将物理世界和信息世界融为一体.典型的传感器包括温度传感器、湿度传感器、红外传感器等.在未来,人们将研发功能更强、精度更高、体积更小、能耗更低、成本低廉的传感器.首先,不同应用需要使用具备特定感知能力的传感器,但是有些需求由于应用面比较狭窄,并未被研制出来,例如在化学和生物等领域之中.其次,缩小传感器的体积会充分激发人类的想象力,制造出更新奇的设备.微机电系统(Microelectromechanicalsystem,MEMS)就是一个较好的例子.与传统机械相比,MEMS的尺寸更小,小到几个微米,大到不足1个厘米,而在狭小的空间内却集成了微型机构、微型传感器、微型执行器和辅助电路等几个部分,在医疗、工业、测试仪器等领域具有广泛的用途.此外,降低能耗、减少成本均可促使传感器应用更加普及.CPS数据管理面临较大的挑战:(1)异构数据融合.要克服不同数据来源的不一致性,获取一致的结果;(2)数据以流的形式持续到达,并期待实时的查询结果.传统的数据管理方法主要从一个静态数据集中执行快照查询,并返回查询处理结果,这并不符合CPS系统的场景.需要采用连续查询方式,首先在系统中注册查询,当输入数据到达时,即可处理查询,并实时刷新查询结果;(3)需要提高CPS系统的自动化程度,以构建决策支持系统.高级传感器为CPS自动化提供了基础设施;高效的数据分析能力可以帮CPS系统解决特定问题;而CPS系统的自动化技术(或半自动化技术)则从系统层面解决问题.CPS系统自动化的应用领域非常广泛,包括智能交通系统、无人驾驶飞机、工业机器人等,不仅可以提高工作效率,还可以在极端条件下工作.但是实现这一点并非那么容易,我们不仅需要开发高级对象识别技术,提高对象鉴别能力,还需要新的学习算法来适应周围的环境.8总结数据密集型科学与工程(DISE)诞生于当今的数据爆炸时代,传统的数据管理技术无法有效应对大数据.本文从数据存储与组织、计算方法、数据分析、用户接口、数据质量、数据安全和数据监护等方面介绍了DISE的研究内容和面临的挑战:(1)分布式存储策略是主流的数据存储与组织形式,另外在许多应用中还涉及数据世系和数据集成等内容;(2)可以采用多种方式提升计算能力,包括分布式计算架构、数据流、新硬件、高性能计算等;(3)需要发展数据分析技术以获取知识,典型的内容包括语义实体分析和数据挖掘;(4)需要提供友好的用户接口,例如海量数据可视化、数据库服务和云计算等;(5)DISE还关注数据质量和数据安全问题,并且执行数据监护.总之,与传统数据管理技术相比,DISE在各个层面的差异都非常显著.尽管目前已经有一些相关的研究工作,但是总体上来说,DISE仍然非常年轻,诸多问题尚待研究.Page14
