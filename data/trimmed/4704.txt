Page1超级计算系统互连网络带内管理的实现与评测1)(国防科学技术大学计算机学院长沙410073)2)(国防科学技术大学并行与分布式计算重点实验室长沙410073)摘要互连网络是超级计算系统的关键部件,其易管理性将直接影响整个系统的RAS特性(可靠性、可用性和服务性).“天河二号”超级计算系统采用了定制的高速互连网络,该网络由大约5856块网络交换芯片NRC和18304块网络接口芯片NIC构成,其互连规模极其巨大.为了实现对系统内众多网络芯片及其端口的高效率配置和监控等管理操作,该互连网络采用了基于带内的网络管理技术.该文描述了带内网络管理的设计与实现,具体包括网络管理功能、网络管理总体结构、带内管理描述符格式与报文处理流程、管理软件的总体框架等.基于部署在国家超级计算广州中心的实际系统,该文对“天河二号”互连网络带内的管理进行了测试,测试结果证明了带内管理的高效性.关键词超级计算系统;互连网络;带内管理;天河二号1引言超级计算系统互连网络的管理主要由硬件和软件两部分实现,其硬件部分主要负责提供管理通路、产生状态信息和支持测试诊断等,而软件部分主要负责分发网络配置、采集网络状态、报告网络故障,对故障部件进行测试诊断,并提供友好的用户管理界面等.就网络管理通路而言,通常有两种实现方式,即带内网络管理(In-bandNetworkManage-ment,INM)和带外网络管理(Out-bandNetworkManagement,ONM).带外网络管理的管理通道独立于网络自身的数据通道,而带内网络管理的管理信息传输与数据传输共用同一通道.与带外网络管理相比,带内网络管理的优点主要体现在3个方面:一是性能高,带内网络管理使用高速数据通道传输管理报文,其性能远高于使用I2C[1]、JTAG[2]、SMBus[3]等低速通道的带外网络管理.二是实现代价低,实现带内网络管理的硬件部分只需要在网络芯片设计时增加传输和处理管理报文的硬件逻辑,而实现带外网络管理通常需要多种电子器件(例如I2CHub等).带内网络管理使网络具备自治管理能力,并且通过对管理报文合理地进行流控,可将管理流量对数据流量的性能影响降至极低.三是保持了故障的一致性,带内网络管理报文和数据报文使用相同的传输通道,所以并不会额外增加网络管理通道的故障,保持了管理通道与数据通道故障的一致性.带外网络管理额外增加了管理信息传输通道,因此不可避免地引入新故障源.目前,排名世界HPCTOP500①榜首的“天河二号(TH-2)”超级计算系统采用了带内网络管理技术,不但提供了丰富的网络管理功能,而且增强了超大规模互连网络的可管理性.本文介绍TH-2互连网络带内网络管理的设计、实现与评测.全文分6节,第2节简单介绍TH-2互连网络结构;第3节详细阐述带内网络管理的设计与实现;第4节测试与分析TH-2互连网络带内网络管理的性能;第5节阐述相关研究;最后总结全文并展望未来工作.2TH-2互连网络TH-2超级计算系统采用全定制的高速互连网络,该网络主要由两款ASIC芯片构成,分别是高速网络接口芯片(High-speedNetworkInterfaceChip,NIC)和高阶网络路由芯片(High-radixNetworkRoutingChip,NRC)[4].2.1网络接口芯片NICNIC主要负责计算节点和服务节点与互连网络的接入.NIC实现了PCIE-G3×16主机接口和14Gbps×8网络接口.支持短消息(Mini-Packet,MP)和远程直接内存访问(RemoteDirectlyMemoryAccess,RDMA)两种数据传输机制.采用基于硬件逻辑的动态连接机制提供消息可靠传输和消息流量控制[5].NIC设计了支持用户级通信的虚端口(VirtualPort,VP)机制.每个VP由一组可编程的寄存器和相应的内存数据结构组成,这些资源被内存映射到用户地址空间.NIC提供40个VP给软件使用,其中8个VP为PIO(ProgrammableInput/Output)类型,另外32个VP为DMA(DirectlyMemoryAccess)类型.NIC为每个PIO类型VP提供了专享的硬件描述符队列(HardwareDescriptorQueue,HDQ),软件用PIO写方式向NIC提交描述符.对于DMA类型的VP,NIC用DMA读的方式取描述符,描述符队列存放在主存中,故称为软件描述符队列(SoftwareDescriptorQueue,SDQ).此外,软件在主机内存中为每个VP分配专享的MP接收队列(Mini-PacketQueue,MPQ)和事件队列(EventQueue,EQ).MPQ用于接收远端节点发送的MP报文,EQ用于实现NIC硬件向软件通告发送或接收数据完成事件.2.2网络路由芯片NRCNRC主要负责网络报文的路由与交换.NRC实现了24个网络端口的无阻塞全交换功能,网络端口采用14Gbps×8链路,报文交换的吞吐率达到5.376Tbps.为了降低全交叉开关(Crossbar)后端实现的难度,芯片内部采用瓦片式交换结构[6-7],即将24个Tile组织为4×6的阵列.报文传输的物理通道划分为6个虚通道(VirtualChannel,VC),报文交换采用虚切通(VirtualCut-Through,VCT)方式[8].利用动态分配多队列(DynamicallyAllocatedMulti-Queue,DAMQ)技术达到了减少缓冲区所需要的存储资源的目的[9].报文路由采用基于分布式查表的自适应路由,即在网络中每个NRC芯片的端口保存一张路由表,该路由表为进入本端口的网络报文指明了到系统中各个目的节点时应该选择的本NRC芯片输出端口集合.报文路由时根据各个输出端口链路状态进行自适应均衡负载.当节点间通信时,源节点只需要直接在报文头部填①HPCTOP500.http://www.top500.org/,2015Page3写目的节点编号并将报文注入网络即可.当网络构建时,需要通过网络管理工具将预先设计的路由表加载到系统中各个NRC或其相应存储器件(即E2prom).2.3互连拓扑结构TH-2互连网络采用胖树结构,该结构的物理实现分为3层:(1)第1层由计算机柜构成,每个计算机柜包含4个机框,机框内的底层交换机(BottomSwitch)连接32个计算节点,并上行连接到叶通信图1TH-2互连网络拓扑结构上述底层交换机、叶交换机、根交换机分别由6、1、6块NRC芯片构成,这3种交换机分别拥有20、24、48个用于扩展互连的网络端口,扩展互连端口之间使用QSFP封装的AOC光纤进行互连.综上所述,构建TH-2大规模的互连网络共使用NRC芯片约5856块,使用NIC芯片约18304块,使用AOC光纤约46000根.互连网络管理的目标是实现对上述大规模互连网络各个芯片及其端口高效地实施配置、监控、测试、诊断等管理操作.3TH-2互连网络管理3.1网络管理功能为了增强网络系统的可管理性,我们为TH-2互连网络定义了丰富的网络管理功能,具体包括网络配置、状态监控、故障主动报告、路径追踪[10]、拓扑发现[11]、链路内建自测试(Build-inSelf-Test,BIST)[12]等.(1)参数配置.当计算节点和交换机加电后,需要对网络接口和交换芯片运行时配置参数进行初始化.无论是在线初始化芯片配置参数,还是芯片在机柜.全系统共有143个计算机柜;(2)第2层为叶通信机柜,每个叶通信机柜包含3组叶交换机(LeafSwitch),每组的20块叶交换机实现了与3个计算机柜内所有底层交换机的互连,并上行连接到根通信机柜.全系统共有16个叶通信机柜;(3)第3层为根通信机柜,每个根通信机柜包含30块根交换机(RootSwitch),根交换机是整个胖树结构的顶层.全系统共8个根通信机柜.图1为TH-2互连网络拓扑结构示意图[4].加电后从存储器件E2prom中读取配置参数,都需要网络管理提供参数配置功能.同时,TH-2采用分布式查表路由,所以网络配置参数除了包括物理层和数据链路层等参数外,还包括网络层路由表参数.(2)状态监控.通过状态监控,可以实时地了解网络的健康状况,这对于网络的调试、测试和日常维护具有重要作用.为了灵活性,对互连网络基本状态的监控通常采用轮询方式.在互连网络提供状态信息支持方面,一是按照重要性对状态信息分级,从而减少管理系统对网络状态信息的访问量,缩短网络故障定位时间.二是提供尽可能丰富的状态信息,特别是数据链路层的状态信息,例如报文重传计数和报文重传率等,从而为网络的数据链路层故障处理提供重要依据.(3)故障报告.除了对互连网络的基本状态采用轮询方式进行监控外,对于网络中出现的某些类型的严重故障(例如链路断开),应该能够实时地报告到网络管理平台(例如管理服务器及运行的管理程序),所以TH-2互连网络支持网络故障的主动报告功能.为了增强主动报告功能的灵活性,支持通过Page4配置参数对故障主动报告行为进行控制.例如,通过设置故障屏蔽寄存器,可以选择主动报告错误的种类.(4)路径追踪.与IP路由追踪[10]类似,该功能为分布式查表路由互连网络提供一种查询计算节点间路由路径的机制与方法,其原理是根据网络管理人员提供的源和目的计算节点,通过连续访问节点接口芯片和网络路由芯片的相关寄存器和路由表信息,仿真计算出从源节点出发经过各个中间各级网络芯片的路由过程,从而判断出路由的正确性(即可达性),并获得路由路径信息.此外,还可以进一步检查该路由路径中各个网络端口的链路层状态.(5)拓扑发现.拓扑发现是高性能互连网络应该支持的重要网络管理功能之一[11].该功能不但可以用于检查光纤和网络端口连接关系的正确性,而且发现的网络拓扑信息可用于管理程序根据路由算法自动生成全系统路由表配置参数并加载到各个网络路由芯片中.实现故障报告和拓扑发现功能的前提是系统中的每个网络芯片及其端口具有唯一的标识.在TH-2系统中,拓扑发现由运行在管理服务器的管理程序发起,采用宽度优先搜索算法获得系统中所有网络端口对的连接关系信息.(6)链路测试.为了快速定位网络链路故障,网络管理需要对网络链路故障诊断与测试提供支持.BIST是一种在芯片内部自行产生测试信号并自行检测信号质量的可测试性增强技术[12].通常,HSS生产厂商已在物理层的各通道上已经内置了BIST测试功能,但这只能针对单条物理通道进行测试.在TH-2系统中,我们在数据链路层提供对绑定后的多通道进行并行测试功能,不仅缩短测试时间,而且可以在数据链路层上对通信链路的信号传输质量进行精确评估.通常,底层硬件只需为上层软件提供基本支持,上层软件可在硬件基础上实现更复杂的功能.为了实现上述丰富的网络管理功能,带内网络管理硬件大致需要提供4种基本功能:(1)寄存器访问.支持对网络芯片的配置和状态寄存器进行按址访问.同时,网络芯片及其端口拥有保存其标识信息的配置寄存器,而且相连芯片端口能够自动获得对方芯片和端口标识信息.NRC的路由表表项可采用间接地址方式访问,即通过读写NRC的路由表配置寄存器而访问路由表表项;(2)E2prom访问.支持保存网络芯片配置参数的E2prom存储器进行按址访问.E2prom中存储了网络芯片所有配置寄存器以及路由表的默认值,芯片加电后可自动从E2prom中读取配置参数对芯片进行配置;(3)故障主动报告.支持网络芯片主动向管理服务器报告故障信息,支持通过相关配置寄存器对故障主动报告行为进行控制;(4)链路级BIST.支持对网络端口链路质量进行测试,支持通过访问网络芯片相关配置寄存器对测试过程进行控制(例如测试的启动与停止、测试时间、测试强度等),支持通过访问网络芯片相关状态寄存器获取测试结果.3.2网络管理总体结构为了实现上述网络管理功能,TH-2互连网络主要采用带内网络管理技术,即对网络芯片寄存器访问、E2prom访问、芯片故障的主动报告、链路自测试的启动和测试结果收集直接依赖于连接在网络中的管理服务器与网络芯片进行交互实现,而且交互过程主要体现为发送和接收管理报文.具体而言,寄存器和E2prom访问是管理服务器向网络芯片发送管理请求报文,而网络芯片向管理服务器应答管理响应报文实现.管理请求报文可携带所要访问对象的地址和/或数据信息,响应报文主要携带管理请求的完成情况和/或数据信息.故障主动报告和链路自测试功能的配置和启动都可通过管理服务器向网络芯片发送管理请求报文实现.芯片发生故障时可主动地向管理服务器发送携带故障编码信息的管理报文.TH-2系统带内网络管理的总体结构如图2所示.在该结构中,每个NRC和NIC芯片中实现网络管理代理模块(NetworkManagementAgent,NMA),该模块首要功能是:接收管理请求报文,并根据报文内容做相应处理(例如读或写寄存器),然后根据请求报文处理结果构造管理响应报文.NMA模块还可以根据配置主动产生管理报文并向管理服务器发送.运行在网络管理服务器(NM-Server)上的管理程序负责将用户的网络管理命令或操作转换为单个或多个管理请求报文,并通过服务器的NIC注入互连网络.用户通过网络管理客户端(NM-Client)主机使用网络管理接口,即登录管理服务器并使用命令行接口(CommandLineInterface,CLI)或使用本地主机的图形化用户管理界面(GraphicUserInterface,GUI)实现对网络系统的管理.对于规模较大的互连网络,可设置多个管理服务器分别管理逻辑隔离的区域(简称为管理区间).单个管理客户端可以通过不同的管理服务器访问不同的管理区间.Page5图2带内网络管理总体结构3.3网络管理描述符格式TH-2互连网络带内网络管理使用长度固定为4个Flit的管理报文.Flit定义为该网络数据链路层所传输的长度,固定为198位宽的数据单元.管理报文的头Flit包含了管理报文使用的VC、报文长度、路由跳步数等信息,其尾Flit包含了覆盖报文关键信息域的CRC信息,用于实现数据链路层的可靠传输.该互连网络共实现了6个VC,分别为VC0~VC5.管理报文单独使用VC3.管理请求报文是NIC硬件逻辑根据用户提交到SDQ中的管理报文描述符生成的.管理描述符长度为512位,图3给出了管理描述符的格式定义.其位域信息简单介绍如下:(1)DestID.目的网络芯片图3网络管理描述符格式的ID.如果向没有配置ID信息的网络芯片发送管理请求报文,则需要将该域设置为全“1”,否则将被目的网络芯片检查为错误报文而丢弃;(2)DestVP.运行在管理服务器的管理程序接收该描述符相应管理响应报文的VP号;(3)SrcVP.运行在管理服务器的管理程序发送管理请求报文所使用的VP号;(4)DestType.芯片类型,用于区分NIC和NRC两种芯片;(5)RtType.报文路由类型.管理报文采用源路由,区别于数据报文所采用的分布式查表路由;(6)Fen.强阻塞执行标记.“0”表示非阻塞执行,“1”表示当且仅当前一描述符执行完毕才执行该描述符;(7)Err.描述符错误标志.对描述符进行检查,如果发现描述符格式错误,则置位;(8)Type、S/M、Page6Inst.这3个位域用于区分各种传输层报文(例如立即数报文MP、集合通信控制报文CP等),管理报文被视为是一种特殊的MP报文;(9)Lint.源端中断控制位,决定管理报文是否在源端产生完成中断;(10)Rint.目的端中断控制位,决定管理报文到达目的端后是否产生MPQ非空中断;(11)Head.描述符标识;(12)TransactionID.用于标识请求响应报文间的对应关系的事务号,其范围为0~216-1.FRoutingFieldF和BRoutingFieldF是管理报文的路由域.其中,FRoutingFieldF表示从管理服务器向目的网络芯片传输管理报文所用的路由域,而BRoutingFieldF表示从目标网络芯片向管理服务器传输管理报文所用的路由域.路由域的格式定义为〈HopNum,Hop0,Hop1,…,Hop19〉,每一跳步的NRC芯片输出端口Hopi和有效跳步数HopNum都用5位表示,整个路由域总长度为105位.在管理报文描述符中,用于网络芯片的NMA模块进行解释执行和信息反馈的域为NMPType和NMPData.其中,NMPType域为6位,共定义了11种可用类型,包括:(1)寄存器访问5种:分为寄存器读请求、寄存器读响应、寄存器写请求、寄存器写响应和寄存器访问请求报文错误的响应报文;(2)E2prom访问类型:也分为5种,分别与寄存器访问报文相对应;(3)故障主动报告类型报文.请求报文错误的响应报文是NMA检查到请求报文错误而产生的,其目的是向管理服务器报告请求报文错误原因,例如访问地址越界等.在TH-2互连网络中,NIC和HNR芯片的寄存器值均设计为64位,其地址分别为12位和15位,E2prom选用了64KB容量,其每字节项的索引地址为16位.根据最大化硬件资源利用和为上层软件提供灵活性的原则,每个寄存器访问管理报文可访问1~2个寄存器,每个E2prom访问管理报文可访问1~6个字节项.3.4管理报文的数据流3.4.1管理程序接口基于NIC硬件,我们实现了GLEX(GalaxyExpress)通信软件系统,为其他应用软件提供了基础的消息传递框架.GLEX由用户级编程接口库Libglex,内核模块gdev,TCP/IP驱动gnet,PXE驱动gpxenet和一些管理工具组成.为了将数量较少的高性能HDQ资源分配给应用软件使用,GLEX限定了只能通过SDQ提交管理描述符.GLEX为发送管理请求报文和接收管理响应报文提供了如下两个基本函数:犵犾犲狓_狉犲狋_狋犵犾犲狓_狊犲狀犱_犿犵犿狋_狉犲狇(犵犾犲狓_犲狆_犺犪狀犱犾犲_狋犲狆,狊狋狉狌犮狋犵犾犲狓_犿犵犿狋_犻狀犳狅狉犲狇,犻狀狋32_狋犳犾犪犵);犵犾犲狓_狉犲狋_狋犵犾犲狓_狉犲犮犲犻狏犲_犿犵犿狋_犪犮犽(犵犾犲狓_犲狆_犺犪狀犱犾犲_狋犲狆,犻狀狋32_狋狋犻犿犲狅狌狋,狊狋狉狌犮狋犵犾犲狓_犿犵犿狋_犻狀犳狅犪犮犽);其中,ep表示系统通信端点,每个MPI进程只能使用单个ep,而且在使用前需要通过调用glex_create_ep()函数进行创建,使用结束后通过调用glex_destroy_ep()函数进行释放.Flag标记可以用来控制管理报文的处理行为,例如是否需要阻塞执行、是否以中断方法从MPQ中获取报文等.Req_timeout用来指定接收管理响应报文的超时时间.由于管理报文通过高速互连网络传输,其请求响应时间非常短(可参见下文评测结果),所以req_timeout通常设置为1秒.Structglex_mgmt_info是在内存中存放管理请求和响应报文的公共数据结构,该结构涵盖了各种管理报文的信息域.Glex_ret_t为函数执行后的返回码.3.4.2管理报文在NIC中的数据流针对管理报文,NIC芯片需要实现4方面数据流的处理:(1)主机产生的管理请求报文.由管理程序向SDQ提交管理描述符后,经过NIC的描述符队列管理与仲裁、描述符分发等模块处理后进入MP发送处理部件.该部件根据描述符携带的相关信息构造管理报文头,再经过发送仲裁与报文变换模块将管理报文转换为链路层的Flit,然后通过数据链路层(LinkLevelProtocols,LLP)发送到物理层;(2)到达NIC-NMA的管理请求报文.从LLP层接收到的管理报文经过NIC的报文变换与分发模块后,进入管理请求报文接收FIFO.NIC-NMA模块从该FIFO中读取管理请求报文进行处理;(3)NIC-NMA产生的管理响应报文.NIC-NMA处理管理请求后产生的管理应答报文,或主动产生的故障报告报文进入管理响应报文的发送FIFO,等待发送仲裁与报文变换模块将管理报文转换为链路层的Flit,然后经过LLP层发送到物理层;(4)达到主机的管理响应报文.从LLP层接收到的管理报文经过NIC的报文变换与分发模块后,进入RDMA读响应/管理响应接收FIFO,再经过DMA写管理、MP接收队列管理模块的处理后,进入主机内存中属于特定VP的MPQ中,从而通过硬件中断或被动查询的方式由管理软件获取并处理.Page7图4给出了NIC芯片处理管理报文的数据流.可见,NIC为了支持带内网络管理,除了需要MP处理部件对管理请求报文进行特殊处理外,只需要增图4管理报文在NIC中的数据流3.4.3管理报文在NRC中的数据流针对管理报文,NRC芯片需要实现3方面的处理:(1)转发管理报文.如果接收到目的为其他NRC/NIC芯片的管理报文,则直接经过由Tile构成的NOC(NetworkonChip)网络进行报文交换,并从正确的端口输出到下一跳步NRC/NIC芯片;(2)吸收管理报文.如果接收到目的为本NRC芯片的管理报文,则交给本芯片的NRC_NMA模块进行处理;(3)产生管理报文.本NRC芯片产生管理响应报文或主动故障报告报文,并从本芯片的正确端口输出到下一跳步NRC/NIC.图5管理报文在NRC中的数据流加NIC_NMA处理模块,该模块处理以本芯片为管理目标芯片的管理请求报文,产生相应的管理响应报文,并在芯片发生故障时主动产生报告报文.图5给出了NRC芯片转发、吸收和产生管理报文的数据流.在实现中,为了节省长线资源,管理报文从输入端口到NMA模块和从NMA模块到输出端口都采用中继(RelayStation,RS)方式实现.而且,为进一步降低芯片后端实现的难度,传输管理报文Flit采用多拍流水传送方式.总体而言,RS模块的功能是将NOC送来的管理报文传递给NMA模块,并将NMA送来的管理报文传递到正确的端口.对于单个RS模块而言,需要处理4个流向的数据:(1)将NOC送入的管理报文向NMA方向送出;(2)将左相邻RS送入的管理报文向NMA方向送Page8出;(3)将右相邻RS或NMA送入的输出端口为本端口的管理报文向本端口LLP层送出;(4)将右相邻RS或NMA送入的输出端口不是本端口的管理报文向左相邻RS送出.RS传送管理报文的数据宽度为20位,所以传送管理报文的一个Flit需要10个时钟周期,而传送单个管理报文需要40个时钟周期.NRC芯片设计为24端口,所以需要实例化24个RS模块,各个RS模块构成的简单Mesh结构网络.3.5管理报文的处理两款芯片NIC和NRC对管理报文处理的模块分别为NIC_NMA和NRC_NMA,两个模块在功能实现方面既有共同点又存在差异.在NRC中,如图6所示,管理报文会从RS网络中任意一行的最后一个RS模块进入NMA模块,该模块首先通过nmp_unpacker子模块对报文解封装,然后由nmp_distributor子模块根据报文类型将其分发给相应的功能处理模块,其处理完成后产生的管理响应报文和主动产生的故障报告报文被nmp_collector子模块收集后进入管理报文输出队列nmp_output_fifo等待发送,最后nmp_packer从该报文输出队列中取出管理报文,并根据报文路由域指定的当前跳步输出端口将报文发送到正确的RS行的相连RS模块.在NIC芯片中,从网络传输而来的管理请求报文被网络接口模块接收后,直接交给该芯片的NMA模块进行处理.在NMA模块中,管理报文首先进入缓冲区,然后根据报文类型将其分派给相应的功能处理模块,接着处理完成产生的管理响应报文以及主动产生的故障报告报文被调度到LLP层报文发送模块,最后进入物理层传输.除了管理报文接收和发送的接口不同外,NMA对管理报文处理以及主动报告报文的产生模块的功能及实现在两款芯片中基本相同.这些功能及实现基本相同的子模块简单描述如下:(1)nmp_distributor子模块.根据管理请求报文NMPType域值,将请求报文分发到相应的功能处理模块;(2)reg_access子模块.解释寄存器访问请求报文内容,并产生寄存器读或写信号,然后根据读出的寄存器数据或写完成情况产生响应报文.每个寄存器访问请求报文可以最多可携带两个寄存器访问请求;(3)eep_access子模块.解释E2prom访问请求报文内容,并向I2C主控制模块产生E2prom读或写信号,然后根据读出的数据或写完成情况产生响应报文.每个E2prom访问请求报文最多可携带6个E2prom项访问请求;(4)active_report子模块.根据被监控模块的故障报告信号、报告使能寄存器、故障屏蔽寄存器等,产生故障主动报告报文;(5)nmp_collector子模块.从reg_access、eep_access和active_report子模块收集管理报文并将其交给后续模块进行处理.该模块需要对多个模块产生的管理报文并发请求进行仲裁,并以管理报文的4个Flit为单位进行发送调度.调度采用固定优先级仲裁,且保证管理响应报文比故障主动报告报文具有更高的优先级.3.6管理软件的框架TH-2网络管理软件主要由管理服务器软件和管理客户端软件构成.管理服务器软件可以通过NIC直接管理高速网络,管理客户端软件通过以太网与网络管理服务器软件通信,而获取高速网络的状态,并能够对网络进行配置管理.具体而言,管理服务器软件部署在管理服务器上,实现网络拓扑、网络故障、网络测量的管理与告警推送等功能.网络测量功能包括配置策略自动模块和性能分析模块;网络拓扑管理包括拓扑发现、拓扑建模;网络故障管理包括事件采集和故障分析;视图服务接口为管理客户端提供了服务接口.管理服务器软件通过发送管理请求报文并接收管理响应报文,获取高速网络的状态信息,并能够对网络进行配置,实现对互连网络的有效管理,支持交换机状态采集和路由静态配置等功能.管理客户端软件提供统一的可视化的管理视图,包括拓扑视图、故障视图、设备视图、流量视图和日志视图.拓扑视图提供了互连网络物理视图和逻辑视图,网络物理视图提供了物理机柜的部署等图示,逻辑视图提供了网络节点、计算节点、存储节点和服务节点间的连接关系图示,并支持网络分层的拓扑显示功能,支持拓扑视图可编辑功能;故障视图以可视化方式给出网络故障发生时间、告警触发位置、故障原因和故障的严重程度描述;配置视图提供了网络性能配置和路由配置等功能.图7给出了Page9TH-2互连网络管理软件呈现的一个底层交换机的拓扑视图.除提供上述图形用户接口外,为了快捷地图7网络管理软件界面示例由于网络监控的重点是链路状态(包括链路的握手次数、重传次数、链路宽度、芯片温度等),所以管理客户端软件可采用多种模式监控网络状态:(1)单次模式.用户通常只是需要单次查看芯片的状态信息,例如温度信息、链路宽度.这类信息的特点是结果相对稳定,变化的幅度和频率较小;(2)循环模式.用户需要连续地查看芯片的状态信息,例如链路握手次数.这类信息的特点是在异常情况下变化的幅度和频率可能都较大;(3)比较模式.用户关心芯片状态的变化情况,例如在调试过程中链路的重传次数信息.这类信息的特点是其绝对值参考价值较小,而差值更有意义.因此,客户端程序需要支持可调的扫描间隔,并自动比较相邻两次扫描结果.4性能评测与分析本节将对TH-2互连网络带内网络管理的性能进行测试与分析.实际上,TH-2互连网络在实现了带内网络管理的同时,还提供了带外网络管理接口.这主要考虑到两方面因素:一是由于带内管理报文传输依赖于网络自身,所以对于某些特殊情况下的网络参数配置还需要借助带外网络管理,例如为了优化链路质量,对物理层HHS的FFE(FeedForwardEqualization)参数进行调制等.二是充分考虑到大规模互连网络管理的复杂性与重要性,增加网络管理的设计余量,提供多途径的网络管理.进行网络调试,管理客户端软件还可以向管理用户提供命令行接口.在整个测试过程中,测试对象无论是带内还是带外网络管理,其管理命令都是在连接到TH-2系统的同一个管理服务器上执行.该管理服务器不仅通过NIC接入TH-2高速互连网络,而且通过万兆以太网(GigabitEthernet)接入了带外监控网络.TH-2系统带外监控网络主要依靠I2C通路实现系统的配置与监控.在具体实现方面,每个计算和通信机框内都有一块嵌入式监控板,该监控板上的ARM处理器和FLASH存储器等硬件构成一个轻量级嵌入式系统,所有监控板通过以太网相连,并与接入以太网的管理服务器构成带外监控网络.管理服务器采用两种方式访问带外监控网络,一是通过Telnet登录到监控板子系统管理其所在机框内的部件,二是通过向监控板子系统发送基于TCP/IP协议传输的带外网络管理报文进行管理.在最终定型的管理体系结构中,带外网络管理主要负责机框内计算板和交换板的加切电和硬复位操作,同时负责对板上温度和电压的监控;带内网络管理主要负责网络芯片的配置与监控等.网络管理操作延迟是评价大规模高速互连网络管理的性能的重要指标之一[13].因此,本节对TH-2互连网络的带内和带外两种网络管理方式进行寄存器访问、E2prom访问、全网拓扑发现的延迟性能做了对比测试.此外,由于带内网管占用数据传输通道,本节还对带内管理对网络性能的影响进行了理论分析.最后,测试了TH-2系统带内网络管理对上Page10一代系统带外网络管理的性能改善情况.4.1寄存器访问性能测试首先,我们对比测试了带内和带外的寄存器访问性能.对于带内网络管理而言,我们先行测试了访问与管理服务器直连NRC寄存器的性能.由于上层管理软件及其底层驱动程序存在访问开销并会带来测量误差,所以性能测试过程采取多次测量求平均值的方法.具体而言,带内网络管理上层软件在构造了管理报文并通过glex_create_ep()函数申请到硬件VP资源后,连续N次执行如下操作事务:(1)通过glex_send_mgmt_req()函数发送管理请求报文;(2)等待该请求报文相应的管理响应报文达到,然后通过glex_receive_mgmt_ack()函数接收管理响应报文.在上述N次请求—响应事务串行执行完后再释放VP资源.该过程避免了VP资源申请与释放带来的额外延迟开销.对于带外网络管理而图8单跳步寄存器访问性能测试结果图8(d)给出了带内网络管理单次事务访问两个寄存器的性能测试结果.可见:(1)各种情况的寄存器访问平均延迟都随着循环测试次数N的增加而降低;(2)单次写两个寄存器与单个寄存器的延迟基本相同;(3)单次读两个寄存器的延迟比读单个寄存器的延迟长,但前者小于后者的2倍.究其原因,NMA模块在接收到寄存器写请求报文后立即返回言,也采取了类似方法降低额外通信开销,限于篇幅不再赘述.在文中的各实验中,除了特别说明是在网络处于繁忙状态下测试之外,对带内管理的性能测试都是在网络处于空闲状态下进行的.图8(a)~(c)给出了带内和带外方式访问寄存器的性能对比测试结果.测试过程中,寄存器访问操作分为读和写;每个请求—响应事务只访问单个64位的寄存器;每次访问对象固定为某个常用的链路状态寄存器.可见:(1)随着循环测试次数N的不断增加,带内与带外方式单次访问单个寄存器的时间趋于稳定;(2)寄存器的带内访问的延迟远低于带外访问延迟.例如在循环测试次数N=1000次时,带内和带外读寄存器的延迟分别为6.73μs和4816.66μs,后者大约是前者的716倍;(3)寄存器的带外读延迟与带外写延迟基本相等,寄存器的带内写延迟略微低于带内读延迟.寄存器写响应报文,而不用等待寄存器写操作完成,而在接收到寄存器读请求报文后必需要等待寄存器读操作完成后才能返回携带寄存器值的读响应报文.带内方式访问寄存器的性能远远高于带外方式,其主要原因在于:带外的I2C是一种低速总线,其串行的8位双向数据传输速率在标准模式下仅有100kbps[1],其带宽远远低于直接使用互连网络高Page11速链路的带内方式.使用低速的带外方式管理管理高速互连网络已经难以适应超级计算系统互连规模不断增大的发展趋势.4.2E2prom访问性能测试在TH-2互连网络中,两种网络芯片的配置参数都是保存在E2prom存储器中,而且系统中每个网络芯片对应一个E2prom.系统选择的E2prom容量为64KB,地址长度为16位,每个地址存储单字节数据.与寄存器访问相同,对E2prom的访问也可采用带内和带外两种方式.为了全面比较两种方式访问E2prom的性能,本实验首先测试了各种方式下的E2prom读写的性能,且每次读写的目标都是E2prom存储器的单字节数据.图9给出了N次循环测试的性能对比结图9E2prom访问性能测试结果由于带内访问E2prom的每个管理请求报文最多可携带6个独立的地址,而相应的管理响应报文可携带6KB的数据.为了进一步全面了解带内访问E2prom的性能,本实验将管理请求报文携带的E2prom单元地址数从1变化到6,并统计各种循环测试次数下的平均访问延迟,其测试结果如图9(c)和(d)所示.可见,单次E2prom访问的延迟随着访问字节数的增加而线性增长.具体而言,在管理请求报文中每增加1个访问地址,其读和写访问E2prom的延迟分别增加约150μs和3000μs.果,其中图9(a)为N的取值从1~10(步长为1)的测试结果,图9(b)为N的取值从10~100(步长为10)的测试结果.可见,在单次访问E2prom时,带内读和写E2prom的延迟基本一致,带外读和写E2prom的延迟也基本一致,这主要是因为上层管理软件及其驱动程序的访问开销隐藏了底层硬件的读或写访问E2prom的延迟差异.但是,随着循环访问次数N的增加,各种访问方式的延迟很快趋于稳定;稳定情况下各种操作方式的延迟对比结果为:带外写带内写>带外读带内读.与寄存器访问相比,即使以带内方式访问E2prom,其访问延迟非常大,这是因为:E2prom存储器通常只提供I2C接口,NMA模块通过I2C接口访问该存储器成为了带内访问E2prom性能瓶颈.4.3跳步数敏感性测试带内网络管理的管理报文是通过高速互连网络自身传输的,而网络传输距离(网络跳步数)将会影响报文的传输延迟,所以寄存器和E2prom的访问延迟必然受到网络跳步数的影响.由于网络传输管理报文时,并不区分管理报文的种类,所以为了了解带内访问延迟对网络跳步数的敏感性,只需要测量各种跳步数情况下的寄存器访问延迟即可.在TH-2互连网络中,网络最大跳步数为9跳,而通过带内访问NRC芯片的最大跳步数为8跳.本实验在TH-2互连网络中选择距离测试所用管理服务器Page12的网络跳步数分别为从0~8的NRC芯片进行访问.为了降低软件开销和测量误差,带内网络管理在每种网络距离情况下读单个寄存器的循环测试次数均设置为1000次.测试结果如图10所示,可见寄存器访问延迟随着网络跳步数的增加基本呈现线性增长.通过进一步分析与计算测试结果可知,带内管理报文传输单个网络跳步的双向延迟约为0.8762μs.如果将管理请求—响应事务时间简单建模为管理报文传输延迟与管理报文处理延迟之和,则可给出带内网络管理访问寄存器和E2prom(假设只考虑每个管理报文访问单个寄存器或E2prom项的情况)延迟的近似模型为带内访问延迟=管理报文处理延迟+(跳步数+1)×管理报文单跳双向传输延迟.则根据以上各实验的相关测试结果可知,寄存器访问管理报文的处理延迟大约为5.9597μs,E2prom访问管理报文的处理延迟大约为157.8260μs.4.4拓扑发现性能测试TH-2互连网络拓扑发现过程简单描述为:从管理服务器的NIC芯片开始探索与之相连的NRC芯片,并构建指向该NRC芯片的源路由表(在管理服务器内存中分配的用来记录管理服务器与各个网络芯片间往返路由路径的数据结构)表项,访问该NRC芯片各个端口所记录的对方端口的标记信息(该信息记录对方端口的芯片类型、芯片编号和端口编号等),并根据标记信息分情况处理:(1)若该端口连接NIC芯片,则记录与该NIC芯片的邻接关系;(2)若该端口连接NRC芯片,且未记录与该芯片的邻接关系,则将该NRC芯片加入队列等待处理并记录与该芯片的邻接关系;(3)若该端口连接NRC芯片,且已记录与该芯片的邻接关系,则无需重复处理;(4)当队列非空的,则依次获取NRC的芯片编号,构建访问NRC芯片的源路由表,并重复上述端口扫描过程.在正常情况下,当队列为空时,意味着整个互连网络系统的拓扑结构发现过程结束.此时,不但构造了访问系统中任意网络芯片的源路由表,而且所有网络芯片端口间的邻接关系也已经记录完成.TH-2互连网络系统共5856块NRC芯片和18304块NIC芯片,本实验将统计基于带内管理的拓扑发现的性能.由于网络闲忙状态影响管理报文传输延迟,本实验分为两种情况进行:(1)网络处于空闲状态,即系统所有计算节点为idle状态;(2)网络处于繁忙状态,即将系统中18304个计算节点分为数目基本相等的8组,对每组节点持续进行组内AlltoAll通信测试.本实验分别测试了两种情况下的拓扑发现耗用的时间,且对每种情况分别测试20次.图11给出了拓扑发现的性能测试结果.在网络空闲和繁忙时,拓扑发现的平均时间分别为472822μs和490885μs,后者比前者只增加了约3.8%.可见,基于带内的网络拓扑发现非常高效,发现TH-2系统所有网络芯片低于500ms,而且网络的繁忙状态对管理报文传输性能影响非常小.4.5对网络性能的影响分析管理报文与数据报文的传输共享底层物理链路,因此带内管理不可避免的会影响网络数据传输性能.为了进一步评估带内管理对网络性能的影响程度,我们首先对此进行理论分析.假设对TH-2互连网络5856块NRC芯片执行一次状态扫描过程.带内管理采用请求-响应模式对管理报文进行流控.在读取每个NRC芯片状态时,再假设每个端口读取10个状态寄存器,则扫描单个NRC共需要发送120个管理请求报文.根据4.1节的实验,带内读寄存器的硬件延迟约为6.73μs,而从生成管理请求描述符、发送管理请求报,到接收相应的管理响应报文,整个过程的延迟大约为7.40μs.根据4.3节的实验,单个网络跳Page13步的双向延迟大约为0.88μs.表1给出了TH-2系统带内网络管理某次拓扑发现的所有NRC距离管理服务器的网络跳步统计情况.跳步数(hop)数量(Amount)跳步数(hop)数量(Amount)01234全系统状态扫描时间为系统中每个NRC状态扫描时间之和,而每个NRC状态扫描时间约等于管理请求处理延迟与管理报文传输延迟之和.根据以上参数可计算扫描整个系统NRC状态的时间(表示为Timescan)的方法如式(1)所示,其中M表示扫描每个NRC所需的请求-响应事务数目;Ri表示编号为i的NRC芯片;k为系统中NRC芯片的总数;P(Ri)表示芯片Ri对管理请求报文的处理延迟;T(Ri)表示访问芯片Ri时管理报文的双向传输延迟.对于TH-2系统而言,k=5856,M=120.式(1)第2步骤中的DP和DT分别表示管理请求报文处理延迟和单跳双向传输延迟,TH-2系统的DP和DT分别取值为7.40μs和0.88μs;Amount(hop)表示系统中距离管理服务器网络跳步数等于hop的NRC芯片的数目,其统计情况如表1所示.由此,可计算出带内网络管理扫描TH-2网络系统所有NRC芯片的时间约为9.38s.Timescan=M·∑为了评估带内管理对网络性能的影响,需要进一步计算出扫描TH-2网络所产生的数据量.对于执行一次网络系统状态扫描而言,共访问5856个NRC,访问每个NRC需要120个请求报文和相应120个响应报文,每个管理报文包含4个Flit,每个Flit包含198位数据.所以,扫描一次网络状态产生的管理报文双向数据量为1.0367GB,其平均带宽为0.1105Gbps.TH-2网络链路双向带宽为224Gbps,所以即使执行连续的网络状态扫描,带内管理产生的流量在最差情况下也只占网络可用带宽的0.0493%.实际的带宽测试与系统使用情况也表明,带内网络管理流量对普通数据流量的带宽影响可忽略不计.同时,由于网络实现中管理报文比普通数据报文具有更高的调度优先级,所以数据报文流量对网络管理流量的性能影响也非常低.4.6与TH-1A网络管理的比较部署于国家超级计算天津中心的“天河-1A(TH-1A)”是TH-2的前一代计算系统.TH-1A系统的全定制高速互连网络采用了基于I2C的带外网络管理,其管理架构与TH-2系统互连网络带外管理基本相同.与TH-1A相比,TH-2网络管理的改进主要体现在3个方面:(1)TH-2网络芯片增加了大量配置寄存器和状态寄存器,大大增强了可配置性和可观测性;(2)TH-2网络芯片中所有寄存器都采用了按址访问(常用寄存器采用直接地址访问,而少数寄存器采用间接地址访问),这区别于TH-1A网络芯片中将所有寄存器串接成扫描链的技术;(3)TH-1A只采用了基于I2C的带外网络管理方式,而TH-2采用了带内与带外相结合,并且主要将带内用于网络芯片的配置与监控的网络管理方式.为了直观了解TH-2系统带内网络管理对TH-1A系统网络带内管理性能的改进情况,我们分别对两个系统的网络管理软件扫描网络状态的时间进行统计.每次网络状态扫描需要访问网络中所有物理端口的链路重传计数器并记录使用的时间,每个系统进行10次状态扫描.表2给出了两个系统网络状态扫描所访问网络芯片数目、物理端口数目和平均状态扫描时间.可见,与带外网络管理相比,带内网络管理显著提高了网络管理效率.表2TH-1A与TH-2互连网络管理性能比较系统名称NRC数目物理端口数目平均状态扫描时间/sTH-1ATH-25相关研究“天河”系列超级计算机由国防科技大学研制.第一代TH-1A计算系统采用了CPU和GPU相结合的异构融合计算体系结构,并设计了专用的高带宽低延迟互连网络实现了计算与通信的平衡.文献[14]对TH-1A计算系统的软硬件结构进行了详细描述.文献[15-16]进一步详细描述了TH-1A互连网络的消息传递服务(Message-PassingService)模型.TH-2是第二代“天河”计算系统,它使用MIC处理器作为计算节点的加速部件,实现了计算性能Page14的提升.TH-2计算系统设计了NIC和NRC两款网络芯片实现了系统的互连.文献[4,17]对该互连网络的用户级通信机制、集合操作卸载方法、端到端可靠通信实现等方面进行了阐述.互连网络的易管理型直接影响超级计算系统的可用性,因此本文重点关注了TH-2计算系统的互连网络管理,详细描述了带内网络管理的实现与性能评测.除了“天河”超级计算系统外,世界上一些著名的超级计算系统也采用了专用定制高速互连网络,例如IBMBlueGene/Q[18],FujitsuTofu[19],CrayGemini[20]等.其中,Gemini互连网络采用自适应路由传输网络数据,并采用源路由传输用于故障诊断的控制报文.作为一种高性能、高可靠的互连网络协议,Infiniband[21]已经成为高性能计算和云计算领域重要的互连技术.InfiniBand的子网管理相关研究已经比较成熟,并产生了开放的网络管理软件OpenSM.文献[13,22-23]对OpenSM网络拓扑发现、路由机制、故障诊断进行了研究.Mellanox设计的FabricIT实现了InfiniBand子网管理,支持通道映射、诊断和调试等功能.在大规模计算系统管理,特别是集群管理方面,国内外不少研究机构提出了各种监控管理软件架构,例如ganglia[24]、supermon[25]和parmon[26]等.这些研究项目重点解决的是大规模计算系统各种软硬件资源及其状态的分布式监控和管理问题.在网络管理的功能设计方面,文献[10-11]分别就拓扑发现和路径追踪进行了深入研究.6结论与展望评价互连网络质量的测度主要包括高性能、低功耗、高可靠、易管理等.高性能通常指网络的通信带宽高和/或通信延迟低等.高性能往往是网络设计追求的首要目标,而易管理却常常由于各种因素而被忽视或未得到足够的重视.实际上,忽视网络易管理的重要性得不偿失.首先,在网络调试阶段,可管理性差的网络将需要更多的人力和精力投入到网络的调试和测试过程.再者,在网络维护过程中,可管理性差的网络需要专业性更强的技术人员从事网络管理和维护工作.此外,在网络出现故障的情况下,可管理性差的网络将需要更长的故障定位和处理时间,才能恢复网络的正常运行,这将延长用户作业的完成时间并影响用户体验质量.TH-2超级计算系统采用了基于带内的网络管理技术,取得了良好的实际应用效果.本文主要介绍了TH-2互连网络带内管理的实现与评测.下一步相关工作包括:一是研究增强型带内管理协议,进一步提高带内网络管理的容错能力;二是将高效的带内网络管理与系统计算资源管理结合起来,在计算资源分配时充分利用带内网络管理可提供的网络状态信息,从而提高系统的可靠性和可用性.
