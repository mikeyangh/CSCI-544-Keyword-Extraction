Page1云计算环境下面向数据密集型应用的数据布局策略与方法郑湃崔立真王海洋徐猛(山东大学计算机科学与技术学院济南250101)摘要云计算环境下面向流程的数据密集型应用已被广泛应用于多个领域.面对多数据中心的云计算环境,这类应用在数据布局方面遇到了新的挑战,主要表现在如何减少跨数据中心的数据传输、如何保持数据间的依赖性以及如何在提高效率的同时兼顾全局的负载均衡等.针对这些挑战,文中提出一种三阶段数据布局策略,分别针对跨数据中心数据传输、数据依赖关系和全局负载均衡三个目标对数据布局方案进行求解和优化.实验显示,文中提出的数据布局策略具有良好的综合性能,特别是在降低流程执行过程中由跨数据中心数据传输所导致的时间开销方面,效果尤为明显.关键词云计算;流程;数据密集;数据布局;数据依赖1引言随着信息技术的发展和普及,互联网逐渐成为一种计算平台.云计算是一种典型的网络计算模式,强调在虚拟计算环境下运行大规模应用的可伸缩性和可用性.基于云计算的大型网络应用呈现出分布、异构的特点和数据密集的趋势,如科学工作流系统,这类应用被称为数据密集型应用[1].目前数据密集型应用已被广泛应用于天文学[2]、高能物理学[3]以及生物信息学[4]等领域.这类应用的数据密集性主要体现在其处理的数据大小通常达TB甚至PB级,Page2其中既有已存在的输入数据源,也有在对数据进行分析和处理的过程中产生的中间数据和最终结果数据,而通过使用流程管理技术,可以实现这类数据密集型应用的自动化执行.数据密集型应用,尤其是那些面向流程的数据密集型应用,在利用云计算环境的过程中遇到了一些新的挑战,特别是在数据布局方面尤为突出.在云计算环境下部署并执行数据密集型应用,需要多数据中心的协作,因此在多数据中心环境下如何为大量数据选择合适的存放位置变得至关重要,具体表现为:(1)面对云环境下的多数据中心,这些应用在其执行过程中不可避免地需要进行跨数据中心的数据传输.一方面数据规模巨大而数据中心间网络带宽有限,另一方面存在一些数据只能被存放于指定的数据中心而不能被移动,故数据中心间的数据传输成为一个挑战.(2)这类应用的流程特性决定了其数据之间存在数据依赖关系.在多数据中心环境下,合理的数据布局方案应力求保持这种数据间的依赖关系,这将利于降低流程执行过程中跨数据中心数据传输所导致的时间开销,进而提升执行效率.(3)合理的数据布局方案,应在对应用执行效率进行优化的基础上,兼顾多数据中心间的全局负载均衡.本文通过分析云计算环境下面向流程的数据密集型应用的特点,在全面考虑数据传输次数、数据集大小以及数据中心间网络带宽等因素的基础上,提出云计算环境下面向数据密集型应用的三阶段数据布局策略,该策略的3个阶段分别针对跨数据中心数据传输、数据间依赖关系和多数据中心间负载均衡三个目标对数据布局方案进行求解和优化.该策略一方面解决了多数据中心环境下大规模数据的布局问题,降低了应用执行过程中跨数据中心数据传输所导致的时间开销;另一方面,对数据集间的数据依赖关系进行建模并依此对不同数据布局方案进行评价和调整,以使数据布局方案尽可能符合数据集间的依赖关系;此外,对不同的数据布局方案所对应的负载均衡状况进行量化分析并依此对数据布局方案进行筛选,从而在保证执行效率的基础上兼顾全局的负载均衡.本文第2节介绍相关工作,并在此基础上进一步阐明本文与相关工作的差异与研究意义;第3节介绍云环境下数据密集型流程应用的数据布局问题,并对相关概念进行建模;第4节介绍本文所提的三阶段数据布局管理策略以及数据布局方案的求解与优化过程;第5节通过仿真实验将本文数据布局策略与其它同类策略进行对比,并对结果进行分析;最后一节,将对本文工作进行总结并对后续研究进行展望.2相关工作本节首先简要介绍当前云计算环境下的数据管理系统;然后阐述几种数据密集型应用系统的数据管理策略;之后介绍目前关于数据依赖性的研究;最后,介绍当前针对云计算环境下数据密集型应用的数据布局问题的相关研究,并指出其局限性.随着云计算日益受到重视,目前出现了一些云计算环境下的数据管理系统,例如GoogleFileSystem[5]和Hadoop①,二者均对用户隐藏了用于存储应用数据的基础设施.GoogleFileSystem主要针对Web搜索应用,而非云计算环境下的流程应用.Hadoop则是一个更为通用的分布式文件系统,包括Amazon和Facebook在内的许多公司使用该系统.当Hadoop文件系统接收到一个文件时,系统会自动将该文件分为若干块,并将每个块随机放置于某个集群中.此外,Cumulus项目[6]提出了一个单数据中心环境的云架构.然而,上述云数据管理系统并未针对云环境下数据密集型流程应用的数据布局问题进行相关研究.常见的数据密集型流程应用系统都有其各自的数据管理策略.在流程的构建阶段,这类策略主要针对数据的建模,例如Kepler[3]使用了一种面向角色的数据建模方法,用于网格环境下的大规模数据建模;Taverna[4]和ASKALON[7]则分别采用了各自的流程定义语言来表示其数据流.在流程的执行阶段,大部分系统采用某种数据网格来对数据进行管理,例如Kepler使用了SRB[8]系统,Pegasus[2]和Triana[9]采用了RLS系统[10].数据网格的主要作用是为分布式环境下的数据密集型应用提供基础设施与服务,以实现对分布存储资源中海量数据集的访问、移动和修改[11].然而,无论在流程的构建阶段还是执行阶段,这些系统的数据管理策略都没有关注数据的存放布局,既没有考虑数据间的依赖性,也无法减少跨数据中心的数据移动.当前已有一些研究注意到数据密集型流程应用中的数据依赖性问题.Filecules项目[12]基于依赖关系对文件进行分组,实验数据显示了其分组策略的可用性和有效性.BitDew[13]将数据的依赖性定义为数据的一个属性,该属性由用户进行预定义.然而,①Hadoop:http://hadoop.apache.orgPage3云计算环境中的所有数据均位于各数据中心,因此由用户来定义数据间的依赖关系,对云计算环境下的数据密集型应用而言是不现实的.此外,这些研究虽然关注数据间的依赖性,但并未基于此来解决数据布局问题,也没有考虑跨数据中心数据传输的代价问题.针对云计算环境下面向流程的数据密集型应用的数据布局管理问题,文献[14]提出了一种基于聚类矩阵的数据布局策略,用于多数据中心环境下数据布局方案的求解和优化.该方法首先将流程应用的所有输入数据构建为依赖矩阵,再利用BEA[15]算法对依赖矩阵进行聚类变换从而得到聚类矩阵,然后基于聚类矩阵对所有数据集组成的集合进行划分,并分别为所得每个划分分配存放位置.实验证明该策略能够减少云计算环境下流程应用执行过程中的跨数据中心数据传输的总次数.然而,数据传输总次数的减少并不一定意味着执行效率的提高,因为每次所传输数据量的大小并不一定相同,且遍布Internet的各数据中心两两之间的网络带宽也不一定相同,即执行过程中跨数据中心数据传输总次数的减少,并不能等同于数据传输所导致时间开销的减少.综上所述,虽然针对云数据管理和流程密集型应用数据管理的研究较多,但关于云计算环境下数据密集型流程应用的数据布局问题的研究较少,当前少数针对该问题的研究也存在一定的局限性,即只关注跨数据中心数据传输的次数,而忽视了所传输数据量大小、各数据中心间的网络带宽差异等因素,因此难以对跨数据中心数据传输所导致的时间开销进行有针对性的优化并进而提高流程应用的执行效率.3问题描述与建模本节将对云计算环境下数据密集型流程应用的数据布局问题的相关概念进行建模,具体包括云计算环境、面向流程的数据密集型应用、单次数据传输时间开销和全局数据传输时间开销.3.1云计算环境云计算环境由多个分布的数据中心组成.由于本文研究重点为云计算环境下的数据布局问题,故本文仅关注其存储资源和网络带宽.据中心组成的集合DC=∪i=1,2…,|DC|示编号为i的数据中心,csi表示数据中心dci的可用定义1.将云计算环境表示为多个分布式数存储空间.DC中各数据中心间网络带宽矩阵表示为对i,j=1,2,…,|DC|且i≠j,B中元素bij表示数据中心dci和dcj之间的网络带宽值.本文假设各数据中心间网络带宽值可知并忽略其实时波动.3.2面向流程的数据密集型应用定义2.将面向流程的数据密集型应用定义为三元组P=〈T,C,DS〉.其中T是P中所有任务的集合;C是各任务间的控制流的集合;DS是P中所有数据集的集合.对流程应用中的单个任务,本文只关注其输入数据集与输出数据集,定义如下.定义3.将面向流程的数据密集型应用P=〈T,C,DS〉中的单个任务定义为二元组ti=〈IDSi,ODSi〉,i=1,2,…,|T|.其中IDSi是任务ti的输入数据集组成的集合;ODSi是任务ti的输出数据集组成的集合.有些数据集只允许被存放在指定的数据中心,本文将其称为固定位置数据集,并将DS中所有固定位置数据集组成的集合记为DSfix,对di∈DSfix,记di的指定存放位置的数据中心编号为fix(di);而允许被存放于任意数据中心的数据集则被称为可变位置数据集,记DS中所有可变位置数据集组成的集合为DSflex.按数据集的产生时间,又可将数据集分为初始数据集和生成数据集.作为流程应用的初始输入数据而在流程执行前已存在的数据集,本文将其称为初始数据集,并将DS中所有初始数据集组成的集合记为DSini;而在执行过程中产生的数据集则被称为生成数据集,DS中所有生成数据集组成的集合被记为DSgen.对DS中的单个数据集,本文只关注其大小、固定存放位置和来源,定义如下.定义4.将面向流程的数据密集型应用P=〈T,C,DS〉中的单个数据集定义为三元组di=〈dsi,lci,gti〉,i=1,2,…,|DS|.其中dsi是数据集di的大小;lci和gti的取值如下:lci=0,di∈DSflex烅烄fix(di),di∈DSf烆结合图1中的两个简单示例说明本文对面向流程的数据密集型应用的建模.在图1(a)中:T=Page4{t1,t2,t3,t4},以其中t3为例,t3=〈{d3,d4},{d5}〉;DS={d1,d2,d3,d4,d5,d6,d7},以其中d6为例,不妨设d6是固定位置数据集必须被放置于2号数据中心且d6大小为2000GB,则d6=〈2000,2,0〉.在图1(b)中:T={t1,t2,t3,t4,t5,t6},以其中任务t3为例,t3=〈{d3,d7},{d6}〉;DS={d1,d2,d3,d4,d5,d6,d7,d8,d9,d10},以其中数据集d8为例,不妨设d8是可变位置数据集且大小为500GB,则d8=〈500,0,1〉.3.3单次数据传输时间开销云计算环境下,流程中每个任务要开始执行须至少满足两个条件:(1)该任务被调度至某个数据中心;(2)该任务的所有输入数据集均位于本地.因此若一个任务的多个输入数据集位于不同的数据中心,则须在任务开始执行前进行跨数据中心的数据传输.关于任务调度策略已有许多相关研究且并非本文重点,故本文基于将任务调度至数据中心比进行跨数据中心数据传输所造成时间开销更小的假设,将任务调度策略简化为:将任务调度至那个使执行该任务所需跨数据中心数据传输所导致时间开销最小的数据中心.考虑单个数据集单次跨数据中心传输的情况.设源数据中心、目标数据中心和目标数据集分别为dci、dcj和dk,则该次数据传输的时间开销可表示为式(1)中dk,dci,dcj3个参数依次表示目标数据集、源数据中心和目标数据中心.dsk表示数据集dk的大小;bij表示数据中心dci和dcj间的网络带宽.此外,在跨数据中心的数据传输过程中存在着请求、响应、建立连接、断开连接等步骤,也会造成一部分时间开销,将其记为Cij.考虑到云计算环境下面向流程的数据密集型应用的数据规模巨大,而Cij相对较小,故本文忽略Cij所代表的那部分与被传输数据集大小无关的时间开销.因此,使用下面式(2)可近似计算单个数据集单次跨数据中心传输所造成的时间开销3.4全局数据传输时间开销定义5.在数据中心集合DC=∪i=1,2,…,|DC|已知的云计算环境中,面向流程的数据密集型应用P=〈T,C,DS〉的一个数据布局方案,是从集合DS到集合DC的映射,使对di∈DS,存在唯一dcj∈DC与之对应.记P=〈T,C,DS〉的一个数据布局方案为s,则有s=∪i=1,2,…,|DS|DC.对di∈DS,记s(di)为在给定数据布局方案s中数据集di所对应存放位置的数据中心编号.定义6.在数据中心集合DC=∪i=1,2,…,|DC|已知的云计算环境中,面向流程的数据密集型应用P=〈T,C,DS〉的一个数据布局方案s的全局跨数据中心数据传输时间开销,是指在DS中所有数据集按s进行布局的情况下,P的执行过程中由跨数据中心数据传输所导致的时间开销.若已知数据中心集合DC、流程应用P=〈T,C,DS〉和数据布局方案s,则可通过模拟流程应用的执行过程来近似计算数据布局方案s的全局跨数据中心数据传输所导致的时间开销.求解给定布局方案的全局跨数据中心数据传输时间开销的近似计算算法将在4.1.3节中给出.4数据布局策略与求解方法如图2所示,本文提出的数据布局求解方法的过程可分为3个阶段:第1阶段,基于遗传算法求得一组跨数据中心数据传输代价较小的数据布局方案;第2阶段,计算第1阶段所得方案集合中各方案的数据依赖关系破坏度,并依此对方案集进行调整;第3阶段,对第2阶段所得方案集中的各方案的数据中心负载均衡状况进行定量分析,并依此确定最终的数据布局方案.Page5图2本文数据布局求解全过程流程图4.1数据布局求解第1阶段在数据布局求解的第1阶段,基于遗传算法求解一组跨数据中心数据传输代价较小的数据布局方案.下面针对云计算环境下面向流程的数据密集型应用的数据布局问题,分别从编码规则、解的有效性保证和解的评价函数3个方面对数据布局方案求解过程的第1阶段进行介绍,并给出第1阶段求解算法.4.1.1编码规则对云计算环境下的数据中心集合DC,面向流程的数据密集型应用P=〈T,C,DS〉,数据布局方案求解第1阶段中解的编码规则如下:对dci∈DC,用log|DC|体的,对i=1,2,…,|DC|-1,dci的编码为i的2位二进制数;而编号为|DC|的数据中心所log|DC|对应的编码为log|DC|如下关系:数据中心dc1dc2…dc9dc10编码00010010…10010000对DS中的每个数据集di∈DS,用一个长度为2的数据中心编码表示其存放位置.对每个log|DC|数据布局方案,用|DS|×log|DC|示:对i=1,2,…,|DS|,染色体左侧第i个长度为2的基因片段表示数据集di存放位置的数据log|DC|中心编号.例如,当|DC|=|DS|=10时,“将数据集di存放于数据中心dci”这一数据布局方案所对应的编码为然而并非每个长度为|DS|×log|DC|0001001000110100010101100111100010010000.制数都一定能表示一个数据布局方案的有效解.4.1.2节中将讨论解的有效性问题与解的有效性保证机制.4.1.2解的有效性保证根据不同的失效原因可将无效解分为3类,下面分别说明,并给出对应的有效性保证机制.第1类无效解.若解s的染色体中存在至少一个基因片段不能代表DC中的数据中心,则解s为第1类无效解.根据4.1.1节中的编码规则,当|DC|满足log|DC|1共2log|DC|数据中心,记这些二进制数的集合为FS|DC|,记解s的染色体中所有|DS|个基因片段所对应的二进制数的集合为PSs,则有在初始布局方案的生成阶段、遗传过程中的交叉、变异阶段,用式(3)对每个新产生的解进行判断,若式(3)成立则淘汰该解.第2类无效解.若解s所表示的数据布局方案使至少一个数据中心在流程开始执行前已处于超负荷状态,则解s为第2类无效解.为保证数据中心的正常运转,通常为数据中心设置一个经验参数λ,若数据中心的使用率不小于λ,则认为该数据中心处于超负荷状态.如3.4节所述,s(di)表示在解s所代表的数据布局方案中数据集di存放位置的数据Page6中心编号,则有dci∈DC,使∑s(dj)=i在初始布局方案的生成阶段、遗传过程中的交叉、变异阶段,用式(4)对每个新产生的解进行判断,若式(4)成立则淘汰该解.第3类无效解.若在解s所表示的数据布局方案中,至少存在一个固定位置数据集的存放位置与其指定位置不同,则解s为第3类无效解.di∈DSfix,使lci≠0且lci≠s(di),则s无效本文对第3类无效解处理策略如下:设P=〈T,C,DS〉满足DSfix≠,则在生成初始解空间的过程中,将每个解的染色体中所有代表di∈DSfix存放位置的基因片段按di的下标升序依次与染色体左侧第一个代表di∈DSflex存放位置的基因片段交换位置,于是所有代表固定位置数据集位置的基因片段将按其下标升序依次分布于染色体左侧,而染色体的其余部分则表示所有可变位置数据集的存放位置.通过对染色体进行上述基因片段的位置变换操作,可保证在交叉和变异阶段不产生第3类无效解.记对P=〈T,C,DS〉的数据布局方案的解所进行的上述基因片段位置变换为Swap(P);记Swap(P)的逆变换为Swap-1(P).4.1.3数据布局方案的评价算法本文所提的数据布局策略的根本目的在于降低云计算环境下面向流程的数据密集型应用在其执行过程中由跨数据中心数据传输所导致的时间开销,故本文以每个数据布局方案所对应的全局数据传输代价的近似值作为布局方案的评价函数,记数据布局方案的评价函数g(s)=TimeCosttotal(DC,P,s).对给定的数据中心集合DC、流程应用P=〈T,C,DS〉和数据布局方案s,可通过算法1求得s对应的数据传输时间开销的近似值,即g(s)值.算法1.数据布局方案的时间开销近似算法.输入:DC,B,P=〈T,C,DS〉,数据布局方案s输出:s的时间开销近似值TimeCosttotal(DC,P,s)主要步骤:1.初始化:令cost=0,TASK为P中所有任务的集合;2.对s进行4.1.2节所述的Swap-1(P)变换;3.令t为P的第一个任务,并将其从TASK中除去;4.while(TASK≠)5.if(t是分支任务)6.for(每个分支)7.记第i个分支对应的子流程为Pi;8.递归计算TimeCosttotal(DC,Pi,s),结果记为9.cost=cost+max{costi};10.令t为t对应的合并任务,将t以及t与t间所11.else12.按3.3节所述任务调度策略为t选择执行位13.for(t的IDS中每个满足s(dj)≠i的数据集dj)14.cost=cost+dsj/b(s(dj),i);15.令t为t在C中的后继任务;16.Return(cost);算法1以“将任务调度至使执行该任务所需跨数据中心数据传输所导致时间开销最小的数据中心”为任务调度策略.若使用其它任务调度策略,只需对算法1稍作修改.算法1虽然只能近似计算给定数据布局方案的数据传输时间开销,但其结果能够反映不同数据布局方案所对应跨数据中心数据传输时间开销的差异与变化趋势,因此算法1结果的不精确性并不影响利用其对不同的数据布局方案进行评价和比较.4.1.4数据布局求解第1阶段算法算法2.数据布局方案求解第1阶段算法.输入:DC,B,P=〈T,C,DS〉,数据布局方案s输出:时间开销较优的数据布局方案集合(CH)主要步骤:1.初始化:定义变量popSize,genSize,maxGen;2.令i=1;3.while(i<=popSize)4.生成随机布局方案s;5.if(s有效且不在CH中)//用式(3)~(5)进行判断6.用算法1近似计算s的时间开销;7.对s进行4.1.2节所述的Swap(P)变换;8.将s加入CH,i++;9.令curGen=0;10.while(curGen<maxGen)11.for(CH中的每个解s)12.if(random(0,1)<变异率mr)13.在s中对应DSflex的部分随机选择变异位置p;14.在位置p对s进行变异,记所得为s;15.对解s进行Swap-1(P)变换,记所得为s;16.if(s无效或s在CH中)17.goto13;18.用s替换s,并用算法1重新计算s的时间开销;19.计算CH中每个解的被选中概率;Page720.令j=0;21.while(true)22.依各解的被选中概率从CH中选两个不同解23.if(random(0,1)<交叉率cr)24.在s中对应DSflex的部分随机选择交叉位置q;25.在位置q对s1与s2进行交叉,记所得为s1,s2;26.for(ns=s1,s2)27.对ns进行Swap-1(P)变换,记所得为ns;28.if(ns有效且ns不在CH中)29.将ns加入CH,并用算法1计算其时间开销;30.j++;31.if(j==genSize)goto32;32.将CH按各解对应时间开销的升序排序;33.从CH中除去后面genSize个解,curGen++;34.对CH中每个解进行Swap-1(P)变换;35.Return(CH);算法2返回的结果是一组跨数据中心数据传输时间开销较优的数据布局方案的集合,该集合中各方案按其所对应时间开销的升序排列.算法2所得即为本文数据布局方案求解方法第1阶段的结果,记为S(1).4.2数据布局求解第2阶段本文数据布局方案求解方法的第2阶段,将基于数据集之间的依赖关系对S(1)中的各方案进行评价和调整.下面给出数据集间的依赖度与数据布局方案的依赖关系破坏度的定义.定义7.面向流程的数据密集型应用P=〈T,C,DS〉,对di∈DS,记Ti为T中所有以di作为输入数据集的任务的集合;对di,dj∈DS,将di和dj之间的数据依赖度记为denp(i,j),则对i≠j有denp(i,j)=|Ti∩Tj|×min{dsi,dsj},di,djDSfix烄|Ti∩Tj|×dsi,diDSfix且dj∈DSfix烅|Ti∩Tj|×dsj,di∈DSfix且djDSfix0,烆定义8.s是面向流程的数据密集型应用P=〈T,C,DS〉的一个数据布局方案,s的数据依赖破坏度记为denp_damage(s),则有denp_damage(s)=∑di,dj∈DS其中dist(i,j)=0,若s(i)=s(j)骤如下:本文数据布局方案求解方法第2阶段的具体步(1)记S(1)中各数据布局方案的全局数据传输时间开销最小值为timeCostmin,在S(1)中选择所有数据传输时间开销值小于timeCostmin×(1+λd)的方案,记这些方案组成的集合为S(1).这里的λd是一个百分比参数,可根据具体需求调整,本文实验中取λd=0.5%.(2)使用式(6)与式(7)计算S(1)中的每个方案的数据依赖破坏度值,并按其升序对S(1)中所有数据布局方案进行排序,所得结果即为本文数据布局方案求解方法第2阶段的结果,记为S(2).4.3数据布局求解第3阶段在本文数据布局方案求解方法的第3阶段,将分别计算S(2)中各方案的负载均衡性能,并依此对各布局方案进行评价和筛选.(1)记S(2)中各数据布局方案数据依赖破坏度最小值为damagemin,在S(2)中选择所有数据依赖破坏度值小于damagemin×(1+λl)的方案,记这些方案所组成的集合为S(2).这里的λl是一个百分比参数,可根据具体需求调整,本文实验中取λl=1%.(2)对S(2)中的每个方案,分别计算其所对应的各数据中心使用率的标准差,其中标准差最小的方案即为本文数据布局方案求解的最终结果.5仿真实验5.1实验设置与环境本节将对本文提出的三阶段数据布局策略(下文简称本文策略)与文献[14]提出的聚类数据布局策略(下文简称聚类策略)进行对比实验.对每个随机生成的测试流程,分别使用本文策略与聚类策略求得各自的数据布局方案,然后基于两个方案对流程进行仿真执行,并记录该过程中的跨数据中心数据传输次数和时间开销.5.2节图中所标注的数据,均为运行1000个参数相同的随机生成测试流程所得结果的平均值;图3与图5中所标注的时间开销单位为模拟时间单位.实验环境为Inter(R)Core(TM)2Duo2.93GHz,RAM3GB,硬盘320GB,100MB网络带宽.5.2实验结果和分析如图3所示,随着输入数据集个数的增加,两种数据布局策略所对应的跨数据中心数据传输所导致的时间开销都呈明显上升趋势;本文策略对应的时间开销明显低于聚类策略,且增速较缓.Page8如图4所示,随着输入数据集个数的增加,两种数据布局策略所对应的跨数据中心数据传输次数都呈明显上升趋势;与聚类策略相比,本文策略所对应的数据传输次数略多,但二者差别非常小.如图5所示,随着数据中心个数的增加,两种数据布局策略所对应的跨数据中心数据传输所导致的时间开销都呈缓慢上升趋势;本文策略对应的时间开销明显低于聚类策略.如图6所示,随着数据中心个数的增加,两种数据布局策略所对应的跨数据中心数据传输次数都呈上升趋势;与聚类策略相比,本文策略所对应的数据传输次数略多,但二者差别非常小.综上所述,对于流程应用执行过程中跨数据中心数据传输的次数,特别是在数据集数较多以及数据中心数较多的情况下,聚类策略所对应的传输次数较本文策略略少,但二者差距较小;而对于流程应用执行过程中跨数据中心数据传输所导致的时间开销,本文策略明显优于聚类策略,且随着数据集数量的增加,本文策略的优势有逐渐扩大的趋势.6结论与未来工作本文首先指出,当前云计算环境下面向流程的数据密集型应用在数据布局管理方面所遇到的挑战,特别是跨数据中心数据传输所造成的不可忽视的时间开销;然后通过对该问题进行分析、建模,并在充分考虑数据移动次数、数据集大小以及网络带宽等因素的基础上提出了兼顾时间开销、数据依赖性和负载均衡三方面指标的数据布局策略与方法;之后,通过与其它数据布局策略的对比实验,说明本文的数据布局策略具有较好的性能,尤其是在降低跨数据中心数据传输导致的时间开销方面,本文策略的优势十分明显.未来我们计划在以下方面进行进一步的研究:首先,计划对本文数据布局方案求解过程第1阶段中初始布局方案生成的环节进行优化,即基于一定的约束条件生成较优的初始方案,以提高求解效率.此外,本文目前主要针对云环境下单个流程应用的数据布局问题进行研究,未来计划研究云计算环境下多个数据密集型流程应用的数据布局管理策略.Page9
