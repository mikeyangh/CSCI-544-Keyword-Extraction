Page1一种面向非对称多核处理器的虚拟机集成调度算法陈锐忠齐德昱林伟伟李剑(华南理工大学计算机系统研究所广州510006)(华南理工大学计算机科学与工程学院广州510006)摘要在计算机体系结构领域,非对称多核处理器将成为未来的主流.对于非对称多核处理器上的虚拟处理器调度问题,现有研究缺乏理论分析,且没有考虑虚拟处理器的同步特性.针对该问题,文中首先建立非线性规划模型,分析得出全面考虑虚拟处理器同步特性、核心非对称性以及核心负载的调度原则.然后,基于调度原则提出一个集成调度算法,该算法定义了效用因子、比例系数、比例资源的概念,结合虚拟处理器的同步特性和核心的非对称性对资源和负载进行全面度量;同时通过运行队列分解降低调度开销.提出的算法是第一个在非对称多核处理器上利用虚拟处理器同步特性的调度算法.实际平台上的实验表明:该算法实现了公平调度,并且性能比其他同类算法提高19%~48%.关键词云计算;虚拟化;非对称多核处理器;虚拟处理器调度;负载均衡1引言云计算将大量软硬件资源整合在一起,形成规模巨大的共享虚拟资源池,为远程计算机用户提供便利、经济的服务,吸引了各界的广泛关注[1].作为云计算的基础技术之一,系统虚拟化在提高资源利用率、简化系统管理等方面有着不可替代的作用,是当今的一个研究热点[2].随着芯片集成规模极限的逼近以及能耗和成本等因素,多核处理器逐渐占据了市场[3-4].相对于对称多核处理器(SymmetricMulti-coreProcessor,SMP),单一指令集非对称多核处理器(AsymmetricSingle-ISAMulti-coreProcessors,AMP)在能耗、面积等方面有着巨大的优势,将成为未来的主流[5-9].在系统虚拟化环境下,虚拟处理器(VirtualCPU,VCPU)调度是AMP发挥优势的关键.因为目前占据市场的仍是SMP,现有的VCPU调度算法[10-14]针对SMP设计,没有利用AMP的特性和优势,从而面临两方面的挑战:(1)AMP的非对称性.很多传统调度器的设计原则,在AMP上不再适用.传统调度器假设所有核心性能相等,因此只根据核心的负载做调度决策.然而在非对称多核处理器上,除了核心负载,调度器还必须考虑核心的性能[15].AMP上的核心支持单一指令集结构,因此VCPU在各个核心上都可以正确执行;而由于核心的性能不同,VCPU在不同核心上的执行效率却是不同的.为了发挥AMP的优势,调度器必须根据各个VCPU在不同核心上的加速比来做调度决策[9,16].研究[17]表明,根据该原则设计的虚拟机调度器可以把性能提高40%.(2)VCPU的同步特性.为了发挥多核处理器的计算能力,并行程序已变得越来越流行[4,18],而同一并行程序中的多个线程需要进行同步.在非虚拟化环境下,线程在物理核心上运行,所有核心一直在线,因此可以迅速释放获得的同步锁.然而,在虚拟化环境下,线程在VCPU上运行,VCPU不是一直在线的.在KVM、Xen等虚拟机管理器(VirtualMachineMonitor,VMM)中,VCPU需要分时共享物理核心,从而导致了同步延迟[10-11,13],例如锁持有者抢占(LockHolderPreemption,LHP)[19]:多个在线的VCPU忙等一个由离线的VCPU持有的锁.同步延迟严重降低了系统的性能和效能(文献[11]表明该问题可使性能降低1.3倍).如何利用VCPU的同步特性与AMP的非对称性,实现高效的VCPU调度,是该形势下的一个关键问题.针对该问题的研究主要有文献[20-21],它们证明了VMM必须针对核心的非对称性进行设计.然而,这些研究存在3个问题:(1)独立调度VCPU,忽略了同步延迟;(2)缺乏理论分析;(3)没有兼顾公平性和性能.因此,这些方法难以高效运行并行程序,特别是同步密集的并行程序(如4.2.1节的实验所示).可见AMP上的VCPU调度问题尚未解决.因此,本文以公平、高性能为目标,为AMP上的VCPU调度问题建立了非线性规划模型,分析核心的非对称性和VCPU的同步特性,得出在公平性约束下,调度应遵循3个原则:(1)同一虚拟机的各个VCPU在同类核心上运行,但不在同一个核心上运行.(2)协同调度运行并行程序的VCPU,独立调度运行串行程序的VCPU.(3)负载均衡.在此基础上,本文提出一个集成调度算法,其特点如下:(1)保证了3个调度原则,提高调度性能.(2)定义了效用因子、比例系数、比例资源的概念.效用因子用于综合度量VCPU的资源需求和核心的负载情况,比例系数用于表征核心的非对称性,比例资源对处理器的计算资源进行抽象.这三者结合VCPU的同步特性和核心的非对称性对资源和负载进行度量,以实现AMP上的公平调度.(3)分解运行队列,控制调度开销.据我们所知,还没有研究对该问题进行建模分析,本文是第一个利用AMP上的VCPU同步特性的调度算法.本文在Xen4.0.1和AMDOpteron2384上对算法的性能、公平性和开销进行比较分析,实验证明:该算法在有效控制开销的情况下实现了公平调度,并且性能比其他同类算法提高了19%~48%.本文第2节对问题进行描述和建模分析,给出调度的目标和原则;第3节详细描述集成调度算法;第4节对所提出的算法进行实验和比较分析;第5节介绍相关研究;最后是总结以及对未来工作的展望.Page32问题描述与建模2.1问题描述目标如下:本文研究AMP上的VCPU调度问题,关注的(1)性能.最小化任务的完成时间.(2)公平性.权重相等的VCPU应得到相等的CPU资源.权重可由管理员根据实际需求手动设定.如图1所示,在系统虚拟化中,虚拟机(VirtualMachine,VM)是在一个物理计算机上模拟出来的多个独立的、具有完整硬件系统功能的执行环境,每个VM里面可以运行不同的操作系统,即客户机操作系统(GuestOperatingSystem,GOS).VMM运行在物理硬件和VM之间,对物理硬件进行抽象,并提供VCPU、虚拟内存等资源给各个VM[22-23].有代表性的系统虚拟化软件包括Xen、KVM、VMwareESX等.下面通过一个简单的例子来说明该问题.示例中的AMP包含6个核心(如图2、图3):F1和F2是快核心,S1~S4是慢核心,快核心的计算能力是慢核心的2倍.对于该平台上运行的3个VM(A,B和C),每个VM包含2个VCPU:A1和A2属于A,B1和B2属于B,C1和C2属于C.3个VM的权重相等.每个VM上运行一个2线程的并行程序,线程每隔2个单位时间就要同步一次,然后继续运行.图2给出一个现有VMM中VCPU调度示例.由于现有VMM调度器没有考虑核心的非对称性,将VCPU随机映射到低负载的核心上,这将导致两方面问题:(1)公平性.快核心的计算能力是慢核心的两倍,但VMM依然对权重相等的VM分配同样的CPU时间,这将导致分配到快核心上的VM得到更多的CPU资源,影响公平性(如图2中A和B得到的CPU资源多于C).(2)性能.当属于同一VM的几个VCPU分配到性能不同的核心上执行时,将导致快核心上的VCPU空等慢核心上的VCPU同步的情况,降低性能(如图2中A1和A2分别映射到异类核心F1和S1上,导致等待;B1和B2亦然).图3给出了理想的VCPU调度示例.该示例一方面根据快慢核心间的性能差异调整了对VM的CPU时间分配,实现了公平调度;另一方面它将属于同一VM的几个VCPU调度到同类核心上运行,从而避免了VCPU空等的情况,并将节省下来的CPU时间用于调度其他VCPU(如图3中的Vx),从而提高了性能.本文提出的集成调度算法实现了这种调度.2.2建模分析在系统虚拟化环境下,任务的执行包含2个操作:GOS将任务映射到所属VM的VCPU上,VMM调度器将VCPU映射到核心上.我们可以为AMP上的VCPU调度问题建立非线性规划模型,表1中给出了本文使用的主要变量和参数.Page4名称含义Ti任务T的第i个线程R(Vi)Vi分配到的CPU资源iTi的第m个阶段vmiVi包含的第m个VCPUTmTki.cTki.stTkTk时间第i个核心的单位时Ci间计算能力Vi第i个VMω(Vi)Vi的权重设T=T1,T2,…,T{i.st表示Tk个线程的任务,所有线程每隔一定时间间隔需进行同步,线程Ti可根据同步间隔分为Ni个阶段i,T2{T1行同步,或者因为运行并行程序,或者因为访问共享资源(如硬盘、网卡等)[11].因此每个阶段可分为计算操作和同步操作,Tk量,TkC2,…,Cn},n∈N表示n个核心的集合,第i个核心的单位时间计算能力为Ci.V={V1,V2,…,Vn},n∈N表示在系统中运行的n个VM的集合,ω(Vi)表示Vi的权重,R(Vi)表示Vi分配到的CPU资源,由2.1节的公平性目标可得式(1)成立:权重相等的VCPU应得到相等的CPU资源.P(Vi)={v1i,v2i,…,vn合.为了避免频繁上下文切换带来的巨大开销[10],我们假设式(2)成立:一个VM包含的VCPU数目不大于物理核心总数,而又不小于该VM上运行的线程数.T的调度可抽象为一个时空映射M=(s,t),其中s是一个空间映射,表示将T的各个阶段映射到各个核心上;t是一个时间映射,表示将T的各个阶段映射到核心的时间片上.设t(Tm时间,即Tm系,只有所有前驱阶段都完成了,一个新阶段才能开始,即式(3):Tk、Tl表示任意2个线程,所有线程要完成前驱阶段(Tml);Tm(Tn性能相关.TimeM(T)表示映射M下T的完成时间,它等于T最后阶段中运行最慢线程的完成时间,满足式(4).式(1)保证了系统的公平性.对于一个动态调度算法来说,最大化系统性能,等价于最小化任务完成时间.因此我们可得该问题的非线性规划模型如下:MinimizeTimeM(T)ω(Vi)=ω(Vj)R(Vi)=R(Vj)烄for0<i,jV(1)maxkt(Tms.t.烅for0<k,lTandm<n(3)TimeM(T)=maxkt(TNkk)+TNkk.c烆但在现实中由于缺乏Tk识,加上求解该问题带来的开销,无法求得该问题的最优解.因此我们采用启发式算法来求问题的近优解.由式(3)、(4)可推出如下等式:其中p是任务T的阶段数目,由T本身属性决定,无法通过调度优化.可见在公平性约束下,AMP上VCPU调度应遵循的原则如下:(1)同一VM的各个VCPU在同类核心上运行,但不在同一个核心上运行.同类核心指性能相等的核心.由式(3)~(5)可知任务完成时间取决于运行最慢的线程,如果将同一VM的各个VCPU放到性能不同的核心上运行,即Tm待慢核心上的VCPU同步的情况(如图2的示例).而当同一VM的各个VCPU放在同一核心上运行时,任务变成串行执行,完成时间TimeM(T)=j=1∑T∑p度需遵循该原则.(2)协同调度运行并行程序的VCPU,独立调度运行串行程序的VCPU.协同调度(co-schedule)指调度多个相关的VCPU在不同核心上同时运行,如VMwareESX的调度器;独立调度是这样一种机制:调度时把VCPU看成一个独立实体,只要有空闲核心就单独运行,不考虑其他VCPU,如Xen的Credit调度器.协同调度在减少VCPU同步时间的同时,将带来优先级反转、处理器碎片等问题[11,13],增加开销.运行并行程序的VCPU同步较多,需要协同调度来减少k.st;而运行串行程序的VCPU的TmTm上原则(1)已保证同一VM的各个VCPU不在同一核心上运行,因此应独立调度,以降低调度开销.同k=1Page5时,该原则将没参与协同调度的核心分配给其它正在运行串行程序的VCPU,这避免了协同调度的碎片问题[11,13],提高了系统性能和效率.(3)各核心负载均衡.由式(3)~(5)可知任务每一阶段的完成时间取决于运行最慢的线程.在公平性约束下,每个VM的得到的资源与其权重成正比,从而轻负载核心将空转,而重负载核心的调度周期将延长,这降低了系统的效率,并使本阶段的Tmt(Tm+1成时间.因此各核心应保持负载均衡.3集成调度算法k)增大,进一步增加了运行最慢的线程的完文献[6,8-9,20]表明:由少量快核心和大量慢核心组成的AMP将是未来的主流.因此本文假设AMP上有2类核心:少量快核心和大量慢核心.如何推广到n种核心是我们下一步研究的内容.本文采用分布式调度器模型[24-26]:每个核心有一个独立的VCPU队列,同一队列中的VCPU循环运行,分时共享该物理核心.现有的虚拟处理器调度器(如KVM、Xen)广泛采用该调度器模型.该算法由4个模块组成:初始映射、资源分配、资源消耗和虚拟处理器选择,执行模型如图4所示.初始映射只在VM启动/关闭时执行,用于根据各个VM的权重、核心的计算能力和负载情况将VCPU映射到各个核心上;资源分配每个调度周期(cycle)执行1次,用于根据各个VM的权重和公平调度原则为VCPU分配计算资源;虚拟处理器选择、资源消耗每个单位时间(slot)执行一次,前者根据2.2节的调度原则作出决策,后者根据公平调度原则处理每个VCPU的资源消耗.3.1初始映射算法根据VM的资源需求和当前核心的负载情况做初始映射.本文提出一个新的概念———效用因子(UtilityFactor,UF),用于综合度量VM的资源需求和核心的负载情况.UF对核心非对称性进行了处理,使算法可以兼顾2.2节所述的调度原则.定义如下:UF(Vi)=μ×Demand(Vi)+(1-μ)×Load,Demand(Vi)=max(0,|P(Vi)|-N(FC))Load=max(0,AvgLoad(FC)-AvgLoad(SC)),其中Demand(Vi)度量了Vi的资源需求,Load度量了当前的核心负载情况,参数μ用于调节资源需求和核心负载的重要性(参数灵敏度分析详见4.2.4节).N(S)表示核心集合S包含核心的数目,FC表示平台上所有快核心的集合,SC表示平台上所有慢核心的集合.AvgLoad(S)表示核心集合S的平均负载.AvgLoad(S)定义如下:CoreLoad(Ci)=其中CoreLoad(Ci)表示核心Ci的负载,即Ci上的VCPU得到的计算资源之和,rq(Ci)表示在Ci上运行的VCPU集合,如式(10)所示.本文定义SF(Ci)为核心Ci的比例系数(ScaledFactor,SF),即核心Ci的频率与平台最低核心频率之比.这里SF(Ci)用于实现非对称多核处理器上的负载均衡———核心的负载与其计算能力成正比[27],后文还将用于资源的公平分配和消耗.VCPULoad(vj到的计算资源.在公平性约束下,VMVk得到的资源与其权重ω(Vk)成正比,这些资源平均分给Vk的每个VCPUvj当一个VM的UF较小时,快核心负载轻于慢核心;并且该VM的VCPU数目小于快核心数目,可根据调度原则(1)将其包含的VCPU映射到快核心上执行.反之当一个VM的UF较大时,快核心负载较重;而当它的VCPU数目大于快核心数目时,Page6将其映射到快核心上将违反调度原则(1),因此应将其调度到慢核心上运行.算法以VM的UF作为初始映射的标准:将UF小于阈值Threshold的VCPU调度到快核心上执行,将UF大于Threshold的VCPU调度到慢核心上执行,并保证同一VM的各个VCPU不在同一核心上运行.伪代码描述如下.算法1.初始映射.for(每一个虚拟机V){NV=V的VCPU数目;if(NV>N(SC)){//此时只能保证各个VCPU不AP=所有核心中NV个负载最轻的核心;}else{if(UF(V)<=Threshold)}将V包含的VCPU分别放入AP中;}初始映射只是尽量兼顾调度原则(1)和(3),如果在后面的执行过程中发现初始映射不是最优方案,虚拟处理器选择模块将根据调度原则做自动调整.3.2资源分配为了实现公平调度,每个VM得到的CPU资源应与其权重成正比.而在AMP上,每个核心根据其性能拥有不同的计算资源.为此我们提出一个新的概念———比例资源(ScaledResource,SR),用于表示CPU资源,使每个核心可分配的资源与其计算能力成正比.SRunit表示单位比例资源,SRtotal表示1个cycle(Z个slot)平台可分配的比例资源总数,定义如式(12);SRtotal按照权重分给各个VM,同属一个VM的各个VCPU平分该VM的SR,如式(13)所示;SRinc(vj增的SR,SR(vj式(14)所示,这实现了对vj过度消耗,新周期vj余,新周期vjSRtotal=Z×(N(FC)×SF(Ci)+N(SC)×为了提高效率,算法对运行队列进行分解:为每个核心Ci维护3个VCPU队列:queue1(Ci),queue2(Ci),queue3(Ci).设|P(v)|为虚拟处理器v所属的VM包含的VCPU数目,queue2(Ci)存放|P(v)|>N(SC)的VCPU.当Ci为慢核心时,queue1(Ci)存放N(FC)<|P(v)|N(SC)的VCPU,queue3(Ci)存放|P(v)|N(FC)的VCPU;当Ci为快核心时,queue1(Ci)存放|P(v)|N(FC)的VCPU,queue3(Ci)存放N(FC)<|P(v)|N(SC)的VCPU.为了控制开销,每个队列没有严格排序,但保证SR>0的VCPU在SR<0的VCPU前面.3.4节将利用这3个VCPU队列提高虚拟处理器选择效率.算法伪代码描述如下.算法2.资源分配.for(每一个VCPUvi)按照式(12)~(14)更新SR(vi)值;for(每一个核心Ci)按照VCPU的SR值调整Ci的VCPU队列;3.3资源消耗每过1个slot,处于运行状态的VCPU的将消耗SR.考虑到AMP的性能非对称性,SR减少的量应与运行核心的计算能力成正比,以实现公平调度.每过1个周期(Z个slot),由启动捆绑处理器(BootStrapProcessor,BSP)触发资源分配操作;每过1个slot,各个核心触发资源消耗操作.设CV(Ci)表示核心Ci正在运行的VCPU,算法伪代码描述如下.算法3.资源消耗.for(每一个核心Ci){SR(CV(Ci))=SR(CV(Ci))-SF(Ci)×SRunit;if(CiisBSP&&1cyclepassed){}3.4虚拟处理器选择在新的slot开始时,算法需为每个核心选择1个VCPU来运行.若CV(Ci)已消耗完资源,算法先在本地的3个运行队列中选择还有剩余资源的VCPU运行;若本地的VCPU资源都消耗完了,则需进行负载均衡:算法从其他核心的运行队列中迁移还有剩余资源的VCPU过来执行.为了使同一VM的各个VCPU能在同类核心上运行(调度原则(2)),在选择迁移的VCPU时,需考虑它所属VM包含的VCPU数目.因此,当与同类核心进行负载均衡时,Page7按照queue1→queue2→queue3的顺序选择VCPU;当与异类核心进行负载均衡时,按照queue3→queue2→queue1的顺序选择VCPU.当CV(Ci)还有剩余资源时,算法操作如下:若CV(Ci)正在运行并行程序,算法同步运行与其同属一个VM的VCPU;否则CV(Ci)单独运行.当|P(CV(Ci))|小于核心总数时,没参与协同调度的核心可分配给其它正在运行串行程序的VCPU,这避免了协同调度的碎片问题[11,13],提高了系统性能和效率.本文使用文献[12]提供的方法判断VCPU上运行的程序类型,该方法是一种基于灰盒知识的推理技术,此处不再赘述.算法伪代码描述如下.算法4.VCPU选择和负载均衡.for(每一个核心Ci){if(SR(CV(Ci))0){//当前运行的VCPU已消耗}else{//当前运行的VCPU还未消耗完资源}}算法5.VCPU执行.输入:核心Ciif(CV(Ci)在运行并行程序){VCPUs=与CV(Ci)同属一个VM的VCPU集合;cores=VCPUs所在的核心集合;}else{CV(Ci)继续在Ci上执行;}3.5算法运行开销相对于Xen的Credit调度器[20],集成调度算法的开销主要来源于2个方面:(1)初始映射.设m表示VM总数,n表示核心总数,初始映射的时间复杂度为O(mnlgn).初始映射的时间复杂度来源于2方面:①for循环,执行m次,时间复杂度为O(m);②选取NV个负载最轻的核心,对核心根据负载做堆排序,时间复杂度为O(nlgn).因为核心选取(①方面)嵌套在for循环(②方面)中执行,初始映射模块总的时间复杂度为O(m)×O(nlgn)=O(mnlgn).由于初始映射只在VM启动/关闭时执行,开销并不大.(2)协同调度.协同调度将带来额外的上下文切换.不过算法只协同调度运行并行程序的VCPU,并且采用了协同调度和独立调度相结合的方法,将没参加协同调度的核心分配给其他正在运行串行程序的VCPU,这避免了碎片问题[11,13].另外,如同Credit调度器,集成调度算法在一个核心没有可运行的资源时才执行VCPU迁移,迁移次数不多于Credit;并且算法通过运行队列分解提高了VCPU的选择效率,因此在VCPU迁移方面并没有额外的开销.综上所述,集成调度算法开销不大,这将在4.2.3节的实验中得到进一步验证.4实验与分析4.1实验平台与方法本节将集成调度算法(下文简称IA)与AASH[20]、Xen自带的调度器[20](下文简称Credit)进行比较.本文采用Xen4.0.1实现和运行上述算法,客户机操作系统为Linux2.6.27内核的Ubuntu8.10.测试程序包括并行程序和串行程序,其中并行程序选自PARSEC[28],串行程序选自SPECCPU2006,如表2所示.实验平台是一台8GB内存的2路AMDOpteron2384服务器.AMDOpteron2384是对称多核处理器,包含4个2.7GHz的核心.本文用Page8DVFS将其中6个核心的频率调整为1.5GHz,另外2个核心的频率保持在2.7GHz,以实现2个快核心+6个慢核心的非对称性结构.fulidanimate、facesim、并行测试程序blackscholes、swaptions实验中我们保证每个VM的VCPU数目等于该VM运行的测试程序线程数,以避免客户机操作系统的调度器可能带来的噪声.对于并行测试程序,我们通过配置程序的线程数来达到该效果;对于串行测试程序,我们通过同时运行程序来实现该效果.测试程序在每个调度算法下分别运行3次,取相应指标的平均值作为度量.当其中某个程序提前完成时,我们让其重新运行,以保持测试环境的稳定性.参考Xen的调度器设计,我们取调度周期cycle=30ms,单位时间slot=10ms.结合测试平台配置和经验,在4.2.1~4.2.3节中我们取式(6)中的μ=0.6,初始映射的Threshold=0.3;μ和Threshold取其他值时的算法表现详见4.2.4节.4.2实验结果与分析4.2.1性能分析由于测试平台包含2个快核心和6个慢核心,为了模拟多种同步特性和资源需求的VM共存的情况,我们为该实验配置了4个DomU(VM1~VM4),包含的VCPU数目如表3所示.为了更加全面地比较各个算法的性能,我们设计了多种组合的并行程序和串行程序组成的测试集,如表4所示,从左到右表示分别在VM1~VM4上运行.为了便于比较实验结果,我们以Credit的完成时间为基准对数据进行归一化处理,Credit的完成时间为1,小于1表示完成时间小于Credit,否则反之.DomainVM1VM2VM3VM4#VCPU2268测试集W1W2W3W4(perlbench、xalancmk、bwaves、swaptions)程序完成时间如图5所示,包括每个程序的相对完成时间以及每个测试集的平均相对完成时间(geo-mean).在各个测试集的平均完成时间上,IA比Credit短23%~28%,也比AASH短23%~25%.特别是对于并行程序,IA的优势尤其明显,相对于Credit和AASH的提高有37%~48%;对于串行程序,IA也有至少19%的提高.IA的性能优势来源于它保证了3个调度原则,在调度时考虑了核心的非对称性,并根据程序的同步特性和AMP的负载情况将VCPU映射到合适的核心上.在实验中我们还发现:对于并行程序(如facesim和swaptions),AASH的性能与Credit接近;对于存储密集型程序(如mcf和soplex),AASH的性能还不如Credit.这是因为AASH在调度时主要关注利用快核心公平地加速每个VCPU,并优先将快核心分配给VCPU数目小于快核心数目的VM,这带来了额外的VCPU迁移,对于运行存储密集型程序的VCPU,迁移将遭受cache的冷启动效应,降低了性能.并且AASH独立调度每个VCPU,没有考虑其运行并行程序时的同步问题,这将带来LHP(LockHolderPreemption)和LCB(LockCompetitorsBlocking)问题[12,14],增加并行程序的运行时间.4.2.2公平性分析该实验包括5个权重相等的DomU(VM1~VM5),每个VM包含2个VCPU.测试程序包括并行程序(blackscholes、fulidanimate、facesim)和串行程序(libquantum、calculix、namd).在每次实验中,我们在5个VM上运行一样的测试程序,为了便于比较实验结果,我们定义了比例完成时间(ScaledCompletionTime,SCT):设ti表示一次实验中第i个VM的实际完成时间,则这次实验中该VM的比例完成时间SCTi定义如下:Page9我们在每次实验中比较IA,AASH和Credit上各VM的SCT的标准差,由于5个VM的权重和VCPU数目都相等,且运行一样的测试程序,SCT的标准差越小,说明算法越公平.程序SCT的标准差如图6所示:IA下标准差不超过0.02,比AASH和Credit稳定.这是因为IA通过比例系数和比例资源,在资源分配和消耗时对核心非对称性进行处理,使资源的消耗速度和核心频率成正比,保证了调度的公平性.实验结果表明Credit下程序完成时间波动最大,这是因为它完全没有考虑核心的性能差异.而AASH在运行串行程序时公平性与IA接近,在运行并行程序时公平性差于IA.这是因为AASH将每个VCPU当成独立的调度实体,从而部分VM出现LHP和LCB问题[12,14],使完成时间出现波动.4.2.3开销分析该实验的虚拟机配置、测试集和实验结果处理方法与4.2.1节相同,不同的是该实验运行在未经DVFS调整的服务器上,即8个核心都是2.7GHz.我们使AASH假设仍在2个快核心+6个慢核心的服务器上运行,同时使IA中每个核心的SF=1.以此来分析IA和AASH带来的额外开销.实验结果如图7所示,超过1表示算法的开销.IA的开销很小,对于串行程序,初始映射只在VM启动/关闭时执行,开销不超过2%;对于并行程序,协同调度带来的收益大于其开销,因此即使在对称多核处理器上,IA的性能仍有17%~20%的提高.AASH的开销主要来源于公平共享快核心造成的VCPU迁移,因此对于计算密集型程序开销较小,而对于存储密集型程序(如mcf和soplex)开销较大,达到18%~20%.这验证了3.5节的算法开销分析,也进一步解释了各算法在4.2.1节中的性能表现.4.2.4参数灵敏度分析该实验分析(μ,Threshold)的不同取值对算法性能和公平性的影响.在实验平台、虚拟机配置和测试集选取上,性能的参数灵敏度实验同4.2.1节,结果如图8所示,由于各个测试集表现相近的趋势,限于篇幅我们只给出W1在不同参数取值下的表现;公平性的参数灵敏度实验方法同4.2.2节,图9为测试程序在不同参数取值下实际完成时间的标准差比较.当(μ,Threshold)=(0.6,0.3)时,IA取得最优性能.不同机器配置的核心性能差异、迁移开销等都不同,而在本文采用的实验平台上,(0.6,0.3)正好平衡了VCPU资源需求、核心非对称性和核心负载.(μ,Threshold)取值主要影响VCPU的初始映射,当取值无法很好地平衡各个因素时,将在后续的虚拟处理器选择时带来额外的VCPU迁移,从而影响性能.另外,如图所示,在(μ,Threshold)的不同取Page10值下,IA的性能差异并不是特别大,这是因为即使初始映射无法平衡各个因素,后续的虚拟处理器选择也会通过动态迁移VCPU予以补偿,这也说明了算法的有效性.(μ,Threshold)取值对算法公平性没有影响,这是因为公平性由资源分配和资源消耗这两个模块决定.不管VCPU初始映射到哪个核心上,资源分配和资源消耗模块都可以保证它得到与其权重相对应的CPU资源.定量分析机器配置和参数取值之间的关系是我们下一步研究的内容.4.3实验小结基于以上实验,我们可以得出以下结论:(1)性能.相对于其他调度算法,集成调度算法具有明显优势,能把测试集平均完成时间缩短23%~28%;对于并行程序,该优势更加明显,完成时间缩短可达到48%;对于串行程序,集成调度算法也有至少19%的提高.(2)公平性.不管是执行并行程序还是串行程序,集成调度算法比Credit和AASH公平.(3)开销.集成调度算法的初始映射开销不超过任务完成时间的2%,这给系统造成的负担很小,是可以接受的.而协同调度的开销远小于其收益.5相关研究AMP将成为未来的主流体系结构[5-9],但出于设计制造成本等方面的考虑,真正的AMP还没有上市.因此,对于VCPU调度问题,之前的研究主要集中在SMP上.业界知名的VMM对该问题有不同的解决方案:VMware协同调度属于同一VM的所有VCPU,Xen和KVM则独立调度所有VCPU.文献[10,12]对SMP上的VCPU调度问题进行建模分析,证明了当一个VM正在运行并行程序时,协同调度它所有的VCPU可以提高性能,协同调度和独立调度有不同的适用场景;并给出了一个面向SMP的VCPU调度算法:协同调度运行并行程序的VCPU,独立调度运行串行程序的VCPU.在文献[10]的方法中,VM上运行的程序类型由管理员手动设定;文献[12]则采用一种基于灰盒知识的推理技术来自动判断程序类型.文献[11]通过实验说明同一VM的VCPU之间的同步有可能是因为运行并行程序,也有可能是因为多个串行程序访问共享资源,并提出一个面向SMP的平衡调度算法:只将属于同一VM的VCPU放在不同核心上,但不强制它们同时执行.该算法是协同调度和独立调度的折中版本.VCPU在SMP上每个核心的执行效率是一样的,但在AMP不同类型核心上的执行效率却是不同的,将SMP上的VCPU调度算法照搬到AMP上的话,对系统的公平性和性能都会有影响(如2.1节示例).而本文提出的集成调度算法定义了效用因子、比例系数、比例资源的概念,针对AMP的非对称性做了处理,保证了调度的公平性和性能.本文讨论的AMP上的VCPU调度问题,近年来有少数研究工作.文献[21]以降低能耗为目标,认为Dom0对核心性能不敏感,因此可以放在慢核心上执行,从而使DomU可以优先使用快核心.但是该方法无法保证公平性和性能.跟本文讨论问题比较相关的是文献[20],其提出的AASH调度器也是以性能和公平性为目标,具有3个特性:①所有VCPU公平共享快核心;②支持面向AMP的操作系统;③支持设定VM使用快核心的优先级.但集成调度算法与AASH存在以下不同:(1)AASH无法兼顾特性①和特性③[20];集成调度算法则兼顾了公平性和3个调度原则.(2)AASH需要在快慢核心间频繁迁移VCPU,增加了调度开销;集成调度算法则通过运行队列分解对调度开销进行有效控制.(3)AASH假设VM的权重与其包含的VCPU数目成正比,但现实中这一假设往往不成立;集成调度算法没对VM的权重做任何假设,可全面支持Xen的权重设置.另外,文献[20-21]都没有考虑VCPU的同步特性,也没有对AMP上的VCPU调度问题进行理论分析;本文建立的非线性规划模型则分析了VCPU的同步特性和核心的非对称性.6总结与展望高效的VCPU调度算法是提高虚拟化系统性能的关键.本文对AMP上的VCPU调度问题进行研究,建立了非线性规划模型,分析得出了3个调度原则,并基于调度原则提出了集成调度算法.据我们所知,本文是第一个对该问题进行建模分析的研究,提出的算法是第一个利用AMP上的VCPU同步特性的调度算法.实际平台上全面的对比实验表明:集成调度算法的性能、公平性和开销都优于其他AMP上的调度算法.集成调度算法的性能优势来Page11源于它保证了3个调度原则,在VCPU调度时全面考虑核心的性能、负载情况以及VCPU的同步特性,这也验证了调度原则的有效性;公平性优势来源于本文提出的概念———效用因子、比例系数、比例资源,它们使核心的负载、资源的消耗速度与核心性能成正比;开销优势主要来源于运行队列分解,它有效提高了VCPU选择效率.本文提出的调度算法以性能和公平性为目标,如何通过VCPU调度降低系统能耗,将是我们下一步的研究工作.
