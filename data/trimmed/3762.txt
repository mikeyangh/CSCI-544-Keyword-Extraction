Page1基于体积语义局部二值模式的行为识别吴娴1),2)赖剑煌1)1)(中山大学信息科学与技术学院广州510006)2)(南方报业传媒集团博士后科研工作站广州510601)摘要基于视觉的行为识别是人体运动分析的重要组成,也是该领域一个富有挑战性的研究方向,因此获得广泛的关注.该文将视频中的人体行为看成由每帧轮廓图像沿时间轴堆叠而成的三维空-时体积,提出一种新颖的局部二值模式,即体积语义局部二值模式(VSLBP),用于提取空-时体积中的有效低维特征,通过计算测试序列与已标记的行为训练集特征间的最近卡方距离得到其所属行为类别.在行为库“Weizmann”上实验结果表明,该文提出方法的识别准确率略高于现有最新方法,且能容忍各种复杂的条件,如遮挡、拍摄角度、行为者外观穿着及行为方式等.关键词行为识别;局部二值模式;语义局部二值模式;体积局部二值模式1引言目前,基于视觉的人体行为识别正在获得越来Page2一定的进展,并提出了一些解决问题的新思路.Efros等人[1]、Dollor等人[2]和Ke等人[3]直接在原始图像构成的空时体积上进行处理,避免了传统方法需要光流计算或特征跟踪等所带来的局限.但以上大部分工作都是基于空-时体积中的梯度或强度等计算特征,因此在视频质量不佳或运动不连续等情况下,这类特征显得不够可靠.Gorelick等人[4]、Wang等人[5]、Weinland等人[6]及Ikizler等人[7]则从人体轮廓出发,对人的行为进行分析.在摄像机静止条件下人体轮廓较易获得,且被认为包含空间足够多的姿势及表观等信息,将人体轮廓按时间顺序接连的表示形式则同时包含了空间表观及时间运动信息,分析并度量它们之间的相似性即可对人的行为进行识别.局部二值模式算子(LocalBinaryPatterns,LBP)是一种有效的纹理描述算子,近十年已广泛应用于纹理分类、图像检索及人脸分析等等.最初的LBP算子是一个固定大小为3×3的矩形块,将周围8个灰度值与中心灰度值比较,大于或等于中心灰度值的点用1表示,反之为0,顺时针方向得到的8个二进制值作为该矩形块的特征值.最后以直方图形式统计出整个区域每个特征值数量,作为此区域的特征描述.为了改善最初LBP算子无法提取大结构纹理特征的局限问题,Ojala等人[8]对其进行了扩展,允许不同数量的邻域点P及不同尺寸的半径R即表示成LBPP,R.而当邻域点P及半径R很大时,提取出的特征大部分对纹理的描述作用很有限,因此Ojala等人[8]又提出了LBP算子的另两种扩展形式,称为“均匀模式”及“旋转不变模式”.二进制序列若至多有两个0与1之间的转换则被定义为均匀的;而通过循环移位得到的最小二进制序列被定义为旋转不变的.这两种模式能够有效地描述出图像中大部分的纹理特征,并大大减小特征的数量.值得注意的是,以上LBP特征都由二进制序列的十进制编码得到,这样可能使得语义上相似的特征经十进制编码后大相径庭,而且空间复杂度高,因此Mu等人[9]从几何的角度重新定义LBP,提出了语义局部二值模式(SemanticLBP,SLBP).另一方面,由于LBP出色的描述特征能力,Heikkila等人[10]用基于LBP的纹理方法建立背景模型从而检测运动目标.Zhao等人[11]将其扩展到三维形式,提出体积局部二值模式(VolumeLBP,VLBP),并发展了基于3个正交平面的局部二值模式(LBPfromThreeOrthogonalPlanes,LBP-TOP),将其用于同时包含表观及运动信息的三维体积,如面部表情、动态纹理中.本文由Zhao等人[11]的工作得到启发,将人体行为看成由每帧轮廓图像沿时间轴堆叠而成的三维空-时体积,VLBP即可用于提取其低维特征.VLBP是LBP的空时扩展形式,其特征向量长度随邻域点个数增大而快速增长.为了压缩特征向量的长度,本文采用语义局部二值模式的思想,提出体积语义局部二值模式(VolumeSemanticLBP,VSLBP),并将其用于提取空-时体积的特征.此方法的最大优点是可直接从空-时体积中提取特征,无需降维,且特征长度仅与邻域点个数P有关,而与视频帧数无关,不需要时间对齐,因此可排除行为之间持续时间不同所造成的影响.本文第2节介绍体积局部二值模式(VLBP);第3节简述语义局部二值模式(SLBP);第4节提出体积语义局部二值模式(VSLBP);第5节描述基于VSLBP的行为识别过程;第6节给出本文提出方法在“Weizmann”库中的实验结果,并进行横向与纵向的比较与分析;第7节是对全文的总结.2体积局部二值模式(VLBP)对体积V建模[11],螺旋状展开,其相关符号定义及坐标计算公式列于表1中,用公式则可表示成:V=v(gtc-L,c,gtc-L,0,…,gtc-L,P-1,gtc,c,gtc,0,…,gt,p(t=tc-L,tc,tc+L,p=0,…,P-1)图像t半径为R区域上的假设(gt,p-gtc,c)独立于gtc,c,忽略中心点v(gtc,c)灰度值.对V阈值化处理,则式(1)可近似写成V1:V1=v(s(gtc-L,c-gtc,c),s(gtc-L,0-gtc,c),…,Page3s(gtc,P-1-gtc,c),s(gtc+L,0-gtc,c),…,s(gtc+L,P-1-gtc,c),s(gtc+L,c-gtc,c))(2)s(x)=1,x0由V1可看出其为3P+2维表示,则V1的十进制编码可简化描述成:图1表示VLBPR,P,L(R=1,P=4,L=1)建模及形成过程,对体积中逐帧采样邻域点,将其与中间帧的中心点灰度值大小进行比较并二值化,最后乘以权重因子构成体积局部二值模式.3语义局部二值模式(SLBP)语义局部二值模式(SLBP)最近由Mu等人[9]提出,它从几何的角度解释并重新定义LBP.基本LBP算子是通过对二进制序列进行十进制编码进而统计直方图特征,这么做,无法保证语义相似的特征能落入直方图的邻近的区域.例如,(00001111)2逆时针左移一个比特构成(10000111)2,它们之间具有很高的相似性,但经十进制编码后却相差甚远(15vs.135).语义局部二值模式则在均匀LBP算子的基础上,将二进制序列顺时针表示成几何意义上的圆弧,用弧长和主轴角度两个特性代替基本LBP算子的十进制编码数.如图2,两个二进制序列弧长一致,主轴角度相差45°,符合语义相似的特性.值得注意的是,均匀LBP算子至多有两个0与1之间的转换,则它所对应的只可能是一段圆弧(若序列中只含单个“1”,则可视为圆弧上的一个点).图2均匀局部二值模式的弧状表示(弧长及主轴角度)4体积语义局部二值模式(VSLBP)由本文第2节可知,VLBP特征向量长度由邻域点个数P决定,P值大则特征向量长度较大,而小的P值则可能丢失有用信息.VLBP的可能模式个数为23P+2,当P值增大时,VLBP所提取的特征长度呈指数级增长.另外,VLBP也是对二进制序列的十进制编码,这就不能保证语义相似的特征经编码后所得十进制数仍十分近似.本节将VLBP的概念从灰度图扩展至二值图,为从人体轮廓出发而进行的行为识别过程作铺垫,并结合SLBP,提出了体积语义局部二值模式(VSLBP)的思想,保留语义信息并大大地减小特征量.本文建模的体积是由二值轮廓按时序堆叠构成.因此,我们对第2节VLBP中的灰度图扩展至二值图,以图3的方式对体积建模.首先类似地,对体积中逐帧(L=1情形)采样邻域点,不同的是,我们将其与中间帧的中心点的值进行异或比较,如果相同则标记为0,反之为1,这么做是为了记录局部空间及时间上像素之间的变化.将体积中如上操作所得的二进制序列组成集合,丢弃其中的全零序列(表示无变化),且表示成均匀模式(见第3节解释,即舍弃圆弧个数大于1的二进制序列),用弧长及主轴角度两个特性代替VLBP的十进制编码数,如Page4图4.若主轴角度落入两邻域点之间,取靠近其的最小主轴角度(如图4(b)虚线所示),而圆弧长度的不同则可以区分不同的二进制序列.图4均匀体积局部二值模式的弧状表示(弧长及主轴角度)这样弧长和主轴角度的可能值均为(3P+2)个,可用(3P+2)×(3P+2)大小的矩阵统计弧长及主轴角度,在相应的弧长及主轴角度上累加计数,如图5,这也近似于“直方图统计”思想.最后将二维矩阵中行向量接连成单一向量,表示体积的LBP特征,即本文提出的体积语义局部二值模式表示.图5VSLBP的统计矩阵(横轴圆弧角度,纵轴圆弧长度)由以上的分析得出,VLBP的可能模式个数为23P+2;Zhao等人[11]提出的3个正交平面的局部二值模式(LBP-TOP),即在XY、XT及YT平面采用均匀LBP算子,可能的模式个数为3×P(P+1);VSLBP的向量长度为(3P+2)2.图6给出了其特征向量长度的对比情况,VSLBP比VLBP大大压缩了特征向量的长度,但当邻域点个数P增大时,其特征向量长度增幅大于LBP-TOP.但其后从理论及实验上分析,LBP-TOP用于基于人体轮廓的行为识别,性能不如VSLBP.与LBP-TOP及VLBP相比,VSLBP旨在“简便性”及“有效性”间寻求折衷.图6特征向量长度与邻域点个数的对应关系5基于VSLBP的行为识别本文从视频帧的原始图像中提取人体轮廓,排除了杂乱背景的干扰,同时也避免了行为者表观及穿着不同等所带来的混淆信息.对轮廓序列进行空间对齐并检测其周期,然后将一个周期内的轮廓接连成体积(Volume)作为输入(如图7左边所示).Zhao等人[11]提出LBP-TOP,如图8,在体积中心点的XY、XT及YT这3个正交平面上各作局部二值模式表示,并将其串接起来的直方图序列作为体积的特征,已成功用于动态纹理与面部表情识别中.通常动态纹理与面部表情不仅在XY平面有空间信息,且XT、YT平面也包含丰富的运动信息,因此LBP-TOP显得可行并且有效.但人体轮廓序列在XT、YT运动信息十分不明显(如图9),若仅在体积中心点的3个正交平面上提取LBP特征,将丢失其余帧的大量细节信息,导致识别准确率不高.图83个正交平面局部二值模式表示(LBP-TOP)图9轮廓行为序列“jump、pjump”和“run”及其在Page5本文从另一方面考虑,提出VSLBP的表示方法,并描述了基于VSLBP的行为识别的具体过程.首先将人体轮廓序列构成的体积分成若干个互不重叠的块体积(BlockVolume),如图7,对每个块体积提取VSLBP特征向量,按照其空间结构顺序接连成单一向量表示人体轮廓行为序列的总特征.获取所有轮廓行为序列总特征后,采用留一法(Leave-One-Group-Out)进行测试,即如果数据库中有p个人q种不同行为,假设某个人的行为未知,将其作为测试行为,而其余(p-1)个人q种已知行为作为训练集,通过计算测试序列特征犜与已知行为训练集特征犕间的最近卡方距离,即以最小χ2测度,得到此测试行为所属行为类别.其中,n代表行为序列总特征的向量长度,足够小的值ε是为了防止Ti=Mi=0时的溢出错误.图10“Weizmann”库中10种行为6.2预处理数据库中的行为一般具有周期性.本文采用Culter等人[12]提出的方法检测行为的周期性,然后将一个周期内的帧接连成体积.首先计算t1和t2时刻目标Ot的自相似性:St1,t2=mindx,dyr∑(x,y)∈Bt1式中,Bt1是Ot1所占边框大小,经空间对齐后,Bt1恒定.较小的半径r是为了容许分割误差.由图11(a)看出,周期性行为的犛t1,t2亦呈现周期性.取犛t1,t2的列向量(即固定t1取所有t2)进行高斯平滑滤波得图11(b),其中的波谷间的时间帧长度即为行为序列的周期长度.虽然每种行为的持续时间不同(一个行为周期内的视频帧数不同),但由于VSLBP的特征向量长度仅与邻域点个数P有关,而与帧的长度无关,所以不需要时间对齐或标准化,因此排除了行为之间持续时间不同或是同一行为不同行为者完成时间不同所带来的影响.6仿真试验6.1测试数据库为了分析本文提出方法的性能,在公测行为库“Weizmann”库上对其进行了测试.“Weizmann”库包含90个视频序列,由9个人完成10种行为,如图10,依次是:弯腰(bend)、蹦高挥手(jack)、双腿向前蹦(jump)、原地蹦(pjump)、跑(run)、侧边走(side)、跳(skip)、走(walk)、挥单手(wave1)及挥双手(wave2).此数据库中的行为具有高度相似性,且行为者穿着、外貌及行为方式都不尽相同,比较接近于实际情形.由于数据库中背景已知,采用背景剪除法提取所有人体行为轮廓,对其进行空间对齐并统一大小为60×80,预处理后构成体积,分块后逐帧(L=1)在半径R=1区域中采样邻域点,再进行基于VSLBP的行为识别.6.3实验结果及比较本实验中需要定义的参数是体积分块大小(按空间大小比例34分块)及邻域点的个数P.表2给出了固定邻域点个数,平均识别率与分块大小的对应关系;图12分别给出分块大小固定为12×16时,所有行为平均识别率及单个行为识别率对应于邻域点个数的关系.从简便及识别率考虑,取体积分块为12×16(即分为25个互不重叠的块),邻域点个数为6.实验结果由混淆矩阵(confusionmatrix)表示.其每行的各个元素代表此类型的行为被分类为其它行为的概率,则混淆矩阵的对角元素值(表示正确分类的概率)被期望越高越好.Page6分块大小平均识别率分块大小平均识别率3×474.4415×2088.896×886.6730×4077.7812×1695.5660×8056.67图12识别率与邻域点个数对应关系图13行为识别结果纵向比较图14行为识别结果横向比较图13给出VLBP、LBP-TOP及VSLBP用于行为识别的纵向对比性实验结果.相同的实验参数及设置条件下,VSLBP的识别正确率最高,虽然VLBP也能正确识别大部分行为,但其所提取的特征向量长度为23P+2,远远大于VSLBP的(3P+2)2,Page7在本实验中即25×22025×202.而由于人体轮廓行为序列中XT和YT平面所包含的时间运动信息不明显,则LBP-TOP的识别效果不尽如人意.图14横向比较了本文提出的方法与一些最新方法[6-7,13-15]在Weizmann库上的实验结果.Niebles等人[13]、Scovanner等人[14]在原始视频序列上计算时空兴趣点的像素强度或梯度等特征,在Weizmann库上它的识别率普遍低于基于轮廓特征的方法[6-7,15].基于轮廓特征的方法通常假设前景已完全分割(如Weizmann库给出的开源数据),将行为识别的重点转向特征的描述及识别算法的研究.本文将VSLBP描绘子与基于轮廓特征的其它最新方法[6-7,15]进行比较.Jia等人[15]在嵌入的低维流形中学习并分类行为,它包含一个降维的过程.Weinzland等人[6]通过提取若干静态关键姿势,进而把每个行为序列看成一系列关键姿势的表达,图14(e)列出50个关键姿势情形下的识别率.这种表达虽然简便,但由于丢失时间信息,它不能区分“顺”和“倒”动作,如“起立”和“坐下”,同时它对行为的持续时间比较敏感.Ikizler等人[7]将姿势分块表达并表示为方向矩形的直方图(HoR),在姿势表达的基础上加入图15不同拍摄角度下的鲁棒性测试视频(图中从左向右,拍摄角度依次为0°,9°,18°,27°,36°,45°,54°,63°,72°,81°)图16鲁棒性测试视频(从左到右自上而下依次是对角线直走(diagonalwalk),牵着狗行走(walkwitha时间上的速度特征,利用分层的模型进行识别.图14(f)给出应用最近邻分类器的识别率.但相对于VSLBP,HoR需要调整更多的参数,执行时间较长.从图14可以看出,以上3种方法在双腿向前蹦(jump)和跳(skip)、跑(run)和跳(skip)、挥单手(wave1)和挥双手(wave2)等行为之间均有高度的混淆性.由于轮廓提取及对齐等预处理方法等不完全相同,它们之间的精确对比较为困难.但本文提出的方法实现相对简单,且具有较高的识别率.它不需要降维,可以直接提取低维特征,同时对测试行为的持续时间长度等不敏感.另外,“Weizmann”库中的20个行为类别均为“走”的测试视频,包括10个不同拍摄角度(0°~81°,每隔9°,如图15)和10个行为方式迥异的视频(如图16),构成鲁棒性测试库,以测试本文提出方法对拍摄角度、空间遮挡及行为方式等影响因素的稳健性.每一个测试的“走”行为序列均与数据库中的所有行为序列匹配,找到最佳匹配的行为类型;若最佳匹配行为不是“走”,则寻找次佳匹配行为类型.表3及表4显示了鲁棒性测试结果,可以看出,本文提出的方法能够容忍拍摄角度的小幅度变化(0°~36°)和行为方式的某些不规则性.Page8Viewpoint091827364554637281表4鲁棒性测试结果(行为方式不规则性测试)DiagonalwalkWalkwithdogSwingingabagWalkinaskirtOccludedlegsSleepwalkLimpwalkWalkwithkneesupjackCarryingabriefcasewalkNormalwalk7结论本文提出体积语义局部二值模式(VSLBP)的表示,并描述了基于VSLBP的行为识别方法.此方法从一个全新的角度对行为识别问题进行探索,将刻画图像局部特征的有效算子发展为三维形式并应用于视频数据,它无需降维,能够从空-时体积直接提取有效低维特征.实验结果表明,本文提出的方法不仅能够处理持续时间不同的行为序列,而且对拍摄角度的变化、遮挡及行为方式的不规则性具有较高的鲁棒性.本文今后的研究工作将对VSLBP方法加入更为丰富的理论分析,以提取更具有判别性的有效特征,并应用于更自然的行为序列及更复杂的场景中.
