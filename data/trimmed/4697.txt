Page1基于高斯Copula的约束贝叶斯网络分类器研究高瑞1)1)(上海立信会计学院数学与信息学院上海201620)2)(上海立信会计学院立信会计研究院上海201620)摘要具有连续属性的分类问题普遍存在,目前主要采用两种方法来处理连续属性:一种是将连续属性进行离散化;另一种是基于高斯函数或高斯核函数来估计属性密度.连续属性的离散化可能导致信息丢失、引入噪声和类对属性的变化不够敏感等问题,而高斯函数和高斯核函数在属性密度估计中各有优势与不足,但它们具有很强的互补性.该文依据Copula和贝叶斯网络理论,结合高斯Copula密度函数、引入平滑参数的高斯核函数和以分类准确性为标准的属性父结点贪婪选择,建立连续属性约束贝叶斯网络分类器,既可以避免连续属性离散化所带来的问题,又能够实现高斯函数和高斯核函数在属性密度估计方面的优势互补.分别采用真实数据和模拟数据进行实验,结果显示,使用结合边缘高斯核函数的高斯Copula估计属性密度的约束贝叶斯网络分类器具有良好的分类准确性.关键词贝叶斯网络分类器;连续属性;高斯Copula;高斯核函数;平滑参数;机器学习1引言贝叶斯网络(BayesianNetwork)[1]是描述随机变量之间依赖关系的图模型,是概率理论与图形理论的结合,也是传统的基于数据的统计方法和强调知识的人工智能方法的统一.贝叶斯网络所解决的基本问题是通过分解来降低联合概率(或密度)的运算复杂性并提高可靠性,因此是研究具有离散和连续属性贝叶斯衍生分类器(贝叶斯分类器的衍生分类器)[2]的有力工具.关于离散属性的贝叶斯衍生分类器(包括将连续属性离散化的情况)已有较多的研究.本文研究不进行离散化的连续属性贝叶斯衍生分类器,其核心是属性密度估计.John和Langley分别基于高斯函数和高斯核函数估计属性密度建立了两种最简单的贝叶斯衍生分类器,即朴素贝叶斯分类器(NaveBayesianClassifier,NBC),他们的研究奠定了采用密度估计方法研究连续属性贝叶斯衍生分类器的基础.Pérez等人[3-4]在John和Langley工作的基础上,依据高斯网络、贝叶斯网络和统计核函数理论,分别使用结合连续属性条件互信息计算、排序与边选择的filter方法和基于余一交叉有效性验证估计分类准确率和贪婪搜索的wrapper方法,对NBC进行树结构依赖扩展、k依赖扩展(限定父结点数量的网络依赖扩展)和完全依赖扩展(直接估计属性联合密度,不考虑属性之间的条件独立性),使分类器的分类准确性得到改进,有力地推动了连续属性贝叶斯衍生分类器的发展.王双成等人[5]和Wang等人[6]使用多元高斯核函数建立连续属性完全贝叶斯分类器,使分类器能够充分拟合数据,具有良好的分类准确性.高斯函数与高斯核函数在属性密度估计方面各有优势和不足.使用高斯核函数能够估计复杂的属性密度,但抗噪声能力相对较弱,而且易于导致对数据的过度拟合.高斯函数抗噪声能力强,但可能出现对数据的欠拟合.可见,高斯函数和高斯核函数具有很强的互补性.我们通过Copula进行高斯函数与高斯核函数的整合,来实现它们之间的优势互补.自从Nelsen[7]给出Copula函数的存在性定理(Copula理论中的最重要定理),标志着Copula基础理论体系的确立.依据Copula理论,我们可以将一个联合分布函数分解为Copula函数和边缘分布函数的乘积两部分,也就是Copula函数能够建立联合分布与边缘分布之间的联系,为此张尧庭教授将Copula函数称为连接函数[8].Copula函数所描述的是变量之间的依赖关系,这使得Copula函数在许多领域得到了广泛的应用.Copula函数也同样适用于分类器中的属性之间依赖信息的提取.在将Copula用于贝叶斯网络和分类器的研究方面,Marta等人[9]、Mostafa等人[10]和Bansal等人[11]结合边缘高斯和高斯Copula估计属性密度,研究连续属性贝叶斯分类器,但并没有对高斯Copula密度函数进行分解,使分类器具有较高的运算复杂度.Elidan等人[12-13]在给出Copula的分解与组合定理的基础上,研究了基于Copula建立连续变量因果贝叶斯网络(CopulaBayesianNetwork,CBN)和贝叶斯网络分类器的可行性,但采用的打分函数非常复杂,而且倾向于发现连续变量之间的因果关系(对于连续属性分类器,则是属性与属性之间的因果关系),不是属性与类之间映射规则的优化,因此,不适合于建立连续属性贝叶斯网络分类器.本文的主要贡献如下:(1)针对基于高斯函数和高斯核函数估计属性密度存在的优势和不足,使用Copula进行高斯函数和高斯核函数的整合,从而实现了它们在属性密度估计方面的优势互补(将属性联合密度分解为以协方差矩阵为核心的高斯Copula密度函数(强调整体特征)和边缘高斯核密度函数(强调局部特征)的乘积两部分,从而实现高斯函数与高斯核函数的整合以及整体和局部的统一,并通过高斯Copula密度函数和边缘高斯核密度函数的相互作用,弥补各自的不足,详见实验部分).(2)在Copula和贝叶斯网络理论的基础上,给出了基于高斯Copula的属性联合密度分解计算和条件密度估计的方法,能够有效降低高斯Copula密度函数的运算复杂性并提高可靠性.Page3(3)将高斯Copula密度函数、引入平滑参数的高斯核函数和以分类准确率为标准的贪婪属性父结点选择相结合,建立了一种新的Copula网络分类器-具有边缘高斯核密度的Copula约束贝叶斯网络分类器(CopulaRestrictedBayesiannetworkclassifierwithmarginalGaussianKerneldensity,CRBK),CRBK能够避免使用Elidan方法建立的贝叶斯网络分类器和Copula完全贝叶斯分类器所存在的问题.我们也分别采用真实数据(包括UCI①数据)和模拟数据对分类器学习方法的有效性和分类器的可靠性进行了验证.本文第1节对具有连续属性的贝叶斯衍生分类器和Copula的发展情况进行回顾与分析;第2节给出用于连续属性约束贝叶斯网络分类器研究的Copula理论与方法;第3节给出基于高斯Copula的属性联合密度分解计算、属性条件密度估计和CRBK结构学习方法;第4节是实验与分析;第5节是结论和进一步的工作.2Copula函数用X1,…,Xn,C表示连续属性和类,x1,…,xn,c为其值,犡=(X1,…,Xn),狓=(x1,…,xn).D是具有N个记录的数据集,数据随机产生于混合分布P,xim(1in,1mN)和cm表示Xi和C在数据集D中第m个记录的观测值.定义1.一个Copula是具有标准均匀分布随机变量的联合分布函数,也就是C(u1,…,un)=P(U1u1,…,Unun),其中Ui~U(0,1).Sklar在1959年给出了下面的关于Copula函数的存在性定理,为后来Copula函数的发展奠定了理论基础.定理1.设F(x1,…,xn)是犡的联合分布函数,F(xi)是关于Xi的边缘分布函数,那么存在一个Copula函数使得F(x1,…,xn)=C(F(x1),…,F(xn)).如果每个F(xi)都是连续的分布函数,则CopulaC唯一存在.根据定理1可以得到下面的推论1.推论1.设f(x1,…,xn)是犡的联合密度函数,f(xi)是Xi的边缘密度函数,那么f(x1,…,xn)=c(F(x1),…,F(xn))∏其中c(F(x1),…,F(xn))=是Copula密度函数.可以看出,联合密度函数能够分解成Copula密度函数和边缘密度的乘积两部分.设G是一个关于犡的有向无环图,πi={xi1,…,}是G中Xi的父结点集Πi={Xi1,…,XiKixiKi置.Elidan在2007年给出了下面的Copula密度函数的分解与组合定理.定理2.分解定理.设f(x1,…,xn)是犡的联合密度函数,而且对所有犡的配置都有f(x1,…,xn)>0.如果f(x1,…,xn)能够按照G进行分解,那么Copula密度函数c(F(x1),…,F(xn))也能依据G进行分解,即c(F(x1),…,F(xn))=∏i其中ci(F(xi),F(xi1),…,F(xiKi中Xi和它的父结点集Πi的局部Copula密度函数,而且ci(F(xi),F(xi1),…,F(xiKi定理3.组合定理.设ci(F(xi),F(xi1),…,F(xiKi严格正的局部Copula密度函数,如果当Πi给定时,Xi条件独立于Xi的非子孙结点,那么g(F(x1),…,F(xn))=∏i关于犡的有效Copula密度函数c(F(x1),…,F(xn)).定理1、2和3为研究连续属性CRBK奠定了理论基础,这3个定理的证明请看文献[7,12-13].3CRBK根据概率公式和贝叶斯网络理论,可得p(c|x1,…,xn)=其中α是与C无关的量,p(c)是类先验概率,f(xi|①MurphySL,AhaDW.UCIrepositoryofmachinelearningPage4πi,c,G)是属性条件密度.定义2.对有向无环图(贝叶斯网络结构)G,称使用进行分类的分类器为连续属性约束贝叶斯网络分类器.CRBK的结构(如图1所示)是一个类约束下的有向无环图(类是每一个属性的父结点),属性除类之外还可以有属性父结点(在NBC中,类是属性的唯一父结点,CRBK是NBC的网络依赖扩展,因此属性还可以有属性父结点,如X4除有类父结点C之外,还有属性父结点X1和X2).从式(5)中能够看出,CRBK是依据后验概率的顺序进行分类,而顺序关系比较稳定(抗干扰性较强),因此CRBK具有良好的抗噪声性.CRBK基于Copula和贝叶斯网络理论[1]分解属性联合密度,这也使分类计算具有更高的效率和可靠性.建立连续属性CRBK需要解决两个问题,一个是属性条件密度估计,另一个是分类器结构学习.3.1属性条件密度估计我们结合高斯Copula密度函数和高斯核函数来估计属性条件密度.分别用C(u1,…,un;Σ)和c(u1,…,un;Σ)表示具有协方差矩阵Σ的高斯Copula分布函数和密度函数,则C(u1,…,un;Σ)=Φn(Φ-1(u1),…,Φ-1(un);Σ),其中Φn(·)是标准n维高斯分布函数,Φ(·)是标准高斯分布函数,ui=Φ(zi),Φ-1(·)是Φ(·)的反函数.从而C(u1,…,un;Σ)=∫因此C(u1,…,un;Σ)=其中狋=(t1,…,tn),狕=(x1-x-的转置,x-根据推论1和式(7),可以得到f(x1,…,xn)=c(Φ(z1),…,Φ(zn))∏=|Σ|-1/2exp-分别用f^(xi,πi|c,D)、f^(πi|c,D)、f^(xi|πi,c,D)和f^(x1,…,xn|c,D)表示f(xi,πi|c)、f(πi|c)、f(xi|πi,c)和f(x1,…,xn|c)的估计,那么f^(xi,πi|c,D)=c^(F(xi),F(xi1),…,F(xiKi=|Σ^c(xi犐Ki+1)狕^c(xic(xi其中Σ^协方差矩阵估计,狕^c(xiXi,Xi1,…,XiKi矩阵,Copula密度函数(或分布函数)和类的标识依据上下文来区分.我们能够得到f^(πi|c,D)=c^(F(xi1),…,F(xiKi=|Σ^c(πiKi∏k=1f^(xik|c,D)其中Σ^差矩阵估计,狕c(πiXiKi的狕的估计,犐Ki我们采用引入平滑参数的高斯核函数来估计属性边缘密度,那么f^(xi|c,D)=其中N(c)是数据集D中C=c的情况数量,sign(cm)=Page51,cm=c烄烅0,cm≠烆结合式(8)~(11),最终可以得到f^(xi|πi,c,D)=(=c^(F(xi),F(xi1),…,F(xiKif^(xi|c,D)∏(c^(F(xi1),…,F(xiKi=f^(xi|c,D)1=N(c)∑exp-(exp-根据定理1、定理2、定理3和式(4)、(12),可得^p(c|D)f^(x1,…,xn|c,D)=^p(c|D)∏=N×(N(c))n-1∏g(xi;xim,h)exp-属性具有过多的父结点,一方面易于导致对数据的过度拟合,另一方面会降低学习与分类的效率,一般可限定属性除类之外的父结点不超过3个(或2个).这样通过属性联合密度的贝叶斯网络分解,CRBK的分类时间复杂度是O(n)(以最多3个父结点的情况为例,需要进行不超过2(n-1)次最多4阶的矩阵求逆和行列式运算),而不进行属性联合密度分解计算的时间复杂度是O(n3)(需要进行n阶矩阵求逆和行列式运算).属性联合密度的贝叶斯网络分解能够有效降低分类计算的时间复杂度,但需要确定分类器的结构,从而会降低分类器的学习效率,不合适的分解也可能导致信息丢失.3.2CRBK结构学习结合属性排序(根据Quinlan[14]的信息增益率排序属性,在信息增益率计算中的属性条件密度估计采用高斯核函数,并基于MISE(MeanIntegratedSquareError)设置平滑参数)、分类准确性标准(分类准确率估计使用10折交叉有效性验证方法[15])和贪婪属性父结点选择进行CRBK的结构学习.MISE的具体设置方法[4]为其中n和N分别是连续属性数量和数据集中的例子数量.分别用Πi和Ωi表示Xi的属性父结点集和子孙结点集,那么可以证明Xi新的属性父结点候选集为{X1,…,Xn}-Ωi∪Πi∪{Xi}.在属性父结点选择过程中,首先进行一阶父结点选择(为属性增加的第一个父结点),在一阶父结点选择的基础上进行二阶父结点选择(为属性增加的第二个父结点),在二阶父结点选择过程中也可能新增一阶父结点,在二阶父结点选择的基础上进行三阶父结点选择(为属性增加的第三个父结点),在三阶父结点选择过程中也可能新增一阶和二阶父结点.我们通过实验发现具有三阶父结点的属性非常少,而且三阶父结点对分类的贡献也很小,因此只进行到三阶父结点选择.具体的属性父结点选择如算法1所示.用accuracy_nbc(h,D,S)表示NBC的分类准确率,accuracy_bnc_f(j|D,Gj),j=1,2,3和accuracy_bnc_b(j|D,Gj)分别表示进行第j阶依赖扩展过程中父结点变化前和变化后的分类准确率,其中h是使用MISE方法设置的平滑参数,S是NBC的结构,Gj是对应的CRBK结构.Π(3)i分别表示Xi的一阶、二阶和三阶属性父结点集,ΠΓi是属性Xi的父结点候选集.算法1.属性父结点选择算法.输入:D、h和accuracy_nbc(h,D,S)输出:accuracy_bnc_b(j|D,Gj)(j=1,2,3)、Gj和G设置ΠXi+1,…,Xn}FORj=1,2,3IFj=1ELSEFORi=1,2,…,nPage6IFj>1ANDaccuracy_bnc_b(j|D,Gj)=算法1给出的是结合属性排序与打分-搜索的CRBK结构学习算法(或者是NBC的网络依赖扩展算法).算法中的属性排序是依据信息增益率的大小,也可以采用其他的方法(如属性对分类的贡献和属性与类的相关性等);分类准确性估计使用10折交叉有效性验证方法,这种方法是目前最可靠的分类准确性估计方法之一[15];搜索策略选择贪婪搜索,因此,最终学习得到的是局部最优结构,也可以采用能够获得全局最优结构(或近似全局最优结构)的搜索策略(如遗传算法、模拟退火法和量子搜索算法等).学习得到的CRBK绝大多数是属性具有一阶或二阶父结点的分类器(一阶、二阶和三阶CRBK所占百分比依次是53.57%(15个)、35.72%(10个)和10.71%(3个)),而且在三阶CRBK中增加三阶父结点所提高的分类准确率一般不超过3%,如果综合考虑效率和可靠性,二阶CRBK应该是比较理想的选择.CRBK的结构学习是CRBK学习的核心.在CRBK的结构学习中,最多需要进行3n2次的分类准确率计算,因此,关于分类准确率计算的时间复杂度是O(n2).由表1给出的属性父结点选择算法,CRBK的结构可被建立,再结合类边缘概率和基于高斯Copula的属性条件密度估计(式(13)),便能够获得CRBK.4实验与分析我们分别使用真实数据和模拟数据进行分类错误率(分类错误率=(100-分类准确率)/100)比较,以及分类贡献计算与分析.4.1分类错误率比较与分析用于实验的分类器的具体情况如下:(1)SNBC:Boullé等人[16]在2007年给出的选择性朴素贝叶斯分类器.(2)EBNC:Jing等人[17]在2009年提出的集成贝叶斯网络分类器.(3)RBNC:基于打分-搜索方法建立的约束贝叶斯网络分类器.(4)GNBC:使用高斯函数估计属性边缘密度的NBC.(5)FBC:John和Langley在1995年构建的FlexibleBayesianclassifier.(6)FNBC:Pérez等人在2009年建立的FlexiblenaiveBayesclassifier.(7)MFB:王双成等人在2012年给出的连续属性完全贝叶斯分类器.(8)GFBC:Pérez等人[3]在2006年提出的基于高斯函数估计属性密度的完全贝叶斯分类器.(9)CFBC:基于高斯Copula估计属性密度(属性具有边缘高斯密度)的完全贝叶斯分类器[10-11].(10)NN:神经网络.(11)SVM:支持向量机(libsvm,http://www.csie.ntu.edu.tw/),其中核函数为RBF函数,CCost参数设置为1,GGamma参数设置为1/k,k为输入数据中的属性数量.本文使用的SVM在文献[5]中SVM的基础上进行了优化调整,相同数据集的分类准确率可能不同.(12)CRBG(CopulaRestrictedBayesiannetworkclassifierwithmarginalGaussiandensity)和CRBK:结合高斯Copula密度函数与高斯函数和高斯核函数的约束贝叶斯网络分类器.在用于实验的13个分类器中,前4个是离散属性分类器(基于Fayyad和Irani[18]方法对连续属性进行离散化),后9个是连续属性分类器(不进行连续属性的离散化).采用10折交叉有效性验证方法进行分类器的分类错误率估计,并使用WilcoxonSigned-RanksTest和FriedmanTestwithpost-hocPage7Bonferronitest[19]进行两个分类器分类错误率之间差异的置信打分,其中※表示CRBK和用于比较的分类器相对于给定的检验方法差异显著.4.1.1真实数据分别选取UCI数据和经济数据用于比较实验表1UCI数据的分类错误率实验结果AnnealingAutomobileBanquesChronic_kidney_disease0.16820.15240.17660.21430.16570.18690.15750.20260.17300.18440.16270.15380.1459Clave_directionColumn_3CCredit(crx)Drive_diagnosisEchocardiogramForest_typesGas_sensor_arrayHorse_colicIonosphereLiver_diseaseNew_thyroidPhishing_websites0.21350.23460.24170.23840.27610.25330.23520.25750.26930.31280.28740.23840.2095Sick_euthyroidSpambaseSpectf_incorrectSteel_plates_faults0.22060.24370.20910.01600.29090.26130.01430.05900.01840.00000.00000.00690.0000Thyroid0387TransfusionWilcoxonSRtestFriedman/Bonferronitest※-3.30※-3.25※-3.88※-8.93※-8.20※-7.50※-3.41※-6.41※-4.38※-4.21※-3.39※-4.22CRBK考察所有数据集的平均值,CRBK优于其他12个分类器的程度依次是5.05%,4.52%,4.76%,13.44%,15.35%,13.27%,3.26%,7.46%,3.65%,范围表2分类准确率的差异比较[0.5,)67.8678.5871.43100.0096.4396.4378.5892.8689.2978.5875.0092.86(-0.5,0.5)17.86(-,-0.5]14.2814.2817.86(2)经济数据分别选择用于中国工业增加值转折点(CITP)、宏观经济景气指数增减性(MEBI)、经济增长转折点(EGTP)、企业财务风险等级(EFR)、企业财务信息失真(EFID)、企业经营风险等级(EOR)、世与分析.(1)UCI数据12个分类器与CRBK的分类错误率实验结果如表1所示.4.25%,4.15%和4.87%.基于表1中数据得到的散点图和分类准确率的差异比较情况如图2和表2所示.3.5710.710.0010.71界工业增加值增减性(WIID)、税收增减性(TID)、通货膨胀风险等级(IRG)和中国工业增加值增减性(CIID)预测的10个具有实际意义的经济数据集,13个分类器的分类错误率实验结果如表3所示.Page8图2分类错误率散点图表3经济数据的分类错误率实验结果WilcoxonSRtestFriedman/Bonferronitest※-6.50※-3.95※-3.65※-7.90※-9.60※-8.40※-5.40※-3.40※5.30※-5.10※-2.90※-2.93CRBKPage9CRBK的分类错误率平均值优于其他12个分类器的程度依次是11.72%,7.62%,5.53%,22.15%,22.58%,18.32%,11.08%,5.55%,9.30%,11.64%,4.79%和6.26%.我们能够发现,使用真实数据进行实验,在分类准确率方面,相对于其他12个分类器,CRBK具有明显的优势.4.1.2模拟数据分别从边缘分布和联合分布两个方面产生模拟数据,并使用模拟数据进行分类错误率实验与分析.表4边缘分布模拟数据的分类错误率实验结果Marginal_Gaussian_10.02610.02780.03060.02670.02930.03570.02840.03310.04230.02970.02650.03140.0258Marginal_Gaussian_20.27390.35880.38710.24180.35240.32610.28570.33150.31720.34660.31840.33290.2681Marginal_Gaussian_30.33210.34270.33840.30620.37510.41530.36640.42270.39520.43190.36750.37140.2568Marginal_Gaussian_40.09870.15410.11280.12080.12580.14370.10560.15120.13150.13880.12970.14860.1025Marginal_Gaussian_50.32160.40150.35860.34250.33420.38190.29370.36640.34020.35290.24880.39340.3128Marginal_Gaussian_60.45020.44810.41070.34960.45940.43310.45170.41190.40560.43620.39180.44250.3728Marginal_Gaussian_70.16350.15830.17640.18540.20260.25620.15430.17140.19300.20100.16120.15260.1413Marginal_Gaussian_80.22430.18340.16850.20930.17520.21560.22730.22180.20460.19830.18690.20300.1805Marginal_Gaussian_90.24540.22560.30360.26810.36020.31870.33160.29070.23750.34840.23180.27340.2185Marginal_Gaussian_100.27190.34790.30550.23180.26610.28730.25340.31520.32340.28950.27760.31740.2702Hybrid_Gaussian_10.32680.31180.28140.30470.26820.38750.25850.31070.30980.32560.28390.30730.2674Hybrid_Gaussian_20.29180.33520.30680.41160.45180.29660.31520.32050.27510.28630.28950.32260.2783Hybrid_Gaussian_30.14620.13650.16240.17650.15280.16630.17240.14130.18320.15840.16490.19880.1103Hybrid_Gaussian_40.36180.50370.45270.35810.42730.47210.43520.46270.44380.48120.42130.47390.3372Hybrid_Gaussian_50.07950.06410.08320.06720.07240.06810.08750.09140.07780.06970.06630.09650.0584Hybrid_Gaussian_60.05870.05180.10850.07430.11240.10370.12650.11780.13260.10530.07250.12540.0671Hybrid_Gaussian_70.23360.22960.25060.21480.22580.18360.24640.23610.24250.25560.30140.24870.1976Hybrid_Gaussian_80.04250.05330.04820.07360.05680.06370.07640.08250.08760.06930.06060.07940.0588Hybrid_Gaussian_90.31840.33540.29570.25950.32360.41450.26240.34610.35130.33020.30690.34260.2837Hybrid_Gaussian_100.03710.04680.05160.05830.10450.06120.07280.06690.05580.07640.09430.06270.0425Logarithm_Gaussian_10.21660.21530.20910.22760.31380.21340.22430.23010.25670.26450.20360.25130.2102Logarithm_Gaussian_20.42580.45720.43150.44150.39640.46050.45330.42770.47140.44710.50380.41520.4119Logarithm_Gaussian_30.24310.16370.18340.20340.17250.18660.20850.21560.22840.18170.16920.19230.1368Logarithm_Gaussian_40.21540.19280.22710.20660.18350.32640.23520.24710.21830.20320.19840.20190.1863Logarithm_Gaussian_50.15230.13920.17530.15750.26480.16270.17240.20350.16660.14670.21730.14790.1385Logarithm_Gaussian_60.34720.37640.22560.25290.41820.40270.38030.31140.32670.30150.26710.27310.2465Logarithm_Gaussian_70.12180.10430.08190.09740.11380.12630.10770.13450.08580.06590.05740.08360.0683Logarithm_Gaussian_80.03460.05170.03820.09650.04630.07680.06260.11540.03210.02520.02830.02760.0257WilcoxonSRtestFriedman/Bonferronitest※-3.79※-4.79※-4.18※-3.79※-5.61※-7.00※-5.29※-9.80※-6.50※-5.89※-3.43※-6.29CRBK范围表5分类准确率的差异比较[0.5,)78.5878.5882.1482.1475.0089.2978.58100.0096.4389.2978.5892.86(-0.5,0.5)10.7114.28(-,-0.5]10.71(2)联合分布数据在联合分别为高斯、多项式和指数分布的假设(1)边缘分布数据在边缘分别为高斯、混合高斯和对数高斯分布的假设下,采用不同的形式和参数产生模拟数据,分类错误率实验结果如表4所示.CRBK的分类错误率平均值优于其他12个分类器的程度依次是3.59%,5.29%,4.27%,3.13%,7.11%,8.50%,5.18%,7.07%,5.87%,6.02%,3.52%和5.79%.基于表4中数据得到的散点图和分类准确率的差异比较情况如图3和表5所示.7.143.5714.28下,采用不同的形式和参数产生模拟数据,分类错误率实验结果如表6所示.Page10图3分类错误率散点图表6联合分布模拟数据的分类错误率实验结果Joint_Gaussian_1Joint_Gaussian_2Joint_Gaussian_3Joint_Gaussian_4Joint_Gaussian_5Joint_Gaussian_6Page11Joint_Gaussian_7Joint_Gaussian_8Joint_Gaussian_9Joint_Gaussian_100.20230.22080.21540.26410.21170.19710.18530.19350.20560.18980.17440.20850.1826Polynomial_1Polynomial_2Polynomial_3Polynomial_4Polynomial_5Polynomial_6Polynomial_7Polynomial_8Polynomial_9Polynomial_10Exponential_1Exponential_2Exponential_3Exponential_4Exponential_5Exponential_6Exponential_7Exponential_8WilcoxonSRtestFriedman/Bonferronitest※-4.46※-7.43※-3.96※-9.75※-6.86※-7.57※-4.75※-6.00※-4.82※-4.54※-3.39※-4.71CRBKCRBK的分类错误率平均值优于其他12个分类器的程度依次是4.83%,7.68%,3.73%,10.15%,7.51%,8.98%,3.82%,6.47%,4.38%,范围[0.5,)82.1496.4375.00100.0096.4396.4385.7282.1489.2989.2975.00100.00表7分类准确率的差异比较(-0.5,0.5)10.71(-,-0.5]7.1500.0010.71从模拟数据的实验结果来看,相对于其他12个分类器,在分类准确率方面,CRBK仍然具有优势.综合真实数据与模拟数据两个方面的实验结果,能够得出结论:在分类准确性方面,CRBK明显优于其他分类器.在连续属性的贝叶斯网络分类器研究中,有两个因素对分类器的可靠性有较大的影响:一个是属性密度估计方法,另一个是分类器的结构,表1、表3、表4和表6中的数据对其进行了验证.使用Elidan建立CBN的方法强调Copula的因果分解,或者是发现连续变量之间的因果结构(对于分类器则是属性与属性之间的因果结构),无法突出分类器中属性(连续变量)与类(离散变量)之间的关系(这种关系是分类器中最重要的关系).而CRBK则是以分类准确性为标准来优化分类器结构(属性与属性之间,以及属性与类之间的信息流动方式和通5.19%,3.59%和4.11%.基于表6中数据得到的散点图和分类准确率的差异比较情况如图4和表7所示.3.5710.710.00道).因此,CRBK在分类可靠性方面要优于使用Elidan方法建立的贝叶斯网络分类器.Copula完全贝叶斯分类器直接使用属性联合密度进行分类,易于导致分类器与数据的过度拟合,而且当属性较多时,属性联合密度的计算也非常困难,因此会降低分类器的效率和可靠性;CRBK是通过属性联合密度的分解计算来降低运算复杂性和提高泛化能力,相对于Copula完全贝叶斯分类器将更加高效和可靠.4.2分类贡献计算与分析使用UCI数据进行分类贡献计算与分析.CRBK由类先验概率和属性条件联合密度构成(核心部分),其中的属性条件联合密度可分解为Copula密度函数和边缘密度函数的乘积两部分.我们分别进行Copula密度函数和边缘密度函数对分类的贡献比较与分析.Page12图4分类错误率散点图给出一些分类准确率的表示形式:AccRANDOM:随机分类器的分类准确率;AccMODE:在AccRANDOM的基础上增加类信息而得到分类器的分类准确率;AccFBC:在AccMODE的基础上增加John和Langley在1995年给出的属性高斯核函数而得到分类器的分类准确率;AccFNBC:在AccFBC的基础上为高斯核函数引入平滑参数,并采用MISE方法优化平滑参数而得到分类器的分类准确率;AccCRBK:在AccFNBC的基础上引入高斯Copula密度函数而得到分类器的分类准确率;AccGNBC:在AccMODE的基础上增加属性高斯函数而得到分类器的分类准确率;AccCRBG:在AccGNBC的基础上引入高斯Copula密度函数而得到分类器的分类准确率.4.2.1Copula密度函数对分类的贡献比较与分析考察GNBC、FNBC、CRBG和CRBK这4个分类器,用AccCRBK-AccFNBC(简记为CRBK-FNBC)和AccCRBG-AccGNBC(简记为CRBG-GNBC)表示分类器CRBK和CRBG中Copula密度函数对分类的贡献,具体情况如图5所示,其中横轴的数字1,2,…,28依次是28个UCI数据集的编号.从图5中能够看出,对不同的数据集,CopulaPage13密度函数对分类的贡献有比较大的差异.关于CRBK,最大、最小和平均贡献依次是:27.16%、0.00%和8.84%;而对于CRBG,最大、最小和平均贡献则依次是:32.86%、0.00%和6.23%.两个分类器的Copula密度函数对分类的贡献都大于5.00%的数据集有14个和11个,说明了这些数据集中属性之间具有较强的条件依赖关系,而Copula密度函数有效地提取了属性之间的条件依赖信息,从而明显提高了分类器的分类准确率.4.2.2边缘密度函数对分类的贡献比较与分析同样考察上面的4个分类器,用AccFNBC-AccGNBC(简记为FNBC-GNBC)和AccCRBK-AccCRBG(简记为CRBK-CRBG)表示属性边缘密度对分类的贡献差异,具体情况如图6所示.图6显示,属性边缘密度函数的选择同样对分类器的分类准确率产生较大的影响.在FNBC和GNBC的比较中,属性边缘密度函数对分类的贡献差异波动幅度较大,但平均分类准确率之差较小(1.43).在19个数据集中,FNBC的分类准确率优于GNBC,但也存在9个数据集,GNBC优于FNBC,其中的Automobile、Column_3C、Spambase和Steel_plates_faults更是达到了-10.5、-15.47、-22.34和-24.53.可见,FNBC和GNBC在分类准确率方面互有优势和不足,总体差异并不明显.在CRBK和CRBG的比较中,由于受到高斯Copula密度函数的平滑作用,属性边缘密度函数对分类的贡献差异波动相对较小,但平均分类准确率之差却较大(3.82),而且CRBK基本上保持优势.这说明在CRBK中,Copula能够通过整合高斯函数和高斯核函数实现它们的优势互补,因此选择使用高斯核函数来估计属性的边缘密度更有利于提高分类器的分类准确率.5结论和进一步的工作本文基于Copula和贝叶斯网络理论建立了CRBK.在CRBK中,通过使用Copula对高斯函数和高斯核函数的整合实现了它们的优势互补,并使CRBK能够充分地拟合数据;属性联合密度的分解计算解决了高斯Copula密度函数估计的复杂性问题;而结合分类准确性标准与属性父结点贪婪选择的分类器结构学习又可避免CRBK与数据的过度拟合.正是这些导致了CRBK具有良好的分类准确性.由于使用高斯Copula能够更可靠地计算满条件分布,我们进一步的工作是在CRBK的基础上建立约束贝叶斯网络回归模型(满条件分布计算是核心),推动贝叶斯网络的理论、方法和应用研究进程.
