Page1YARM:基于MapReduce的高效可扩展的语义推理引擎顾荣王芳芳袁春风黄宜华(南京大学计算机软件新技术国家重点实验室南京210046)摘要随着语义网的快速发展,RDF语义数据大量涌现.大规模RDF语义数据推理的一个主要问题是计算量大、完成计算需要消耗很长的时间.显然,传统的单机语义推理引擎难以处理大规模的语义数据.另一方面,现有的基于MapReduce的大规模语义推理引擎,缺乏对算法在分布和并行计算环境下执行效率的优化,使得推理时间仍然较长.此外,现有的推理引擎大多存在可扩展性方面的不足,难以适应大规模语义数据的增长需求.针对现有的语义推理系统在执行效率和可扩展性方面的不足,文中提出了一种基于MapReduce的并行化语义推理算法和引擎YARM.为了实现分布和并行计算环境下的高效推理,YARM做出了以下4点优化:(1)采用合理的数据划分模型和并行化算法,降低计算节点间的通信开销;(2)优化推理规则的执行次序,提升了推理计算速度;(3)设计了简洁的去重策略,避免新增作业处理重复数据;(4)设计实现了一种新的基于MapReduce的并行化推理算法.实验结果表明,在真实数据集和大规模合成数据集上,YARM的执行速度比当前最新的基于MapReduce的推理引擎快10倍左右,同时YARM还表现出更好的数据和系统可扩展性.关键词RDF;RDFS推理;MapReduce;语义推理;分布式推理1引言近年来,行业应用数据规模的爆炸性增长推动了大数据技术的迅猛发展.在常规大数据迅猛增长的同时,语义数据特别是RDF数据也以数亿甚至数十亿元组的规模大量涌现.例如,截至2012年3月,LOD(LinkedOpenData)项目①所收集的RDF数据集已经包含了超过325亿条RDF三元组.大规模语义数据发展的这一趋势对RDF数据存储、查询和推理在可扩展性和效率方面提出了新的挑战[1].RDF推理所关注的主要目标是如何借助自动推理机从给定的知识演绎(推导)出一些结论,从而使隐含的知识外显出来[2].对隐含的语义数据的支持是RDF图与其他数据模型的本质区别,也是语义网发展的重要推动力[3].大数据技术背景下,随着RDF语义数据规模的迅速扩大,研究寻找高效的并行化语义推理机制和方法成为一个重要技术难题,成为大规模RDF数据管理系统迫切需要研究解决的重要问题.利用并行计算技术解决大规模RDF数据相关问题已成为学术界和工业界的普遍共识[4].由Google提出的MapReduce并行计算模型以其高可扩展性和高易用性成为目前大数据处理最为成功的并行计算技术之一[5].Hadoop是GoogleMapReduce框架的一个开源实现,其提供了类似于GoogleGFS的分布式数据存储系统HDFS以及类似于GoogleBigTable的面向半结构化数据存储和管理系统HBase.目前,Hadoop已成为大数据存储和并行处理实际上的工业标准,也成为目前大数据深度分析挖掘并行处理的主流技术和平台,在国内外诸多大型互联网企业和其他大数据分析行业应用中得到广泛应用.因此,现实生活中很多涉及到大规模语义分析挖掘的大数据分析应用都可能需要在这个平台上实现,这就使得基于MapReduce完成大数据场景下快速的RDFS推理变得十分重要.目前已有基于MapReduce的并行推理的研究工作[6-7].这些工作主要是将传统的推理技术直接迁移到MapReduce框架下,这种直接迁移的方式使得一次推理任务需多个链式MapReduce作业协同工作才能完成,其中包括增加额外处理重复数据的作业.因此,现有的这些基于MapReduce的方法推理计算效率较低.为了实现MapReduce下大规模RDF数据的高效推理,本文在对资源描述框架RDF、RDFSchema(RDFS)等相关技术分析的基础上,实现了一种高效的基于MapReduce的RDFS推理算法和引擎YARM(YetAnotherReasoningSystemwithMapReduce).通过采用合理的数据划分方案和优化的推理规则执行策略,YARM将推理计算分解为多个相互间没有依赖关系的独立的推理任务,解决了传统推理算法的直接迁移所带来的大量数据移动问题.此外,不同于传统的推理机,YARM根据推理规则之间的依赖关系,优化了规则执行次序,避免了迭代计算,提高了推理过程的执行效率.最后,YARM还采取了有效的措施来解决分布式推理中的重复数据消除问题.在大规模LUBM以及WordNet与DBpedia等模拟和真实实验数据集上的实验结果表明,相比于传统的基于MapReduce的推理引擎,YARM在执行效率上提升了10倍左右,同时表现出良好的可扩展性.与当前基于MapReduce的语义信息并行推理算法相比,论文的主要贡献可以归纳为如下4个方面:(1)研究设计了一种简洁的数据划分方案,将模式RDF和实例RDF数据分开处理,解决了传统推理算法的直接迁移而导致的多次数据通信问题.(2)研究并提供了一种优化的规则应用次序,提高了推理的执行效率.①TheCooperativeAssociationforInternetDataAnalysis(CAI-Page3(3)结合RDFS规则特征和MapReduce框架特点设计了一种高效的重复数据检测和消除策略.(4)设计实现了完整的MapReduce并行化推理算法.本文第2节详细介绍RDF、RDFS以及推理问题的相关概念;第3节介绍RDFS推理并行化的相关工作;第4节对RDFS推理并行化处理的技术困难进行分析并给出解决方案;第5节讨论YARM的设计和实现;第6节采用多个数据集对YARM进行测试和分析;最后对全文进行总结.2语义推理相关概念RDF(ResourceDescriptionFramework,资源描述框架)①是一种数据模型,是由万维网联盟(WorldWideWebConsortium,W3C)组织的RDF工作组于1999年提出的描述Web信息的知识表示语言.RDF是谓词逻辑的一种特殊形式,具有形式化的语义表示,有助于计算机理解它所表达的语义信息.RDF数据模型(RDF图)的组成包括资源、属性和陈述.资源以唯一的统一资源标识符(UniformResourceIdentifiers,URI)来表示,可以是网络上的任何信息、虚拟概念或现实事物等;属性则用来描述资源的特征以及资源之间的关系,每一属性都有其意义;陈述是一条三元组,表示为(主语、谓语、宾语)的形式.其中主语是资源,由URI表示;谓语是属性,亦由URI表示;宾语是资源(URI)或文本.RDF的词汇描述语言RDFSchema(RDFS)②利用RDF进一步定义了建模原语,RDFS可以看作是针对RDF模型的一个基本类型系统,是一种简单的本体语言,即“一种对共享概念化的、明确的形式化说明”[8].使用RDFS可以定义属性的特征,定义被描述资源的类,并对类和关系的可能组合进行约束.RDFS规则推理支持几乎所有的RDFS蕴含,并且具有良好的可计算性和表达能力,是最广泛使用的推理方法之一,得到了众多研究者的关注和研究[1,3,6-7,9].RDF图显式地表示了一个三元组的集合,同时结合RDFS语义定义的一组规则(如表1所示)还具有表示隐含数据的能力,这是RDF数据模型不同于传统数据模型的主要特征之一.隐含数据的求解过程即为推理过程,亦即在给定一个RDF图G的情况下,根据RDFS推理规则加入一组新的三元组T,从而得到更大的RDF图G,这个过程称为推理过程或RDFS闭包的具体化[9].G所描述的数据是显式的RDF语义信息,称为显式数据;新加入的三元组集合T是隐含的RDF语义信息,称为隐含数据.例如,设RDF图中有如下三元组{(Master,rdfs:subClassOf,Student),(Student,rdfs:subClassOf,Person)}.根据规则11可知,RDF图中还隐含着三元组(Master,rdfs:subClassOf,Person).事实上,表1中给出的13条规则是RDFS推理的一个标准规则集.该规则集具有良好的计算能力和可判定性,包含了所有RDFS蕴涵,被广泛应用于各种领域[1].RDFS本身是一个原始本体语言,用于描述概念型的信息,而非特定的实例或对象,是具有广泛的抽象意义的,也就是说RDFS适用于任何领域,具有高度的通用性[9].基于RDFS,用户可定义面向特定应用系统的概念对象和数据关系,创建相应的RDF数据.推理可以在数据插入到RDF存储系统时执行,称为前向推理;也可以在查询发生时执行,称为后向推理.前向推理(forwardchaining)从一个初始的事实出发,不断应用规则得出结论.前向推理在数据插入存储系统时被触发,推理得到的三元组和原三元组都保存在RDF存储系统中.其优点是查询速度快;缺点是计算全部隐式数据需要的时间开销较大,而且推理结果的物化需要占用较多的磁盘空间.当前有一些前向推理系统,如Sesame和RStar.后向推理(backwardchaining)从查询目标出发,利用规则不断地进行目标消解来完成推理.推理在查询时触发,从规则的结论出发依次归纳为规则的条件.这种方法不需要大量的磁盘空间来保存无用的推理结果,也不需要额外的数据预处理时间,但是由于推理在查询时完成,因此会导致查询处理性能较低.由于前向推理在查询响应时间方面的优势以及其在推理系统中的主流地位[10],同时也由于目前主流的大数据分析挖掘并行处理平台是HadoopMap-Reduce,本文主要研究基于MapReduce的前向推理并行化算法.下文中的推理均指前向推理.为了表达方便,本文使用实例数据和模式数据分别代表由RDF语义构造的三元组和使用RDFS语义构造的三元组.①②Page4表1RDFS推理规则3相关工作当前,在RDFS语义推理方面有着众多的研究[6,7,10-21].根据计算模式和实现方式的不同,可以分为以下几种:(1)基于单节点的推理方法.典型的单机推理系统有Jena[11]、Pellet[12]、Sesame[13]等.这些系统为语义数据推理奠定了重要的技术基础,但是由于单节点运行环境的限制,在可扩展性和计算性能方面存在不足,它们难以处理大规模语义数据.(2)基于关系型数据库的推理方法[14-15].这类方法采用关系数据库作为RDF存储系统,结合现有的单机推理系统对语义数据进行推理,满足了语义信息的存储和查询要求.与单机推理系统类似,这类系统在推理速度和可扩展性方面也存在不足.(3)基于分布式哈希技术的推理方法.文献[16]采用了基于分布式哈希技术的并行推理方法.该方法将数据存储在分布式哈希表中,推理过程需不断访问哈希表以避免数据重复.该类方法存在的主要问题是负载不均衡,因此在处理大规模数据的场景下,容易产生严重的性能瓶颈.(4)基于数据划分的推理方法.这类方法主要通过对语义数据或规则进行划分来实现语义数据推理的并行化.MacCartney等人[17]提出了一种基于图划分的一阶逻辑推理算法;Soma和Prasanna[10]提出了一种通过数据划分来实现并行推理的技术,但是这些方法并没有提供大数据集下的实验结果.Weaver与Hendler[18]提出了一种数据划分模型,在该模型下推理任务可被分解为相互独立的多个并行子任务,各节点对本地的数据应用所有的推理规则,直到不再有新的数据产生,最后通过合并各节点局部结果得到全局解.该方案的缺陷是没有检测和过滤重复数据,另外该方案在每个数据单元上使用传统的推理机,计算效率较低.(5)基于P2P网络的推理方法.文献[1,19-20]提出了基于P2P自组织网络的并行化推理方法Marvin.Marvin以“divide-conquer-swap”的方式执行前向推理,蕴含规则以渐进方式执行直到不会再产生新数据为止,整个推理过程也需要多次数据通信[21].(6)基于MapReduce的推理方法.这类方法在底层采用HadoopMapReduce方法和平台,结合数据划分方法来实现大规模语义数据的推理.文献[7]第一次提出基于MapReduce的推理算法,但是并未给出任何实验结果.Urbani等人[6]提出的基于MapReduce物化RDFS闭包的分布式推理算法reasoning-hadoop,是目前为止最快的大规模并行化推理算法.该算法通过分析RDFS规则之间的依赖关系,分析出RDFS规则依赖图,在该图的指导下将原来需要多次迭代才能完成的推理工作简化为只需4次MapReduce作业.但是该方案中每个步骤使用相同的数据划分方案,不同的只是计算部分,这导致了大量静态数据重复传输和中间结果不能有效利用的问题,此外reasoning-hadoop中每个作业一般都是较短的数据密集型作业,推理过程中的大部分时间都消耗在任务的创建、数据传输以及磁盘输入输出上,处理代价高,计算性能较低.基于MapReduce的RDFS推理算法提出后,得到了学术界的广泛关注,众多研究者开始探讨基于MapReduce的特定领域或其他规则库的推理算法.Liu等人[22]提出了基于MapReduce的大规模模糊RDF语义数据的分布推理引擎;Tachmazidis等人[23]提出了基于MapReduce的非单调规则推理的并行化设计方案;而Wu等人[24]提出了基于MapReduce的分布式规则执行机制,但并未给出实验数据;Jang和Ha[25]针对规则推理中的传递性关系的计算提出了特定Page5的解决方案;Maeda等人[26]提出了基于MapReduce的规则系统的设计和实现.这些工作的研究进一步拓展了MapReduce在语义推理领域的应用,为大规模分布式语义推理做出了重要贡献.本文所提出的并行化推理算法和对应实现的引擎YARM采用了与Weaver和Hendler类似的数据划分模型,并根据RDFS规则依赖关系优化了推理过程.YARM采用不同数据划分模型,使推理在一次MapReduce作业之内即可完成,显著提升了计算效率.在单个任务上,YARM采用与reasoning-hadoop类似的规则优化策略进行推理计算,以避免多次迭代处理.此外,YARM还结合MapReduce的特点设计了高效的重复数据检测和消除机制.4RDFS推理并行化问题和解决方案4.1并行化问题大规模RDF语义数据推理的一个主要问题是计算量大、完成计算需要消耗很长的时间,因此,需要研究并行化的RDFS推理算法.RDFS推理过程实质上是一个对RDF输入数据反复应用RDFS推理规则进行推理的过程.RDFS推理规则如表1所示.其中,规则1、4、6、8、10只有一个条件语句,对推理并行化算法改造没有影响;而规则12和13在RDF数据中是极少出现的,在大多数推理工作中均不进行讨论[6,14-15,18,21].因此,影响推理并行化改造的主要规则归结在表2中.表2影响推理并行化改造的RDFS规则子集规则2prdfs:domainx3prdfs:rangex5prdfs:subPropertyOfq7spo9srdf:typex11xrdfs:subClassOfy这些规则在推理中被表示为三元组的连接(join)操作,并且需要反复执行.应用于处理大规模RDF数据时,将会面临多次大规模数据集的自连接操作,导致巨大的计算量,因此,传统的推理机不能直接应用于大规模数据的处理.此外,在推理过程中会产生大量重复数据,这些重复数据既可能位于同一节点,也可能位于不同节点,如图1所示.如何检测和消除这些重复数据也是推理算法并行化改造时需要研究并解决的一个重要问题.图1重复数据(灰色部分和白色部分既可能位于同一词的规则:规则5.规则:规则11.则2、3、9.4.2推理并行化解决方案4.2.1规则依赖关系为了设计出高效可扩展的并行化推理引擎,需要对RDFS的规则进行深入分析.首先按规则的输出对其分类,可分为如下几类:(1)输出三元组以rdfs:subPropertyOf为谓(2)输出三元组以rdfs:subClassOf为谓词的(3)输出三元组以rdf:type为谓词的规则:规(4)输出三元组无固定模式的规则:规则7.另一方面,依据规则输入可将规则分为4类:(1)输入三元组中至少有一条谓词为rdfs:subPropertyOf的规则:规则5、7.(2)输入三元组中至少有一条谓词为rdfs:subClassOf的规则:规则9、11.(3)输入三元组中至少有一条谓词为rdf:type的规则:规则9.(4)输入三元组中至少有一条为任意实例三元组的规则:规则2、3、7.按以上推理规则的输入输出关系重新对这些规则进行组织,可得到如图2所示的规则依赖关系图.Page6RDFS规则还具有如下的特征:(1)RDFS中每一条规则的输入至多有两个三元组,且至少一个为RDFS模式三元组;(2)据统计,RDF数据集中模式三元组的数量只占极少的一部分,大部分数据为实例三元组.这说明RDFS推理中不存在实例数据之间的连接操作,只存在模式数据之间或模式数据与实例数据之间的连接操作[6,14-15,18,21].4.2.2数据划分模型解决数据通信问题的方法是设计一个好的数据划分策略[10].根据对RDFS规则的分析可知,RDF数据集可以被分成两部分:一部分是小规模的模式数据;另一部分是大规模的实例数据.模式数据和实例数据之间存在连接关系,而实例数据之间是没有数据依赖关系的,因此在划分数据时,将小规模模式数据作为全局数据,复制到每个节点的内存中;然后,我们对大规模的实例数据进行划分,并采用分布式存储的方式,以此解决大规模RDF实例数据的存储管理和并行化推理计算.在这种数据划分模型下,一方面,规则匹配由原来一个大表的自连接操作转换为两个集合间的连接(一个小规模模式数据集与一个大规模实例数据集的连接),例如,规则9(srdf:typex)(xrdfs:subClassOfy)→(srdf:typey)可通过对模式数据集和实例数据集在x上做连接实现;另一方面,各计算节点的任务之间无关联关系,整个输入数据上的推理可分解成多个可同时并行执行的推理任务.该数据划分模型在文献[18]中被首次提出,并经过了严格的证明,YARM借鉴上述数据划分模型,以减少MapReduce环境下推理时节点间的数据通信开销.4.2.3消除迭代在推理过程中迭代涉及到两个方面:第一,单个规则需要迭代运算,如规则5、7、9、11,这类规则的特点是规则输出又可以作为自身的输入,称为传递规则.传递规则的推理计算实质上是求解输入数据的传递闭包.第二,不同规则间存在依赖关系(图2),整个推理过程需要多次迭代直到不再产生新的隐含数据为止.通过对规则间依赖关系的分析,我们得到了一个非循环的规则依赖图(图2),该图存在一种拓扑排序(比如规则“5,11,7,2,3,9”,这里的序列不是表达前后两项的一一依赖关系,而是图论中的拓扑排序关系.具体地,指在这个序列中不存在任何一项依赖于该项之后出现的项的情况),使得我们对每条规则只应用一次即可推导出所有的隐含数据,推理过程不再需要多次迭代.另一方面,对于单个传递规则来说,通过在规则7之前执行规则5,可以消除规则7的迭代计算,同样在规则9之前执行规则11,可以消除规则9的迭代计算[15].而同时规则5和11的推理只涉及小规模模式数据,其推理计算可在内存中完成.4.2.4消重策略在RDFS推理中重复数据存在两种类型:第一种是新推导出的结果和原数据存在重复(图3);第二种是新推导出的数据之间存在重复(图1).为了消除结果中的重复数据,需要将原始数据和新推导出的数据进行比较.因为Hadoop能自动地将Map端输出的键值对按键值组织在一起,因此在将三元组设置为键值的情况下,相同三元组会被组织在一起,可以很容易地使用Combine和Reduce来实现重复数据的检测和消除.图3重复数据(白色框内为原始数据,黑色框内为由表2可知,RDFS规则的输出存在4种模式:(1)模式1(?x,rdf:type,?y),即谓词为rdf:type的三元组;(2)模式2(?x,rdfs:subPropertyOf,?y),即谓词为rdfs:subPropertyOf的三元组;(3)模式3(?x,rdfs:subClassOf,?y),即谓词为rdfs:subClassOf的三元组;(4)模式4(?x,?subPropertyRelated,?y),即谓词具有rdfs:subPropertyOf属性的三元组.其中,与模式1和模式4匹配的三元组只可能为实例三元组;与模式2和模式3匹配的三元组只可能为模式三元组.可见,RDFS规则的输出遵循固定的模式,因此,只需与原始RDF图中匹配这些模式的部分数据进行比较,即可检测出所有与原始RDF三元组存在重复的推理结果.这种方式会减少大量不必要的数据传输,对提升推理性能起到重要作用.Page75YARM的设计与实现5.1MapReduce并行化推理算法设计与实现根据第4节的推理算法并行化解决方案,在YARM中RDFS前向推理可归结为3个阶段.在阶段I中,将小规模模式数据复制到每个节点的内存中,同时将实例数据划分为多个互不重叠的分区.每个节点拥有全部的模式数据和部分实例数据,在推理执行过程中,将不需要从其他节点得到数据或者图4YARM:基于MapReduce的并行化推理算法与处理过程5.2数据划分在YARM中,我们假定整个RDF三元组数据集按行存储在HDFS中,实例数据和模式数据分别作为一个文件.首先,将利用HadoopMapReduce中的DistributedCache机制,在map()的setup()初始化函数中将模式数据复制到每个节点的本地内存中;然后将实例数据作为map()函数的输入,这样可以利用HDFS自身的存储机制把数据集切分成固定大小的N个子数据块(默认为64MB),这些子数据块分布在集群内不同的节点上.为了节省数据导入时间和存储空间,我们对RDF三元组进行了编码压缩,模式三元组和实例三元组在编码阶段分别输出到不同的文件,同时,考虑到程序的实现,存储文件采用HadoopSequenceFile格式,每条序列以键值(key-value)对的形式存储,直接以三元组作为键(key),值(value)设置为空.由于所有三元组的大小被编码为相同的长度,因此各节点得到的三元组数量基本相同,保证了各节点间的负载均衡.其次,为了便于Map阶段的处理,依据所匹配的规则,模式数据被组织成四类相应的内存数据结构.其中与规则2匹配的三元组(即谓词为rdfs:其他控制信息,亦即各节点之间是相互独立的,可以并行地执行推理计算.在阶段II中,各节点并行地对本地数据执行推理计算过程,该阶段主要负责依据规则依赖图对输入数据应用推理规则进行推理处理.阶段Ⅲ负责对各节点的推理结果进行合并,并消除结果中的重复数据.可以看出,阶段I相当于数据划分阶段,阶段II相当于推理计算阶段,而阶段Ⅲ相当于合并阶段,因此这3个阶段可以方便地用Map-Reduce并行计算模型加以实现.YARM执行框架如图4所示.domain的三元组)存放在domainMap数据集中,例如,三元组(masterDegreeFrom,rdfs:domain,Master)的谓词为rdfs:domain,则〈masterDegree-From,Master〉被添加到domainMap中;与规则3匹配的三元组(谓词为rdfs:range的三元组)存放在rangeMap数据集中;与规则5和7匹配的三元组(谓词为rdfs:subClassOf的三元组)存放在subClassMap数据集中,例如,三元组(Master,rdfs:subClassOf,Student)的谓词为subClassOf,则〈Master,Student〉被添加到subClassMap中;而与规则9和11匹配的三元组(谓词为rdfs:subPro-pertyOf的三元组)存放在subPropMap数据集中.Mapper端setup()装载和组织数据的实现如算法1所示.其中,setup()函数从HDFS中读取所有的模式三元组,并根据三元组所匹配的规则逐条进行处理,将其组织为不同的内存数据结构,方便之后各推理规则的执行;最后,因为规则5和规则11的推理只涉及模式数据,并且处于规则依赖图的底层,应该首先被执行,因此这两条规则的推理在模式数据装载到内存后便立即以批处理方式加以执行,在执行过程中重复的模式数据也会得到处理.而其余涉及到实例数据的推理规则在map()函数中逐行Page8加以处理.算法1.模式数据预处理.输入:模式三元组集合Schema输出:模式三元组分类集合setup()FORSchema.next()!=nulltriple=Schema.next();IFtriple.predicate==rdfs:domaindomainMap.add(triple.subject,triple.object);ELSEIFtriple.predicate==rdfs:rangerangeMap.add(triple.subject,triple.object);ELSEIFtriple.predicate==rdfs:subPropertyOfsubpropMap.add(triple.subject,triple.object);ELSEIFtriple.predicate==rdfs:subClassOfsubclassMap.add(triple.subject,triple.object)ENDIFENDFORsubpropMap.transitiveClosure();//执行规则5的推理subclassMap.transitiveClosure();//执行规则11的推理5.3Map阶段的规则推理计算Map计算阶段(阶段II),用来执行规则2、3、7、9的推理.Map端的输入是从实例数据文件中读取出来的〈spo-null〉键值对.如算法2所示:在map()函数中,对读入的实例三元组确定所匹配的规则,并根据规则依赖图触发新的推理直到到达规则依赖图的顶端,即可得到该实例三元组的全部推理结果.同时map()还对原数据进行过滤,以便在Reduce端进行重复数据的检测和消除.匹配规则的确定是通过检查三元组的谓词(模式)实现的.例如,如图5所示,RDF图中有如下三元组{(Jolin,masterDegreeFrom,University0),(masterDegreeFrom,rdfs:domain,Master),(Master,rdfs:subClassOf,Student)},其中模式三元组(masterDegreeFrom,rdfs:domain,Master)和实例三元组(Jolin,masterDegreeFrom,University0)与规则2匹配,因此首先要对其应用规则2;规则2的输出(Jolin,rdf:type,Master)和模式三元组(Master,rdfs:subClassOf,Student)与规则9匹配,因此规则2会继续触发规则9的执行;规则9在规则依赖图中是最上层的规则,推理计算至此完成.为了检测和消除重复数据,YARM需要将输入的原始三元组和新推导出的三元组进行比较,所以Map端输出新三元组的同时,还需要将原始三元组传递到Reduce端.为了尽可能减少传输不必要的静态数据,YARM在Map阶段对原数据进行过滤.通过对RDFS规则的输出进行分析,看到只有谓词为rdf:type以及谓词具有rdfs:subPropertyOf属性的实例三元组才存在与新推导出的三元组产生重复的可能性,因此Map只需过滤出这部分数据并将其传递给Reduce即可.Map会输出两种类型的数据(原始的和新推导出的三元组),为了对两者进行区分以便后续的消重处理,YARM使用(s,p,o)三元组作为键,使用标志作为值来识别三元组的类型.算法2.Map阶段的规则推理算法.输入:key为实例三元组;value为空(null)输出:key为输出三元组;value表示key是否为原实例map(key,value)T={key};//T存放各步的推理结果,初始化为原始三IFkey.predicate==“rdf:type”orsubprop.containsemit(key,original_flag);//原始数据的过滤ENDIFFOR(rule:RDFSrules)FOR(t:T)IFt.match(rule)applyruletot;addderivedtripletoT;ENDIFENDFORENDFORT.delete(key);FOR(t:T)emit(t,derived_flag);ENDFOR5.4合并阶段的去重处理合并阶段的任务是收集所有新推导出的三元组,同时对RDFS推理中存在的重复数据进行处理,该阶段使用Reduce和Combine来实现.Page9Combine先对本地的重复数据进行处理,以减少数据传输量;Reduce确保推理结果中没有重复推理结果.如算法3和4所示:因为同一键值的元组会被Hadoop自动组织在一起,所以combine()和reduce()只需要判断该元组对应的数据集中是否存在原始三元组,若存在则直接丢弃,否则对每个三元组输出唯一一份.算法3.Combiner类.输入:算法2中map函数的输出结果输出:key为推理结果三元组;value表示输出的key是combine(key,valueList)IFvalueList.contains(original_flag)emit(key,original_flag);ELSEemit(key,derived_flag);ENDIF算法4.Reducer类.reduce(key,valueList)输入:算法2和算法3的输出结果输出:key为推理结果三元组;value为空IF!valueList.contains(original_flag)emit(key,null);ENDIF6实验6.1实验环境与设置我们从执行效率、数据扩展性和机器可扩展性三个方面分别评估YARM的性能.实验过程中,我们采用reasoning-hadoop[6]与YARM进行对比,据我们所知,reasoning-hadoop是目前最快的并具有高可扩展性的大规模RDF数据推理引擎,通过与reasoning-hadoop做比较,可间接地取得与其他方法比较的结果.我们采用的实验集群由1个主控制节点(Job-Tracker)和16个计算节点(TaskTracker)组成,集群的节点配置参见表3.NetworkBandwidthJVMVersionHadoopVersion实验所用数据集选用了一个合成的数据集LUBM(LehighUniversityBenchmark)[27]大学语义数据,两个真实的数据集WordNet[28]电子词典语义数据以及DBpedia数据集[29].所有数据经编码压缩后以HadoopSequenceFile文件格式存储在HDFS中,默认的分块大小为64MB,均匀地分布在集群内的各计算节点上.LUBM数据集是当前公认的面向大规模本体应用环境的语义Web知识库系统测试基准.实验中利用拟合工具生成了5组规模的测试数据:LUBM-100、LUBM-250、LUBM-500、LUBM-750和LUBM-1000,分别含有100、250、500、750和1000个大学的语义数据,三元组规模分别为13million、33million、66million、100million和133million.WordNet是一个真实的语义数据集,是美国普林斯顿大学认知科学实验室于1985年起开发的大型英文词汇数据库,在WordNet中词语按照语义来组织,共含有1942887条三元组.DBpedia是一个被广泛使用的RDF数据集,数据是从维基百科网页中抽取出的结构化信息,包含了众多领域的实体信息,被广泛用作RDF数据查询的一个标准数据集.实验中选用了4组不同大小的DBpedia数据集:DBpedia-1(35milliontriples),DBpedia-2(85milliontriples),DBpedia-3(140milliontriples)和DBpedia-4(210milliontriples).6.2执行性能测试我们对10组数据(5组LUBM数据,1组Word-Net以及4组DBpedia数据)分别在reasoning-hadoop和YARM下做了5趟测试,最后取平均运行时间,实验结果如表4所示.数据集TripleLUBM-10013.0630.06646.54713.5LUBM-25033.0742.16454.48613.6LUBM-50066.0834.11458.51214.2LUBM-750100.0911.10664.76014.0LUBM-1000133.0964.14372.73213.2WordNet1.9373.54870.7185.3DBpedia-135.0146.65122.5486.5DBpedia-285.0383.29533.63911.4DBpedia-3140.0662.13140.64216.3DBpedia-4210.0734.42443.64616.8由实验结果可见,与reasoning-hadoop相比,YARM在执行时间上要快10倍左右.此外,虽然WordNet的数据集规模小于LUBM-100,但是YARM在WordNet上的推理时间大于在LUBM-Page10100上的推理时间,这是因为WordNet的推理复杂性要远远大于LUBM,实验结果说明影响YARM执行效率的是推理复杂性,影响reasonging-hadoop的因素则侧重于数据集规模.因此在大规模RDF推理任务中,YARM比reasoning-hadoop具有更好的性能.6.3数据可扩展性测试为了观测数据规模增长时YARM实际运行时间的变化情况,并且尽量避免因采用复杂性不同的数据集对结果造成的影响,我们选用复杂性相同但大小不同的5组LUBM和4组DBpedia数据集进行测试.LUBM的规模从100个大学增加到1000个,每个规模级别下分别作5趟测试,最后取平均运行时间.DBpedia选用了不同大小的4组数据:分别为35M条记录、85M条记录、140M条记录和210M条记录,每组数据下也分别做5趟测试,最后取平均运行时间.实验结果见图6和图7,图中纵坐标为执行时间,横坐标为数据规模.可见,随着数据规模的增长,YARM推理时间呈现出近似于线性增长的趋势,与reasoning-hadoop相比,YARM具备了更理想的数据可扩展性.6.4系统可扩展性测试为了观察集群规模增大时,YARM的性能变化情况,我们还进行了系统可扩展性实验.实验中采用了LUBM-1000数据集,集群计算节点规模从1个节点增长到16个节点.实验结果数据处理后如图8所示.图8显示了计算节点数目变化时YARM的运行性能变化曲线.其中横坐标为集群内计算节点数目,纵坐标为执行时间.由图中曲线可见,YARM运行时间在小于8个结点时随集群内节点数目的增加呈接近于线性的下降,但超过8个节点后则下降趋于平缓并接近于一个下限,这个下限取决于一个数据块由单个处理器处理所需的计算时间加上整个算法并行化的额外开销.另外,我们计算了算法的相对加速比和计算效率.相对加速比即同一算法在单个处理器上运行的时间除以在多个处理器上运行的时间,计算效率是指加速比和处理器数目的比值.我们发现随着集群中节点数目的增加,YARM加速比快速上升.与reasoning-hadoop相比,加速比上升得更快,到达极限的速度更慢.本实验中加速比相对的执行时间基础是YARM在与集群内计算节点配置相同的单节点环境下,以local模式运行的Hadoop上的运行时间.图6LUBM数据规模变化时运行时间对比图图7DBPedia数据规模变化时运行时间对比图计算效率定义为加速比和处理器数目的比值,计算效率反应了集群系统中计算资源的利用率的高低.在计算量确定的前提下,随着并行计算系统规模的增长,计算效率会有所下降.经计算发现,与reasonong-hadoop相比,YARM的计算效率曲线下降的更平缓.总的说来,从图8以及相应的计算结果可以发现,随着处理器数目的增长,YARM运行时间的下降和加速比的上升都十分显著,并行执行的效果较Page11好.同时,随着处理器规模的增大,YARM计算效率下降的趋势也是比较缓慢的,即算法有比较好的可扩展性.7总结为了实现大规模RDF数据的推理计算,本文设计和实现了一种基于MapReduce的高效并行化推理执行引擎YARM.它将整个RDF图的推理分解成多个相互独立的更小规模的推理任务,增加了任务执行的并行度,使得RDFS推理在一次MapReduce作业之内即可完成.同时,对单个节点上的本地数据使用优化的推理执行机制.实验结果表明,YARM的计算速度比当前最快的基于MapReduce的并行推理引擎(reasoning-hadoop)高出10倍左右,同时YARM也具备了良好的可扩展性.在未来的工作中,我们将继续对YARM进行改进.我们将进一步研究高效的分布式OWL推理引擎.另外,我们还拟研究如何利用基于内存的分布式计算平台来设计和实现RDFS及OWL推理算法和系统.致谢感谢审稿人提出的宝贵意见及王善永同学对论文终稿进行的格式校验!
