Page1基于差异合并的分布式随机梯度下降算法1)(中国科学院计算技术研究所网络数据科学与技术重点实验室北京100190)2)(中国科学院大学北京100190)摘要大规模随机梯度下降算法是近年来的热点研究问题,提高其收敛速度和性能具有重要的应用价值.大规模随机梯度下降算法可以分为数据并行和模型并行两大类.在数据并行算法中,模型合并是一种比较常用的策略.目前,基于模型合并的随机梯度下降算法普遍采用平均加权方式进行合并,虽然取得了不错的效果,但是,这种方式忽略了参与合并的模型的内在差异性,最终导致算法收敛速度慢,模型的性能及稳定性较差.针对上述问题,该文在分布式场景下,提出了基于模型差异进行合并的策略,差异性主要体现在两方面,各模型在其训练数据上错误率的差异和训练不同阶段模型合并策略的差异.此外,该文对合并后的模型采用规范化技术,将其投射到与合并前模型Frobenius范数相同的球体上,提高了模型的收敛性能.作者在Epsilon、RCV1-v2和URL3个数据集上,验证了提出的基于差异合并的分布式随机梯度下降算法相对于平均加权方式具有收敛速度更快、模型性能更好的性质.关键词分布式;随机梯度下降;规范化;模型合并;社交网络;社会计算1引言机器学习算法中的随机梯度下降算法由于使用简单、收敛速度快、效果可靠等优点得到了普遍应用,但是该算法需要在训练数据上不断迭代,遍历多遍数据,这在数据规模较大以及单台机器计算能力有限的情况下,算法执行效率往往比较低.在大数据背景下,分布式随机梯度下降算法得到了广泛的研究,提高其收敛速度和性能具有重要的应用价值.根据文献[1],我们可以把当前的大规模随机梯度下降算法分为两类:数据并行和模型并行.在数据并行算法研究中,之前的工作[2-6]将数据随机划分分布到不同机器上,通过在多个机器上同时独立地执行随机梯度下降算法,将得到的多个模型进行合并作为最终的模型或者下一次迭代的初始模型,这种策略取得了很好的效果.目前,基于模型合并的分布式随机梯度下降算法普遍采用平均加权方式,平等对待每台机器上得到的模型.这样的合并方式存在以下两个缺点:第一,采用平均加权的方式,忽略了各模型内在的差异性,合并得到的模型不能很好地反映全局数据间的差异特点,导致学习收敛速度变慢;第二,将合并得到的模型作为下一轮迭代计算的初始模型时,从每台机器的角度来看,相当于在模型空间中根据自己当前的模型和远程机器上的模型搜索下一个更好的点,直接平均加权合并得到的模型相对本地模型变化比较大,一定程度上影响了模型性能.虽然文献[2]尝试基于模型错误率进行合并,但其实验结果表明基于模型错误率的合并策略和平均加权合并的策略效果基本没有差别.针对上述问题,本文提出了一种基于差异合并的分布式随机梯度下降算法DA-DSGD(DistributedStochasticGradientDescentwithDiscriminativeAggregating),通过两种策略来提升分布式随机梯度下降算法的收敛速度和模型性能:(1)基于性能的加权合并.与平均加权方式和简单的基于模型错误率进行合并的策略不同,参与合并的各个模型的权重综合考虑了其在所在机器上已使用训练数据的误差以及整个学习过程的进度.特别是随着学习过程的推进,给予性能较好的远程模型更高的权重,从而能更好地捕捉全局数据的特点,保证模型的稳定性;(2)合并模型的规范化.对于加权合并后的模型,我们使用规范化技术使得合并后的模型与本地模型的Frobenius范数相同,即两个模型处于模型空间的同一个球体表面上,模型合并相当于利用全局信息修正了本地模型的方向,从而提高本地模型的性能.我们在分布式环境下,通过实验验证了上述合并策略的有效性,使用上述合并策略的算法相对平均加权收敛速度更快更稳定,而且算法能够达到更优的性能.本文第2节介绍相关工作;第3节介绍本文使用的Pegasos学习算法以及分布式通信框架;第4节详细阐述本文提出的基于差异合并的分布式随机梯度下降算法DA-DSGD;第5节通过实验验证本文提出的算法的有效性;第6节对本文进行总结并讨论下一步研究的方向.2相关工作分布式随机梯度下降算法是近几年来的一个热点研究问题.本文关注基于模型合并的分布式随机梯度下降算法,由于篇幅限制,我们并不详细介绍共享内存多核并行下的随机梯度下降算法[7-9]和基于参数服务器的算法[1,9-12]等相关工作.基于模型合并是处理大规模数据的一种常用策略,特别是在完全分布式的环境下,例如p2p网络中,大部分算法普遍采用模型合并的方式进行训练[13-14].文献[3]在MapReduce和Bigtable框架下验证了DGD(DistributedGradientDescent)、IPM(IterativeParameterMixtures)和DAT(DistributedAsyn-chronousTraining)等算法的性能.DGD算法在Map阶段,每个机器获取最新模型,然后计算各自机器上数据的梯度,Reduce阶段将Map阶段得到的梯度加到一起更新模型,重复多次直到模型收敛.与DGD不同,IPM算法[2-3]在Map阶段各机器独立地执行一遍随机梯度下降,Reduce阶段将Map阶Page3段得到的模型进行平均加权合并,得到下一轮迭代的初始模型.DGD和IPM算法在每一轮迭代后需要同步更新全局模型,为避免同步带来的额外时间开销,DAT算法在计算的时候每个机器在每一轮迭代开始时异步地获取全局模型,然后在本地机器上独立地运行随机梯度下降算法,并用每一轮结束时得到的模型与这一轮初始模型的差对全局模型进行异步地更新.DAT是一种简单的基于参数服务器实现的分布式随机梯度下降算法.DAT相对DGD和IPM虽然节省了同步的时间开销,但是DAT算法中每个机器上的模型不是最新的模型,导致异步更新时使用的梯度不能很好的反应当前全局模型的梯度,每一轮迭代的收敛速度相对较慢[11].由于网络延迟以及同步所需的额外开销,MapReduce计算框架并不太适合随机梯度下降这种需要在数据上迭代多次、顺序更新模型的算法.文献[5]提出的PSGD(ParallelStochasticGradientDescent)算法与IPM算法类似,但PSGD算法只有一轮的MapReduce,在Map阶段,每个机器独立地执行完整的随机梯度下降算法,直到模型收敛;在Reduce阶段,对每个机器上的模型进行平均加权合并,得到最终的模型.PSGD相对IPM算法大大地降低了机器间的通信开销,但是由于每台机器都只使用本地的数据,训练过程没能够利用全局数据信息提高本地模型的性能.介于IPM和PSGD之间,文献[15]提出的BM-DSGD(DistributedStochasticGradientDescentwithButterflyMixing)算法采用蝴蝶状通信方式,去除参数服务器中心节点,每轮迭代中各个节点独立地执行随机梯度下降算法,然后将模型仅发送给下一个通信节点,同时每个节点平均加权合并本地模型与接收到的模型,这种方式较PSGD加强了全局数据在训练过程中对于本地模型的作用,蝴蝶型的通信方式与IPM相比又降低了通信代价,因此具有良好的性能,在分布式随机梯度方法的研究中成为一个热点.其具体通信机制及优点将在3.2小节中进行详细介绍.综上所述,据我们目前调研的结果,大部分分布式梯度下降算法在做模型合并时都只是简单地进行平均加权,忽略了模型之间的差异性,而且平均加权合并得到的模型在模型空间中的分布范围较大,可能会影响算法收敛的速度和性能.本文以BM-DSGD算法的通信框架为基础,在进行模型合并时利用各个模型在其机器上数据的性能,同时考虑整个学习算法的进度对模型进行加权合并.另外,通过限制结果模型在模型空间的分布范围,很好地提高了模型的收敛速度和性能.3基本学习算法与通信机制本文采用Pegasos[16]作为每个节点上的基本学习算法,因为Pegasos是一种使用随机梯度下降算法求解支持向量机(SupportVectorMachine)原始问题的知名算法,而支持向量机是被广泛使用和研究的机器学习算法.本文提出的DA-DSGD算法执行时各机器节点间的通信计算采用与BM-DSGD[15]算法相同的方式.本节中,我们分别介绍Pegasos和BM-DSGD算法.3.1Pegasos算法支持向量机是目前广泛使用的机器学习算法之一,对于给定的训练数据集S={(xi,yi)}mxi∈Rn,yi∈{+1,-1},支持向量机可以形式化为式(1)定义的最小化问题.Pegasos使用随机梯度下降直接求解式(1),具体求解步骤如算法1所示.minw算法1.PegasosAlgorithm.输入:S,λ,T,k输出:wT+11.INITIALIZE:Choosew1s.t.w11/槡λ2.FORt=1,2,…,T3.ChooseAtS,whereAt=k4.SetA+5.Setηt=6.Setwt+7.Setwt+1=min1,1/槡λPegasos算法输入参数为迭代次数T和用来计算梯度的样本数k,每一轮迭代分两步:第1步选择训练集S中的k个样本组成集合At,对At中导致目标函数产生非零损失的数据点计算梯度更新模型w;第2步将得到的w映射到集合B={w:w1/槡λ}中.3.2BM-DSGD通信机制BM-DSGD(ButterflyMixingDistributedSto-chasticGradientDescent)采用蝴蝶状通信方式,如Page4图1所示.假设集群中有2n个机器,这里以n=2为例进行说明.BM-DSGD算法每一轮迭代分两步,每个节点先独立地执行一遍随机梯度下降算法,然后将得到的模型按图1的通信方式发送给对应节点,同时将收到的来自其他节点的模型与本地模型进行平均加权,合并得到的模型作为本地节点下一次迭代的初始模型.例如第1轮通信时,节点1与节点2互发模型,节点3与节点4互发模型;第2轮通信节点1与节点3互发模型,节点2与节点4互发模型.BM-DSGD算法每经过n轮迭代,使每台机器上的数据信息会传播到整个集群上.相对DGD[3]和IPM[2-3]算法来说,BM-DSGD避免了同步更新全局模型带来的网络开销及中心节点瓶颈限制,每个节点同时进行模型合并,大大降低了每一轮迭代的通信开销;相对PSGD算法,BM-DSGD在迭代的过程中能利用不同机器上的数据信息,提高算法的收敛速度和性能;相对基于参数服务器实现的大规模随机梯度下降算法,BM-DSGD是一种更加分布式化的实现,每个节点独立地保存最新的模型,能并行地进行模型应用.特别地,在p2p网络中,例如传感器网络和移动手机网络中,基于模型合并的BM-DSGD是一种典型且普遍应用的训练框架[13-14].4DA-DSGD算法通过上述相关工作的回顾,我们发现,目前基于模型合并的分布式随机梯度下降算法在进行模型合并时基本采用平均加权方式,忽略了模型之间的差异性,合并结果相对本地模型变化较大,作为下一轮迭代的初始模型可能导致模型收敛速度较慢,而提高大规模随机梯度下降算法的收敛速度和性能具有重要的应用价值,能极大地节省计算资源和训练时间.针对这个问题,本文提出基于差异合并的分布式随机梯度下降算法,DA-DSGD(DistributedStochasticGradientDescentwithDiscriminativeAggregating),算法具体步骤如算法2所示.核心思想是在合并时充分考虑每个模型在其所在机器上已使用训练数据的误差以及整个学习过程的进度这两项差异,从而加快算法收敛速度;同时使用规范化技术使得合并后的模型与本地模型的Frobenius范数相同,降低合并给模型带来的巨大变化,提高学习精度.算法2.DA-DSGD算法.输入:S,λ,PT,k,T,N输出:wT1.ShuffleSandrandomlysplitintoNdisjointsets2.INITIALIZE:forallnodesi=1,2,…,N,choose3.FORt=1,2,…,TPARALLELDO4.wi5.εi=Average0-1lossoflocalseentrainingdata6.j=NextCommunicateNode(i,t,N)7.send(wi8.μi=ln9.wi10.wi11.ENDFOR12.wT=∑过程1.PegasosIterateOnce(Si,λ,PT,k,wi1.Setwi2.FORpt=1,2,…,PT3.ChooseAptS,whereApt=k4.SetA+5.Setηt-1,pt=6.Setwi7.Setwi8.ENDFOR9.RETURNwiPage5过程2.NextCommunicateNode(i,t,N).1.t=(t-1)%log2N+12.j=i+2t-13.lower_bound=04.range=2t5.bias=06.WHILEbias<N7.IFi<=bias+range8.lower_bound=bias9.BREAK10.ENDIF11.bias+=range12.ENDWHILE13.IFj>lower_bound+step14.j=lower_bound+j%range15.ENDIF16.RETURNjDA-DSGD算法输入参数中S为训练数据集,λ为Pegasos算法目标函数中模型参数w的正则因子,PT为本地节点每一轮迭代中Pegasos算法的迭代次数,k是Pegasos算法每一轮迭代中用来计算梯度的训练样本数,T是DA-DSGD算法每个节点的迭代次数,N是集群中参与计算的节点数.其中,PT的值用来调节本地计算时间和网络通信时间的平衡,显然太小的PT值会使算法的大部分时间开销都在网络通信上.具体地,训练数据被随机均匀划分到N个节点上,每个节点随机初始化模型参数wi限制初始模型wi代中,各计算节点调用函数PegasosIterateOnce执行PT次Pegasos算法的内部迭代运算,然后在本地已经被使用过的训练数据上计算模型的平均错误率.算法2的步骤7中NextCommunicateNode函数根据当前迭代次数以及蝴蝶状通信网络结构选择通信节点,并互相发送节点上的模型和错误率,各节点将接收到的模型及其错误率与本地模型进行差异化合并.最后收集合并各机器上的模型得到DA-DSGD算法的最终输出模型.DA-DSGD与BM-DSGD算法的主要差别在于BM-DSGD采用平均加权方式进行模型合并,而DA-DSGD对模型进行差异化合并.DA-DSGD借鉴集成学习算法AdaBoost[17]的权重计算公式,根据模型的错误率使用算法2中步骤8公式得到模型的基本权重;同时,考虑到算法不同阶段模型表现的差异以及对全局数据信息的利用情况,我们选择算法2中步骤9的公式在步骤8的基础上重新对权重进行计算,得到最终合并使用的权重(具体做法在下一段落解释).此外,在每轮迭代的最后一步(算法2步骤10),我们将合并得到的模型投射到与本地节点合并前模型的Frobenius范数相同的球面上,实验结果表明这么做能够使最终模型的误差更小,模型也更稳定.本文使用的模型差异化计算公式能够很好地刻画学习算法不同阶段应该采取的合并策略.算法2步骤9中本地模型wi化情况如图2所示.其中,“errorratei”和“errorratej”坐标分别表示模型wi也就是算法2中的εi和εj.从图2可以看到,在训练刚开始的时候,各个节点上模型的误差率相对较大,例如在0.4~0.5之间,模型还不能很好地建模训练数据,来自其他节点的模型对本地数据的建模效果也很差,此时,如果本地模型误差率与接收到的模型误差率接近,DA-DSGD就给予本地模型更大的权重,即μiμi+μj差率显著低于本地模型误差率时,DA-DSGD给予接收到的模型较大的权重.而在算法训练后期,各模型表现趋于稳定,在各节点数据属于独立同分布的假设下,各模型的训练误差率比较接近,此时误差率也相对较小,DA-DSGD给予接收到的模型更大的权重,原因在于此时来自其他节点的模型相对本地模型包含的数据信息更大,能更好地建模全局训练数据.DA-DSGD相对BM-DSGD在模型合并时采用了差异化的合并策略,虽然需要额外计算各节点的错误率,但是在分布式环境下,这些开销相对每次迭代中的通信开销小得多.所以本文并不讨论DA-DSGD与BM-DSGD在运行时间上的差异.另外,DA-DSGD差异化合并的思想能方便地扩展到MapReduce等Page6其他通信框架上.5实验分析本文在Epsilon、RCV1-v2[18]和URL[19]3个分类数据集上对比DA-DSGD与BM-DSGD算法的收敛速度和最终模型的性能,采用二分类而不是多分类任务进行实验主要是因为多分类问题可以转换为二分类问题,同时,这也是大部分相关工作采用的做法[13-14].另外,为了探究差异化合并和规范化技术对模型收敛速度及性能的影响,我们对BM-DSGD合并后的模型使用DA-DSGD采用的规范化技术,得到SBM-DSGD,对DA-DSGD去除规范化步骤,得到UDA-DSGD,并对这些算法的性能及收敛性进行对比实验.下面分别介绍实验使用的数据集和实验结果.5.1数据集Epsilon是人工构造的数据集,来自2008年Pascal大规模学习竞赛,是二分类问题.Epsilon数据集包含400000条训练数据和100000条测试数据,共2000个特征,特征预处理时先按特征进行z-score归一化,再对每条数据按长度为1进行归一化.RCV1-v2数据集共804414篇文档,我们使用CCAT类别对其进行二分类,使用其中的621392篇文档作为训练数据,183022篇文档作为测试数据,文档用词的向量空间模型表示,去除停用词并进行词干还原,特征使用tf-idf计算方式,每个文档向量按长度为1进行归一化.为降低特征数量,我们去图3N=16,32,64时算法的测试集错误率下面我们以N=16为例,进行详细的分析.首先我们对比DA-DSGD与BM-DSGD两种算法的性除在训练集中文档频率小于5的词项,最终的特征数为118840.URL数据集共2396130条数据,3231961个特征,用于判断URL是否为恶意链接,是二分类问题.特征主要有词法特征和基于主机的特征两大类,都是从网页url抽取的,不涉及网页具体内容.词法特征是对网页url按分隔符切分得到词项,再用词袋模型表示,基于主机的特征包括域名注册日期、注册者、登记者、主机地理位置信息、IP地址前缀等,关于该数据集的更加详细的说明请参考文献[19].我们对该数据集进行随机划分,划分后训练数据集有2255171条数据,测试集有140959条数据.5.2实验结果我们对N取不同的值,N=16,32,64,分别进行实验,验证提出的算法的有效性.我们发现N取不同值时得到的实验结论是一致的,于是,我们对N=16的实验结果进行详细分析,验证DA-DSGD相对BM-DSGD在性能和收敛速度上的优势.实验中,迭代次数T取足够大的值,保证观察到算法的收敛情况.参考文献[15]BM-DSGD和文献[16]Pegasos算法的实验,我们取PT=100,k=10,λ=10-4.5.2.1DA-DSGD与BM-DSGD两种算法的性能针对N的不同取值,我们得到图3的实验结果,可以看到,本文提出的算法在Epsilon、RCV1-v2和URL3个数据集上相对BM-DSGD算法收敛速度更快、性能更好.能.为此,我们计算测试集错误率随迭代次数T的变化,在3个数据集上的测试集错误率如图4所示.Page7可以看出,DA-DSGD在测试集上的性能明显优于BM-DSGD的性能.例如T=300时,在3个数图4测试集错误率图5Pegasos目标函数值图6训练集错误率据集上我们的方法比BM-DSGD的性能分别提高了1.86%、0.49%和0.08%.Page8下面我们对比DA-DSGD与BM-DSGD两种算法的收敛速度.为此,我们分别计算Pegasos目标函数值和训练集错误率随迭代次数T的变化,注意这些结果都是在全部训练数据上进行计算的.Pegasos目标函数值和训练集错误率在3个数据集上的结果分别如图5和图6所示.可以看到,DA-DSGD算法相对BM-DSGD算法收敛得更快.具体地,DA-DSGD仅用300轮到400轮的迭代其目标函数值和训练误差就基本收敛了,而BM-DSGD目标函数值虽然基本收敛了,但是其训练错误率还有很大的波动,当我们将迭代次数T增加到1000次时,发现BM-DSGD算法在Epsilon和URL两个数据集上的训练错误率依然没有收敛.图7测试集错误率首先我们研究差异化模型合并因素的影响,为此我们对比DA-DSGD和SBM-DSGD算法,同时对比UDA-DSGD和BM-DSGD算法.通过实验结果,我们发现DA-DSGD相对SBM-DSGD收敛速度更快,随着迭代次数的增加,DA-DSGD很快就收敛了,但是SBM-DSGD还有一定程度的波动,但是两者最终收敛值一致.对比UDA-DSGD和BM-DSGD我们得到了相同的结果.3个数据集上得到的结果也基本一致,相对RCV1-v2数据集,Epsilon和URL数据集上的差异更明显,部分原因可能在于RCV1-v2上CCAT的分类任务相对容易,算法基本都能很快收敛.接下来研究规范化技术对模型收敛速度和收敛值的影响,为此我们对比DA-DSGD和UDA-DSGD算法,同时对比SBM-DSGD和BM-DSGD算法.在3个数据集上的实验结果说明,通过使用规范化技5.2.2差异化合并和规范化两个因素的深度分析下面我们进一步分析DA-DSGD中差异化合并和规范化这两个因素对收敛速度和收敛值的影响.我们对DA-DSGD去除规范化,采用与DA-DSGD相同的合并权重计算公式,但是用权重归一化取代合并结果规范化,得到UDA-DSGD.同时,对BM-DSGD的平均加权合并结果进行规范化,得到SBM-DSGD.本文实验结果中测试集错误率和训练集错误率曲线趋势基本一致,所以在接下来的分析中我们使用测试集错误率来比较各种算法的收敛速度和收敛值,探究差异化合并和规范化两个因素的不同作用.在Epsilon、RCV1-v2和URL的3个数据集上不同算法的实验结果如图7所示.术,DA-DSGD相对UDA-DSGD、SBM-DSGD相对BM-DSGD均收敛到更好的值.综合以上实验结果表明,差异化合并能够提高模型收敛速度,而规范化技术能使模型收敛到更好的值.5.2.3实验小结上述对DA-DSGD算法实验结果的分析和对比,用实验验证了差异化模型合并策略和规范化技术能很好地提高模型的收敛速度和性能,使模型随着迭代次数的增加,其性能有更稳定和更好的表现.另外,我们也尝试使用不同的权重计算方式,直接对模型在其所在机器上使用过的训练数据的准确率进行线性加权,实验结果与平均加权合并方式接近,因为每个节点上的模型从训练数据属于独立同分布的假设上来看,其准确率应该是接近的,直接线性加权的方式不能很好地捕捉模型之间的差异性.Page9另外,最终模型合并时对DA-DSGD算法根据各节点模型按性能仅取前K个进行合并,能进一步稍微提高最终模型的性能.6总结本文针对分布式随机梯度下降算法普遍采用平均加权方式进行模型合并存在的收敛速度慢和最终模型性能较差的问题,提出了基于模型性能进行差异化合并的策略,同时对合并得到的模型进行规范化,使得到的模型能更好地利用全局数据信息,提高收敛速度和性能.实验结果证明,差异化合并策略相对平均加权方式,能提高模型收敛速度,同时,规范化技术的使用,使模型收敛到了更好的点.后续研究工作中,我们打算使用逻辑回归等其他学习算法,同时考虑MapReduce等分布式计算框架,验证本文提出的差异化合并策略和规范化技术的普遍有效性.另外,对于本文使用的差异化加权方式,我们将更细致的研究算法迭代的不同阶段其加权机制对模型收敛速度的影响,同时,我们也会研究其他形式的权重计算方式.
