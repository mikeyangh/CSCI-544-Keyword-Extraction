Page1直接优化性能指标的多排序模型融合方法王扬1),3)黄亚楼1)卢敏1),4)庞晓东2)谢茂强2)刘杰1)1)(南开大学信息技术科学学院天津300071)2)(南开大学软件学院天津300071)3)(国家电网天津市电力公司信息通信公司天津300010)4)(中国民航大学计算机科学与技术学院天津300300)摘要现有排序学习算法忽视了查询之间的差异,在建立排序模型的过程中等同对待训练样本集中的所有查询及其相关文档,影响了排序模型的性能.文中描述了查询之间的差异,并在训练过程中考虑查询之间的差异,提出了一种基于有监督学习的多排序模型融合方法.这种方法首先使用每一个查询及其相关文档训练出子排序模型,并将每一个子排序模型的输出转化为体现查询差异的特征数据,使用监督学习方法,实现了多排序模型的融合.更进一步,针对排序问题的特性,文中提出了一种直接优化排序性能的融合函数融合子排序模型,使用梯度上升方法优化其下界函数.文中证明了直接优化排序性能的融合函数融合子排序模型的性能优于子排序模型线性合并的性能.基于较大规模真实数据应用的实验结果表明,直接优化性能指标的多排序模型融合方法可以比传统排序学习模型具有更好的排序性能.关键词排序模型融合;直接优化性能指标;排序学习;信息检索1引言排序学习旨在为目标对象按照某种规律确定一个等级顺序,是目前信息检索与机器学习领域研究的一个热点问题.现有排序学习方法可分为3类:基于数据点(Point-wise)排序学习算法[1]、基于有序对(Pair-wise)的排序学习算法[2-4]和基于列表的(List-wise)排序学习算法[5-7].排序学习在信息检索[8]、网页搜索[2,9]等方面有着广泛的应用前景.与传统的机器学习任务(如分类任务等)相比,排序学习问题具有自身特性.由于待排序的文档分别是由不同的查询检索得到的,因此只有同一个查询检索到的文档之间才存在有序关系.在排序学习任务中,不同查询及其对应文档之间,在如数据分布、评价指标和预测未知查询能力等方面,存在显著的差异.现有排序学习方法在建立排序模型过程中,没有考虑查询其相关文档之间的差异,在一定程度上影响了排序模型的性能.与本文研究紧密相关的包括两大类方法:一是与查询相关的排序学习(QueryDependentRanking),二是排序模型融合(RankAggregation).与查询相关的排序学习方法建立多个排序模型,对于不同的预测查询使用不同的排序模型预测.Geng等人[10]基于K近邻方法,提出了与查询相关的排序学习算法.Ni等人[11]将排序样本与查询相关的性质抽象为分组学习问题,使用共性模型和特性模型共同预测排序结果.Peng等人[12]提出使用JS-散度选择与未知查询最相关的排序模型算法.以上3种与查询相关的排序学习方法,虽考虑了排序样本与查询相关的特性,但仍存在以下一些不足:(1)与查询相关的排序学习方法将训练集割裂为若干个训练子集.此方法只注意到训练集中样本的区别,没有考虑到样本之间还存在着联系;(2)每个与查询相关排序子模型只使用训练集中的部分样本而非所有样本参与训练,导致排序模型性能不佳;(3)训练过程中需要建立大量排序模型,模型训练的时间代价过大.排序模型融合主要包括以下几种算法.Qin等人[13]提出依照查询-文档对的相关程度标注将整个数据集划分为多个数据子集,而后使用BordaCount算法融合多个子排序模型的结果.Liu等人[14]将排序模型融合问题转化为半正定规划问题,使用马尔科夫过程建模并优化.Bian等人[15]提出一种基于主题的多排序模型融合算法,使用支持向量机方法建立排序模型.排序模型融合方法虽然在性能上取得比传统使用单一模型决策更好的性能,但是在子模型建立过程中(如文献[13])并未特别考虑排序学习中查询之间存在的差异.此外,多数方法中使用计算概率、加权融合等方法简单线性合并子模型,并未明确提出一种适用于排序学习问题的融合函数.本文针对如上问题,提出一种基于监督学习融合多个子模型的方法,在建立排序模型过程中考虑查询差异,称为多排序模型融合方法.该方法首先在每一个查询及其相关文档组成的数据子集上,以查询-文档对为训练单元建立子排序模型.此步骤的目的是建立多个具有较大差异性的子排序模型,依据每一个子排序模型预测未知查询.在此基础上以整个数据集为整体,使用基于监督学习的融合函数建立融合模型,在融合子排序模型的同时调节不同子模型产生损失的权重.融合过程不仅可以增强模型的泛化性,避免模型过度拟合,还可以更进一步提高排序性能.更进一步,针对排序问题的特性,本文提出一种直接优化排序性能的融合函数融合子排序模型.由于排序性能函数不连续、不可导、不易优化,本文提出优化其下界函数,并证明了其下界函数的凸性,而后使用梯度上升方法进行优化.本文证明了直接优化排序性能的融合函数融合子排序模型的性能优于子排序模型线性合并的性能.基于较大规模真实数据应用的实验结果表明,直接优化性能指标的多排序模型融合方法可以比传统排序学习模型具有更好的排序性能.本文第2节详细分析排序学习中查询之间存在的差异;第3节介绍基于监督学习的多排序模型融合方法;第4节介绍直接优化性能指标的融合函数设计与优化过程;第5节给出直接优化性能指标的多排序模型融合方法应用于实际检索任务的实验结果并进行实验分析;第6节总结全文.2排序学习任务中的查询差异分析与传统的机器学习任务(如分类任务等)相比,排序学习问题具有自身特性.由于待排序的文档分别是由不同的查询检索得到的,因此只有同一个查询检索到的文档之间才有序关系.在排序学习任务中,不同查询及其相关文档组成的”查询-文档”子集之间存在显著差异.这些差异在一定程度上影响排Page3序模型的性能.首先,不同训练查询及其相关文档建立的排序模型具有不同预测未知查询的能力.本文以OHSUMED数据集中查询5和查询49为例进行分析.以查询5及其相关文档为训练单元建立单个查询排序模型,并使用其他查询作为测试样本检测单个查询建立的排序模型性能.对查询49进行相同操作,结果如表1.表1显示,使用查询5建立的单个查询排序模型预测未知查询的MAP值[16]要高于单个查询排序模型的平均MAP值,而使用查询49建立的单个查询排序模型预测未知查询的MAP值则要低于单个查询排序模型的平均MAP值.由此可以看出,不同训练查询及其相关文档建立的排序模型的预测未知查询的能力也不同.表1单个查询排序模型预测未知查询能力比较表单个查询排序模型(查询5建立)单个查询排序模型(查询49建立)单个查询排序模型(平均)其次,从评价指标的角度,不同查询中相同数量的排序错误对整体性能产生的影响也存在很大差异.如表2所示,查询1和查询2同样错排序了10个样本,但其整体查询正确率是截然不同的.这也从评价指标方面反映出不同查询之间是有很大区别的,其产生的损失需要区别对待.表2不同查询中相同数量的排序错误对整体性能的影响查询正确排序样本错误排序样本文档总数正确率/%查询1990查询210综合排序模型预测未知查询能力和评价指标等方面,可以看出不同查询及其相关文档组成的训练子集之间具有差异.现有排序学习算法,在训练过程中未考虑查询的差异,等同对待训练样本,影响了排序模型的性能.有必要在在训练过程中考虑查询差异,对不同子集产生的损失赋予不同的权重.3多排序模型融合方法针对第2节中提出的查询差异问题,本章提出一种基于监督学习融合多个子模型的方法,在建立排序模型过程中考虑查询差异,称为多排序模型融合方法.首先给出一些符号定义.S={(qi,狓ij,yij)}n表示训练数据集.Q={qi;i=1,2,…,n}表示训练集中的所有查询.每个查询qi有一组相关文档Di={dij;j=1,2,…,mi}.每一个查询-文档对由一个特征向量狓ij表示,每一个狓ij都有一个相关等级标注yij.{f(狑i);i=1,2,…,k}是一组子排序模型,其中狑i是子排序模型f(狑i)的模型参数向量.狑={αi;i=1,2,…,n}是融合模型的模型参数.本文所言多排序模型融合是指,首先使用每一个查询及其相关文档训练出子排序模型,并将每一个子排序模型的输出转化为体现查询差异的特征数据,使用监督学习方法,实现多排序模型的融合.多排序模型融合方法主要包括3个步骤:建立子排序模型、多排序模型融合和预测未知查询,可用算法1具体描述.算法1.多排序模型融合方法.输入:trainingsetS={(qi,狓ij,yij)}n输出:rankaggregationmodel1.Fori=1,…,n;2.Setupthebaserankersf(狑i)oneachsubsets;3.EndFor;4.Constructtheaggregationmodelinputfeaturevector;5.Optimizetheaggregationfunctiontolearnaggrega-3.1建立子排序模型在多排序模型的融合方法中,首先需要建立子排序模型.每一个子排序模型由一个查询及其相关文档建立.不同子排序模型之间可以体现出查询之间的差异性.对于每一个查询qi∈Q,将这个查询与其所有的相关文档组成查询-文档对.每一个查询-文档对〈qi,dij〉都可以用一个特征向量狓ij描述.其中,D为特征向量狓ij的维数.以查询为单位将整个训练数据集S={(qi,狓ij,yij)}ni=1划分为n个数据子集.随后,在每一个训练子集上建立子排序模型.假设排序决策函数f为线性损失函数,以子模型的输出作为子模型特征的描述,每一个子模型的输出为一维列向量,由融合模型调节每一维的权重.Page43.2多排序模型融合险可一般性的表示为在传统的排序学习问题中,排序模型的经验风其中,δ为符号函数,狓ij表示训练数据集中的样本,yij表示训练样本狓ij的相关程度等级标注.以写成:本文提出的多排序模型融合方法的经验风险可其中,S表示训练数据集.多排序模型融合方法将训练数据集以查询为单位划分为n个训练子集.狓ij表示第i个子集中的第j个训练样本,mi表示第i个子集中的样本个数.对比式(3)与式(4),多排序模型融合算法在融合子排序模型的过程中,可以优化权重函数φi(狓).在融合函数的优化过程中调节不同查询产生损失的权重.3.3预测未知查询当有新的查询需要预测时,需要使用子排序模型和融合模型两步预测.首先,使用每一个子排序模型预测未知查询,每一个子排序模型预测结果为一列构建融合模型输入特征向量.最后使用融合模型预测最终的排序结果.4直接优化性能指标的融合函数在本文第3节提出的多排序模型融合方法基础上,针对排序问题的特性,本节提出一种直接优化排序性能(DirectlyOptimizingPerformance)的融合函数(简称为RankAgg.NDCG)融合子排序模型.4.1直接优化性能指标的融合函数设计排序性能评价指标NDCG[17]如下定义.对于给定一个查询qi,第k位的NDCG值NDCG@k的计算公式为其中,r(j)表示第j个文档的相关等级.归一化参数Nr使得最优的排序的NDCG@r的值始终为1.基于NDCG表达式,直接优化排序性能的多排序模型融合函数设计为其中,Nr是归一化参数.狑={αi;i=1,2,…,n}.N是训练集中查询的个数,Mn是训练集中第n个查询包含的候选文档狓nm的个数.ynm是狓nm的相关程度标注.符号函数π(狓nm)表征狓nm的排序位置信息.定义π(狓nm):π(狓nm)=1+∑Mn其中,表示排序顺序关系.f狑(狓nm)为线性排序函数.f狑(狓nm)的输出是样本狓nm的排序分值.I(狓nm)是一个0-1识别函数.当f狑(狓nm)f狑(狓np)时,I(狓nm)输出1;反之则输出0.将式(8)、式(9)和式(10)代入式(7),式(7)可以改写为E(狑)=n=1∑MnNr∑N1式(11)即为直接优化排序性能的融合函数.由于式(11)是一个不连续的函数,所以很难直接优化式(11).一些之前的研究成果,例如文献[18],使用logistic函数拟合0-1识别函数I(狓nm).本文给出式(11)的下界,将优化式(11)的问题转化为优化其下界函数的问题.并且,优化其下界函数的问题是一个连续凸函数最优化问题,使用梯度上升方法可以很方便的优化求解.对于所有的x∈R,指数函数exp(x)均为0-1函数的上界.因此,对于所有的x∈R,I[x>0]exp(x)均成立.即根据式(12),可以得到π(狓nm)的上界函数π^(狓nm).π^(狓nm)=1+∑Mn将式(13)代入式(11),直接优化排序性能的融Page5合函数改写为E^(狑)=n=1∑MnNr∑N1对比式(14)和式(11),式(14)是直接优化排序性能的融合函数的下界,并且是一个连续可导函数.4.2融合函数的优化参数狑求导,可得Δ狑=E^(狑)使用梯度上升方法优化式(14).对式(14)中的更进一步,Δ狑=E^(狑)π^(狓nm)狑=-∑Mn综合式(15)、(16)和式(17),可以得到融合目标函数式(14)的梯度表达式.使用梯度上升方法迭代优化:将狑={αi;i=1,2,…,n}代入式(18)可得E^(狑)=E^(狑)从式(19)中可以明显看出,直接优化排序性能的融合函数在优化过程中为不同子排序模型赋予不同权重.4.3融合函数理论分析本节对融合函数的性质进行理论分析.首先给出融合函数E^(狑)是一个凸函数的理论证明.基于此,可以推论出直接优化排序性能的融合函数融合子排序模型的NDCG性能优于线性合并子排序模型的NDCG性能.定理1.融合函数E^(狑)是一个凸函数.证明.对于所有的x∈R,函数log(1+exp(x))直接优化排序性能的融合函数式(12),可以抽是一个凹函数.象成1/log(1+exp(x))的形式.一个凸函数.并且,f狑(狓nm)为线性排序函数.因此,融合函数E^(狑)是一个凸函数.证毕.下面给出定理1的一个推论.推论1.直接优化排序性能的融合函数融合子排序模型的NDCG性能优于线性合并子排序模型的NDCG性能.证明.根据定理1,已证明融合函数E^(狑)是当严格限定参数定义域αi∈[0,1]且∑n时,直接优化排序性能的融合函数E^(狑)的NDCG性能优于线性合并子排序模型的NDCG性能.即∑NNDCGqn,∑N更进一步,由于直接优化排序性能的融合函数E^(狑)是在所有实数范围内优化,寻找αi∈R中,NDCG性能的最优值.n=1i=1max∑Nmax∑N∑nmax∑N∑ni=1因此,通过式(21)可以得出,在NDCG性能方面,直接优化排序性能的融合函数融合子排序模型的性能要优于线性合并子排序模型的性能.证毕.5实验结果及分析将本文提出的直接优化性能指标的多排序模型融合方法应用于信息检索领域,包括文本检索、网页检索和大规模文档检索.5.1实验准备5.1.1数据集本文实验使用LETOR①数据集合[20]作为实验用数据集.LETOR数据集合发布于2007年,迄今①http://research.microsoft.com/en-us/um/beijing/projects/letor/Page6在排序学习领域已被广泛使用[4-7,12-15,18-19].LETOR数据集合中包括OHSUMED、TREC.Gov等多个数据集.文本检索的实验使用OHSUMED数据集[20]作为数据集.OHSUMED数据集中数据内容主要是医药类杂志文章的标题和/或摘要,来源于美国医药信息数据库.数据集包含了106个查询和348566个文档.基于这些文档集合和查询集合,OHSUMED一共标注了16140个查询-文档对,每一个查询-文档对都被标注成相关、部分相关或者不相关,最终的标注结果中一共包含了2557个相关、2932个部分相关以及12498个不相关的查询-文档对.OHSUMED数据集合曾在TREC-9国际文档检索竞赛中使用.网页检索的实验使用TREC.Gov2003和TREC.Gov2004数据集合作为数据集.TREC.Gov数据集合是一个网页文档集合,抓取自2002年早期.gov域名下网站的网页.TREC.Gov数据集包含了1053110个网页和11164829个超链接.本文使用TREC2003和TREC2004中的主题选择(TopicDistillation)、主页查找(HomepageFinding)和命名网页查找(NamedPageFinding)6个任务,共计575个查询.基于这些网页集合和查询集合,TREC竞赛的组织者针对每一个查询都标注了大量的网页,每一个查询-网页对都被标注成相关或者不相关.使用TREC2007和TREC2008中的大规模查询(MillionQuery)任务数据集合作为大规模文档检索的实验用数据集.其中,MQ2007数据集包括1692个查询,69623个文档;MQ2008数据集包括784个查询,15211个文档.基于这些网页集合和查询集合,TREC竞赛的组织者针对每一个查询都标注了大量的网页,用相关、部分相关或者不相关描述每一个查询-网页对的相关程度.5.1.2评价指标别为P@n,MAP和NDCG@n.前n位准确率的评价指标.本文实验使用3种评价指标评价排序性能,分P@n(Precision@n)是一种用来衡量排序结果其中,n是参与计算的样本个数,rj是一个0-1识别函数.rj=1,若排在第j位的文档是相关文档法对多个查询的平均排序结果,计算公式为MAP[16](MeanAveragePrecision)用来衡量算MAP=∑i∑M其中,j表示排序的位置,M是检索到的文档总数,Precision(j)是检索到排在前j位文档的查准率,pos(j)是一个二值函数,如果排在第j位文档是相关的,其值为1,否则为0.由于P@n和MAP是0-1等级评价指标,在OHSUMED,MQ2007和MQ2008这3个具有多个评价等级的数据集上,本文实验设置完全相关作为相关文档,部分相关和不相关的文档作为不相关文档.NDCG[17](NormalizedDiscountedCumulativeGain)用来评价排序结果中顶部序列的准确性,考虑了相关性的等级和排序位置的影响.对于给定一个查询qi,第k位的NDCG值NDCG@k的计算公式为其中,r(j)表示第j个文档的相关等级.归一化参数Nr使得最优的排序的NDCG@r的值始终为1.5.1.3特征向量的生成首先,所有查询-文档对都被表示成了特征向量的形式.OHSUMED数据集共采用了45维特征,分为两个大类.第1类是基本特征,共30个,反映查询与文档之间的匹配程度,如共现词频tf=∑qi∈q∩d其变型式、文档翻转频率idf=∑qi∈q∩d及其变型形式、共现词频与文档翻转频率的乘积tf·idf=∑qi∈q∩d形式.第2类是高级特征,共25个,包括一些经典的检索模型,如BM25、LMIR等,对该查询-文档对的打分及这些打分的变型形式.TREC.Gov2003和TREC.Gov2004数据集采用了64维特征,分为4个大类:第1类是描述文档基本内容的特征,共20个.主要反映了查询与网页各组成部分之间内容匹配情况,如文档长度dl、共现词频tf、文档翻转频率idf及它们的各种组合形式.第2类是描述内容的高级特征,共24个,主要Page7是一些经典的检索模型,如BM25、LMIR等,对该查询-文档对的打分,以及这些打分的变型形式.第3类是超链接特征,共12个,主要包括PageRank、HITS等链接分析算法对该网页的打分.第4类是网络层次特征,共8个,主要反映了网页所在网络中的一些结构信息.MQ2007和MQ2008数据集采用了3大类共46维特征:第1类是20个基本内容特征,主要反映了查询与网页的各组成部分之间的匹配情况,如共现词频tf、文档翻转频率idf、文档长度dl及它们的各种组合形式.第2类是20个高级内容特征,主要是一些经典的检索模型对该查询-文档对的打分,以及这些打分的变型形式.第3类6个网络层次特征.查询-文档对表示成特征向量形式后的示意图如图1所示.每一行表示一个查询-文档对表示成的特征向量,第1列为相关程度标注,随后为特征数据.图1查询-文档对表示成特征向量形式后的示意图表3MQ2007和MQ2008数据集实验结果算法BM25算法0.33910.25430.27150.29790.29370.28480.27940.35880.25550.33990.43110.30740.25920.2340LMIR算法0.34600.27760.27580.29950.32210.28010.27050.34980.25720.32540.41730.30480.24820.2307RankSVM算法0.46150.40790.40760.44030.47410.41350.38210.47160.37120.46770.55200.43750.34360.2753RankBoost算法0.46620.41340.41830.44640.48230.41850.38620.47750.38560.46660.22550.45790.34030.2487ListNet算法0.46520.40020.41700.44400.46400.41260.37980.47750.37540.47470.23030.44510.34260.2476AdaRank.MAP算法0.45770.38210.40700.43350.43920.40540.37380.47640.37540.47940.22880.44260.34490.2454AdaRank.NDCG算法0.46020.38760.41020.43690.44750.40680.37560.48240.38260.48210.23070.45150.34540.2454SVMMAP算法0.46450.40960.41430.44390.47460.40820.38330.46960.36270.46950.22790.42730.34740.2491BordCount算法0.32520.19020.21880.25070.24880.25970.26900.39450.23680.37130.16940.29720.29030.2230LTS-JS算法0.4676-0.41820.4422-0.41320.37830.4911-0.48130.2300-0.34880.2494TopicalRSVM算法0.46100.41200.43700.4540---0.48900.3750.48300.2100---Q.D.RSVM算法0.46440.41150.41910.44630.46860.41210.39330.47560.37370.47350.55450.44000.34490.2759RankAgg.NDCG算法0.47100.41390.44770.45520.48680.42480.40640.49540.38850.48970.56040.45140.35940.27045.1.4基准算法本文实验共使用12种基准算法,分别为:经典的无监督排序BM25算法[21]和LMIR算法[22];基于监督学习的Regression排序算法;基于有序对的RankSVM算法[2]、RankBoost算法[3]和FRank算法[4];基于列表的ListNet算法[5]和直接优化评价指标的AdaRank算法[6]和SVMMAP算法[7].此外,与查询相关排序学习LTS-JS算法[12],排序融合BordaCount算法、TopicalRSVM算法[15]和Q.D.RSVM算法[23]也被选作为基准算法.所有的基准算法实验结果都来自于基准数据集LETOR网站或已发表论文,具有较高的权威性.5.2实验结果5.2.1实验参数设置本文提出的直接优化性能指标的多排序模型融合方法包括以下2个参数,即使用梯度上升算法优化直接优化排序性能融合函数时的收敛速率η和迭代次数n.本文分别经验设置收敛速率η=0.01,迭代次数n=1000次.5.2.2实验结果展示本文所有实验均使用5折交叉验证方法验证排序模型的性能.表3~表5是本文提出的RankAgg.NDCG算法和各个基准算法在MQ2007、MQ2008、TREC2003、TREC2004和OHSUMED数据集上的性能结果比较表.对比表中的实验结果,使用直接优化性能指标的多排序模型融合方法,在P@n、MAP和NDCG3种性能评估指标下,即排序的整体性能和顶部序列的准确性,均取得比基准算法更好的性能.Page8表4TREC2003和TREC2004数据集实验结果算法BM25算法0.42640.35780.49850.51300.35780.15160.09080.38760.36000.44170.46740.36000.14930.1053LMIR算法0.38660.30220.46170.48470.30220.13820.08920.37290.30670.43570.47140.30670.14310.1102Regression算法0.43400.39560.49570.52880.39560.16890.11600.41590.37330.51740.53450.37330.20000.1387RankSVM算法0.56640.53110.64660.65140.53110.21510.12800.51670.49780.62360.62760.49780.21960.1471RankBoost算法0.55590.51560.63340.64540.51560.19910.12310.48350.48000.62960.59490.48000.22310.1516FRank算法0.52550.49780.59480.61410.49780.20000.11650.50710.52440.58670.60810.52440.22040.1484ListNet算法0.57690.56220.65110.66250.56220.20930.13310.52830.49780.63280.63830.49780.22490.1498AdaRank.MAP算法0.55920.52440.62540.63650.52440.18890.11690.52090.50220.63960.63700.50220.22580.1440AdaRank.NDCG算法0.55090.54440.61310.62560.54440.18670.11780.50400.50670.61850.62010.50670.22490.1449SVMMAP算法0.55780.53110.63740.64170.53110.17960.11980.52820.48000.59950.63490.48000.21960.1462LTS-JS算法0.5705-0.64840.6959-0.18430.10800.5397-0.62860.6265-0.22040.1413TopicalRSVM算法0.56800.57800.66500.6830---0.53200.48200.60800.6150---Q.D.RSVM算法0.56670.54780.66500.65810.54780.21640.13230.53690.51560.64430.64100.51560.22490.1449RankAgg.NDCG算法0.57830.58000.67570.66920.58000.21930.13340.53850.52000.65210.65000.52000.23200.1462表5OHSUMED数据集实验结果BM25算法LMIR算法Regression算法RankSVM算法RankBoost算法FRank算法ListNet算法AdaRank.MAP算法0.44870.53880.46130.44290.63380.56740.4976AdaRank.NDCG算法0.44980.53300.46730.44960.67190.57670.5087SVMMAP算法Q.D.RSVM算法RankAgg.NDCG算法0.44980.58670.48260.46040.68830.57590.5152为了进一步验证多查询相关排序模型融合算法的优越性,本文对RankAgg.NDCG算法相比于基准算法的性能提升进行了显著性检验(T-test),发现绝大多数p-value值均小于0.05.这说明在这个实验中,本文提出的直接优化性能指标的多排序模型融合方法在统计意义上要优于其他基准算法.5.3实验分析5.3.1实验结果统计分析本文将所有算法的每一折实验结果散射到一张二维平面图上统计分析实验结果.将本文提出的RankAgg.NDCG算法的实验结果散射到x轴,将基准算法的实验结果散射到y轴,并一一对应匹配成对(x,y).直线y=x为比较分割线.当点(x,y)位于比较分割线y=x下方时,说明本文方法的实验结果优于基准算法的实验结果;当点(x,y)位于比较分割线y=x下方时,说明本文方法的实验结果劣于基准算法的实验结果.图2中绝大部分的(x,y)点都位于比较分割线y=x下方,即在绝大部分的实验结果中,本文提出的RankAgg.NDCG算OHSUMED数据集法的实验结果优于基准算法.虽然仍有少量点位于比较分割线y=x上方,但从数量和幅度(点到y=x的垂直距离)上看,都小于位于y=x下方的点.图2直接优化性能指标的多排序模型融合方法与5.3.2算法性能比较为了分析比较RankAgg.NDCG算法和多种基Page9准算法之间的性能优劣,本文定义一种算法‘打败’另一种算法的次数作为评价方法,称之为‘WinNumber’.WinNumber定义如下:Ci(E)=∑m其中,m是数据集的个数,n是算法的个数.对于所有算法在所有数据集上的性能都要比较.E(i,j)是第i种算法在第j个数据集上的性能比较.C{E(i,j)>E(k,j)}是一个是一个0-1计数函数.C{E(i,j)>E(k,j)}=1,E(i,j)>E(k,j)显而易见,当C{E(i,j)>E(k,j)}越大,第i种算法越好.所有算法的WinNumber对比图如图3所示.图3显示出:图3各种算法之间WinNumber比较图5.3.3算法有效性分析本节以OHSUMED数据集为例,分析RankAgg.NDCG算法性能提升的原因.RankAgg.NDCG模型与传统排序学习模型的区别主要在于融合过程为不同子模型赋予了不同权重,而传统方法一致对待这些权重.前文第2节排序学习中查询间的差异分析表1中提到,使用查询5建立的单个查询排序模型预测未知查询的MAP值要高于单个查询排序模型的平均MAP值,而使用查询49建立的单个查询排序模型预测未知查询的MAP值则要低于单个查询排序模型的平均MAP值.通过分析融合模型参数后发现,融合模型显著增大了由查询5及其相关文档建立的子模型的权重,降低了由查询49及其相关文档建立的子模型的权重,如表6所示.即直接优化性能指标的多排序模型融合方法增大的是排序性(1)对比各种基准算法,基于监督学习的排序学习算法明显优于两种无监督排序算法.在各种建立单一排序模型排序学习算法中,基于列表的排序学习算法性能最优.(2)基准算法中3种排序模型融合算法和本文提出的RankAgg.NDCG算法的WinNumber值高于其他基准算法的WinNumber值,证明在排序过程中考虑查询差异的有效性.(3)本文提出的RankAgg.NDCG算法的WinNumber值高于基准算法中3种排序模型融合算法的WinNumber值,表明本文提出的算法具有更好的排序性能.更进一步,本文方法在NDCG上的优势更为明显,表明直接优化性能指标NDCG的融合函数设计合理且有效.能较好的那些查询的权重,并因此导致整体排序性能的提升.单个查询排序模型(查询5建立)0.4352680.211912单个查询排序模型(查询49建立)0.276690-0.0745995.3.4算法时间代价分析本文提出的直接优化性能指标的多排序模型融合方法的时间复杂度主要由子模型建立过程和融合过程两大部分组成.相比于融合过程,子模型建立的过程由于样本数量较少,其时间相比于融合过程可忽略不计.因此,直接优化性能指标的多排序模型融合方法的时间代价主要由融合函数产生.直接优化排序性能融合方法使用梯度上升方法Page10优化,与参与训练的查询-文档对个数的成正比,与每个查询-文档对特征维数成正比,与迭代次数成正比.因此,直接优化排序性能融合方法整体时间复杂度与同类型传统排序学习算法仍在同一量级.6结束语本文对信息检索排序任务中不同查询及其对应文档之间的差异性进行了分析,并在排序模型建立过程中考虑这些差异,提出了基于监督学习的多排序模型融合方法.更进一步,针对排序问题的特性,本文提出一种直接优化排序性能的融合函数融合子排序模型.本文证明了直接优化排序性能的融合函数融合子排序模型的性能优于子排序模型线性合并的性能.在文本检索、网页检索和大规模文档检索等应用上的实验结果表明,使用本文提出的直接优化性能指标的多排序模型融合方法可以取得比传统排序学习模型更好的性能.本文提出的多模型融合思想除排序学习之外,还可应用于多类分类、序列标注等问题,在文本分类、信息检索、网络搜索等领域具有广泛的应用前景.
