Page1最小代价路径标签传播算法汪西莉蔺洪帅(陕西师范大学计算机科学学院西安710119)摘要现有的半监督分类方法由于时间复杂度较高等原因无法用于稍大规模的图像分类.该文根据聚类假设,通过寻找标签在图中进行传播的最主要路径,即最小代价路径,提出了最小代价路径标签传播算法(MinimumCostPathLabelPropagation,MCPLP).该算法通过变形的最小生成树得到无标记样本到标记样本间的最小代价路径,使标记沿着节点间代价最小的路径传播来实现分类,每个节点仅需被传播一次就能得到它们的标记.同时发现本文算法以及其他这类基于图的标签传播半监督分类方法由于构建的稀疏图存在图的连通性问题,导致可能出现标签不能被传播到所有节点,即存在数据不能被分类的情况.我们研究了图的双向不连通问题和图的单向不连通问题(非对称图),提出构建稀疏对称矩阵增强图的连通性以及对未分类数据进行再次分类的方法,解决由连通性带来的数据不能被全部分类的问题.分析及实验结果表明提出的MCPLP算法不仅具有较低的时间复杂度,而且有较高的分类正确率.通过对大规模图像的分类实验,验证了MCPLP算法同样适合于大规模的图像数据分类.关键词基于图的半监督分类;最小代价路径;图的连通性;最小生成树;图像分类1引言半监督学习①(Semi-SupervisedLearning,SSL)是机器学习和模式识别领域的一个研究热点.在实际应用中,对数据进行标记通常代价高昂,因此被标记的数据往往稀少而且昂贵.由于半监督分类在利用已标记信息进行分类的过程中能够充分利用无标记样本中隐藏的信息,所以备受研究者关注.基于图的半监督分类是半监督分类领域一个重要的方面,因其拥有坚实的理论基础和分类准确性高等特点被人们所重视.基于图的半监督分类方法实质上是进行标签的传播[1],这类方法选择不同的方式构图,图中节点代表数据,边代表所连接的两个节点间的相似性关系,定义距离函数计算数据间的相似性,通过图中数据的几何结构,采用不同的方法对数据的标签进行传播.不同的方法在构图和传播方式上存在不同,当采用相同的构图方式时,各算法在分类时间复杂度上有所不同,但普遍较高,例如对于c个类别n个样本的问题,采用TikhonovRegularization、ManifoldRegularization[2]、SGT(SpectralGraphTransducer)[3]等算法的分类时间复杂度为O(n3),而采用Mincut[4]、GaussianRandomFieldsandHarmonicFunctions[5]、LocalandGlobalConsistency法的分类时间复杂度为O(cn2).接下来讨论各半监督分类方法时,假设其构图方式相同,故其时间复杂度仅指分类部分的时间复杂度.为了降低基于图的半监督分类方法的时间复杂度,Delalleu等人[8]利用样本集中的少量样本组成子集构图,并提出一种非参数的标签预测方式使样本的标签可以根据该子集进行预测,将算法的分类时间复杂度降低到了O(n2/m2),m表示样本子集的规模,且nm.Liu等人[9]提出AGR(Anchor-GraphRegularization)算法通过寻找数据的聚类中心,建立数据集与类中心相结合的相似性矩阵,计算缩小的拉普拉斯图,将算法的分类时间复杂度进一步缩小到了O(m2n),m代表聚类中心数目.2014年Kim和Choi[10]提出了极小极大标签传播算法(MinimaxLabelPropagation,MMLP),该算法在传播过程中不断判断图中节点间路径的距离,阻断多数传播路径,使已标记样本的标签只沿少数重要的路径传播,该方法将时间复杂度的低限降到了O(n).虽然MMLP算法极大地降低了时间复杂度,但它忽略了由于构建稀疏图带来的连通性问题,导致某些分类问题(如图像分类)在数据规模较大的时候(如n>103)不能对所有数据进行分类.基于聚类假设的路径传播算法认为,通过高密度区域连接的节点之间往往有着相同的标记,也是标签传播的主要路径,因此一些算法(如MMLP算法)通过去除或阻断节点间的多数路径,只保留重要路径来传播标签,从而降低传播的时间复杂度.受该思想启发,我们提出了一种基于最小代价路径的标签传播算法(MinimumCostPathLabelPropagation,MCPLP).算法核心思想是:标记信息从已标记样本传播到无标记样本经过的最主要的路径不仅是通过高密度区域进行连接的路径,同时也是标签在传播过程中花费代价最小的路径,该路径存在于从图中得到的包含了无标记样本和已标记样本的最小生成树中.算法通过结合优先队列构造变形的最小生成树得到最小代价路径,进而传播标签实现半监督分类,具有较低的时间复杂度O(nk),k是节点的近邻个数.同时我们分析解决了由于稀疏图的连通性带来的数据可能不能全部被分类的问题.实验结果表明,所提方法具有较低的时间复杂度,较高的分类正确率,适于大规模数据的分类.2最小代价路径标签传播算法2.1最小代价路径标签传播设数据样本集合犡={狓i}n样本为已标记样本,其余为无标记样本.每个样本属于c个类中的一类,半监督分类的目的是得到无标记样本{狓i}n基于图的半监督分类首先对数据集犡构建一个无向连通图犌(犡,犈),图中的节点为数据集中所①http://pages.cs.wisc.edu/~jerryzhu/pub/ssl_survey_7_Page3有的数据,节点间通过边犈={(狓i,狓j)}连接.通常采用稀疏的k近邻图来构建图,由稀疏图得到的稀疏相似度矩阵节点间的虚假连接要少得多,有利于得到更真实的权重,Kim和Choi[10]也指出,稀疏矩阵能够阻止语义不相关节点间信息的传播.因而采用稀疏图既可降低运算量,又有利于提高分类精度[10].因此本文选择k近邻构建图.图中边的权值w为节点间的相似性度量,使用高斯核函数计算:带宽参数σ>0,通过图犌可以得到数据集的稀疏相似度矩阵犠.定义一个c维的实值函数犳i∈犚c作为节点狓i的标签预测函数,一个c维的二值向量狔i∈{0,1}c作为节点狓i的标记,c是类别数目.已知狓i属于第p(p∈(1,…,c))类时,犳i和狔i的第p维置1,否则置0.定义目标函数E(f),当目标函数E(f)达到最小时各个无标记样本得到各自最优的标记:定义存在于任意两个样本狓i和狓j之间的路径:Aij={犪=(a0,a1,…,am)m1,路径犪∈Aij通过若干条连续的边连接了节点狓i和狓j,路径中任一条边的代价为c(a,a+1)=w,+1,则整条路径的代价为c(犪)p=∑a+1)]p之和为则犳i=∑文献[10]分析指出:当P→时,通过低密度区域连接的路径代价越来越大,通过高密度区域连接的路径其代价越来越小.根据聚类假设:通过高密度区域连接的路径中的节点越来越具有相似的标记.当T→0时,更少的路径的代价能够代表到所有已标记样本的路径的总体代价.因此,当T→0,P→时,c(狓i)→min记样本的路径代价之和近似等于到各已标记样本的路径中代价最小的路径的代价,因此根据式(4)有式(5)表明狓i的标记应是使c(犪)p最小的已标记样本狓j的标记,因此算法目标转化为:求无标记样本狓i与所有已标记样本的最小代价路径,即样本的标签应当通过代价最小的路径进行传播.2.2基于最小生成树求最小代价路径当T→0,P→时,对任一条路径犪∈Aij,根据路径代价的定义可知c(犪)p→maxc(a,a+1),即从i到j整条路径的代价近似于这条路径中代价最大的那段路径的代价,因此为了计算方便本文使用一条路径中代价最大的那部分路径的代价代表整条路径的代价.根据最小生成树原理:在图犌(犡,犈)中,犝是犡的一个非空子集,代表最小生成树节点集合,节点u∈犝,v∈犡-犝为不在犝中的节点,若(u,v)为犌中的一条边,且边(u,v)的代价是所有直接连接到犝的边中代价最小的,则下一个加入最小生成树的节点为v,即由图犌生成的最小生成树一定是连接各个顶点的代价之和最小的边的集合.我们提出两个定理并加以证明.定理1.两个样本间的最小代价路径一定存在于包含这两个样本的最小生成树中.定理2.先加入到最小生成树中的已标记样本到树中其他节点的路径代价一定不大于后加入到树中的已标记节点到树中其他节点的路径代价.首先用反证法证明定理1:从图犌中任一无标记节点狓i开始构建一棵最小生成树犜,直至加入一个已标记节点狓j,假设狓i到狓j代价最小的路径不存在于最小生成树犜中,则必存在一条路径犪∈Aij,有c(犪)p<c(犜ij)p,这里c(犜ij)p为狓j通过最小生成树犜连接到点狓i的代价,且c(犪)p=maxc(a,a+1),c(犜ij)p=maxaτ+1)为当狓j加入到树犜之后,犜中连接狓i和狓j路径中相邻两点的代价.分两种情况证明:(1)假设的最小代价整条路径均不在最小生成树中;(2)假设的最小代价路径中的一部分在最小生成树中.第1种情况:假设c(犪)p中连接狓i的点为狓p,且狓p不在最小生成树中,则根据最小生成树的规则有c(狓i,狓p)maxc(aτ,aτ+1)=c(犜ij)p且c(狓i,狓p)c(犪)p,因此c(犪)pc(犜ij)p,与假设不符,因此定理1在第1种情况下成立.第2种情况:若c(犪)p通过不在树中的点狓pPage4(狓p≠狓j)连接到最小生成树犜中的一点狓p+1上,那么必有c(狓p,狓p+1)maxc(aτ,aτ+1)=c(犜ij)p,且c(狓p,狓p+1)maxc(犪)pc(犜ij)p,与假设不符,因此定理1在第2种情况下成立.定理1为我们提供了寻找最小代价路径的方法,即通过包含任意两点的最小生成树寻找两点间的最小代价路径.其次证明定理2.证明.假设狓j为先加入的已标记样本,后加入的已标记样本为狓z,若狓z到狓i的路径通过了节点狓j,显然有c(aiz)p=c(aij)p+c(ajz)p>c(aij)p;若狓z到狓i的路径未经过狓j,且与狓j到狓i的路径的第一个共同节点为狓p(狓p可以与狓i为同一个节点),则根据最小生成树规则有maxc(apz)maxc(apj),maxc(apj)表示树中连接狓p和狓j路径中代价最大的边的代价.这说明狓z到狓i的路径代价大于狓j到狓i的路径代价,即先加入到最小生成树中的已标记样本到树中其他节点的路径代价一定不大于后加入到树中的已标记节点到树中其他节点的路径代价.由定理2可知,最小生成树上先加入的点到狓i的代价小于等于后加入的点到狓i的代价,当最先加入的已标记样本与后加入的已标记样本节点之间加入的节点数目越多,两者之间的最小路径代价差距越大.根据定理1、2可知:如果以无标记样本狓i为起点构建的最小生成树上最先加入的已标记样本是狓j,那么狓i到所有已标记样本的最小代价路径一定是最小生成树中狓i到狓j的路径.2.3最小生成树的构建本文算法对图犌构建的最小生成树有多棵,其过程为:从任一无标记样本开始,将该样本加入树,寻找树中所有样本u与不在树中的其余样本的最小代价(u,v),将v加入树中,直到加入的是一个已标记样本为止,这一棵最小生成树建立完成,从不在任一最小生成树中的无标记样本中任选一个样本出发重复上述过程构造最小生成树,直至所有无标记样本都在某个最小生成树中,构建最小生成树过程结束.可见,这里的最小生成树算法不是构建一棵包含所有节点的最小生成树,而是建立多棵最小生成树,每棵只包含图中的部分节点.对于含有多个类别、多个已标记节点的数据集,该算法构建的最小生成树有多棵(如对于包含c个类的数据集,该算法构建的最小生成树至少有c棵).可采用Prim算法构建每棵最小生成树,但Prim算法的时间复杂度较高为O(n2),为此我们提出结合优先队列和Prim算法构建最小生成树,通过对预加入树中的节点进行排序,置于优先队列中加速搜索比较,从而减少时间开销.结合优先队列与Prim算法构建最小生成树的过程如下:从任一无标记样本狓i开始,将狓i加入最小生成树集合U中,将狓i与其k个近邻狓j(狓j∈X-U)的相似度权重wij按序加入到优先队列中.弹出优先队列的队头元素狓e,如果狓eU则将其加入最小生成树集合U中,检查其是否为已标记样本,若不是,将狓e的近邻按相似度权重加入到优先队列中重复上述过程.若是该最小生成树构造完毕,树中所有无标记样本获得标记.若还有无标记样本,任选一个无标记样本,从其出发重复上述过程.2.4图的连通性问题2.4.1稀疏图的不连通问题基于聚类假设的半监督分类算法建立在节点间构成的相似度矩阵是无向连通的基础上,但是为了提高算法的正确率和运行速度,减少不相关节点之间连接对算法的影响[11],多数算法(例如AGR、MMLP、LP等)采用稀疏图构造相似度矩阵,稀疏图不能保证图的连通性.当近邻个数较少或者数据规模较大且数据之间相互聚集时,就容易在稀疏相似性矩阵中形成若干个不连通的团簇,这时由于图不连通会导致标记不能传播到图中每个样本,从而导致有的样本不能被分类,如图1所示.图1中,白色代表第1类已标记样本,灰色代表第2类已标记样本,黑色代表无标记样本.图中每个节点只与两个最近邻节点间存在连接,导致一个稀疏的相似度矩阵形成了3个相互聚集又互不连通的团簇.若采用LP算法、MMLP算法分类,图1中的3个与任何已标记样本不存在通路的数据将不能被分类.本文3.2节的实验表明当数据集中的已标记样本较少且近邻数较少时,这种不连通现象很容易发生.2.4.2稀疏图的弱连通问题稀疏图中还存在弱连通问题:由全连接的完全Page5图可得到无向对称的相似性矩阵,但由k近邻构造的稀疏矩阵可能是非对称矩阵,即点狓i是点狓j的k个近邻中的一个,但点狓j不是点狓i的前k个近邻.此时由稀疏近邻图能找到一条从狓j到狓i的路径,但是不存在狓i到狓j的路径,即路径不是双向的,构成的不是无向对称的图,而是有向非对称图,导致稀疏近邻图中存在一些点对(狓i,狓j),可以找到从狓i到狓j的通路,但找不到从狓j到狓i的路径,或反之,我们称此为弱连通的.采用k近邻构图还可能存在弱连通问题,对这些弱连通的节点可能无法进行分类,其他文献都没有分析和解决不连通以及弱连通问题.2.4.3连通性问题的解决为了解决上述问题,基于路径的标签传播必须借助全连接的完全图或者增加近邻个数的稀疏图.增加近邻个数会提高算法构图的时间复杂度,进而增加整个分类算法的时间复杂度.从本文3.2节实验可以看出,小幅度提高稀疏矩阵的近邻个数不能保证能够解决该问题,而采用完全图又由于其中虚假连接增多,既丧失了基于路径的传播算法的时间复杂度低的优势,也不利于提高分类正确率.Liu等人[12]通过构造Symmetry-FavoredGraph使相似度矩阵对称,但该方法明显增大了图中原本对称的节点的权重.为了解决弱连通问题同时保持节点间的权重关系,我们将稀疏的相似度矩阵变成对称矩阵,同时不改变那些原本就对称的节点的权重,即定义:wij=新定义的相似度矩阵解决了稀疏图带来的弱连通问题,使标签可以在任意方向传播而不会出现有节点不能被传播到的情况.为了解决图的不连通问题,我们提出再次传播的方法:当一次传播后,对于那些仍没有进行分类的点,使用flann[13]的KD树近邻搜索算法扩大搜索那些传播不到的点的近邻,此时近邻的个数为上一次搜索时近邻个数的两倍.虽然增加了近邻数,但只是搜索某些特定数据在全部数据中的近邻,得到的是缩小了数据规模的近邻矩阵,因此不会增加太多计算量.如果增加一次近邻个数仍然有数据不能被传播到,则重复上述过程,直到每个节点都被传播到.下面给出最小代价路径标签传播(MCPLP)算法步骤:1.以所有样本为节点构建k近邻图及稀疏的相似性矩阵犠,并按照式(6)调整犠.无标记样本的标记初始化为0,已标记样本初始化为它们各自的标记.2.从任一无标记样本开始,基于优先队列和Prim算法构造最小生成树.3.当树中包含一个已标记样本时,修改这棵树上的所有节点的标记为该已标记样本的标记,并且记录这棵树上的样本为已查找过的样本.4.如果无法找到一个已标记样本,则记录这棵树上的样本为已查找过的样本,但是不更改这些样本的标记,清空这棵最小生成树.5.若有尚未查找过的无标记样本,任选一个开始,重复步2~4.直到所有无标记样本都被查找过.6.提取尚未得到标记的样本,利用flann近邻搜索算法构建稀疏相似性矩阵,此时近邻个数为上一次近邻个数的两倍.7.重复步2~6,直到所有的样本都获得标记.2.5最小代价路径标记传播算法复杂度分析提出的MCPLP算法是一个快速的半监督分类算法,该算法的时间复杂度约为O(nk).算法过程主要包括3个部分:(1)构图;(2)计算相似性矩阵,构造最小生成树进行标签传播;(3)对未传播到的数据进行再次传播.第1部分使用flann算法构建数据间的稀疏近邻图.构图的时间复杂度为O(ldnlogn)[13],这里l为flann中并行树的个数,d为数据的维数.第2部分通过式(6)构建稀疏对称矩阵的时间复杂度为O(nk).在通过优先队列寻找最小代价路径对数据进行分类的过程中,算法使用优先队列进行排序,从近邻矩阵中提取一个样本加入优先队列的时间复杂度为O(1),从优先队列中弹出一个样本并调整队列的最大时间复杂度为O(lognq),nq是队列长度,因此该最小生成树加入一个节点的最大时间复杂度近似为O(lognq),构建一棵最小生成树的最大时间复杂度为O(nqlognq),则建立所有最小生成树的最大时间复杂度为O∑这里p为树的个数,nq为树中节点的数目,由于图像特征的复杂性、空间聚集性,往往p值较大,nq值较小,而p越大,nq越小,该时间复杂度越接近O(n).因此第2部分的算法时间复杂度为O(nk).第3部分是对未分类数据进行再次传播.假定需要进行再次传播的数据规模为m,对其构图的时间复杂度为O(mk1)(k1为再次传播的数据的近邻个数),这是因为flann算法只需要在第一次构图的时候进行KD树的运算,之后查找节点的近邻时间Page6为O(mk1),对该部分数据进行再次传播的时间复杂度为O(m).因此进行再次传播的时间复杂度为O(mk1)<O(n).综上所述,MCPLP算法第1、2、3部分的时间复杂度分别为O(ldnlogn)、O(nk)、O(mk1),因此MCPLP总的算法时间复杂度为O(ldnlogn)、算法分类部分的时间复杂度为O(nk),如表1所示.构图时间复杂度第1部分O(ldnlogn)2.6MCPLP算法与LP算法、AGR算法、MMLP算法的比较各算法构图方式相同,下面不考虑构图部分的时间复杂度.LP(LabelPropagation)算法的基本思路是[7]:已标记样本的标签根据它与其他样本间的相似度通过图中的所有路径传播给所有的样本.算法从标记样本出发沿图中所有路径传播至无标记样本,其以迭代的方式传播,每个样本最终得到它们最可能的标记,其时间复杂度较高为O(cn2).AGR(AnchorGraphRegularization)[9]算法是为了解决基于图的半监督分类算法时间复杂度过高的问题而提出的算法.该算法首先对数据聚类,从聚类中提取数据的类中心并称之为锚点,建立表示锚点与数据之间特征关系的锚点图(AnchorGraph),利用拉普拉斯流形正则化算法预测锚点的标签,通过锚点的标签和锚点图进而得到每个样本的标签.AGR算法时间复杂度为O(m2n),但是AGR算法受聚类的结果影响较大,而合适的聚类数目不容易确定,导致其鲁棒性较差.MMLP算法的主要思路是从已标记样本开始,通过不断调整路径的极小极大距离判别路径中节点的标记是否应该被改变,直到所有无标记样本被传播到的标记不再改变时标记传播结束.其时间复杂度下限为O(n).MMLP以通过高密度区域的重要路径为基础,已标记样本的标签仅通过少量重要路径传递给无标记样本,与LP算法通过所有路径传播相比,MMLP具有较高的时间复杂度优势.分析和应用该算法,我们发现它在迭代传播时往往会进行路径的重复对比降低了算法效率,同时存在图的不连通和弱连通带来的数据不能被传播到问题,导致算法在很多应用中不能对数据进行完全的分类.本文提出的最小代价路径标签传播(MCPLP)算法受MMLP算法启发,也是选择最重要的路径(即代价最小的路径)传播标签从而降低算法时间复杂度.我们提出了新的寻找重要传播路径的思想和方法:从无标记样本出发构造最小生成树,通过变形的最小生成树查找代价最小的传播路径,进而对节点的标记进行传播.MCPLP算法的时间复杂度是O(nk).相比LP算法的全路径传播,MMLP和MCPLP算法均通过极少数重要的路径进行传播,因此极大地降低了算法时间复杂度.本文算法与AGR算法相比时间复杂度更低,且不像AGR算法受数据聚类数等算法参数的影响,鲁棒性更好.与MMLP算法相比,MCPLP算法明确了传播路径为最小代价路径,最小生成树构造完成后,标记随即传播至树中所有节点,每个节点只需要被标记一次.而MMLP则是通过多路传播,快速阻断不重要的传播路径减少传播量,在此过程中算法不断比较极小极大距离,据此不断修正节点标记,因此MMLP算法在重要路径定义及寻找上不及MCPLP.同时MMLP算法存在连通图可能造成数据不能全部被分类的问题,但它没有发现和解决.本文提出的MCPLP算法通过构建对称稀疏图解决图的弱连通问题,通过对首次分类后尚未分类的数据进行再次分类解决不连通问题,从而使所有数据都被传播到.因此,本文算法相比MMLP算法不仅保留了低时间复杂度的特点,还解决了算法不能分类所有数据的问题,提高了算法的分类能力,适用于大规模数据的分类.3实验与分析实验环境为Windows8.164位版本,处理器为IntelXeonE55042.0GHz,内存容量为8GB,采用Matlab和C++混合编程.实验分为两部分:(1)采用基准数据集[14],并与几个半监督分类方法进行比较;(2)采用Weizmannhorsedataset①中的图像作为实验数据,与MMLP等算法进行针对图像的半监督分类任务比较.实验中所有算法均采用相同的flann算法构图.3.1基于基准数据集的半监督分类实验实验采用7个小型的基准数据集和3个手写数字数据集USPS-7291、MNIST、MNIST-630K[10](见表2).比较方法如下:①http://www.msri.org/people/members/eranb/Page7(1)1-NN分类器.寻找每个无标记样本的最近邻已标记样本,无标记样本的标记为最近邻已标记样本的标记.(2)LP(LabelPropagation)[7].该算法中边的权重w(i,j)=exp(-β狓i-狓j为每个样本与它第10个近邻的距离的平方的均值.(3)AGR(AnchorGraphRegularization)[9].其参数s设置为3,s为每个样本的近邻锚点个数,使用LAE算法[9]计算每个样本与近邻锚点的特征关表2MCPLP算法与其他算法分类错误率数据集g241cg241dDigit1COILCOIL2USPS-7291MNISTMNIST-630K数据集g241cg241dDigit1COILCOIL2USPS-7291MNISTMNIST-630K表3MCPLP算法与其他算法运行时间表2加粗数据显示了各数据集在实验中的最好分类结果,MCPLP算法在大部分数据集中的表现比较好,但对某些数据集中也存在较高的错误率(如g241c和g241d),主要是因为数据集中不同类之间存在着较为密集的重叠分布,导致紧凑的路径中含有不同的类,因此影响了数据分类的效果.MCPLP算法解决了弱连通和不连通带来的问题,结果显示其比MMLP算法分类正确率高.与LP和AGR相比,MCPLP算法不存在参数设定等影响,因此更加灵活.LP适合数据规模较小情况下的分类,由于标签传播了所有路径,在大部分数据集中都能保持较好的分类效果,但随着数据规模的增加,LP算法的运算时间增长速度较快,数据集MNIST-630K中LP算法因为运算时间过久(超过3600s)其分类结果和运行时间未列出.MCPLP算法在大部分数据系矩阵,γ=0.01.(4)MMLP(MinimaxLabelPropagation)[10].实验中所有算法均使用数据集给定的10组不同的已标记样本进行10次实验,每组已标记样本为100个,其中MNIST和MNIST-630K的已标记样本均为1000个,取10次结果的均值作为实验结果.表2列出了上述所有算法的分类错误率,表3给出所有算法的完整运行时间(包括构图).其中所有数据的近邻个数均设定为20.LP47.0445.182.4213.055.4146.944.294.544.21—LP1.291.161.121.090.890.150.939.38667.10—集的分类实验中分类正确率均比AGR算法高,不过从g241c可以看出,AGR适用于某些数据集.AGR算法可能需要更多的锚点来提升算法的正确率,但这会增加运算时间,而且由于较高的复杂度不适于大规模数据.1-NN算法比较简单,标记样本的分布和数量影响了分类结果和时间.MCPLP和MMLP算法都是基于聚类假设的路径传播算法,具有相近的时间复杂度,表3的结果表明了这一点.MCPLP算法要解决图的弱连通和不连通问题,需要的时间比MMLP算法稍多,但是由于MCPLP中标记只经过一条路径传播,而MMLP要多次比较距离和修正标记,总的来说本文算法和MMLP算法花费的时间差别不大.MMLP和MCPLP算法比AGR和LP算法时间复杂度低,数据的规模越大其时间差距越明显.总Page8之,MCPLP算法比LP算法、AGR算法时间复杂度低,和MMLP算法的运算时间相近,同时可以完成对所有数据的分类,适合大规模数据的分类.3.2连通性问题实验实验针对本文提出的稀疏相似度矩阵中存在不连通或弱连通的问题进行验证.采用上述实验所用的7个小型数据集.已标记样本由原来的100个改为10个,近邻个数为20个,选择10组不同的已标记样本进行分类并给出分类结果的均值,所有结果均向上取整.表4给出MMLP的未分类点数和MCPLP算法在第1次分类之后未分类的点数.数据集g241c15002g241d15002Digit115002COILCOIL215002BCIText图2给出对COIL数据集,已标记样本固定,改变近邻个数时MMLP未分类的样本数和MCPLP算法首次未分类样本数的对比图,所有结果均为进行10次实验的均值且向上取整.从表4可以看出MCPLP算法在首次分类后没被分类的数据明显少于MMLP算法,这是因为MCPLP解决了稀疏相似度矩阵中的弱连通问题,使得图中的节点双向连通,减少了不能被分类的样本数目.而MMLP算法不仅不能对那些与已标记样本完全不连通的无标记样本进行分类,而且因为弱连通问题找不到从无标记样本到标记样本的路径,导致一些样本不能进行分类.由图2可以看出当近邻数目减少时,MMLP算法由于相似度矩阵的连通性较差而导致不能分类的样本数增多.当近邻个数增加后,不能分类的样本逐渐减少,其减少的速度逐渐降低.当近邻个数为60的时候,MCPLP算法的首次未分类样本数为0,当近邻个数为70的时候,MMLP能够对所有样本进行分类.当k<20时增加近邻数,MMLP未分类的样本数和MCPLP算法首次未分类的样本数下降较快;当k>20后增加近邻数,对两个算法降低未分类的样本数的影响都小了,同时近邻个数的增加会使构图和分类时间复杂度大幅度提升,还可能增加相似度矩阵中错误连接的数量,因此近邻个数k不宜过大.3.3节的实验也表明对于大规模数据单纯增加近邻个数并不能使数据得到完全的分类,这表明MCPLP算法采用再次传播处理不连通问题的必要性.3.3图像分类实验下面给出本文算法和MMLP算法对图像分类的实验结果和分析.实验采用Weizmannhorsedataset中的图像,将每幅图像分为两类,目标是不同姿态、颜色均匀或不完全均匀的马,其余为复杂程度不同的背景.实验分为两部分:第1部分利用所有图像数据构图.由于对大规模图像利用所有数据构图进行分类导致算法时间和空间代价高,甚至于无法进行分类,因此第2部分通过约减数据的方法对图像分类,即首先对图像聚类,从每个聚类中提取若干数据作为该聚类的代表点,得到约减的数据集合,然后利用这个缩小了规模的约减数据集进行半监督分类,进而得到原始图像各个聚类中像素的类别.3.3.1基于完整图像的半监督图像分类实验对于图像这种节点数多且邻近节点间有着相同或相似特征的情况,如果相似度矩阵是稀疏的,则容易产生图1所示的不连通情况,从而导致MMLP算法中标签无法传播到所有的节点,本文算法也因此需要对首次未分类的数据进行再次分类.本节实验结果验证了这一点,图3给出了MCPLP和MMLP算法的图像分类结果,表5列出了算法完整运行时间和正确率.表5MCPLP与MMLP算法图像分类时间和正确率图像大小040475×35341.1294.56112800×600133.6369.58146479×37532.4179.072031600×1094795.9155.25607875181502×40849.2586.59243800×600142.5595.291592000×1816—Page9图3不同规模图像的MMLP和MCPLP的分类结果实验通过划线法获得已标记样本,每幅图像的已标记样本数量均固定为600个,每类300个.为了减少不连通现象对算法的影响,将近邻个数由原来的20个增加到80个.结果中未能被分类的数据被标记为红色(255,0,0),以区分图像中的目标(白色:255,255,255)和背景(黑色:0,0,0).从图3的112、146、203可以看出,对于背景较为杂乱的图像MMLP的分类效果均不理想,Page10MCPLP的分类效果较MMLP有明显的提升.本文算法和MMLP均可以执行数据规模较大(图像203)的图像分类实验.MMLP由于受构图所形成的稀疏矩阵的连通性的影响,图的规模越大,图像中越多的像素不能被分类,图像203相比其他图像有大量未分类的红色区域证明了该问题.各幅图像未能进行分类的红色区域大多比较集中,区域中像素的特征十分相近,这也说明了它们因为互为各自的近邻,导致了稀疏近邻图中不连通区域的形成,而无法进行分类.图像159因数据量大受机器内存限制无法求取近邻矩阵,因此无法进行分类.从表4可以看出:虽然大幅度提升了近邻个数(从20个到80个),MMLP算法仍有很多像素不能被分类.像素规模越大、图的复杂程度越高,MMLP不能分类的像素数也越多.本文算法比MMLP算法分类正确率高,这不仅得益于本文方法能完全分类,也因为通过最小代价路径传播标签降低了在复图4本文方法和改进的AGR方法以及约减数据MMLP方法分类结果杂图像数据中通过错误路径传播的可能性.3.3.2基于数据约减的半监督图像分类随着图像规模的增加,以图像像素为节点构图在时间和空间复杂度上的增加导致无法对图像进行分类,下面对图像数据先进行约减后再分类.本文算法将和结合Meanshift的AGR算法以及与约减的MMLP算法(通过Meanshift聚类,从每个聚类中抽取若干数据代表该聚类组成约减的数据子集,通过对该数据子集进行分类从而得到原始图像中每个像素所属聚类的分类类别,进而得到所有数据的分类)进行对比.这里Meanshift的参数(hr,hs)为(16,8),所有方法均使用相同的约减数据集进行分类,每幅图像的已标记样本数量均固定为600个,算法的近邻个数都为20个.其中AGR算法使用每个聚类的聚类中心作为锚点.图4给出了3种方法的实验结果,表6给出了它们各自对应的分类时间和正确率.Page11表6本文方法与对比方法的分类时间和正确率图像040112146203181243159从图像146、203和181可见,本文算法比改进的AGR算法在图像的小范围区域的分类能力更好一点,对边缘的刻画能力也比较突出.从表6可见,本文算法比改进的AGR算法正确率更高、时间更短.由于数据规模的减小,MMLP算法中所有的无标记样本都得了分类,但是本文方法在分类正确率上普遍优于MMLP算法,体现了本文方法在约减图像上分类的能力.本文算法在分类时间上和MMLP算法相近.总的来说,本文所提方法用于大规模图像分类是可行的且具有时间和正确率上的优势.通过表6与表5可见,使用约减的数据集并结合MCPLP算法能够在大规模图像上有更好的分类效果,需要的近邻个数更少、所用分类时间更短,表明本文算法能运用于大规模数据分类.通过图4与图3中MMLP及MCPLP的实验结果可以看出,对大规模图像数据约减之后再进行分类不仅提高了待分类数据间的连通性,使得MMLP能进行完全的分类,也提高了MCPLP算法对图像数据的分类正确率,因此数据约减可用于各方法并适用于大规模的图像数据.4结论我们提出了一种最小代价路径标签传播算法(MCPLP).和其他半监督分类算法不同,该算法从无标记样本出发寻找到标记样本的路径,采用优先队列和Prim算法构建变形的最小生成树,找到无标记样本到标记样本的最小代价路径,沿该路径传播标签,同时发现和解决了基于路径传播的半监督分类方法因为采用稀疏近邻图带来的数据不能全部被分类的问题.MCPLP算法具有线性的时间复杂度,能够解决由于数据规模大而导致的分类困难问题.和多路径传播的算法相比该算法仅沿着一条最小代价路径传播标签,因而分类速度比大多数半监督分类算法快.本文97.9297.7295.7596.0595.5397.3298.83分析各半监督标记传播方法可见,数据规模增加会大大增加构图的复杂度,后续将研究分层构图及分类的可能性,以及最小代价路径的代价作为非近邻节点的相似性度量的可能性.
