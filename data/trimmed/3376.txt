Page1一种基于图像分割及邻域限制与放松的立体匹配方法伍春洪付国亮(北京科技大学自动化学院北京100083)(北京科技大学钢铁流程先进控制教育部重点实验室北京100083)摘要提出了一种以K-均值分割为基础的立体匹配方法.该方法不仅可以根据图像的内容自动调整匹配窗口的形状,还可实现对参与匹配窗口的大小、数目和权重的智能调节.作者采用K-均值分割方法精确定位物体边界,保证匹配窗口位于同一物体内部;邻域限制与放松可以进一步根据图像内容灵活地运用匹配窗口周围的环境信息;两种方法的结合有效地提高了匹配过程中窗口选取的智能性.在国际立体视觉标准平台Middlebury网站中测试的结果证实该算法提取的深度图的错误率低于其它局部优化算法,接近全局优化算法,运行效率高于现有的全局优化算法,综合性能是出众的.关键词立体匹配;邻域限制与放松;K-均值分割;邻域权重设置;遮挡处理1引言立体视觉技术在三维测量、虚拟现实以及机器人导航等许多领域都极具应用价值,自20世纪60年代中期诞生以来就深受关注.经过多年的研究,立体视觉的发展虽然取得了不少进步,但远未达到成熟阶段[1-2].在立体匹配过程中缺少人类的智能来面对Page2各种不同环境是制约立体视觉技术发展的关键因素.当前,立体匹配的主要问题在于如何根据图像的内容灵活地选取匹配窗口的形状和大小,对缺少纹理的区域如何寻找对应点以及对遮挡区域如何处理这几个问题上[1-4].本文针对以上问题,提出一种以K-均值分割为基础的立体匹配方法.该方法采用K-均值分割方法来精确定位物体边界,保证匹配窗口位于同一物体内部;同时采用邻域限制与放松进一步根据图像内容灵活地运用匹配窗口周围的环境信息;两种方法的有机结合有效地提高了匹配过程中窗口选取的智能性.不仅可以根据图像的内容自动调整匹配窗口的形状,还可实现对参与匹配的窗口的大小、数目和权重的智能调节.在国际立体视觉标准平台Middlebury网站中测试的结果证实本算法提取的深度图的错误率低于其它局部优化算法,接近全局优化算法.运行效率高于现有的全局优化算法,综合性能是出众的.本文第2节介绍算法的基本框架;第3节介绍K-均值分割方法;第4节介绍遮挡区域的检测;第5节介绍邻域权重的设置;第6节用Middlbebury标准图像数据库对本算法进行测试,并和现有算法进行比较;最后给出结论.2算法整体框架本算法以邻域限制和放松(NeighhoodCon-straintandRelaxation,NCR)的多窗口匹配算法为基本框架[5-7].NCR算法的依据是空间一致规则,即深度空间是分段连续的.设Bi,j为待匹配的子窗口,Bk,l为Bi,j的邻域,称为邻域子窗口,如图1所示.在分析区域Bi,j视差时,若将相邻区域Bk,l∈B的视差也考虑进来,可以取得更加可靠的结果[6-7].考虑邻域后视差分析的记分函数可表示为score(Bi,j,d)=SSD(Bi,j,d)+∑Bk,l∈Ν(Bi,j)w(Bk,l,Bi,j)SSD(Bk,l,d)其中,w(Bk,l,Bi,j)为对应不同邻域块的权重因子.权重因子可以根据邻域块到待匹配块的距离、邻域块和待匹配块的相似度、邻域块自身的可信度等几个因素来确定.通过权重因子的设置可以灵活地调整邻域子窗口在匹配过程中对记分函数的贡献.权重因子的设置将在第5节中具体讨论.考虑到邻域块和待匹配块深度相近但并不一定相同,邻域放松进一步允许邻域块和待匹配块有一个小的深度变化δ,以此来增加匹配的适应性.考虑邻域放松因素后的代价函数可修正为score(Bi,j,d)(=SSD(Bi,j,d)+∑Bk,l∈Ν(Bi,j)w(Bk,l,Bi,j)minδ(1+∑Bk,l∈Ν(Bi,j)w(Bk,l,Bi,j式(2)是完整的NCR代价函数.邻域限制是通过考虑周围邻域的记分而实现的,邻域放松是通过允许邻域的深度和中心块的深度在一定范围内变化实现的.最后期望的视差值在代价函数取最小值时获得[6-7].以往NCR算法的子窗口是固定的正方形,因此在匹配过程中往往会有部分子窗口跨在不同物体上(深度不连续区域),从而使得空间连续性条件不再满足.为解决这一问题,我们首先使用K-均值分割对源图像进行分割,再将分割后的结果作为传统NCR算法中的子窗口.3犓-均值分割K均值聚类的基本思想是:首先随机选取K个点作为初始聚类中心,计算各个样本到聚类中心的距离,把样本归属到离它最近的那个聚类中心所在的类;然后对调整后的新类计算新的聚类中心,重新聚类,如此反复的操作,直到相邻两次的聚类中心的变化在一定范围内时聚类结束[8-11].本文采用的初始聚类中心是如下设置的:首先将图像分成等大小正方形区域,以每个正方形块为初始类,该类的颜色为每个正方形块内像素的颜色均值,空间位置为每个正方形块的中心位置.本文的聚类过程是根据计算每个像素点属于各个类的概率来实现的.像素点属于某个类的概率通过下式来计算:Page3probability=(exp-color_distance2其中,color_distance表示像素点与聚类中心在颜色空间中的距离,spatial_distance表示像素点与聚类中心在空间分布上的距离,b是初始正方形块的边长,Δ为分割块内的颜色粗糙度,λ用来控制颜色和空间距离对聚类影响的程度.图2为采用K-均值分割对Middlebury平台的标准图像Cone及Teddy分割后的结果.从图中可以看出,没有分割块跨在不同的物体上.4遮挡区域的检测由于遮挡区域没有相对应的匹配区域,对这些区域进行匹配将没有意义.而且遮挡区域还会严重影响其邻近非遮挡区域的匹配.因此,需要将遮挡区域标记出来,去除这部分区域在匹配时的不良影响.在遮挡区域的检测方面,目前较有效的方法是基于像素点的左右匹配一致性的检测方法[12-14].基于左右匹配一致性的遮挡检测方法的基本思想是:分别以左、右视图为匹配的基准得到两幅视差图(分别称为左视差图和右视差图);然后先以左图中区域A出发,根据左视差图在右图中找到其对应匹配区域为B,再以右图中B区域为已知量,根据右视差图回到左图中去寻找其对应的区域,若对应区域仍为A,那么我们称区域AB是相互一致的.相互一致用数学形式可表示为这里,DL(A)和DR(B)分别表示区域A在左视差图和区域B在右视差图的视差.考虑实际匹配过程中存在一定误差,令delta=DL(A)+DR(B).若delta的绝对值小于一定范围,即可认为区域AB是相互一致的.5邻域权重的设置采用K-均值对源图像进行分割以后,可以保证分割后的子窗口位于同一物体之内.接下来就可以以这些分割后的子窗口为基础,结合相关邻域的信息进行匹配.其中权重因子需要根据邻域子窗口的内容及和待匹配子窗口的关系来调整.本节讨论如何根据图像的具体内容设置邻域权重因子.首先,邻域分割块与中心分割块颜色越接近,其属于同一物体的可能性越大,彼此深度一致的可能性就越大;同样,邻域分割块与中心分割块在空间上越接近,其深度一致的可能性也就越大[15].基于这两方面的考虑,我们将邻域分割块的权重设置为颜色距离权重和空间距离权重之积.w(Bi,j,Bk,l)=wc×wd=exp-color_dis(Bk,l,Bi,j)烅烄烆这里,color_dis(Bk,l,Bi,j)是块Bk,l的平均颜色和块Bi,j的平均颜色在颜色空间的距离,spatial_dis(Bk,l,Bi,j)是块Bk,l的中心和块Bi,j的中心的欧式距离,n为邻域的个数,σ,b为常量.除了对分割块进行颜色、空间权重设置之外,还需对分割块进行可信度的设置.可信度的设置是依据匹配块内的颜色粗糙程度和是否为遮挡区域设定的[6-7].匹配块内的颜色粗糙程度越高,所含的匹配信息越丰富,匹配结果的可信度就越大.对于遮挡区域的可信度可以直接设为0.设置权重因子后的代价函数如下:score(Bi,j,犱)=SSD(Bi,j,犱)×Ri,j∑Bk,l∈Ν(Bi,j)w(Bk,l,Bi,j)×Rk,lminδ(Ri,j+∑Bk,l∈Ν(Bi,j)w(Bk,l,Bi,j)×Rk,这里,Rk,l表示邻域分割块Bk,l的可信度,Rk,l∈[0,1].6实验我们分别将本文算法用于Middlebury平台中的四组标准图像对Tsukuba,Venus,Cone,TeddyPage4上,并将结果与同类算法进行了比较.本文所列出的各类算法的性能数据均引用自Scharsteia和Szeliki的立体平台网站(vision.middlebury.edu/stereo).6.1本算法测试结果图3为应用本算法对Middlebury平台中的图3采用本算法对Middlebury平台4组标准图像进行深度提取的结果表1采用Middlebury平台对本算法提取结果的定量评估图像名称Tsukuba1.611.390.248.0210.230.82Venus1.030.860.854.1810.20.49Cone5.643.622.2613.5963.074.45Teddy10.226.9912.6412.0485.975.25注:all表示所有的区域,non-occ表示非遮挡区域,untex.表示纹理稀少区域,disc.表示深度不连续区域,occl.表示遮挡区域.匹配结果相差2pixel以上认为匹配错.4组标准图像对进行深度提取的结果.4组图像采用的参数相同(b=7,n=48,λ=3,σ=1).表1给出了采用Middlebury标准平台对4幅深度图进行定量评估的结果.6.2同类算法的比较本文算法属于局部优化算法,同类算法中较有代表性的有变换窗口最小值滤波算法(SSD+MF)[2]、实时相关匹配算法(Realtimecorrela-tion)[16]、紧凑窗口算法(Compactwindows)[17]、可变窗口算法(Variablewindows)[3].从表2同类算法错误百分比的数据比较中可以看出,本算法的各项错误率均明显低于同类算法.Page5表2同类算法错误百分比比较本文算法1.610.248.021.030.864.180.570.155.04Var.Win.2.351.6512.171.231.1613.351.280.237.09Comp.win.3.373.5412.911.672.1812.331.610.457.87Realtime4.254.4715.051.531.812.331.320.359.21SSD+MF5.235.824.663.746.2812.942.210.7213.976.3与现有性能最优算法的比较目前排在平台前几名的算法多为全局优化算法.它们分别是Klaus和Sormann提出的Adapt-ingBP算法[18]、Yng等人提出的doubleBP算表3与目前平台上性能最优算法错误百分比比较本文算法1.391.618.020.861.034.185.607.6413.66.9910.212.0AdaptingBP1.111.375.790.010.211.444.227.0611.82.487.927.32DoubleBP0.881.294.760.140.602.003.558.719.702.909.247.82OverSegmBP1.691.978.470.500.684.696.7411.915.83.198.818.89AdaptWeight1.381.856.900.711.196.137.8813.318.63.979.798.26在Tsukuba和Venus两幅图像上,本文算法与上述最优算法接近.但在Cone以及Teddy两幅图像上,本文算法的错误百分比要略高于平台上的最优算法.然而,上述基于全局优化的算法在匹配阶段都需要多次迭代,计算复杂度高,计算时间较长.AdaptWeight算法虽然不需要迭代,但它每次只能计算一个像素点的视差,计算效率相当低.以上几种算法中只有Zitnick的OverSegmentBP算法在论文中给出了具体的运行时间和环境参数(CPU2.8GHz,匹配阶段运行时间40s)[10].本文在同等条件下的匹配过程只需要5s左右.7结论从以上实验数据及分析可以看出,本算法提取的深度图的错误率低于局部优化算法,接近全局优化算法.但是,运行效率高于现有的全局优化算法.在综合性能方面是出众的.
