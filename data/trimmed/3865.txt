Page1基于统计模型及SVM的低速率语音编码QIM隐写检测李松斌1),3)黄永峰1)卢记仓2)1)(清华大学电子工程系北京100084)2)(解放军信息工程大学网络工程系郑州450002)3)(中国科学院声学研究所南海研究站海口570105)摘要QIM(QuantizationIndexModulation,量化索引调制)隐写在标量或矢量量化时嵌入机密信息,可在语音压缩编码过程中进行高隐蔽性的信息隐藏,文中试图对该种隐写进行检测.文中发现该种隐写将导致压缩语音流中的音素分布特性发生改变,提出了音素向量空间模型和音素状态转移模型对音素分布特性进行了量化表示.基于所得量化特征并结合SVM(SupportVectorMachine,支持向量机)构建了隐写检测器.针对典型的低速率语音编码标准G.729以及G.723.1的实验表明,文中方法性能远优于现有检测方法,实现了对QIM隐写的快速准确检测.关键词QIM隐写;隐写检测;低速率语音编码器;音素分布特性1引言VoIP(VoiceoverIP)是非常流行的流媒体通信服务,在全球范围内得到了广泛应用,彻底变革了语音通信市场格局.由VoIP带来的语音数据流具有量大且实时瞬态等特征,非常适合作为信息隐藏载体,这使VoIP很可能被用于在IP网络中进行隐蔽通信[1].当前在语音中进行信息隐藏的方法可大致分为以下几类:(1)针对脉冲编码调制语音数据的最低有效位替换或匹配方法[2];(2)变换域方法,该方法先将载体数据变换到变换域,然后通过在变换域修改一些参数实现机密信息的嵌入,常用的变换包括倒谱变换[3]、离散余弦变换[4]、离散小波变换[5]等;(3)基于量化索引调制(QuantizationIndexModulation,QIM)的方法,该方法由Chen等人[6]提出,适用于包含矢量量化的数字音频、图像和视频编码,可用于在压缩编码过程中进行信息隐藏;(4)一些针对特定压缩语音标准的信息隐藏方法,例如,最近文献[7]提出了一种在G.723.1码流的静音帧中嵌入机密信息的方法.QIM隐写的基本思想是将量化码本分组.假设原量化码书为C,将其分为C1和C2两部分,满足C1∩C2=且C1∪C2=C,C1和C2分别代表比特“0”和“1”;当嵌入0时仅在分组码书C1中选取最佳量化值,嵌入1时则仅在分组码书C2中选取最佳量化值.接收方根据所接收的量化结果中的索引值是属于C1和C2来恢复机密信息比特.显然,这种方法实现简单,不增加计算量.为了减少带宽消耗,VoIP一般在发送端对语音进行低速率压缩编码然后传输.因此,上述几类语音信息隐藏方法中第3种方法最适合用于在VoIP建立隐蔽信道,因为第1类方法嵌入后的秘密信息在进行压缩编码时将丢失,第2类方法的运算复杂度较高不适合在语音实时编码时使用,而第4类方法仅适用于G.723.1.文献[8]针对低速率语音编码提出了一种改进的基于QIM的信息隐藏方法,它的主要贡献在于可以保证原码书划分后每个码字和它最邻近码字属于不同的分组,从而使得嵌入机密消息后局部附加量化失真的极大值相对其它划分方式取得极小,减小了隐写带来的语音失真,提高了隐蔽性.这使对其进行隐写分析非常困难,是当前在低速率压缩语音流中进行信息隐藏最先进的方法之一.为此本文将以文献[8]提出的QIM信息隐藏的方法作为隐写检测目标.当前QIM信息隐藏方法的隐写分析已有一些研究,但这些研究主要针对图像作为载体时的QIM隐写展开[9-12].文献[9]发现进行QIM信息隐藏会对载体图像的局部相关性引入相当强的扰动,通过引入Gamma分布对这种扰动进行建模并结合预先确定的似然率参数实现QIM嵌入的检测.文献[10]观察到使用QIM嵌入机密信息会增加量化图像的不规则性(随机性),通过引入“近似熵”对载体和载密图像的这种不规则性进行量化分析实现QIM嵌入的检测;文献[11]的方法与此类似,所不同的是该文使用基于核密度估计(KernelDensityEstimate,KDE)的方法对上述局部不规则性进行衡量.文献[12]发现QIM嵌入扰乱了图像像素及DCT系数直方图,构造了直方图变化与机密消息长度之间的估计公式,实现了图像中QIM嵌入率的估计.显然,这些方法都利用了QIM嵌入所引起的某一维度图像统计特征的显著变化进行隐写分析,因此对于语音流的QIM嵌入检测其难点也在于寻找并确定QIM嵌入后所引起的显著变化特征.此外,一些盲检测方法也可用于对QIM隐写进行检测,例如文献[13]给出了一种基于Mel倒谱频率系数(MFCC)统计特征的音频信息隐藏盲检测方法.该方法对于最低有效位隐写具有较好的检测效果,但对于QIM隐写其检测效果并不理想,其原因主要是压缩编码使语音产生很大的失真,直接从解码后语音采样值提取特征其实已经很难反映原始语音所蕴含的特征信息.鉴于此,本文针对低速率语音编码中的QIM隐写给出了一种无需解码直接在压缩域提取特征的方法,在此基础上构建了基于机器学习理论的隐写检测器.2压缩域隐写检测特征提取2.1基本思想VoIP所使用的低速率语音编码标准主要是G.729和G.723.1,这两种低速率语音编码器都使用了线性预测编码(LPC)方法,编码过程的核心步骤是对语音信号进行LPC分析以获得声道系统函数.通常声道系统函数可由式(1)表示,其中a1,a2,…,ap为语音信号的p阶LPC预测系数.语音信号x(n)可视为激励信号通过滤波器H(z)获得,例如一般语音中的浊音可视为周期性脉冲激励得到(如图1的元音“o”),而清音则由白噪声激励得到(如图1的清音“sh”).不同音素发音时一Page3般具有不同的声道形态,据此可以推知,不同的音素发音时其声道系统函数也不同,所以在理想情况下应该对每个音素对应的语音片段分别进行LPC分析,每个音素的LPC预测系数刻画了该音素的量化发音特性.获得LPC预测系数后的步骤是对其进行矢量量化,假设获得的量化矢量索引为I,则对于音素P必有一个I与之对应,用符号PI表示这种关系并称I为P的量化特征索引.图1语音、音素序列及LPC系数索引序列关系示意图音素在语言学中被称为音标,它是构成语言的基本单元,这些离散的基本单元根据一定的音素和文法规则或多或少地连缀成词语[14],如图1中的单词“shop”的发音由3个音素构成;词语按照一定的句法形式构成完整的语言系统.语言系统是存在某些统计规律的,例如,据统计英语中使用次数最多的字母是“e”,那么映射到语音上可以认为音素“e”的出现次数也最多;其次,英语中字母之间的组合排列方式是存在一定规律的,如“q”的后面大多数时候跟着“u”,那么映射到语音上可以认为音素之间的组合排列也存在一定的规律.换句话说,一段语音中的各音素的出现是不均衡的,其次不同音素的出现存在相关性.称上述特性为语音中的音素分布特性.假设某段语音对应的音素序列为S=P1P2…Pn-1Pn,根据PI,它将有一个与之对应的量化特征索引图2音素序列向量空间表示模型原理图序列:S=I1I2…In-1In,如图1所示.文献[8]给出的信息隐藏方法是在获得LPC系数的量化索引I时进行QIM隐写的.显然,进行QIM隐写势必使序列S的某些量化索引值发生变化,例如对于音素Pk,设其原量化索引为Im,进行QIM隐写后可能变为Im+1,S中索引的改变将导致S中音素Pk发生相应的改变,如变为Pk+1.音素的改变将使S中的音素分布特性发生变化.因此,如能够有效量化S中音素的分布特性,则通过比较QIM隐写前后该特征的变化即可实现隐写检测.2.2音素分布特性的量化统计模型为便于设计量化统计模型,我们首先给出本文中音素这一概念的形式化描述.本文将音素P用三元组(p,s,t)表示,其中p为音素的语言学符号即音标,s为音标p的发音是具有一定时长的语音小片段,t为s的时长.根据语音学理论,音素P为语音的基本组成单位,且特定语言所包含的音素是有限的,如英语包含40个音素[14],本文假设有一种虚拟语言L,它包含有限个音素,这些因素构成集合:B={P1,P2,…,Pn-1,Pn}.基于上述假设,属于虚拟语言L的一段语音S可以根据B中的音素分解为多个小片段,即可将S切分为多个按时序排列的语音分片S=f1f2…fm-1fm,分片fk实质上是音素Pl的发音,即存在fk=sl(k∈[1,m],l∈[1,n]),据此可将语音片段S表示为音素序列:S=PkPl…PxPy(k,l,x,y∈[1,n]).显然,属于虚拟语言L的任意一段语音都可由上文方法获得其对应的音素序列.如将音素P视为一个单词,那么相应的可将语音片段S视为一个文档.据此,借鉴自然语言处理中的文档量化表示模型:文档向量空间模型,我们可用音素向量空间模型(PhonemeVectorSpaceModel,PVSM)作为音素序列的量化表示模型,如图2所示.Page4音素向量空间量化表示模型的正规定义如下.定义1.虚拟语言L的音素集合B={P1,P2,…,Pn-1,Pn},称Pi∈B为音素词汇(PhonemeWord),称B为语言L的音素词典,属于虚拟语言L的语音片段所包含的音素都在B中.定义2.虚拟语言L的一段语音S,通过查找音素词典,可切分为按时序排列的N个音素,称上述过程为基于音素的语音分帧.定义3.设语音片段S分帧后所得的音素序列为S=PkPl…PxPy;根据音素词典B={P1,P2,…,Pn-1,Pn}可构造如下n维向量:犞={W1,W2,…,Wn-1,Wn}对音素序列S进行量化表示,称Wi为音素词汇Pi的权重(它是与Pi在音素序列S中的分布相关的变量,其取值依据预先设定的计算规则求取),称向量犞对应的n维空间为音素向量空间,音素序列S可用该空间中的一个点表示;称上述定义构成的语音片段量化表示方法为音素向量空间量化表示模型,称犞为S的音素向量.本文音素Pi(1in)的权重Wi的计算规则如式(2)所示,其中Count(Pi)表示音素词汇Pi在音素序列S=PkPl…PxPy的出现次数,Sum(S)表示S所包含的音素词汇总数.据此,我们可计算出任一语音片段的音素向量犞,它是一个n维向量.如前文所述,音素在音素序列中的分布存在不均衡性和相关性,显然音素向量并没有体现音素分布的相关性特性.为此,还必须设计相关性特性的量化统计模型.根据语音产生模型,发音的基本单位为音素,发音过程实际上就是不断变换声道形态的过程,可将该过程视为离散时间随机过程{x(i),i>0},x(i)表示音素发音时的声道形态,由于不同的声道形态对应不同的音素,因此可用音素来代表声道形态即取x(i)=Pi音素Pk(Pk∈B)的音.据此,可将音素序列S=l…PN-1xPNP1kP2学的统计规律,一般认为某个音素的出现仅与其前一个音素存在较大关联,鉴于此,本文假设下一个音素的出现仅与当前音素有关,即存在以下关系:Pr(PN/P1P2…PN-1)=Pr(PN/PN-1)(3)据此可证,随机状态序列S=P1为一阶马尔可夫链,即音素序列可视为声道(音素)状态转移一阶马尔可夫链.显然,声道状态集合即音素集合B={P1,P2,…,Pn-1,Pn}.根据上述性质,声道状态转移概率可用条件概率表示如下:ai,j=Pr(Pi/Pj),1i,jn且∑M它表征了音素序列中各音素出现的相关性,可作为音素相关性的量化统计特征.在实际计算时直接计算式(4)的条件概率较为困难,一般将其转化为联合概率进行计算,即根据条件概率公式将式(4)转化为式(5):ai,j=Pr(Pi/Pj)=Pr(Pi,Pj)进行各音素间相关性的计算.以ai,j(1i,jn)作为元素可获得一个n×n维的矩阵犕,称该矩阵为音素状态转移矩阵.显然,它量化不同音素出现的相关性.综上,我们得到了音素分布不均衡性的量化表示(即音素向量犞)以及音素分布相关性的量化表示(即音素状态转移矩阵犕).这两个不同角度量化特征必须进行融合,方能全面量化音素分布特性.由于犞和犕的维度不同,我们首先对犕进行降维操作,将其降为n维以便于和犞进行融合.对犕降维后得到n维向量犞={R1,R2,…,Rn-1,Rn},其中Rj(1jn)的取值方法如下:将犞与犞进行融合,获得融合向量犎={(W1,R1),(W2,R2),…,(Wn-1,Rn-1),(Wn,Rn)}作为音素分布特性的量化特征向量,下文称该向量为音素分布特征向量(PhonemeDistributionFeatureVector,PDFV).2.3分帧方法及音素集合的确定上面,我们已经给出了音素分布特征的量化统计模型,但是要计算该量化特征,还必须针对不同的低速率编码标准确定音素集合以及分帧方法.G.729和G.723.1是ITU为VoIP应用定义的低速率语音编码标准,因此,本文给出这两种编码器的音素集合和分帧方法,其它低速率编码器可类推.语音中每个音素的持续时间是不等长的,例如浊音“o”可能持续50ms以上,浊爆破音“b”则可能仅持续10ms,而且随着发音人及语速的不同其持续时长更是千变万化.因此,音素的持续时长是很难事先确定的,这导致将一段语音进行基于音素的分帧甚为困难.但是,本文利用低速率语音编码器都是对语音进行分帧处理这一事实解决这一问题.例如,G.729以10ms为单位对语音进行分帧并对每帧计算一次LPC预测系数(即估计一次声道发音参数),这意味着G.729认为在10ms的短时内声道的形态是稳定的;假设不同的声道形态对应不同音素发音,Page5那么可以认为G.729中每帧对应一个音素或者是一个音素的一部分.根据对实际语音的统计,英语中音素的持续时长均值远大于10ms,这印证了上述结论的正确性.为此以10ms为界限,本文将时长不超过10ms的音素称为α类,反之为β类.作为一种近似,对于α类音素其时长设为G.729的帧长l,对于β类音素设其时长为n×l(n>1)即β类音素包含多个G.729帧.我们发现β类音素发音时的信号波形一般具有周期性特征,例如图1中的音素“o”包含了4个明显的周期,此时一个周期的信号已可反映声道特征,因此对于β类音素在G.729中可视为对其声道参数进行了多次重复估计.鉴于此,本文认为对于β类音素,可分成n个帧分别进行LPC分析.综合上述分析,本文认为每个G.729帧可近似地跟一个音素对应(对于β类音素,可能连续几个帧都对应相同的音素),据此,对G.729压缩语音流直接以其原有的帧结构进行分帧即可.由于G.729对每个帧的LPC预测系数采用分级矢量量化,每个音素P的量化特征索引I=(i1,i2,i3),其中i1有128种取值,i2和i3都有32种取值,因此,索引I共有128×32×32=131072种取值,这意味着音素集合包含了131072个音素.音素集合太大,在音素序列的长度较小时不易凸显其统计特性(例如,设音素序列的长度为100,此时音素集合中99%以上的音素都将不在音素序列中出现,这将导致量化统计特征中很多元素的值为0),因此必须对量化特征索引I进行降维.由于,一级矢量i1与所有的LPC系数的量化有关其重要性超过了i2和i3,而且QIM隐写是在3个分裂矢量量化时分别进行的,因此本文近似地取I=i1,即取i1作为G.729的音素集合B中元素P的量化特征索引,据此可得B={i1127,i1128}.所以,对于G.729其音素向量犞与音素状i1态转移向量犞都是128维向量,而融合向量犎为图3进行QIM隐写对融合特征向量造成的扰动256维向量.对于G.723.1,基于类似的分析,仍可基于其压缩语音流的原始帧结构进行分帧并近似地取其第1个分裂矢量作为音素的量化特征索引,此时其音素集合B={i1向量犞与音素状态转移向量犞都是256维向量,而融合向量犎为512维向量.确定音素集合及分帧方法后,对于给定的压缩语音片段可方便地计算其融合特征向量犎.图3给出了QIM隐写对融合特征向量扰动情况的分析结果.其中,图3(a)是一段长度为10s的G.729压缩语音流片段及其使用文献[8]的方法进行QIM隐写后的融合特征向量犎对比图,从该图可以看出隐写前后融合特征向量重合的点极少,这说明隐写前后融合特征向量的变化幅度较大.为了量化分析隐写对融合特征向量的扰动程度,本文引入向量变化率(VectorVariationRate,VVR)对向量的改变进行衡量.设对某个压缩语音流片段,其在隐写前后计算所得的融合特征向量为犎1和犎2,VVR定义为犎1中取值发生变化的子向量的比例,定义如下:其中N为融合特征向量维数,μi和τi定义如下:μi=1,ai≠0其中ai和bi分别为犎1和犎2中第i维子向量的取值.显然,VVR的值越大,隐写对融合特征向量的扰动幅度越大.将VVR的值域分为10个区间:di=[i×0.1,(i+1)×0.1),其中i取值为0~9;本文对实验部分所涉及的2674个不同语音片段使用G.729及G.723.1分别计算了其VVR值,图3(b)统计了计算所得VVR值属于区间di的语音文件数量.从图3(b)可以看出对于G.729和G.723.1,文件对应的向量变化率值都超过0.5,这意味着至少有一半以上的Page6融合特征向量中的子向量在隐写前后的取值发生了改变;对于G.729,所有文件的VVR均值为0.86,对于G.723.1该值为0.68.因此可以认为本文所提取的特征对隐写是非常敏感的———隐写将导致该特征发生显著性变化.这对隐写检测非常有利.3基于机器学习的隐写检测假设有一个未知是否存在QIM隐写的压缩语音片段S,隐写检测的目标即判定S是否存在QIM隐写.假设通过对S进行处理所抽取的可用于隐写检测的特征向量为狋,则隐写检测过程可用式(9)表示:其中函数f为隐写检测器其输出结果即为检测结果,若y=+1,表示S不存在隐写,否则存在隐写.显然函数f是一个二值分类器,隐写检测过程实质上是分类过程:假设y=+1时S属于未隐写类(称为cover类),y=-1时S属于隐写类(称为stego类),则隐写检测就是将未知类别的样本S分为cover类或stego类.对于分类问题,基于机器学习的分类方法是当前主流,本文也采用这种方法.对于未知类别的压缩语音片段,本文基于机器学习的隐写检测过程如图4所示.显然,隐写检测的关键是确定特征向量狋和分类器f.在文献[13]中,特征向量的提取必须首先对压缩语音片段进行解码,其后基于解码获得的语音数据计算基于MFCC的统计特征向量,这种特征提取方法需要进行解码操作,甚为耗时.上一节中我们介绍了本文的特征提取方法,该方法不需要对压缩语音进行解码,直接在压缩域抽取特征向量,计算速度较快.为此,本文将上节给出的音素分布特性量化向量犎作为特征向量狋.关于分类器的设计,现有研究中,不同的对象分类识别系统有不同的训练方法,这些方法大致可分为两大类:判别法(discriminativeapproach)和生成法(generativeapproach).判别法可以灵活地选择用来识别的特征,检测速度也较快,为此本文采用基于判别法的分类器.在判别型分类器中,由于支持向量机(SupportVectorMachine,SVM)较适合小样本训练的情况,本文考虑到训练时间和训练样本量,使用支持向量机作为分类器.SVM分类器是一种监督学习分类器,它是通过使用某些已标注类别的样本进行训练获得的.对于特征向量狋,分类器f的训练和预测步骤如下:(1)获取尽可能多的cover类别低速率压缩编码语音片段,并使用QIM嵌入方法(分组码本使用文献[8]算法进行优化划分)进行隐写以获得cover类别中每个样本对应的stego样本,并做好标注;(2)抽取上一步骤所获得的两类样本的特征向量狋,标记每个向量的类别;(3)训练分类器:使用上一步骤获得已标记类别的特征向量集合训练分类器,获得分类器f;(4)使用分类器f对未知类别样本进行隐写检测:对于未知类别样本首先抽取特征向量狋,将狋作为分类器f的输入,分类器输出即为隐写检测结果.LIBSVM是一个优秀的SVM工具,本文基于LIBSVM进行分类器的训练和预测.4实验及讨论本文选择G.729和G.723.1作为实验测试所用的低速率语音编码器,并采用文献[8]给出的方法作为隐写算法.本文针对两种编码器分别进行了本文隐写检测方法的性能测试,并与文献[13]给出的隐写检测方法进行了比较.为了阐明算法具有较好的普适性,本文选择不同发音人的多个语音片段组成语音样本库.所用语音片段样本包含4个种类,分别是中文男声(ChineseMan,CM),包含500个语音片段;中文女声(ChineseWoman,CW),包含532个语音片段;英文男声(EnglishMan,EM),包含818个语音片段;英文女声(EnglishWoman,EW),包含824个语音片段.语音片段总计2674个.每个语音片段的时长为10s,采样率为8000Hz,对每个采样点用16bit进行量化,用PCM格式存储.我们称没有进行信息隐藏的压缩语音片段为未隐写类(C类),否则称其为隐写类(S类).不同类别发音人的语音片段编码所得的C类及其对应的S类压缩语音流片段构成进行分类器进行训练和预测时的数据集.由于本文已将隐写检测问题转化为分类问题,因此本文采用式(10)定义的分类准确率Precision对检测算法的性能的进行评估:其中λ和θ是数据集中的C类和S类样本的个数,λ^和θ^则是被分类器准确判定类别的C类和S类样本Page7的个数.4.1低速率语音编码器QIM隐写检测结果对语音样本库中CM中的每个PCM格式存储的语音片段使用G.729编码器进行压缩编码,获得没有进行信息隐藏的500个G.729压缩语音流片段,由于G.729的帧长为10ms,因此每个片段包含1000个G.729帧,这些压缩语音片段组成未隐写类别(C类)样本.使用文献[8]介绍的CNV算法方法对G.729进行矢量量化时的3个分裂矢量码本进行优化划分,获得进行QIM嵌入的分组码本.再次对每个PCM格式的语音样本进行基于G.729标准的编码压缩,并且,在对每个帧的LPC系数进行矢量量化时使用QIM机制嵌入机密信息,获得包含隐藏信息的500个G.729压缩语音流片段,这些压缩语音片段组成隐写类别(S类)样本.C类及其对应的S类压缩语音流片段构成进行分类器训练和预测时的CM数据集.同理可得CW、EM和EW数据集.这4个数据集的所有样本构成混合(Hybrid)数据集.因此,本文在5个不同的数据集上评估了算法性能.用类似的方法获得使用G.723.1作为低速率语音编码器时,进行检测算法性能评估的数据集.由于每个语音片段的长度为10s,G.723.1的帧长为30ms,因此每个G.723.1压缩语音片段包含333个帧.对上述的每个数据集,选择75%的C类样本及其对应的S类样本,组成该种类分类器的训练样本库,剩余的25%样本组成测试样本库用于评估训练所得分类器的分类准确性.表1给出了测试结果,表1中列PDFV是使用本文方法获得的隐写检测结果,列MFCC是使用文献[13]的方法获得的隐写检测结果.从测试结果看本文方法在5个测试数据集上均优于文献[13]的方法,在语音片段时长为表2压缩语音流时长变化时的G.729QIM隐写检测结果时长/sCM的检测结果/%0.1069.1653.6065.2252.2667.8457.0766.2052.9174.3358.370.1578.1459.6080.3557.8978.4263.4174.7556.8083.3861.210.2085.4258.8087.5957.5285.5763.6681.6758.5089.6061.730.4094.6166.4094.7360.5394.2567.0793.5660.4495.9266.290.8099.4067.6098.2165.4199.0277.0798.6662.8699.1469.511.6099.9077.60100.0067.6799.8775.1299.7567.2399.8575.113.20100.0087.20100.0073.68100.0077.3299.9374.76100.0078.924.80100.0089.60100.0081.95100.0075.59100.0075.24100.0081.546.40100.0089.60100.0086.84100.0076.83100.0080.34100.0084.458.00100.0094.00100.0088.35100.0077.07100.0081.30100.0086.92为了更直观地比较两种方法的性能,图5给出了5个数据集的平均检测准确率与语音片段时长的关系图.从该图可以看出,随着语音片段时长的增加,隐写检测准确率也随之提升;本文方法在任一时10s时,对于两种低速率语音编码标准,本文方法检测准确率均超过98%,而文献[13]的方法对于G.723.1基本上无法有效检测:对5个数据集检测准确率均低于60%.数据集名使用G.729的结果/%CM100.0094.0098.4049.60CW100.0088.7296.8052.26EM100.0080.0098.2254.63EW100.0077.4397.8756.55Hybrid99.9886.7098.6252.76上面获得的测试结果所用的语音片段的时长为10s.本文面向的是VoIP中低速率编码的压缩语音流的隐写检测;VoIP中的语音流是实时流,进行隐写检测前必须进行流的存储.为了达到较快检测以及减少存储的数据量,显然达到可以接受的隐写检测准确率时,我们希望所需要存储的语音流时长越短越好.为此,我们在下文对语音片段时长与隐写检测的性能进行了评估.4.2压缩语音流时长对隐写检测结果的影响为了评估语音片段时长对隐写检测结果的影响,首先根据不同的低速率编码器的帧长,对数据集中的10s长度的语音片段进行截短处理.对于G.729,由于其帧长为10ms,10s长度的语音片段总共包含了1000帧,截取前N(0<N1000)个帧编码所需的采样值,构成时长为0.01×Ns的新的CM、CW、EM、EW和Hybrid数据集.对这些新的数据集进行分类器的训练并测试分类准确性.表2给出了不同语音片段时长时(N取不同值)的检测结果.长下其检测准确率均优于文献[13]的方法;在语音片段时长为0.40s时本文方法已能够达到有效检测(检测准确率已经超过90%),而此时文献[13]的方法仍不超过70%.因此,对于G.729,在语音片段时Page8长较小时本文方法性能远优于文献[13];在语音片段时长较大时(超过4.8s),本文达到100%的隐写检测准确率,这一点是文献[13]无法达到的.图55个数据集的G.729QIM隐写检测平均准确率由于G.723.1的帧长为30ms,10s长度的语音片段总共包含了333帧,仍截取前N(0<N333)时长/sCM的检测结果/%0.3052.7956.8045.9554.1444.7450.2445.6947.8249.7148.800.6055.4852.4046.5251.8849.7550.9850.6050.7353.9650.451.2057.4856.8051.1247.7456.4752.4460.7455.1068.3748.732.4071.8554.4064.5651.5080.0152.4474.2752.1880.1852.473.6087.6251.2080.4551.1385.8153.9187.1053.6488.7852.024.5089.4250.0085.9056.3990.9553.1789.4453.8891.7051.796.0092.6157.2090.9753.3893.8251.9594.2353.4095.1253.447.5096.1050.0094.7357.8995.9052.6897.0252.4397.2352.329.0097.9051.2095.8653.3897.3149.0297.6355.1098.0953.14图65个数据集的G.723.1QIM隐写检测平均准确率根据上述实验,本文方法对于两种典型的低速率语音编码器中的QIM隐写均能有效检测,检测性能远优于时域特征抽取方法.个帧编码所需的采样值,构成时长为0.03×Ns的新的CM、CW、EM、EW和Hybrid数据集.对这些新的数据集进行分类器的训练并测试分类准确性.表3给出了不同语音片段时长时(N取不同值)的检测结果.为了更好地比较两种方法的性能,图6给出了5个数据集的平均检测准确率与语音片段时长的关系图.从该图可以看出,随着语音片段时长的增加,本文方法的隐写检测准确率也随之提升,但是文献[13]的方法其检测准确率一直低于60%(可以认为无法对隐写作出检测).其原因可能是G.723.1每30ms的采样值采用文献[8]的QIM隐写方法仅嵌入3bit秘密信息,嵌入率太低导致解码后的语音采样值序列并不因隐写而产生较大的改变,这使基于采样值序列统计的特征对隐写不够敏感,从而导致检测率低.但是本文方法是压缩域方法,不考察解码后的语音数据,因此仍能获得较好的隐写检测准确率:在语音片段时长较大超过6s时,本文方法检测准确率超过90%.表3压缩语音流时长变化时的G.723.1QIM隐写检测结果5总结本文对在低速率语音编码过程中的QIM隐写给出了高效的检测方法.本文发现一段语音中的音素其分布存在不均衡性和相关性,据此本文提出了一种基于压缩域的隐写检测特征抽取方法,并结合支持向量机构建了隐写检测分类器.与基于时域的特征抽取方法相比,本文方法不仅具有较高的检测准确率,而且节省了压缩语音的解码时间,实现了对压缩语音流的快速隐写检测.本文方法借鉴了文档的向量空间表示方法及其分类模型,正是利用这些方法所蕴含的深刻思想建立了本文的隐写检测算法.本文方法为隐写检测提供了一种新的思路.
