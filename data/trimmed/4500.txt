Page1一种基于跨领域典型相关性分析的迁移学习方法1)(中国科学院计算技术研究所智能信息处理重点实验室北京100190)2)(中国矿业大学计算机科学与技术学院江苏徐州221116)3)(中国科学院大学北京100049)摘要作为迁移学习的一个重要研究方向,基于特征映射的方法学习各领域特有特征与领域共享特征之间的相关性,通过一些相关特征减少领域之间的差异,已经获得了广泛的关注和研究.典型相关性分析是一种用来分析两组随机变量之间相关性的统计分析工具.将典型相关性分析引入迁移学习,结合基于特征映射迁移学习的思路,提出了一种跨领域典型相关性分析算法.该算法在保持各领域特有特征与领域共享特征相关性的基础上,通过选择合适的基向量组合训练分类器,使降维后的相关特征在领域间具有相似的判别性.在20Newsgroups上864个分类问题以及多领域情感分析数据集上12个分类问题的实验结果表明,跨领域典型相关性分析算法可以有效地提高跨领域迁移分类准确率.关键词迁移学习;典型相关性分析;跨领域分类学习;领域自适应1引言分类作为一种重要的机器学习方法,已经得到了广泛的研究与应用.它根据带有标签的数据样本(也称为“源领域数据”或者“训练样本”)训练分类模型,然后运用分类模型对新数据样本(也称为“目标领域数据”或者“测试样本”)的类型进行预测.为了保证训练得到的分类模型具有准确性和高可靠性,传统的分类学习需要满足两个基本假设:(1)用于学习的训练样本与新的测试样本满足独立同分布的条件;(2)必须有足够可利用的训练样本才能学习得到一个好的分类模型.但是,在实际应用中我们发现这两个条件往往无法满足.在Web数据挖掘等领域,新数据不断涌现,原先可利用的有标签训练样本与新产生的测试样本间存在的分布差异,使已有的训练样本不足以通过训练得到一个可靠的分类模型.同时,人工重新标注大量的新样本又非常费时费力,而且容易出错.这就引出了机器学习中的另外一个重要问题,即,如何利用少量的有标签训练样本或者源领域数据,建立一个可靠的分类模型对目标领域数据进行预测(源领域数据和目标领域数据可以不具有相同的数据分布).近年来,迁移学习已经引起了广泛的关注和研究[1].迁移学习是运用已有知识对不同但相关领域的问题进行求解的一种新机器学习方法.它放宽了传统机器学习中的两个基本假设,目的是在源领域数据与目标领域数据具有不同数据分布的情况下,把从有标签源领域学习到的知识迁移到目标领域,解决目标领域中仅有少量有标签样本数据甚至没有的学习问题.基于特征映射的迁移学习方法是迁移学习的一个重要研究方向.这类方法首先把各个领域的数据从原始高维特征空间映射到低维特征空间.在该低维空间下,使源领域数据与目标领域数据拥有相同的分布.然后利用低维空间表示的有标签源领域数据训练分类器,并对目标领域数据进行预测.该方法与另一种基于特征选择的迁移学习方法的区别在于上述映射得到的特征不在原始的特征空间,是全新的特征[2].典型相关性分析(CanonicalCorrelationAnalysis,CCA)是一种用来分析两组随机变量之间相关性的统计分析工具,其相关性保持特征己经在理论上得到证明,并成功地应用于人脸识别、图像标注、文本挖掘与跨媒体特征相关性分析.本文针对迁移学习中源领域数据和目标领域数据相关但具有不同数据分布的特点,提出一种跨领域典型相关性分析(CanonicalCorrelationAnalysisacrossDifferentDomains,CCADD)算法.该算法在保持领域间相关性的基础上,将各个领域的数据从原始高维特征空间映射到低维特征空间.该低维空间中,各领域之间的数据具有相似的分布.本文第2节介绍该问题的相关工作,对单个源领域到单个目标领域的迁移分类学习问题和CCA作简要介绍;第3节具体介绍跨领域典型相关性分析(CCADD)算法及其求解方法;第4节通过实验对所提出算法进行性能测试,并对实验结果进行分析;最后对本文的工作进行总结,并展望进一步的工作.2相关工作2.1迁移学习迁移学习研究如何将源领域的知识应用到相关目标领域,提高机器学习算法在目标领域上的性能.分类算法研究如何利用源领域中大量有标签的样本,来提高目标领域数据的分类效果[2].给出训练集犇s={(狓i,yi)}ns域数据,服从于某种数据分布Ps(狓,y);而测试集犇t={(狓i,yi)}nt分布Pt(狓,y),其中ns和nt分别为训练集和测试集的样本个数,狓i为样本点,yi为对应样本类别.本文对文本数据进行处理,Xs和Xt表示源领域与目标领域样本点的特征空间,采用tf·idf特征,因此特征空间的取值为非负,即狓∈特征维度,本文还进一步假设:(1)Xs∩Xt≠;(2)Ps(狓,y)≠Pt(狓,y);(3)目标领域中无任何有标签的数据;(4)单个源领域到单个目标领域的迁移分类学习.如图1所示的二维数据集,hs和ht分别为源领域和目标领域的理想分类器.可以看出从源领域数Page3据训练得到分类器hs,虽然可以在源领域中表现很好,但却不能对目标领域数据进行很好的预测.本文致力于利用源领域中有标签的样本数据,把知识迁移到目标领域中,从而在目标领域中得到理想的分类性能.图1源领域与目标领域数据分布不一致示意图迁移学习广泛存在于人类的活动中,两个不同领域共享的因素越多,迁移学习就越容易,否则就越困难,甚至出现“负迁移”[3-5],产生副作用.比如:一个人要是学会了自行车,那他就很容易学会开摩托车;一个人要是熟悉五子棋,也可以轻松地将知识迁移到学习围棋中.但是有时候看起来很相似的事情,却有可能产生“负迁移”,比如,学会自行车的人来学习三轮车反而不适应,因为它们的重心位置不同[2].Blitzer等人[6]指出影响迁移学习效果的原因可以归纳为以下3个方面:(1)源领域中的判别性特征在目标领域没有判别性或没有出现;(2)目标领域中具有判别性的特征没有出现在源领域;(3)领域间共享的判别性特征,在领域间的判别结果相反[7].Blitzer等人提出了一种结构对应学习算法(StructuralCorrespondingLearning,SCL),该算法首先选择领域间频繁出现且具有代表性的共享特征作为“轴”特征(pivotfeature),通过奇异值分解(SVD)建立各领域混合特有特征与领域共享“轴”特征之间的相关矩阵(correspondencematrix),把各领域特有特征映射到“轴”特征,然后在这个“轴”特征下对有标签的源领域样本进行训练学习,对目标领域数据进行预测.相关矩阵度量了各领域特有特征与“轴”特征之间的统计相关性.Ji等人[8]分析了“轴”特征在领域间具有相反判别性时,SCL算法的局限性,如用户使用“read-the-book”评价书籍时,表示这是一本好书,但在使用“read-the-book”评价一部电影时,却表示这部电影很无聊,提出了基于多视图主成分分析的迁移学习方法(Multi-ViewPrincipalComponentAnalysis,MVPCA),类似SCL-MI算法[7]采用互信息(mutualinformation)取代频繁程度作为选择“轴”特征的依据,分别计算源领域、目标领域特有特征与领域共享“轴”特征之间的相关性.SCL算法、SCL-MI算法和MVPCA算法本质都是基于特征映射的迁移学习方法.算法首先选择在各领域间具有相似判别性的特征作为“轴”特征,构成低维特征空间,然后使用无标签的源领域和目标领域样本,以及有标签的源领域样本,学习各领域特有特征与领域共享“轴”特征之间的相关性,将各领域的数据从原始高维特征空间映射到低维特征空间.在该低维空间下,源领域数据与目标领域数据拥有类似的分布.其中,各领域特有特征与领域共享“轴”特征之间的相关性学习,可以抽象为维度分别为p和q的两组随机变量间的相关关系研究.2.2典型相关性分析对于维度分别为p和q的两组随机变量狓和狔,给定均值为0的成对观察样本集合{(狓i,狔i)}n即狓-=是多种信息来源(如爆炸的声音和图像),也可以是从同一来源的信息中抽取的不同特征(如图像的颜[色特征和纹理特征).记犡=狓1,狓2,…,狓犢=狔1,狔2,…,狔两组基向量犠狓∈和狏=犠T相关系数的最大值问题:其中:犆狓狓=犡犡T∈内协方差矩阵(within-setcovariancematrix),犆狓狔=犡犢T∈covariancematrix),且犆狔狓=犆T在一些文献中,常将CCA问题等价地描述为以下特征值问题:烄烆2010年,黄贤立[9]从多视图的角度提出了一种跨领域文本分类的方法(MTV算法).MTV算法和MVPCA算法都是从多视图的角度分析了迁移学习的问题.MTV算法首先通过线性分类器(LogisticRegression)分别学习各领域特有特征与领域共享特征之间的相关性,然后通过典型相关性分析,对共享特征与各领域特有特征的多视图统计相关性进行分析,得到一个跨领域的公共子空间.在该公共子空间里面,不同领域样本的分布更加接近.Page42.3桥接特征算法具有良好领域适应性的关键在于如何选择领域间具有相似判别性的特征.SCL算法[6]选择领域间频繁出现的共享特征,称此类特征为“轴”特征,用于词性标注.在情感分析领域,SCL-MI算法[7]使用有标签的源领域样本,计算领域共享特征与源领域样本类别间的互信息,选择互信息值大的共享特征作为“轴”特征.互信息取值反映了领域共享特征与样本类别之间相关性的大小.互信息取值大的共享特征对于预测样本类别具有更强的判别性.本文目的是提高目标领域文本分类性能,因此采用互信息选择领域间共享特征,类似文献[8]称其为桥接特征(bridgefeature),作为连接源领域和目标领域的桥梁.设Xi∈Xs∩Xt,Xi与有标签源领域样本犇s中样本类别Y的互信息计算公式如下IXi;(其中,pXi,()y表示桥接特征Xi与类别标记y的联合分布概率.选择m个互信息值最大的特征组成桥接特征集合,记为X∩=X∩1,X∩2,…,X∩3跨领域典型相关性分析由源领域训练集犇s={(狓i,yi)}ns机变量α和β的成对样本集合{(αi,βi)}ns|Xs-X∩|,其中|X∩|和|Xs-X∩|分别表示桥接特征和源领域特有特征的维度,{αi}ns域样本点狓i在桥接特征空间X∩上的取值,β{}i|Xs-X∩|表示源领域样本点狓i在特征空间Xs-X∩上的取值.根据2.2节中典型相关性分析的定义,寻找两组基向量犠犃∈犃α和狏=犠T狌=犠Tραβ=max其中:犃s=α1,α2,…,αn犅s=β1,β2,…,βn犆犃s犃s=犃s犃T犆犅s犅s=犅s犅T犆犃s犅s=犃s犅T同样对于目标领域测试集犇t={(狓i,yi)}nt造以下两组随机变量α和γ的成对样本集合{(αi,i=1∈γi)}nt分别表示桥接特征和目标领域特有特征的维度,可以形式化为以下CCA问题:ραγ=max其中:犃t=α1,α2,…,αnΓt=γ1,γ2,…,γn犆犃t犃t=犃t犃T犆ΓtΓt=ΓtΓT犆犃tΓt=犃tΓT其中,桥接特征基向量犠犃由式(2)得到.联合优化式(2)和(3),可以得到以下优化问题:犠犃上式中,犆犃s犃s征的协方差矩阵(within-setcovariancematrix).为了充分挖掘领域间的共享知识,使用犇s∪犇t中样本桥接特征的协方差矩阵犆犃犃代替犆犃s犃s问题转化为其中:犆犃犃=犃s∪犃(3.1问题求解使用Lagrange乘子法.令:L(λ1,λ2,λ3,犠犃,犠犅s求解上述Lagrange函数,令Page5L犠犃L犠犅s用犠T犠T犃犆犃s犅s犠犅s+犠T用犠T犠T犆犅s犃s犠犃=λ2犠T犅s用犠T犠T犆Γt犃t犠犃=λ3犠TΓt式(9)、式(10)代入式(8),得设λ1=λ,λ2=pλ,λ3=qλ且p+q=1,则求解犠犃,犠犅s式(12)最大的前m个广义特征值对应的特征向量即为所求基向量,犠犃=犠i{}犃求得犠犃,犠犅s源领域训练集:犇s=犠T式(13)和式(14)分别简称为样本特征的“串行组合”和“并行组合”.对于目标领域测试集,同样也可以表示为以下两种形式:犇t=犠TCCADD算法的伪码描述如算法1.算法1.CCADD.输入:有标签源领域数据犇s输出:犠犃,犠犅1.从Xs∩Xt中选择m个互信息值最大的特征组成桥接特征集合X∩;2.构造成对样本集:3.计算矩阵犆犃犃,犆犅4.求解式(12)特征值最大的前m组特征向量犠i;和犠iΓt5.根据3.3节中的方法,选择r组基向量,犠犃=犠i{}犃6.根据3.2节中的方法,在犇s上训练分类器f.3.2分类器使用“串行组合”形式表示投影后的源领域数据集犇s,训练线性分类器fs:其中,α∈α{}i和狑β分别表示桥接特征和源领域特有特征的权重向量.以上方式训练获得的分类器,只对源领域中出现的特征有效.用于目标领域分类时,无法直接处理目标领域特有特征γ∈γ{}i第i组基向量犠i中,源领域样本投影结果犠iT样本投影结果犠iT设fs和ft分别为源领域样本和目标领域样本投影后的理想分类器.如果领域间共享的桥接特征投影到犠i判别性,则类似文献[10],目标领域样本的类别可以采用以下方式计算:其中狑α为分类器fs中桥接特征的权重向量.3.3基向量选择并非沿所有的基向量组降维,都能获得图2中所示的理想迁移分类效果.图3、图4给出了降维后,影响迁移效果的两种典型情况:(1)源领域中的判别性特征在目标领域没有判别性;(2)领域间共享的判别性特征,在领域间的判别结果相反.Page6图2基向量犠i图3投影后源领域的判别性特征在目标领域不具有判别性出现这种问题的主要原因是桥接特征在源领域和目标领域间具有不同的分布.以数据集20Newsgroups为例,选用sci.crypt和talk.politics.guns作为源领域,sci.electronics和talk.politics.mideast作为目标领域,桥接特征集合的词频如图5所示.X轴为按字母顺序排列的桥接特征,Y轴表示词频.为了获得理想的投影效果,需要对求解式(12)得到的前m个特征值和特征向量犠i图4投影后领域共享特征在领域间具有相反判别性图5桥接特征在源领域和目标领域间具有不同的分布一步筛选.Ben-David等人[11]给出了迁移分类方法用于目标领域的错误上限,并指出迁移学习中,好的特征表示方式应该满足两方面的要求:(1)缩小领域间的分布差异dH珦US,珦U(率^ξS()h.领域间的分布差异dH珦US,珦U(计算.在有限样本的情况下,训练线性分类器区分源领域和目标领域样本,并使用100×1-(A-distance,其中loss为分类器的平均Huber损失.损失越高,领域间的分布差异越小.根据Ben-David的方法,本文采用以下过程选择基向量:对于给定的两个领域,求解式(12)特征值最大的m组特征向量,选择其中r组,犠犃=犠i{}犃Page7源领域和目标领域样本分别投影并标注来源后,本文得到数据集并训练分类器,使A-distance取值最小.同时,对投影后的源领域样本最小化源领域分类错误率^4实验过程和结果本节将展示实验结果来证明本文所提出CCADD算法的有效性,主要集中在两类问题.4.1实验数据数据集20Newsgroups①是评价文本分类的标准数据集,包括大约20000个文档,根据不同的主题被划分为20个小类,每个小类包含的文档数差不多.由于某些主题比较相近又可以组成一些大类,比如sci.srypt,sci.electronics,sci.med和sci.space这4个小类构成一个大类sci.本文选用该数据集的4个大类作为本文的实验数据,如表1所示.这样该数据集包含两层结构,每个大类下面都有对应的4个小类.表1数据集20Newsgroups中的4大类以及对应的4个小类大类comprecscitalk实验从4个大类comp,rec,sci,talk中任意选择两大类数据(分别为正类和负类),来构造两类分类问题,包括comp和rec,comp和sci,comp和talk,rec和sci,rec和talk,sci和talk.本文构造两类问题如下,以数据集sci和talk为例,分别从大类sci以及talk各选一个小类构成源领域数据,而同样从两个大类中各选一个小类构成目标领域数据,注意源领域数据和目标领域数据的文档集不相交.这样构造的分类问题符合迁移学习问题:(1)源领域数据与目标领域数据分布不相同,因为它们来自于不同的小类,即不同的主题;(2)源领域数据与目标领域数据是相关的,因为它们来自于相同的大类.通过这样的构造方法,每个数据集可以构造144(P2个两类分类问题,6个数据集总共864个分类问题.为了进一步验证本文提出的算法,在多领域情感分析数据集②上也做了比较实验.该数据集来自亚马逊,由书籍、DVD、电子产品和厨房电器这4种产品的用户评价构成,如表2.实验采用Blitzer等人[7]文章中构造的12组分类任务.大类booksDVDelectronickitchen4.2比较算法和实现细节比较算法.与CCADD比较的算法包括:(1)监督学习方法,逻辑回归(LogisticRegression,LG)[12],支持向量机算法(SupportVectorMachine,SVM)[13];(2)跨领域分类方法,Blitzer等人[10]提出的SCL-MI算法.实现细节.实验采用tf·idf特征来构造词———文档矩阵,另外采用文档频率值15来选择词特征.逻辑回归采用LIBLINEAR[14]工具箱③,SVM使用LIBSVM[15]工具箱④,采用线性核.CCADD算法中参数p和q分别取值0.5.数据集20Newsgroups中,CCADD算法桥接特征数100,SCL-MI算法桥接特征数m=100,投影向量维度p=70.多领域情感分析数据集中,CCADD算法桥接特征数1000.4.3比较结果实验比较了20Newsgroups上864个分类问题以及多领域情感分析数据集上12个分类问题.20Newsgroups上的实验结果如图6所示.每个数据集的144个问题按照LG算法准确率的升序排列,这在一定程度上反映了这些分类问题的迁移学习难度,LG准确率越小,迁移学习难度越大,反之越容易.从实验结果看,CCADD算法优越于监督学习算法LG和SVM,这表明监督学习方法并不能很好地处理迁移学习问题.为了更加直观地体现所提出CCADD算法的优越性,表3给出了算法在6个数据集上的平均准确率比较,表中的L,R分别表示LG准确率低于和高于65%的分类问题的平均值,而Total表示所有①②③④Page8图6算法在20Newsgroups数据集上的比较144个问题的平均值.Ji等人[8]在20Newsgroups数据集上,对SCL和MVPCA/VMVPCA算法做了实验对比,S/M/VM列表示该对比实验在6个数据集上最高准确率.可以清楚地看到CCADD算法比所有的比较算法好很多,特别是当分类问题较难的情况(LG准确率低于65%).此外,实验还在多领域情感分析数据集上对算法SCL,SCL-MI和CCADD进行了比较,实验结果图7,其中算法SCL,SCL-MI和测试基准(在源领域训练分类器,并直接用于目标领域分类,没有知识迁移,记为Baseline)的数据来自Blitzer等人[7]文章中的实验.D→B表示DVD的用户评价作为源领域,训练分类器,学习用户对DVD的好恶,然后用于分析目标领域书籍,通过用户对书籍的评价分析其对书籍的喜好.从实验结果看,算法CCADD的分类准确率整体优于算法SCL和SCL-MI.特别是K→B,B→D的分类问题中,算法CCADD克服了算法SCL和SCL-MI出现的负迁移问题,分类准确率高于测试基准近10%.Page9表3算法在6个两类分类问题上的平均准确率比较sci和talkrec和scirec和talkcomp和reccomp和scicomp和talk图7算法在情感分析数据集上的比较(水平黑线为目标领域类内训练分类器的分类准确率)5总结与展望迁移学习是一种新的机器学习方法,将已有知识运用到不同但相关领域的问题.这种对问题进行求解的思路广泛存在于人类的活动中,是人类解决问题的常用方法.迁移学习的关键是如何准确地找到不同领域问题间的相关性.典型相关性分析是一种用来分析两组随机变量之间相关性的统计分析工具.本文分析了影响迁移分类学习效果的原因,并在传统典型相关性分析方法的基础上,结合基于特征映射迁移学习的思路,提出了一种SCL59.6272.6168.1958.7175.3867.1661.5676.1974.2661.2684.9284.5959.6875.3772.43/88.3088.30跨领域典型相关性分析算法,用于分析领域特有特征与领域共享特征之间的相关性.实验结果表明本文提出的算法可以很好地解决单个源领域到单个目标领域的迁移分类学习问题,优于所有比较的算法,并且可以在一定程度上克服负迁移问题.目前,桥接特征的选择方法还很有限,互信息仍然是一种比较有效的方法.实验中,发现有些互信息取值大的桥接特征在领域间却可能具有完全相反的判别性,并造成负迁移问题.在未来的研究中,将尝试新的桥接特征选择算法,如基于生成模型PLSA产生领域间共享的主题,作为桥接特征.Page10
