Page1WSR:一种基于维基百科结构信息的语义关联度计算算法孙琛琛申德荣单菁聂铁铮于戈(东北大学信息科学与工程学院沈阳110819)摘要该文提出了一种基于维基百科结构信息的语义关联度的计算方法———WikiStruRel(WSR).维基百科作为目前规模最大和增长最快的在线百科系统,其典型包括两个网状结构:文章网络和分类树(以树为主体的图),这两个网状结构包括了丰富的、明确定义的语义知识.WSR充分分析维基百科的文章网络和分类树,进而计算词语间的语义关联度.该方法没有涉及文本处理,算法开销较小,在3个数据集上的实验,取得了较好的准确率和覆盖度.关键词语义关联度;维基百科;文章网络;分类树1引言在判断“汽车”与“全球变暖”、“社交网络”与“个人隐私”、“苹果”与“手机”的关系时,通常依赖个人常识和积累的知识,并通过综合判断得出比较准确且满意的结论(取决于个人的见识广博程度和智Page2特定领域的知识[1-2]作为支撑.为计算语义关联度,有些方法是通过对大型语料库进行统计分析来实现[3-4];有些方法则使用经过手工处理得出的语汇结构如同义词典[5-6].无论哪一种情况,背景知识都是一个限制因素.对于前者,无结构和不准确的语料库是难题;对于后者,范围和数量级的限制非常突出.维基百科是目前最大和增长速度最快的百科知识库,有超过200万的文章数和数以万计的贡献者.其广泛的文章链接构成的相互参考网络、数目庞大的网络入口和层次的分类(以树为主体的图结构)能提供大量的明确定义的语义知识.基于以上原因,研究者热衷基于维基百科来进行语义计算.研究维基百科的最大挑战是,如何使这个庞大的百科知识变得机器可处理.为了克服上文中提到的背景知识的限制因素,本文提出了一种基于维基百科结构信息(文章网络和分类树)的新的语义关联度计算算法WikiStruRel(WSR).本文的主要贡献如下:(1)将维基百科的文章网络中的链接分类,并赋予不同经验权重,对目标概念结点的相邻结点进行层次划分,应用Jaccard系数,提出一种基于文章网络的语义关联度计算算法RelArtNet.(2)利用维基百科的分类树的类本体性,提出一种基于分类树的语义关联度计算算法RelCatTree.(3)综合基于文章网络和基于分类树的语义关联度计算法,提出一种基于维基百科的结构信息(文章网络和分类树)的语义关联度计算算法WSR,使得语义关联度准确性和计算效率得了提升.(4)通过实验验证了本文提出的WSR的有效性.2相关工作现有的语义关联度计算方法的主要区别在于背景知识来源的不同.几种关联度算法在测试词集WordSimilarity-353的准确率[7]如表1所示,其中算法准确率通过与人工识别的关联度相比较得到.表1中的前两个是基于人工产生的语义词典Wordnet和Roget的语义关联度计算算法的准确率.基于Wordnet的算法[8]是通过语义词典的分类体系中的结点信息来判断结点间的关联度;基于Roget的算法[9]是通过计算语义词典的分类体系中结点的语义距离来判断结点间的关联度,距离越近,关联度越大.语义词典全部是人工处理得到的,基于语义词典的关联度计算方法受限于语义词典的词汇量.国内研究者基于HowNet[10]中文语义词典也进行了相关研究.基于同义词词典基于语料库LatentSemanticAnalysis(LSA)0.56基于维基百科基于语料库的算法是通过对大量文本进行统计分析来得出语义关联度.由ScottDeerwester等人提出的LatentSemanticAnalysis(LSA)[11]是最著名和效果最好的基于语料库的语义关联度计算算法.LSA算法核心在于有语义关联的词语被期望出现在同一文本中,算法高度依赖于基于语料库的词汇表.只有较大的语料库才能保证理想的准确度,因而,该算法的语料预处理的工作量非常巨大.目前有多种基于维基百科的语义关联度计算方法,如WikiRelate、ESA和WLM.WikiRelate[12]是由Strube和Ponzetto提出的基于维基百科的层次分类结构(本文称之为分类树)的语义关联度计算方法.WikiRelate将基于Wordnet的方法“Pathbasedmeasures”、“Informationcontentbasedmeasures”和“Textoverlapbasedmeasures”进行修改后应用在维基百科上,并且取得了与基于Wordnet相近的准确度.WikiRelate相比于基于Wordnet方法的优势是,维基百科能够提供更广的词汇覆盖度.ExplicitSemanticAnalysis(ESA)[13]是由Gabrilovich和Markovitch提出的,是迄今为止基于维基百科的准确率最高的语义关联度计算算法.ESA借用了向量空间模型思想,但它没有通过比较语汇权重向量来比较关联度,而是比较维基文章彼此间链接的带权向量,ESA中的向量是由人工定义的概念构成.ESA不仅可以计算词语的语义关联度,而且可以计算文本之间的语义关联度.但是ESA需要比较多的人工参与.Milne和Witten提出了基于维基百科文章链接关系的语义关联度计算算法WikipediaLink-basedMeasure(WLM)[7].WLM采用向量空间模型和NormalizedGoogleDistance[14]来处理维基百科中的文章链接,得到词语语义关联度.WLMPage3比ESA算法开销小,但从表1可知,准确度只略低于ESA.通过分析,我们发现,维基百科中由文章链接构成的相互参考网络和由分类组成的分类树(以树为主体的图结构)能够提供丰富的、明确定义的语义知识.为此,本文充分挖掘了文章之间、分类之间以及文章与分类之间的关联关系,提出一种基于这两个网络结构的语义关联度计算算法WikiStruRel(WSR).3维基百科和问题定义本部分介绍维基百科以及相应的两个网络结构、两类链接和两类特殊页面的含义,同时给出了本文问题定义.3.1维基百科及其相关概念维基百科是一个巨大的、协作的、免费的、开放的在线百科全书.这个大型百科在线系统是目前最大且增长速度最快的百科知识库,其广泛的相互参考网络、数目庞大的网络入口和层次的分类(以树为主体的图结构)能提供大量的明确定义的语义知识.从2001年发布上线到2012年1月,英文维基百科条目数已有385万个条目,全球所有282种语言的独立运作版本已突破2100万个条目,总登记用户也超越3200万人,总编辑次数更是超越12亿次.这些数据说明了它具有大规模语料库的特征.维基百科中的每一篇文章都描述一个单一的主题,文章题目像传统的同义词典中的语汇或短语一样,简明扼要且表达清晰.每篇文章至少隶属于一个维基分类.文章之间的超链接关系描述不同文章之间存在的(如等价、层次或者关联等)语义关系.维基条目之间的链接构成了一个巨大的语义网络.维基百科在2004年5月增加了分类,文章隶属于分类,分类构成了分类树(实际为图结构),这使其增加了语义词典的特征.针对维基百科的内容组织结构,我们给出如下相关概念.3.1.1文章网络和分类树图1揭示了维基百科中的文章网络和分类树的结构以及两个网络结构的关联.分类树是一个以层次树为主体的有向图结构,其中Ci为任意分类;文章网络是一个庞大的包含大量的链接的有向图,其中Ai为任意文章,分类树延伸至文章,使得文章网络与分类树产生紧密关联.3.1.2文章链接和分类链接维基百科的文章Ai、Aj之间通过超链接相互联系,构成文章网络.每篇文章都能链向多个其它维基文章.维基编写者为不同文章中的关联的语汇或短语添加超链接,指向相应的维基页面.我们视维基文章为结点,文章之间的超链接为从一结点到另一个结点的边,将得到一个有向图(如图1中Ai组成部分).维基百科中,除“Category:Contents”作为所有分类的根结点外,任意文章和分类都隶属于至少一个分类,比如文章“Semanticsimilarity”隶属于分类“Computationallinguistics”和“Statisticaldistancemeasures”.这两个分类可能还有多个双亲分类和多个子分类.可见,维基百科的分类结构不是一个简单树型结构的分类系统,而是以树为主的有向图.因此,维基百科的分类具有同义词典的特征.维基百科中的文章与分类之间的链接是双向的,每篇文章指向一个或多个分类,一个分类指向多篇文章和多个分类.可以将分类看作是文章的语义标签.可见,文章网络和分类树(以树为主的图)具有紧密的关联关系.文章网络中的链接代表文章的关联,分类间的链接则代表上下位关系或部分整体关系.3.1.3重定向页面和消歧页面维基百科中,一个概念只会对应一篇文章来描述它,但一个概念可能存在多个同义词,维基百科为不同的同义词设置了重定向页面,将其重定向到唯一的文章页面.比如“King”和“Monarch”都有国王的意思,维基百科中只有一篇名为〈Monarch〉的文章来描述这两个词,当我们搜索“King”,系统会自动重定向到〈Monarch〉.人类语言中的同一个词可能会有多个解释,我们称之为歧义.维基百科为了解决一词多义的问题,Page4设置了消歧页面,让用户在消歧页面中选择自己想要了解的意项.消歧页面中意项的格式一般为“歧义概念(注释)”,维基会根据被选频率推荐一个首选解释,其它的解释按不同类别排列.比如概念“Ring”,推荐解释是“Ring(jewellery)”,而又按“Artsandentertainment”、“Music”、“Scienceandtechnology”、“People”、“Places”、“Sports”和“Otheruses”分别排列.如下所示(不完全示例):Ring(jewellery)ArtsandentertainmentRing(film),a1998horrorfilmbyHideoNakataRings(shortfilm),a2005horrorfilmbyJona-thanLiebesmanMusicRing(TheConnellsalbum),1993Ring(MiliyahKatoalbum)Ring(GaryBurtonalbum),19743.1.4维基概念维基百科中的每篇文章都被认为是对一个维基概念的描述,而文章的题目就是维基概念的名称.如上文中的文章〈Monarch〉就是对维基概念“Monarch”的描述.这样,维基的数据集就可以看作维基概念的集合.3.2问题定义词语之间的语义关系[15]有语义关联度、语义相似度和语义距离.为了研究完整性,下面给出这些概念的简略定义.定义1.语义关联度.语义关联度描述两个词语之间的任何关联关系(包括如上下位关系、同义关系、反义关系和整体局部关系等),通常是两个词之间数据化的相似性.定义2.语义相似度.语义相似度是关联度的一个特例,只包括词语之间的上位关系和同义关系.定义3.语义距离.语义距离是基于距离的语义关联度的表示方法,两个词之间语义关联度越大,语义距离越小.本文核心的研究是词语或短语之间的语义关联度的计算.首先,将待比较词语分别映射到维基概念;之后,通过计算维基概念间的语义关联度得到待比较词语的语义关联度.4词语映射词语映射是将要比较的词语映射为维基概念.进行映射时,需要解决两个问题:一词多义(歧义)和同义词.一词多义是指同一个词汇具有不同的意思,比如lead的意思有:(1)v.&n.领导,引导;(2)v.领先,占首位;(3)v.通向,导致,引起;(4)v.经验,过(生活);(5)n.铅.我们需要根据上下文语境来推断lead的准确意思,金属lead是“铅”,而“leadahardlife”中的lead是“经验,过(私生活)”.同义词是指多个词汇具有同一个意思,比如abandon的同义词有:(1)desert;(2)forsake;(3)leave;(4)giveup.所以在计算某一词与另外一词的语义关联度时,需要能够对它进行同义替代.本文通过超链接来识别词语的候选概念.维基百科的文档中,跟某一重要主题相关的词汇或短语通常会有超链接指向该主题的文章,因此,维基文章中会有很多的超链接文本,并涉及到歧义和同义,比如,abandon会根据不同的上下文而指向不同的文章,而desert、forsake、giveup和leave很可能会指向相同的文章.消歧页面可以解决一词多义,重定向页面可以将同义词重定向到同一文章.因此,本文映射的全过程是:首先,获得所有被计算词语语义相关的维基概念及其相关文章题目;然后,扫描括号中的解释部分实现最佳匹配.在映射过程中,有些文章题目可以直接被映射到,重定向页面可解决同义词的映射,而对于一词多义,可通过分析相应的连接关系消除歧义页面.可见,在词语映射中,本文充分利用了维基百科的不同类型页面,并且只使用文章题目,而不涉及文本内容.本部分的目标是尽最大努力准确地实现概念映射,且仅需较少代价.5基于维基百科结构信息的语义关联度计算算法WSR维基百科的结构典型包括如下两个网状结构:文章网络和分类树.WSR算法是充分利用这两个网状结构中的语义知识而提出的语义关联度计算方法.首先,分析文章网络的多层次结构,结合Jaccard系数,得到基于文章网络的语义关联度算法RelArtNet;然后,根据分类树的类本体结构,结合基于本体的关联度算法思想,得到基于分类树的语义关联度算法RelCatTree;最后,综合RelArtNet和RelCatTree得到WSR算法.Page5图2为维基百科链接结构示例,其中,概念结点a和概念结点b之间有多个直接或者间接相邻的其它概念结点,概念结点间的链接类型分为输入链接和输出链接两类.相邻概念结点之间存在语义关系,有助于语义计算.5.1基于文章网络的语义关联度计算算法RelArtNet5.1.1Jaccard系数简介Jaccard系数,也叫Jaccard指数,来源于统计学,最早由PaulJaccard提出.它可以用来比较两个样本集合的相似性和差异性.Jaccard系数通过样本集合的交集除以样本集合的并集得到:5.1.2简单的基于文章网络的语义关联度计算算法维基百科中,概念a与概念b分别有多个直接相邻的概念结点,它们之间的链接关系代表了一定程度的语义关系.因此,可以通过对相邻概念结点的统计运算来得到概念a与概念b的语义关联度:Rel(a,b)=Neighbor(a)∩Neighbor(b)其中,Neighbor(a)表示与概念a相邻的结点,Neighbor(b)表示与概念b相邻的结点;|Neighbor(a)∩Neighbor(b)|为概念a与概念b的相邻概念结点的交集的个数;|Neighbor(a)∪Neighbor(b)|为概念a与概念b的相邻概念结点的并集的个数.使用Jaccard系数可保证语义关联度在[0,1]闭区间上,关联度的值越大表示语义关联度越强.但RelArtNetSimple算法存在如下不足:(1)将所有链接同等对待,没有考虑权重区分度;(2)只考虑了直接相邻的概念结点,未考虑间接关联的概念结点.针对上述不足,我们进行了如下改进:(1)引入带权重的链接,并通过链接的权重来计算概念的语义关联度;(2)层次划分相邻结点,并按层次计算其语义关联度,各层次的语义关联度加权求和得到最终语义关联度.详细介绍见下文.5.1.3引入带权重的链接为给链接赋予权重,需要经历链接权值初始化、基于TF-IDF的链接权值演化和确定相邻概念结点权值3步完成.(1)链接权值初始化维基百科中包括了多种链接,本文只关注特定的几个链接,并且给它们赋予相应的初始权值.双向链接.两篇文章分别有链接指向对方,表示两篇文章具有较强的语义关联.比如说,概念“中国”和“北京”之间就有着很强的关联关系,因为主题为“中国”的页面表示中国的首都是北京,同时主题为“北京”的页面也表示北京是中国的首都.相反,位于中国山西省平遥县洪善镇的“白家庄村”跟“中国”有较弱的语义关联,因此在“中国”的主题页面上并没有指向“白家庄村”的链接.这种单向链接代表的语义关联度要比双向链接弱.SeeAlso链接.大部分的维基百科文章都有SeeAlso链接.这些链接指向的文章跟该文章具有很强的语义关联.因此,SeeAlso链接对于语义关联度计算是非常重要的.反向SeeAlso,即被SeeAlso链接所指向的文章接受到的链接,同样具有很强语义关联.同一分类下的文章之间的链接.维基百科有一个丰富的分类结构(以树为主体的图结构),而隶属于同一分类的文章之间应该具有明显的语义关联.但不可避免的是,有一些分类是比较边缘的,可能会包括一些不关联的文章.比如“中国大陆演员”包括了超过1000篇的文章,但这些演员中大部分(如‘周璇’和‘李胜素’)之间的语义关联并不太强.维基文章中的普通链接.代表一定的语义关联,通常经过人工语义判断发现,指向链接(从某篇文章指向另外一篇)的语义作用要强于被指向链接(从别的文章指向本文章).表2给出了各种连接被赋予的经验权重.链接类型初始权值链接类型初始权值SeeAlso链接0.7双向链接1.0反向SeeAlso链接0.4同分类链接0.6NavBox链接0.6信息盒链接0.7普通指向链接0.5普通被指向链接0.3Page6(2)基于TF-IDF的链接权值演化在一份给定的文件里,词频(TermFrequency,TF)指的是某一个给定的词语在该文件中出现的次数.逆向文件频率(InverseDocumentfrequency,IDF)是一个词语普遍重要性的度量.某一特定文件内的高词语频率,以及该词语在整个文件集合中的低文件频率,可以产生出高权重的TF-IDF.因此,TF-IDF倾向于过滤掉常见的词语,保留重要的词语.本文借鉴TF-IDF思想,使用概念的相关链接出现的概率来代替TF-IDF中的词语出现的概率.设s,t分别是源概念和目标概念,那么s→t的权值描述为w(s→t)=w(s→t)0×|s→t|其中,w(s→t)0是s到t的初始权值;|s→t|是s到t的链接数目,|s→x|是从s出发的所有链接数目,|s→t|/|s→x|是从s到t的链接占从s出发的链接的比例,对应TF-IDF中的TF;|all|表示维基百科中的链接总数目,|y→t|表示任意概念结点到t的链接数目,log后面的部分是任意一条链接指向目标概念的反比例值,如果不存在该链接,则取0,对应TF-IDF中IDF.如果同时有很多文章指向了同一目标文章,那么在判断其中两篇文章的关联度时,不能给予这条链接太大权值.比如,如果两篇文章同时指向了“Art”,而另外两篇文章同时指向了“Softrock”,显然前者的权值应该小于后者的权值.对于间接相邻的概念结点,采用递减乘法计算链接权重.如图3所示,a到e的权重为w(a→e)=w(a→c)×(w(c→e)×φ),其中φ是层次递减系数,随着距离的增加,概念之间的关联度则减小.本文中φ=0.9.(3)相邻概念结点的权值为适应Jaccard系数公式,需要将链接的权值转换为概念结点的权值.因此,以a,b为源概念结点,则目标概念结点x的权值是w(x)=如果x是a和b的共同邻结点(直接或间接),那么x的权值是w(a→x)和w(b→x)的平均数;如果x只是a或b中的一个结点的单一邻结点,那么x权值是w(a→x)或w(b→x);其它情况下,x被认为与源概念结点无关,权值是0.5.1.4层次划分相邻结点将结点按层次划分,与源概念结点直接相邻的为第一层相邻结点,依次类推.对于某一层的邻结点,源概念的关联度描述为Rel(a,b)=∑w(x)x∈Neighbor(a∩b),y∈Neighbor(a∪b)结合结点层次结构和链接权重,基于文章网络5.1.5语义关联度计算算法RelArtNet的语义关联度描述为Rel(a,b)=α×Rel1+β×Rel2+…+ω×RelN其中,Rel1,Rel2,…,RelN是概念a,b的相应层次的关联度,α,β,…,ω是相应层次的权重,且α+β+…+ω=1.本文N=3,α=0.6,β=0.3,γ=0.1(本文的最外层权重).5.2基于分类树的语义关联度计算算法RelCatTree维基百科中每篇文章都至少隶属于一个维基分类,并且文章与分类之间存在紧密的语义关系.维基分类是以树为主体的图结构,具有分类系统的特征,因此,我们将分类系统的关联度计算方法用在分类树上.Lin[16]提出了基于分类系统中的结点的关联度计算方法.比较分类系统中的两个分类C1和C2(具体实例)的关联度时,并不比较它们自身.例如,计算工具汽车跟火车的关联度时,不是将工具汽车的集合与火车的集合(具体实例)进行比较,而是比较工具汽车类与火车类(抽象类).即用Rel(C1,C2)来表示x1,x2的关联度,其中,x1和x2是实例,C1和C2是类,x1∈C1,x2∈C2.“x1∈C1”和“x2∈C2”是独立的,因为从C1中任选一个实例x1和从C2中任选一个实例x2是完全没关系的.“x1∈C1,x2∈C2”的信息量是-log(P(C1))-log(P(C2)),其中,P(C1)和Page7P(C2)是从C1和C2中分别随机选取实例的概率.在树型的分类系统中,如果C1,C2是分类系统中的类或概念,x1∈C1,x2∈C2,C0是C1,C2的最小共同蕴含(leastcommonsubsume),那么,x1,x2的关联度为Rel(x1,x2)=2×log(P(C0))例如,图4为维基百科分类树中的有关“Train”和“Truck”的部分示例,分类旁边数字是信息量.那么,“Train”和“Truck”的关联度为Rel(Train,Truck)=log(P(Train))+log(P(Truck))=0.423.5.3语义关联度计算方法WSR综合基于文章网络的语义关联度计算方法RelArtNet和基于分类树的语义关联度计算方法RelCatTree,得到基于维基百科结构信息语义关联度计算方法(WSR).WSR的处理流程如图5.概念结点a和b的WSR语义关联度是图5WSR处理流程WSR(a,b)=∑N其中,式(8)中加号前半部分表示基于维基百科文章网络的语义关联度,αi是不同层次概念结点的权重,本文中N=3;式(8)中加号后半部分表示基于分类树的语义关联度,根据图1概念结点与分类的隶属关系,概念结点a和b(对应图1中的Ai),至少分别隶属于一个分类aj和bk(对应图1中的Ci),RelCatTree(Caj,Cbk)是aj和bk的语义关联度,βl是其权重,M和P分别是a和b分类的数目.式(8)中的αi和βl通过实验对比得到.从定性角度分析,文章节点是千万级而分类节点是百万级,前者包含的语义知识和关联要大于与后者.本文通过αi和βl分别取多组不同的值,对相应的准确率进行比较,发现∑αi=0.73,∑βl=0.27的时候,准确率最大,其中,α1=0.49,α2=0.15,α3=0.09;βl根据目标节点所属分类的具体情况而定.文章网络的层次N也是通过实验对比取得.通过实验发现,随着N的增加,准确率不断增长,然而,当N>3以后,准确率增加变的不明显,而算法开销却以指数增加,因此,综合考虑准确率和开销,本文N=3.6实验与分析6.1数据源与数据集本文使用的维基百科数据版本于2011年1月Page815日发布.我们选择了数据的sql备份版本,page.sql.gz(716.6MB)是页面信息(包括id、标题等,不包括文章内容)sql脚本,category.sql.gz(14.1MB)是分类信息(包括id、分类题目等),categorylinks.sql.gz(698.9MB)是分类链接信息(包括分类之间、分类与文章之间的链接信息),pagelinks.sql.gz(3.5GB)是页面链接信息(包括页面间的多对多的链接信息).本文的测试集是语义关联度研究领域常用的3个数据集:MillerandCharles(1991)(含30对词语)、RubensteinandGoodenough(1965)(含65对词语)和WordSim-353datasets(Finkelsteinetal.,2002)(含353对词语).6.2算法评价方法定义4.准确率.采用Spearman等级相关系数来衡量目标算法与人工识别的结果的相关程度,称为准确率,即语义关联度.Spearman等级相关系数公式如下其中,di是第i个元素的等级差,对应第i个词对的关联度算法结果和人工识别的结果在各自排序表中位置的差值,n表示测试集的规模.6.3实验结果与分析在3个测试数据集上,将本文提出的3个算法(RelArtNet、RelCatTree、WSR)进行实验,并对RelArtNet进行单因素改变实验,实验结果如下.6.3.1WSR与传统方法的对比图6是WSR算法与传统的语义关联度算法的准确率对比,由于WSR克服了传统方法的缺陷,因此准确率取得了显著的提高.算法时间开销方面,WSR与传统方法相当.6.3.2WSR与WikiRelate、WLM和ESA的对比观察图7可以发现:WSR算法准确率明显优于WikiRelate,也优于WLM.WikiRelate利用了维基百科的分类树中的语义知识,WLM利用了维基百科文章网络中的页面链接信息(直接关链的页面),而WSR算法充分利用了维基百科文章网络中包括直接和间接的多层次的链接信息、文章与分类和分类之间的语义关联关系.ESA是基于维基百科页面文本的算法,使用了大量的文本信息、分类信息和标题信息,它不仅可以计算词语之间的关联度,还可以计算文本之间的关联度.ESA由于背景知识量庞大,需要大量的预处理,算法开销巨大.而WSR仅基于维基百科的结构信息,背景知识量远小于ESA,因此,WSR的算法的开销远小于ESA.由于背景知识的差距,WSR的准确率略小于ESA.图7不同测试集上WSR与其它3种方法的准确率对比从算法时间角度分析,WikiRelate只涉及分类树,数量级是百万,WikiRelate算法时间开销最小;WSR和WLM都涉及到分类树和文章网络,数量级是千万,两者的时间开销是相当的;ESA基于维基百科页面文本内容,因此,它的时间开销要远大于前三者.权衡算法准确率和开销,WSR是一个具有优势的词语或短语之间的语义关联度计算算法.6.3.3RelArtNet、RelCatTree和WSR对比本文提出的3个算法(RelArtNet、RelCatTree和WSR)分别运行在3个测试数据集上的测试结果见图8.Page9通过对比图7和图8中测试结果发现,基于文章网络的RelArtNet算法的准确率略高于基于文章网络的WLM算法的准确率,而基于分类树的RelCatTree算法的准确率与基于分类树的WikiRelate算法准确率基本相当.因为,RelArtNet算法利用了目标概念节点的直接的和间接的相邻概念节点,而WLM只使用了目标概念节点的直接相邻的概念节点.观察图8,RelArtNet的准确率明显优于RelCatTree,因为维基百科的文章网络比分类树蕴含了更多的、更明确的语义知识.WSR的准确率都高于同一测试集下的RelArtNet和RelCatTree.可见,同时利用文章网络与分类树蕴含的语义知识,可以取得比单独使用其中一类具有更高的算法准确率.RelCatTree和WSR的算法时间开销在相同数量级,而RelArtNet的算法时间开销远小于前两者.6.3.4RelArtNet算法分析(1)RelArtNetSimple与单层RelArtNet对比单层RelArtNet算法是指只考虑目标概念节点直接相邻的概念节点时的RelArtNet算法.由图9对比可知,RelArtNetSimple算法的准确率较低,经过赋予链接权值和演化、生成概念节点权值等处理步骤之后,得到了单层RelArtNet算法,取得了更理想的算法准确率.单层RelArtNet算法的时间开销明显大于RelArtNetSimple算法.图9RelArtNetSimple算法与单层RelArtNet(2)层次划分节点对算法RelArtNet的影响本小节研究对节点划分层次对算法RelArtNet的影响,实验数据如图10.图10中单层RelArtNet是指只考虑目标概念节点的直接相邻概念节点的RelArtNet算法,双层RelArtNet是指考虑直接相邻和次相邻的概念节点的RelArtNet算法,依次类推.算法RelArtNet中,层次划分节点具有重要的意义,它将相邻概念节点的范围从直接相邻拓展到了间接相邻.观察图10,随着层次的增加,算法的准确率明显地提高;关注每个测试集上第1列的值、第1、2列与第2、3列的差值可以发现,随着层次的增加,越靠近外层的概念节点,对目标概念节点的语义关联度影响越小.本文的实验中,随着N的增加,准确率不断增长,然而,当N>3以后,准确率增加变得不明显,而算法开销却以指数增加,因此,综合考虑准确率和开销,本文N=3.图10层次划分节点对算法RelArtNet的影响7结束语语义关联度计算是基础性研究课题,它在信息检索、自然语言处理和人工智能等研究领域有着重要地位.语义关联度计算的准确性会直接影响计算机处理信息的准确性.本文主要从维基百科结构信息出发,分析了结构信息中包含的语义知识及关联,提出了一种基于维基百科结构信息的语义关联度计算算法WSR.在后续的工作中,我们将进一步研究如下方面的问题:(1)维基百科包含最丰富语义知识的是维基文章,即维基百科的页面内容,在本文研究的基础上,对页面内容进行语义分析和利用,必定会提高语义关联度计算的准确率.(2)本文研究的链接全部是维基百科的内部链接,除内部链接外,维基百科还有大量指向维基百科以外的链接,通过这些链接,使得它与更广阔的英特网联系起来,英特网拥有海量的信息.通过对维基百科结构化的、明确的语义知识和英特网中的海量信息进行分析,可能会提高语义关联度计算的覆盖度和准确率.(3)在本文的研究基础上,希望将WSR应用在信息检索(如检索推荐)、知识关联和自然语言处理等研究任务中.
