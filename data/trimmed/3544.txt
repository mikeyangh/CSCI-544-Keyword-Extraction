Page1多信息融合的多姿态三维人脸面部五官标志点定位方法郭哲张艳宁林增刚(陕西省语音与图像信息处理重点实验室西北工业大学计算机学院西安710129)摘要针对三维人脸模型面部五官标志点定位对姿态变化非常敏感的问题,提出了一种基于多信息融合的多姿态三维人脸五官标志点定位方法.首先对二维人脸纹理图像采用仿射不变的Affine-SIFT方法进行特征点检测,再利用映射关系将其投影到三维空间,并采用局部邻域曲率变化最大规则和迭代约束优化相结合的方法对面部五官标志点进行精确定位.在FRGC2.0和自建NPU3D数据库的实验结果表明,文中方法无需对姿态和三维数据的格式进行预先估计和定义,算法复杂度低,同时对人脸模型的姿态有着较强的鲁棒性,与现有五官标志点定位方法相比,有着更高的定位精度.关键词三维人脸模型;标志点定位;多信息融合;多姿态;迭代约束优化1引言人脸五官标志点定位是人脸建模、表情分析及人脸识别中的关键技术,准确高效的面部五官特征Page2无法避免的,因坐标轴的变化导致同一个体不同姿态下模型点的对应坐标各不相同.实用的人脸五官标志点定位系统应该是在用户不配合的情况下使用[4],此时人的头部会以多种姿态的形式出现,因此进行标志点定位必须考虑头部姿态的变化,多姿态面部五官标志点定位也一直是人脸识别研究的难点.与二维图像不同,三维数据大都以非均匀分布的三角网格来存储,由此造成一些传统特征提取方法如模板匹配法[5]等较难直接应用于三维数据中.而二维人脸特征点定位的主流方法———主动形状模型(ActiveShapeModel,ASMs[6])、主动表象模型(ActiveAppearanceModel,AAMs[7])以及一系列的改进方法[8-11],由于采用形状模型建模的思路,需要手工标定大量的人脸特征点来进行模型训练,因而较难应用于五官轮廓特征不明显的三维人脸数据.为解决基于三维数据的人脸面部标志点定位,Gordon[12]首先利用曲率特征将三维人脸表面进行分割,并假设人脸对称平面严格垂直来削减姿态变化,从而完成面部特征点的提取.该方法仅在包含24个深度数据的小型数据库中进行了测试.Lu等人[13]采用子空间描述的鼻子侧面轮廓模型来筛选出最佳鼻尖点,同时利用多模态方法提取出眼角和嘴角点.该方法能扩展到任意姿态,但是姿态的量化使得算法所耗费时间以指数级增长,严重影响了实际应用.Colbry等人[14]首先检测出一系列满足特定要求的待选点,并采用迭代最近点匹配方法(Itera-tiveClosestPoint,ICP)来判断最终适合的特征点.该方法对正面姿态人脸数据达到了99%的正确率,对有较大姿态和表情变化的人脸数据达到了82%的正确率,但是在该算法中,任意姿态特征点检测需要大约15s才能完成,算法复杂度大、耗时长.Zhang等人[15]提出了一种多姿态三维人脸特征点提取方法,首先采用曲率特征对人脸表面进行粗分割,其次采用统计形状模型对分割后的区域进行特征点定位,从而实现姿态不变特征点的提取,但是该算法对多姿态人脸模型的特征点定位精度不高.Nair等人[16]提出了一种基于三维点分布模型拟合的面部特征点提取方法,无需对姿态进行估计和补偿,但是该方法需要基于预先确定的基准点来进行.Szeptycki等人[17]提出了一种基于面部曲率分析和几何分布模型的面部特征点定位方法,并通过由粗到精的筛选策略来完成面部特征点的提取.在FRGC数据库下与手动选取的特征点进行对比,鼻尖点定位误差小于8mm,内眼角的定位误差小于12mm.由以上描述可以看出大多数已有的方法或假设姿态是正面的,或以某种方法对姿态进行估计并由此确定平均分布位置下的特征点,或仅对正面姿态人脸模型适用.然而,当三维模型姿态未知或姿态估计过于耗费时间时,以上方法均不适合实际应用.为了克服姿态变化对定位精度的影响,五官标志点定位算法必须对人脸的姿态不敏感,同时能够在非均匀分布三角网格数据中进行.三维人脸数据获取时大都包含相应的二维纹理图像,同时二维纹理图像数据与三维网格数据存在一一对应的映射关系,因此可以利用这种对应关系结合二维图像和三维曲面在人脸五官描述的优势来完成人脸面部五官标志点的定位.根据以上分析,本文提出一种多姿态三维人脸五官标志点定位方法,该方法采用多信息结合的思路,借助二维图像中五官结构轮廓清晰的优势,在多姿态二维人脸图像中提取特征点,并将其映射到相应的三维空间中进行表示;对三维人脸数据采用曲面上局部突变描述的迭代约束进行特征点筛选,最终准确定位出人脸面部五官标志点.2基于二维纹理图像的特征点检测二维人脸图像中的五官结构轮廓相比三维曲面较为清晰,因此可以首先在二维纹理图像中进行人脸特征点检测.而对于二维图像的特征点检测也已有很多有效的方法,Lowe[18]提出的SIFT(ScaleInvariantFeatureTransform)就是其中最具代表性的方法.SIFT描述子具有对旋转、尺度缩放、平移、亮度变化的不变特性,同时对视角变化、噪声也保持一定程度的稳定性,因此适合多姿态人脸图像特征点的检测.但是在实际应用中,不同相机获取到的人脸图像由于相机光轴方向变化往往产生仿射畸变失真,SIFT虽然对仿射变换具有一定的稳定性,但仍不能克服其影响.为了解决SIFT对仿射变换不鲁棒的缺点,Morel等人[19]提出了Affine-SIFT(ASIFT),该方法能够对尺度、相机经度角和相机纬度角等三个参数进行仿真,同时对旋转和平移参数进行归一化,因此在保留SIFT方法优良性能的基础上,对仿射变换具有不变性.ASIFT方法进行人脸二维纹理图像特征点匹配的具体实现步骤如下:Page31.将每幅人脸二维图像对由前视位置绕相机光轴方向可能引起的仿射形变进行仿真,该形变由2个参数决定:相机经度角和纬度角θ.图像经由依照转换倾斜度相关参数t=1cosθ进行旋转.文中,一个由t描述的在x方向上的转换倾斜度可以表示为u(x,y)→u(tx,y).对于数字图像而言,转换倾斜度由一个定向的t子采样来完成,该过程需要首先在x方向上使用一个有着标准偏差ct2槡-1的高斯函数来对图像进行卷积操作.其中c=0.8,该值已被证实能够保证有着非常小的重叠误差[20].2.旋转和转换倾斜度变量通过一系列有限的纬度和经度角来调节,这些参数的采样步骤保证仿真图像与其它由相机经度角和纬度角θ产生的视图相似性较强.图1ASIFT方法正面姿态人脸图像特征点提取结果(FRGC2.0库)图2ASIFT方法仿射畸变人脸图像特征点提取结果(NPU3D库)3三维空间标志点定位三维人脸库中的二维纹理图像数据U={ui∈R2:i=1,2,…,N}与三维网格数据犞={vj=(xj,yj,zj)∈R3:j=1,2,…,M}存在映射关系,记为ψ:ui→vj,i=1,2,…,N|vj0.将第2节得到的二维图像的特征点向三维空间进行映射,二维图像中非人脸区域内检测出的特征点在三维人脸数据中对比较.3.所有仿真图像用相似度不变匹配方法SIFT来进行由图1、图2可以看出ASIFT对仿射变换具有不变性,同时由于其保留了SIFT本身对尺度、旋转、平移的不变特性,因此ASIFT能够较为鲁棒地检测同一个体不同姿态人脸图像对间相匹配的特征点对.可以看出,ASIFT提取的特征点对并非正确对应,大多数特征点在人脸五官描述方面并没有实际意义,对于人脸识别所需要的最为重要的五官描述标志点,绝大多数特征点为冗余特征.为了有效地进行人脸分析,必须从提取出的特征点中抽取出最具有代表性的五官特征描述点.应点的特征值为0,即非人脸区域,由此可以将非面部区域点从三维人脸数据中自动剔除,但在面部区域仍存在较多无特定意义的非五官描述点,需要进一步筛选.人脸区别于其它自然图像最为明显的不同在于有其特定的描述规范,即人脸的面貌特征,而在面貌特征中,又以五官特征为主导,反应了不同人脸之间最为明显的区别.在五官区域的描述中,曲率是较为简单准确的特征,因为五官区域的曲率都有着较为Page4明显的变化.以五官中的鼻子为例,鼻尖点的曲率变化是其邻域中最为明显的.针对该特征,本文提出一种局部邻域突变描述和迭代约束优化相结合的人脸面部五官标志点精确定位方法,首先采用局部邻域曲率变化最大的规则来对第二部分提取出的特征点进行筛选;然后,利用迭代约束的优化方法精确定位五官标志点.3.1五官局部突变描述以P{pi,i=1,2,…,N}表示三维人脸数据集合,对该数据集中的每一个顶点pi,其最大和最小曲率分别表示为k1pi和k2pi,能够描述曲面结构的重要信息,而由最大最小曲率计算出的三维曲面上的脊线和谷线能够较好地描述人脸五官区域的凹凸变化[21],分别以lridge和lvalley表示,其计算原则为lvalley={pi,if(k2pi<kthresh2)|pi∈P}(2)其中kthresh1、kthresh2分别为局部区域的门限曲率,其值可以由遗传算法计算得出.由以上定义脊线和谷线的计算原则,能分别得到人脸五官区域位置的脊线和谷线.假设映射到三维空间的面部区域特征点集由PF{pFj,j=1,2,…,M;M<N}表示,在该集合中按照式(1)和(2)计算满足脊线和谷线的点,并保留相应的脊线和谷线.令特征点集PF内的脊线和谷线分别标记为PF|ridge,PF|valley,并将两集合合并为PF|mark,表示人脸五官的局部突变点集.3.2迭代约束的五官标志点定位为了从五官局部突变点集合PF|mark中确定最终的标志点,需要建立不同姿态人脸数据集中五官标志点间的约束关系,并采用迭代优化的方式进行修正,达到最优匹配.算法思想为:采用spinimage算法[22]建立不同姿态人脸特征点对间的约束关系,然后用最小二乘法进行匹配优化,对匹配结果进行统计分析,得出某一偏差值θ,使绝大多数点均在该偏差值以内,以此偏差值作为阈值滤除偏差大的点,建立新的集合PF|mark,认为被滤出的点是非五官标志点,直到相邻两次阈值之差小于给定的误差值,将此时集合PF|mark中的点确定为人脸五官标志点.算法过程如下:1.假设不同姿态三维人脸数据集Mf,Mnf,分别对Mf和Mnf的突变点集合Pf立spinimage形状编码,并比较这些spinimages建立Mf和Mnf特征点对间的约束关系R={pf2.对R建立的点对约束,计算Pf匹配误差D(pf3.去除Pf新的集合Pf定误差值,迭代结束;4.记此时的Pf的五官标志点.经过迭代优化,眉峰点、内、外眼角点、鼻尖点、嘴角点等共9个人脸五官标志点被确定,对于正面姿态、中性表情人脸模型,以上9个标志点均能精确定位;对于姿态变化较大的中性表情人脸模型,如绕Y轴左、右旋转60°或90°的人脸模型,由于采集数据中标志点本身有所缺失,因此能确定的标志点个数仅为5~6个.图3分别给出了不同姿态、表情人脸模型五官标志点定位结果(见下页).由图3可以看出,对于正面姿态或者平面内旋转姿态变化较小的中性表情人脸模型,9个五官标志点均能较好的定位;但是对于平面外旋转角度较大的中性表情人脸模型(如图3中第2行,第3列),由于采集数据标志点所在区域存在数据缺失,因此仅能定位6个标志点,同时标志点定位精度也有所下降.而对于表情变化的人脸模型,由于表情变化造成人脸表面的严重变形,对五官局部突变影响较大,且由此建立的迭代约束关系R与实际误差亦较大,因此虽然标志点定位个数在7个以上,但是定位出的标志点精度明显比中性表情人脸模型标志点定位精度低(如图3中第3行表情变化人脸模型).4实验结果与分析4.1实验数据采用国际基准三维人脸库FRGC2.0①以及所在实验室建立的NPU3D数据库进行对比实验.FRGC2.0三维人脸库中包含4003个不同个体在4种不同光照下的三维人脸扫描数据(不仅有表面形状数据,还包括相应的纹理图像),但每个个体仅采集正面姿态的三维人脸数据.作者所在实验室自建的NPU3D人脸库是目前国际上包含人脸变换因素最多的东方三维人脸库,共采集300人的数据,每个个体采集35幅包含姿态、表情、遮挡等变化的人脸数据,共包含10500幅人脸数据.姿态变化考虑了三维空间的旋转,每个个体采集14种不同姿态变①http://frvt.org./FRGC/Page5图3FRGC2.0数据库正面姿态模型和NPU3D数据库多姿态、多表情模型标志点定位结果(左上为FRGC2.0人脸数据化的人脸数据,分别为4幅正面姿态,绕Y轴左、右分别旋转30°、60°、90°,俯视,仰视,绕Z轴旋转左、右旋转45°,较为全面地反映了人脸的三维空间姿态变化.为了较为系统地对本文提出的五官标志点定位方法进行评估,将包含姿态变化因素较多的NPU3D数据库按照姿态旋转轴和角度大小的不同划分为若干子库,划分规则如表1所示,由于FRGC2.0库中仅包含正面姿态数据,因此将该数据库整体作为正面姿态(NF)子库.姿态变化子库名称正面姿态(NF)平面内绕X轴姿态变化(PIX)(俯视,仰视)平面内绕Z轴姿态变化(PIZ)(绕Z轴左、右旋转45°)平面外姿态较小变化(POS)(绕Y轴左、右旋转30°)平面外姿态较大变化(POL)(绕Y轴左、右旋转60°)4.2实验结果与分析为了检测本文所提方法的有效性,在FRGC2.0数据库和实验室自建NPU3D数据库中进行对比实验.分别将个数据库划分为一个基准集合和一个测试集合,对于FRGC2.0数据库,由于数据库中每个个体仅包含4个正面三维人脸数据,因此选取200个人的三维人脸数据,每个个体第1个人脸数据作为基准集合,采用手动标记点的方法对五官标志点进行提取,后3个人脸数据作为测试集合;对于包含多种姿态变化的NPU3D数据库,基准集合包含了50个正面姿态人脸数据,测试集合包含50个个体的450个9种不同姿态的人脸扫描数据,姿态分别为:正面、俯视、仰视、绕Z轴左、右旋转45°、绕Y轴左、右旋转30°、绕Y轴左、右旋转60°.对以上数据集合,分别采用定位误差、定位准确率、基于定位特征点的人脸识别正确率、算法复杂度以及算法适用性等5种评价准则来对本文提出的算法与现有算法[12-17]进行对比评估.所有的实验都运行在2.94Page6GHzCPU和1.90GB内存的PC机环境上,采用Matlab7.8.0编程语言实现.4.2.1定位误差对于FRGC2.0和NPU3D数据库,分别在基准集合中手动确定五官标志点作为基准参照点,将每一个由算法定位出的特征点与基准参照点进行比对,并计算两者的欧式距离作为定位误差,用于评价算法对姿态的鲁棒性.图4和图5分别为FRGC2.0库和NPU3D中9个五官标志点的定位误差直方图.由图4可以看出,本文算法对于全部为正面姿态人脸数据的FRGC2.0库,92%以上的模型标记点平均定位误差均在10mm以内.相比同样使用FRGC数据库的文献[17]中的方法(鼻尖点定位误差小于8mm,内眼角定位误差小于12mm),本文方法能够精确定位更多的五官标志点(9个).值得一提的是,文献[17]方法仅对仿真姿态变化的人脸模型进行了实验验证,对于多姿态人脸模型的有效性无从考证.由图5可以看出,对于包含平面内及平面外多角度旋转的多姿态变化NPU3D人脸数据库,本文方法能够使得大约90%的标记点定位误差都在20mm以内,因此图5NPU3D数据库人脸五官标志点定位误差直方图本文方法对于姿态变化具有较强的鲁棒性.同时,可以看出鼻尖点和内眼角点的定位精度要高于其它标志点,这是因为鼻尖点和内眼角点的曲率要比外眼角点受表情和噪声的影响要小,同时鼻尖点和内眼角对姿态变化造成的数据缺失影响亦小于其它标志点.图4FRGC2.0数据库人脸五官标志点平均定位误差直方图4.2.2定位准确率由文献[14]可知,ICP方法对三维模型进行配准时,容差为20mm,也就是说对于标记点定位误差Page7计算来讲,如果定位误差在20mm以内,可以认为定位准确.依据上述原则,对本文提出方法进行定量分析与比较,对于每一个人脸数据模型来说,如果有6个以上五官标志点定位误差在20mm以内,即6个以上五官标志点定位准确,则认为该模型标志姿态变化子库本文方法9标志点定位正确率表2不同姿态子库人脸数据的五官标志点定位准确率本文方法9标志点定位正确率NPU3D数据库98.5%91.6%89.7%73.5%68.2%84.3%POSPOL平均定位正确率由表2可知,本文提出的方法能够定位面部五官的9个标志点,其中眉峰点和嘴角点是文献[14-15]方法所没有考虑的3个标志点.3种方法对正面姿态人脸模型的五官标志点定位准确率很高,均接近100%.本文方法对FRGC2.0数据库的正面姿态人脸数据(NF)的五官标志点定位准确率达到了98.8%的正确率.对于姿态变化较小的人脸模型,如仰视、俯视人脸模型(PIX),本文方法的五官标志点定位准确率亦达到了91.6%,高于文献[15]对5个标志点的定位精度88.3%.而对于姿态变化较大的人脸模型,本文方法具有显著的优越性,对于绕Y轴旋转60°的姿态变化模型(POL),达到了68.2%的定位正确率,远远高于文献[15]方法对于绕Y轴旋转30°姿态变化模型(POS)的五官标志点定位正确率57.7%.本文方法虽然相比文献[14]方法对任意姿态82%的定位精度,略显不足,但是值得注意的是本文方法的定位精度是在正确定位6个以上标志点的前提下计算的,其测评难度本身就远大于文献[14].虽然本文提出的五官标志点定位方法对姿态变化有着较好的鲁棒性,但是,对于平面外旋转姿态变化下的定位准确率相对于其它姿态变化仍然较低,这是因为平面外旋转会引起较大的变形和数据缺失,特别是对于外眼角点、眉尖点以及嘴角点,数据缺失的可能性非常大,因此本文定义的定位正确的条件本身就无法满足,由此造成定位准确率偏低.4.2.3基于定位特征点的人脸识别正确率本文提出的五官标志点定位方法的直接应用为人脸识别,即将本文定位出的五官标志点作为特征点用于人脸识别.为了验证本文方法对于人脸识别应用的有效性,将本文定位出的五官标志点作为特点定位成功.由此分别计算FRGC2.0和NPU3D数据库中各个姿态子库人脸数据模型的五官标志点定位准确率,并与文献[14-15]中的方法进行对比,如表2所示.征点采用多姿态三维人脸识别的基准方法———ICP[23]进行配准识别.由此分别计算FRGC2.0和NPU3D数据库中各个姿态子库人脸数据模型的识别准确率,并与未进行特征点初始化的ICP方法进行比较,对比结果如表3所示.姿态变化子库NF98.2%97.0%98.2%96.6%PIXN/AN/A91.1%88.4%PIZN/AN/A87.5%81.2%POSN/AN/A71.0%63.5%POLN/AN/A65.1%58.2%平均识别正确率98.2%97.0%82.6%77.6%由表3可以看出,采用本文方法定位出的五官标志点作为特征点用ICP方法进行配准识别的识别率总体要比未能提供特征点计算初始迭代参数的ICP方法识别率高.对于姿态变化较大的人脸数据特别是平面外姿态变化数据(POS和POL子库),以上结果尤为明显,采用本文方法定位的标志点作为特征点的ICP方法在POS和POL子库下的人脸识别率为71.0%和65.1%,远远高于传统ICP方法的63.5%和58.2%,可见本文方法定位出的五官标志点可以有效地用于人脸识别.4.2.4算法复杂度算法的复杂度是制约算法进行实际应用的关键因素之一,对于三维人脸五官标志点定位方法来讲,五官标志点的定位结果是为了对三维人脸模型的进一步处理提供较好的初始值,因此五官定位算法的实时性成为衡量算法优良的一个重要指标.本节对不同定位算法对正面及多姿态人脸数据的平均定位Page8时间进行对比评估,结果如表4所示.不同方法正面姿态数据文献[14]方法文献[15]方法本文方法由对比结果可知,文献[14]方法对计算量较小的正面人脸模型,特征点定位平均耗时很小,仅有0.3s,而对任意姿态模型,算法复杂度极高,平均耗时达15s,说明该方法对姿态估计的耗时较长.文献[15]方法建立的统计形状模型对姿态有着较好的鲁棒性,因此该算法复杂度对姿态相对不敏感,正面姿态与姿态变化下定位时间相差不大.本文方法对正面姿态数据的平均定位时间为1.83s,优于文献[15]的方法;对于姿态变化数据,本文方法有着更为明显的优势,平均定位时间仅为2.15s,远远小于文献[14].因此本文方法在算法复杂度和时间效率方面有着较明显的优势.4.2.5算法适用性本文所采用的NPU3D数据库与先前的其它方法[12-14,16-17]使用的数据库相比,包含了多种姿态的变化,同时本文提出的方法无需对姿态和三维数据的格式进行预先估计和定义.虽然文献[16]中的方法也无需对姿态进行估计和补偿,但是该方法需要基于预先确定的基准点来进行.文献[14]方法定位出了鼻尖点和内、外眼角点5个特征点,实验数据库中包含了与本文实验相同的正面姿态UND数据库(其数据亦被收录在FRGC2.0库中),和有着姿态和表情变化的数据库(对每个个体包含6幅姿态和表情变化人脸数据).对UND数据库人脸模型特征点的定位正确率达到99%,平均耗时0.3s,对任意姿态模型定位正确率达到86%,平均耗时达到15s,算法复杂度较高.同时该算法在定位嘴角和眼角点时需要预先通过对2000个人脸数据特征点位置的训练建立特征点的统计分布模型.文献[17]中的方法使用了与本文相同的FRGC数据库,其特征点定位准确率亦采用与手动选取的特征点进行对比的方法来评估,该方法的评估结果为鼻尖点定位误差小于8mm,内眼角的定位误差小于12mm,由于FRGC数据库中仅包含正面姿态人脸模型,因此该方法对正面姿态人脸模型进行人工姿态变化仿真,构建了多姿态变化数据,并进行了实验验证,结果达到了惊人的95.6%的定位准确率.但是该方法的姿态变化数据为仿真所得,可信度较低,而本文方法在FRGC数据库中的9个五官标志点平均定位准确率达到98.8%,与文献[17]方法的结果相当,同时也在NPU3D的多姿态三维人脸子库中进行了实验验证,得到了满意的定位准确率.由以上分析可知,本文提出的方法相比已有方法有着更高的五官标志点定位精度,同时适用于各种姿态变化,可以为人脸模型的下一步处理提供较为准确的标记点,算法复杂度较低,具有很强的实用性.5结论本文提出了一种多姿态三维人脸五官标志点定位方法,该方法采用多信息结合的思路,借助二维图像中五官结构轮廓清晰的优势,在多姿态二维人脸图像中提取特征点,并将其映射到相应的三维空间中进行表示;对三维人脸数据采用曲面上局部突变描述的迭代约束进行特征点筛选,最终准确定位出人脸面部五官标志点.在国际公共人脸库FRGC2.0和实验室自建东方三维人脸库NPU3D的实验结果表明,本文方法对FRGC2.0正面三维人脸模型的9个典型五官标志点平均定位准确率达到98.8%,对NPU3D多姿态三维人脸模型库中姿态变化较小的仰视、俯视人脸模型,定位准确率达到91.6%,高于文献[15]方法的88.3%,对于姿态变化较大的人脸模型,本文方法具有显著的优越性,远远高于现有五官标志点定位方法的定位准确率,姿态变化数据的单次定位时间为2.15s.因此本文提出的多信息融合的三维人脸面部五官标志点定位方法对姿态变化有着较强的鲁棒性,时间效率满足实际应用需要,能够为三维人脸模型的进一步处理提供良好的基础.
