Page1面向高性能计算的众核处理器结构级高能效技术郑方1)张昆1)邬贵明1)高红光1)唐勇1)吕晖1)过锋1)李宏亮1)谢向辉1)陈左宁2)1)(数学工程与先进计算国家重点实验室江苏无锡214125)2)(国家并行计算机工程技术研究中心北京100190)摘要随着半导体技术的进步,众核处理器已经广泛应用于高性能计算领域.而要构建未来高性能计算系统,处理器必须突破严峻的“能耗墙”挑战.文中以一款自主众核处理器DFMC原型为基础,首先对其在典型负载下的能耗分布进行了分析,结合该处理器的具体结构,提出了基于指令窗口的指令缓冲、操作数锁存两种结构级能效优化技术,探索了能效优先的浮点部件设计方法.实验表明,通过上述技术可以降低处理器取指和译码能耗约50%、寄存器文件能耗11.2%和浮点部件能耗17.6%,最终全芯片降低能耗约14.7%.在该文所述实验环境下,作者还进行了DFMC原型的双精度矩阵乘(DGEMM)性能功耗比测试,并与NVIDIA公司的KeplerK20GPU进行了对比.关键词众核处理器;结构优化;能效;高性能计算1引言高性能计算机是21世纪科学研究的重要支柱,技术水平在很大程度上影响甚至决定了相关科学技术领域的创新能力.目前高性能计算机能力处于50P量级(PetaScale,每秒千万亿次运算),美国、日本等先进国家的后续发展计划是在2020年左右达到E级(ExaScale,每秒百亿亿次运算)计算能力.高性能计算机的发展面临能耗、效率、可靠性、应用适应性等诸多挑战,其中能耗挑战被认为是制约高性能计算机发展的最大技术障碍.目前国际上能效比最高的系统,即Green500排名第一的日本研制的TSUBAME-KFC,系统能效比也仅达到4.5GFlops/W(每瓦每秒45亿次浮点计算),与构建E级计算机需要达到的30~50GFlops/W的能效指标还有十倍左右的差距.处理器是高性能计算机的核心器件,其主要参数指标对整个系统的结构和能力起着决定性作用,同时也是系统能量的主要消耗者.根据对集成电路工艺发展路线的分析,尽管晶体管的密度仍然会随工艺进步不断提升,但是每个晶体管的能量优化的速率在快速降低[1],除依靠工艺进步外,还必须对片上结构进行面向能效的优化和针对性设计[2-3].面向高性能计算的处理器,需要在物理可实现性约束下对芯片的性能和功耗进行平衡优化,这也是研发自主处理器的核心目标之一.处理器的高能效技术按照作用的层次可分为系统级、结构级、电路级和工艺级.系统级主要通过软硬协同的方式,根据负载情况进行能耗管理,实现运行、休眠等不同运行等级状态的切换;结构级通过选择面向能效优化的算法和编码,在保证一定性能的前提下,控制芯片的峰值功耗和运行功耗;电路级主要是针对确定功能的部件,选择能效最优的电路实现;工艺级需要密切结合工艺情况,采用合适的晶体管和逻辑器件,优化后端设计流程,以降低功耗[4].本文的研究主要集中在结构级高能效技术上.本文以本团队设计的自主众核处理器原型为基础,对其在典型负载下的能耗分布进行了分析,针对其能耗特征结合处理器结构提出了基于指令窗口的指令缓冲、操作数锁存两种结构级能效优化技术,探索出了能效优先的浮点部件设计方法.通过实验,获得相应的优化数据,并将实验数据与商用高端GPU进行了对比.本文给面向国产高性能计算系统的处理器设计提供了积极的思路.本文第2节介绍相关工作;第3节对自主众核处理器原型的结构和能耗控制体系进行介绍;第4节对自主众核处理器的能耗分布进行分析;第5节提出针对该处理器能效优化的结构级技术和方法;第6节为实验结果与分析;第7节总结全文,并对未来工作进行展望.2相关工作(1)高能效处理器结构美国DARPA(DefenseAdvancedResearchProjectsAgency,国防部先进项目研究局)资助的UHPC(UbiquitousHighPerformanceComputing,泛在高性能计算)计划,主要目标是通过软硬件核心技术突破来大幅提升系统能效.该计划中进行结构研究的4个项目中有3个是处理器研究.由Intel公司牵头研究的Runnemede处理器,芯片由通用控制核心和能效优化的执行核心组成,片上支持3层树形网络和4层软件管理的存储层次[5];由NVIDIA公司牵头研究的Echelon处理器,片上集成了少量的延迟优化核心和大量的吞吐率优化核心,在吞吐率优化核心中采用了多种能耗优化技术,它是由GPU技术演化而来的技术方案[6];Sandia国家实验室牵头的X-Caliber处理器,核心思想是使用3D堆叠技术将大量精简计算核心和主存进行片上集成.上述高能效处理器的结构有以下共同特点:片上集成用于管理和计算的异构核心,集成大量充分精简的计算核心,提高芯片能效和集成度;通过增强片上存储层次和片上网络设计减少数据移动带来的能耗;放弃支持一致性的Cache和页式TLB(TranslationLookasideBuffer,翻译后备缓冲)结构,降低数据管Page3理带来的能耗;采用软硬协同技术,降低硬件复杂性.(2)结构级高能效设计技术和方法处理器结构级高能效设计技术和方法是目前的研究热点,主要的技术途径是在不影响性能的前提下,通过结构优化的方法降低晶体管的翻转率.高性能众核处理器主要能量的消耗在于核心流水线中的指令系统、寄存器文件和运算部件(尤其是浮点部件)等.指令系统的高能效技术的主要技术路线是在一级指令Cache和流水线之间增加一个较小的指令缓冲,保存并向流水线提供最常使用的指令,以减少对一级指令Cache的访问.该缓冲也可以放置在译码之后,以进一步降低流水线前端的功耗.该指令缓冲可以组织成Cache、存储器或队列的形式,也可以由硬件自动管理或软硬协同管理.学术界和业界根据具体的处理器微结构和技术目标,进行了FilterCache、LoopCache、微操作Cache、指令寄存器文件、译码缓冲等大量技术研究[7-14].寄存器文件的高能效技术主要是减少寄存器文件的访问次数或降低单次访问的功耗.减少寄存器文件访问次数的技术主要是利用旁路直接获取数据,减少不必要的寄存器文件读写[15-16];降低单次访问功耗主要是对寄存器文件进行分割,学术界提出了分体寄存器文件、层次式寄存器文件、分布寄存器文件、操作数寄存器文件等多种优化技术[11,17-20].浮点部件的算法结构很难进行大幅调整,其能耗优化的主要方法是采用更细粒度的门控时钟技术[21]与能效优先的设计空间探索方法[22].3自主众核处理器原型3.1自主众核处理器原型结构在高性能计算领域,大量应用对芯片计算能力有很高要求,同时应用程序的核心段具有良好的并行可分特征,这就使众核处理器具有很好的应用前景.同时,相比多核处理器,众核处理器能够提供更高的计算密度和性能功耗比,被认为是构成未来高性能计算系统的核心器件[23].面向高性能计算的众核处理器结构是国际学术界和业界的研究热点,还存在大量的结构探索空间.本文的研究基于本团队提出的一种自主众核处理器结构DFMC(DeeplyFusedandheterogeneousMany-Core),为验证设计目标,并考虑到知识产权要求,DFMC采用自主设计,并已完成了原型的RTL实现.DFMC原型中集成了两种不同类型核心,分别处理程序中不同特征的代码段,不同类型的核心采用兼容的指令体系;异构核心间实现主存共享.DFMC原型结构如图1所示.芯片主要由管理核心、运算核心(ComputingProcessingElementsClusters,CPE)簇、存储控制器和系统接口组成,这些部件通过片上网络相连接.其中,一个运算核心簇包括多个紧耦合的运算核心,高效完成协同计算.架构中各主要组成部件的配比、运算核心簇的规模等可根据目标灵活调节.管理核心是全功能的通用核心,支持两级Cache结构和SIMD向量指令扩展.管理核心为超标量RISC结构,支持乱序发射、乱序执行和推测执行.运算核心私有的数据存储,可以配置成由软件控制的局部数据存储,也可以配置成Cache的方式.配置成Cache方式时,运算核心间的一致性由软件保证;运算核心的指令存储系统由私有的一级指令Cache和运算核心簇内共享的二级指令Cache构成.运算核心流水线采用双发射、乱序执行的结构,支持SIMD向量指令扩展,支持静态转移预测.运算核心簇的内部结构如图2所示.每个运算Page4核心簇内的运算核心通过高带宽低延迟的簇通信网络交互,并通过簇控制器与片上网络相连接.3.2自主众核处理器原型中的能耗控制体系高能效是自主众核处理器原型设计的核心目标之一,需要在各层次上进行体系化控制,综合达到最优效果.这里对我们在DFMC中采用的能耗控制体系进行简要介绍.其中,结构级是本文研究的重点.(1)系统级系统级高能效技术主要包括从部件到核心再到片上系统的多级低功耗运行模式.各种低功耗运行模式可由硬件自动控制或在软件管理下灵活切换.同时还支持功耗平缓过渡,保证运行模式切换过程中功耗负载大幅变化不影响芯片运行稳定性.(2)结构级片上异构的众核结构,为在结构级进行高能效设计扩展了空间.主要的技术途径是根据高性能计算领域的目标,在保证性能的基础上进行信号翻转率控制、结构精简和数据局部性开发.(3)电路级全面采用门控时钟和操作数隔离技术,充分降低电路翻转率.(4)工艺级根据性能和功耗目标的综合情况,混合使用多种不同域值电压的晶体管单元库等优化技术,保证频率性能的同时有效控制静态功耗.4自主众核处理器原型能耗分析本节通过定量分析DFMC原型的能耗分布情况,进而找到需要进一步进行结构级优化的主要瓶颈问题.为获取在更为精确接近课题情况下实际芯片上运行时的功耗和性能,本文在DFMC原型的全片RTL和门级网表的基础上进行测试,并采用主流商用EDA软件进行分析实验,包括综合工具DesignCompiler、仿真工具NCVerilog等[24].由于真实应用做为激励直接输入网表的方式运行时间过长,本文的能耗计算主要使用课题运行的能耗特征和轨迹推算的方式,测试的方法如下:通过EDA工具获得静态功耗;通过大量针对体系结构设计的特征激励波形VCD注入网表,获得设计中各主要部件和时钟网络在各种运行情况下的动态功耗;在仿真环境中运行实际课题,统计其主要能耗特征和运行性能.汇总上述信息后,折算出应用课题运行的能耗.我们对该方法进行过多道课题的准确性检验,结果与直接波形注入的方式吻合,可信度达到90%以上.本分析对应的自主处理器原型的RTL配置如表1所示.后文中如无特别说明,结构分析所用的配置均基于该表.控制核心运算核心SIMD宽度管理核心存储体系运算核心存储体系簇通信网络拓扑主存系统目标工艺自主处理器原型在不同的负载下,体现出不同的能耗特征.为获得真实应用的能耗分布情况,本文在SPEC2006中选取了部分代表性课题作为测试激励.具体包括CINT2006中的bzip2、mcf、gobmk、hmmer、libquantum、h264ref和omnetpp七个典型课题和CFP2006中的milc、gromacs、leslie3d、namd、soplex和calculix六个典型课题.本文将自主众核处理器原型的能耗划分为运算核心动态能耗、其他部件动态能耗和漏电能耗三大部分.由于运算核心数量众多,是芯片能耗的主体,因此将运算核心进一步细分为ALU部件、浮点部件、寄存器文件、L1指令Cache、译码和L1数据Cache六大部分.其他部件中能量消耗最大的部分是运算核心之外的时钟能耗,另外还包括管理核心、簇控制器、存储控制器和片上网络等部件的能耗.测试的结果如图3所示.各种课题的执行特征不同,能耗分布也有较大差异,图3将各个课题的能耗进行了归一化处理,以便于比较各个课题的能耗分布.本文对选取的各课题运行的能耗进行了平均,其分布如图4所示.从平均分布情况来看,运算核心的动态能耗仍占据了芯片能耗主体,漏电能耗只占约7%的比例.虽然随着工艺的发展,漏电功耗比例有不断增大的趋势,但是众核处理器原型芯片设计过程中采用混合阈值晶体管和其他控制漏电功耗的设计方法[25],可以在保证其性能的基础上有效控制漏电功耗.其他部件中能量消耗最大的部分是运算Page5图3典型课题运行的能耗分布核心之外的时钟能耗,针对该部分的研究主要为时钟系统的电路级优化,不在本文研究范围内.DFMC原型中,运算核心数量众多,并承担了主要的任务负载,其动态能耗占据了整个芯片能耗的59%,其中取指译码部分占总能耗的24%、寄存器访问部分占总能耗的13%、一级数据Cache部分占总能耗的12%、运算部分占总能耗的10%,因此运算核心的动态能耗是本文进一步进行结构级优化的主要目标.5结构级高能效优化本节针对DFMC原型的运算核心动态能耗进行优化.选择了其中的3个部分:取指译码、寄存器文件和浮点部件.面向高性能计算的众核处理器通过集成大量核心实现单芯片较高的聚合计算能力,有限的芯片面积也是结构设计的一个关键约束.本文在优化设计过程中还考虑了具体技术带来的芯片面积增加的影响,结构级高能效技术的一个基本条件是,该技术带来的能耗降低的比例,必须远大于面积增加的比例.5.1基于指令窗口的指令缓冲为减少运算核心一级指令Cache的访问,本文在一级指令Cache和流水线之间增加了容量小、访问能耗低的指令缓冲,同时为节省译码能耗,该缓冲的位置设置在译码站台之后,保存了译码后的指令,命中后不需要重新译码.该指令缓冲在流水线中的位置如图5所示.与已有工作中使用Cache或基本块组织指令缓冲的方式不同,DFMC原型的运算核心采用了基于指令窗口的管理算法.采用Cache管理机制的主要问题在于,DFMC的运算核心为双发射结构,译码宽度为2条指令,如果指令缓冲以2条指令为单位进行管理,将带来很大的Tag开销,对时序和能耗都存在一定的不利影响.而采用基本块的管理方式时,由于基本块大小是动态的,需要支持较多的基本块数量才能保证缓冲的有效填充率(缓冲内有效指令/缓冲容量),例如在缓冲容量为保存256条指令时,至少需要支持16个基本块才能达到较好的命中率,同时支持多个基本块的全相连比较会抵消指令缓冲的功耗收益,在缓冲命中率较低时甚至带来负作用.本文采用基于指令窗口的管理算法,使用循环队列的方式将程序中一块连续的指令序列整个映射到指令缓冲中.指令缓冲的大小与对应的指令窗口相等,并完全对应,该窗口随着代码执行而移动.指令缓冲用一个头指针指示指令窗口起始位置在缓冲内的地址,并用有效位的方式指示指令窗口中的指令在指令缓冲中的保存状态.指令缓冲和指令窗口的对应关系如图6所示.该管理方式可以使缓冲因为管理和比对增加的复杂度最小化,同时也可保证有限的Page6缓冲容量被充分利用.另外,本文的指令缓冲是通过对DFMC运算核心流水线中“指令预取队列”扩展而来的,“指令预取队列”是处理器中为保证转移预测时指令流不出现空槽的必要设计,一个缓冲两种用途使得即使在缓冲命中率较低时,也不会因为对该缓冲的填充带来额外的功耗浪费.指令缓冲的管理算法如图7所示,图中W表示指令窗口的大小.当前PC位于指令窗口内时,硬件将查询指令缓冲内对应的有效位,如果有效位有效,表示命中指令缓冲,即从缓冲中取出译码后的指令;如果有效位无效,则按正常流程取指,同时用译码后的指令对指令缓冲进行装填.当前PC不命中指令窗口时,则按正常流程取指,同时用译码后的指令对指令缓冲进行装填,这种情况下指令窗口需要挪动,挪动的方式需要再分两种情况:如果当前PC到PC+W或PC-W到PC两段区间中的一个与指令窗口有重叠,则将指令缓冲头指针挪动到PC或PC-W,同时移动指令窗口,作废缓冲中超出新指令窗口的部分,但仍保持重叠部分指令有效状态;如果PC-W到PC+W的区间均与指令窗口无重叠,则作废整个指令缓冲,并将缓冲头指针设置为PC,同时挪动指令窗口.判断PC-W到PC+W与当前指令窗口的重叠,目的是尽量多地利用指令缓冲中已有指令,减少作废指令缓冲带来的浪费.5.2操作数锁存面向寄存器文件的结构级高能效技术有两种技术途径:一种是对寄存器文件进行分割或分层,将常用数据保存在访问能耗较少的部分中,使得访问寄存器文件的平均能耗降低;另一种是通过流水线结构优化,减少寄存器文件的读写次数.在DFMC原型中,寄存器文件占用的面积较大、时序紧张,如果在结构级采用分割或分层的方式,将增大寄存器文件面积、影响关键路径的延迟,未来该能效优化思想可在工艺级定制设计流程中考虑.在结构级,主要采用操作数锁存技术,减少寄存器文件访问.操作数锁存包括硬件识别的源操作数锁存和软硬协同的目标操作数锁存技术.该技术主要由一个控制器实现对多个站台的管理,其作用在流水线中的位置如图8所示.已有的通过旁路技术减少寄存器文件的访问的工作,都是将旁路信息完全交由软件管理,依靠编译技术完成对旁路信息的指示,这些技术只能适用于顺序单发射处理器.在乱序多发射处理器中,由于指令调度,流水线的工作情况可能与程序序不同,且相邻指令可能调度到不同流水线上执行,软件无法完成静态的预测.与已有工作不同,本文设计了“操作数锁存控制器”检测两条流水线多级站台的当前状态,对源和目标操作数的行为和状态进行动态分析,设计中除了是否为“临时变量”的标志需要软件指示Page7外,其他均由硬件完成识别,能够在DFMC原型的运算核心的乱序双发射结构下完成操作数锁存,并降低寄存器文件访问频度.操作数锁存的算法描述如图9所示.其中源操作数锁存技术可以发现连续执行指令的相同操作数对同一寄存器文件条目的读操作,在保证前导指令没有通过旁路写回该寄存器文件条目的情况下,硬件自动作废后继指令对寄存器文件该条目的读访问,直接使用锁存在站台中的操作数.目标操作数锁存可以从两个方面节省寄存器文件的访问,如果硬件发现某个源操作数可以从旁路网络得到,则直接作废该操作数对应的寄存器文件读访问,数据从锁存站台获取;如果软件指示某个目标操作数为“临时变量”(该数据若可通过旁路送给后继指令,则不需要写回寄存器文件),当旁路成功后,该目标操作数不写回寄存器文件.//RO(i,j)含义为流水线i等待访问寄存器文件的指令的源操作数j//SO(i,j)含义为流水线i操作数锁存站台保存的有效的源操作数j//BDO(x)含义为流水线x当前送入旁路网络的指令的目标操作数源操作数锁存:条件1:RO(i,j)对应的寄存器文件条目号==SO(i,j)对应的寄存器文件条目号;条件2:旁路网络本拍不修改SO(i,j)If(条件1条件2){RO(i,j)使用SO(i,j)中锁存的数据,不访问寄存器文件}目标操作数锁存:If(RO(i,j)对应的寄存器文件条目==BDO(0)对应的寄存器文件条目){RO(i,j)使用BDO(0)中提供的数据,不访问寄存器文件}If(RO(i,j)对应的寄存器文件条目==BDO(1)对应的寄存器文件条目){RO(i,j)使用BDO(1)中提供的数据,不访问寄存器文件}If(回写站台i对应指令携带软件“临时变量”标志旁路成功){流水线i写回站台的目标操作数不写回寄存器文件}5.3能效优先的浮点部件设计方法面向高能效目标进行运算部件的算法结构调整非常困难.以浮点部件为例,国际上主要的能效优化方法是更细粒度的门控时钟技术与能效优先的设计空间探索方法.DFMC原型中的电路级优化技术采用了细粒度门控时钟技术,本文在结构级的优化方向主要是能效优先的设计方法.能效优先的设计方法主要是通过调整部件内部站台的精细划分和频率约束,寻找功耗、性能与面积的最佳平衡点.本文以自主开发的双精度浮点乘加部件为例,进行了设计探索,采用的主要评价指标包括性能功耗比、性能面积比和实现单位性能情况下的面积与功耗的乘积.本文使用的双精度浮点乘加部件如图10所示.6实验分析本文对基于指令窗口的指令缓冲技术、操作数锁存技术进行了代码实现,对能效优先的浮点部件设计空间进行了探索.采用的测试方法和环境与第4节中使用的方法相同.(1)基于指令窗口的指令缓冲本文实现的基于指令窗口的指令缓冲,容量设置为能够保存256条指令,总面积开销小于一级指令Cache的1/15.另外,由于本文的指令缓冲是在“指令预取队列”的基础上扩展而成,并采用锁存器进行电路构造,其访问能耗基本与深度无关,因此即使命中率较低,也不会因为填充缓冲带来额外的能量浪费.各典型课题在该结构下的指令缓冲命中率如图11所示.由于课题核心段的规模和运行特征不同,指令缓冲命中率差异很大,gobmk课题的命中率高达97.3%,而omnetpp课题的命中率仅为2%,上述课题的指令缓冲平均命中率为52.4%.指令缓冲保存的内容为译码后的指令,命中缓冲的指令的译码能耗将全部被节省,该技术将降低运算核心的平均译码能耗52.4%.另一方面,由于指令缓冲容量远小于一级指令Cache,且管理算法和逻辑非常简单,指令缓冲的访问能耗也远小于一级指令Cache,经计算该技术能降低一级指令Cache平均访问能耗约47%.Page8(2)操作数锁存本文实现的操作数锁存,在原有代码基础上进行了扩展,主要增加的是进行条件判断的组合逻辑,对芯片的面积影响很小.相比于原始设计,各典型课题采用操作数锁存技术后的寄存器文件访问的情况如图12所示.图中分别列出了采用源操作数锁存技术后寄存器文件读访问降低的比例、使用目标操作数锁存技术后寄存器读访问降低的比例和使用目标操作数锁存技术后寄存器写访问降低的比例三组数据.这三组数据的效果可完全叠加.图12使用操作数锁存后的寄存器文件访问率采用源操作数锁存技术,读操作的减少率在0.7%到17.3%之间,平均降低率为9.4%;采用目标操作数锁存技术,读操作的减少率在0.6%~6.6%之间,平均降低率为4.1%;采用目标操作数锁存技术,写操作的减少率在1.1%~12.4%之间,平均降低率为7.8%.根据寄存器文件读写访问的功耗计算,采用源操作数锁存技术平均可降低运算核心寄存器文件访问能耗6.1%;采用目标操作数锁存技术,平均可降低运算核心寄存器文件能耗5.4%.两者叠加,总计可降低运算核心寄存器文件访问能耗为11.5%.(3)能效优先的浮点部件设计方法本文在已有的双精度浮点部件设计的基础上,进行了不同设计参数下的设计空间探索.列出了各种参数下的性能功耗比、性能面积比和实现单位性能的面积功耗积.本文仅以浮点部件为实例进行分析,相关方法可以应用到芯片内的其他部分.本文选取的实现频率为1GHz~1.7GHz,每隔100MHz设置一个实验点.根据具体浮点部件的情况,选择了4级/5级/6级3种不同的内部站台切分方式,站台切分时尽量控制站台触发器数量,在逻辑较窄处进行切分.实验结果如图13所示.图13中,由于6级站台的切分方案继承了性能优先的设计方案,其频率特性较好,EDA工具不用进行大幅优化即可满足频率要求,因此在实验中呈现出性能功耗比基本不变、性能面积比线性增加的特征.而4级和5级两种站台切分方式出现了关键路径,频率约束对其总体特性表现影响很大.图13中可以看出,由于浮点部件的算法没有改Page9变,因此在一种设计之下,性能功耗比和性能面积比无法同时达到最优,例如性能功耗比最优的方案是1GHz、4级站台,而性能面积比最优的方案是1.7GHz、6级站台.单位性能下的面积功耗积是一个比较平衡的参考指标.实验中,面积功耗积最优的设计是4级站、1GHz,比起自主处理器原型最初使用的6级站台、1.2GHz设计,性能功耗比提升17.6%,性能面积比基本相当.这里需要说明的是,面积功耗积仅能做为设计参数选择的参考,实际中还需要根据具体实现条件下的功耗和面积预算约束进行平衡.另外,浮点部件的频率设置还要考虑到整个运算核心其他部件的情况.因此能效优先的设计方法,需要在具体情况下进行大量的实验,才能得到最终综合指标满足要求的设计.(4)综合效果与对比结合整个芯片的平均能耗分布情况,总结了各种技术的综合效果.基于指令窗口的指令缓冲技术平均能够降低译码能耗52.4%、一级指令Cache访问的能耗约47%,折合约降低整个芯片平均能耗的12%;操作数锁存技术平均可以降低运算核心寄存器文件能耗表2与商用GPU运行DGEMM的比较10401173本文401000NVIDIAK20[26]28705225DFMC原型目标工艺为40nm,相比NVIDIAGPUK20的28nm工艺,落后了一代(与40nm工艺相比,相同性能下使用28nm工艺可降低功耗40%以上①).但DFMC的实测的性能功耗比为7.16GFlops/W,仍是K20的1.29倍.这里还需要对本比较的置信度进行补充说明:(1)文献[26]测试的是GPU的板级功耗,除了GPU功耗外,还包含了GDDR5显存芯片的功耗.本文的测试数据只包含DFMC原型的芯片功耗,不含主存功耗.K20GPU加速卡上包含了10片GDDR5颗粒,根据三星公司的文献数据②,其总功耗估计在15W左右,约占GPU测量总功耗的7.9%.(2)本文采用的是评估功耗,而GPU功耗是实测值.尽管本文的功耗分析方法,使用的是课题运行信息和设计电路物理信息,接近真实芯片的工作情况,但仍会与最终芯片的功耗有一定差异.根据本团队的芯片设计经验,该差异应能控制在15%以内.综上,面向40nm工艺设计的DFMC原型的能效11.5%,折合约平均降低整个芯片能耗的1.5%;能效优先的浮点部件设计方法预计可提升浮点部件性能功耗比17.6%,折合降低全片能耗1.2%.综合上述结构级技术,芯片总能耗平均可降低约14.7%.本文还对结构级优化后的众核处理器原型的整体能效情况进行了测试.选择的测试程序为双精度浮点矩阵乘(DGEMM),该程序也是用于高性能计算机TOP500排名的linpack测试的核心.使用了高能效技术优化后的众核处理器原型,设计频率调整为1GHz、浮点部件选择了面积功耗积最优的4级流水线结构,并重新进行了综合布线.在4个管理核心+256运算核心的规模下,通过在RTL上仿真运行的波形注入网表的方式进行能耗测试.测试中本文提出的指令缓冲命中率高达95%,寄存器锁存技术吸收了31%的寄存器源操作数读操作,发挥了很好的节能效果.测试结果如表2所示.为更直观地反映众核处理器原型能效水平,本文选择了NVIDIA公司面向高性能计算的Kepler架构GPUK20进行对比.该款GPU采用28nm工艺,K20GPU实际运行DGEMM的功耗和性能的测量数据来自于文献[26].其结果也列于表2中.水平,与28nm工艺下的NVIDIAGPUK20相当.7结论与未来工作面向高性能计算的众核处理器面临严峻的“能耗墙”挑战.本文以一款自主众核处理器DFMC原型为基础,首先对其在典型负载下的能耗分布进行了分析,结合该处理器的具体结构,提出了保存部分译码后指令的基于指令窗口的指令缓冲技术,该技术能够有效降低处理器运算核心一级指令Cache和译码逻辑平均能耗约50%;提出了操作数锁存技术以减少寄存器文件访问次数,该技术能够减少运算核心寄存器文件平均能耗约11.5%;探索了能效优先的浮点部件设计方法,该技术预计可提升浮点部①②Page10件性能功耗比17.6%.综合使用上述技术,最终全芯片平均能耗可降低14.7%.在本文的实验环境下,DFMC原型在DGEMM课题测试中得到的性能功耗比,与比其工艺先进一代的NVIDIAK20GPU相当.本文工作目前还主要关注DFMC的结构级高能效,未来还将深入研究系统级、电路级和工艺级高能效技术和方法.另外,针对除运算核心外的其他部分的动态功耗优化研究也正在开展之中.
