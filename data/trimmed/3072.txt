Page1分类超曲面算法复杂度研究何清1),2)赵卫中1),2)史忠植1)1)(中国科学院计算技术研究所智能信息处理重点实验室北京100190)2)(中国科学院研究生院北京100039)摘要分类超曲面算法是一种简单的基于覆盖的分类算法.实验证明该算法具有分类正确率高、速度快的优点.但是,关于该算法的相关理论问题需要深入研究.文中对该算法的几个相关理论问题进行了研究.首先给出并证明了在分割的最大层数给定时算法假设空间的VC维,在此基础上结合可能近似正确(ProbablyApproximatelyCorrect,PAC)学习框架,得出了对算法样本复杂度的估计,使得分类超曲面算法保证可PAC学习到任意目标概念.其次,分析了算法的时间复杂度和空间复杂度.最后,给出了无矛盾样本集的概念,并证明当输入样本集是有限无矛盾样本集的条件下,算法一定是收敛的.关键词分类超曲面算法;VC维;PAC可学习性;样本复杂度1引言分类算法研究是机器学习的核心研究内容,分类能力是人类智能的最显著特征之一.基于拓扑学Page2分类超曲面的围绕数的奇偶性即可简单方便地判定其类别.实验表明,在二维、三维及高维空间中,分类超曲面算法分类正确率高、速度快;而存储量和计算量都很小,从而能够处理海量数据.各种分类算法共有的局限性是:每种算法的推广性都依赖于测试数据分布与训练数据分布是否一致.但如何获得数据分布,如何划分可以使测试数据分布与训练数据分布一致是一个难以解决的重要问题.在分类超曲面算法方面,文献[4]通过对极小样本集的研究找到了答案,解决了为什么极小样本集会影响分类准确率的问题,还指出了极小样本集有多少种表达方式.但是,对于该算法的相关理论问题还需要深入研究.在本文中,我们研究了分类超曲面算法的几个相关理论问题,包括VC维、样本复杂度、时间复杂度、空间复杂度以及收敛性等,使分类超曲面算法的理论更加完整.本文第2节介绍与本文相关的工作,包括VC维、PAC框架的相关概念以及分类超曲面算法的简略描述;第3节分析分类超曲面算法的相关理论问题,其中首先证明算法假设空间的VC维,在此基础上结合PAC框架求得算法的样本复杂度;接着分析算法的时间复杂度和空间复杂度;最后给出算法收敛的条件;第4节对我们的工作进行总结.2相关工作2.1VC维的概念VC维是假设空间复杂度的度量标准.为了描述这一概念,首先引入对一个实例集合打散(Shat-tering)的概念[5].对于假设空间H、样本集X以及X的某个子集S,H中的每个假设h导致S的某个划分,即h将S划分为两个子集{x∈S|h(x)=1}以及{x∈S|h(x)=0}.当S的每个可能的划分都可由H中的某个假设来表达时,我们就称H打散S.如果一个实例集合没有被假设空间打散,那么必然存在某个概念(划分)可被定义在实例集之上,但不能由假设空间表示.因此,H的这种打散实例集合的能力是其表示这些实例上定义的目标概念的能力.定义在实例集X上的假设空间H的VC维是可被H打散的X的最大有限子集的大小,记作VC(H)[5].如果X的任意大的子集可被H打散,则VC(H)≡.2.2PAC学习框架及样本复杂度为了描述学习算法L输出的假设h对真实目标概念c的逼近程度,我们引入假设h对于目标概念c和实例分布D的真实错误率.假设样本集X中样本按照概率分布D随机产生.对于X中任意样本x及其目标值c(x)提供给学习算法L,学习算法L输出的假设h的真实错误率为把h应用到将来按分布D抽取的实例时期望的错误率,用errorD(h)表示.即errorD(h)≡Prx∈D[c(x)≠h(x)],其中符号Prx∈D表示在实例分布D的概率.如果一个假设空间是H的机器学习算法L满足如下条件,我们就称L是可PAC学习的:给定任意的实数ε,δ满足0<ε<1以及0<δ<1,如果存在一个正整数m0=m0(δ,ε),对于任意的目标概念c∈H和样本分布D,当样本数mm0时,学习算法L将以至少1-δ的概率输出一个假设h∈H,使errorD(h)ε[6].在上面的定义中,m0是一个学习算法以较高的概率收敛到目标概念所需样本数目的边界,称为学习算法的样本复杂度,即样本复杂度是一个学习算法所需样本数目以确保在误差ε范围内以至少1-δ的概率学习到目标概念.2.3分类超曲面算法概述Jordan曲线定理.Jordan曲线定理.设XR3是闭子集,X同胚于球面S2,那么它的余集R3\X有两个连通分支,一个是有界的,另一个是无界的,X中任何一点的任何邻域与这两个连通分支均相交.分类超曲面算法的理论基础是拓扑学中的Jordan曲线定理可以推广到高维空间.高维空间中的Jordan曲线定理.设XSn同胚于球面XSn,那么mn,否则X=Sn.若m<n,余集的同调群为Hk(Sn\X)特别地,当m=n-1时,Sn\X由两个连通分支组成;当m<n-1时,只有一个连通分支.Jordan曲线定理表明:任何由n-1维球面经连续变形得到的双侧闭曲面都把n维空间分成两个区域———一个外部和一个内部,这种曲面可用于分类,我们称之为分类超曲面.则有下面的分类定理.分类定理.任取x∈Rn\X,则x∈X的内部自x引出的射线与X的相交数(即X关于x的围Page3绕数)为奇数;x∈X的外部自x引出的射线与X的相交数为偶数.基于以上定理,我们可以把与球面同胚的双侧闭曲面作为分类超曲面对空间进行划分.分类超曲面可以由多个超平面构成复合超曲面,而点属于超曲面内部还是外部取决于该点引出的射线与超曲面相交数为奇数还是偶数.文献[2]中给出了详细的训练和预测步骤.训练步骤.1.输入训练样本集,并使样本集分布在超立方体样本空间中.2.把该超立方体均匀地分割为大小相等的更小的超立方体区域,每个区域称为单元格.3.对于每个单元格,如果其中包含的样本属于同一类别,则转步4;如果单元格中包含属于不同类别的样本,则把该单元格作为一个超立方体,跳转到步2(进行局部细化操作).4.对于其中只包含一种类别样本的单元格,标记该单元格的类别为其中样本的类别,并将其边界存储在一个链表中.5.合并相邻且类别相同的单元格,标记合并后区域的类别为原单元格的类别,存储合并后区域的边界作为一个曲面片,所有的曲面片以链表形式存储,形成最终的分类超曲面.预测步骤1.输入待测试的样本,并从它向外引一条射线.2.输入训练步骤中得到的分类超曲面.3.计算射线与曲面片交点的个数.如果射线与某种类别的曲面片交点的个数是奇数,则标记该样本类别为该类曲面片的类别;如果射线与所有类别的曲面片交点的个数都是偶数,则该样本类别不能确定.4.跳转步1预测下一个样本的类别.分类超曲面算法不需要考虑选择使用何种核函数,不需要作升维变换,不需要找出支持向量,它通过单元格合并计算获得多个超平面组成的双侧闭曲面作为分类超曲面对空间划分,使得基于非凸的超曲面的分类判别变得直接、简便、易行.3分类超曲面算法相关理论分析在本节中,我们对分类超曲面算法的几个相关理论问题进行了研究.首先,我们给出分类超曲面算法假设空间的VC维,并在PAC学习框架下得出样本复杂度的结论;接着我们分析了分类超曲面算法的时间复杂度和空间复杂度,最后我们讨论了该算每次分割后所得分类超曲面可抽象为假设h,由分类定理,对于任意的样本x,如果x在闭合的正类别曲面片内,则h(x)=1;反之,如果x在闭合的负类别曲面片内,则h(x)=0.分类超曲面算法的假设空间记作H.为了控制算法的泛化能力,我们限定分割的最大层数为l,即把样本空间最多分割为l层.如果l层结点中的样本不属于同一类别将不再进行局部细化操作,按照多数原则,把该区域类别标记为其中所包含的多数样本的类别.则有下面的定理.法的收敛性和分割最大层数的问题.其中每一部分都给出了严格的证明过程.为了叙述方便,我们以二维样本集为例进行分类超曲面算法的理论分析,所得结论可以直接推广到多维样本集的情况.3.1VC维及样本复杂度在构造分类超曲面时,假设把样本空间或单元格分割为d×d(把每一维分成d等份)个区域.这样分割的结果是一棵正则d2叉树,树中每个中间结点都有d2棵子树.我们定义层的概念:原样本空间对应正则d2叉树的根结点,记作第0层;第i(i0)层的区域经过局部细化步骤后所分成的区域所在层为第(i+1)层.维VC(H)=d2l.定理1.分类超曲面算法假设空间H的VC证明.要证明结论,需要两步:(1)证明H可以打散某个元素个数为d2l的集合;(2)证明任意元素个数为(d2l+1)的集合都不能被H打散.第1步.把样本空间均匀地分割为dl×dl个区域,等价于把样本空间分割为一棵l层的满d2叉树,每个区域对应该树的第l层的某个叶结点.假设在每个这样的区域中各有一个样本,则共有d2l个样本,将这d2l个样本组成一个集合,记作S.设{S1,S2}是S的任意一个可能的划分,下面只需证明分类超曲面算法能够输出一个假设(即分类超曲面)与划分{S1,S2}相对应,即可证明假设空间H可以打散样本集合S.假设S1中的样本都赋予正类别,S2中的样本都赋予负类别,将样本集S作为输入样本集,则分类超曲面算法至多将样本空间分割为l层(满足最大层数的限制)即可使得每个单元格中的样本属于同一类别.经过合并单元格操作后,最终所得的分类超曲面记为h,则由分类定理,h将S1中的样本都判定为正样本,将S2中的样本都判定为Page4负样本.所以h与S的划分{S1,S2}相对应.由以上分析可得,H可以打散S,所以VC(H)|S|=d2l.第2步.设T是任意的含有(d2l+1)个样本的集合.把样本空间均匀地分割为dl×dl个区域,根据鸽巢原理[7],则至少有一个区域,其中含有至少两个样本,不妨记作x1,x2.假设{T1,T2}是T的一个划分,满足x1∈T1,x2∈T2,对于其它样本不加限制,只需要满足属于且仅属于T1和T2中的一个集合.将T作为输入样本集,由于限制分割的最大层数为l,则无论为T中样本赋予何种类别组合(每个样本可以任意赋予正类别或负类别),应用分类超曲面算法后,x1和x2必定在同一个单元格中,进行合并单元格操作后,二者必然在同一个区域中.根据分类定理,最终输出的假设h必定将x1和x2同时判定为正样本或同时判定为负样本,即与假设h对应的划分中x1和x2必定属于同一个子集,所以假设h与划分{T1,T2}不一致.由样本集T中样本类别组合的任意性可得,假设空间H不能打散T.又因为T是任意的含有(d2l+1)个样本的集合,所以H不能打散任意一个含有(d2l+1)个样本的集合,所以VC(H)<d2l+1.综上所述,分类超曲面算法假设空间H的VC维VC(H)=d2l.Blumer等[8]给出了一个保证可能近似学习到任意目标概念所需的样本数目m的边界为m1在PAC学习框架下,应用定理1中的结论和式(1),我们可以得到分类超曲面算法的样本复杂度.推论1.在分类超曲面算法中,每次把单元格分割为d×d个区域,并且限制分割的最大层数为l,则当样本数m满足如下条件时,分类超曲面算法能够以概率(1-δ)输出一个真实错误率小于ε的假设h(即分类超曲面):结论.证明.将定理1中的结果代入式(1)即可证明从推论1的结论中可以看到,算法的样本复杂度以1/δ的对数增长,以1/ε对数乘以线性增长.并且样本复杂度以参数d的幂次增长,以参数l的指数次增长.所以可以选取合理的分割数d和尽可能较小的层数l值以使用较小数目的样本集能够准确高效地学习到目标概念.3.2时间复杂度和空间复杂度分析假设输入样本集含有n个样本,每次进行分割和局部细化操作时,把单元格分割为d×d个区域,同时限制分割的最大层数为l.因为算法的训练步骤是构造分类超曲面的过程,预测步骤是计算从待预测样本出发的射线与训练步骤中所求的分类超曲面的相交数,所以预测步骤的时间复杂度不会超过训练步骤的时间复杂度.故我们只需要分析训练步骤的时间复杂度.在第1步中,输入训练样本集并令它们分布在样本空间内,时间复杂度为O(n).在接下来的步骤中进行分割和局部细化的操作,由于限制最大层数为l,所以在最坏情况下,样本空间被分割成一棵l层的满d2叉树,树中全部结点的个数为1+d2+d2×2+…+d2×l=d2l+2-1间复杂度为Od2l+2-1构造分类超曲面的操作只是在叶结点中进行,所以时间复杂度不会超过O(d2l).综上所述,基于超曲面的分类算法的时间复杂度为O(n+d2l).从分析可以看出,分类超曲面算法的时间复杂度与样本点规模n和两个预先设定的参数d、l有关.所以对于大规模样本集,我们可以设定合理的参数d和l,从而能够保证较高的时间效率和分类性能.关于空间复杂度,在分类超曲面的算法中,所需要的辅助存储空间包括划分后的正则d2叉树中的结点和分类超曲面.由时间复杂度中的分析,在最坏情况下,树中结点个数的复杂度为O(d2l),并且每个结点需要常数个存储单元;存储曲面片的边界只在叶结点中进行,并且每个超曲面片的边界也只需要常数个存储单元,所以总的空间复杂度仍然为O(d2l).3.3收敛性及分割的最大层数为了证明分类超曲面算法的收敛性,我们先给出无矛盾样本集的定义.定义1.对于样本集S={(x1,y1),…,(xn,yn)},其中xi∈R2,yi∈{0,1},i=1,2,…,n,如果对于样本集S中任意的两个样本(xi,yi),(xj,yj),1i<jn,都不出现xi=xj,yi≠yj即两个样本的Page5属性值分别对应相等,但是类别不同,则我们就称样本集S是无矛盾样本集.因为分类超曲面算法是一个构造性的算法,对样本空间和单元格分割和局部细化操作进行完毕,相应的分类超曲面也随之构造完成,所以我们有如下结论.算法一定是收敛的.定理2.对于有限无矛盾样本集,分类超曲面证明.由无矛盾样本集的定义,对于有限无矛盾样本集,不同类别的任意两个样本之间的距离大于零.又因为有限样本集的样本空间是有限的,所以分类超曲面算法经过有限步对样本空间和单元格分割和局部细化操作后,可使每个区域中的样本都属于同一类别,经过合并单元格的操作后,可以得到相应的分类超曲面,即算法收敛,结论得证.证毕.接下来,我们讨论根据样本分布确定分割的最大层数.所谓分割的最大层数,就是对样本空间分割后区域的最大层号.为了得到分类准确率高的分类超曲面,在划分后每个区域中的样本都属于同一类别.我们要确定满足这一要求的最小层号.定理3.设全部样本点分布在L×L的二维样本空间内,不同类别的任意两个样本之间的最小距离为Dmin,分割的最大层号为l,则l=logdL证明.由已知条件,要使划分层数不超过l层,并且使每个区域中的样本都属于同一类别,则必须使第l层区域的大小即第l层单元格边长小于Dmin,这样能够保证不同类别的样本经过分割分布在不同的区域中.经过等距均匀的分割,第l层区域的边长为L要使满足要求,则有Ll>logL从定理3的结论中可以看出,分割的最大层数l的取值是受参数d的值限制的.对于相同的样本集,当参数d的值减小时,l的值增大;当参数d值增大时,l的值减小.又由3.1节和3.2节的分析,算法的样本复杂度、时间复杂度、空间复杂度都以d的幂次增长,以l的指数次增长,所以在应用分类超曲面算法时,可以适当地选用较大的d值,从而能够选用小的l值,使得在保证分类准确率的同时,算法的时空效率也能得到提高.4结论在本文中,我们对分类超曲面算法的几个相关理论问题进行了研究.首先我们证明了在分割的最大层数为l的情况下,算法假设空间的VC维VC(H)=d2l.由得到的VC维并结合Blumer等的结论,我们给出了该算法的样本复杂度:当样本数目ε4log22()δ+8d2llog213()m1算法保证可能近似学习到任意的目标概念.接着,我们分析了时间复杂度和空间复杂度,并得到结论:时间复杂度为O(n+d2l);空间复杂度为O(d2l).最后我们给出了无矛盾样本集的概念,并证明了当样本集是有限无矛盾样本集时,分类超曲面算法一定是收敛的.同时我们还分析了应用算法时参数d和l值的选取问题,得到结论:在保证分类准确率的同时,可以适当地选取较大的d值,从而能够选用较小的l值,使得算法时空效率能够得到提高.
