Page1基于MapReduce快速犽NNJoin方法戴健1),2)丁治明2)1)(中国科学院大学北京100049)2)(中国科学院软件研究所基础软件国家工程研究中心北京100190)摘要kNN连接是空间数据库领域里一个基本而又重要的问题,被广泛地应用于多个其他领域.它对提高众多实际应用的性能有着重要意义.随着目前参加kNN连接的数据集的增大和要求的响应时间的缩短(尤其在一些应急环境中),作者实际上对kNN连接的效率要求更高.然而,目前的方法大多基于单个进程或者单台机器,并不具有很好的伸缩性.为了解决这个问题,作者引入了map-reduce框架来运行kNNjoin并提出了两种新的方法:基于map-reduce的分布式网格概略化kNNjoin(DSGMP-J)和基于map-reduce的voronoidiagram下kNNjoin(VDMP-J).并把它们和最新的方法H-BNLJ进行了实验对比.实验结果证明了作者提出的DSGMP-J和VDMP-J方法具有较优的伸缩性.关键词kNN连接;大数据;MapReduce1引言对很多应用而言,K最近邻连接(kNNjoin)是一个非常基本和关键的操作.这些应用可能来自于知识发现,数据挖掘和空间数据库等.近些年随着移动应用的广泛发展,相应地,kNNjoin具有下面两个趋势:一方面,参与kNN连接的数据集越来越大;另一方面,需要kNN返回结果的响应时间越来越短.传统地,很多K最近邻连接的算法是在单个进程或者单台机器上执行.一般要求是用其中一个集合S的每个元素扫描一次另一个集合R的全部元素,这样,很容易导致计算复杂度为O(|S|·|R|).虽然这样的算法在单进程或者单CPU上运行很好,然而,随着K最近邻连接的规模的增大和要求相应时间的缩短,这些算法不能很好的伸缩,不能满足海量动态数据场景下应用的需求.归根到底,为了能够快速响应大规模的K最近邻连接,我们需要一个具有很好伸缩性,能够并行的集群来进行K最近邻连接的计算.MapReduce体系结构的设计采用了divide-conquer的方法,这是一个简单但功能强大的并行和分布式计算架构.同时,MapReduce充分考虑到可扩展性.近年来,MapReduce得到了来自工业界和学术界的众多支持.在工业界,Google公司内部,通过大规模集群和MapReduce软件,每天有超过20PB的数据得到处理,每个月处理的数据量超过400PB.在数据分析的基础上,Google提供了围绕互联网搜索的一系列服务(包括地图服务、定向广告服务等).如此大规模的在线数据管理和分析,是传统的关系数据管理技术所无法完成的.与此同时,在学术界,一些数据库相关的重要国际会议上近年来也越来越多的出现使用MapReduce来进行大数据处理的方法.MapReduce已经成为了一个充满生命力的大数据处理框架.出于这些考虑,本文中我们用MapReduce贯穿了所涉及到的3个kNN连接处理方法.首先,我们介绍了局部暴力方法,即H-BNLJ(HadoopBlockNestedLoopJoin)方法,并把它作为了我们的baseline方法.然而,由于2次的MapReduce和过多的传输代价,随着数据集规模的增大,通讯代价显著增加,H-BNLJ的伸缩性并不好.然后,我们思考并尝试了使用基于栅格的数据划分方式,同时使用分布式栅格索引对局部数据进行索引,提出了DSGMR-J(DistributedSketchedGridJoin)方法.实验证明,这个栅格的划分方法加上分布式索引的方式可以加速kNN连接的处理过程.但是,由于数据的分布可能呈现出除均匀分布外的多种形式,因此,栅格式划分并不能保证kNN连接结果的局部性.换句话说,在大多数情况下,我们仍然需要2次的MapReduce才能得到kNN的结果.最后,我们设计了一种基于VoronoiDiagram的数据划分方式,在此划分基础上,我们证明了合适的参数选择可以提供一个很好的近似kNN连接结果.从而,通过1次MapReduce可以得到kNN近似连接结果.在第2节,我们形式化定义了本文要解决的问题kNNJoin;第3节,我们介绍本文所涉及到的相关技术;第4节详细给出我们为了解决快速大规模kNN连接所采用的3个方法;这3个方法的对比分析在第5节通过实验结果进行展示;最后,我们在第6节总结全文.2问题定义形式化地,设两个定义在S.这两个集合中的每个记录r∈R(s∈S)都是一个d维空间的点.本文中,为了简单起见并不失一般性,我们考察d=2的情况;同时,两个点之间的距离使用它们的欧式距离来表示d(r,s).这样knn(r,S)返回k个属于S集合的最近邻r的点.我们定义knnJ(R,S)为R和S的连接:knnJ(R,S)={(r,knn(r,S))|forallr∈R}.3相关技术介绍3.1MapReduce作为一种广受关注和欢迎的编程模型,Map-Reduce已经被成功地用在众多大数据集的并行处理程序中[1-6].这些并行程序甚至可以很好地扩展到上千台普通机器上.Hadoop是一个流行的开源MapReduce实现.它运行在Hadoop文件系统(HDFS):一种分布式的存储系统之上.在HDFS中,一个大文件被拆分成很多大小固定的块(不能整除的情况下会有一块碎片)并在计算机之间进行分配.而MapReduce是一种可以直接对这些文件进行操作的框架.一般地,MapReduce包含两个由用户自定义的函数,即map函数和reduce函数.Map函数用于把输入分块对应地转化为中间结果,而Page3reduce函数用于把中间结果进行提取,并进行归纳合并计算得到最终的结果.MapReduce技术是一种简洁的并行计算模型,它在系统层面解决了扩展性、容错性等问题,通过接受用户编写的Map函数和Reduce函数,自动地在可伸缩的大规模集群上并行执行,从而可以处理和分析大规模的数据.形式化地,3.2DSTR-Tree从抽象模型的角度来看,移动对象的时空轨迹对应于X×Y×T空间的一条曲线.在移动对象数据库中往往需要对轨迹曲线进行离散化才能进行进一步操作和处理.网络受限移动对象的动态概略化轨迹R树索引(DynamicSketched-TrajectoryR-TreeforNetworkconstrainedMovingObjects,DSTR-Tree)就是一种采用概率化方法对空间轨迹进行处理的灵活方法.这里,设移动对象的时空轨迹对应于时空空间Ix×Iy×It,其中,Ix=[x0,x1],Iy=[y0,y1],并且It=[t0,T](T代表不断增长的时间).DSTR-Tree将此三维空间的投影空间Ix×Iy栅格化为n×m个栅格,其中ζx=x1-x0n,ζy=y1-y0m.由于It的不断增长,它被划分为等间距Δt的时间段,ζt=Δt.DSTR-Tree是一个非常灵活的移动对象轨迹索引.它的灵活性体现在两个方面:(1)它在Ix×Iy的投影为栅格,而栅格被认为是一种非常高效的二维空间索引结构,并被经常应用于各种实际应用中;(2)它的概率化算法可以有效地把空间轨迹转化成栅格内的线段集合,避免了路网匹配中不能把轨迹匹配到路上的个别情况,从而快速进行处理一些查询(如最近邻查询).3.3沃罗诺伊图沃罗诺伊图(VoronoiDiagram,也称作Dirichlettessellation,狄利克雷镶嵌)是由俄国数学家GeorgyFedoseevichVoronoi建立的空间分割算法.最初来源于笛卡尔用凸域分割空间的思想.Voronoi图是根据目标的最邻近原则而对空间目标所在的整个空间的一种剖分,其中的每一个目标均与其最近的邻近区域即Voronoi区域相连.通常地,一个点目标的Voronoi区域可以定义为由距该点目标比其他所有目标距离近的目标构成:i={x|d(x,pi)d(x,pj),pi,pj∈P,i≠j},pv其中,pv集,x为空间中任意一点,d为距离函数.对组成Voronoi图的每一个Voronoi区域而言,它不仅获取了考察点的空间邻域,反映了它与周围考察点的空间关系,而且Voronoi区域对于不同的空间关系是敏感的,因此相应地,有限的Voronoi内部区域起到了一个无限的外部区域的类似作用,而Voronoi的范围却比目标的补空间大大缩小,易于我们的kNN连接操作.4快速犽NNJoin4.1Baseline:H-BNLJ文献[7]提出了一种H-BNLJ(HadoopBlockNestedLoopJoin)的方法,如图1所示.本文把它作为我们的基准对比方法.这里,H-BNLJ是一种直接的局部暴力解决kNN连接的算法,它利用了MapReduce的嵌套循环算法.基本思想是把待连接的两个集合R和S分割成大小相等的n块,这里可以通过线性扫描的方法来进行,每个块中分别含有|R|n(或|S|块包含一个来自于R的分割块和一个来自S的分割Page4块(也就是总共有n2个连接块).在Reduce阶段,采用了n2个reducer来处理每个mapper生成的中间结果.每个reducer在本地嵌套执行局部R和S的kNN连接,也就是对每个局部块中的S通过嵌套循环找到在局部块中R的kNN.所有来自reducer的结果写入(n2)DFS文件中.然而,注意到在上面的MapReduce过程中,每个记录r∈R出现在一个|R|n个与它相连接的连接块中(与每个来自|S|个连接块).在reduce阶段,只有本地的kNN被发现出来.因此,为了得到全局的kNN连接结果,还需要对每个r∈R通过第1次MapReduce所产生的n×k个候选结果进行筛选.也就是要求对形如(rid,sid,d(rid,sid))的元组进行排序,其中,rid为r∈R中r的id,sid为s∈S中s的id,d(rid,sid)为r和s的距离.这样,第2次MapReduce在map阶段,需要把第一次MapReduce的结果按照rid作为划分划分主键(partitioningkey).同时,第2次MapReduce的reducer遍历(rid,list(sid,d(r,s))),对其中的list(sid,d(r,s))进行按照d(r,s)的升序排序,然后为每个rid得出top-k的结果.4.2DSGMR-JH-BNLJ本质上作为一种暴力解法,虽然使用了两次MapReduce,但并不是一种高效的方法.首先,它划分的依据是线性扫描,如果原本的R和S并没有排序(二维的排序诸如Z-Value等),那么由于不能保证R中元素的全局kNN结果和它被分配到n2个连接块中的某一个(对称地,对S也一样),它在第一步MapReduce得到的结果可能和最后的kNN连接结果偏离很大.其次,由于没有采取索引的方法,将会导致在R或者S很大的时候,H-BNLJ不能有效地从外存(DFS)数据加载内存中.通常来说,索引的本质是排序和内容摘要.为了弥补H-BNLJ的不足,我们引入分布式概略化网格索引(DistributedSketchedGrid,DSG)来对数据进行划分和索引,DSG是DSTR-Tree[8]的变种.DSTR-Tree原本是一种用于移动对象轨迹概略化索引的树形结构,在本文中,我们使用它来进行空间区域的划分和子区域数据的索引.采用DSG而不是简单基于简单栅格的索引的原因在于两个方面.一方面,DSTR-Tree[8-10]很容易将我们的方法扩展到路网空间进行kNN连接.另一方面,DSTR-Tree很容易将我们的应用范围扩展到移动对象(MovingObject)的连续kNN查询.这是我们的下一步工作,超出了本文的内容,但是本文仍将采用DSG来进行索引.为了对数据集R和S进行划分,首先需要对R和S所在空间范围进行栅格化划分.设R所在的空间区间为[Rxmin,Rxmax]×[Rymin,Rymax],S所在的空间区域为[Sxmin,Sxmax]×[Symin,Symax].在进行栅格化处理时,将相应地需要对空间[min(Rxmin,Sxmin),max(Rxmax,Sxmax)]×[min(Rymin,Symin),max(Rymax,Symax)]进行等大小m×m划分,如图2所示.算法1.DSG划分(DSGpartition).输入:R,S,m输出:DSG索引及相应数据块1.xmax=Rxmax>Sxmax?Rxmax:Sxmax2.xmin=Rxmin<Sxmin?Rxmin:Sxmin3.ymax=Rymax>Symax?Rymax:Symax4.xmax=Rxmax>Sxmax?Rxmax:Sxmax5.ζx=xmax-xminm6.ζy=ymax-yminm7.Intervali=[xmin+ζx(i-1),xmin+ζx×i]×8.distributethecorrespondingdataandindex算法1描述了根据R,S的变化范围生成的m2个栅格的过程.其中每个栅格的x和y变化范围为intervalx和intervaly.每个R或S中的元素根据它的x和y坐标确定所属的栅格.对每个栅格而言,我们分布地构建了对应于此栅格的分布式索引DSG.这样,每个reducer可以快速地通过本地DSG索引来发现本地kNN从而避免了嵌套循环.这里,使用本地DSG索引来发现本地kNN是一个filter-refine的过程.显然地,如果当前栅格中的元素RDSG(i)k或者SDSG(i)k(我们总是栅格化含有元素较多的那个集合),并且查询点位于栅格的中央附近的时候(即x-xmin+ζx×i-ζxPage5并且y-ymin+ζy×i-ζyRDSG(i)或者SDSG(i)均分别为对方的kNN.当且仅当RDSG(i)<k或者SDSG(i)<k时候,在本地的kNN才无法发现所有的k个元素,从而需要进行扩展.这里,我们定义x-xmin+ζx×i-ζx且y-ymin+ζy×i-ζy邻域,其中i为栅格的编号.当点不在gridi(δ)邻域的时候,我们这里需要对当前栅格进行扩展.我们的扩展方式有4种:左上扩展,左下扩展,右上扩展和右下扩展.具体地,当x-xmin+ζx×i-ζx(y-ymin+ζy×i-ζy合并原有栅格和相邻左上,上和左边的栅格形成一个新的栅格;当x-xmin+ζx×i-ζx(y-ymin+ζy×i-ζy合并原有栅格和相邻右上,上和右边的栅格形成一个新的栅格;当x-xmin+ζx×i-ζx(y-ymin+ζy×i-ζy展,合并原有栅格和相邻右上,上和右边的栅格形成一个新的栅格;当x-xmin+ζx×i-ζx(y-ymin+ζy×i-ζy展,合并原有栅格和相邻右上,上和右边的栅格形成一个新的栅格.定理1.当δ>maxζy4,ζx()4时候,根据当前点的坐标,我们可以通过一次相应的扩展调整后得到,(x,y)∈gridi(δ).证明.以左上扩展为例,我们有x-xmin+ζx×i-ζx即x-xmin-ζx×i+ζx2<-δ,也就是x-xmin-ζx×i+ζx2+2δ<δ,因为δ>maxζy4,ζx()4,所以x-(xmin+ζx×(i-1))<x-xmin-ζx×i+ζx2+2δ<δ,得到|x-(xmin+ζx×(i-1))|<δ,同样地,|y-(ymin+ζy×(i+1))|<δ.综上,当δ>maxζy4,ζx()4时候,通过左上扩展将得到(x,y)∈gridi(δ).同法,其余3种扩展也可以证明.证毕.然而,即使在扩展后可能仍然无法得到全部的kNN结果集,这时我们仍然需要两遍MapReduce过程来进行kNN连接的结果计算,但是这里的kNN连接的集合为R,其中R为已经完成kNN连接的属于集合R的子集,R为R的补集(这里设|R|<|S|).我们注意到在不预先知道数据集R和S的数据分布的情况下,在某一个m×m子区域mi内的R和S的数据可能很多,然而在另外一个子区域mj的数据可能很少,即mimj.这种不均衡的情况会大大影响我们的两阶段MapReduce过程.由于存在平凡的划分mj,第一次MapReduce中map的结果将会有很多空值.换句话说,极端的情况下,由于R和S的数据分布为r∈R,rgrid(i),DSGMP-J将会退化成H-BNLJ.4.3VDMR-J对应我们的kNNJoin而言,DSGMP-J的不足之处在于,它均匀地划分了空间区域.换句话说,在(XYT)的投影空间(XY)上,DSGMP-J并没有考虑R或者S的原始分布情况.由于VoronoiDiagram[11-12]充分考虑了空间的相互位置关系,基于VoronoiDiagram,对于kNNPage6Join问题,我们可以通过单遍MapReduce来近似完成.我们把方法命名为VDMR-J(VoronoiDiagrambasedkNNJoinusingMapReduce).为了说明我们的近似方法,我们需要证明下面的两个定理及两个相关推论.定理2.凸多边形外的点到该凸多边形各顶点的距离之和大于凸多边形内(上)的点到该凸多边形各顶点的距离之和.证明.不失一般性,设q1,…,qn是凸多边形V的n个顶点,d(r,V)表示点r到凸多边形V的各个顶点的距离之和,且d(r,V)=∑nV外一点,我们可以分两种情况进行讨论:(1)如果p在V的某一条边旁.设p在边qiqj(i≠j)旁,d(p,V)=|pq1|+…+|pqn|.则在凸多边形V内,必然存在一点p,有|pq1|<|pq1|,…,|pqn|<|pqn|,使得d(p,V)=|pq1|+…+|pqn|<d(p,V).(2)如果p在V的某一个顶点旁.设p在边qi旁,则有|qiq1|<|pq1|,…,|qiqn|<|pqn|.使得d(qi,V)=|qiq1|+…+|qiqn|<d(p,V).i=1综上可知命题正确.推论1.设kNNJoin的两个点集分别为R={r1,r2,…,rm}和S={s1,s2,…,sm},其中R的凸壳边界为凸多边形CR(相应地,S的为CS),其顶点分别为R和S中的点,同时,记S所在的Voronoi图记作∪ni=1VDi(S)(设|R|<|S|),则对Rj所对在的VDi(S),我们有Rj到VDi(S)各顶点距离之和小于任何Rj到VDi(S)各顶点距离之和.的凸多边形一一对应.证明.VDi(S)和以当前VDi(S)的点为定点由于Rj在VDi(S)内部,由定理2可知,Rj到VDi(S)各顶点距离之和小于任何Rj到VDi(S)各顶点距离之和.定理3.设集合S={S1,S2,…,SN}S,而且kNN(Rj)S,我们从这些点中按照一定的概率p=1ε2N随机均匀抽样N^次,这样我们可以得到集合S^={S^1,S^2,…,S^N^}(其中ε∈[0,1]).定义r(N,ψ)=∑N足di<ψ.定义s(N^,ψ)=∑N^应地,[di<ψ]=1,如果满足di<ψ.那么,r^(N^,ψ)=1ps(N^,ψ)是r(N,ψ)的无偏估计,且标准差sdεN,ε∈[0,1].证明.首先,S的存在性,我们通过构造的方法可以获得.由定理2和推理2.1我们可以知道,通过扩展Rj所在的VD(S),我们可以不断得到离Rj较近的点集,从而直到kNN(Rj)∪n这些Sj∈∪n得到S={S1,S2,…,SN}S,而且kNN(Ri)S.其次,我们定义N个独立同分布的随机变量,他们分别为X1,X2,…,XN,其中Xi以概率p的可能性为1,1-p为0.我们把这些随机变量和相应的[di<ψ]=1对应起来,就有s(N^,ψ)=∑N^根据定义,Xi是概率为p=1验.这样,s(N^,ψ)就是一个可以表示为B(r(N,ψ),p)的二项分布.根据二项分布的性质,我们可以得到E[r^(N^,ψ)]=E1并且Var[r^(N^,ψ)]=Vars(N^,ψ)[]p=1<N计s∈N的r(N,ψ),则有下面的推论.如果我们使用随机采样的s∈N^的r^(N^,ψ)来估推论2.通过s=arg烐烏烑min得到的s满足Pr[|r(N,ψ)-r|εN]1-e-2/ε.证明.具体地,推理3.1的目标是证明使用r^(N^,ψ)估计出来的kNN结果集和真实kNN结果集的差值以大于1-e-2/ε的概率小于εN.Pr[|r(N,ψ)-r|>εN]=(1-p)2εN=1-1也就是Pr[|r(N,ψ)-r|εN]1-e-2/ε.证毕.Pre-processing.使用Fortune’salgorithm生成相应的具有标签的voronoidiagram.这里,如果|R|<|S|,则生成S相应的voronoidiagram,反之,Page7则生成R相应的voronoidiagram.需要说明的是,一方面Fortune算法是一个增量扫描线算法,这样有2个好处,一个是可以实现对大规模数据的一边加载一边编号,不需要一次性加载所有数据到内存中,另一个是Fortune算法的时间复杂度是O(nlogn),保证了预处理的时间是可以接受的;另一方面,我们使用了改进的Fortune算法,在扫描的同时按照扫描顺序加上了标签(L),L∈N是一个从1开始的递增自然数.Partition.对生成的voronoidiagram的按照L值的大小,进行N分割(N>2k),也就是每N个元素放入一个分割块中,从而得到max(|R|,|S|)分割块.Map.假设我们对如图3所示的数据集进行3-NNJoin操作,我们可以采用2个mapper和1个reducer.首先,每个mapper(mapperi)读取它相应的分割(spliti).所有的在spliti的元素被放入一个hashmap中,其中每个元素的形式为〈rid,VN(r)〉,rid为R中元素的id,VN(r)VDi(S),∪nS为S的第i个包含r的voronoidiagram分割.如果r∈R,我们都有|VN(r)|k,其中,VNk(r)为r的k邻域.根据定理2,我们有kNN(r)=VNk(r).因此,对多个R中元素可以同时求解它们的kNN.Reduce.得到mapper的〈rid,VN(r)〉作为输入,然后进行VN(r)作为搜索空间进行kNNjoin.由定理3可知,在进行N分割后的s=arg烐烏烑minr(N,ψ)|在N足够大的时候,是以较大的概率逼近于真实kNN连接结果的.因此,我们只要通过reducer找出VN(r)的kNN结果即可近似地表示为真实kNN连接结果.需要注意Map函数开始产生输出结果时,并不是简单地把结果直接写到磁盘.每个map任务都有一个环形内存缓冲区.默认情况下,输出会被先写到环形内存缓冲区中,当缓冲内容达到指定比率(一般默认为0.8)时,map任务会把内容溢出写到磁盘中(而不是DFS中).这样,map任务如果还有输出结果,那么它需要进行阻塞直到溢写过程结束.在我们的kNN连接中,如果数据集非常大(即|R|,|S|都非常大)的时候,我们通过配置,采用了两个优化方法.首先,由于数据集非常大,溢写文件的合并是频繁发生的.我们需要根据具体数据集的大小来调整溢写文件的合并值(例如,在hadoop中就是io.sort.factor)来进行调优.其次,当溢写频繁发生时,我们需要对map的中间输出结果进行压缩来减少频繁溢写带来的代价.相应地,在hadoop中,我们需要设置mapred.compress.map.output为true,并定义或者重写相应的压缩方法.在我们的kNN连接中,当k非常大的时候,显然map的输出结果非常大,我们可以在map的基础上定义它的优化函数combiner来限制可用的reduce输入,从而减少对可用带宽的消耗,保证我们程序的健壮性,防止频繁的map任务重分配.当|R|,|S|都非常大,但是|S|在有限的机器节点的情况下,我们可以通过配置combiner合并的溢写次数来进行调优.相应地,在hadoop里,我们需要配置min.num.spills.for.combine属性的值,并且此值必须大于等于3.在本文我们的方法主要适用于|k||S|5实验分析为了验证我们方法的有效性和高效性,证明我们的方法能够胜任快速大规模的kNN连接操作.我们在不同的实验环境下进行了详细的实验及分析,包括不同的数据集,不同的节点数目,不同的连接参数设置.在相同的实验条件下将本文提出的方法和baseline方法进行了对比分析.5.1实验条件实验使用平台配置:DellPowerEdgeR720,处理器类型Intel?Xeon?CPUE5-26200@2.00GHz,网卡6个,内存60907MB,硬盘9.09TB.通过VMwarevSphere5EnterprisePlus进行管理.在虚拟机上我们使用的CentOS5.9的64位系统,使用的Hadoop版本是0.20.2,DFS的块大小是64MB.实验中使用的数据集来源于两个数据源,一个数据源是我们随机生成的数据集D1,另外一个数据源是北京市出租车的数据源D2.D1中我们随机生成了200000000个二维点,然后随机抽取了20000个点作为R中元素,其余作为了S中的元素.D2中包含了北京市的60258辆出租车7天中的运动轨迹数据,我们从中选取了260000条数据记录,并在其中随机选择了10000个点作为R中的元素,其余作为了S中的元素.整个系统的配置图如图4所示.Page85.2实验结果与分析5.2.1不同的数据集及k的影响图5(a)和(b)分别展示了我们在不同的数据集(D1和D2)不同的k取值(k={2,4,6})上运行3个方法(VDMP-J,H-BNLJ和DSGMP-J)的运行时间.关于运行时间这里有两点说明,一是所有的运行时间均为多次实验的平均值;二是这里的运行时间包含建立索引和预处理的时间.另外,本实验的目的在于考察不同的数据集和k对于运行时间的影响,因此,我们设置节点数目均为6.总体上,从图5(a)和(b)中我们可以看出随着k的增加,3个方法的运行时间都在增加.其中,H-BNLJ图5不同数据集不同的k下kNNJoin运行时间的时间增加最为迅速,VDMP-J和DSGMP-J的增加较为缓慢.这说明了VDMP-J和DSGMP-J方法的有效性,通过DSG索引划分和VD划分,和没有进行局部索引的暴力方法H-BNLJ相比,可以有效地减少运行时间.另一方面,在k较小的时候,DSGMP-J往往优于VDMP-J,原因在于DSGMP-J建立索引的时间较短,而且在k较小的时候,DSGMP-J的filter-refine可以有效获取kNN连接的结果.往往并不需要进行第二次MapReduce.5.2.2不同的节点数的影响本实验的目的在于比较采用MapReduce框架的不同方法的伸缩性,即随着节点数目的增加运行时间的变化情况.实验中,对于同一个数据集(D1和D2),我们设置了相同的k值(k=6),并把节点数目(DataNodenumber)从4增加到了6,最后进一步增加到了10,分别运行了VDMP-J,H-BNLJ和DSGMP-J,得到的实验结果如图6(a)和(b)所示.注意由于一次实验结果可能存在一定的随机性,这里,我们的运行时间均为平均时间.而且,我们的时间单位为102s.Page9从图6(a)可以看出,从总体上讲,一方面,随着节点数目的增加,3个方法的运行时间都呈现下降趋势,这说明MapReduce框架本身保证了3种方法的伸缩性都比较好,但是需要指出的是随着节点数目的增多,同时带来的也有通讯代价的增多,因此下降率并不是线性的;另一方面,在运行时间上,H-BNLJ的运行时间一直长于DSGMP-J的运行时间,并且VDMP-J的运行时间最少,这说明VDMP-J的执行效率最高.但是需要指出VDMP-J是一种近似算法,就DSGMP-J和H-BNLJ而言,DSGMP-J较优.另外,需要说明的是,H-BNLJ的下降较为缓慢,DSGMP-J次之,而VDMP-J下降的最为迅速.这里也说明了DSGMP-J采用栅格化的有效性和VDMP-J使用一遍MapRedcue的高效性.图6(b)给出了在数据集D2上运行结果,同样验证了我们上面的两个结论:(1)MapReduce可以保证方法具有较好的伸缩性;(2)在近似的情况下,VDMP-J较优,在精确的情况下,DSGMP-J较优.我们同时也通过实验分析了在不同k下VDMP-J的精度,实验结果如图7所示.可以看出相比较数据集D2,数据集D1的VDMP-J具有较高的精度,这也同时验证了在N足够大的时候,VDMP-J是以较大的概率逼近于真实kNN连接结果的.6结论kNN连接是空间数据库领域里一个基本而又重要的问题,它对提高众多实际应用的性能有着重要意义.随着目前参加kNN连接的数据集的增大和要求的响应时间的缩短(尤其在一些应急环境中),kNN连接的效率要求越来越高.传统的方法大多基于单个进程或者单台机器,并不具有很好的伸缩性.我们发现:一方面,有效的过滤可以减少待比较的两个集合中元素的对数(candidatepair);另一方面,在执行map-reduce的时候,良好的划分策略可以达到较好的负载均衡.基于这两个观察,本文在H-BNLJ两次MapReduce框架的基础上,提出了精确的DSGMP-J和近似的VDMP-J方法,充分利用了局部索引和划分来求解kNN连接问题.实验证明了我们提出的DSGMP-J和VDMP-J方法的有效性和具有较优的伸缩性.
