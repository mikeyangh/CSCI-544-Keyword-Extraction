Page1一种基于并行度分析模型的GPU功耗优化技术林一松杨学军唐滔王桂彬徐新海(国防科学技术大学并行与分布处理国家重点实验室长沙410073)摘要随着硬件功能的不断丰富和软件开发环境的逐渐成熟,GPU开始被应用于通用计算领域,协助CPU加速程序的运行.为了追求高性能,GPU往往包含成百上千个核心运算单元.高密度的计算资源,使得其在性能远高于CPU的同时功耗也高于CPU.功耗问题已经成为制约GPU发展的重要问题之一.DVFS技术被广泛应用于处理器的低功耗优化,而对GPU进行相应研究的前提是对其程序运行过程进行分析和建模,从而可以根据应用程序的特征来确定优化策略.此外,GPU主要由图形处理器芯片和片外的DRAM组成,有研究指出针对这类系统的功耗优化应当综合考虑处理器和存储器,使二者可以互相协调以达到更好的优化效果.文中在一个已有的基于程序并行度分析的GPU性能模型的基础上,综合考虑计算部件与存储部件的功耗,建立了性能约束条件下的GPU功耗优化模型.对于给定的程序,在满足性能约束的前提下,以功耗最优为目标分别给出处理器和存储器的DVFS优化策略.作者选取了9个测试用例在3种模拟平台上进行了实验验证,结果表明文中的方法可以在满足性能约束条件10%的误差范围内获得最优的GPU能量消耗.关键词GPU;并行度模型;功耗模型;功耗优化1引言半导体工艺的发展使得处理器芯片上集成的晶体管越来越多,目前已经达到10亿的量级.图形处理器(GraphicsProcessingUnit,GPU)的性能也因此得到了飞速的提升,并且远远超过了通用CPU.例如,AMD公司推出的FireStream9250GPU[1]拥有800个计算核心,超过1TFlop/s的峰值计算性能,而同时期Intel公司的Core2Quad处理器仅能达到100GFlop/s.随着硬件功能的逐渐丰富以及软件环境的日臻成熟,GPU被越来越多地应用到非图形计算领域[2].随着GPU应用领域的拓展,其功耗问题引起了人们越来越多的关注.虽然性能/功耗比相对较高,但其远高于CPU的绝对功耗也成为了GPU参与通用计算特别是大规模科学计算不可忽略的问题.高功耗不仅使得计算的成本增加,也会导致芯片的可靠性下降,这是科学计算不能容忍的.此外,GPU在移动设备、嵌入式设备上广泛的应用前景也对其低功耗的研究提出了迫切的需求.因此GPU的低功耗优化是一个亟待解决的问题.目前针对GPU的低功耗研究还处于起步阶段,主要原因是缺乏对GPU上程序执行过程的准确分析,因而难以根据程序的特征有针对性地对电压/频率进行调节.现有的GPU支持比较简单的功耗优化,如驱动程序检测到GPU轻负载时降低其频率,而一旦有任务执行时则恢复工作频率,这种优化方式获得的能效比显然没有程序指导下的优化方法高.另一方面,传统的功耗优化技术大多针对处理器,而忽略了存储器.有研究者指出,在一个包含处理器和存储器的计算系统中,存储器消耗的能量不可忽略,能量的优化应同时考虑处理器和存储器,其效果优于只针对处理器或存储器的优化[3].现代高性能GPU中除了显示芯片外,往往还包含一个大容量的存储器,这意味着必须将存储器的功耗纳入GPU的功耗优化范围才能取得较好的优化效果.针对以上问题,本文对GPU的功耗优化展开研究,综合考虑GPU上的处理器与存储器,研究在性能模型指导下的GPU功耗优化方法.为了分析程序的行为特征,同时在优化功耗的同时对程序性能进行一定的约束,我们的功耗优化方法的一个重要的基础是对GPU程序执行过程的分析和程序性能的建模.Hong和Kim在2009年国际体系结构年会(ISCA’09)上提出了一种GPU性能解析模型[4].该模型以NvidiaGPU为硬件平台,CUDA[5]为编程模型,提出了计算并行度(ComputationWarpParallelism,CWP)和存储并行度(MemoryWarpParallelism,MWP)的概念,并以此来分析GPU程序运行过程中处理器与存储器之间的关系,确定出性能瓶颈,并预测程序执行的时间.其实验结果表明,该模型可以比较准确地评估GPU程序的运行时间,因此本文以这个性能模型为基础来指导GPU低功耗研究.本文的主要创新点在于:首先,基于文献[4]分析了程序的计算并行度、访存并行度与处理器、存储器频率之间的关系;其次,根据并行度与频率的关系建立GPU的功耗优化模型并对模型进行求解;最后,对9个科学计算领域常用的核心函数进行了测试,实验结果表明:理论分析给出的频率调节因子可以在达到性能约束条件的10%误差以内,最小化GPU的能量消耗,因此可以有效地指导应用程序在GPU上的低功耗优化.本文第2节分析并建立功耗优化模型;第3节对模型进行求解;第4节给出实验评测;第5节介绍相关工作;最后总结全文.2并行度分析指导下的GPU功耗优化模型2.1基于并行度分析的性能模型一般来说,对功耗进行优化的同时需要保证一定的性能约束,即在性能损失不超过某个阈值的前提下尽可能降低功耗,因此需要一个性能模型对程序的运行时间进行分析和预测.文献[4]中提出的GPU性能模型通过定义CWP和MWP这两个参Page3数来分析GPU程序的性能瓶颈,并据此预测程序的执行时间.CWP用于表示程序执行时计算操作的并行度,主要依赖于程序特征;而MWP则代表了访存操作的并行度,更多地依赖于存储系统的性能.该模型中讨论了CWP和MWP对程序执行时间的影响:当计算并行度高于访存并行度时,访存操作成为程序运行的瓶颈,程序的执行时间也主要由访存时间决定;而当访存并行度高于计算并行度时,程序的计算操作没有完全利用存储系统提供的访存带宽,成为程序运行的瓶颈,因而程序的执行时间主要由计算时间决定.最后,当GPU上运行的计算任务太少时,导致访存操作的延迟无法得到有效的隐藏,程序的执行时间由访存和计算时间之和决定.我们记该性能模型为tk,P表示程序k在GPU平台P下的执行时间.我们的功耗优化方法中使用该性能模型作为性能约束的条件,因此建立功耗优化模型时首先需要分析CWP、MWP和功耗之间的关系.2.2并行度与功耗优化功耗优化通常通过动态电压/频率调节(DynamicVoltage/FrequencyScaling,DVFS)[6]技术实现,它通过在一定范围内降低轻负载的处理器的频率以及电压,使得在损失部分性能甚至不影响性能的情况下减少能量的消耗.电路的核心电压V和其工作频率f一般要同时调节才能保证电路正常工作,它们之间满足f∝(V-Vt)γ一个工艺相关的参数.通常情况下Vt远小于V且γ∈[1,2].本文假定γ=2,此时频率f和电压V近似为线性关系.根据CMOS电路的能量消耗公式P=αCV2f(α是一个与工艺相关的系数),功耗P可以看成和频率f的立方成正比,即P=Kf3.因此本文的功耗优化模型仅关注频率的调节.处理器和存储器的频率对其性能的影响方式是不同的.对于处理器,频率直接决定其运行性能,因此可以认为其运行速度和频率成正比;而存储器的情形则比处理器要复杂一些.我们考察存储器的3个性能参数Mem_L,Departure_delay和Mem_Bandwidth,其中Mem_L表示存储器服务一次访存请求的时间,Departure_delay是指连续两次访存请求之间的最小时间间隔,Mem_Bandwidth则表示存储带宽.现代DRAM存储器一般由存储阵列和存控组成,其中存储阵列用于存储数据,存控则受时钟驱动,对外提供数据访问接口.存储阵列本身的访问延迟(时间)以及相邻两次访问的间隔时间一般是由工艺决定的,不受存控频率的影响.换言之,不同的存控频率对应着不同的延迟周期数,但其绝对时间是基本一致的.因此我们的模型中假定Mem_L和Departure_delay不随着存储器的频率变化而变化.Mem_Bandwidth的情形则有所不同.带宽是指在理想状态下单位时间内存储器可以对外提供的最大数据量,这受限于单位时间内存控的时钟周期数,因此我们认为Mem_Bandwidth和存储器的频率成正比.假定处理器和存储器的原始频率分别为fc和fm,而调节后变为fc=αcfc,fm=αmfm,其中αc和αm为调节系数.下面我们分别给出CWP、MWP和αc、αm的关系.CWP=minComp_cycles+Mem_cycles其中Comp_cycles指的是每个warp的总计算周期,而Mem_cycles则表示每个warp的总访存等待周期,N表示SM内活跃的warp个数.CWP表示在warp的一次访存等待时间内处理器可以计算的warp的个数.当SM内活跃的warp数不够时,处理器无法发挥出计算并行性,CWP由N决定.式(1)中第1项(记为CWP[1])中的计算周期和访存周期都是以处理器的频率fc为参考计量的,因此该式上下同除以fc即可转化为以绝对时间的比值,即(1)CWP.CWP的形式化定义为根据上面的分析,调整频率后,计算时间变为Comp_time/αc,而访存时间不变,因此第1项变为CWP[1]=Comp_time/αc+Mem_time式(1)中第2项为SM上活跃的warp数,与频率无关,因此有(2)MWP.MWP的形式化定义为MWP=minMem_LFreq×Loads_bytes_per_warp×#ActiveSM,)N其中,Mem_L和Departure_delay分别指warp的Page4一次访存等待周期的长度和连续两次访存请求之间的最小时间间隔;Mem_Bandwidth指存储器的带宽;Loads_bytes_per_warp指warp的每次访存包含的字节数;Freq为处理器的频率;#ActiveSM则是指GPU内活跃的SM的个数,N表示SM内活跃的warp个数.注意到这里的访存延迟和时间间隔都是以处理器频率为参考的时钟周期数而非绝对时间.此外,和CWP一样,warp数不足时MWP也由N决定.注意到前面分析存储器频率与其性能的关系时,提到的Mem_L和Departure_delay是从存储器角度看一次访存的时间和相邻两次访存的间隔,属于硬件固有特征,而这里使用的Mem_L和Departure_delay是指一个warp(32个线程)的一次访存时间和相邻两个warp访存之间的最小间隔,这和warp内线程的访存方式有关,由程序和硬件共同决定.但是调整存储器频率并不改变程序的行为,因此后者依然不随着频率变化而变化.即调整存储器频率后,式(3)中的第1项(记为MWP[1])保持不变.对于第2项(记为MWP[2]),由于Mem_L是以处理器的频率Freq为参考计算的时钟周期数,因此Mem_L/Freq即为存储器处理warp的一次访存请求的时间,根据上面的分析,该时间不随着频率变化而变化.第2项中只有Mem_Bandwidth会随着存储器的频率发生变化,即MWP[2]=αm×Freq×Loads_bytes_per_warp×#ActiveSM=αmMWP[2].式(3)中第3项为SM上活跃的warp数,与频率无关,因此有MWP=min(MWP[1],αmMWP[2],N)(4)2.3功耗优化模型通过2.2节的分析,我们得出了调节处理器和存储器频率对CWP和MWP产生的影响,为描述方便,我们将这个关系记为CWP=gc(CWP,αc),MWP=gm(MWP,αm),其中αc和αm分别表示处理器和存储器的频率调节系数.至此,我们可以在性能模型的基础上对功耗优化问题进行建模.假定fc和fm分别表示GPU中处理器和存储器的原始频率,warp的一次计算周期给处理器带来的能量消耗为Ec=Kcf3c,一次访存周期给存储器带来的能量消耗为Em=Kmf3m,其中Kc和Km分别为GPU处理器和存储器相关的常数,功耗优化允许的性能损失因子为β(β1),基于并行度分析的GPU功耗优化问题可以归结为如下规划问题:minE=Kcf3c+Kmf3m烄s.t.fc=αcfc,fm=αmfmCWP=gc(CWP,αc)烅MWP=gm(MWP,αm)Γ(CWP,MWP)βΓ(CWP,MWP烆3功耗优化模型求解本节讨论上述功耗优化问题的求解.绝大部分情况下,SM上活跃的warp数都远大于CWP和MWP,这也是GPU可以发挥出高性能的基础,因此我们的求解重点关注这种情况.warp数不足的情形最后进行单独讨论.此外,为了简化求解过程,我们首先假定处理器和存储器的频率都是连续可调的,然后再考虑解空间的离散化.定理1.满足性能约束,且能量最优时的CWP和MWP满足关系CWP=MWP+1.证明.用反证法.假定满足性能约束且能量最优时CWP≠MWP+1,分以下两种情况讨论:(1)CWP<MWP+1.根据式(1)可知,CWP=1+Mem_p/Comp_p.其中Mem_p和Comp_p分别表示warp的一次访存和一次计算的周期.根据假设条件有,Mem_p/Comp_p<MWP.MWP表示在Mem_p的时间内SM上最多可以同时访问存储器的warp个数,可以理解为存储器向SM提供的“访存通道”的个数.而Mem_p/Comp_p代表了在Mem_p时间内SM流出的计算warp的个数.如图1中所示,除了1号warp的访存请求外,存储器在Mem_p时间内最多还可以服务MWP-1个访存warp,而在这段时间内,只有Mem_p/Comp_p-1个warp需要使用这MWP-1个“访存通道”,因为最后一个计算warp(n号warp)完成时,1号warp的存储访问已经完成,其空出的“访存通道”可以供n号warp使用.因此Mem_p/Comp_p<MWP意味着存储器提供的访存并行性没有被充分利用,此时程序的性能瓶颈在于计算,程序运行的总时间也就近似等于程序的总计算时间.文献[4]中给出在这一情况下程序的总执行周期为Exec_cycles=Mem_p+Comp_cycles×N(5)其中,Mem_p表示warp的一次访存等待周期(等于Mem_L),Comp_cycles则指每个warp的总计算Page5周期.从该式也可以看出,程序的总执行时间主要取决于计算时间.图1中给出了当MWP=n-1而CWP<n时的情况,存储器在1号warp的访存操作结束后到n号warp的计算操作结束之前存在一段空隙.这种情况下,由式(4)可知,通过适当降低存储器的频率以降低访存储并行性,从而更好地匹配计算性能,可以在不影响性能约束条件的情况下减少能耗,即此时能量不是最优的.图1MWP=n-1,CWP<n时warp运行时空图(2)CWP>MWP+1.和第1种情况类似,Mem_p/Comp_p>MWP意味着存储器提供的访存并行性不足以满足Mem_p的时间内SM内流出的计算warp的访存需求.此时程序的性能瓶颈在于访存,程序总时间近似等于访存所占的时间.文献[4]中给出在这一情况下的程序执行时间为Exec_cycles=Mem_cycles×N其中,Mem_p表示每个warp的总访存等待周期,N为SM内活跃的warp的个数,Comp_p则代表warp的一次计算周期.从该式也可以看出,当N足够大时,总执行周期主要由访存周期决定.因此由式(2)可知,通过适当降低处理器的频率以降低计算并行性,更好地匹配存储性能,同样可以在不影响性能约束条件的情况下减少能耗.综上,能量最优时必然有CWP=MWP+1,定理1得证.此外,通过定理证明过程可知,CWP=MWP+1时程序的计算和访存时间完美重叠,计算并行性和访存并行性都得到充分发挥,程序的总运行时间也近似等于计算时间或访存时间.证毕.推论1.满足性能约束T且能量最优时,程序运行的总时间一定是T.证明.用反证法.假设此时程序运行总时间t<T.由定理1可知,此时CWP=MWP+1,程序运行的总时间近似等于warp的计算总时间Tc,因此Tc<T.显然,此时可以通过降低处理器的频率使得计算时间延长至T.降低处理器频率会导致CWP<MWP+1,因此,可以进一步降低存储器的频率以减小MWP,使得CWP=MWP+1,而总运行时间仍然为T.注意到我们的优化目标为E=Ec+Em,即E=Pctc+Pmtm.其中Pc和Pm表示处理器和存储器的功率,tc和tm则表示warp的一个计算周期和一个访存周期的时间长度.根据2.2节中的分析,tc∝f-1c,tm则与fm无关,另外P∝f3,因此我们有E=kcf2c+kmf3m.这意味着我们同时降低了处理器和存储器的频率一定可以减少能量的消耗,即t<T时的能量不是最优的.CWP=MWP+1,代入式(2)和(4),有1+αc(CWP[1]-1)=若MWP[1]αmMWP[2],我们可以得出由定理1,我们可知为达到功耗最优,必须有否则,有但不论哪种情况,此时访存和计算的时间都完美重叠,程序运行的总时间近似等于计算时间或访存时间.即其中Comp_time表示调节频率后一个warp的总计算时间.由推论1,可知其中t为初始条件下程序的运行时间.由定理1的证明过程以及式(5)、(6)可知t≈因此,我们得到Comp_time×N=Comp_time烄=烅烆即αc=αm的解.联立式(7)、(9)或式(8)、(9)就可以得到αc和式(7)、(9)联立后,只有在极端特殊的条件下才Page6有解.因为调节后程序运行时间也近似等于访存时间,即Mem_time为调整频率后一个warp的总访存时间,根据2.2节的分析,Mem_time=Mem_time.而此时由于MWP[1]<αmMWP[2],由式(4)知MWP=MWP[1].因此Mem_time×N即Mem_time×NMWP[1]=烄烅烆我们得到β=当CWP<MWP+1时,有CWP[1]-1MWP的定义也有MWP约束中β1.因此在式(7)、(9)联立时,只有当性能约束条件改为β=1时才有解,并且此时原始程序必须满足MWP=MWP[1]以及CWPMWP+1.此时根据式(7)得到式(8)、(9)联立时,我们可以直接求出αm的值.为达到能量最优,αm取下确界.αm=αc(CWP[1]-1)不难发现,式(7)、(9)联立的解是式(8)、(9)联立解在某些特殊条件下的一个特解.至此,式(9)和(10)给出在warp数足够时,满足性能约束且达到最优能量消耗时,处理器和存储器的频率调节系数.以上的解是在处理器和存储器的频率连续可调的前提下得出的,而在实际中,处理器和存储器都只提供若干个离散的频率值以供调节,因此最后要进行解空间的离散化.根据推论1,能量最优时,程序的运行时间已经达到约束条件的上界,且运行时间近似等于总计算时间或总访存时间.这意味着,此时处理器和存储器的频率都达到了满足性能约束条件时的下界.因此为了满足性能约束条件,只能在离散的频率值中选择不小于理论解的最小频率值.最后我们考虑warp数不足时的情况.由于这种情况出现很少,GPU运行效率极低,使用GPU对应用进行加速没有实际意义,因此这里对模型进行一定的简化.假定对于给定的程序k,在处理器和存储器允许的频率范围内都有CWP=MWP=N,即在任意的频率下,warp数始终不足,此时CWP和MWP都受限于warp数.文献[4]给出的在这一情况下程序的总执行周期为Exec_cycles=Mem_cycles+Comp_cycles+从式(11)可以看出,此时程序的总时间近似等于一个warp的总计算时间和总访存时间之和.根据2.2节的分析可知,计算时间和处理器的频率成反比,而访存时间不受存储器频率的影响.因此有Γ(k,αcfc,αmfm)≈Comp_time+Mem_time从推论1的证明过程中我们不难得出,即便warp数不足时,推论1仍然成立,即能量最优时程序运行的总时间一定为性能约束的上限.因此有Comp_time我们可以得到warp数不足时处理器的频率调节系数αc=Comp_time而此时为达到能量最优,存储器的频率应当降至硬件允许的最低值.4实验为了验证本文提出的GPU功耗优化模型的有效性,我们基于课题组先前开发的一款GPU功耗模拟器进行了一系列测试.本文采用的9个测试用例来自NVIDIACUDASoftwareDevelopmentKitPage7核心函数bitonicblackscholes2000000fwtBatch1matrixmulRandomGPU4096×5860scalarProdscan_bestdwtHaar1Dtranspose256128512256128256512512256(CUDASDK)2.2.1,它们都是科学计算领域中常见的核心函数.表1列出了各计算核心函数的相关参数.其中#thread表示每个block内包含的线程表1Kernel程序说明注:fwtBatch1来自fastwalshtransform,RandomGPU来自MersenneTwister,scan_best来自scan.4.1节将简要介绍实验使用的GPU功耗模拟器,4.2节给出实验结果和分析.4.1实验平台由于现有的GPU对电压/频率的动态调节支持不够完善,可调的档位也很少,不利于进行GPU低功耗优化的理论研究和验证,因此本文采用GPU功耗模拟器进行实验验证.本文采用的GPU功耗模拟器是课题组在GPU性能模拟器GPGPU-Sim[7]的基础上,结合Wattch[8]功耗模型进行开发的.GPGPU-Sim是由BritishColumbia大学设计的时钟精确的GPU性能模拟器,它支持CUDA和OpenCL编程模型,主要模拟现代GPU上非图形类应用的运行.GPGPU-Sim将GPU划分为5个主要模块:ShaderCores、InterconnectionNetwork、L2cache、DRAM以及MemoryController.整个GPU被划分为4个独立的时钟域:Core、片上互连网络、Dram和L2cache时钟域,每个域都按照时钟步进的方式独立驱动模拟.Wattch是低功耗研究领域广泛使用的功耗模拟器之一,它使用一组参数化的解析模型来计算处理器中不同种类部件的功耗.它将部件分为4类:阵列结构、全相联CAM结构、组合逻辑、总线结构和时钟,并分别给出它们的功耗模型.Wattch预先计算好处理器中各种部件的单位活动功耗,并在时钟精确的性能模拟器中通过监视每个时钟周期内部件表2GPU模拟器参数设置MemorySizeQuadroFX5600161.356001.61.5GB76.842010GeForce8800GT141.506001.8512MB57.642010GeForceGTX280301.306021.11GB141.745040数,#Compinst和#Meminst表示每个线程内的计算指令和访存指令的数目,Arith.Int.表示计算指令密度(#Compinst/#Meminst).的活动情况来累计整个处理器的功耗.我们在GPGPU-Sim模拟器中加入了Wattch功耗模型,对GPU中的ShaderCores、L2cache以及MemoryController等部件进行功耗建模;对于InterconnectionNetwork,我们借鉴了PowerRed[9]中使用的功耗建模方法;对于DRAM,我们则借鉴了文献[10]中的方法进行建模.对于每个部件,我们都在其所属的时钟域内统计各周期的活动情况并累计功耗,最后求和得出GPU的总功耗.需要说明的是,由于现代GPU所采用的半导体工艺较Wattch模型中的设定更加成熟,特征系数更小,因而模拟器给出的绝对功耗比模拟的目标GPU稍高(一般误差在10%以内),但作为理论优化方法的研究,本文重点关注的是降频优化后GPU功耗的变化和性能变化之间的关系,而非功耗的绝对值,因此其绝对功耗的误差是可以接受的.4.2结果与分析通过调整配置参数,我们模拟了NVIDIA公司的三款高性能GPU:QuadroFX5600、GeForce8800GT和GeForceGTX280.表2给出了部分功耗模拟相关的配置参数.其中Mem_LD表示访存延迟,Departure_del_uncoal和Departure_del_coal分别表示warp内各线程访问非连续地址和连续地址时相邻两次访存请求之间的最小间隔.表中未给出的其它参数均按照各GPU所对应的CUDA的计算能力[5]规范设置.参数MemoryBandwidth/Page8表3给出各核心函数在不同模拟平台中单位SM上的活动warp数(以下记为N)以及频率设置下的CWP和MWP.从整体上看,N在不同的平台间变化不大,其中有6个测试用例在3种平台上的N完全相同.它们可以进一步被划分成两类:black-scholes、fwtBatch1和transpose的block数足够大,使得各GPU平台的单位SM上活动的block数均核心函数表3活动warp数,犆犠犘和犕犠犘GeForce8800GTbitonicblackscholes325.8611.67325.869.00326.2112.77fwtBatch1matrixmulRandomGPUscalarProdscan_bestdwtHaar1Dtranspose对于CWP,我们可以看出:(1)bitonic、scan_best和fwtBatch1的CWP值较小,这是由于它们的计算指令的密度很大(见表1),因此根据式(1),其CWP值较小;scalarProd的CWP值明显高于其它核心函数,这是由于它的计算指令的密度很低.(2)RandomGPU的计算密度也相对较高,但其CWP明显高于bitonic、scan_best和fwtBatch1,这是由于RandomGPU的访存模式使得其warp的访存等待周期较长,因次虽然其访存指令数目比例较小,但Mem_cycles在总周期中的比例较大,从而其CWP高于上述3个核心函数.(3)matrixmul、RandomGPU、scalarProd和dwtHaar1D在GTX280平台下的CWP明显高于其它平台.这是由于它们的访存模式决定了它们的CWP受限于Departure_del_uncoal参数,而由表2可知,GTX280的这项参数明显高于其它两种GPU平台.对于MWP,我们可以看出:(1)bitonic和scan_best的MWP值没有随着平台变化而变化,这是由于它们都仅有1个block,单位SM上活动的warp数N很小,其MWP值受限于N.(2)matrix、RandomGPU、scalarProd和dwtHaar1D的MWP值较小,这是由于它们的访存模式使得它们的Departure_delay的值远高于其它几个核函数的值,因而式(3)中第1项的值很小,成为决定其MWP的因素.综合CWP和MWP的值可以看出,只有达到GPU的上限(8),因此N的大小仅取决于每个block内包含的warp数,这是由程序决定的,因此在不同的平台上没有变化;bitonic、scan_best和dwtHaar1D的block数太小,只有部分SM被使用,且活跃的SM上最多只运行一个block,因此N也仅取决于block内包含的warp数.对于另外3个测试用例,它们的N则随着GPU上SM数的变化而变化.matrixmul、RandomGPU、scalarProd和dwtHaar1D4个测试用例的CWP要高于MWP,这说明一般情况下,核心函数的CWP和MWP值的相对大小主要取决于其访存模式.对于warp内各线程访问非连续地址的访存模式,MWP值很小,一般低于CWP,此时程序的瓶颈在于访存,应该降低处理器的频率以匹配存储器的性能;反之对于warp内各线程访问连续地址的模式,程序对存储器的性能要求大大降低,则程序的瓶颈在于计算,应该降低存储器的频率以节约能量.获得各核心函数的CWP和MWP后,根据本文提出的功耗优化模型,我们得出处理器和存储器的频率调节因子αc和αm,如表4所示.这里我们假定性能约束条件β=1.2.bitonic0.830.010.830.010.830.01blackscholes0.830.350.830.450.830.34fwtBatch10.830.20.830.250.830.19matrixmul0.350.270.350.220.390.32RandomGPU0.520.350.520.350.330.42scalarProd0.320.290.330.260.300.32scan_best0.830.010.830.010.830.01dwtHaar1D0.380.020.380.030.400.01transpose0.830.280.830.360.830.27从表4中可以看出,bitonic、blackscholes、fwt-Batch1、scan_best和transpose5个核心函数的αc值始终为0.83,即1/β.此时程序运行受限于GPUPage9中的处理器,主要的功耗优化空间在于降低存储器的频率.另外,bitonic、scan_best和dwtHaar1D3个kernel的αm值非常小,这是由于这3个函数的block数很小,程序运行时只启用了部分SM,按照理论模型计算,每个warp所分配的存储带宽非常高,即MWP[2]的值很大,因此为了节约功耗需要大幅降低存储器的频率以匹配处理器的运行速度.按照表4进行调节频率后,我们得到如图2所示的性能加速比.可以看出调节频率后,各核心函数的性能有不同程度的下降,但其均值介于0.75~0.8之间,和预期的性能损失0.83(1/β),相对误差在10%以内.图3给出调节频率后的GPU能耗占原始能耗的比值,其均值介于0.66~0.72之间.注意到,根据能量消耗公式E=PT,而根据2.2节的分析,P∝f3,而T大致满足T∝f-1,因此一般有E∝f2.但根据GPGPUSim的模拟环境,我们的功耗模拟器中的模块被划分为4个独立的时钟域,而本文进行降频时仅调节了其中ShaderCore和Dram时钟域,因此片上互连网络和Cache等消耗的能量在调节前后保持不变.此外,在某些测试用例,如bitonic、scalarProd和scan_best中,这两个模块消耗的能量相对较高.这是本文的模拟结果中,能耗加速比高于性能加速比的平方的主要原因.为了验证本文给出的频率调节策略的最优性,我们分别调节GPU处理器和存储器的频率调节因子αc和αm,寻找满足性能约束的最优功耗调节点.我们在QuadroFX5600平台下选取matrixmul和blackscholes两个核心函数进行验证,它们分别代表了CWP>MWP+1和CWP<MWP+1两种类型的测试用例.图4给出matrixmul在不同的αc和αm配置下的性能加速比,其中虚线给出的是值为0.83(1/β)的参考线.从图中可以看出随着性能的下降,处理器频率的降低在αc等于0.3~0.4之间出现拐点,这是由于matrixmul的CWP>MWP+1,当处理器频率较高时,程序运行的瓶颈在于存储器,而当处理器频率下降到一定程度时,程序运行的瓶颈由存储器变为处理器,即由CWP>MWP+1变为CWP<MWP+1,因此继续降低处理器的频率会使得性能急剧下降.图5给出到达0.83的性能加速比边界时,各(αc,αm)配置下的能耗占原始能耗的比值.其中最低点出现在(0.43,0.22)处,此时能耗占原始能耗的比值为0.65,而如图3所示,优化模型给出的配置(0.35,0.27)所取得的能耗比值为0.63,接近且低于上图中最低点的值.图4Matrixmul在不同频率配置下的性能加速比图5Matrixmul在性能边界处各配置的能耗加速比图6给出blackscholes在不同的αc和αm配置下的性能加速比,图中虚线同样是值为0.83(1/β)的参考线.从图中可以看出,绝大部分αm设置下性能和处理器的频率基本呈线性关系,这是由于这些情况下CWP<MWP+1,此时程序运行的瓶颈在于Page10计算,降低处理器的频率必然导致性能的下降.当αm足够低时,程序运行的瓶颈发生转化,此时小幅降低处理器频率不会显著影响程序性能,直至αc减少到上述不等式再次成立.图6Blackscholes在不同频率配置下的性能加速比和matrixmul一样,我们继续考察达到0.83的性能加速比边界时各(αc,αm)配置下的能耗占原始能耗的比值,如图7所示.注意到αm=0.2时的性能曲线与参考线没有交点,因此这里只有四组(αc,αm)配置下的能耗比值.其中最低点出现在(0.79,0.6)处,此时能耗占原始能耗的比值为0.61.优化模型给出的配置(0.83,0.35)所取得的能耗比值为0.59(见图3),接近且低于上图中的最低值.图7Blackscholes在性能边界处各配置的能耗加速比从以上实验结果可以说明,本文提出的功耗优化模型,可以比较精确地分析程序的行为,针对不同的程序特征给出功耗优化策略,在性能达到约束条件的10%误差以内,获得最优的能量消耗,从而可以有效地指导GPU程序的低功耗优化.5相关工作在传统的低功耗领域,DVFS在操作系统级和编译级都早有研究.Weiser等人[11]首先提出了通用操作系统上基于时间间隔的动态电压调节算法.Govil等人[12]和Lorch等人[13]继续了这一工作并考虑了大量不同的工作负载预测及速度选择策略.Hsu[14]较早提出了编译指导的动态电压调节算法,给出了编译策略来识别电压调节机会,同时保证没有很明显的性能损失.而后通过进一步研究[15]提出了编译指导的动态电压调节算法,一方面准确地预测了一个程序段在任意一个频率值时的性能,另一方面有效地选择了合适的程序段进行电压降低的操作.在目前GPU低功耗研究尚处于起步阶段的时候,这些研究对我们来说有极大的启发和借鉴意义.在GPU低功耗领域,目前的研究大多集中在能耗评测分析阶段.Collange等人[16]使用测量统计的方式研究了在CUDA环境下不同计算程序运行时GPU是怎样耗能的.Huang等人[17]以一个典型的生物计算应用为案例,详细对比了CPU和GPU的执行性能和能量消耗,同时指出GPU高效能的发挥受程序特征和程序优化的影响较大.Rofouei等人[18]将使用GPU与只使用CPU的系统能耗作对比,通过实验发现使用GPU时,当系统性能增益超过某一边界值后就能实现节能,并对这个边界进行了说明.同时,也出现了一些优化和建模的文章,但是数量较少.Takizawa等人[19]提出了一种编译时程序动态选择能耗较低处理器运行的方法,来优化系统的整体功耗.Ma等人[20]则对GPU功耗通过统计分析的方法建立模型,用来预测目标GPU运行所需功耗,为以后优化GPU功耗提供帮助.该模型由于是基于统计方法得到,因此其就存有很大局限性,并不精确.综上所述,GPU功耗研究领域缺少精确的模型与有针对性的优化方法,而这正是本文的研究的出发点.本文基于一个GPU性能解析模型建立GPU的功耗优化模型,可以对程序行为进行准确的分析,从而获得较好的优化效果.6结束语随着GPU越来越多地被应用到通用计算领域,人们也日益关注其性能以外其它方面的表现,如可靠性、功耗等等.GPU中处理芯片的计算资源密度大,其功耗也高于通用CPU.高功耗带来的散热问题也影响了其可靠性和稳定性.本文针对GPU高功耗的问题,结合S.Hong等人在ISCA’09上提出的GPU性能解析模型,提出了一个综合考虑GPU处理器和存储器的功耗优化方法.我们的方法利用性能模型分析出程序运行的瓶颈,并由此计算出处理器和存储器的频率调节因子,使得在满足性能损失约束的情况下,GPU整体的功耗最低.通过模拟实验,我们对所提出的优化方法进行了验证.实Page11验结果表明,理论分析给出的频率调节因子可以在达到性能的约束条件的10%误差以内,最小化GPU的能量消耗,因此可以有效地指导应用程序在GPU上的低功耗优化.
