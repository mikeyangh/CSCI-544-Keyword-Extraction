Page1基于特征学习的广告点击率预估技术研究张志强周永谢晓芹潘海为(哈尔滨工程大学计算机科学与技术学院哈尔滨150001)摘要搜索广告中的点击率预估问题在信息检索和机器学习等领域一直是研究的热点.目前通过设计特征提取方案获得特征和针对用户点击行为建模等方法,并没有充分考虑广告数据具有的高维稀疏性、特征之间存在高度非线性关联的特点,致使信息利用不充分.为了降低数据稀疏性和充分挖掘广告数据中隐藏的规律,该文提出了面向广告数据的稀疏特征学习方法.该方法基于张量分解实现特征降维,并充分利用深度学习技术刻画数据中的非线性关联,以解决高维稀疏广告数据的特征学习问题,实验结果验证了文中提出的方法能够有效地提升广告点击率的预估精度,达到了预期效果.关键词搜索广告;点击率;张量分解;深度学习;社交网络;社会媒体;计算广告学1引言搜索广告又称赞助商搜索(SponsoredSearch),Page2费.点击率(ClickThroughRate,CTR)是指用户点击广告的概率,点击率预估是根据给定的〈查询,广告〉信息以及上下文环境信息等,预估用户点击广告的概率.随着在线推广技术的发展,广告由过去“粗放式”投放正在向“精准化”投放转变,以数据驱动的广告精准投放已成为在线推广的主流趋势.在广告需求方平台(DemandSidePlatform,DSP)的程序化购买和搜索广告投放的过程中,都需要评估用户对广告的偏好程度,而衡量这一偏好程度的重要指标就是广告的点击率[1-2].搜索广告展现过程与网页搜索结果展现过程十分类似,包括查询分析,广告检索,广告排序等阶段.其中在广告排序阶段,目前相对成熟的搜索广告系统采用的排序规则是按照广告预期收益进行排序,预期收益等于广告质量度与广告竞价的乘积,其中,广告点击率是广告质量度最重要的衡量指标.广告预期收益[3]可以简写为式(1)形式:Pad(click)指广告的预估点击率,CPCad表示发生一次点击行为时,搜索引擎的收益.也就是说,点击率预估是广告排序阶段的核心技术,直接影响搜索引擎的收益和用户体验,并且预估点击率对广告的后续投放具有非常重要的指导意义.本文的主要贡献在于,针对广告数据呈现的高维稀疏性和特征之间存在着高度非线性关联的特点,从特征学习的角度出发提出了面向广告数据的稀疏特征学习方法;在数据降维和特征之间非线性关联深度学习方面进行了有意义的探索;同时,通过大量的实验与相类似方法进行了详细的比较分析,证明了本文方法的有效性.本文第1节介绍研究问题的背景;第2节简要概括搜索广告点击率预估的相关工作以及存在的问题;第3节是本文的核心内容,根据当前研究工作存在的问题和广告数据自身的特点,提出面向广告数据的稀疏特征学习方法,并描述算法思想和具体过程;第4节给出实验方案设计,通过对比实验验证本文提出方法的预估效果;第5节总结全文工作,并指出存在的不足之处,对将来的工作方向进行讨论.2广告点击率预估点击率预估一直是信息检索和机器学习等领域的热点问题.最初的研究是用来预估查询关键词与文档之间的真实相关性[4-5],建立预估模型消除点击数据中的各种偏倚因素,如页面上下文环境偏倚、广告位置偏倚、用户信息偏倚等,以获得查询与文档的真实相关性.后来将该研究应用在排序结果的优化和点击预估等方面.在排序结果优化方面,通常将从点击预估模型中得到的真实相关性作为新特征加入到排序算法中,之后借助A/Btest方法来检验新特征对算法排序能力的影响效果[6].例如Dupret等人[7]使用这种方式训练模型,实验表明该方法能有效提升结果排序的质量.在点击预估方面,点击模型通常用来预估一个查询会话中各个文档的点击概率或一次会话中点击序列的概率.通过模型预估返回列表中各个文档的点击概率,有助于排序算法调整返回的文档顺序,使用户点击文档的概率最大化.这方面已有许多研究成果,如点击链模型[8]和动态贝叶斯网络模型[9]等.2.1相关工作本文的核心为点击率预估模型,因此我们将从特征学习、用户行为和数据特点等3个角度来分别介绍点击率预估方面的相关研究工作.(1)特征学习.影响点击率的特征很多,并不是考虑的特征越多,效果就会越好.在实际中往往要在精度与效益方面进行权衡.因此,需要尽可能获取与点击率高度相关的特征,以提高点击率预估的准确率.当前影响CTR预估最主要的特征是位置和相关性.位置决定了广告的曝光程度,Zhang和Jones[10]考察了原始查询和重写后的查询之间的相关性与广告点击率之间的关系,目的是提升查询重写的质量,从而提高广告的点击率.虽然其实际工作重点没有放到广告点击率预估上面,但是该工作考察了一些特征对广告点击率的影响,如次序(Rank)、长度差异(LengthDifference)、编辑距离(EditDistance)等.文献[3,8]将位置因素和广告查询相关性作为特征,同时考虑了根据相同或相似项(Term)的已知广告来解决稀疏广告或新广告的点击率预估问题.文献[11]综合了协同过滤,贝叶斯网络和特征工程等模型来预测点击率.该工作本质上是一种对多种模型的组合式运用,而非单一的预估模型.鉴于实际中“查询-文档”相关性模型并非对所有用户都是一致的,有很多被不同用户提交的相似查询往往导致不同的信息需求,因此文献[12]考虑了用户个性化信息,提出了基于协同过滤和张量分解来提取个性化特征.Hu等人[13]结合用户查询意图,认为影响点击Page3率预估的因素不仅受到位置和文档因素的影响,还受到用户查询的真正意图与实际查询语句之间偏差的影响,作者利用贝叶斯方法基于意图假设进行建模.另外一些研究人员通过构造同一页面广告之间的相关性特征、广告与自然结果的相关性特征并融入点击预估模型,来提高点击率预估的准确率.(2)用户行为建模.通过假设检验,借助贝叶斯网络刻画用户浏览场景,进而估计出用户点击广告的概率.对用户行为建模通常是基于一个前提假设,即搜索结果返回列表中的任意一个文档,只有先被查阅到,用户才有可能发生点击行为,如果文档没有被查阅到,则一定不会被点击.Taylor等人[14]基于这种最简单的浏览行为假设提出级联模型.进一步考虑,如果用户点击一个文档后,该文档不能满足用户的查询需求,则用户可能仍会向后检视搜索结果并有可能发生点击行为,因此Guo等人[15]对级联模型的假设做了扩展,扩展至多次点击.多次点击是指用户点击一个文档后,仍可能浏览后续文档并计算下一个位置文档点击发生的概率.点击链模型[7]是针对用户与搜索结果交互行为而建模的生成模型,被点击文档di的相关性影响继续浏览的可能性,被点击文档di的相关性越大,则继续浏览下一文档di+1的可能性就越小,这说明相关性越大的文档越能满足用户的查询意图.动态贝叶斯网络模型[8]的建模过程中,引入了两个文档相关性变量,即观察相关性(perceivedrelevance)和实际相关性(actualrelevance).观察相关性用来衡量用户点击广告链接(URL)的概率;实际相关性用来衡量用户进入广告链接后,该搜索结果的真实满意度.用户浏览模型[4]认为用户点击下一个位置文档的概率跟上次点击位置的距离有关,同时也与当前文档的位置有关,引入距离变量是因为当用户浏览了一系列不相关文档后,则倾向于放弃此次搜索结果.(3)数据稀疏性特点.从广告数据稀疏性特点出发,研究广告点击率预估问题.Richardson等人[10]利用包含稀疏广告相同或相似项的已知广告来预估其点击率.CTR预估中最大的挑战之一就是信息的缺失,尤其对于新广告而言,历史展示数据信息过少,无法给点击预估模型提供预估基准.因此,针对广告数据的特点,Rain等人[16]基于“竞拍词-广告主”矩阵,提出了层次聚类的方法解决历史数据不充分的广告CTR预估问题.Agarwal等人[17]从建模的角度设计适应稀疏广告或新广告的点击预估模型,分别提出了基于层级结构的预估模型和基于Time-Spatial的预估模型[18].文献[19]提出的基于经验贝叶斯的自然数据分层和基于数据一致性的两种平滑计算方法对层级模型做了改进.由于不同模型之间的兼容性问题,实际可计算问题和问题自身的复杂性,目前还没有出现一个大一统的模型,能够覆盖所有方面,绝大部分工作都是通过不同角度来考察单一模型的预估效果,本文工作亦属此类.文献[11]做出了一种有意义的尝试,它通过综合运用多种模型来预测点击率,试图利用不同模型和方法的互补性来实现更高精度的预估结果.虽然结果显示这种组合式方法比单一模型好,但该工作只是单纯的从预估效果角度来做调整,并没有对如何组合运用现有模型给出清晰合理的解释,相关做法难于理解.该工作只说明了这种方式有效,至于为什么有效及如何更有效没有给出具体理论指导意义的结论.对于各种不同模型之间关联问题的研究是个挑战,而该项工作正是我们后续的一个研究课题.2.2存在的问题尽管点击率预估方法已经得到了广泛研究,但是仍然存在一些问题.目前,通过人工构造特征的方法,存在效率低、可扩展性和性能提升困难的问题.而贝叶斯网络刻画用户浏览行为,存在信息利用不充分,并且没有考虑到广告数据具有高度稀疏性、特征之间存在高度非线性关联的本质特点.已有的从广告数据特点出发进行点击率预估问题的研究中,仅仅考虑了稀疏广告(即展示不充分、统计量不足的广告)点击率预估问题,实际上并未从整体角度考虑广告数据的本质特点.广告数据具有高维稀疏性特征,高维特征中有效信息(非0值)的维度很低,其中包含的噪声会对真实信息干扰很大.已有的研究成果很少从广告数据的特点考虑,使得大多数CTR预估方法无法高效地在高维、高稀疏的广告数据上准确地预估点击率.如何解决高维稀疏数据给CTR预估准确率带来的影响,是一个值得研究的问题.广告数据另一个特点是特征之间存在高度非线性关联关系,复杂度高.传统方法采用人工构造组合特征(又称“人工特征工程”)的方式,挖掘特征之间的关联,但是该方式存在效率低、领域知识无法迁移等诸多问题.因此,如何在减少人工干预的情况下,通过算法自动挖掘特征之间的关联是文中要研究的重点.Page43基于特征学习的CTR预估方法特征是数据的抽象表示形式,是用于表达数据中隐藏的、且对具体任务有帮助的标签系统.从原始广告数据中挖掘与预估任务高度关联的特征是点击率预估系统的关键步骤之一.然而,广告数据呈现的高维稀疏性且特征之间存在高度非线性关联的特点,使得已有方法无法高效地进行CTR预估.因此,本文从如何降低特征的高维稀疏性以及如何刻画特征之间的非线性关联的角度出发,提出了面向广告数据的稀疏特征学习方法(AdvertisingData-orientedSparseFeatureLearningMethod,ADoSFLM),以解决高维稀疏广告数据的特征学习问题.3.1问题描述本文研究的广告点击率预估问题可以描述为:给定一个用户查询和其他信息(如性别、年龄、地域、兴趣爱好等),经过查询分析、广告检索步骤后,得到一个与查询相关的广告候选集.点击率预估系统需要计算用户点击广告候选集中每一则广告的概率,即广告的预估点击率.图1中的灰色模块描述了一个广告点击率预估系统的工作流程.搜索广告中,广告主通过购买竞拍词的方式设定了广告被触发的场景,广告投放系统根据用户的查询关键词,匹配相应的广告,对广告排序后与自然搜索结果一起返回给用户.3.2算法基本思想本文针对广告数据的特点提出ADoSFLM方法用于挖掘特征之间的内在关联,获取对数据有更强表达能力的特征集合,进而得到更加精确的点击率预估模型.该方法主要包含以下3个环节:(1)数据降维.数据降维是解决数据稀疏性的一个有效手段.针对广告数据中相同类型对象内部之间存在相似性关系,首先对相似对象进行聚类,获得初始的聚合数据;然后,对于不同类型对象之间存在的复杂关联关系,采用张量结构对其建模,并运用张量分解法得到近似张量.(2)复杂特征学习.广告数据的特征之间存在高度非线性关联的特点,而高阶多项式函数可以有效地刻画高度关联关系.本文研究并利用深度学习模型———栈式自编码神经网络算法———利用其多层网络结构逐层学习特征之间的非线性关联,将学习到的组合特征集合用于描述广告数据中隐藏的内在规律.(3)CTR预估模型.利用学到的特征集合训练预估模型,得到点击预估模型.这样,给定一个新的样本,经过降维和特征学习的变换后,点击模型可以预估广告的点击率.3.3数据降维方法降维是为高维数据获取一个能反映原始数据内在结构特性的低维表示,同时达到降噪、降低稀疏性的目的.点击日志数据中包含了用户、查询、广告等多种类型的对象,这些对象之间的关系很复杂.相同对象内部之间存在关系,如广告对象内部之间存在相似性关系.同时,不同类型对象之间也存在着复杂的关系,如给定一个特定用户和该用户提交的查询,需要预估用户是否会点击广告,以及点击广告的概率大小,用户、查询和广告3个对象之间存在复杂的隐含关系.本文结合点击日志数据的特点,分别从相同对象内部之间存在相似性关系和不同对象之间存在关联关系这两个角度出发进行降维.3.3.1相同对象聚类表示点击日志数据中,用户之间、查询之间以及广告之间都存在相似性,例如用户输入的同一个查询所返回的广告之间具有相似性,触发同一个广告的不同查询之间同样存在相似性.同样的,输入相似查询的不同用户由于查询意图近似也具有相似性.因此,首先从相似性的角度对用户、查询和广告3个维度进行降维.本文采用基于距离划分的K-means聚类算法[20]对查询、广告和用户进行聚类.目的是通过聚类使得相似对象聚合到同一簇中,同一簇中的对象相似度尽可能的高,获得初始的聚合数据.直接利用传统IR领域的文本相似性技术实现对查询甚至广告的聚类,虽然可以完成聚类任务,但是这种做法没有考虑到实际数据中蕴含的广告与查询之间的关联关系,得到的聚类结果对点击率预估没有任何参考Page5意义.因此为了能够更好的挖掘和利用广告与查询之间的关联关系,本文提出了新的方法,用实验数据中提供的广告展示次数作为广告Ai与查询Qj的权重,来建立广告-查询矩阵犠Na×N数,Nq表示查询数,wij表示〈Ai,Qj〉之间的权重.对该广告-查询矩阵采用K-means算法进行聚类,得到一个相对密集的数据集合.以广告聚类为例,图2介绍了聚类算法的流程,对查询的聚类采取同样处理方式.输入:广告-查询矩阵犠M×N,聚类簇数K输出:K个广告簇集合1.对广告-查询矩阵犠M×N扫描,得到所有的M个广告和N个查询,分别记作犃={a1,a2,…,aM}和犙={q1,q2,…,qN};2.从M个广告中随机抽取K个作为最初的聚类中心点,记作犜={t1,t2,…,tk};3.初始化K个聚类集合{犘1,犘2,…,犘K}为空集;4.计算每个广告ai与各个聚类中心点tj之间的距离,计算公式如下:(其中Gij表示广告ai与作为聚类中心的广告tj共同展现的查询集合,WaDis(ai,tj)表示ai与tj的距离);5.若Dis(ai,tj)=max{D(ai,t1),D(ai,t2),…,D(ai,tk)},则广告ai属于簇犘j;6.计算同一聚类集合中所有广告的平均权重值,重新生成聚类中心;7.如果聚类中心的偏差达到了设定的阈值,则聚类完成;否则转到步4重新计算.基于广告-查询矩阵犠Na×N聚类算法完成对广告/查询的聚类,使得同一簇中的广告/查询相似度尽可能的高.本文具体作法是基于同一个广告-查询矩阵分别对广告和查询作聚类,两次聚类相互独立,聚类顺序不影响后续的计算.对于用户维度的聚类,考虑到具有相似查询需求的用户具有相似性,本文直接根据前面得到的查询聚类结果,将同一簇中的查询所对应的用户聚在一起组成一个用户簇.初始数据中的用户数、查询数和广告数分别用Nu,Nq和Na表示,相同类型对象内部聚类后,属于同一个簇中的对象用同一个ID表示,将聚类后的用户、查询和广告的簇数分别用Ku,Kq,Ka表示.这样,初始数据集中的用户数、查询数和广告数由原来的Nu,Nq和Na分别降维到Ku,Kq和Ka.假设Tq和Ta分别表示对查询和广告调用聚类算法完成聚类任务而需要执行的迭代次数,K表示聚类的个数,则完成对查询聚类的时间复杂性为O(KTqNq),而对广告进行聚类的时间复杂性为O(KTaNa).由于用户的聚类没有调用图2的算法,而是根据查询的聚类结果直接得到的,其复杂性为O(Nq+Nu),令T=max{Tq,Ta},N=max{Nu,Nq,Na},则聚类环节的复杂性表示为O(KTqNq)+O(KTaNa)+O(Nq+Nu)=O(KTN).3.3.2不同对象复杂关联关系求精点击日志数据中的用户-查询-广告之间存在三元关系.传统的降维方法(如PCA等)不仅破坏了三者之间的内在关系,当数据维度数很大时,容易导致维数灾难.为此,本文用三维张量结构模型表示用户、查询和广告三维数据,然后利用张量分解法进行降维.张量模式降维充分保留了用户、查询和广告之间的结构信息和内在关联,由于参数更少,对于高维数据来说,张量模式的降维要比向量模式有更好的约简效果.定义1.张量(Tensor)[21].张量是一个定义在向量空间和对偶空间笛卡尔积上的多线性函数.在n维空间内,有nr个分量(r是张量的秩或阶),其中每个分量都是坐标的函数,在进行坐标变换时,这些分量同样根据相应规则做线性变换.其中一阶张量(r=1)称为向量,二阶张量(r=2)称为矩阵,矩阵分解是张量分解的特殊形式.基于聚类后的数据,建立“用户-查询-广告-权重”四元关系〈ui,qj,ak,wi,j,k〉,关于权重的计算有很多种方式,本文结合实验用的数据,利用聚类后广告簇中广告的展示数之和作为三维空间中元素的权重来构建三维张量模型,用犎∈RKu×K型如图3所示,三个维度的维度数分别是Ku,Kq,Ka.构建三维张量犎∈RKu×K分解法(TuckerFactorization)[22],分解张量犎,公式表示如下:犎=犆×u犝×q犙×a犃=∑=犆;犝,犙,式(2)中的犆表示张量犎的核心张量(CoreTensor),类似于奇异值分解的对角矩阵,本文用犝,犙,犃表示张量犎在维度Ku,Kq,Ka上对应的特征矩阵,是张量犎在对应3个维度上的主成分.Tucker分解原理示意图,如图3所示.Tucker分解的目的是找到一个与原始张量犎的近似张量,并且最大程度保留原始的张量信息和结构信息[23].Tucker分解计算可以得到一个与原始张量相近的张量表示犎^,如最小化公式(3)所示:Page6式(3)表示原始张量与近似张量的近似程度,是优化的目标函数.根据式(3)可以得到核心张量的表达式:目标函数可以写成平方形式,即犎-犆;犝,犙,=犎2-2〈犎×u犝T×q犙T×a犃T,犆〉+犆2=犎2-2〈犆,犆〉+犆2=犎2-犆2=犃2-犎×u犝T×q犙T×a犃T2犎2是一个常数,由原来的张量犎∈RKu×K确定.因此,目标函数转化为式(3)中右边的最大化问题的最优解,即式(6)中的目标可以写成如下形式:在求最优解的过程中,需要固定其他维度的特征矩阵,即变量犠,依次求解犝T,犙T,犃T,然后对犝T,犙T,犃T进行SVD分解.对犝T,犙T,犃T进行SVD分解时,首先展开张量犎,在用户、查询、广告维度展开张量犎成为矩阵,分别记作犎1,犎2,犎3,然后在这3个矩阵犎1,犎2,犎3上应用奇异值分解,可得到对于矩阵犎1,犎2,犎3,需要确定3个维数的参数,分别是左奇异值矩阵犝,犙,犃中的维数c1,c2,c3.这3个参数决定张量犎的核心张量犆的维数.3个对角的奇异值矩阵犆1,犆2和犆3是通过对张量犎的展开矩阵犎1,犎2,犎3进行奇异值分解得到的,而核心张量犆的计算则是通过3个对角奇异值矩阵犆1,犆2和犆3求得.维数c1,c2,c3的计算则通过对犆1,犆2和犆3的对角奇异值从大到小按照比例计算而得.保留大的奇异值,按照比例删减小的奇异值,从而达到维数的归约,对原始张量降维的目的.本文在降维的过程中将删减奇异值的比例分别设置为50%.这样,降维后新的核心张量犆计算公式如下:确定新核心张量犆以及新的特征矩阵犝r1犙r2,犃r3初始张量犎的3个维度数分别是Ku,Kq,Ka,经过降维后的近似张量犎的3个维度数分别用Iu,Iq,Ia表示.Tucker分解算法的时间复杂性与张量的各个维度成正比,可以表示为O(KuKqKa).由于我们之前利用聚类方法已经实现了对原始矩阵的降维,使得此处的Tucker分解开销大大降低,效率和精度都有显著提高.3.4复杂特征学习方法机器学习领域的研究表明,深度或层次结构的模型对于刻画数据中的非线性关系和复杂模式更有效[24].受到这项研究的启发,本文利用一种能够刻画特征之间高度非线性关联的方法———栈式自编码网络算法(StackedAutoEncoderNetwork,SAEN)[25]用于学习广告数据中的结构信息,使用该算法自动学习数据中的模式特征,并将学到的特征融入到建模(如分类、预测)的过程中,从而克服人工特征工程的不完备性缺陷.3.4.1输入层特征构成分析广告数据中的特征之间存在高度非线性关联,虽然通过Tucker分解获得原始张量降维后的近似张量,但仅仅反映User,Query,Ad三个特征维度之间的信息,数据中其他对点击率预估有用的信息没有充分利用,如广告在返回页面的位置、广告数量以及用户年龄、性别等信息.本文结合张量降维后的〈User,Query,Ad〉特征以及日志数据中其他有效信息作为特征学习的对象,输入层特征的构成总结如下:(1)ID类特征.ID类特征可以唯一标识某类实体,在实际的点击日志中,通常使用一组数字字符串来表示此类变量,如‘10010’可标识唯一一个用户群体.文中用到的ID类特征有用户ID(UserID),查询ID(QueryID),广告ID(AdID),广告位置Position以及返回页上的广告数Depth.值得注意的是,这里的UserID,QueryID和AdID是经过K-means聚类和张量降维后得到的“虚拟”Page7ID类集合.最初的用户数、查询数和广告数分别是Nu,Nq,Na,经过K-means聚类后的数量分别是Ku,Kq,Ka,再经过张量降维后的用户数、查询数和广告数分别是Iu,Iq,Ia.(2)属性类特征.ID类特征仅仅是一个标识,此类特征无法从新出现的实体数据中获得,泛化能力比较弱.而属性类特征可以用于描述某类用户集合、广告集合等,有较好的泛化能力,该类特征可命中多个实例.例如,通过IP属性类特征可以知道用户的地理位置信息,那么对地域有要求的广告,如肯德基等餐饮类广告,IP能够提供较大的信息量.因此,有必要将属性类特征作为深度学习的输入层特征.常用的属性类特征有:用户所在网址IP,广告被触发的时间Time,用户性别Gender,用户年龄Age,查询关键词Keywords等.Time类特征是一种对用户行为影响比较强的特征,用于记录用户行为发生的时段.Keywords是图4输入层特征构成情况3.4.2自编码器自编码器(AutoEncoder)[26]是一个尽可能复现初始特征的深度学习算法,通常被用来学习原始数据更好的特征表示,由3层网络结构组成:底层是输入层I、中间为隐藏层H(新的数据表示层)以及输出层O.自编码网络如图5所示.输入数据经过隐藏层,在输出层重构,通过最小化输入和输出的重构误差来校准网络权重,学习输入数据的潜在特征或数据的压缩表示.本文用ins和hids分别表示输入层单元的个数和隐藏层单元个数,给定一个训练数据集合犡={狓(1),狓(2),…,狓(M)},其中狓(i)中狔∈犚hids),映射的过程就是一个编码的过程,用(i)由查询字符串去除停用词后切词得到的.(3)统计类特征.统计类特征尝试使用历史数据的统计信息给点击预估模型提供预估基准,例如,在某一广告位上所有展现的广告平均CTR值.文中的统计类特征有广告历史展现次数Shows,广告历史点击次数Clicks以及广告位置归一化后的点击率COEC.关于COEC的计算,文献[9]根据式(11)计算得到去除位置偏倚后的历史点击率,COEC计算公式为其中,式(11)的分子表示广告a在所有位置上的点击次数之和,分母表示广告a在各个位置上的期望点击次数之和.综上所述,在本文的实验中,SAEN算法的输入层特征构成情况如图4所示.Sigmoid函数作为连接函数完成编码过程,表示如下:参数犠(1)向量犫(1)犚ins,是重构输入向量的过程,也是一个解码过程,目的是尽可能重构输入向量狓(i),由狔一个线性映射表示如下:这里犠(2)过程的权重矩阵和偏置向量.从学习的角度,自编码算法旨在最小化输入狓(i)与输出狕(i)之间的重构误差,得到编码和解码过程的参数集合.这里犣={狕(1),狕(2),…,狕(N)},用J(犡,犣)表示重构误差:图6描述了自编码器算法的学习流程.虽然自编码器可以通过最小化输入输出的重构误差获得输入数据的隐藏表示,但是它只有一个隐层,属于浅层结构模型,限制了对数据的表示能力,无法刻画广告数据中特征之间的高度非线性关联.因此,本文利用含有多个隐藏层的栈式自编码网络算法学习特征之间非线性的关联,本质上是学习单Page8输入:犡={数据集合},ε=随机梯度下降算法的学习率,iters=参数迭代次数,num_i=输入层节点数,num_h=隐藏层节点数输出:隐层结果Result,网络连接权重矩阵犠(1),输入层偏置向量犫1.初始化网络连接权重矩阵犠,矩阵大小为num_h×num_i,输入层偏置向量犫,隐藏层偏置向量犮;2.利用式(12)连接函数求出隐层犢(犡,犠(1),犫),利用式(14)求出重构层Z(犢,犠(2),犮).其中犠(2)是犠(1)的转置矩阵;3.根据重构层犣和输入层犡,构造重构误差J(犡,犣).即损失函数;4.分别对损失函数求参数犠(1),犫,犮的偏导,分别用表示;5.Forifrom1toitersdo6.犠(1)←犠(1)+ε×J(犡,犣)/W(1)7.犫←犫+ε×J(犡,犣)/犫8.犮←犮+ε×J(犡,犣)/犮9.End-For10.计算隐藏层潜在表示Result=f(犠×犡+犫)11.返回Result,犠,犫.图7特征学习过程与LR预估模型训练示意图(2)将低阶组合特征作为新的学习的对象,再次经过非线性变换得到相对高阶的组合特征,此过程重复下去,直到达到设定的隐藏层数为止.其中,多层网络中不同的隐藏层是对输入层的不同潜在表示,高层的特征是低层特征的组合,从低层到高层的特征表达越抽象和概念化,也就越能挖掘数据中蕴藏的有价值信息.为了更好的学习网络权重参数,本文采用文献[27]中提出的基于逐层贪婪训练的无监督学习算法.逐层贪婪学习的关键是逐层训练网络权重参数,每次只学习相邻两层节点的连接权重,通过逐层学习以获得全局的SAEN模型参数.逐层贪婪方法学特征之间的组合特征形式,构造最佳的(组合)特征集合用以提高模型预估CTR的准确率.3.4.3基于SAEN的特征学习方法SAEN算法是由多个自编码器组成的多层深度网络结构,其特点是每一个隐藏层都是对上一层的输出进行非线性变换得到的.SAEN特征学习示意图,如图7粗矩形框部分所示.SAEN算法的一个很重要的特点是从输入层特征(原始特征)中学习或发现高度非线性或复杂的模式,直接从数据中自动学习潜在特征表示.本文利用SAEN算法学习广告数据中的高阶组合特征过程,描述如下:(1)将3.4.1节中提取的初始特征作为模型的输入,对初始特征做特征非线性变换得到第1隐藏层,即低阶组合特征,如图7所示.习SAEN权重参数的过程如下:(1)由输入层到第1个隐藏层,通过最小化输入输出的重构误差,利用反向传播算法训练参数,得到输入数据的第1个潜在表示(即第1隐藏层).(2)将上一层特征向量作为训练下一层的输入,采用同样的方法训练权重参数,得到数据的另一个潜在表示(即第2隐藏层),依次类推.也就是说,第i隐藏层的特征作为训练第i+1层的输入,逐层贪婪的学习过程是把SAEN网络进行分层,对每一层进行无监督学习,又称为预训练过程.图8描述了基于逐层贪婪学习的训练过程.Page9输入:稀疏训练样本集合犡={狓(i),1iM,狓(i)∈犚D(I)},隐藏层数k输出:网络连接权重参数矩阵集合{犠h,1hk},偏置向量集合{犫h,1hk}第k隐藏层输出结果犢(k)1.初始化:犢(0)=犡;2.用原始训练样本作为输入,通过图5训练出第1个隐层结构的网络参数W1,利用式(12),将训练好的参数算法第1个隐层的输出,得到犢(1);3.把上一步的输出犢(1)作为下一个自编码的输入,同样用图5训练下一个隐层网络的参数W2,并根据式(12)计算下一个隐层的输出,得到犢(2);4.重复步3,直至第k个隐层,并根据式(12)计算出第k个隐层的输出犢(k);5.返回SAEN网络连接权重矩阵集合,偏置向量集合以及第k层的隐层犢(k).上述算法复杂性与自编码器的网络结构密切相关,假设k为网络隐藏层的数目,则本文采用的逐层贪婪训练学习算法的复杂性可以表示为O(insk·hids),其中ins和hids分别表示输入层单元的个数和隐藏层单元的个数,k表示网络隐藏层数.3.5点击率预估模型上一小节中,通过SAEN算法学习得到单特征之间的关联特征,新特征有更强的表达能力,对原始数据有着更本质的刻画.因此本小节使用新特征作为点击预估模型的训练对象.点击率预估问题实质上是一个基于概率的二分类问题,本文使用逻辑回归作为点击预估模型,逻辑回归(LogisticRegression,LR)模型[28]是机器学习中十分常用的一种广义线性分类模型,通常用来描述事件发生的概率,在互联网领域得到广泛应用.除了广告系统的CTR预估外,推荐系统中预估转化率、反垃圾系统中垃圾识别等也广泛使用该模型.LR预估模型训练过程示意图,如图7中黑色框部分所示.定义2.正负样本.第i个样本用(犡(i),y个样本的组合特征向量描述,y击,取值为0或1,y(i)的值为0表示该则广告未被点击.本文把yy值为1的样本定义为正样本,y义为负样本.给定M条训练样本{(犡(i),yN表示特征数.对于第i个样本中对应的广告,用户点击广告的概率表示为Py其中θ是要求解的参数.等式右侧的函数称为Sigmoid函数,其值域在(0,1)之间.点击变量y分布,拟合二项分布通常用极大似然估计法,假设样本之间独立,所以它们的联合分布可表示为各边缘分布的乘积,即通过对式(16)进行极大似然估计,即可求得参数.本文使用L-BFGS优化算法[29]求解参数,该方法收敛更快且节省内存.该算法的复杂性为O(iters·L3),其中iters表示迭代次数,L=|犢(k)算法最后第k隐藏层输出的结果向量,即学习得到的新特征.3.6算法复杂性分析本文算法的整体复杂性为上述各个环节的累加,即聚类、张量分解、深度学习和点击率预估,最后算法的复杂性可以如下描述:O(KTN)+O(KuKqKa)+O(insk·hids)+O(iters·L3),其中K表示聚类的个数,T=max{Tq,Ta},Tq和Ta分别表示对查询和广告调用聚类算法完成聚类任务而需要执行的迭代次数,N=max{Nu,Nq,Na};Ku,Kq和Ka分别为张量犎的3个维度数;ins和hids分别表示输入层单元的个数和隐藏层单元个数,k表示网络隐藏层数;iters表示迭代次数,L=|犢(k)|,犢(k)为SAEN算法最后第k隐藏层输出的结果向量.由于实际中T的取值远小于N,且KN;Ku,Kq,Ka<N,Lins=O(Ku+Kq+Ka),深度学习网络确定后,可将hids,iters看作常数,令P=max{k,3},则算法的复杂性可以简化为O(NP),其中P3.4实验与结果分析实验的目的是想通过实验验证本文提出的稀疏特征学习方法,并进一步验证与已有方法相比本文方法在模型运行时间上是否高效,预估效果是否更有效,以及观察不同数据规模对点击率预估结果的影响趋势.4.1实验环境硬件环境:中科曙光服务器1台,Intel(R)Xeon(R)E5-2670@2.60GHz32核CPU,32GB内存.软件环境:CentOS6.2操作系统,Python2.7.6Page10开发环境以及pyTensor,scikit-tensor,scikit-learn,theano相关工具包.4.2实验数据本文的实验数据来自SIGKDDCup2012track2①,由腾讯公司旗下的搜索引擎搜搜(2013年9月并入搜狗)提供的广告点击日志数据.KDD2012CUPtrack2对应的研究问题是根据给出的真实点击数据信息,包括用户查询,返回广告信息,返回页信息等,来预测该广告的点击率.比赛提供的训练数据集共有149639105条记录,9.87GB大小.测试数据集中除了没有点击数和展示数之外,其他信息与训练集一致,共有20257594条记录,1.26GB大小.数据集中一条记录表示用户的一次检索行为所展示的k条广告中一条广告包含的所有信息,又称为一个实例.4.3实验设计过程(1)实验数据划分本文经过对无效数据清洗,以及数据预处理后,从候选数据集中随机抽取330万条样本用于实验,最终实验所用数据统计,如表1所示.总数据训练数据测试数据实验过程中,本文通过划分训练数据分别在7个不同规模的数据集上训练模型,并且在同一测试集上验证不同方法的预估性能.训练数据集划分情况,如表1所示.以上训练和测试数据的划分以及训练数据的分组均采用随机划分.7种不同规模数据集的每组样本数分别为15万、20万、30万、50万、60万、75万和100万.每种规模的数据都至少选取3组以上完全不同的数据,最终的结果取所有组实验结果的平均值,以此来保证实验结果的可靠性.(2)对比方法在进行对比实验时,为了更有针对性和公平性,我们按照如下标准选择对比方法:①最新的点击率预估模型;②针对广告数据的点击率预估(在广告数据上有过实验的工作);③单一点击率预估模型,而非综合多种模型的组合式模型.由于本文工作的核心是预估模型,因此第1个原则保证我们与最新的预估模型进行对比.由于点击率预估方面的工作目前主要分为两类,Web搜索文档和广告,第2个原则是为了选择真正在广告数据上有过测试的模型;第3个原则是要求选择那些单一模型进行对比,可以更好的分析不同模型之间的异同,当然本文的方法可以很容易的集成到文献[11]的框架中.本文预估模型最大特点有两个方面:①降维方法在保证降低维数的前提下,并没有丢失关键信息;②在特征关联的深度学习方面,通过自动学习挖掘关键特征和关联.其属于基于特征学习的点击率预估方法.因此根据上述原则和本文方法的特点,选取了与本文方法相近的两个代表性工作进行对比.文献[3]与本文提出的ADoSFLM方法都使用LR作为预估模型,从数据中抽取与点击率预估相关的特征,是通过人工设定特征提取方案后得到的,如通过数据中的信息得到广告质量特征,相似广告CTR值等.而本文提出的方法是利用深度学习算法,通过挖掘特征之间的关联自动获得特征.文献[12]使用矩阵分解获得查询-广告内在关联以及通过张量分解获得用户-查询-广告之间的关联信息,然后集合广告位置和广告与查询相关性信息,利用贝叶斯网络建模,得到的概率模型用EM算法求解结果.该文使用张量分解法是为了获得用户个性化信息,最后得到的是基于个性化点击率预估模型.通过对用户行为建模,考虑到了用户信息,通过对比实验,验证该方法好于其他已有的概率图模型方法.然而,与本文方法相比,两者最大的差异是对信息的利用方式不同.本文最大特点是使用深度学习算法挖掘特征之间的内在关联,获得的是组合特征集合,而非简单的对用户行为进行建模.通过与文献[3,12]中的方法进行比较,可以验证本文通过深度学习获得的特征与人工方式获得特征相比是否更高效.同时,也可以验证经过张量分解后得到的低维核心张量是否仍然具有足够的信息量用于深度学习点击率预估的关键特征.表2简要的介绍了本文进行对比的几种方法.方法Human_LRHPCMADoSFLM(3)实验评估方法本文采用ROC曲线下面积AUC[30](AreaUnder①SIGKDD12Cup.http://www.kddcup2012.org/c/kdd-Page11theReceiverOperatingCharacteristic)作为模型预估性能评价标准.ROC曲线基于混淆矩阵,它主要用于比较预估结果和真实结果.矩阵中的行表示实例的预测结果,列表示实例的真实结果.在ROC空间中,每个点的纵坐标是真正率,横坐标是假正率,描绘了分类器在TP和FP之间的权衡.对于本文的二值分类问题来说,实例值往往是连续值,需要设定一个阈值,将实例分类到正类或负类.曲线下面积(AUC)就是ROC曲线下方的那部分面积大小,该值通常介于[0.5,1)之间,AUC越大,代表点击预估模型性能越好[30].4.4实验结果分析主要包括3个部分:(1)参数对模型预估效果的影响;(2)模型运行时间比较;(3)预估效果的比较与分析.4.4.1参数对模型预估效果的影响本文提出的ADoSFLM方法涉及到很多参数,最关键的参数如深度学习阶段中网络层数k和模型训练阶段中迭代次数iters.这些参数对于模型最后的预估结果产生直接的影响,因此本文首先针对参数进行了实验,以选出最佳的参数组合.本文使用数据规模为500000样本的一组抽样数据训练模型,在测试集上测试,用于选取最佳参数.固定SAEN算法的网络层数(k=2,3,4,5,6)时,分析不同iters对模型性能的影响,所得结果如表3所示.表3不同网络层数与LR模型训练迭代次数之间的关系迭代次数iters=100.66340.65770.66840.66440.6639iters=200.67570.65910.68420.67310.6693iters=300.67930.66850.69540.67390.6802iters=500.69890.69320.70970.69830.6937iters=700.71690.71490.72240.71210.7139iters=900.72460.72650.73470.72380.7354iters=1000.72830.72940.73840.73770.7335iters=1100.73050.73080.74090.73940.7390iters=1300.73110.73210.74080.74110.7368iters=1500.73240.73200.74040.73850.7382根据表3生成曲线图,如图9所示,图9反映了不同的网络隐层数k值与LR模型迭代次数iters所对应的AUC变化情况,从图9中不难看出,当迭代次数为100~120次时,几条曲线的AUC值已经变化不大,趋于稳定.因此在下面的对比实验中,本文选择110作为训练预估模型的迭代数.值得注意的是,SAEN算法的复杂度与参数k直图9LR模型的AUC值随不同迭代次数变化情况接相关,k表示隐层数,其值越大,SAEN算法的计算开销越大.通过图9可知,达到收敛时,k=2,3,4,5,6对应的AUC值分别是0.7324,0.732,0.7404,0.7385和0.7382.从曲线上看,随着迭代次数的变化,各条曲线波动较大,其中k=4时相对稳定,并且当迭代数达到一定值时,AUC值趋于收敛.因此,就本实验所用的数据集、数据规模以及计算开销而言,综合考虑k=4(即隐层数为4)是一个合理的选择.4.4.2模型运行时间比较本文记录了3种方法在不同数据规模下的运行时间,表4给出了分别在15万、30万、50万、75万和100万数据规模下的平均运行时间.平均时间/s对比方法Human_LRHPCMADoSFLM从表4可知,3种方法在模型运行时间上相差很大.Human_LR运行时间只有预估模型训练阶段,特征抽取过程依赖领域知识,特征数相对较少,模型运行时间相对也较小.而HPCM和ADoSFLM模型涉及到张量分解的复杂运算以及EM算法和深度学习阶段算法的计算开销也很大,并且涉及到的特征数较多.因此,HPCM和ADoSFLM方法运行时间相对较长.虽然本文提出的ADoSFLM方法在运行时间方面并没有特别优势.但是,最耗时的广告点击率预估模型是基于海量数据训练得到的,其计算过程是在离线环境下进行的.因此,运行时间对在线预估CTR值并没有影响.4.4.3预估效果的比较与分析本文分别在7个不同规模的数据集上训练模型,在同一测试集上评估预估效果.分别考察不同方法之间的预估效果,以及数据规模对预估质量的影Page12响.表5描述了不同方法在不同数据规模下的预估结果.表53种方法在不同数据规模下的平均预估效果数据规模/万152030506075100从表5可以看到3种方法在不同规模数据集下的预估结果,ADoSFLM模型相对于Human_LR的预估效果随着数据规模的加大提升效果越发明显,以数据规模100万为例,预估性能提升了8.35%.ADoSFLM之所以预估性能更好,主要有3个原因:(1)原始数据中存在很多长尾数据和无效数据,本文经过数据清洗后,通过对原始数据进行K-means聚类和张量分解两次降维,降低了数据中的噪声对真实信息的干扰,同时也降低了数据的稀疏性,这对于提高预估准确率是有利的;(2)ADoSFLM方法采用了深度SAEN算法学习特征之间的高度非线性关联,多层结构的特征学习模型对于挖掘特征之间深层次的规律是有效的;(3)实验过程中,利用ADoSFLM方法学到的特征数大于Human_LR方法中人工抽取的特征,ADoSFLM方法学到的特征对数据有更强的表达能力.通过人工方式提取出对点击率预估高度关联的特征越来困难,而SAEN算法通过对广告数据进行深度学习,得到更多的对点击率预估有意义的特征,这对于提高模型预估准确率是有帮助的.从表5还可知,采用ADoSFLM方法的点击率预估效果也要好于HPCM.主要原因有:就模型而言,两种方法都使用张量分解,获得近似张量用于点击预估模型,ADoSFLM方法使用LR模型预估点击率,后者使用概率模型预估点击率,其中最大的区别是本文提出的方法含有深度特征学习的阶段.ADoSFLM中的深度学习方法,充分学习了张量分解后的近似张量和数据中其他属性特征之间的非线性关系,SAEN算法刻画特征之间的高度非线性关联,最大限度的挖掘隐藏在特征之间的规律,这是HPCM模型中没有的.因此,从预估质量上来看,本文使用深度结构模型学习特征之间的高度非线性关联,对于提高点击率预估的准确性是可行的,预估质量也有所提升.为了能清晰的看出3种方法的预估质量在不同规模数据下的变化趋势,本文根据表7得到相应的平均预估AUC值折线图,如图10所示.图10不同数据规模下3种方法的预估效果比较从图10可以看出,3种方法随着数据规模(即训练样本数)的增加,在同一测试集上的预估质量都有所提升.这主要是因为,最初的训练样本数比较少,对于3种方法来说,模型都处于过拟合状态,随着数据规模的增加,训练得到的参数稳定性和健壮性都有所增强.值得注意的是,随着数据规模的增长,3条曲线的变化趋势并不相同,即模型预估效果的收敛程度不同.开始时,3种方法预估结果基本无差异,随着数据规模的增长,本文提出的ADoSFLM方法与Human_LR和HPCM方法相比,预估效果增长明显加快.在相同数据规模下,增长幅度也大于其他两个方法.Human_LR方法在数据规模为600000时,已基本趋于收敛,这说明人工抽取特征方法,在较小规模数据集上表现良好.当数据规模较小时,数据中隐藏的结构和规律不明显,人工抽取的特征可以很好的表示数据.HPCM方法中用到的张量分解,一方面是为了获得数据的降维、降噪表示,另一方面也是为了挖掘广告日志数据中隐藏的用户个性化信息,从图10可以看出,随着数据规模的增加,预估效果也在提升.本文提出的ADoSFLM方法,随着数据规模的增长,预估结果好于HPCM.这主要是因为ADoSFLM方法中包括特征学习阶段,借助SAEN算法的多层网络结构,学习特征之间的高度非线性关联关系.当数据规模很小时,数据无法体现特征之间复杂的内在关联,此时SAEN也不能很好的刻画这种关联.随着数据规模的增加,SAEN算法可以更好的学习Page13数据中隐藏的规律,也就是说,本文使用深度学习算法来学习广告数据单特征之间的组合特征(即特征之间的关联).从理论上来说,训练数据越多,该算法学到的特征对数据的表达能力就越强,广告CTR预估的准确率也就越高.虽然受到当前实验所用硬件设备的限制,实验过程中没有使用更大规模的数据来训练模型,但是上述结果也证明本文提出的方法比其他方法更适合于大数据量情况下的应用.5结论与展望本文基于最基本的搜索广告点击数据,从特征学习的角度,提出了面向广告数据的稀疏特征学习方法.考虑到广告数据的高维和高稀疏性特点,本文利用降维的方法,首先基于相似度分别对相似的广告、查询和用户进行聚类,使数据具有初始聚合性;其次对降维后的三元组建立三维张量模型,利用Tucker分解获得低阶近似张量.针对特征之间存在的高度非线性关联关系,文中研究了基于深度学习的特征学习方法,首先分析了输入层特征构成,结合栈式自编码网络算法学习特征之间的高阶组合特征,作为点击预估模型的训练对象.实际中如果还可以获得其他类型的数据,如不同用户群体的偏好,不同类型广告的投放规律等,则可以结合使用不同类型的方法,以此获得更高的预估准确率,因为不同类型的方法可以覆盖问题的不同方面.尽管本研究从特征学习的角度研究点击率预估问题取得了较好的效果,但仍存在一些不足之处.因此,在后续的工作中,可在本文基础上,从以下几个角度进一步研究:(1)文中基于深度学习算法的时间复杂度比较高,计算开销较大,该算法复杂度与每一层的单元数和网络层数有关,同时也与连接函数有关.在保证特征学习效果的前提下,如何改进连接函数、调节每一层单元数和网络层数,以降低时间开销的问题有待解决;(2)文中提出的特征学习方法预估广告点击率,仅考虑了展示充分的广告数据,未考虑展示不充分的广告(稀疏广告).接下来的工作中,如何从特征学习的角度,预估稀疏广告的点击率,是一个值得研究的问题,也是实际中目前亟需解决的一个问题;(3)不同预估模型之间的深入分析与对比,开展不同模型融合方面的机理性研究.
