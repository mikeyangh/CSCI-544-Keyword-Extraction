Page1基于分布式数据流的大数据分类模型和算法毛国君胡殿军谢松燕(中央财经大学信息学院北京100086)摘要大数据是需求驱动的概念.随着数据库系统的普及和因特网服务的扩张,企业或者个人可用的数据正在膨胀,已有的技术很难满足大数据时代的数据分析需求,因此需要探索新的理论和方法来支撑大数据的应用.虽然大数据的4V属性已经被广泛讨论,但是它们大多描述的仍然是大数据的表象,所以很难从中抽象出统一的数据格式,因而进一步寻找可用于数据格式化的技术特征是必要的.面向于以分布式和流动性为主要技术特征的大数据应用需求,文中以分布式数据流为数据表达载体,在此基础上设计对应的大数据分类模型和挖掘算子.同时针对大数据的分类挖掘需要解决的关键问题来构建关键步骤对应的算法.理论上证明了文中给出的微簇合并技术和样本数据重构方法的合理性.实验表明:文中提出的基于分布式数据流的大数据的分类模型及算法不仅能大幅度地减少网络节点间的通讯代价,而且可以获得平均10%左右的全局挖掘精度的提升(对比已有的典型算法DS-means);虽然时间花费略高于DS-means,但是两者在不同的数据容量测试下相差很小、且时间攀升趋势相当.关键词大数据;数据挖掘;分布式数据流;微簇;集成分类1引言大数据(bigdata)概念最早是在20世纪80年代提出的,来自于《Nature》2008年推出的大数据专刊,其强大的应用需求使之成为近年研究和应用的焦点.特别是,大数据潜在的应用前景已经被许多国家的政府关注,国家政府成为大数据技术的重要推动者.例如:2012年,美国政府已经联合6个部门宣布了2亿美元的“大数据研究与发展计划”;2015年9月,中国国务院也印发了“促进大数据发展行动纲要”.迄今为止,至少有35个国家出台了相关的政策或文件来支持大数据的发展.然而,虽然大数据的应用价值及前景已经得到国家层面、学者及商界的广泛认可,但是大数据作为新生事物,面对的技术问题仍然很多,许多的理论和方法也亟待解决,研究远远落后于应用的需求.从研究角度看,目前出现的大数据概念可以大致归纳为如下几个流派:(1)数据论.强调大数据的核心是超大规模的数据集.典型观点来自于麦肯锡报告:“大数据指的是大小超出常规的数据库工具来获取、存储、管理和分析能力的数据集[1]”;(2)方法论.强调大数据的核心是寻找新的分析方法.典型观点来自于维克托的《大数据时代》著作:“大数据指不用随机分析法(抽样调查)这样的捷径,而采用所有数据处理的方法[2]”;(3)环境论.强调大数据必须结合相应的应用领域或者应用环境才有意义.如目前广泛讨论的社交大数据[3]、科学大数据[4]等;(4)特征论.强调大数据应该具有独特的属性.如国际数据公司(IDC)认为大数据有4个主要特征,即4V属性[5]:数据规模大(Volume)、数据聚集快(Velocity)、数据类型多(Variety)、数据价值大(Value).这些研究从不同视角解释了大数据概念的内涵和外延.特别是4V属性集中概括了它的主要特征.然而,不容忽略的事实是目前大数据仍处于概念探索的初级研究阶段,特别是基础性研究远远落后于大数据概念的应用.我们通过中国知网,使用“大数据”作为关键词能检索出30多万篇文章,但是在限定计算机或者自动化相关期刊下,只有6万多篇.就是这1/5不到的文献绝大多数都是综述类的,专门涉及大数据挖掘的基础理论和方法的文献很少.这种“边研究边应用”的现状应该引起计算机及其相关学科研究人员的重视,当然也为其提供了广阔的研究空间.事实上,大数据的4V属性给出的是大数据的表象特征,很难进行形式化研究.因此,结合应用特点找到更利于形式化抽象的技术特征可能是大数据技术研究的一个很好的突破口.例如,社交大数据一般是指来自于大型网站的网页数据,这样的数据不像数据库中数据表那样具有单一的数据结构,而是由结构化、半结构化及非结构化数据混合构成的,因此数据结构的多样性可能成为社交大数据的主要技术特征之一[2,5].再如,许多科学大数据具有很高维度的表达形式,表现出显著的高维性特征[4].类似地,图像、声音、视频等多媒体应用产生的大数据也是典型的高维数据.还有,在一个网络监控系统中收集的网络流量(networktraffic)大数据,总是随着时间在不断增长的,而且数据隐藏的知识模式也是在动态流动中演化的,所以这类大数据就表现出典型的流式数据特征[6].类似地,电子商务网站采集的交易大数据也是典型的流式数据.这样,既然从大数据的4V属性出发很难进行数据的抽象表达,那么根据应用特点来寻找某类大数据的技术特征、进而进行形式化研究就是一条可行的技术路径.以著名的电子商务网站eBay为例[1].它每天要处理TB级的数据流量,是典型的大规模数据.支持这种大规模数据处理的硬件环境则是几百台的数据服务器.硬件的分布性决定了数据收集是分布式的.此外,每台数据服务器上处理的数据都是按照交易时间来收集的,所以大数据的快速集聚属性对应着技术上的数据流动性.同时,如果我们只关心交易数据的话,那么这类大数据的数据结构是规范而简单的.所以,像eBay这样的电子商务网站上收集的大数据的主要技术特征就可以归纳为分布性和流动性,因而我们可以针对分布式和流动性为技术特征的大数据来进行相关的挖掘方法研究,且具有很好的理论和应用价值.从概念演化角度上说,本文关注的这类大数据是目前已经出现的“流式大数据”[6]及“分布式大数据”[7]等概念的自然延伸.从应用价值上说,抽象出的分布式和流动性的技术特征在许多大数据的应用环境中存在.除了上面提到的电子商务网站的交易大数据外,分布式和流动性的大数据环境也可能发生在网络流量监控、传感器网络以及股票交易、银行业务、商品销售等交易系统中.本文重点聚焦在具有典型的分布式和流动性技术特征的大数据的分类挖掘问题上.相比传统的分类挖掘技术,这类大数据的分类挖掘隐含着许多挑Page3战性的问题.首先,传统的分类挖掘方法以单一学习样本集为基础,而大数据的分布式收集特性决定分类学习需要分布式进行,因而对应的分布式学习策略和方法需要研究;其次,动态流动的流式大数据和传统数据库存储的静态数据有显著的不同,不可能一次性将所有数据存储起来再进行离线式的挖掘,必须探索在线实时的收集技术和随时间变化的增量式的挖掘方法;最后,传统的分类挖掘技术对学习样本集要求较高,而分布式、流式大数据的分类挖掘需要多节点、多步骤协同处理,很难保证学习样本集的纯度,所以必须针对这类大数据的挖掘特点来探索鲁棒性能好的分类技术.因此,面向于这类分布式的数据收集和随时间的数据流式聚集的大数据中的分类挖掘问题,需要集成化的技术和创新性的理论和方法来解决.大数据的分类挖掘系统是一个多步骤协作工作的系统.既有节点级的局部分析处理、又有全局性的模式发现,而且不同的阶段所要解决问题的侧重点也不同.例如:面对潜在的快速流动、随时间不断集聚的流式大数据,局部节点处理应该更强调处理的实时性和高效性.而全局的分类模式挖掘最主要的任务就是构造可以全局共享的分类器,所以更应该注重模式的预测能力和抗干扰性等.因此,应该根据不同的挖掘阶段需求来研究对应的理论和方法,形成技术集成化、方法系统化的解决方案.毋庸讳言,目前在大数据或者分布式数据流(distributeddatastream)挖掘研究上还是以单一技术为主(如单独使用基于距离的分类模型[8]、基于频度挖掘的方法[9-10]),对于整体的解决方法研究还不够.简言之,本文将重点关注具有分布式和流动性技术特征的大数据的分类挖掘问题,针对主要阶段的技术需求来探索有效的解决策略,通过研究对应的方法、并集成它们形成一个系统化的解决框架.主要工作归纳为:借助于分布式数据流的数据形态来刻画这类以分布式和流动性为主要技术特征的大数据;在此基础上设计一个适合于这类大数据的分类挖掘模型;针对模型中的主要挖掘算子进行算法设计,并在理论和实验上评估这些算法的有效性.2相关工作流式大数据的挖掘已经得到广泛关注,其中作为基础性的数据流挖掘(datastreammining)已经成为数据挖掘研究中的一个活跃分支.数据流挖掘成果最多的是单数据流挖掘方法,其中增量式挖掘被广泛关注[11],成为动态挖掘随时间流动的流式数据的有效方法.滑动窗口(slidingwindow)被认为是解决数据流中动态知识发现问题的基本技术之一,它使得潜在无限数据流中的知识发现问题能够通过有限容量的数据窗口的叠加处理来解决[12-13].经过十余年的研究,(单)数据流挖掘已经积累了许多丰富的研究成果,它们构成了本文研究工作最基本的理论和技术基础.为了高效地解决数据流挖掘问题,数据流的分布式挖掘研究出现.2007年,Parthasarathy等人[14]给出了数据流的分布式挖掘需要面对的主要问题及对策,是较早地、比较全面地介绍数据流的分布式挖掘技术的文献之一.他们的一个重要观点是:有效地利用有限的计算机处理资源来解决潜在无限数据的知识发现问题,必须寻找到一个代价与精度平衡的分布式(而不是集中式)解决方案.Bhaduri等人[15]则从性能优化的角度说明了数据流的分布式挖掘需要综合考虑分布式计算、内存缓冲及节点交互代价等问题.他们也设计了一个层次式的数据流的挖掘构架,即挖掘系统有若干局部节点和1个中心节点构成,通过局部节点的并行挖掘形成初级模式、中心节点再生成全局性的知识模式.这些研究,特别是代价与精度平衡的挖掘思想,也是本文挖掘模型设计时需要重点考虑的问题.当然,数据流的分布式挖掘关注的主要还是如何利用分布式并行技术来解决大容量的(单)数据流的知识发现问题.事实上,随着基于网络的计算机应用系统的普及和壮大,多节点独立数据集聚但逻辑上关联的多数据流成为另一重要的数据形态,即分布式数据流.诚然,目前关于分布式数据流挖掘的大多数文献还主要集中在关键科学问题及解决对策的研究上,但是随着科学问题越来越清晰,近年也出现了一些相关的挖掘构架及方法的讨论.2012年,Guerrieri等人[8]提出了一个分布式数据流的挖掘算法DS-means.它的挖掘工作分成局部聚类、模式传输和全局聚类等3个关键步骤,是典型的层次式的分布式数据流挖掘构架.在DS-means的局部及全局聚类中都使用了典型的无监督学习算法k-means.但是,为了适应不同节点、不同时间段上不同数据流的容量波动情况,在全局节点聚类之前先根据局部节点的聚类结果来动态地调整全局类簇的数目.2014年,Anceaume等人[16]设计了多数据流的分布式数据评估算法AnKLe,很好地解决了多节点并行Page4检测数据分布变化的问题.2014年,Cesario等人[9]则面向于分布式数据流的频繁项目集挖掘问题构建了一个分布式多节点的挖掘构架,并设计了对应算法来实现该构架的关键操作.本文工作借鉴了这些分布式数据流的挖掘构架和方法.简言之,分布式数据流挖掘是数据挖掘及其数据流挖掘技术研究的自然延伸和发展,目前的研究主要以算法设计为主.然而,面对日益增长的大数据需求,系统化地研究大数据的挖掘构架及其相关构架下的核心挖掘模型及算法成为一个必须面对的问题.从这个意义上讲,分布式数据流可以为许多应用环境的大数据提供一种数据组织的理想模型,而分布式数据流的挖掘算法可以作为解决大数据挖掘的核心技术之一来使用.事实上,随着大数据概念的日益升温,一些学者或者研究机构也开始尝试性探索大数据中的知识挖掘问题.2012年,Luo等人[7]认为大数据的挖掘需要在不同处理阶段研究不同的算法,并且针对一些关键步骤设计了相应的算法.2013年,Wu等人[17]从数据挖掘观点讨论了大数据分析问题,并且基于数据驱动策略探讨了大数据挖掘中的核心问题,并设计了一种大数据挖掘的体系构架和核心模型.2014年,孙大为等人[6]认为大数据有批量和流式处理两种数据形态,并对大数据流式计算中的关键技术进行了较为系统地分析.大数据挖掘也是一个代价与精度的平衡优化问题,其中在合理的通讯代价下提升分布式挖掘的精度是关键的科学问题之一.减少通讯代价的主要策略是节点间共享统计数据(而不是实时传输原始数据)[7,17].2008年,Masud等人[18]提出了一种在数据流中挖掘微簇(micro-cluster)模式的思想,即在对一个数据流执行聚类算法后抽取每个簇的点数、均值等统计值形成所谓的微簇模式.2011年,Kranen等人则将微簇类似的数据统计信息设计成一种ClusTree的树结构,随着时间增长来维护它[19].以上两个工作都是面向于单数据流挖掘的.一个直接面向于分布式数据流挖掘的相关方法来自于Wang等人[10]2011年的工作.它们设计了一个分布式数据流的频繁项目集挖掘框架,并通过维护数据概要(datasynopsis)来实现节点间的信息交流,其中的数据概要模式和本文讨论的微簇模式的思想是一致的.由于微簇挖掘生成的是数据的统计概要,所以对于分布式数据流分类挖掘来说,它可能是局部模式挖掘的理想解决方法之一.这是因为传输微簇模式能有效地减少节点间的数据通讯代价(相比原始数据)、进而能有效地避免有限的网络带宽可能造成的通讯瓶颈问题.微簇挖掘及其相关技术是本文局部模式挖掘方法的主要技术支撑.虽然微簇挖掘在局部节点是有效的,但是由于微簇模式缺乏足够的预测能力,即对未知数据的分类能力,所以作为全局模式是不合适的.事实上,在分布式数据流分类挖掘中,虽然数据是在局部节点分散收集的,但是分散在局部节点的数据流是相互关联的,所以发现全局分类器以用于多节点共享和预测是分布式、流式大数据的分类挖掘的主要任务之一.此外,由于分布式挖掘要经过局部模式挖掘和数据传输才能进行全局模式挖掘,所以多步骤的处理可能导致数据质量的下降,因此全局模式的选择和设计也必须考虑抗噪性能.基于以上两点,考虑到集成学习技术具有很高的预测能力和更好的鲁棒性能[20],所以本文将借鉴已有的集成学习技术,研究适合于分布式、流式大数据的分类挖掘需求的集成分类方法.集成分类技术的研究相对比较成熟,可以借鉴的成果也较多[20-21].3大数据的分类模型给定训练数据集T和类标识集合C,分类学习就是从T中学习出一个分类器,而分类算法则是构建这种分类器的过程描述.然而,流式大数据中的分类学习的训练数据集是随时间动态收集的,所以分类器的学习必然是一个动态的演化过程.此外,传统机器学习的分类算法强调挑选出的训练集的质量,而且认为完整的分类学习需要通过正例集和负例集来学习.即使是在数据流或者分布式数据流的相关研究中,也不乏关于基于抽样技术或者基于负例学习方法的研究[22].然而,在大数据的概念下,数据抽样和负例生成技术都不被推荐[2].事实上,面对庞大而快速流动的大数据,挑选高质量的训练样本数据集是不现实的,同时实时地构造出合适的负例样本集也是困难的.大数据的挖掘首先要解决被分析数据的形式化表达问题.如前所述,泛泛而谈的大数据概念隐含着形态各异的数据格式,很难统一地进行规范化描述.然而,如果只关心这类具有统一逻辑视图的、多节点分布式采集的、随时间流动增长的数据形态,那么这类大数据可以借助于已有的(同构)分布式数据流的概念来完成数据的格式化抽象[8,15],形成可用于分Page5析的规范化数据形态.定义1(分布式数据流).给定:时间序列T=〈t1,t2,…,ti,…〉,数据维度d和节点数n.一个分布式数据流被定义为:S={S1,S2,…,Sn},其中每个Sk(k=1,2,…,n)是一个单数据流,是在T上采集的多维数据元组序列Sk=〈r1,r2,…,ri,…〉,ri=(r1i,…,rdi,r2对于以分布式和流动性为主要技术特征的大数据的分类挖掘而言,定义1中界定的数据形态可以作为训练样本的收集模型来使用.例如,在诸如网络流量监测、电子商务交易等系统中,可以使用这样的数据模型来收集对应的训练数据.事实上,随着收集时间点的增长,训练用的样本数据在不断地集聚,当然隐藏的知识模式也在发生变化.因此,流动性大数据的分类挖掘目标之一就是随着时间变化来及时更新分类器.然而,如果采用点到点的模式挖掘策略的话,即在每个收集点都进行分类器更新,虽然实时性很好,但是对于快速流动的流式大数据来说是不现实的.因此,本文将探索块到块的模式挖掘策略,即以数据块为单位来进行分类器的更新.这样,我们就需要改进传统的滑动窗口技术.定义2给出的历史窗口概念可以帮助解决这个问题.定义2(历史窗口).给定:时间序列T=〈t1,t2,…,ti,…〉和它上的一个数据流S=〈r1,r2,…,ri,…〉.设ti,tk∈T,i<k,则Hk=[ti,tk)被称为S在k上的历史窗口,k被称为一个挖掘点,同时在Hk内收集的数据chunkk=〈ri,ri+1,…,rk-1〉则被称为该历史窗口的数据块.对于一个分布式数据流来说,约定所有的节点都使用相同的挖掘点序列,而且在任意一个挖掘点k上,所有的局部节点都使用相同的历史窗口.对每个局部节点来说,它们的主要任务就是挖掘局部模式,所以局部模式的表达是首先要解决的问题.面向于分布式、流式大数据的层次式挖掘构架[8-9],局部节点需要实时地维护自己的局部模式、并将它们传递到中心节点,因此数据传输量与局部模式的表达形式有直接的关系.当然是表达越紧凑越好.同时,由于局部模式最终要用于全局模式的学习,所以我们在选择局部模式表达形式时也需要考虑它的可恢复性,即利用它恢复全局学习样本数据的能力.基于这些考虑,本文在借鉴了已有的微簇(micro-cluster)挖掘研究成果的基础上,根据大数据的分布式和流动性的技术特点及其分类挖掘的需求,设计了定义3的微簇结构.与已有的相关研究相比[18],定义3通过增加平方和等统计变量来提高微簇的表达能力和微簇之间操作的方便性,同时也根据后面分类算法的需要增加了类标识项.定义3(微簇).设d维的数据集X={x1,x2,…,xn},其中xi=(x1微簇结构由一个5元组M=〈n,c,s,d,f〉定义:(1)M.n:数据个数(本例就是n).(2)M.c:中心点或称为均值,即(3)M.s:平方和统计(为防止溢出被开方),即(4)M.d:方差统计值,即M.dj=∑n(5)M.f:数据集的类标识.定义3的微簇结构能够满足分布式、流式大数据的局部模式的紧凑型和可恢复性要求.这是因为一个微簇对应的是一个原始数据簇的统计信息,因而要比原始数据容量小得多,而且合适的统计信息要比更抽象的分类器(如C4.5等)更有利于全局学习数据样本点的恢复.值得注意地是,微簇作为全局模式是不合适的.事实上,分布式、流式大数据的全局模式应该是对分布在多个节点的局部流动数据的共性归纳,而且主要任务是能够对流动的未知类别的数据进行分类预测,为分布式的多节点的流式数据提供共享的预测模型.很显然,微簇模式不具备这样的预测能力.因此,作为最终的知识模式,全局模式需要预测能力更强的知识模式形式.集成分类器具备这些优势,因此本文将研究对应的集成分类器方法来实现分布式流式大数据的全局模式挖掘.简言之,面对复杂的分布式、流式大数据分类问题,本文将研究、改进、集成多种技术方法,其中包括上面提到的块到块的增量式更新策略、局部的微簇挖掘方法和全局的集成学习技术等.图1给出了一个从原始数据流到局部模式再到全局模式的增量式的挖掘过程示意.在图1中,包含3个局部节点和1个中心节点,通过网络形成一个层次式的大数据挖掘构架.局部节点主要负责本节点的流式数据的收集和局部挖掘、中心节点则负责全局模式的挖掘.给定一个挖掘Page6时间点t,分类挖掘的任务就是利用t时刻的时间窗口来将局部的微簇模式和全局的集成分类器更新到t时刻的(当前)状态.对独立的阶段:如图1所示,一个大数据的分类挖掘有3个相(1)局部挖掘,即在每个局部节点依据定义1的数据模型来收集当前数据块chunkt,然后利用chunkt对上一个挖掘点所维护的局部微簇模式进行增量式更新、形成新的(当前)微簇模式.更新完成后就通过网络把它传送到中心节点.(2)模式传输,即当一个局部节点的微簇模式(3)全局挖掘,即当所有局部节点的当前微簇模式都被成功地送到中心节点后,中心节点就进行全局集成分类器的学习,将全局模式更新到当前状态.大数据的分类挖掘模型.基于上面的定义和分析,定义4给出了对应的定义4(大数据分类模型).具有分布式和流动性为主要技术特征的大数据的分类模型定义为M=〈T,D,O,P〉,其中:T=〈t1,t2,…〉是收集数据的时间点序列;D={S1,S2,…,Sn}是依据T在局部节点上收集的n条局部数据流组成的分布式数据流,是数据挖掘的数据源;O是对D的操作算子集,需要相应的算法来实现;P是全局分类器,是学习的最终结果.给定挖掘点t∈T,具有分布式和流动性为主要技术特征的大数据的分类模型通过如下的操作来层次式构造:(1)局部挖掘器,包含如下操作:①chunk-maker:D→{chunk1,chunk2,…,chunkt,…}.按照预先设定的挖掘点来收集窗口数据,chunkt被称为当前数据块.②micro-cluster-abstractor:chunkt→{m1,m2,…,mk}.负责从当前数据块中挖掘出微簇集{m1,m2,…,mk}.③micro-cluster-maintainer:{Mt-1;m1,m2,…,mk}→Mt.利用当前的微簇集来增量式更新上个挖掘点存储的微簇集Mt-1,得到当前挖掘点的微簇集Mt.转换成全局学习样本集St.(2)全局挖掘器,包含如下操作:①micro-cluster-pool:{Mt}→pool.在中心节点,设置内存缓冲池pool以收集所有局部节点发送来的局部微簇集.②sample-remaker:{Mt}→St.将当前微簇集③ensemble-updater:{Et-1;St}→Et.利用样本集St来增量式更新上个挖掘点的全局集成分类器Et-1,得到当前集成分类器Et.定义4的模型系统化地界定了具有分布式和流动性为主要技术特征的大数据的分类挖掘系统的主要功能需求及需要探索的主要挖掘操作算子.(1)在局部挖掘器中,基本的操作算子包括当前数据块的获取、局部微簇模式挖掘以及局部微簇模式的更新维护等操作.即:按照块到块的挖掘技术,通过调用局部挖掘器,在一个新数据块到达后,可以实现局部微簇模式的增量式更新.(2)在全局挖掘器中,基本的操作算子涉及到局部微簇模式的(缓冲)存储、全局训练样本数据的生成(恢复)以及全局集成分类器的更新维护等操作.即通过集成学习技术,当一个历史窗口的所有节点的局部模式到达中心节点后,通过触发全局挖掘器可以实现全局模式的增量式更新.当然,在定义4模型中的挖掘操作算子需要通过设计对应的算法来实现,并且它们构成了分布式、流式大数据分类挖掘目标对应的核心算法,因此本文接下来的主要工作就是设计和分析这些核心算法.4算法设计和分析本节将对定义4分类挖掘模型中的关键操作算Page7子进行算法设计.主要的算法包括:在局部节点中的微簇抽取和增量式微簇维护算法;在中心节点中的学习样本数据重构和集成分类算法.4.1局部节点的微簇抽取算法当一个局部节点的当前数据块被收集完成后,接下来的工作就是对其进行微簇挖掘.首先,要对当前数据块进行类簇划分.考虑到大数据的分类挖掘特点,可能存在类标识不全的情况,所以使用经典的无监督学习算法k-means进行聚类.然后,对聚类得到的每个簇进行微簇抽取.这个工作主要是依据定义3描述的微簇结构对每个类簇的数据进行对应的统计值抽取.算法1给出了在局部节点中抽取微簇模式的过程描述.算法1.micro-cluster-abstractor.输入:当前挖掘时间点t;在t时刻获得的数据块D;数输出:在t时刻的微簇集合M1.divideDintokclustersCbyAlgorithmk-means;2.FOReachp∈C3.p.n←|p|;4.FORi=1tod5.p.ci←∑q∈p6.p.si←∑q∈p7.p.di←∑q∈p8.ENDFOR9.p.c←(p.c1,p.c2,…,p.cd);10.p.s←(p.s1,p.s2,…,p.sd);11.p.d←(p.d1,p.d2,…,p.dd);12.flagp.fwiththemostlabelininstancesofp;13.integratep.n,p.c,p.s,p.dandp.fintomicro-14.M←M∪{m};15.ENDFOR16.returnM.算法1中的步骤1是使用k-means进行聚类,其时间复杂度为o(l×m),其中l和m是寻找最优划分簇的迭代次数和被挖掘的数据点大小[8].步骤2~15是实现微簇模式的构建,它的时间复杂度是O(k×n),其中k和n分别是k-means挖掘出的类簇数目和每个簇中数据点的平均大小.很显然,上面的m=k×n,所以算法1的时间复杂度由k-means算法的时间复杂度决定.此外,算法1的内存空间占用情况是:除了k-means执行所必须的内存空间外,算法1的主要额外空间是为k个簇对应的微簇统计信息提供内存的数据结构.按照定义3,每个微簇结构只需要5个数值级别的存储空间.因此,相对于传统的聚类算法k-means,算法1只有很少的额外时间花费和空间消耗.4.2局部节点的增量式微簇维护算法随着挖掘时间点的变化,一个局部节点维护的微簇集合需要及时更新来适应数据的变化.依据图1所示的增量式方法,局部节点的微簇维护意味着:利用当前数据块获得的微簇集合M,对上次挖掘点维护的微簇集合M进行增量式更新.值得注意的是,作为局部节点的局部模式,一个节点上维护的微簇模式中的微簇数目必须适当加以控制,不能随着时间的增长无限制地膨胀.这可以通过设置一个阈值参数L来加以控制.当增量式更新导致微簇数目超过L时,就需要进行微簇合并.因此,两个微簇的合并操作应该作为一个基本操作来加以研究,其中一个重要的问题就是如何在一个微簇集合中寻找两个最佳的微簇进行合并.考虑分布式大数据的特点,我们采用“方差和最小”作为寻找最佳合并簇的标准.即:给定一个微簇集合M,被选择的用于合并的两个微簇m1和m2需要满足min∑d其中:.di是一个微簇的方差的第i个维度值;unite(m1,m2)代表m1和m2合并后的微簇.由于微簇并不是直接保存数据点,所以合并后的微簇模式不能通过定义3直接获得.唯一的方法就是从两个待合并的微簇推导出合并后的微簇的统计值.定义5给出了对应的计算方法.定义5(微簇的合并操作).给定两个d维的微簇m1和m2,假如它们有共同的类标识,那么它们可以通过一个被称为合并的运算unite(m1,m2)合并成一个新的微簇,记为m3=unite(m1,m2),则m3的统计值计算如下:m3.n←m1.n+m2.nm3.ci←m1.n×m1.ci+m2.n×m2.cim3.si←(m1.si×m1.si+m2.si×m2.sim3.di←m1.si×m1.si+m2.si×m2.siPage8定理1.设m3=unite(m1,m2),则微簇m3的统计值可以通过定义5的式(5)~(9)计算出,且计算结果正确反映合并前的数据分布.证明.不失一般性,假设m1和m2是一维的,且对应的原始数据集分别为c1={x1,x2,…,xp}和c2={y1,y2,…,yq}(因为是一维就不再标识维度).设m3=unite(m1,m2),则m3对应的簇的原始数据集为c1∪c2={x1,x2,…,xp,y1,y2,…,yq}.根据定义3中微簇的点数计算,有所以定义5的(5)成立.根据定义3中微簇中心点的计算方法,有m3.c=(x1+…+xp+y1+…+yq)/(p+q)m1.c=(x1+x2+…+xp)/m1.n,m2.c=(y1+y2+…+yq)/m2.n(12)m3.c=(m1.c×m1.n+m2.c×m2.n)/m3.n(13)根据定义3中微簇的平方和统计值计算,有应用式(12)到式(11),得到所以定义5的式(6)成立.应用式(15)到式(14),得到根据定义3中微簇的方差统计值计算,有所以定义5的式(7)成立.m3.d=∑p=∑pm3.c2应用式(15)、(12)和式(10)到式(17),得到m3.d=m1.s×m1.s+m2.s×m2.s所以定义5的式(8)成立.最后,显然有由上面的式(10)、(13)、(16)、(18)和式(19)知道,在一维情况下定理1是正确的.多维情况只需要按每个维度计算即可.定理1确保了定义5的微簇合并方法是正确的.这样,当维护的微簇模式超过限定的数目时,就可以通过重复执行两个微簇的合并操作来减少微簇的数目.算法2给出了在一个局部节点上进行微簇的增量式维护的基本过程.算法2.micro-cluster-maintainer.输入:当前挖掘时间点t;从当前块抽取的微簇集合输出:t时刻更新的微簇集M1.M←M∪M;2.LM←|M|;3.WHILELM>LDO4.b←thelargestnumberofmachine;5.FOReachm1∈M6.FOReachm2∈M7.IF∑d8.s1←m1;s2←m2;9.b←∑d10.ENDIF11.ENDFOR12.ENDFOR13.p←unite(s1,s2);14.M←M∪{p};M←M-{s1}-{s2};15.LM←LM-1;16.ENDDO17.returnM.算法2的时间花费取决于微簇的合并次数.很显然,由于基于k-means的微簇抽取算法将从当前数据块中产生k个微簇,所以算法2最多执行k次微簇的unite操作.但是,为了寻找这k次合并的微簇,需要按照式(4)进行测试.每次测试的微簇集合的容量和L相当,且在一个L大小的集合中进行两两测试的时间复杂度是O(L2).因此,算法2的总的时间复杂度是O(k×L2).考虑到k和L都可以控制在合理范围内,因此算法2的时间效率可以得到保证.此外,算法2的主要内存占用是k+L个微簇对应的数据结构,所以算法2也不会产生过大的内存消耗.4.3中心节点的样本重构算法依据图1的挖掘流程,在一个挖掘点上,当一个Page9局部节点的微簇模式被更新完成后,就会把它通过网络传输到中心节点.当所有的局部节点的当前微簇模式都被传送到中心节点的缓冲池后,中心节点就会启动全局模式挖掘工作.按照定义4给出的模型,为了提高全局模式的预测能力和抗干扰性,我们使用集成分类器作为全局模式.这样,一个具有挑战性的问题就被提出:微簇模式不可能直接作为学习样本被使用,那么如何在中心节点获得集成学习所需的训练样本集就成为一个关键问题.一个可行的方法就是利用局部节点传送过来的微簇模式来重新构造全局学习样本.算法的伪代码.算法3给出了生成全局训练样本数据集的对应算法3.Sample-remaker.输入:当前挖掘时间点t;t时刻从所有局部节点传送来输出:t时刻重构的样本数据集S1.FOReachm∈M2.n←m.n;3.FORi=1ton4.FORj=1tod5.r←rand(-1.1);生成(-1,1)中的随机数;6.l←3×n×m.dj/槡2;7.xj←m.cj+l×r;8.ENDFOR9.x←(x1,x2,…,xd);合成多维数据点x;10.flagxwithm.f;11.insertxintoS;12.EDNFOR13.ENDFOR14.returnS.很显然,算法3的时间复杂度(不考虑数据维度)是O(n),其中n是恢复的样本数目.内存消耗也主要是n个样本数据所需的空间.理论上说,重构的训练样本集和原始数据集必须是等价的,至少应该保持重要的统计参数值.定理2从理论上保证了这点,因此算法3采用的数据恢复方法是合理的.定理2.假如分布式数据流中的数据满足正态分布,则对于每个微簇来说,算法3重新构造的数据集与原始的微簇的均值和方差统计值是等价的.证明.不失一般性,假设数据是一维的,处理的微簇集合M只有一个微簇m,m对应的均值和方差分别是μ和σ;对m实施算法3后得到了样本集X={x1,x2,…,xn}.根据微簇的均值定义,计算X的中心点Xc:根据算法3,X的点产生如下:xi∈X,xi←μ+3nσ/槡2×rand(-1,1)(21)代入式(21)到式(20),有Xc=1/n×∑n=μ+1/n×3nσ/槡2×∑n因为正态分布下,∑rand(-1,1)~∫10,所以根据式(22),有另外,根据定义3的方差定义,X的方差Xd为代入式(21)到(24),得到Xd=1/n×∑n=1/n×∑n根据式(23)的Xc~μ,式(25)和下面式子等价:因为∑rand(-1,1)2~∫1上面式(23)和式(27)说明在1个微簇和1维数据空间的情况下,定理2成立.当多个微簇或者多维数据时,只需要对每个微簇或者每个维度使用上面方法进行推理.4.4中心节点的集成分类器更新算法集成分类器的构造首先需要选择一个基础(弱)分类器.本文选用C4.5,它是经典的高效数据分类算法[21],特别是由于它良好的剪枝和优化机制能很好地适应大数据的处理.此外,集成分类器的更新策略也是一个重要的问题.目前流行的集成分类器大多都是基于BoostingPage10和Bagging模型的[21].基于Boosting的模型需要不断学习与更新样本数据和弱分类器的权重,对于大数据来说不仅计算太复杂、而且对于像C4.5这样的决策树模型来说也缺乏足够的稳定性[20].基于Bagging的模型随机选取每个弱分类器的训练样本,对弱分类模型要求不高,但它的收敛速度要比基于Boosting模型差.考虑分布式、流式大数据的特点,特别是对全局模式的高归纳性及抗干扰性的要求,我们将借鉴Boosting和Bagging技术,力求集成两者的技术优势来设计本文的全局集成分类器.本文集成学习策略可以简单地归纳为学习样本的淘汰策略.主要思想是:给定一个集成分类器E={e},当一个学习样本s在一个弱分类器中被正确预测时,就及时将s淘汰掉、不再用它作为其他的弱分类器的训练样本.这样做的目的是为了尽可能地保证弱分类器之间的差异以提高对样本的覆盖度,同时也提高了集成分类器的学习效率.算法4给出了中心节点学习集成分类器的过程描述.算法4.ensemble-updater.输入:当前挖掘时间点t;训练样本集S;在上个挖掘点输出:t时刻更新的集成分类器E1.p←|S|/Q;设定弱分类器的样本数2.FOReache∈E3.e.error←0;4.FORs∈S5.f←e(s);使用弱分类器e进行预测6.IFf=s.fTHENdeletesfromS7.ELSEe.error←e.error+1;8.ENDFOR9.IFS=THENbreak10.ELSE11.K←randomlyselectpsamplesfromS;12.e←C4.5(K);学习一个新分类器13.E←E∪{e};14.ENDIF15.IF|E|>QTHEN16.c←ethatsatisfiesmax{e.error|e∈E}17.E←E-{c};超过上界时删除最差的弱分类器18.ENDIF19.ENDFOR20.returnE.算法4在每个挖掘时间点更新全局集成分类器.依据增量式更新的策略,针对每个弱分类器,做了如下3个工作:(1)步骤3~8对所有的训练样本针对一个弱分类器进行测试,对于测试正确的样本进行淘汰(即不用它们产生新的弱分类器).假设整个训练样本集有n个数据点,则其时间花费和n成正比.(2)步骤9~14利用未被淘汰的样本数据(随机选取)进行新的C4.5分类器学习.假设C4.5的平均学习时间是c的话,那么步骤9~14的时间花费和c相当.(3)步骤15~18完成一个弱分类器的裁剪(在弱分类器数目超过设定的阈值时),这需要在被观察的集成分类器中对每个弱分类器的错误情况进行比较,需要测试的次数和Q相当,其中Q是集成分类器中弱分类器数目的上限值.根据算法4,上面的3个工作需要对每个弱分类器进行,而弱分类器的数目由Q值决定,所以整个算法4的时间复杂度是Max{O(Q×n),O(Q×c),O(Q2)}.一般地说,Q是远小于n和c,因此算法4的执行时间主要取决于训练数据的规模和C4.5算法的训练学习时间.算法4的内存消耗主要是集成分类器中所有C4.5对应的数据结构,与集成分类器的弱分类器数目有关.5实验与分析为了评估本文模型和算法的有效性,我们使用公共数据集KDD(CUP)99①来构建对应的大数据挖掘的训练和测试数据.KDD99的原始数据来自于MIT林肯实验室收集的美国空军模拟网的流量监控数据,后来被哥伦比亚大学等整理成规范的公共数据集.KDD99数据集是网络连接记录的时间序列数据,所以被认为是研究流式的网络流量数据分析及入侵检测模式评价的标尺数据集(benchmark).同时,由于它的训练数据部分已经被很好地标注,而且网络流量及入侵检测分析的主要手段是分类挖掘,因此也被用来评估数据流中的分类算法.KDD99的整个训练数据有5000000多个网络连接记录,有41个学习的条件属性,包含正常(normal)或攻击(attack)两大类,后者又被分级成4个二级类别.考虑到本文主要是进行分类挖掘(而不是专门的入侵检测)实验,因此本文的实验不再对4个二级类别做①KDDCup1999Data(KDDCup99).http://kdd.ics.uci.Page11进一步划分和区分.为了模拟分布式、流式大数据,我们编制了一个数据流生成的软件工具stream-producer.它通过对KDD99数据集的I/O操作来模拟流动数据的在线到达情况.stream-producer主要通过数据收集时间间隔和数据流速两个参数来控制数据流.本文实验的设置为:数据收集时间间隔是1/2000s;流速范围1000~2000记录/s.设置不同的数据流速是为了更好地模拟数据的随机流动情况,所以实验是针对不同的时间段内收集的数据容量可能不同的实际情况设计的.本文实验基于3个局部节点和1个中心节点的分布式数据流应用环境,使用4台Intel酷睿i7、内存2GB的计算机构成对应的硬件单元.利用Hadoop的HDFS分布式文件系统,将KDD99数据集分布存储在3个局部节点中,中心节点作为Master节点,负责对应的文件目录信息的维护.在每个局部节点上,stream-producer工具被部署,来模拟数据流的产生过程以形成窗口数据.算法1~4主要采用Hadoop的MapReduce编程方法来实现.例如,就局部微簇的抽取(算法1)而言,Map()函数的键值对被设计成〈数据元组,簇号〉,完成数据块的k-means聚类映射操作,而对应的一次Reduce()函数的调用则完成一个数据簇(相同簇号)的统计计算,即微簇模式抽取.按照定义4模型和图1的流程,局部挖掘器的核心处理是基于算法1和2的,全局挖掘器的核心处理是基于算法3和4的.因此,在每个局部节点,需要以算法1和2为核心形成完整的局部挖掘器,在中心节点以算法3和4为骨干形成完整的全局挖掘器.实验中通过增加“本文算法的连接程序模块”,实现了完善的局部挖掘器和全局挖掘器功能.例如,就局部挖掘器而言,通过算法1对应的Reduce函数的调用可以得到所有数据簇对应的微簇集合,所以在微簇合并操作(算法2的核心操作)的实现中,我们设计的Map()键值对是〈(簇号1,簇号2),方差和〉,调用它来完成一个微簇集的方差和映射,其中输入的簇号1和2都来自于算法1中Reduce的输出结果.对应的微簇合并中的Reduce()的功能则是寻找最小方差和、并将最小方差和的两个微簇合并起来以实现对应的微簇合并功能.类似的,全局挖掘器也通过这样的编程方式加以实现.就局部挖掘器和全局挖掘器的连接问题而言,本文实验是通过中心节点的存储缓冲值的变化来触发的,即当3个局部节点的局部微簇模式全部到达中心节点时就触发全局分类器开始工作.正如定义4模型所刻画的那样,以分布式和流动性为主要技术特征的大数据的分类挖掘是在多个节点、由多个步骤来协作完成的,以全局分类器为最终的挖掘成果,因此全局分类器的精度决定一个方案的整体挖掘精度.但是,一个分布式系统的挖掘时间和内存消耗总是被分散在多个节点上,因此依据定义4模型,局部挖掘器和全局挖掘器都有对应的时空效率评估问题.当然,全局的性能评估是最重要的,所以以下的实验主要是针对全局分类器的性能进行评价.本文方法简称为BDS-ensemble,使用的主要控制参数有H-size、unlab%和E-no,它们分别代表时间窗口大小、未标签的样本比例和集成分类器的弱分类器数目.对比算法是DS-means[8],其中DS-means的类簇数目是根据数据容量动态产生的(按照原始论文方法).在本文实验中,DS-means产生的类簇数目在30~100的范围内.之所以选择DS-means作为对比算法,主要是考虑它和本文方法都是基于局部节点和中心节点构成的层次式挖掘构架的,因此具有可比性.实验1(不同历史窗口下的精度测试).当固定其他控制参数时,按照定义4模型及相关的算法1~4,在1000s内的训练数据流中,使用本文方法BDS-ensemble和对比算法DS-means生成对应的全局分类器.然后,利用KDD99中的测试数据集来进行精度测试.图2给出了随着历史窗口长度增加时BDS-ensemble和DS-means的错误率对应变化.图2表明,BDS-ensemble的错误率明显小于DS-means(平均优于10%左右).因为历史窗口变长意味着收集的数据块变大,所以在1000s处理的窗口数目变少,因而挖掘精度应该被期望变高.图2说明,当历史窗口增大时BDS-ensemble的精度在Page12逐步提升,而DS-means则表现出波动.当然,设置窗口的目的就是为了利用有限的计算机资源(内存、CPU等)来解决潜在无限的大数据问题,所以也不可能通过无限度地增加窗口长度来换取分类精度.另外从图2中也可以看出,相比DS-means,BDS-ensemble的稳定性要好.就图2而言:当窗口长度达到30s时,BDS-ensemble的错误率已经下降到10%左右,当再加大窗口长度时,错误率的下降幅度明显收窄.这种稳定性使得代价与精度的优化的分布式流式解决方案成为可能.实验2(不同的集成分类器设置下的分类精度测试).固定H-size=30和unlab%=25%,在1000s内,每增加100s执行1次BDS-ensemble和DS-means来生成全局分类器,然后进行错误率测试.本实验的目的是测试集成分类器中的弱分类器数目对挖掘精度的影响,图3给出了不同的弱分类器数目下的BDS-ensemble的错误率随着训练时间增加时的变化情况(对比算法是DS-means).此外,为了更清楚地看到两种方法的差别,图4把E-no=20时的BDS-ensemble和DS-means的错误率用折线图形式展示出来.从图3中可以看出:当E-no=5时,BDS-ensemble的分类精度并不是很好;在E-no=10时已经有很大改善;当E-no=15和E-no=20时,BDS-图3流动数据在不同的集成分类设置下的错误率变化ensemble的分类精度随着训练时间的增加在稳步提升,当训练了1000s后,其分类精度已经达到90%左右.相比而言,DS-means则不稳定,而且分类精度明显要比本文方法要差.从图4中可以清楚看到:当集成分类器维持一定大小的弱分类器数目时(如实验中的E-no=20),BDS-ensemble会随着训练时间的增加分类精度逐步提升,而且逐步稳定在一定的精度范围内.相比较而言,DS-means则存在一定的波动.实验3(执行时间和内存空间测试).固定unlab%=25%和E-no=20,通过设置不同的历史窗口长度,跟踪BDS-ensemble和DS-means执行时在中心节点的时间花费和空间消耗.因为BDS-ensemble和DS-means都需要依次经过局部节点和中心节点挖掘来进行,在相应节点上都有对应的CPU时间占用和内存空间消费,因此本实验只跟踪了中心节点的时间和空间消耗.就中心节点而言,它们的时间和空间消耗主要花费在全局模式的更新上.图5给出了在中心节点中BDS-ensemble和DS-means学习全局分类器的时间花费比较,而图6则给出了BDS-ensemble和DS-means学习全局分类器的内存消耗情况.从图5中可以看出,BDS-ensemble和DS-means随着历史窗口的时间增长,一次增量式更新的时间图5时间窗口长度增加时执行时间的变化情况图6时间窗口长度增加时内存空间的变化情况Page13花费都会增加.这是因为历史窗口增长使得CPU的窗口计算时间增加.同时,虽然BDS-ensemble比DS-means略高,但是两者的攀升幅度相当.这主要是因为BDS-ensemble使用的集成学习方法需要多次调用C4.5算法.但是,按照算法4的设计,每次调用C4.5算法时不是使用全部的训练样本、而是随机选取部分样本,所以BDS-ensemble的执行时间并没有比DS-means有特别明显地提升.图6中说明,BDS-ensemble和DS-means的内存消耗相差不大.同样是由于BDS-ensemble在调用C4.5算法时使用地是部分训练样本,所以内存消耗要稍微少于DS-means.综合实验1、2和3,面对复杂的大数据应用,本文方法能够通过较小时间代价的增加获得较大挖掘精度的提升,进而在精度与代价的平衡上获得了一个较优化的解决方法.6优势和局限性讨论本文针对大数据4V属性难以进行形式化研究的问题,分析了大数据隐藏的技术属性.从概念上讲,不同技术属性及其组合能演变出特定类型的大数据形态.聚焦在大数据的分布式和流动性的技术特征上,本文研究了这类大数据的知识挖掘问题,并且可以契合电子商务业务、股票交易等大数据的应用需求.本文模型和方法的优势首先表现在合理的网络通讯代价上.大数据的分布式挖掘必须面对代价与精度的平衡问题,再高精度的方法如果存在无法承受的代价(包含网络传输量)都是不可行的.本文方法的优势也体现在方法和技术的集成上.大数据中分布式挖掘问题应该建立在多节点、多步骤协同工作基础上,而不同数据挖掘方法在不同挖掘步骤中的有效性和局限性是客观存在的,因此针对不同步骤或者阶段来寻找和实施对应的挖掘技术是本文解决问题的基本理念之一.本文在局部节点采用微簇挖掘技术、在全局节点利用集成学习方法、针对大数据特点来研究和使用块到块的增量式挖掘手段等,都体现了这种理念的运用.对应的实验也验证了这种集成化的解决方案的有效性和科学性.当然,本文模型和方法也存在应用的局限性.主要表现在两个方面:(1)本文探讨的只是大数据中的一类数据形态,并不能完全适应所有的大数据应用.例如:对于像大型电子商务网站的交易大数据而言,本文模型和方法可以提供一种可行的解决方案;但是对于像门户网站这样具有数据类型多样化的大数据而言,基于本文定义1的数据形态就无法形成规格化的数据描述,因而本文的模型和方法就不能完全解决这类问题;(2)本文探讨的全局样本恢复算法是以数据的正态分布为前提的,对于数据分布极其不规范的情况,算法的精度可能会下降.7总结大数据概念在强大的应用需求下被提出,而且随着云计算等软硬件基础设施的发展,使得大数据的分析成为可能.然而,大数据的研究和应用仍然处于起步阶段,有许多挑战性的问题需要逐步解决.特别是,在理论和方法上的需求越来越迫切.本文从大数据的分布式和流动性这些技术特征出发,在挖掘模型及关键算法等方面进行了系统化地研究和设计.本文首先从大数据的应用需求入手,分析了具有分布式和流动性技术特征的大数据的应用范围和潜在的应用价值.然后,借助于分布式数据流概念刻画了这类大数据的抽象数据模型,并在此基础上设计了一个大数据的分类模型.最后,对于模型中关键操作对应的算法进行了设计.本文对应的研究,突出体现了利用技术的集成化来系统化地解决大数据挖掘问题的主要思想,在分布式的微簇挖掘、块到块的增量式学习以及基于淘汰策略的集成分类器学习等理论和方法上进行了创新性的工作.本文对应的大数据的分类挖掘构架及其系列算法,不仅可以全方位地改善以分布式和流动性为主要技术特征的大数据的分类挖掘效果,而且在分布式计算、内存占用及节点间的网络通讯代价的平衡问题上可以获得了一个优化的结果.进一步的工作包括:针对非正态化的数据分布情况,研究基于密度估计等的样本重构方法;寻找非样本重构技术的全局模式挖掘方法;针对大数据的其他需求,研究分类以外的挖掘问题,如关联规则、概念归纳等;针对大数据的其他技术特征,如高维性、数据半结构化等,开展相应的理论、模型和算法研究.
