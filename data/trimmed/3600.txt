Page1基于熵的模糊信息测度研究丁世飞1),2)朱红1)许新征1)史忠植2)1)(中国矿业大学计算机科学与技术学院江苏徐州221116)2)(中国科学院计算技术研究所智能信息处理重点实验室北京100190)摘要模糊信息测度(FuzzyInformationMeasures,FIM)是度量两个模糊集之间相似性大小的一种量度,在模式识别、机器学习、聚类分析等研究中,起着重要的作用.文中对模糊测度进行了分析,研究了基于熵的模糊信息测度理论:首先,概述了模糊测度理论,指出了其优缺点;其次,基于信息熵理论,研究了模糊熵理论,建立了模糊熵公理化体系,讨论了各种模糊熵,在此基础上,提出了模糊绝对熵测度、模糊相对熵测度等模糊熵测度;最后,基于交互熵理论,建立了模糊交互熵理论,进而提出了模糊交互熵测度.这些测度理论,不仅丰富与发展了FIM理论,而且为模式识别、机器学习、聚类分析等理论与应用研究提供了新的研究方法.关键词模糊熵;模糊交互熵;模糊绝对熵测度;模糊相对熵测度;模糊交互熵测度1引言模式识别(PatternRecognition,PR)是智能信息处理中的一个重要学科领域,不是一门简单的分类学,它包括对系统的描述、理解与综合,它要通过大量信息对复杂过程进行学习、判断和寻找规律.模式识别诞生于20世纪20年代,随着40年代计算机的出现,50年代人工智能的兴起,模式识别在60年代初迅速发展成一门学科,它所研究的理论和方法在很多科学和技术领域中得到了广泛的重视,推动了人工智能系统的迅速发展[1-2].从本质上说,PR方法就是将观测模式向量与已知模式类相比较,而归根结底是测试模式与已知模式类中的模式向量相比较,如果测试模式与模式类最相似,则就将其归入该模式类中,以实现模式的分类识别.因此研究如何度量两个模式之间的相似性测度问题是PR研究中的核心问题之一.为了能划分模式的类别,必须首先定义模式相似性测度,用来刻画各模式之间的相似程度.常用的主要有距离测度(差值测度),它是以两个模式向量矢端的距离为基础,是两个向量各对应分量之差的函数,两个模式越相似,其距离测度值越小.常见的距离测度有欧氏(Euclidean)距离、绝对值距离(或Manhattan距离)、切氏(Chebyshev)距离、明氏(Minkowski)距离及马氏(Mahalanobis)距离等[3-4];相似测度,它是以两个模式向量的方向是否相近作为考虑的基础,向量的大小并不重要,两个模式向量越相似,其相似性测度值越大.常用的几种相似性测度有夹角余弦(也称为角度相似系数)、相关系数、指数相似系数等;匹配测度,这种测度多用于医学和植物的分类之中.在有些情况下,特征只有两个状态,对象或具有此特征或不具有此特征.此时,若对象有此特征,则相应分量定义为1;若对象无此特征,则相应分量定义为0,这就是所谓的二值特征.对于二值n维模式向量,常用的匹配测度有Tanimoto测度、Rao测度、简单匹配系数、Dice系数、Kulzinsky系数等.这些测度理论与方法,在模式识别与分类、图像处理以及无监督学习理论中发挥了重要的作用,但本质上他们都是利用了确定环境下两模式的相似性度量.而在实际工作中,人们经常遇到随机环境、模糊环境等不确定性环境,研究不确定性环境下两模式的相似性度量具有重要的理论意义与实践意义.美国控制论专家扎德(ZadehLA)于1965年在《InformationandControl》杂志上发表了题为“Fuzzysets”的著名论文,这标志着模糊理论的产生[5].该理论引起了数学界和科技工程界的极大兴趣并对其进行了深入广泛的研究,理论成果和应用成果不断出现,从而创建了一门新的学科———模糊数学[6].有关模糊信息处理的理论和应用取得了重大进展,并由此产生了模糊模式识别(FuzzyPatternRecognition,FPR)方法,在FPR理论与应用研究中,模糊贴近度作为两个模糊集之间彼此接近的程度的一种度量,起到了关键作用[7].但这种模糊贴近度是建立在模糊贴近度公理化基础之上,计算复杂度较高.本文将研究基于距离测度公理化理论基础上的模糊信息测度[8-11],这样一方面弱化了模糊贴近度公理化条件,从而增大了模糊测度的应用领域,另一方面,不仅进一步丰富与发展了FIM理论,而且为模式识别、机器学习、聚类分析等理论与应用研究提供了新的研究方法.2模糊熵测度2.1信息熵设有一离散型随机变量X,其n个可能的取值为a1,a2,…,an,每一结果出现的概率分别是p1,p2,…,pn,X的概率空间可表示为i=1由于[X·P]完整地描述了由X所代表的离散其中∑n信源的特性,故称为信源X的信源空间.我们称为信息函数,在事件{X=ai}发生之前,表示事件的不确定性;在事件{X=ai}发生以后,表示事件所含有的信息量,又称为ai的自信息.Shannon把信息函数在信源空间[X·P]中的统计平均值H(X)=H(p1,p2,…,pn)=-∑n作为信源X的不确定性程度的度量,称为信息熵、Shannon熵或概率熵[12-14].2.2模糊熵模糊熵(FuzzyEntropy)是模糊信息处理的基本函数,用以度量模糊集合的模糊程度,在模式识别、图像处理、语言分析等许多领域有着广泛的应用[15-16].一般来说,关于模糊集A的信息熵,即模糊熵Page3是下列一个映射:这里假定ξ(X)是离散论域X={x1,x2,…,xn}上所有模糊子集的集合,A∈ξ(X).通常H满足Deluca-Termini4条公理,即(1)H(A)=0μA(x)=0或1,x∈X;(2)H(A)取最大值μA(x)=1/2,x∈X;(3)如果AB,则H(A)H(B),其中“AB”表示A比B峰化,即0μA(x)μB(x)1/2,0μB(x)1/2烅烄1/2μB(x)μA(x)1,1/2μB(x)烆(4)H(A)=H(珡A),其中珡A是A的补集.模糊熵刻画一个模糊集的整体模糊程度,上面4条公理是容易理解的:分明集显然是不模糊的,即模糊熵等于零;(2)和(3)表明,从总体上讲各元素隶属度越接近于1或0,越不模糊,越接近于0.5,越模糊;(4)表明A与它的补集珡A具有相同的模糊程度.2.3模糊熵测度我们知道,在Shannon信息理论中,平均互信息量I(X;Y)度量了两个随机变量X与Y之间的公共信息,又称为公共信息量(MutualInformation,MI),借用Shannon信息理论的有关提法,研究两个模糊集之间的模糊公共信息量.下面虽然我们借用了Shannon信息熵的提法,但从概念上是完全不同的.定义1.设X为离散论域,A,B∈ξ(X),记则有(1)模糊熵H(A)=-1H(B)=-1(2)模糊联合熵H(A∪B)=-1n∑x∈X[1-μA(x)∨μB(x)]log[1-μA(x)∨μB(x)]}=-1n∑x∈X+1n∑x∈X-{μB(x)logμB(x)-[1-μB(x)]log[1-μB(x)]}(3)模糊条件熵H(A/B)=-1[1-μA(x)]log[1-μA(x)]-[1-μB(x)]log[1-μB(x)]}H(B/A)=-1[1-μB(x)]log[1-μB(x)]-[1-μA(x)]log[1-μA(x)]}它们具有下列性质.定理1.设X为离散论域,A,B∈ξ(X),则证明.首先证明式(10).{μA(x)logμA(x)-μB(x)logμB(x)+H(A)-H(A/B)=-1n∑x∈X1n∑x∈X+[1-μA(x)]log[1-μA(x)]-[1-μB(x)]log[1-μB(x)]}=-1n∑x∈X+(1-μB(x))log(1-μB(x))]-1n∑x∈X-0,所以H(A/B)H(A)成立.念,我们得到下列定义.同理可证式(11)成立,即H(B/A)H(B).由定理1的证明,不难看出下列结论成立.定理2.设X为离散论域,A,B∈ξ(X),则借助于Shannon信息理论中公共信息量的概定义2.设X为离散论域,A,B∈ξ(X),则称绝对差值H(A)-H(A/B)为A与B的模糊公共信息量(FuzzyMutualInformation,FMI),记作H(A∩B),即H(A∩B)=H(A)-H(A/B)=-1n∑x∈X+1n∑x∈X-类似地可定义H(B∩A),即[μA(x)logμA(x)+(1-μA(x))log(1-μA(x))]Page4H(B∩A)=H(B)-H(B/A)=-1n∑x∈X+1n∑x∈X-[μA(x)logμA(x)+(1-μA(x))log(1-μA(x))]根据定理2及定义2,容易看出FMI满足非负性、对称性等基本性质,所以FMI是一种广义的、绝对的模糊性测度,称之为模糊绝对熵测度(FuzzyAbsoluteEntropyMeasure,FAEM),它在某种程度上度量了两个模糊集A与B之间的相似性程度.对模糊集A与B之间的相似性程度,除了用FAEM度量之外,在实际应用中,我们有时会用到相对的模糊性度量,下面我们给出一种相对的模糊性度量.定义3.设X为离散论域,A,B∈ξ(X),则称R(A,B)=H(A∩B)为B对A的模糊相对公息(FuzzyRelativeMutualInformation,FRMI).同样地R(B,A)=H(B∩A)称为A对B的模糊相对公息(FRMI).性,为此我们对FRMI改进如下.S(A,B)=R(A,B)+R(B,A)=H(A∩B)由于R(A,B)≠R(B,A),即FRMI不满足对称定义4.设X为离散论域,A,B∈ξ(X),则称为A与B的模糊相对熵测度(FuzzyRelativeEntropyMeasure,FREM)FREM表示在模糊信息方面模糊集A与B之间的模糊相似性度量,可用于聚类分析、图像处理等方面.3模糊交互熵测度3.1模糊交互熵pn),Q=(q1,q2,…,qn),P对Q的交互熵为对于X的两个概率分布向量P=(p1,p2,…,交互熵概念在Shannon信息理论中占有非常重要的地位,用于度量两个概率分布间的差异性信息.但在实际测量数据处理中,信息并非必然具有概率性质,在某些非概率情况下,一样存在信息,就是说存在着所谓的“非概率信息”.(q,1-q),则根据式(18),当n=2时,令P=(p,1-p),Q=H(P‖Q)=plogp由于模糊集合的隶属度函数与其补集的隶属度函数间的关系与式(19)是类似的,因而仿此可定义一种类似的熵,称之为模糊交互熵,用以度量一个可能性分布与另一个可能性分布之间的信息差异程度.定义5.设为两个模糊向量,对于某个xi,定义μA(xi)对μB(xi)的交互熵为f[μA(xi)‖μB(xi)]=μA(xi)logμA(xi)因此,两个模糊集A对B的模糊交互熵(FuzzyCrossEntropy,FCE)可定义为F(A‖B)={i=1μA(xi)logμA(xi)∑n式(21)有个缺点,即当μB(xi)→0(或1)时,其值趋向于无穷大,为此仿照FCE的定义,改进的模糊交互熵(ImprovedFCE,IFCE)定义如下:F(A‖B)=∑n这样对于所有的μA(xi)和μB(xi)该公式都有定义.3.2模糊交互熵测度可以证明,F(A‖B)只满足非负性,而不满足对称性,为此我们构造对称型的模糊交互熵.定义6.设为两个模糊向量,F(A‖B)与F(B‖A)分别为A对B和B对A的模糊交互熵,则称为对称模糊交互熵(SymmetricFuzzyCrossPage5Entropy,SFCE).具有下列性质:下面给出并证明SFCE的性质.定理3.对称模糊交互熵(SFCE),即D(A,B)(1)非负性.D(A,B)0;(2)规范性.D(A,B)=0A=B;(3)与模糊熵的关系.D(A,珡A)=(-2nlog2)d(A)+2nlog2,d(A)=-1其中为模糊熵.证明.性质(1)、(2)是显然的,下面证明性质(3):根据式(22)与式(23),我们有D(A,B)=F(A‖B)+F(B‖A)设B=珡A,则有将式(26)代入式(25),得到D(A,珡A)=∑n(1-μA(xi)log[2(1-μA(xi))]}+i=1i=1∑nμA(xi)log[2μA(xi)]}=2∑n=2(-nlog2[)-1(1-μA(xi))log(1-μA(xi]))}+2nlog2(1-μA(xi)log(1-μA(xi))+log2}=(-2nlog2)d(A)+2nlog2.因此有D(A,珡A)=(-2nlog2)d(A)+2nlog2.性质(3)得证.对于任意有限的模糊集合A,有0d(A)1,因此得0D(A,珡A)2nlog2,所以当A=珡A时,D(A,珡A)=0达到最小值;当A是普通集合时,D(A,珡A)=2nlog2达到最大值,所以A与珡A相差越大,D(A,珡A)也越大,反之亦然.D(A,B)是一种广义的距离测度,用以度量两个模糊集A与B之间的差异程度,作为两个模糊集之间的一种信息度量准则,我们称之为模糊交互熵测度(FuzzyCrossEntropyMeasure,FCEM).4结论在现有模糊信息测度理论研究基础上,基于Shannon信息理论,给出了模糊熵公理化理论,讨论了模糊熵的各种定义.在此基础上,建立了模糊绝对熵测度(FAEM)、模糊相对熵测度(FREM);在交互熵理论研究的基础上,给出了模糊交互熵的定义,以此为基础,建立了模糊交互熵测度(FCEM).这些理论与方法,拓宽了模糊信息测度理论研究领域,为进一步开展模式识别、机器学习、聚类分析等理论与应用研究提供了理论基础.
