Page1面向CGRA循环流水映射的数据并行优化杨子煜1)严明2)王大伟1)李思昆1)1)(国防科学技术大学计算机学院长沙410073)2)(西北核技术研究所西安710024)摘要数据密集型应用中的核心循环消耗了程序的大量执行时间.如何实现核心循环在粗粒度可重构体系结构(CGRA)上的有效映射仍是当前研究领域的难点.为了在CGRA上最大程度开发应用并行性,降低循环访存开销,提高硬件资源利用率,文中提出一种新颖的面向CGRA循环流水映射的数据并行优化方法.通过定义一种新的可重构计算模型TMGC2以实现对循环的多条数据流水线并行加速.为避免并行化执行带来的额外存储体冲突问题影响CGRA执行性能,为后续循环映射创造良好的数据条件,引入存储体消除策略对数据进行重组,并结合数据重用图实现数据并行优化.实验表明,采用文中方法对已有CGRA循环流水映射方法进行优化,可以提高37.2%的数据吞吐量及41.3%的资源利用率.关键词可重构计算;数据密集型应用;数据重组;数据重用;循环映射;粗粒度可重构体系结构1引言可重构计算体系结构现已在嵌入式系统领域被Page2结构所不具备的可编程能力.相对于传统计算模式,可重构体系结构具有高性能、高效率和可编程特性,非常适于对性能和功耗要求均比较苛刻的嵌入式数据密集型应用的处理,如图像压缩、模式识别和数字信号处理等.与细粒度可重构体系结构(如FPGA)相比,粗粒度可重构体系结构(Coarse-GrainedReconfigurableArchitecture,CGRA)采用存储与计算分离的思想.在计算方面,CGRA由大粒度的处理单元(ProcessingElement,PE)阵列构成,实行集中式功能配置管理,提供强大的计算能力,可实现更快的配置速度和更好的执行加速.在存储方面,采用层次化的存储结构,对应用加速执行时可实行3个层次的并行:指令级并行、数据级并行和任务级并行,提供了更大的应用映射优化空间[1].但由于数据密集型应用通常包含大量循环,CGRA处理这些循环时存在大量PE与数据存储体(DataMemoryBank,DMB),以及数据存储体间的通信操作和访存冲突,从而严重影响CGRA的执行性能,降低了应用加速效率.已有大量研究工作针对CGRA应用映射进行优化[2-5],但主要通过对应用本身进行复杂的循环转换和调度实现并行和加速,映射过程较为繁琐且资源利用率不高.为了在CGRA上最大程度开发应用并行性,降低循环访存开销,提高硬件资源利用率,本文提出一种新颖的面向CGRA循环流水映射的数据并行优化方法.文中首先借鉴单指令多数据流(SIMD)思想,利用数据流驱动,构建多个可重构数据流水线(DataPipeline,DP)灵活组合的可变宏粒度CGRA计算(TransformableMacroGranularityCGRAComputing,TMGC2)模型,以实现不同领域数据密集型应用的多粒度映射.随后针对循环映射过程中的访存问题,根据循环迭代的数据复用关系进行数据重组(DataReorgani-zation,DR)以避免存储体冲突.该方法通过对循环数据进行重组以实现CGRA应用映射时的数据并行优化,改进了CGRA存储体局部性,有利于消除数据密集型应用的访存瓶颈,同时支持后续循环流水化映射,提高了CGRA计算及存储效率.本文的主要创新点如下:(1)提出了一种可变的宏粒度CGRA计算模型TMGC2.与已有可重构计算模型面向整个PE阵列考虑应用映射不同,该模型支持根据不同应用的映射方案,构建相应数目的多条PE数据流水线,实现了CGRA灵活的配置.通过多条流水线并行执行,可支持循环迭代间并行处理,从而提高资源利用率.(2)提出了一种发掘循环迭代数据重用的存储体冲突消除(MemoryBankConflictsEliminate,MBCE)算法.结合数据重组DR和数据重用图等方法重新组织循环的数据访问方式实现存储感知的数据并行(Memory-awareDataParallelism,MDP)优化,MDP方法实现了CGRA循环映射的数据并行优化,消除了CGRA访存瓶颈,提高了数据处理的吞吐量.(3)结合TMGC2模型,文中提出的数据并行优化方法可以有效改善后续CGRA循环流水映射性能.结合已有循环自流水LPKM映射方法[6],采用文中数据优化方法后的CGRA应用映射的资源利用率提高了41.3%,同时数据吞吐量提高了26.7%.本文第2节介绍相关研究工作;第3节讲述了TMGC2模型及应用映射过程;第4节分析了CGRA存储冲突并给出数据并行优化方法MDP;第5节给出了结合MDP的循环流水映射实现并进行了实验评测;最后在第6节对本文进行了总结.2相关工作随着半导体制造工艺的发展,处理器芯片的性能提升由依靠深度流水来提升流水线工作频率转向依靠片上资源扩展来增加内核数量.处理器片内并行性也因此在传统的指令级并行基础上,增加了多核线程级并行和数据级并行.对于数据密集型应用如多媒体处理、科学计算等程序,主要考虑针对其中的循环进行加速以扩展数据并行性来获得程序执行性能的提升.在体系结构方面,现已有大量采用SIMD技术的嵌入式系统,通过对硬件运算单元进行并行扩充,提高流水线的数据处理能力,如ARMNEONTM①、EStarIII[7]等.但在可重构计算领域类似SIMD执行机制的体系结构则有ADRES[5]、MorphoSys[8]和IMAPCAR[9]等.其中ADRES包括一个二维可重构PE阵列和一个VLIW主控处理器.在对应用程序进行处理时,首先对程序进行划分,随后进行模调度以便将核心计算任务映射到可重构阵列上各个PE并行执行.和ADRES相似,MorphoSys采用主控RISC处理器与可重构阵列紧耦合的方式,其可重构单元阵列可通过更改软件配置,使得多个单元按照SIMD方式执行,而单元间通①ARM.Neon[EB/OL].http://www.arm.com/products/Page3过可配置网络实现多种数据交换模式.IMAPCAR包括128个处理单元,采用4路VLIW架构对数据进行并行处理,通过严格限制单元与存储体间的数据传输方式来实现一对一访存从而实现SIMD并行执行.但这些结构在应用映射时均需要复杂的循环转换优化方法以适应目标硬件,且由于重构粒度固定,对于不同数据驱动特征的应用需要更换不同的映射优化方法,难以实现应用自动映射.而LEAP[10]将流水线并行执行和数据驱动执行紧密结合.其采用分布式循环控制,实现固定指令多数据流的执行模式,同时充分考虑循环时的数据重用,减轻高流水线吞吐率对存储带宽的压力.但LEAP结构假设处理单元所需数据已存在于对应的数据存储体中,未考虑存储延迟,因而本文主要基于对其计算模型进行扩展得到TMGC2模型以解决存储体冲突等问题,实现数据并行优化.在映射策略方面,大多数已有方法只考虑了计算映射[5-6,11-12].如王大伟等人[6]针对LEAP采用LKPM方法实现循环的流水化自动执行并在映射目标函数中考虑了存储资源约束,但未能考虑循环依赖关系对数据访问的影响;Yoon等人[11]采用SPKM方法支持CGRA上应用的自动映射,并获得了较高资源利用率,但其并未考虑通过优化存储提升数据密集型应用性能;Cardoso[12]讨论了循环自流水在可重构硬件上的实现,提高了循环吞吐率,但尚未考虑循环中的数组依赖关系.目前针对CGRA存储系统的数据优化研究得还较少.Dimitroulakos等人[13]提出了一种在PE间重用数据的路由转发机制,以减少PE对CGRA局部存储的访问;Kim等人[14]改进了文献[13]中方法,在循环粒度的数据流图上添加数据重用边并减少访存节点数量,随后采用启发式模调度算法进行映射.同时Kim等人[15]提出了以SIMD思想实现CGRA数据映射的方法图1CGRA传统计算模型与TMGC2模型映射比较并比较了数据不同存储方式对循环迭代映射的影响,但其仅限于定性描述,未考虑CGRA存储层次且缺乏具体的数据并行化算法细节.本文所提出的MDP算法着眼于循环数据并行优化,通过对CGRA存储体冲突的判别和消除,在不影响计算映射性能的前提下实现高效的数据映射.3TMGC2模型下的应用映射数据密集型应用通常有较高的数据吞吐量要求.有效映射这些应用,尤其是对循环等一些关键代码块进行并行优化,是CGRA能否高效执行的关键.由于CGRA的性能主要取决于其计算模型和应用映射策略,因此不仅仅需要对应用的关键代码块进行转换与优化,更需要定义高效的计算模型,以充分利用CGRA有限的计算及存储资源,以满足系统约束和应用需求.3.1面向CGRA的应用映射如图1(a)所示,CGRA体系结构主要由处理单元(PE)阵列、存储系统和接口控制器3部分构成.以LEAP为例,其计算映射主要由具有数据流计算特征的PE二维阵列完成.阵列内部单元分为用于循环控制和存储访问控制的mPE(memoryProcessingElement)和用于计算加速的cPE(com-putingProcessingElement),各单元由互联网络相连;数据映射由外部存储(ExternalMemory,EM)、多个数据存储体(DataMemoryBank,DMB)和若干局部配置存储(LocalMemory,LM)组成的存储系统配合mPE实现;接口控制器则负责连接主控处理器核、外部存储和可重构处理单元阵列,用于加载配置信息、传输数据以及传递主控处理器指令.cPE由配置存储器和指令寄存器指导完成特定功能的计算操作并将结果输出至指定目标.mPE与DMB连接,Page4负责将数据从DMB载入并传送至cPE或将计算结果存储至DMB.具体的体系结构细节参见文献[10].传统模型计算过程首先由配置控制逻辑对配置信息进行解释,通过LM经配置总线传递至各PE,PE完成功能与互联配置后即实现硬件电路结构的重构.待重构完成,PE阵列内部构成特定的数据映射域(Mappingdomain),如图1(a)阴影部分所示.随后从EM经DMB加载待运算数据至各流水线,进行数据驱动的计算,最后将执行结果再次由mPE返回至DMB和EM.若从应用的循环映射角度来看,循环执行时其计算/访存操作分别映射至CGRA的各个cPE和mPE上;所需数据从EM经接口控制器导入各DMB上并根据一定策略放置以供mPE快速访问.数据密集型应用的循环映射即是找到CGRA执行时存储体冲突最小、资源利用率最大以及数据吞吐量最高的最优或局部最优的映射域方案.3.2TMGC2模型由图1(a)可知,传统的CGRA计算模式通常面向整个PE阵列进行计算及存储映射,因此CGRA的PE阵列规模越大,其资源利用率越低,映射域搜索空间过大的问题越严重.考虑到数据密集型应用的核心代码块大多为关键循环,通过循环展开可将同一循环的多个迭代实例映射至PE阵列上并行执行,以单配置流多数据流的方式加速循环.定义1.Kernel.循环体内可在DP上进行加速流水执行的若干计算操作的集合.循环的一次迭代实例所包含的计算操作,视为Kernel的一个实例.若循环体内包括访存操作时,则应将其划分为多个Kernel,分别映射至不同DP上.与已有的类似SIMD形式加速CGRA计算方式不同,TMGC2模型可将CGRA的PE阵列视为由多条同构数据流水线DP组成,可同时并行地对多个Kernel实例进行流水处理.对于不同的待加速应用,其DP的cPE数目也可随Kernel映射需求而改变.对于PE阵列为n×m的CGRA,DP构成形如“i个mPE+j个cPE”,其中1im,1jn.图1(b)与图1(c)为n×m阵列的两种TMGC2构成形式,其中深色阴影框表示DP中负责与DMB通信的活跃mPE(ActivemPE),其数目根据不同映射需要灵活设置.循环开始执行时,由配置管理器统一发出配置信号至各条流水线.当流水线注入启动信号后,由mPE从DMB载入所需运算数据,各cPE由数据驱动进行独立计算.每次完成一个Kernel实例时,由mPE发出循环迭代终止判断信号,与其它流水线的mPE进行同步.若mPE收到主控循环终止的信号,则向cPE发出运算停止信号,待cPE返回计算结果后,将当前所存储的数据返回至DMB.为保证流水线存储/计算配置一致,DP只能通过mPE访问DMB,各流水线PE连接方式相同.以图1(b)的流水线结构为例.将n×m的PE阵列划分为m条DP使得配置搜索空间规模由n×m降至n×1.对循环进行加速时,可将其不同迭代分配至不同DP并行执行,在单条DP内对于Kernel则是流水执行方式,因此TMGC2可实现应用的循环并行流水映射,提高PE资源利用率.当需要加速不同循环时,例如Kernel内操作改变、操作数目增加时,只需改变cPE功能和连接方式,加大流水线规模即可,如图1(c).由于TMGC2模型将循环迭代映射至多条DP进行加速,改变了原有循环数据访问方式.因此相较于传统的CGRA应用映射仅包含计算映射和数据映射,TMGC2映射需要进一步考虑循环的迭代映射.迭代映射与数据映射紧密相关,由图1可知,TMGC2可能导致对存储体访问次数的增加,从而引发更多的存储体冲突(BankConflict)问题.因此在文中第4节引入MBCE算法以解决这些问题.4数据并行优化方法进行循环迭代并行加速时,mPE主要完成以下任务:(1)负责从DMB中获取数据供cPE使用;(2)存放cPE执行完循环单次迭代后所产生的临时数据;(3)循环终止时将DP执行结果输出至DMB.由于在DP执行过程中cPE只能通过mPE获得所需计算数据,若存在循环迭代间依赖,需要访问其它DP中mPE内数据时,只能通过DMB将数据传至本地mPE,才能对这些数据进行访问.循环迭代间依赖将导致大量DMB通信访问,从而引起DMB的存储体冲突问题.因此为避免迭代映射改变访存顺序所导致的冲突问题,有必要根据循环迭代映射至DP的方式针对性地对DMB内数据进行重组.4.1数据重组TMGC2的局部数据存储分为多个数据存储体DMB,每个DMB向与之相连的数据流水线DP提供数据.通常在CGRA内数据的存储管理方式可分为交叉存放(InterleavedDataPlacement)和顺序存Page5放(SequentialDataPlacement)[15].考虑到TMGC2流水并行的执行方式,为避免多条DP对同一DMB进行频繁访问,本文只考虑数据交叉存放方式.图2(a)上半部分为计算一阶差分代码,其循环迭代次数N为256,数组A[i]和A[i+1]存在迭代间依赖.假设CGRA的PE阵列按照TMGC2配置为m条数据流水DP,与m个存储体DMB一一对应,将循环的不同迭代交叉分配至各DP,如图2(b)所示,其中流水线上的数字表示处理循环迭代序号,图2TMGC2下循环迭代映射与数据重组定义2.重用距离.数组引用a若在迭代i中引用的数据被数组引用b在迭代i+d中使用,则迭代间隔d被称为重用距离.如图2(a)中A[i]与A[i+1]的重用距离为1.由图2(c)示例可知,若重用距离d不为DMB数目m的整数倍时,这两个数组引用将分布在不同DMB中.若要实现对数据的重用,则需要对数据在DMB上的分布进行重组,使得重用数据分布在同一DWB上,有效避免了DMB间的频繁通信.假设CGRA中DMB数目为M,循环体内存在迭代依赖的数组A[i],迭代次数为N.DMB中数据重组前数组A[i]访问跨步为M,存储长度为N/M.对于A[i]和A[i+d]间存在重用距离为d,数据重组后生成数组为A[i].A[i]的访问跨步定为N/M,存储长度定义为N/M+d.可知A[i]所访问的从第N/M×k个到第N/M×(k+1)-1个数据,A[i+d]所访问的第N/M×k+d个到第N/M×(k+1)+d-1个数据均分布于第k个DMB上.因而重组前DMB间的数据重用均已转换成同一DMB内的数据重用.若对于同一数组内存在多个跨迭代重用(d1,d2,…,dn),令D=max(d1,d2,…,dn),数组在DMB中的存储长度定为N/M+D.图2(d)显示了数据重组后A[i]在DMB中的分布情况,其中M=8,N=256,重用距离为1.下面给出数据重组算法DR.m值为8.数组A[i]在8个DMB中的交叉分布如图2(c)所示,图中数字代表数组元素在外存的地址顺序.相应地,在DMB中数字代表该数组元素分布在此DMB中.由于数组A[i]与A[i+1]存在依赖,因此A[i]可以重用A[i+1]在前一次迭代生成且保存在DMB上的数据.但由于TMGC2实行DP间交叉迭代映射,因此仅对数据进行重用将导致频繁的DMB间通信.因而有必要改变对数组在DMB交叉放置的方式,进行数据重组.算法1.数据重组DR算法.输入:循环L,TMGC2硬件描述输出:数据重组后生成的与L等价的循环L配置信息1.扫描循环L代码,找到所有与数组引用a存在跨最内层迭代依赖的数组引用,求出重用距离d,存入临时数组集合ASet0;2.求出ASet的最大复用距离D0,D0=max(d1,d2,…,dn),若ASet0中只有一个数组引用,则D0=0;3.记录a的迭代次数N,设置a的访问跨步为N/M,存储长度为N/M+D0;4.构建新的数组a,标记至各DMB;5.对ASet0中所有数组引用重复2~4步;6.若L中存在其它数组引用依赖,构建新的ASet1,直到处理完毕,输出循环L;的数据处理顺序对L进行流水化映射.7.将数据重组信息输出至TMGC2数据管理器,按照新DR算法对图2(a)中代码进行处理时将生成两个数组集合ASet0={A[i],A[i+1]}和ASet1={B[i]},且D0=1,D1=0.重组后A[i]访问跨步为32,存储长度为33;B[i]的访问跨步为32,存储长度为32.图2(c)和(d)比较了A[i]和A[i]在DMB的分布情况.数据重组前同一DP每次循环迭代所访问数据均分布在相邻DMB上,而重组后存在重用关系的数组分布在同一DMB上,因此各DP计算图2(a)代码中循环迭代时无需进行DMB间通信,实现了多流水线并行执行,提高了计算吞吐量.但由于数据重组改变了程序原有的访存顺序,Page6生成新数组访问跨步大于1,从而导致多个连续的访存地址落在同一存储体DMB上,导致了存储体冲突.因此在进行数据重组前必须进行存储体冲突消除处理.定理1.假设循环中数组引用a的起始地址为0,DR算法生成数组a的访问跨步大小s若满足则a的访存序列将产生存储体冲突,且从第k×sizeSA×numDP至(k+1)×sizeSA×(numDP-1)个引用地址均在同一存储体中,k=0,1,2,….其中sizeSA为DP执行时一次载入数组a的数据量(以字为单位),numDP为DP数目,M为DMB数目.证明.数据重组后a的长度为s×numDP的访存序列应为0,s,2×s,…,(numDP-1)×s,1,s+1,…,(numDP-1)×s+1,…,(numDP-1)×s+(sizeSA-1).可知前numDP个相邻地址间隔为s.因s为M×sizeSA的整数倍且sizeSA2.又因在TMGC2模型中DP数目为DMB数目整数倍,所以前numDP个地址将落在同一存储体中,产生冲突.考虑到访存序列0,1,…,s-1属于同一次载入,所以第k×sizeSA×numDP到(k+1)×sizeSA×(numDP-1)的引用在同一存储体中,得证.证毕.由定理1可知产生存储体冲突的原因在于数据重组后数组a的访问跨步大小为M×sizeSA的整数倍.因此我们考虑引入存储体冲突消除MBCE算法对循环进行分割,改变数组访问跨步大小,以避免上述问题.定理2.若采用DR算法对循环中数组a进行处理,生成的访问跨步大小为s,将产生存储体冲突.令s0=s/2-1,s1=s/2+1,若DR算法分别以s0和s1为访问跨步构建数组a,则不会产生存储体冲突.证明.由定理1可知s=i×(M×sizeSA),则有s0/(M×sizeSA)=i/2-1/(M×sizeSA).因M×sizeSA2,s0不能被M×sizeSA整除.同理s1亦不能被M×sizeSA整除.因此以s0和s1为访问跨步构建数组a,不会产生存储体冲突,得证.证毕.定理3.若对迭代次数为N的循环L采用DR算法生成数组引用a产生了存储体冲突,其访问跨步为s.若将L拆分为子循环L0和L1,其迭代次数分别为N0=N/2-numDP,N1=N/2+numDP,则DR算法对L0和L1进行数据重组不会2.根据定理1判断DR处理的L是否存在存储体冲突;3.若不存在冲突,则转向步7;4.若存在冲突,则:5.令迭代次数N0=N/2-numDP,以L循环体为6.令迭代次数N1=N/2+numDP,以L循环体为循环体子循环L0;循环体子循环L1;产生存储体冲突.证明.由定理1可知且N0=N/2-numDP,N1=N/2+numDP,因此DR算法为L0和L1生成数组引用访问跨步分别为s0=s/2-1,s1=s/2+1.由定理2可知DR算法处理L0和L1中数组引用将不产生存储体冲突,得证.下面我们考虑引入存储体冲突消除(Memory算法2.存储体冲突消除MBCE算法.输入:循环L输出:L的子循环L0和L11.扫描循环L代码,采用DR算法对其中数组引用进BankConflictsEliminate)算法MBCE.行初步处理;7.将当前产生循环返回,并作为DR算法的输入;8.否则,返回0,数据重组将不产生存储体冲突.图2(a)下半部分为循环通过MBCE算法拆分后所生成的代码.实际情况中,若循环数组规模较大,DMB容量不足时,则考虑对循环进行进一步划分,以免DMB溢出.通过合理设置划分参数(如划分级数、循环子块大小等),降低数组存储需求规模并避免引入新的迭代间依赖,提高数据局部性.4.2数据重用4.1节主要研究如何避免单个DP执行循环迭代时访问所对应DMB的数据缺失问题,通过数据重组优化单个DMB的局部性.对于n×m规模PE阵列的CGRA而言,当循环体Kernel数目多于1个,或Kernel内部计算操作较多时,n个cPE构成的DP无法完成一次完整的迭代执行,此时应考虑采用如图1(c)所示较大粒度的DP构成形式,通过多条DP共同完成计算.若循环存在数据跨迭代依赖,则会导致不同Kernel对同一数组引用的访问.为保证DP并行计算时数据一致性,有必要在单个DMB数据重组基础上进一步考虑数据重用.以图3(a)所示代码为一个典型的迭代间存在相关性的嵌套循环.将其迭代内部各操作向DP进行映射时,构成的数据流图(Data-flowGraph,Page7DFG)如图3(b)方框内所示,包括两个Kernel:K0和K1,Kernel内部为cPE计算节点,外部为mPE存储节点.两类节点之间的边反映了存储流,计算节图3循环迭代映射的数据重用对于循环内访问同一数组的引用ai和aj,假设ai涉及的数据(若ai为读引用,即载入数据,或ai为写引用,即生成数据)在aj引用前保持不变,则ai和aj存在数据重用的可能,无需访问外部存储.数据复用存在两种类型:(1)迭代内复用,即ai和aj对同一数据的访问发生在同一迭代内;(2)跨迭代复用,即ai和aj处于不同迭代中,此时仅当ai和aj间的相对地址间隔不变,即重用距离保持不变时,采用数据重用才能减少存储访问数量.以图3(a)为例,可知嵌套循环内层j迭代间数组B[i,j]和B[i,j-1]以及外层i迭代间数组A[i,j]和A[i-1,j]可采用数据重用.通过遍历已有DFG,发现所有在同一数组引用上存在读后读及写后读相关的访存操作节点对,如图3(b)中DFG中节点对(0,2)与(1,7).通过消除这些节点对中的后续节点(2和7),并在这些节点对的前导节点(0和1)与后续节点的原有后继间添加重用边,即可生成数据重用图(DataReuseGraph,DRG).图3(c)显示了对图2中DFG进行数据重用转换后的DRG,可以发现通过数据重用循环体仅包括一个KernelK0,从而降低了DP规模和配置难度.图3(d)则显示了经过转换后循环单次迭代在PE阵列上的数据流向,其中虚线边代表了重用边,用以表示存储流的跨迭代重用.重用边的权值为其数组引用的最大重用距离D.由此可知D越大,数据重用的时间耗费越长.在实际应用中我们可以综合考虑目标体系结构的可用存储数、访存操作延迟以及目标启动间距II来设定重用距离D的上限,从而保证数点间的边则反映了计算流.mPE节点是数据流的阀门.两个mPE控制数据的流入,最后一个mPE则控制数据的流出.据重用有效.5实验与分析5.1实验环境本节实验所采用粗粒度可重构SoC平台包括一个嵌入式通用RISC处理器核EstarIII以及一个可重构阵列LEAP.EstarIII用作主处理器核,LEAP作为协处理器进行关键循环映射加速.通过扩展LEAP结构以符合TMGC2模型特征,采用循环自流水技术将循环控制表达式映射至mPE,并将循环体映射至cPE阵列.LEAP通过接口控制器与EstarIII互联,完成配置信息和数据的加载、结果的返回以及反馈循环运行状态.实验环境配置采用AMDAthlon4400+(2.31GHz)和2GB内存,操作系统为RedHatEnterpriseLinuxAS4.7(kernel2.69),采用LooPo-20081008工具对循环内部数组间的数据依赖关系进行分析.采用的应用实例包括一些典型的数据密集型算法核心,面向LEAP采用文中方法首先对循环进行数据并行优化,随后利用文献[6]中循环自流水LPKM方法进行映射,并测试各典型算法的运行时间和映射性能.比较的指标包括各算法所占用的计算/存储资源数目、存储需求、执行时间、吞吐量和资源占用率.包括:(1)基本算法核心:离散余弦变换DCT、矩阵响亮转置MVT和矩阵LU分解;(2)典型算法:矩阵乘(MatrixMultiply,MM)、运动检测(MotionDetection,MD)和中值滤波(MedianFilter,MF).Page85.2实验结果与分析表1给出了在应用TMGC2模型前后采用MDP方法对各算法映射性能的影响,包括应用TMGC2前后占用cPE/mPE/DM数目、应用MDP后访存操作降低比率(LoadsReduction)、存储/访问时间比(DCR)以及执行时间(Runtime,以时钟周期为单位).LoadsReduction列表示应用MDP方法后,减少的数据加载表1TMGC2模型和MDP方法对CGRA映射性能的影响算法名称(算法规模)DCT(2000)4/4/46/4/4-40.3%1.4910.63076207358034877320754MVT(10000)3/3/36/6/3-63.6%1.4090.422173299482126516522LU(2000)9/3/410/4/4-50.3%1.3810.31748239337592797919580MD(4,32)6/10/58/16/8-40.1%1.3691.065190862170553166049102881MD(8,120)6/12/410/16/8-43.2%1.5151.064391223374348352100306913MM(64×64)10/8/210/10/5-20.7%1.4270.75365293416724113423253MM(128×128)10/8/210/12/4-22.6%1.6640.632413038318901335641224583MF(320×240)8/8/420/10/5-21.3%1.5581.232213932182010158309121547MF(480×360)8/8/420/10/5-22.5%1.6211.302428467379792338488286035从表1中可知,TMGC2模型的应用有效提高了硬件资源,特别是计算单元cPE的利用率.由于DP流水线并行执行,大幅减少了运行时间.同时由于进一步采用MDP方法挖掘数据并行度并进行了数据重组,使得LEAP执行时访存操作大大减少,降低了数据加载量,改善了存储/访问时间比,亦进一步改善了算法映射效果.注意到MDP对于包含较为简单的循环体算法优化效果更好.由于MDP中避免存储体冲突的MBCE算法仅是对循环进行分段,因此对于较为复杂的程序在数据重组时仍包含未消除的数据依赖从而影响了优化效果.图4则给出了LKPM+MDP方法进行映射的资源利用率UoR和吞吐量ThO.此时我们未采用TMGC2模型对计算阵列进行流水线并行化.对比已有LKPM和SPKM方法,将SPKM方法的数据标准化为1,可以看到在图4(a)和图4(b)中,由于对算法核心进行映射时充分考虑了存储影响,并预先对矩阵乘、运动检测等具有较多数据依赖的算法核心进行了数据重用,节省了存储资源,较之仅采用LKPM方法显著提高了资源利用率UoR,且提高了数据吞吐量ThO.其计算方法为,假设将循环L映射至PE阵列上,此PE阵列包括CPE数目为m×(n-1),MPE数目为m,数据存储DM数目为dmn.假设执行循环L占用了i个cPE,j个mPE以及s个DM,执行时间为TL,包含NumL个计算及存量与优化前总数据加载量之间的比值,即(MDP-MDP-off)/MDP-off×100%.Original表示仅采用LKPM方法面向整个LEAP处理阵列进行循环映射,MDP-off表示不对算法进行数据并行优化.MD(4,32)表示MD算法参数为m=n=4,M=N=32,MM(64×64)表示计算MM时矩阵规模为64×64,MF(320×240)表示MF所采用图像大小为320×240.储操作,则此循环的UoR、ThO分别为图4典型算法映射效果比较(以SPKM方法的数据作归一化)Page9综合表1及图4的实验结果可知,采用文中方法对已有CGRA循环流水映射方法进行优化,平均提高了37.2%的数据吞吐量及41.3%的资源利用率.6结论CGRA提供了高效和灵活的配置来加速复杂的数据密集型应用,但如何有效映射这些应用中的计算核心部分,尤其是关键循环,仍是一个挑战性任务.我们针对CGRA的资源利用率不足的问题,定义了TMGC2模型以实现循环到CGRA映射的并行映射加速.其中针对在CGRA映射关键循环时由于频繁的存储访问带来的延迟问题,我们将数组进行重组,并对数据进行重用,实现了数据的并行优化,以消除CGRA访存瓶颈,提高了数据处理的吞吐量.文中提出的MDP方法可以有效改善后续CGRA循环流水映射性能.通过结合已有LPKM映射方法,几种典型应用算法的映射实验表明,引入MDP方法后的TMGC2并行映射的资源利用率有了显著提高,对接近于手工映射方法的性能.在未来工作中我们将进一步考虑CGRA存储层次以实现对应用中循环映射的更多优化.
