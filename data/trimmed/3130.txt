Page1一种新的基于瞳孔-角膜反射技术的视线追踪方法张闯1),2)迟健男1),2)张朝晖1),2)王志良1),2)1)(北京科技大学信息工程学院北京100083)2)(北京科技大学钢铁流程先进控制教育部重点实验室北京100083)摘要针对现有单相机单光源视线追踪系统存在的几个问题:精度不高、头动受限以及标定复杂,提出了一种新的基于瞳孔-角膜反射(PCCR)技术的视线追踪方法.通过提出的瞳孔边缘滤波算法(RDPEF)和三通道伪彩色图(TCPCM)解决了近红外条件下瞳孔定位误差较大、瞳孔跟踪鲁棒性较差的问题,进而提高了视线特征提取的精度.通过提出的头部位置补偿方法以及个体差异转化模型,使二维映射模型允许使用者头部运动并且只需要单点标定.该方法提高了单相机视线追踪的精度和应用范围,为面向人机交互的视线追踪系统提供了有效的低成本解决方案.关键词视线追踪;瞳孔定位;瞳孔跟踪;视线估计;瞳孔-角膜反射(PCCR)技术1引言视线是眼睛注视的方向.它代表一个人关注的焦点.近几十年,视线追踪一直都是比较活跃的研究课题.视线追踪在交互和诊断[1]两个领域都存在着很大的应用潜力,如人机交互界面(HCI)、虚拟现实、眼部疾病诊断、人类行为研究等.例如,当使用者注视显示器屏幕,可以通过视线追踪系统估计出使用者在屏幕上的注视点.因此,视线可以作为先进的计算机输入手段[2],其已经被证明比传统输入设备(比如鼠标指针)更有效率[3],而且身体残障的人士也可以使用系统.此外,基于视线追踪技术的互动显示器也可以实现[4],该显示器的显示画面可随视线的变化而变化.视线追踪也被认知科学家广泛地应用于人类的认知[5]和记忆[6]研究.高精度和高鲁棒性的视线追踪系统是研究视线追踪技术的最终目标.用于诊断的视线追踪系统对精度要求较高,往往可以采用接触式的视线追踪系统以达到更高的精度[1].用于交互的视线追踪系统除了对精度、鲁棒性、实时性的要求以外,需要最大程度地减少或消除对使用者的干扰.随着数字摄像机和微型计算机两项技术的迅速发展,基于数字视频分析(VideoOculographic,VOG)的视线追踪技术成为非接触式视线追踪热点研究方向.因为不要求与使用者有任何形式的接触,使用者的视线完全通过处理眼睛图像的方法而得到,对于使用者来说是舒适的,没有干扰的.基于VOG的视线追踪系统随着硬件的不同和提取图像特征的不同而产生很多变化.视线(LineOfSight/PointOfRegard,LOS/POR)是通过计算眼部图像的特征而进行估计的,例如计算瞳孔中心与角膜反射的向量(PCCR)[7-8]、角膜反射阵列(Cross-RatiosMethod)[9]或者虹膜的椭圆(“One-Circle”Algorithm)[10-11].视线追踪系统有些是基于单相机和单红外光源[12].有些系统则加入第2个光源[13]或更多,目的是为了创造出特殊的角膜反射模式[14]以增加跟踪的鲁棒性和准确性.Tomono[15]使用的系统由3个相机和两个不同极性的偏振光源构成.由可控制的偏振光所产生的图像,通过滤光片,被相机捕获,从而减少了该系统对外部光线变化的敏感性.Yoo和Chung[16]使用5个红外光源和两个相机,通过角膜反射与瞳孔中心的位置特征和屏幕的实际大小来估计注视点,方法是使用投影平面不变的交比(Cross-Ratios)值.Beymer和Flickner[17]采用4个相机和两个光源,以区分头部检测和视线估计.其系统采用广角立体相机来检测人脸的位置,然后控制活动的窄视野立体相机来追踪高分辨率的眼睛图像.其后,Brolly和Mulligan[18]减少系统配置,使用3个相机,删除其中一个窄视野相机.Ohno和Mukawa[19]提出一个与Beymer和Flickner类似的解决方案,在眼睛模型上有所不同.Hansen和Pece[20]和Wang等[21]对降低系统硬件配置进行了尝试,使用单相机无红外光源进行视线估计,方法是基于虹膜检测.Hansen和Pece[20]研究了头部姿态不变情况的视线估计的基本特性,其方法不需要预先知道相机、屏幕和使用者眼球的空间位置.Wang等[21]使用一个头部模型,并通过基本的投影几何关系计算椭圆虹膜圈的法线方向,作为视线方向.本文提出一种包括瞳孔定位跟踪和视线估计的实时视线追踪方法.下面将详细介绍该方法的整个流程.2基于瞳孔-角膜反射技术的视线追踪方法理想的视线追踪系统需要满足以下几点要求:(1)准确的.例如,精确到分;(2)可靠的.结果可重复;(3)鲁棒的.可以在各种条件下正常工作,例如室内/室外,带眼镜,带隐形眼镜;(4)非接触式的.对用户无害,舒适的;(5)允许自由的头部运动;(6)不需要初始校准;(7)实时的.瞳孔-角膜反射技术是基于VOG的视线追踪系统最普遍使用的方法.视线方向(或显示器表面的注视点)的估计方法是追踪瞳孔中心和角膜反射的Page3相对位置.角膜反射是光源(一般是近红外光源)在角膜表面反射形成的虚像.相机获取到的眼睛图像中的瞳孔是真实瞳孔经过角膜折射后形成的虚像.系统的精确性可以通过设置与相机镜头同轴的近红外(IR)发光二极管进一步提高,其产生的“亮瞳”现象(如图1所示)会使视频图像更容易处理.本文采用的近红外(IR)发光二极管的功率在安全阈值以下,对人体无害,而且对于使用者是不可见的.亮瞳和暗瞳的产生原理见图1.基于瞳孔-角膜反射技术的视线追踪大致可分为两类:基于二维映射模型的视线估计方法[4,22]和直接的三维视线估计方法[17,23-24].三维视线估计方法有以下几个优点:(1)因为采用立体视觉,可以检测使用者头部的空间位置,所以允许使用者头部自然运动.(2)因为采用几何模型进行视线估计,映射函数不依赖于标定位置,所以视线估计的精度不会随着头部远离标定位置而下降.(3)因为只要标定视线与眼球光轴的夹角,不需要依靠标定确定眼睛特征参数与视线的映射函数,所以标定点数较少,在双相机双光源的条件下可以做到单点标定.(4)三维视线估计方法估计的是空间视线方向,而不是屏幕视线落点,所以视线估计不依赖于屏幕位置、大小、形状,可以计算视线在任何物体上的注视点,并且不需要重新标定视线估计函数.同时,三维视线估计方法有以下几个缺点:(1)因为三维视线估计需要使用立体眼睛特征参数,增加了眼睛特征检测和参数提取的复杂性.(2)因为需要采用立体视觉,所以至少需要两个相机.(3)因为需要估计角膜球面中心的空间位置,而角膜球面中心不可见,需要至少两个光源的像去估计角膜球面中心的空间位置,所以至少需要两个光源.(4)三维视线估计的精度依赖于立体视觉的精度,对硬件配置要求较高.(5)需要进行相机标定,光源位置标定和屏幕位置标定,并且三维视线估计对以上位置非常敏感,相机发生变化不仅要对自身重新进行标定,而且要对光源和屏幕重新进行标定,光源和屏幕发生变化要对自身重新进行标定.二维视线估计方法有以下几个优点:(1)因为二维视线估计仅需要使用平面眼睛特征参数,眼睛特征识别和参数提取简单快速.(2)因为不需要采用立体视觉,所以可以使用单相机.(3)不需要估计角膜球面中心的空间位置,仅需要知道平面图像上的一个角膜反射与瞳孔中心的相对位置就可以进行二维视线估计,所以可以采用单光源.(4)二维视线估计的精度依赖于用户标定算法而不依赖于立体视觉,不需要进行三维重建,对硬件配置要求较低.(5)不需要进行相机标定、光源位置标定和屏幕位置标定,仅需进行用户标定.同时,二维视线估计方法有以下几个缺点:(1)二维视线估计依赖于标定位置,视线估计的精度随着使用者头部远离标定位置而迅速下降,所以使用者需要保持头部静止.(2)需要依靠标定确定眼睛特征参数与视线的映射函数,所以标定点数较多.为了解决以上问题,提出一种新的基于瞳孔-角膜反射技术的视线追踪方法,包括特征参数提取、视线映射函数和头部位置及个体差异补偿算法,如图2所示.图2本文基于瞳孔-角膜反射技术的视线追踪方法本文创新工作主要体现在以下几个方面:(1)利用亮瞳现象提出一种新的基于多通道图像的亚像素瞳孔定位算法.(2)针对角膜反射对瞳孔边缘的影响,提出一种基于径向距离的瞳孔边缘专用滤波算法(RDPEF算法).(3)针对亮瞳现象提出用于瞳孔跟踪的三通道伪彩色图(TCPCM)的概念.(4)结合改进的粒子滤波算法,提出一种针对实时视线追踪的伪彩色瞳孔跟踪算法.(5)提出一种单相机单光源条件下的视线估计方法,在保证回归和泛化能力的前提下,减少标定点数到一点.(6)提出了一种单相机单光源条件下头部位置的补偿算法.(7)提出了一种单相机单光源条件下使用者个体差异的转化模型.CCD、GPIO卡、单片机、主机和屏幕组成.使用者注视屏幕,由CCD摄像机获取人脸图像,通过图像采集卡传送到主机,主机通过特征参数提取和视线映射函数来得到视线落点,显示在屏本文硬件系统由光源、滤光片、镜头、采集卡、Page4幕上.另一方面,为了得到方便处理的人脸图像,采用GPIO卡(GeneralPurposeInput/Output)获取CDD视频图像的帧同步信号,再通过单片机控制光源的开关.通过内外环光源的交替亮灭产生交替的亮瞳和暗瞳图像.本文硬件系统结构见图3.红外光源配置见图4.3基于眼睛检测和跟踪的特征参数提取3.1基于主动红外光源的眼睛检测和跟踪传统的眼睛检测和跟踪方法主要利用眼睛在外观和形状上与人脸其它部分的差别.眼睛的特点,如黑色的瞳孔、白色的巩膜、圆形的虹膜、眼角、眼睛的形状等,可以用来区分人眼与其他对象.但由于闭眼、眨眼、眼睛大小和位置的可变性、不同的照明条件、人脸的方向等原因,这些眼睛的特点将减小甚至消失.基于主动红外光源的眼睛检测和跟踪是一种简单有效的方法.其利用瞳孔对近红外光的反射现象定位瞳孔.有很多基于此原理的眼睛追踪系统[25-31],包括一些商业产品[12-14,25].其依靠主动红外光源产生的亮瞳和暗瞳效果.Ebisawa等[26]利用两个红外光源(近轴光源和远轴光源)产生亮瞳和暗瞳图像.通过跟踪差分图像中的亮瞳孔,可以有效地跟踪眼睛.Ebisawa在文献[27]中进一步改善其方法,利用瞳孔亮度的稳定性,来消除眼镜反光的影响.Morimoto[28]利用两个红外光源产生亮瞳和暗瞳图像,在阈值化后的差分图像中检测瞳孔.Morimoto[29]针对不同光照条件下的眼睛检测和跟踪做了一些工作,通过动态的设置差分图像的阈值来消除背景的影响.Haro[30]在亮瞳和暗瞳的基础上,结合眼睛的外观,进行眼睛检测和跟踪.Ji等[31]对差分图像进行滤波,以消除外部光线干扰.3.2特征参数提取框架特征参数提取是视线估计的前提,本文提取瞳孔中心到角膜反射的向量作为视线估计的依据.特征参数提取需要满足以下几点要求:(1)眼睛检测与跟踪的特征参数提取过程是自动的,不需要使用者干预.(2)整个特征参数提取过程快速准确,满足视线估计对参数的精度和实时性要求.(3)能够提取用于视线估计的所有特征参数,包括估计头部位置所需要的参数.(4)特征参数提取过程能适应个体差异,不因为眼睛大小、形态个体差异而影响算法性能.特征提取方面影响最终视线估计精度的原因主要有以下几点:(1)角膜反射造成瞳孔轮廓改变,造成瞳孔定位误差.(2)瞳孔运动造成差分图像瞳孔区域不全,造成运动瞳孔定位误差.(3)角膜反射形状的不规则和边界的不确定性造成角膜反射中心定位误差.(4)作为头动补偿的其它特征参数产生的误差.瞳孔及角膜反射中心定位是本文视线追踪系统实现的必要步骤,为满足上述要求,并针对影响特征提取精度的主要原因,本文提出一种基于多通道图像的特征参数提取方法.在追求高精度亚像素特Page5征参数提取及鲁棒性方面做了如下研究:(1)角膜反射是造成瞳孔轮廓改变的主要因素,是影响瞳孔中心定位精度的主要因素之一.针对角膜反射对瞳孔边缘的影响,提出一种基于径向距离的瞳孔边缘专用滤波算法(RDPEF算法),提高了瞳孔定位的精度.(2)瞳孔运动造成差分图像瞳孔区域不全是造成运动瞳孔定位误差的主要因素,通过迭代扩展的方式还原运动瞳孔区域,提高了运动瞳孔定位的精度.(3)角膜反射区域形状的不规则和边界的不确定性是造成角膜反射区域定位误差的主要因素,通过多阈值分割角膜反射的模糊区域,减小了模糊的边界区域对质心结果的影响.(4)建立了一个多特征参数提取的流程,提取人眼特征的多个参数,为下一步的视线估计提供了参数依据.本文提出的检测方法优于通常采用的阈值分割方法,实验结果及系统实际应用证明了本文方法的有效性.下面介绍该方法的整个流程和关键步骤.本文方法整个流程如图5所示.首先,亮瞳(图6(a))与暗瞳图像(图6(b))相减得到差分图像(图6(c)),对差分图像做滤波,得到瞳孔区域.检测瞳孔区域的边缘(图7(a))并在眼睛区域附近基于灰度搜索角膜反射(图7(b)).求质心定位角膜反射中心(图7(e)),并对瞳孔边缘做滤波消除角膜反射对瞳孔边缘轮廓的影响(图7(c)),椭圆拟合定位瞳孔中心,得到亚像素的中心坐标(图7(e)).最后提取的视线特征向量犔t(图7(f))如下:其中(Δx,Δy)=pipjp-picjc为瞳孔中心到角膜反射的向量,amajoraminor圆长轴与垂直方向的角度,(ip,jp)为瞳孔中心在图像中的位置,(ic,jc)为角膜反射在图像中的位置.使用者1的部分数据见表1.(4.870,11.207,1.213,117.552,287.637,437.932)(88,86)(-0.880,11.357,1.058,65.256,231.91,443.770)(726,34)(-6.269,10.866,1.139,54.755,185.966,453.136)(1216,75)(5.159,7.824,1.057,147.106,213.819,459.712)(42,469)(-0.901,7.718,1.066,12.618,199.004,467.304)(707,387)(-7.231,7.710,1.142,42.529,177.404,471.379)(1205,384)(5.063,3.783,1.182,256.705,208.628,475.365)(26,860)(-0.979,3.287,1.140,3.635,196.633,477.365)(581,800)(-6.922,3.617,1.104,13.373,173.485,485.351)(1201,874)3.2.1瞳孔运动补偿提取差分图像眼睛区域的边缘之前,要消除瞳孔运动对差分图像瞳孔区域的影响.瞳孔运动造成亮暗瞳图像瞳孔区域不完全重合,以至差分图像瞳孔区域不完全是造成运动瞳孔定位误差的主要因素,本步骤通过迭代扩展的方式还原运动瞳孔区域,规则如下:Page6mapG=BLOBdomapG=mapG∪{pdij|(Ppq)(Ppq∈mapG∧pdijuntilmapGconvergence.对滤波后的瞳孔区域BLOB进行扩展,在与BLOB边界相邻的像素中,迭代搜索暗瞳像素灰度pdij小于暗瞳灰度阈值thres1的像素并将其加入扩展后的瞳孔区域mapG,直至mapG收敛.3.2.2质心定位角膜反射中心求解求角膜反射中心的方法一般有两种:一种是先求角膜反射的轮廓,然后对角膜反射边缘进行椭圆拟合,通过拟合椭圆的中心估计角膜反射中心[17];另一种是通过质心来估计角膜反射中心.文献[8]在差分阈值化后的二值图像中求角膜反射区域的质心,并且通过500个样本比较了两种方法的效果,结果是两种方法精度相当.由于角膜反射区域边界的不确定性,图像二值化时采用的阈值对最后的角膜反射中心估计结果有较大影响.本文通过以下两种方法来减小角膜反射中心的估计误差:(1)采用多个阈值分别分割出多个角膜反射区域,对各个区域分别求质心后的平均结果作为角膜反射中心.(2)分割出多个角膜反射区域后,不在二值图像中而在暗瞳图像中求质心,因为角膜反射中心是角膜反射区域中最亮的部分,越往边界亮度越低,这样可以减小模糊的边界区域对质心结果的影响.具体方法如下:首先,采用多个阈值分别分割出多个角膜反射区域:k=1k=1然后,对各个区域分别求质心,将各个区域质心ickK=∑KjckK=∑K的平均值作为角膜反射中心:ic=∑Kjc=∑K式中,(ick,jck)分别为区域blobpurk的质心,(ic,jc)为最后估计的角膜反射质心,如图7(e)所示.3.2.3边缘滤波角膜反射是造成瞳孔轮廓改变的主要因素,是影响瞳孔中心定位精度的主要因素之一.文献[32]通过迭代逼近的方法定位瞳孔中心,可以在部分情况下减小角膜反射对瞳孔椭圆拟合的影响,但是该方法存在以下几点问题:(1)当角膜反射在瞳孔内部而不与瞳孔轮廓相交的情况下会造成错误滤波,造成瞳孔中心定位错误.(2)有些使用者的角膜反射较大,而瞳孔较小,这种情况下该滤波算法不能有效地消除角膜反射产生的边缘.(3)迭代方法效率较低,增加处理时间.为了有效消除角膜反射对瞳孔椭圆拟合的影响,首先判断角膜反射与瞳孔椭圆的相对位置,当角膜反射与瞳孔椭圆相离时,角膜反射对瞳孔轮廓无影响,不需要进行滤波,当角膜反射与瞳孔椭圆相交或包含时,角膜反射改变瞳孔轮廓,需要进行滤波.理想的实心椭圆区域是一个有界严凸集,其边界是一个具有严格凸性的全局闭凸曲线,即使由于采样误差和离散误差,图像中瞳孔的边界也应该是一个全局闭凸曲线,正是由于角膜反射的存在,对瞳孔边界产生了较大的影响.本文通过对瞳孔边界求凸壳来还原瞳孔区域,用还原后的瞳孔区域去判断与角膜反射的位置关系.本文采用一种简单快速的凸壳检测算法,其时间复杂度为1logN[33].在此基础上,本文提出一种基于径向距离的瞳孔边缘专用滤波算法(RDPEF算法).规则如下:mapK{=pij|pij∈mapH∧(ppq)ifconvexhull(mapH)∩blobpurK≠elsemapK=mapH.首先,判断通过凸壳算法还原后的瞳孔区域convexhull(mapH)与角膜反射区域blobpurK的位置关系,当角膜反射与瞳孔椭圆相离时不进行滤波,当角膜反射与瞳孔椭圆相交或包含时进行滤波.在瞳孔边缘mapH中,以角膜反射中心picjc为圆心,在每一个半径方向上,如果存在两点pij和ppq,pij到角膜反射中心picjc的直线的斜率j-jci-icppq到角膜反射中心picjc的直线的斜率q-jc即pij和ppq在同一半径方向上,远端边缘点为瞳孔形成的边缘,近端边缘点为角膜反射形成的边缘,过滤掉角膜反射形成的边缘后的眼睛区域边缘如图7(c)所示.RDPEF算法示意图如图8所示.3.3眼睛跟踪以上的参数提取过程在相邻两帧中完成,可以在接下来的视频序列中重复进行以上参数提取过程,得到实时的视线参数.但是这样做有下面两点问Page7题:(1)每次在整幅图像中搜索瞳孔,效率低,时间长,影响系统的实时性.(2)由于没有使用瞳孔的历史信息,使瞳孔定位的鲁棒性差,对外部光照、眼睛角度、眨眼等情况的适应性差,不能满足系统的鲁棒性要求.所以在初始帧中对瞳孔进行定位以后,需要在接下来的视频序列中对瞳孔进行跟踪.Ebisawa和Satoh[26]利用亮暗瞳现象跟踪瞳孔,其后,卡尔曼滤波[31]、均值漂移[34]、组合卡尔曼滤波与均值漂移[35],相继被用于瞳孔跟踪.这些方法依赖于瞳孔的外观,跟踪效果仍然受外部光照、眼睛角度等条件的影响,对于眨眼的跟踪效果较差[36].瞳孔运动具有以下特点:(1)由于头部运动和眼球运动的随机性,瞳孔运动属于非线性、非高斯问题.(2)由于眨眼和闭眼的存在,瞳孔目标存在固有的遮挡和消失问题.由于以上原因,卡尔曼滤波与均值漂移不能很好地跟踪瞳孔.粒子滤波是处理非线性、非高斯问题的有效工具,可以处理由于眨眼和闭眼造成的瞳孔目标遮挡和消失问题.文献[20]采用粒子滤波对虹膜进行跟踪,文献[37]采用粒子滤波对瞳孔进行跟踪.但是这些粒子滤波跟踪方法没有考虑瞳孔目标的形状特点,瞳孔目标区域是椭圆的,通常的矩形目标模型不能有效区分瞳孔前后景.用于实时视线追踪系统的瞳孔跟踪需要满足以下几点要求:(1)由于采用的是灰度图像,所以必须充分利用亮瞳和暗瞳两个通道的图像信息,以增加跟踪的鲁棒性.(2)由于瞳孔尺寸较小,所以必须选择一种能充分区分前景和背景的目标模型,以减小背景对目标模型的干扰.为满足上述要求,并针对现有瞳孔跟踪方法的不足,本文提出一种基于伪彩色图的粒子滤波瞳孔跟踪算法,解决了视线追踪系统中红外图像瞳孔跟踪鲁棒性差的问题.工作主要体现在以下几个方面:(1)利用亮暗瞳现象,提出三通道伪彩色图(TCPCM)的概念,并将其引入瞳孔跟踪过程,TCPCM充分利用了各通道信息,瞳孔特征明显,瞳孔区域的色彩明显与人脸其它部位不同,提高了跟踪的稳定性与精确性.(2)建立一种符合瞳孔形态特征和变化规律的瞳孔目标模型,充分区分前景和背景,减小了背景对目标模型的干扰.下面介绍该方法的整个流程和关键步骤.跟踪方法框架如图9所示.本文提出基于三通道伪彩色图(Triple-ChannelPseudo-ColorMap,TCPCM)的瞳孔跟踪,TCPCM定义如下:TCPCM={pij|p1ij=pbij∧p2ij=pdij∧p3ij=blobij},式中,p1ij,p2ij,p3ij分别为TCPCM的3个通道上的像素点,pbij为亮瞳图像的像素点,pbij为暗瞳图像的像素点,blobij为差分图像滤波后瞳孔图像的像素点.TCPCM为三通道伪彩色图,如图10所示.红外图像中,瞳孔的灰度与脸部其它区域比较接近,特征不明显,区分度较低.TCPCM充分利用了各通道信息,瞳孔特征较明显,瞳孔区域的色彩明显与人脸其它部位不同,提高了跟踪的稳定性与精确性.Page8特征参数提取成功时,记录目标模型.本文根据瞳孔的形态特征和运动特征,提出一种用于跟踪的瞳孔模型.瞳孔状态X由9个状态变量描述:Xt=(cx,cy,amajor,aminor,θ,vx,vy,a·,θ·),式中,cx,cy为瞳孔椭圆的中心,amajor,aminor为瞳孔椭圆的长轴与短轴,θ为瞳孔椭圆长轴与垂直方向的角度,vx,vy为瞳孔椭圆分别在x和y方向的运动速度,a·为瞳孔椭圆尺度的变化率,θ·为瞳孔椭圆方向θ的变化率.记录目标时,cx,cy,amajor,aminor,θ已经在特征参数提取环节中得到,vx,vy,a·,θ·初始设置为零.瞳孔初始状态如图11所示.计算目标区域X的加权直方图时采用d(x)=xx-cxamaj()or线距离”,作为衡量瞳孔像素点重要性加权的依据,d(x)越小,像素权值越大.d(x)相同的点构成一条椭圆曲线,该曲线上的点具有相同的灰度值.瞳孔椭圆轮廓线的d(x)等于1,向瞳孔中心点方向d(x)逐渐减小,直至d(x)等于0时,等灰度线为瞳孔椭圆中心点.4视线估计4.1基于二维映射模型的视线估计方法基于二维映射模型的视线估计方法,通过一个经过标定的视线映射函数来估计视线方向,映射函数的输入是从眼睛图像提取的一系列二维眼动特征,输出是视线注视点.二维映射模型不需要估计三维的视线方向,所以不需要使用立体视觉系统,不需要进行相机的标定,不需要进行光源和屏幕三维位置的标定,为低硬件配置条件下的视线估计提供了有效的解决方案.提取的二维眼动特征随视线而变化,使它们之间的关系可以由一个视线映射函数来表示.为了得到视线映射函数,需要对每个使用者进行在线标定.但是,二维眼动特征随着头部位置的变化而显著变化,因此,标定的视线映射函数对头部位置非常的敏感[22].因此,为了得到准确的注视点,使用者需要保持头部静止.如果使用者保持其头部固定,或通过支架限制其头部活动,眼睛注视点跟踪的结果可以达到非常高的精度.平均误差可以小于1°(对应在计算机屏幕上小于10mm).但是如果头部离开使用者标定时的位置,视线追踪系统的准确性将显著下降,文献[22]报告了详细的数据,数据显示,视线映射函数的准确性将严重降低.可以通过使用者局部手工重新标定解决这个问题[38],但是这给使用者带来许多麻烦.大部分的商业视线追踪系统[12-14,25]是建立在二维映射模型之上,大多可以容忍小的头部运动.例如,LC视线追踪系统[12]可以容忍少于2平方英寸的头部运动.ASL视线追踪系统[25]可以容忍约一平方英尺的头部运动.消除了对头部静止的限制,方法是结合了磁性头部跟踪器和带云台的相机.不过,如何处理头部运动的细节是不公开的.此外,结合了磁性头部跟踪器和带云台的相机的系统不仅是复杂的而且对普通用户是昂贵的.总括来说,现有的基于二维映射模型的视线追踪系统都存在两个共同的缺点:(1)用户在使用视线追踪系统前都需要进行个体标定,以确定视线落点与用户依赖参数的关系;(2)用户需要保持头部静止,无显著的头部运动.针对现有视线估计方法的不足,本文提出一种可适应自然头动的视线估计方法.在单相机单光源条件下实现了头动对视线参数影响的补偿,既不需要繁杂的系统标定,又实现了自然头动视线估计,并且简化用户标定为单点标定.4.2基于PCCR的视线估计方法射函数和头部位置补偿,如图12所示.采用非线性多项式模型对视线进行估计,用经过训练的SVR计算头部运动引起的全屏视线估计误差.用估计的误差对视线进行补偿.实现头部运动情况下的视线方向检测.采用个体差异模型对使用本文视线估计方法包括个体差异校准、视线映Page9者眼球个体差异进行估计,用经过标定的补偿系数校准个体差异引起的特征参数变化.用校准后的特征参数进行视线估计.实现不同使用者的视线方向检测.头部位置补偿模型采用离线建模,只需在建立模型时进行一次.首先在头部静止状态下,使用者盯视屏幕上的标定点,标定多项式模型对视线进行估计,然后在头部不同姿态下,盯视屏幕上的标定点,计算盯视点视线落点误差,用来训练SVR以计算头部运动引起的全屏视线估计误差.以后使用者使用系统时,用估计的误差对视线进行补偿,得到最终的视线估计结果.个体差异校准模型采用在线标定,只需在初次使用系统时进行一次.首先在头部标定位置下,使用者盯视屏幕上的标定点,标定其个体差异系数,然后使用者使用系统时,用标定的个体差异系数对视线特征参数进行校准,得到消除个体差异的特征参数.系统经一次标定后能够记忆使用者的个体差异参数,后续使用时可免于初始标定.(1)个体差异补偿.本文采用的视线特征向量犔t如下:为了补偿个体差异对视线估计的影响,本文经过大量实验总结出以下事实:(1)不同的使用者在同一位置注视同一点的情况下,眼球的方位是大致相同的,因此(Δx,Δy)的方向是大致相同的,其方向的差异是由于视线和眼球光轴夹角的个体差异造成的,如图13(a)所示,这个差异可以通过单点用户标定进行捕捉.(2)不同的使用者在同一位置注视同一点的情况下,(Δx,Δy)的长度差异往往大于方向的差异,其差异是由于角膜球面半径大小的个体差异造成的,这个差异也可以通过单点用户标定进行捕捉.如图13(b)所示,当角膜球面半径发生变化时,瞳孔中心P1发生线性变化,图像中的瞳孔中心p1也随之线性变化,而图像中的普尔钦斑g1不变.即角膜球面半径增加k倍,g1到p1的向量(Δx,Δy)长度随之增加k倍.(3)不同的使用者在同一位置注视同一点的情况下,amajoraminor相同的.本文提出一种视线特征向量个体差异校准方法,通过单点标定确定使用者的角膜半径比例系数k和视线偏角λ,校准方法如下:式中,(Δx,Δy)为校准后的瞳孔中心到普尔钦斑向量.校准后的视线特征向量犔t为(Δx,Δy)=(Δx,Δy)×k(cosλ+isinλ),(2)多项式模型完整的视线映射函数(Gx,Gy)=F(Δx,Δy)是一个复杂的非线性函数,本步骤讨论的是使用者和头部位置固定情况下的视线映射函数(Gx,Gy)=f(Δx,Δy).在本文的系统配置下,其函数规律总结如下:Gx=fx(Δx,Δy)≈a1(Δy)+a2(Δy)Δx,a1(Δy)≈a3+a4Δy,a2(Δy)≈a5+a6Δy,Gy=fy(Δx,Δy)≈b1(Δx)+b2Δy+b3Δy2,b1(Δx)≈b4+b5Δx.可以看到,(Gx,Gy)=f(Δx,Δy)中有8个未知数,通过4个以上的标定点就可以确定其关系,为了覆盖屏幕落点的各个区域,本文通过9点标定对应的18个等式对8个未知数进行多项式回归.这个回归过程只在建立模型的时候进行一次,一旦8个未知数已经确定,以后不同使用者使用系统时,因为Page10已经经过上个步骤的个体差异校准,所以可以直接使用这个视线映射函数,无需重新进行回归过程.(3)头部位置补偿由于二维图像不能提取眼睛的精确空间位置,本文采用视线特征向量犔t反映眼睛的空间状态,通过SVR对由眼睛空间状态变化引起的视线估计误差进行回归,其表达式如下:(ΔGx,ΔGy)=fΔΔx,Δy,amajoraminor表2使用者2的部分数据(Δx,Δy)(4.870,11.207,1.213,117.552,287.637,437.932)(5.430,12.495)(88,86)(6,-18)(94,68)(-0.880,11.357,1.058,65.256,231.91,443.770)(-0.981,12.663)(726,34)(-51,24)(675,58)(-6.269,10.866,1.139,54.755,185.966,453.136)(-6.989,12.115)(1216,75)(-26,-7)(1190,68)(5.159,7.824,1.057,147.106,213.819,459.712)(5.752,8.723)(42,469)(53,6)(95,475)(-0.901,7.718,1.066,12.618,199.004,467.304)(-1.004,8.605)(707,387)(-50,47)(657,434)(-7.231,7.710,1.142,42.529,177.404,471.379)(-8.062,8.596)(1205,384)(-23,80)(1182,464)(5.063,3.783,1.182,256.705,208.628,475.365)(5.645,4.218)(26,860)(53,30)(79,890)(-0.979,3.287,1.140,3.635,196.633,477.365)(-1.091,3.665)(581,800)(42,96)(623,896)(-6.922,3.617,1.104,13.373,173.485,485.351)(-7.718,4.033)(1201,874)(-15,18)(1186,892)5实验结果通过一系列实验来说明本文方法的效果,包括参数提取与视线估计两部分.5.1不同头部位置的参数提取由于特征提取是视线追踪系统的共性问题,要求在不同的头部位置都能有效地进行,为了验证本文特征提取方法的效果,本文对150使用者进行了实验,实验过程在室内进行,不同使用者测试的环境不相同,包括白天晚上、晴天阴天、室内照明灯开关等各种室内光线情况,图14为使用者1,2,4在各种头部位置的检测结果,可以看到,即使在头部转动明显的情况下,本文方法也能有效地提取视线特征参数.5.2眨眼情况下的参数提取用于视线追踪的眼睛跟踪,要求在眨眼的情况下也能有效地跟踪,图15为使用者1,2,3在眨眼情况下的跟踪结果,可以看到,在眨眼的情况下,本文方法也能有效地跟踪眼睛.5.3佩戴眼镜情况下的参数提取用于视线追踪的眼睛参数提取,要求在使用者佩戴眼镜的情况下也能有效地进行,图16为使用者1,5,4在佩戴眼镜的情况下的检测结果,可以看到,即使在镜片反光情况下,只要反光不遮盖瞳孔,本文方法就能有效地提取视线特征参数.本文采用5个不同距离,每个距离上9个头部位置,在每个位置上注视屏幕上的9个点的方式,对视线估计误差函数fΔ进行回归训练.这个训练过程只在建立模型的时候进行一次,以后不同使用者使用系统时,因为已经经过个体差异校准,所以可以直接使用fΔ对头部位置引起的误差进行补偿,无需重新进行训练过程.头部位置补偿公式如下:Page115.4与其它眼睛跟踪方法的比较对用于视线追踪系统的眼睛跟踪方法进行了对比.图17给出使用者8眼睛跟踪结果中心点与目标真实中心点之间的均方根误差(RootofMeanSquareError,RMSE),其中,真实位置采用手工逐帧标定.由图17可见,(a)最初,3种算法都能正确跟踪目标;(b)随着跟踪进行,文献[33,37]方法虽仍能跟踪目标一段时间,但结果已明显不再准确,5.5不同使用者的视线估计结果本文对不同使用者的视线估计效果进行了实验,部分结果见表3,水平方向平均精度1.5左右,竖直方向平均精度1.9左右.图18为使用者3的视线估计结果.表3不同使用者的视线估计结果基于本文视线追踪方法的人机交互系统界面如5.6人机交互系统图19所示,实验中准确率在95%以上.5.7与其他系统的比较与其它视线追踪系统比较结果见表4,可以看到,本文提出的方法是一种单相机单光源条件下的、单点用户标定、可以允许头部较大范围运动、高性价比的视线追踪解决方案.而本文方法在整个跟踪过程中,都能一直保持对眼睛的稳定跟踪能力;(c)相对于文献[33]中组合卡尔曼滤波与均值漂移的方法和文献[37]中的粒子滤波方法,本文提出的方法能更为准确和稳定地跟踪目标,其跟踪结果与目标真实位置的误差最小,完全能满足实时视线追踪对眼睛跟踪的精度要求.方法头部允许运动范围文献[23]<70mm0.8°多相机多光源单点文献[17]N/A,but>70mm0.6°文献[7]200mm文献[4]500mm文献[24]40mm文献[8]100mm本文300mm注1.文献[8]需要另外配置立体相机,用来标定相机、光源和屏幕的空间三维位置;注2.本文方法在头部运动小于50mm时,平均精度在1.0°左右.Page126结论与展望现有单相机单光源条件下的视线追踪系统存在以下几个问题:(1)精度不高.(2)头动受限.(3)标定复杂.本文提出一种单相机单光源条件下视线追踪的高性价比解决方案.首先利用亮瞳现象提出一种新的基于多通道图像的亚像素瞳孔定位算法,通过RDPEF滤波解决了角膜反射对瞳孔中心定位的影响.以此为基础结合改进的粒子滤波算法,提出一种针对实时视线追踪的TCPCM瞳孔跟踪算法,解决了近红外图像中瞳孔色彩不突出的问题.接下来针对PCCR技术存在的主要问题:限制使用者头部运动和个体标定问题,提出了一种单相机单光源条件下头部位置的补偿方法,并提出一种个体差异的转化模型,进而简化标定过程为单点标定.最后以此为基础提出一种新的视线估计方法,本方法允许使用者头部运动并且只需要单点标定.本文的视线追踪方法为具有普适应用价值的低成本视线追踪提供了有效的解决方案.本方法具有以下几个特点:(1)通过高质量的特征检测与跟踪,使视线估计精度达到了满足实时人机交互的水平.(2)在相机视野范围内,头部可以自由移动,头部移动不会带来视线估计精度的明显下降.(3)通过个体差异校准机制,实现了单相机单光源条件下的单点标定.在未来的研究中,建立单相机单光源条件下解析形式的精确头部位置补偿模型是一项重点工作.自然光照条件下的精确视线追踪也是今后研究的方向之一.
