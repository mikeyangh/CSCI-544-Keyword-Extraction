Page1基于页着色的多核处理器共享Cache动态分区张栌丹1)王锐1),2)刘轶1),2)钱德沛1),2)1)(北京航空航天大学计算机学院中德联合软件技术研究所北京100091)2)(北京航空航天大学计算机学院北京市网络技术重点实验室北京100091)摘要随着多核/众核成为处理器结构发展的主流,并行任务间共享地使用Cache而导致的冲突越来越成为性能提升的瓶颈.利用页着色可以实现对Cache的分区管理,减少共享Cache导致的冲突.页着色的原理是利用内存与Cache之间的组相联映射关系,通过控制分配固定区域的内存而达到分配固定区域Cache的目的,这一方面限制了任务能够请求的物理内存范围,另一方面调整程序使用的Cache空间需要做大量的内存拷贝,带来了不可忽视的开销.为了克服页着色的缺点,文中通过动态内存分配的方式,只对动态分配的页进行着色,在不修改内核和程序源码的前提下实现了动态Cache分区.文中提出的动态内存分配策略(CachePM)会根据运行时环境为任务分配内存,避免不同任务间共享Cache的冲突和同一任务内出现Cache的访问热点,通过合理划分程序运行时动态分配的内存达到Cache分区的目的.当任务的运行环境改变时,CachePM自适应地改变已经分配的堆中数据在物理内存中的布局,以实现Cache分区的动态调节.为进一步降低动态页着色的开销,作者采用了减少和延迟内存拷贝的策略.实验表明,该方法能够有效实现动态Cache分区,从而提高并行运行的任务的性能;同时由于动态内存分配策略避免了同一任务内出现Cache访问热点,单独运行的任务的性能也较在libc下运行有所提升.关键词Cache分区;动态页着色;动态内存分配1引言近年来,在一个芯片内集成多个处理器核已成为处理器发展的主要趋势.在这种多核处理器中,多种应用会同时运行,共享芯片内的Cache、片上网络、I/O通道等资源.多个同时运行的任务在访问共享资源时会相互干扰,可能导致资源不能被充分利用,而使任务性能下降.Cache是片内的主要共享资源之一,对Cache的使用效率直接影响应用程序的性能.例如,不同进程/线程访问不同的数据集合,可能导致共享Cache中的数据频繁换入/换出,这将降低Cache命中率,进而导致它们对内存带宽和总线带宽的争抢,使得系统性能下降.因此高效管理片上共享Cache资源是提高多核处理器系统性能的关键点之一.由于Cache对软件是不可见的,所以一些研究开始利用物理内存到Cache之间的组相联映射关系,通过操作系统的页着色来间接地实现Cache分区[1-2].页着色是利用存储器与Cache的组相联映射关系,把操作系统的页划分为多种颜色,同种颜色的内存页将会映射到相同的Cache区域中,而不同颜色的内存页对Cache的使用没有重叠.通过给应用程序分配特定颜色的页,使得操作系统可以控制应用访问的Cache区域.然而利用页着色来管理共享Cache有不可忽视的缺点[3].一方面,页着色限制了任务能够请求的物理内存范围,即限制了任务可以请求的页帧的数量.如果任务的物理内存不足,因为Cache分区大小的限制,即使还有可用的内存,也不能被分配给其它颜色的物理页,使应用性能下降.另一方面,调整任务Cache分区的大小是通过改变已经分配的页面颜色实现,需要将应用的数据拷贝到另一部分颜色集合的物理页上,涉及到大量的数据移动操作,如果频繁改变Cache分区会带来很大的开销,Cache分区所带来的性能提升将不足以抵消这一部分开销,因而利用页着色实现的Cache分区制约了Cache分区策略的灵活性.利用页着色修改内核以改变操作系统默认的内存管理方式来实现Cache分区可能反而会影响普通程序的性能,仅适应于研究目的.目前很多相关研究都是通过修改操作系统内核实现,文献[1]引入页着色,提供了一种在实际硬件上研究和验证Cache分区算法的方式,在验证时,需要在计算分区效果时把页着色的开销忽略掉.目前的软件Cache分区方法还不具备通用性.实现Cache动态分区的主要难点在于,如何不修改操作系统内核及应用程序源代码就能实现分区以及如何降低动态页着色带来的开销.应用程序在运行时分配的动态内存(堆)中的数据是造成共享Cache冲突的重要来源之一.目前通用的动态内存分配库(libc),主要关注的是分配器本身的性能,而忽略了动态分配的内存对任务Cache性能的影响.对单个任务来说,由于Cache的组相联映射,所分配的数据可能都被映射到Cache的一小部分区域,导致这个Cache区域成为热点,而别的区域没有被充分利用,因而大量的缓存扑空(CacheMiss)发生在这个热点Cache区域中.当多个任务共享Cache运行时,它们动态请求的内存可能被映射到相同的Cache区域中,也会导致冲突缓存扑空.因此,通过设计合理的动态内存分配策略,能够达到降低Cache冲突的目的.因此,本文通过动态内存分配的方式,只对动态分配的页进行着色,实现了动态Cache分区.只对运行时动态请求的内存进行着色能够缓解可分配的内存数量限制,并减少改变Cache分区时内存拷贝的开销.本文提出的动态内存分配策略(CachePM)会根据运行时环境为任务分配内存,避免不同任务间共享Cache的冲突和同一任务内出现Cache的访问热点,通过合理划分程序运行时动态分配的内存区域达到Cache分区的目的.当任务的运行环境改变时,CachePM自适应地改变已经分配的堆中数据在物理内存中的布局,以实现Cache分区的动态调节.为了进一步降低动态页着色的开销,本文通过最小距离数据移动策略来减少内存拷贝次数,利用延迟数据移动的策略避免不必要的数据移动.实验表明,CachePM能够有效实现共享Cache的分区和动态调整,从而提高并行任务的性能;对单个任务由于使其数据分布到整个Cache区域,避免了局部Cache区域成为热点,提高了Cache利用率,单独运行时的性能也较在libc下运行有所提升.本文第2节介绍本文的相关工作和背景;第3节详细介绍动态内存分配策略,Cache分区动态调整策略以及降低重着色开销的策略;第4节通过实验评估CachePM对程序性能提升的效果;最后在第5节进行总结.2相关工作2.1页着色在组相联映射的Cache中,根据物理地址中间Page3的一些位确定映射到的Cache组,这些物理页号和Cache组号之间的公共位所代表的就是页面的颜色(图1).页着色利用页面的颜色来控制虚拟内存页到处理器Cache块的映射.通过控制分配给进程的物理页的颜色,就能够以页为粒度来控制进程的数据映射到Cache中的具体位置.页着色技术最早被用来保证程序的性能稳定性,文献[4-6]利用页着色提高单个程序的性能,近年来页着色技术开始被应用到Cache分区中[1-2].与页着色相关的是动态重着色,即为页面分配新的颜色.动态重着色可以改变进程在内存中的存储位置,进而改变进程访问的Cache区域,实现动态Cache分区.但是这一操作涉及到了内存拷贝(数据移动),其带来的开销不可忽视.2.2软件Cache分区软件Cache分区即利用页着色原理来降低共享Cache的冲突.张晓东等人[1]提出,尽管用页着色实现的动态Cache分区的开销不可忽略,但是软件Cache分区使得在实际机器上研究Cache分区策略成为可能,这比在模拟器上研究更有参考价值.ULCC[7]则是一个软件库,程序员可以利用ULCC提供的库函数来管理和优化对多核的共享Cache的使用.然而利用ULCC管理多核Cache一方面需要修改代码,对程序员提出了较高的要求,另一方面分区是静态的.Soft-OLP[8]则是一个对象级的Cache分区工具,它利用二进制插桩来计算对象的重用距离,并以此作为分区的依据.然而二进制插桩会使得程序变慢很多,Soft-OLP依然不具有通用性.文献[3]则针对页着色本身的缺点对软件Cache分区的实现进行了优化,当需要重着色时,他们通过遍历页表,来确定经常被访问的页,然后只对最常被访问的N个页进行重着色,这样能够减少重着色的开销.然而这也需要修改内核和页表项,且遍历页表的开销也不可忽视.因此他的重点是确定页的热度以及降低遍历页表的开销.与本文工作在实现方式上比较接近的是Swann的Ccontrol[9],Ccontrol提供了静态Cache分区的功能,但是不支持动态分区且需要用户指定分配Cache大小以及分配的内存的大小,这个软件本身没有包括任何分区策略.CachePM相对于Ccontrol的优势主要包括了:(1)CachePM支持自适应的动态分区;(2)Ccontrol需要预先为任务预留足够的内存,在运行时内存不够用也不能扩展内存,而CachePM不必事先预留,能够动态按需分配,这样资源利用率高,灵活性好;(3)CachePM分配的内存是与8字节对齐的,而Ccontrol分配的内存是4字节对齐的,8字节对齐能够提高读取数据的效率.与现有工作相比,本论文工作的特点在于,首先,在不修改内核和程序源码的前提下实现了动态Cache分区;其次,为了克服页着色的缺点,通过动态内存分配的方式,只对部分经常访问的页进行着色;再次,提出了降低动态重着色开销的策略,使得基于页着色的Cache分区更有实用价值.3运行时共享Cache管理CachePM主要包括了动态内存分配策略和Cache分区动态调整策略.首先,CachePM会根据运行时环境为任务分配内存,避免不同任务间共享Cache导致的冲突和同一任务内出现Cache的访问热点.在需要调整Cache分区时,自适应地改变已经分配的堆中数据在物理内存中的布局.为了不修改内核,我们首先通过可加载的内核模块将物理页按不同颜色来管理,并为用户态提供了实现动态页着色的接口.为了不修改程序源代码,我们利用LD_PRELOAD环境变量,改变程序的动态链接库,这样任务在动态请求内存的时候,就能够调用CachePM提供的内存分配函数(代替malloc等).本节详细介绍了CachePM动态内存分配和Cache分区动态调整策略以及降低重着色开销的策略.3.1运行时动态内存分配策略为了通过动态内存分配实现Cache分区,为不同的任务分配的物理页的颜色集合应该是不相交的;为了避免同一个任务内出现Cache访问热点区域,应该使分配的物理页分散到该任务的颜色集的所有可用颜色上;内存的分配还涉及到了线性地址的分配和管理策略,本节将详细介绍这些策略.3.1.1感知任务Cache敏感度的颜色选择策略CachePM为任务分配内存的时候,首先会确定可以为其分配的页面颜色的集合.当多个任务共享Cache运行的时候,分配给它们的物理页的颜色集Page4合应该是不相交的,这样才能保证在共享Cache中不同任务的数据不会互相干扰,本文采用的页面颜色选择策略基于对最后一级缓存扑空率随着Cache容量的变化而变化的曲线(MissRatioCurve,MRC)进行的观察.从图2的MRC曲线可以看到,当两个任务的Cache容量逐渐增加时,刚开始容量miss占总缓存扑空的大部分,因此缓存扑空不断下降,然而再继续增加容量对其影响不大.因此可以给对Cache大小敏感的任务分配较多的颜色,将剩下的颜色分配给对Cache大小不敏感的任务,使它们各取所需,互不干扰.MRC曲线miss率变化最大的点对应的Cache大小是应用的Cache大小最优配额.有的任务的MRC几乎不会随着Cache容量而变化,当对Cache容量变化敏感的任务与这类任务并行运行时,优先为Cache敏感的任务分配颜色,满足其最优Cache配额.图2所示的两个应用共享Cache时,设系统一共有64种颜色,则可以为mcf分配56种颜色,而把剩下的8种颜色都分配给gromacs.确定好每个任务可以使用的颜色数量之后,还需要进一步确定具体使用哪些颜色,选择颜色的时候需要考虑颜色的连续性,一方面是为了减少选择颜色的开销,另一方面,若所分配的颜色连续,则分配给应用的物理地址空间也可能是连续的.3.1.2线性地址的管理和分配策略CachePM为每个进程维护一个全局链表来管理空闲线性地址空间.每一个链表项所代表线性地址空间是连续的,低地址在前,高地址在后,每一个链表项的首地址存储了该线性地址空间的大小.当任务动态请求内存的时候,首先会调整请求的大小(加上元数据的开销),然后从全局链表中选择满足请求大小的线性地址区间并返回给任务,并更新该线性地址区间的大小(减去刚刚分配的大小),返回的线性地址需与8字节对齐.若在链表中没有找到足够大的区域以满足请求,则需要扩展全局线性地址链表.首先以页为单位扩展堆,然后将扩展的线性地址空间插入到全局链表中,由于堆是从高地址向低地址扩展,故新插入的线性地址一定是在链表的前面,这样保证了实际分配时能够很快找到合适大小的链表项.由于进程在分配内存的时候,往往会连续分配,因此扩展的堆的大小应大于请求大小,以满足接下来几次的分配.这样能减少接下来内存分配的时候扩展堆的开销,扩展的大小如果太小容易造成内存碎片,如果太大可能实际分配不到那么多内存而造成浪费.当任务释放内存的时候,会首先将这段线性地址空间重新插入到全局链表中,并根据这段线性地址头部记录的大小来更新链表,若这段地址空间与下一段或者上一段正好邻接,则将它们合并为一个链表项,并更新其大小为合并段的总大小.在程序结束时将全局链表的每个线性地址空间释放.3.1.3感知Cache的物理页的分配策略CachePM通过可加载的内核模块按照颜色管理物理页,在应用第一次访问malloc返回的线性地址时,会通过CachePM内核模块的缺页处理函数将线性地址与物理地址通过建立页表项关联起来.设由颜色选择策略为当前任务确定的可用颜色集为Scolor,在缺页处理函数选择物理页的时候则需要以颜色平衡作为原则,使分配的物理页分散到Scolor里的每种颜色上,且每种颜色的物理页数量基本一致.同时连续分配的物理页的颜色不能相同,因为局部性原理,在空间上连续的页往往在时间访问上也是连续的,若连续分配的页颜色相同,则很有可能导致Cache局部区域成为热点.3.2Cache分区动态调整策略当动态请求的内存通过CachePM分配好以后,任务的运行环境可能会发生变化(有新的任务到来或者有任务结束),我们通过动态重着色调整任务Cache分区的大小.在重着色的时候,首先需要根据并行运行的任务确定新的颜色集,颜色选择策略同3.1.1节,然后将数据从原来的物理页拷贝到新的颜色集的物理页中.若改变Cache分区的频率较低则按照3.1.3节的策略重新分配页帧,否则为了降低数据移动的开销,就要尽量减少数据移动次数以及推迟数据移动.Page53.2.1最小距离数据移动策略在内存颜色集需要改变时,仍然要保证新的颜色集中各个颜色的平衡,所以并不能随意将某个页的颜色改变.为了保证颜色平衡,我们首先确定每种目标颜色的物理页的数量(基本相等).为了减少数据移动的次数,我们通过维护一个current_map数组记录当前每个页面的颜色,计算每个页面的目标颜色并存储在数组target_map中.在物理页数量确定的着色方案中,target_map数组和current_map数组的距离(两个数组间的距离指两个数组不同项的个数)是最小的,伪代码如算法1所示.(1)懒惰页拷贝策略将数据移动推迟到当它被访问的时候,一方面能够防止内存分配成为性能瓶颈.另一方面,有的数据不会被再次访问,或实际访问的时候运行环境又发生了变化,因此移动这些数据是无意义的.若要将某个页的颜色从A改为B,则首先设置该页的目标颜色为B;然后清除该页的页表项;页表项被清除后,再次访问该页会发生缺页异常,在缺页处理例程中,将数据从原始物理页拷贝到颜色为B的物理页,并释放掉原物理页.算法1.最小距离数据移动.输入:current_map数组,物理页数n,目标颜色数cn输出:target_map数组1.//count[1…cn]记录移动后每种目标颜色的物理页数2.count[1…cn]=n/cn;count[1…n%cn]++3.Forifrom1tonDO//计算count数组4.c=current_map[i]//偏移为i的页当前的颜色5.IFcount[c]>0THEN//颜色c的可分配物理页6.target_map[i]=c;//保持当前物理页颜色不变7.count[c]--;//更新颜色c的可分配物理页数量8.ELSE//若颜色c的可分配物理页数量为09.循环选择可分配物理页数量大于0的颜色cnew10.target_map[i]=cnew;//更新当前物理页的颜色11.count[cnew]--;//更新可分配的物理页数量12.ENDIF13.ENDFOR确定好了target_map数组之后,若某一页的target_map与current_map的颜色不一致,则说明需要修改它的颜色.由于target_map到current_map的距离是最小的,故需要修改的页面颜色数量是最少的,即需要移动的页面数量最少.3.2.2数据移动延迟策略和懒惰刷新策略.为了推迟数据移动,本文采用懒惰页拷贝策略[1](2)懒惰刷新策略该策略作为懒惰页拷贝策略的增强.页表项被清零之后,Cache中仍然有原始页的缓存,在TLB(TranslationLookasideBuffer)中也仍然缓存着当前页表项在被清零之前的值.故需要对数据Cache和TLB进行刷新操作,而刷新操作必然导致com-pulsorymiss(强制缺失),因此需要尽量减少刷新次数.我们采取的是懒惰刷新策略,即确定target_map数组后,遍历target_map和current_map数组,若当前页的current_map的值不等于target_map的值,说明该页的颜色需要被改变,则清除该页的页表项值,直到所有页面被处理完之后再刷新Cache和TLB.然而,动态重着色的开销不可完全避免,因此不能太频繁地改变Cache分区,分区策略需在动态迁移带来的性能提高和迁移本身的开销之间权衡.4实验结果与分析实验测试平台为IntelCoreTM2DuoCPU,详细配置参数见表1.由于L2Cache的容量是6MB,页面大小是4KB,相联度为24路,则页面的颜色一共被分为了6144KB/(4KB×24)=64种,操作系统的内核是Linux2.6.32,采样工具为perf①.测试程序集为SPECCPU2006②,我们从中选择了12个测试程序.处理器核数双核页面大小4KB页面颜色数量64L1Cach容量32KBCache相联度8路L2Cach容量6MBCache相联度24路4.1程序的Cache访问特征分析CachePM提供了通过参数指定可用Cache大小的功能,因此可以利用CachePM得到程序的MRC曲线,进而分析程序的Cache访问特征.通过为每个测试程序递增地分配Cache大小,利用perf统计各次执行中的最后一级缓存扑空,得到它们的MRC曲线,通过分析MRC曲线可以将这些测试程序分为4类,分类结果如表2所示.A类,缓存扑空对Cache容量变化很敏感;B类,缓存扑空对Cache容量变化较敏感;①②Page6存扑空率一直较高;C类,缓存扑空对Cache容量变化不敏感,但缓D类,缓存扑空对Cache容量变化不敏感,且缓存扑空率一直很低.类型Abzip2、mcf、sphinx(sph)BH264ref(h264)、GemsFDTD(Gem)、libquantum(libq)Czeusmp(zeu)、bwaves(bwa)、lbm.SjengDgromacs、namd由于篇幅限制,这里只列出4个程序的MRC(图3~图6),它们分别属于4种不同的类型.4.2单个任务的Cache性能优化每次只运行一个任务,比较在默认的动态内存分配策略(libc)、CachePM提供的动态内存分配策略以及在Ccontrol下运行的程序性能.利用LD_PRELOAD环境变量,可以修改程序的动态链接库,首先在默认情况下,任务的动态链接库是libc,在此情况下运行一个任务,接着分别将动态链接库修改为CachePM和Control,并运行同一个程序,分别采样这3种策略下任务的运行时间,计算CachePM和Control下的运行时间较libc下运行时间的百分比,得到图7.图7单个程序的运行时间较默认情况的百分比可以发现在CachePM的管理下,单个任务的性能较默认的libc有所提高,总体上CachePM比Control的性能略高,而在Control下有几个测试程序的运行时间超过了默认情况的10%.主要原因一方面是因为字节对齐提高了数据读取效率;另一方面Control预留的空闲内存在运行时被划分成了很多不连续的空闲内存,在内存分配时寻找合适大小的空闲内存空间的开销较大.4.3并行任务的Cache性能优化在共享Cache的处理器上同时运行两个程序,由于共享Cache冲突,这两个程序的性能较单独运Page7行时都会受到影响.而CachePM会在两个任务运行时,根据Cache分区的决策进行内存分配.由于两个任务运行时间不同,静态分区会导致一个任务运行结束后,它所使用的Cache区域闲置,可能反而降低系统性能.而CachePM会在一个程序运行结束时,改变分区决策并据此调整还在运行的任务的内存布局,使得它能使用全部的Cache区域,从而提高系统性能.为了分析比较并行任务在默认情况下(不进行分区)和在CachePM实现Cache分区并动态调节Cache分区后的程序性能.我们在默认情况和CachePM下分别运行两个程序,计算其性能.设程序1、程序2单独运行的时间为分别为ts1,ts2,它们并行运行的时间分别为tp1,tp2,则系统性能定义为则理想情况下,两个任务运行时没有任何干扰的系统性能为1.0.我们从上述的12个测试程序中选出10个,其中9个来自类型A,B,C,有一个来自类型D,D类型的程序对别的程序几乎不会造成什么影响,自身也受Cache冲突的影响小,Cache分区提升其性能的程度也有限,所以本文只选择了一个D类程序作为示例.接着将这10个测试程序分为两组:组1={mcf,GemsFDTD,libquantum,lbm};组2={bzip2,mcf,sphinx,h264ref,GemsFDTD,libquantum,zeusmp,bwaves,lbm,gromacs};这样划分是因为组1中的程序攻击性较强,对别的程序性能影响较大,为了在较大的冲突下评估Cache分区的效果,我们每次从组1和组2中分别选择一个程序(选择的两个程序不相同),绑定到共享Cache的核上运行.图8~图11说明了两种策略下的系统性能.图8各程序与lbm组合运行的系统性能对比图9各程序与mcf组合运行的系统性能对比图10各程序与Gem组合运行的系统性能对比图11各程序与libq组合运行的系统性能对比图8~图11说明并行任务的性能较默认情况提升了,这也说明动态调整分区的代价被抵消了.总体来说,libq、lbm、Gems、mcf、sphinx对系统性能影响较大,且性能容易受冲突影响,性能都较低,h264ref、gromacs对系统性能的影响很小,系统性能最接近1,这与文献[10]得到的结论也是一致的.由于h264ref和gromacs对系统性能影响较小,故CachePM对其性能的提升程度也较小.值得注意的是,其中有两组数据的性能较默认情况有所下降,这两组数据分别是mcfvs.bzip和mcfvs.sphinx,主要Page8是因为mcf,bzip和sphinx都是A类任务,其缓存扑空对Cache的容量都非常敏感,两个A类任务并行运行时,由于Cache的总大小是有限的,Cache分区不能同时使它们使用的Cache大小满足需求,虽然分区使得任务间的冲突降低了,但是容量miss却大量增加,此时容量miss导致的性能损失大于了降低冲突miss带来的性能提升,因此分区策略需要在容量miss和冲突miss之间权衡.5结论现有的动态内存分配策略在多核环境中越来越显出不足,对应用的Cache性能造成了不可忽视的负面影响.本文通过设计适用于多核环境的动态内存分配策略,利用基于页着色的动态内存分配实现Cache分区,这种方式一方面比较灵活,只需要控制一部分数据的分布;另一方面,动态分配的数据往往是程序中被频繁访问的,因此同样能够达到降低共享Cache冲突的目的.更重要的是,在现有硬件平台上为页面重着色,有着不可忽视的数据移动的开销,所以只对部分频繁访问的页面进行着色更加有效.我们首先介绍了如何根据数据的Cache分布以及共享Cache运行的任务,为任务动态分配内存,实现Cache分区;接着讨论了,如何通过动态重着色改变数据的物理内存分布,以实现Cache分区的动态调整;同时还提出了降低重着色开销的策略.实验结果说明CachePM能通过动态Cache分区提高多核并行程序的性能;同时由于提高了程序的Cache利用率,也使单独运行的任务的性能有所提升.
