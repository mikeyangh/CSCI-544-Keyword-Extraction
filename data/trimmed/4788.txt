Page1SDaaS:一种传感流数据的服务化封装方法张仲妹1),2),3)刘晨2),3)苏申2),3)张守利1),2),3)韩燕波1),2),3)1)(天津大学计算机科学与技术学院天津300072)2)(北方工业大学大规模流数据集成与分析技术北京市重点实验室北京100144)3)(北方工业大学云计算研究中心北京100144)摘要来自不同传感器网络的流数据共享和集成对于带动相关业务和行业的创新具有重要意义.现有的传感网络往往是任务导向或领域专用的,仅适用于特定的应用场景,难以有效地在不同应用间共享和重用其数据资源.传感流数据的服务化是一种有效解决物理传感网络数据资源共享和重用的方法.针对已有服务化方法在应对大规模传感流数据共享和用户并发访问方面存在的局限性,该文提出了一种面向传感流数据的服务化封装方法———SDaaS(StreamDataasaService),该方法使用事件的方式驱动传感流数据的处理和传输,通过对传感数据的融合操作实现服务对传感流数据的深层次加工,并基于Pub/Sub机制实现传感流数据的按需分发.文中基于SparkStreaming实现对大规模流数据加工操作的封装,并通过对传统的基于匹配树的事件匹配算法进行改进实现了高效的流数据内容分发,以保障将传感数据实时的分发给相应需求.该文通过实验验证了流数据服务的性能,印证了流数据服务能够响应不同的数据需求,在毫秒级别将数据流分发给不同应用.关键词传感流数据;流数据服务;Pub/Sub机制;事件驱动;事件匹配;云计算1引言近年来,随着传感网络技术的不断发展,越来越多的传感器被部署到物理世界中并连接入网.据欧洲委员会预计,到2020年将有500~1000亿的传感设备连接到因特网上[1].传感设备能够持续产生大量的传感数据,进而帮助用户(人类或者机器)与其所处的环境互动,并对现实生活中的事件及时反应.这些传感数据具有实时到达、持续不间断、变化快等特征,是典型的流数据.来自不同传感器网络的流数据的共享和集成对于带动相关业务和行业的创新具有重要意义.然而现有的传感器网络一般是领域专用或者任务导向的,仅服务于特定的应用.因此在不同企业或组织之间共享传感流数据存在极大障碍.首先,数据提供者并不希望对外提供与隐私相关的数据,因此传感流数据不能直接交付给数据消费者.例如,对于交管局的车牌自动识别流数据(AutomaticNumberPlateRecognitionData,ANPR),实时导航可以利用车牌流数据做路况分析,但交管局并不希望暴露具体的车牌.其次,传感流数据规模一般比较大,数据消费者只关心其中很少的一部分,而不希望接受并处理一个大规模的数据流.因此更好的方案是按需的推送传感流数据.为了克服上述障碍,一些现有工作本着“数据即服务”[2]的思想,以服务化的方式来对外提供传感流数据.比如,一些传感器网络(如USTL[3],HomePort[4]等)以RESTful服务接口的形式对外提供传感数据,以实现方便的数据访问.为了使应用能够获取不同来源的传感流数据,一些研究团队建立了面向社区的流数据服务化平台(如微软的SenseWeb[5],GlobalSensorNetworks[6]及LiveWeb[7]),使得用户能够将不同来源的传感流数据组合起来以创建更具有价值的应用.然而,前者仅仅对外提供了获取数据的接口,并不考虑第三方对获取数据的需求;后者虽然允许编码流数据的处理逻辑,但往往采用集中处理的方式,且需要为不同种类的用户需求提供不同的服务接口.因此无法有效的处理大规模流数据,也就在保障用户并发访问方面具有一定的局限性.针对已有方法在流数据服务化方面存在的局限性,本文提出面向传感流数据的服务化封装方法———SDaaS(StreamDataasaService),以实现大规模传感流数据在服务化过程中的深层次数据加工和按需定制.具体的,本文主要贡献如下:(1)提出一个针对传感流数据的服务化封装方法,通过对流数据的融合操作实现传感流数据服务的深层次加工,通过Pub/Sub系统实现传感流数据的按需分发,并将该服务封装方法进行模型抽象,然后面向服务提供者和数据消费者抽象封装接口;(2)根据本文提出的服务封装方法,提出了一个可行的实现方案,该方案基于SparkStreaming实现了对流数据加工操作的封装,基于对传统匹配树算法的改进实现了高效的流数据内容分发,并进一步通过性能检验验证了本文提出的服务封装方法的可行性.2相关工作传感流数据的服务化是一种有效解决传感数据资源共享和重用的方法,能够依托互联网提供跨组织共享数据能力,保障数据获取时的安全性和私密性.服务需要依托流数据的实时处理来对原始的传感流数据进行加工转换,在流数据实时处理领域,文献[8-10]采用事件驱动的方式对数据进行抽象.本文采用类似的思路,将传感设备产生的数据记录视为传感事件.这样一个传感数据流可以视为一个传感事件流,多个传感事件流经过过滤、聚合和关联等加工之后可以生成具有更丰富语义的传感事件流.然后本文利用事件订阅系统来实现服务内容的分发过程,将经过加工处理的传感事件流按需分发给不同的订阅请求.2.1流数据服务化SenseWeb[5]允许应用在其提供的Web平台上共享和获取传感数据.GlobalSensorNetworks[6]提Page3供一个灵活的、能够动态集成和管理不同传感网络数据的中间件.文献[5-6]采用了轮询的方式在互联网上向用户提供数据.早期工作均采用集中式的方式实现对流数据的转换、查询能力.文献[11-13]采用了分布式的方式实现对流数据的处理.上述工作均采用传统的服务模型,需要创建不同服务来满足流数据共享的不同需求,对这些服务的管理势必会对整个系统造成巨大的负担.文献[14-15]提出了“WebofThing”的概念,将来自不同物联网中的数据在Web之上共享,并提供与其他Web服务进行组合(Mashup)的能力.文献[15]讨论了基于Web向用户主动推送消息的几种方式,由于其认为传感设备的采样频率很少超过1Hz,因此采用了WebHooks的推送方式.LiveWeb[7]提供了一个SensorWeb服务门户网站,允许用户随时对物理世界进行实时查询、监控,并提供离线通知功能.文献[15]和文献[7,16]分别采用了基于主题和基于内容的Pub/Sub机制实现流数据在不同的用户之间的共享,但不支持对流数据的转换融合以及用户的灵活按需获取,因此更适用于流数据产生速率较慢的情况.目前已有部分工作在其传感网络[3-4]或者基于传感流数据的具体应用[17-18]中采用了服务化的方式共享和获取传感数据.其中,文献[4,17]采用了服务器发送事件(ServerSendEvent,SSE)技术实现服务端主动推送数据.这些工作对外共享其传感数据或者处理传感数据的能力,但第三方应用在获取其传感流数据或者处理能力时需要根据需求对传感数据进一步处理或者对处理能力进行改进.2.2事件匹配方法文献[19]指出Pub/Sub机制由于其以数据为中心、多对多的通信模式、动态性及低耦合的特性,非常适用于基于传感网络的应用.然而目前在传感网络领域很少有工作涉及事件匹配算法.目前基于内容的Pub/Sub系统中事件匹配算法主要分为3类:基于树状结构的算法,基于谓词索引的算法,及基于分布式哈希表的算法.Gough等人[20]提出一种基于搜索树的匹配算法,但是当订阅请求增加或者取消时,该算法难以对搜索树进行修改.Aguilera等人在文献[21]中也通过对匹配树进行遍历来得到所有匹配成功的订阅请求,但是该算法中只能考虑部分重复的谓词.Silvia等人在文献[22]中提出了基于R-tree的匹配方法,将每个订阅请求视为一个范围,并根据订阅请求范围之间的关系,构建一个R-tree.文献[23-24]中同样使用了基于R-tree的匹配算法,主要基于订阅请求的位置约束来构建树.本文中的订阅请求结构较为复杂,订阅请求整体之间的关系难以表达,因此不适合采用R-tree的方法.文献[25]提出了基于谓词索引的内容匹配算法,为所有订阅请求包含的谓词建立一个保存谓词和订阅请求映射关系的表,在匹配时遍历这个表找出满足订阅请求的谓词数目,如果与其包含的谓词数目相同,则说明该订阅请求与事件相匹配.在订阅请求包含的谓词数目较少的情况下,文献[25]有较高的吞吐量和较低的时间延迟.文献[26-29]在谓词索引的基础上进行了改进,其中[28]通过判断事件属性间的重复关系、订阅请求之间的重复和包含关系减少不必要的匹配,能够较快的找到与事件相匹配的订阅请求.谓词索引方法避免了相同的谓词被多次验证,但是需要对所有的谓词进行验证.基于树状结构和谓词索引的算法大都基于这样的思想:对于所有订阅请求中的一些重复的部分,只需要判断一次,并充分利用索引结构来缩短匹配时间.基于分布式哈希表的算法将订阅请求和事件分布到不同的哈希区域中,事件仅和同一区域的订阅请求进行匹配.文献[30]利用哈希树将订阅请求分布到不同的bucket中,每个事件只需要对相应的bucket的订阅请求进行匹配.文献[31]将事件和订阅请求按照事件的属性值和订阅请求定义的范围分配到不同的分区中,对不同分区的订阅请求分别进行验证.基于分布式哈希表的匹配算法易于实现对大规模的订阅请求进行并行化匹配,可以与基于树状结构或基于谓词索引的算法相结合,更进一步的提高事件匹配的效率.2.3流数据实时处理早期的流数据管理系统(DataStreamManage-mentSystem,DSMS)采用集中式架构,包括Aurora[32],STREAM[33],TelegraphCQ[34]等.显然,一旦负责查询处理的节点资源出现饱和状态,查询处理的速度就会减慢,从而导致查询结果的输出时间延迟变长.近年来,分布式的流处理系统(DistributedStreamProcessingSystem),如S4[35],Storm①,SparkStreaming[36]成为主流.这些平台都采用分布式架构,处理能力能够随着节点数目的增长而得到扩展.S4是Yahoo开发的分布式、可扩展的、对等的流数①Storm,http://storm.apache.org/2012Page4据处理平台,处理节点间保持相对的独立性、对等性和高并发性,极大的提高系统性能.S4仅支持部分容错,当数据流速率超过一定界限时,数据处理的错误率会随着速率增加.Storm是Twitter支持开发的一款分布式、开源、实时、主从式的流数据计算系统,采用简单的编程模型,能够保证消息的快速计算,目前不支持数据负载的动态变化.SparkStreaming是Berkeley开源的通用分布式流数据处理平台,引用了微批次的概念,具有高容错性.SparkStreaming可以与Spark框架中的其他项目(如Spark、SparkR、MLlib等)无缝对接,能够减少单独编写流处理程序和历史数据处理程序.3SDaaS服务化封装方法为了方便进一步的细节描述,本节首先参考文献[37-39]给出SDaaS模型的基本定义,然后介绍流数据服务模型和服务化封装方法.3.1传感流数据相关概念和定义本文将传感流数据视为由部署在物理世界的传感设备或应用程序产生的、有时间属性的传感数据记录序列.定义1.传感流数据.传感流数据可以被表示为S={d1,d2,…,di,…},其中每一条数据记录都具有相同的属性集合{a1,a2,…,am}.di=〈vi1,vi2,…,vim〉表示传感流数据的一条数据记录,其中,vik表示属性ak在记录di中所对应的取值.图1给出了一个来自某出租车公司的真实GPS数据集片段.GPS数据流S的属性集合为{车id,检测时间,经度,维度,速率,方向,卫星个数},根据定义1,流数据中的数据记录可以表示为d1={18834,2015-04-0108:00:21,121.441895,31.206928,38.5,228.0,7},d2={27320,2015-04-0108:01:21,121.562235,传感流数据每条最新的数据记录都可以视为一个事件e,数据消费者可以通过提交订阅请求的方式获取符合其需求的事件.定义2.事件.事件由一组包含属性及其属性值的键值对组成,可以表示为其中:ai表示属性名;vi表示具体的属性值.传感流数据S的每条数据记录di=〈vi1,vi2,…,vim〉可以对应一个更新事件ei={〈ai1,vi1〉,〈ai2,vi2〉,…,〈aim,vim〉}.比如来自出租车公司的GPS传感流数据所产生的事件可以由{〈id,18834〉,〈longitude,121.441895〉,〈latitude,31.206928〉,〈direction,228.0〉,〈speed,38.50〉,〈siteNum,7〉,〈time,2015-04-0108:00:21〉}表示.定义3.事件约束.事件约束constraints表示事件e的值域,由其包含的属性可能存在的取值范围组成,可以表示为其中:ai是事件所包含的属性;属性约束cai表示属性ai所能取值的范围.如GPS传感流数据所产生的事件中的车速属性取值一定大于0,该事件中存在一个属性约束cspeed=(speed>0).显然一个事件流中所有事件的格式相同,因此一个事件流的事件约束即这个事件流中每个事件的约束.定义4.操作算子.对传感流数据的操作算子op可以表示为一个四元组:op=〈name,func,in_events,out_event〉,其中:集合;事件流.(1)name表示操作算子的名称;(2)func描述具体的操作逻辑;(3)in_events表示操作算子作用的事件流对象(4)out_event表示经过操作转换之后所生成的数据消费者可以通过提交订阅请求的方式来定义对传感流数据的内容需求.定义5.订阅请求.订阅请求r可以由k(k1)个谓词pi通过逻辑运算符“∧”或“∨”连接而成的合取或析取范式来表示,r可以等值演算为由有限个合取式所组成的析取式,记作:Page5如应用可以通过提交订阅请求:(〈speed,>,10〉∨〈speed,<,60〉)其中,谓词pij可以定义为一个三元组:其中:aij是属性名;关系运算符roij∈{<,,>,,=,≠};vij是对应属性aij的属性值,谓词的定义一定在事件约束的范围之内.r1=〈vid,=,京B34C91〉;r2=〈longitude,<,126.89〉∧〈longitude,>,116.29〉∧来获取相应的传感数据.其中,订阅请求r2可以转换为一个析取范式:r2=(〈longitude,<,126.89〉∧〈longitude,>,116.29〉∧〈speed,>,10〉)∨(〈longitude,<,126.89〉∧〈longitude,>,116.29〉∧〈speed,>,10〉).定义6.事件和订阅请求的匹配.给定事件e和订阅请求r,事件需要r中的所有谓词pi=〈ai,roi,vi〉∈r进行验证匹配,其中对于任意的谓词pi,当e包含键值对〈a,v〉,并且(a=ai)∧(vroivi)时,e与谓词pi相匹配,记作:将r所有谓词的匹配结果按照定义5进行逻辑计算,当计算结果为真时,事件与订阅请求相匹配,记作:例如,事件中的属性键值对〈speed,62〉与谓词〈speed,>,60〉相匹配,因为62>60;事件{〈id,18834〉,〈longitude,121.441895〉,〈latitude,31.206928〉,〈direction,228.0〉,〈speed,38.5〉,〈siteNum,7〉,〈time,2015-04-0108:00:21〉}与订阅请求r2相匹配.3.2流数据服务模型原始传感流数据除了安全性和私密性的问题,还存在着价值密度较低的问题.因此我们对原始的传感流数据进行转换、以服务的方式共享更具有价值的流数据.为了更好的为应用所重用,流数据服务能够响应不同订阅请求,仅向应用分发其所需的事件.本文借鉴前期数据服务模型[40]和基于内容的Pub/Sub机制,对流数据服务进行定义.流数据服务相当于部署在流数据源和业务应用系统之间的具有处理能力、可配置的“软传感器”,能够灵活响应不同的应用需求.定义7.流数据服务.一个流数据服务是一个传感流数据资源的统一抽象表示,从构成角度,一个流数据服务可以表示为一个多元组:sds={uri,in_events,ops,out_event,constraints,rs,disLogic},其中:(1)uri是服务创建者用来描述其流数据服务的唯一标示,服务消费者可以使用HTTP标准方法访问该uri来获取数据;(2)in_events表示服务所接入事件流,事件可以来自于原始传感流数据,也可以来自于其它的流数据服务;逻辑转换之后所形成的事件流;一组由操作算子组成的操作逻辑;(3)ops表示服务创建者定义在in_events上的(4)out_event表示in_events在经过ops操作(5)constraints表示out_event的事件约束,服务消费者定义在该服务上的订阅请求必须符合该约束条件;(6)rs表示定义在流数据服务之上的订阅请求;(7)disLogic分发逻辑决定流数据服务输出的事件向哪些数据消费者进行分发.在一个流数据服务中,in_events,ops,out_event元素面向服务创建者,constraints,rs元素面向服务消费者.流数据服务接入、输出,及通过操作算子所产生的中间事件都按照定义2所示的格式.流数据服务对数据转换融合的实时性要求较高,需要及时的输出新的流数据,在创建过程中选择以事件驱动的方式接入、转换、输出流数据.当接收到来自流数据源的数据后,主动将数据以事件的方式发送到相应的操作算子,最终得到输出结果.3.3服务化封装流数据的共享和重用问题可以映射为用户订阅请求和流数据服务所输出数据的适配问题.图2展示了传感流数据共享和重用的服务化封装的总体框架图.从体系结构上看,传感流数据的服务化封装主要由3个部分组成:服务代理、事件的分发逻辑以及Page6所有在服务代理上注册的流数据服务及用户的状态信息.服务代理负责管理流数据服务的创建和事件分发的整个过程,是传感流数据服务化封装中的核心.事件分发逻辑是把流数据服务产生的事件分发到事件目的地(用户)时所使用的策略.服务状态提供所有流数据服务的实时运行状态和服务元数据,以及与服务对应的用户订阅状态和元数据.基于图2所示的结构,图3展示了传感流数据服务化封装的实例.为了实现对传感流数据实时、按图3传感流数据服务化封装实例服务创建者通过在服务代理上创建并注册流数3.3.1流数据服务管理过程据服务的方式来共享和重用传感流数据.原始的传感流数据具有数据规模大,价值密度低的问题,服务创建者可以将其拥有的传感流数据根据需求配置相应的处理逻辑,将其转换为一个新的数据流,并根据输出事件流形成事件约束.与此同时,服务创建者还可以选择来自其它服务的流数据来创建流数据服务.如ANPR数据的拥有者可以将原始的ANPR数据进行聚集操作(count)将其转换为车流量数据TrafficFlow,创建流数据服务犵犲狀-犜狉犪犳犳犻犮犉犾狅狑.其中,ANPR数据中的一条数据记录可以表示为d1={CAM3913,京K36452,2015-04-0108:30:56},其产生的事件具有属性集{cid,vid,time}和事件约束constraints={〈cid=〉,〈vid=〉,〈time>2010/01/0100:00:00〉},表示ANPR数据的时间范围为2010年以后.Traffic-需的共享和重用,本文的服务化封装方法需要对流数据服务和订阅请求进行管理.其中,流数据服务管理允许数据提供者(服务创建者)对传感流数据源进行转换、融合,将新的、可公开的流数据以服务的方式公布给外界.订阅请求管理在流数据服务的基础上进一步支持数据消费者(服务消费者)按需的共享和重用流数据服务所提供的数据,流数据服务能够同时响应来自不同数据消费者的订阅请求.Flow数据的事件具有属性集合{cid,flow,time}和事件约束constraints={〈cid=〉,〈flow>0〉,〈time>2010/01/0100:00:00〉},表示车流量必须大于0,时间范围是2010年以后.相比较于ANPR数据,车流量数据更具有价值意义.又如服务创建者可以选择不同来源的GPS数据作为原始传感流数据,对其进行融合(merge)处理,转换为一个更完整的GPS数据流,创建流数据服务犻狀狋犲犌犘犛.原始的GPS数据(如图1所示)和转换后的GPS数据具有相同的属性集合和事件约束constraints={〈vid=〉,〈115.25<longitude<117.30〉,〈39.26<latitude<41.03〉,〈speed>0〉,〈time>2010/01/0100:00:00〉},表示GPS事件的属性值中,地理位置在北京市,速率必须大于0,时间范围在2010年以后.一般情况下,服务创建者还需要自定义操作或者算法,以对流数据源进行更复杂的数据处理或融合.如本文所在团队的其他工作[41]中实现对ANPRPage7数据的实时分析,将ANPR数据转换为一个包含伴随车组信息的流数据.对于车辆追踪、实时拼车等应用都更具有价值意义.在流数据服务创建过程中,对原始的传感流数据的处理逻辑是基于事件驱动的,不需事先将数据存储起来,因此流数据服务所接入和输出的数据是持续不断的.基于分布式流数据处理平台,流数据服务对原始流数据的处理具有高可用性和可伸缩性,能够满足流数据实时处理的需求[42].3.3.2订阅请求管理过程数据消费者可以通过向指定流数据服务提交订阅请求的方式获取传感数据.只要数据消费者的订阅请求符合服务输出的事件约束,数据消费者便可以获得其所需的数据,而无需创建专门的流数据服务或者自行处理原始的传感流数据.面对流数据服务所产生的持续不断的事件以及应用不同的订阅请求,流数据服务需要一个分发逻辑———即事件匹配方法,负责找到与当前事件相匹配的所有订阅请求,将事件分发给相应订阅请求.在图3的例子中,数据消费者想要获取指定需求的GPS车辆数据,首先找到流数据服务犻狀狋犲犌犘犛并得到订阅请求需要遵循的服务约束,即服务输出事件的事件约束constraints={〈vid=〉,〈115.25<longitude<117.30〉,〈39.26<latitude<41.03〉,〈speed>0〉,〈time>2010/01/0100:00:00〉}.遵循服务约束,数据消费者向流数据服务提交订阅请求;服务将按照分发逻辑将其产生的每个事件分发给相应的订阅请求.例如:假设数据消费者提交了订阅请求r2={〈longitude,>,130〉,〈latitude,>,32〉,〈speed,<,50〉}和r3={〈longitude,>,130〉,〈latitude,>,34〉,〈speed,>,55〉}来说,对于服务犻狀狋犲犌犘犛产生的事件e1={〈vid,京A57C23〉,〈longitude,134.2〉,〈latitude,36.41〉,〈speed,56.0〉}和e2={〈vid,京B34A12〉,〈longitude,151.4〉,〈latitude,34.06〉,〈speed,35.0〉}来说,事件e1仅发送到r3,事件e2仅发送到r2.高效的事件匹配算法是保证数据消费者能够实时获取所需数据的关键之一.一种简单的事件匹配方法是将事件与所有的订阅请求分别进行验证.这种方法的执行时间会随着订阅请求的增加而线性增长,并不适合于多流数据来源及多应用请求的场景.当订阅请求的数量较多时,组成订阅请求的各谓词之间可能存在着大量相等或者包含关系,本文中的分发逻辑通过考虑不同订阅请求之间的关系,来减少谓词匹配的数目,以提高事件匹配的效率.如订阅请求r2和r3中相同的谓词(longitude>130)仅需要匹配一次,具有包含关系的谓词(latitude>32与latitude>34),存在(e∝(latitude>32)→e∝(latitude>34))∨(e∝(latitude>34)→e∝(latitude>32)).在事件向数据消费者发送时,可以选择三种传输模式:轮询、长连接和主动连接方式.其中轮询模式属于被动拉取的模式,相当于传统数据服务的轮询方式实现;长连接和主动连接的方式属于主动推送的模式.长连接模式主要基于由客户端向服务器端建立的长连接:数据消费者通过建立一个长连接向流数据服务提交订阅请求,流数据服务在该长连接之上将符合订阅请求的事件持续的发送给数据消费者.主动连接传输模式更为灵活:数据消费者通过短连接向流数据服务提交或者取消其订阅请求;每当事件符合订阅请求时,流数据服务主动向相应数据消费者建起连接并发送数据.相比较而言,主动推送方式获取数据的效率更高.其中,长连接方式对于每个订阅请求都需要维护一个长连接,流数据服务支持的订阅请求数目受到系统本身的限制[43].主动连接方式不会出现连接资源浪费以及连接限制的情况,然而由于连接的重复建立,并不适用于数据发送频率较高的场景.由于本文目前侧重于支持大规模流数据的实时共享,因此暂时采用了基于长连接的传输方式,在后续研究中,我们将界定不同方式的适用范围,灵活选用传感数据的传输方式.4SDaaS实现4.1流数据融合操作本文当前实现的操作算子主要包含3类:针对单个流数据源的转换算子、基于滑动窗口的聚集算子以及针对多源流数据的融合算子.在当前实现中,针对接入的传感流数据源可能出现数据规模较大的情况,操作算子被映射为一个或多个SparkStreaming方法,利用SparkStreaming并行框架实现.表1展示了流数据服务的建模操作算子及其对应的部分SparkStreaming方法.(1)转换算子过滤.过滤操作可以仅输出符合相关条件的事件.过滤操作可以表示为Page8表1流数据服务的操作算子及对应SparkStreaming方法类型算子转换算子incrAggregatorreduceByWindow(fun(),wL,sI)聚集算子融合算子其中:a为事件所包含的属性;ro∈{<,>,=,≠,,}是关系运算符;v为具体的属性值.经过过滤操作转换所得的流数据与原始的流数据具有相同的属性集合.性及值映射新的数据流,可以表示为投影.投影操作可以选择输入流数据的若干属其中:A为从原始流数据中选择的属性集合;A为新指定的属性集合;M={〈a1,a1〉,〈a2,a2〉,…,〈ak,ak〉}是新旧属性集合的映射关系,V={〈ai,vi〉}在A中包含原始流数据属性集合以外的属性时指定相应的默认属性值.经过投影操作转换所得到的流数据具有新的属性集合A.排序.排序操作可以对指定窗口内的事件按照指定属性值进行排序,可以表示为其中:a为输入事件所包含的属性;o∈{asce,desc}用来指定排序的方式是降序还是升序;wL表示窗口大小;sI表示窗口的滑动距离.经过排序算子转换所得到的流数据与原始的流数据具有相同的属性集合.与过滤操作和投影操作不同的是排序操作属于阻塞式操作[44],对于单条数据记录做排序操作是毫无意义的.排序操作需要额外的指定wL和sI参数来指定操作的流数据输入范围和操作频率.本文中所使用的滑动窗口是基于元组的滑动窗口[45].(2)聚集算子聚集操作包含求和、计数、最小值、最大值以及平均数操作.与排序操作相同,聚集操作也属于阻塞式操作,需要指定wL及sI参数,针对指定窗口wL内的流数据记录进行操作.本文实现两类聚集操作aggregator和incrAggregator,其中:aggregator={sum,count,min,max,avg}仅对窗口内的数据进行操作,每次窗口数据改变时以新计算的结果代替上一次的计算结果.以最大值操作为例,最大值操作仅输出窗口内指定属性值最大的事件,可以表示为其中:a为输入事件所包含的属性;wL表示窗口大小;sI表示窗口的滑动距离.incrAggregator={incrSum,incrCount,incrMin,incrMax,incrAvg}为递增式的聚集操作,可以对多次的计算结果进行累加.同样以递增式最大值操作为例,当前窗口内指定属性值最大的事件会与上一次输出的事件相比较输出属性值较大的事件,可以表示为其中:a为输入事件所包含的属性;wL表示窗口大小;sI表示窗口的滑动距离.经过聚集算子转换所得到的流数据与原始的流数据具有相同的属性集合.(3)融合操作流数据服务可以利用融合操作对接入的多个传感流数据进行融合,输出更具有价值的流数据.为一个新的流数据,可以表示为合并.合并操作能够将两个同构的流数据合并其中,S所产生的事件和原始流数据产生的事件具有相同的属性集合,经过合并算子转换所得到的流数据与原始的流数据也具有相同的属性集合.连接.连接操作可以将两个描述同一对象或具有相同属性的传感数据连接为一个流数据,可以表示为其中:S与原始流数据描述同一个对象或者具有相同的属性a;wL表示窗口大小;sI表示窗口的滑动距离.连接操作能够对窗口内的两个流数据所产生的事件进行笛卡尔积连接,或者将具有相同属性值的事件进行连接.使用连接操作所转换得到的流数据包含的属性集合为{a1,a2,…,am}∪{a1,a2,…,an},其中,{a1,a2,…,an}和{a1,a2,…,am}为原始流数据的属性集合.目前的融合操作均为二元操作,流数据服务可以通过多个连续的融合操作,实现对多源流数据的融合.4.2事件订阅系统现有的事件匹配算法大都是将订阅请求组织为特定的数据结构,对其进行遍历,从而得到与事件相匹配的订阅请求.文献[20-21,46]中使用树状结构来对订阅请求集合进行预处理,增加事件的匹配效Page9率,这种结构被称为匹配树.本文使用了改进的匹配树来获取与事件相匹配的订阅请求,并实现了匹配树的并行化验证.4.2.1匹配树的数据结构匹配树中包含3种类型的节点:根节点、叶子节点和谓词节点,其中,根节点用虚拟节点表示;叶子节点代表一个订阅请求;谓词节点包含订阅请求中的一个谓词.定义8.匹配树.一个匹配树T可以由其根节点和多个索引结构来表示其中:t_r是一个虚拟节点,代表所有订阅请求的起点;索引结构PL用来表述树中不同谓词节点之间的相等或者包含关系,PL的数目与匹配树所对应的事件所包含的属性数目有关.匹配树具有以下性质:(1)给定事件e,对于匹配树中的任意谓词节点n,仅当e∝n.p时,访问n的所有子节点N,并对于谓词节点n∈N,验证e与n.p的匹配关系;(2)给定事件e,设匹配树中的所有叶子节点为N,NN是事件e对匹配树遍历验证时所访问到的所有叶子节点,则R=n1.r∪n2.r∪…∪nk.r,ni∈N,N∧1ik为所有与事件相匹配的订阅请求;(3)对于任意的订阅请求ri=pi1∧pi2∧…∧pin和rj=pj1∧pj2∧…∧pjn,令pi1∧pi2∧…∧pik和pj1∧pj2∧…∧pjk为ri和rj的前缀谓词,其中1kmin(n,m),如果(pi1=pj1)∧(pi2=pj2)∧…∧(pik=pjk),那么ri和rj的前k个谓词可以在匹配树上共用k个谓词节点.(4)对于任意的谓词节点,n∈PL可以根据n.p的验证结果推理获取部分谓词节点n∈PL的谓词匹配结果.下面通过介一个简单的匹配树实例来说明匹配树的性质.例如,假如存在3个订阅请求r1,r2和r3:其中:r1和r2包含相同的谓词p1;r2和r3包含相同的谓词p2;谓词p3和p4存在一个包含关系p3p4,这3个订阅请求组成的匹配树如图4所示.在图4中,对于事件e,仅在e∝p1时才需要对节点p2和p3进行访问和验证(性质1).对于订阅请求r1来说,路径:虚拟节点→p1→p2→r1代表了订阅请求r1=p1∧p2.当事件e对匹配树进行遍历验证时,访问到的所有叶子节点即为与事件e相匹配的订阅请求(性质2).订阅请求r1和r2共同拥有谓词p1,它们在匹配树中共用同一个谓词节点(性质3).传统匹配树只在不同订阅请求具有相同的前缀谓词时才能共享谓词节点,无法涵盖所有的谓词关系.如图4中订阅请求r2和r3包含同样的谓词p2,但它们无法共用同一个谓词节点.为了进一步减少谓词的验证次数,我们在匹配树中使用了多个索引结构来表述谓词节点的谓词之间关系,对匹配树进行优化.如图4中包含两个索引结构,其中,对于索引结构index1来说,两个谓词节点的匹配结果相同,对于索引结构index2来说,由于p3p4,因此(e∝p4→e∝p3)∧(e∝p3→e∝p4)(性质4).4.2.2匹配树创建根据定义5,本文将组成订阅请求ri的每一个简单合取式称为条件表达式cij,对于订阅请求ri来说,(e∝cij)→(e∝ri).定义在同一个流数据服务之上的订阅请求所包含的所有条件表达式可以转换为一颗匹配树.匹配树构建的步骤可以分为:(1)初始化匹配树及(2)依次向匹配树中添加新的条件表达式.在向匹配树添加新的条件表达式时,给定已有的匹配树T和条件表达式ci,对于任意的谓词pij∈ci,需要遍历T中所有谓词节点才能获取所有可能的谓词关系,这种方式复杂且不易于实现.因此,我们将谓词集合按照其所定义的属性名称和关系运算符来逐级建立多级索引,每一个最终索引项为事件所包含的属性,按照不同的关系运算符形成谓词列表PL.如图5所示,对于包含判定大小关系的运算符的谓词,在PL中按照谓词的包含关系进行排序,即对pi,pj∈PL,j<j→pipj.对于这一类PL,能Page10够得到(e∝pi→e∝{pj})∨(e∝pi→e∝{pk}),其中pj为排在pi后面的谓词,pk为排在pi前面的谓词.对于相等和不相等关系运算符,该PL实质上是一个Hash表,对于相等运算符的PL中的谓词来说,存在e∝pi→e∝{pj},其中,pj为除pi之外的谓词.对于不相等运算符的PL来说,存在e∝pi→e∝{pj},其中,pj为除pi之外的谓词.因此,对于事件e={〈a1,v1〉,〈a2,v2〉,…,〈am,vm〉}来说,每一个属性ai都可以定义一个多级索引结构来表述定义在该属性上不同谓词的关系.定义在e上的订阅请求所形成的匹配树可以由一个根节点以及m个多级索引结构组成.在匹配树中,如果能够事先知道每个谓词的出现概率,并根据概率来对谓词排序,可以增加不同的条件表达式共享谓词节点的可能性[47].然而,统计谓词出现的概率并进行排序需要复杂的处理过程,且谓词出现的概率会随着订阅请求的改变而改变.简化起见,本文中的谓词顺序使用字母排序,即对于任意条件表达式:c=〈a1,ro,v1〉∧〈a2,ro,v2〉∧…∧〈ak,ro,vk〉.其包含的属性{a1,a2,…,ak}存在a1a2…ak.图6展示了一个优化后的匹配树,由于匹配树对应的事件包含4个属性,匹配树中包含一个根节点以及4个多级索引结构.简单起见,图中并没有将所有的索引结构在图中画出.在匹配树中从根节点到任一叶子节点的路径上,对于任意的aiaj,ai一定出现在aj之前.将所有的条件表达式转换为匹配树的伪代码如算法1所示.算法1.匹配树创建算法.输入:条件表达式集合C输出:新的匹配树T1.过程create_Tree(C)2.INITT;3.FOREACHcinC4.addConInTree(T,c);5.RETURNT;6.过程addConToTree(T,c)7.qisthenumberofpredicatesinc;8.piisthei-thpredicateinc;9.n←T.root;i←1;10.IFnhasnochildTHENflag←FALSE;11.ELSEIF12.flag←TRUE;13.WHILEflagandiqDO14.FOREACHchildnodemofn15.IFm.value==pi16.THENn←m;i←i+1;BREAK;17.IFtherearenochildofnequalwithp118.THENflag←FALSE;19.IFflag==FALSE20.WHILEiqDO21.newnoden←pi;22.findPLfornandinsertn;23.n.addChild(n);24.n←n;25.newnoden←c;n.addChild(n);创建匹配树时,首先需要初始化匹配树(行2),然后向匹配树中依次添加新的条件表达式(行3,4).添加新的表达式时,我们首先判断原始的匹配树的根节点是否不含任何子节点(行10),如果不含任何子节点,则将条件表达式的每个谓词形成的谓词节点依次添加到树中(行19~24).如果根节点具有子节点,判断并找到匹配树中包含的条件表达式的前缀谓词,共享谓词节点(行12~18).然后向树中依次添加表达式中剩余的谓词(行19~24),在添加谓词节点时,需要根据谓词所包含的属性及关系运算符找到谓词所在的索引列表PL,并将其插入到PL中(行22).最后在树中添加一个代表该条件表达式Page11的叶子节点(行25).在创建匹配树时,每往匹配树中插入一个新的节点都需要查找并改变该节点所属的索引结构.假设事件包含的属性数目为m,需要对n个条件表达式创建匹配树.这里假设每个表达式所包含的谓词为2m,每个属性之上的谓词数目为2n.最好的情况下,每次插入请求时,插入谓词均包含其他谓词或者与其他谓词等价,匹配树的创建时间复杂度为2mn.最坏的情况下,每次插入一个谓词节点时,都需要与同层次的其他节点进行比较,此时的时间复杂度为2n×(n+(m-1)×n).创建匹配树的平均时间复杂度为O(mn2).空间复杂度方面,每个条件表达式的插入需要占用至少2m+1个节点,由于每个节点需要有链表的前后驱信息和树的父子信息,所以占用空间复杂度为O(mn).匹配树的生成算法允许订阅请求的动态增加.当新的订阅请求到来时,仅需要对其进行转换,然后对相应的条件表达式调用算法1中的过程addConToTree即可.当删除订阅条件时,可以通过对匹配树的局部节点进行删除,同时对相应的索引结构进行调整.4.2.3匹配树并行化验证对于可能出现的大规模的应用订阅请求,为了更好的保障应用获取传感流数据的时效性,在利用匹配树对事件进行匹配时,我们可以将匹配树划分为多个子树并对其行进并行化遍历.如图6中的匹配树可以划分为图7所示的子树.由图7可以看到,匹配树可以根据不同层次的子节点划分为不同的子树.由于构成匹配树的订阅请求数目及其所包含的谓词数目都不相同,匹配树划分的子树数目会受到每层节点数目的影响,无法动态的调节匹配树验证的并行度.而且每个子树包含的谓词数目也会出现倾斜的状况.因此我们可以先将匹配树划分成多个子树,然后将子树分配到不同的分块中重新组成一个子树,并行的对每个分块中的子树进行遍历.为了避免出现分块负载过重或者负载过小的情况,在对子树进行划分时需要尽量保证分块的均匀性.因此本文按照子树包含的谓词数目对其进行划分,尽量保证同一分块中子树包含谓词的总数目相近.本文将匹配树的划分转换为典型的整数划分问题[48]以进行求解,定义9给出了对匹配树进行划分的形式化定义.定义9.匹配树的划分策略.给定匹配树T,可以将其划分为子树集合犜,设分块数目为k,基于谓词数目的匹配树划分策略sp是一个分块函数sp(犜,k)={犜1,犜2,…,犜k},它满足:在本文中,我们先按照设置的并行度及匹配树中每层谓词节点的数目将匹配树划分为多个子树,所有子树包含的谓词数目便形成一个数组,其中每个子树中包含的谓词数目相当于数组中的一个元子树包含谓词的总数目.(1)犜=∪i=1…k犜i;(2)犜i∩犜j=,i,j=1…k∧i≠j;(3)min∑i,j=1…k整数划分问题就是如何把一个数组L分成k个子数组,使得每个子树组的元素之和大小尽量相等.如一个数组{3,1,1,2,2,1}可以分成两个子数组L1={3,1,1}和L2={2,2,1},显然这两个子数组满足定义9的所有要求.Page12素.如图7中,假设匹配树的并行度设置为2,按照第一层子节点的数目将匹配树划分为3个子树,这些子树的包含的谓词数目可以组成数组{12,4,7}.该数组可以分成两个子数组L1={12}和L2={4,7}.整数划分问题是一个NP难问题.本文采用了文献[48]给出的时间复杂度为O(kn2)的算法,该算法并不打乱原有数组元素的顺序,通过将数组顺序的进行划分得到一个次优解.它计算各种划分的可能情况的最小开销M[i][j]以及相应的数组划分的位置D[i][j].其中,M[i][j]表示将数组的前i个元素分成j个分块的最小开销,D[i][j]用来记录元素划分的位置信息.算法的详细信息可以见参考文献[48].利用匹配树的划分策略,我们对匹配树并行的进行遍历验证.匹配树并行化验证的伪代码如算法2所示:算法2.匹配树并行化验证算法.输入:匹配树T,事件e,并行度k输出:匹配成功的条件表达式集合C1.过程match(T,e)2.犜←T.childTree;3.犘犜←sp(犜,k);4.FOREACH犜iin犘犜5.execsub_match(犜i,e)inparallel;6.过程sub_match(犜,e)7.INITC;8.FOREACHTiin犜9.nistherootofTi;10.visit(T,n,e,R);11.RETURNC;12.过程visit(T,n,e,C)13.IFnisaleafnodeTHENC.add(n.value);14.ELSE15.IFn.resultisNULL16.verifyn.valueone;17.findPLfornandsetresultforrelativenodes;18.IFn.resultisTRUE19.FOREACHchildnofn20.visit(T,n,e,R);我们首先获取匹配树的所有子树(行2),并将子树集合按照定义6进行划分(行3).对于每一个分块我们并行的执行子匹配过程sub_match(行4,5).在每个子匹配过程中,对每个子树递归的进行遍历(行8~10),所有访问到的叶子节点为与事件相匹配的条件表达式(行7).当访问到谓词节点时,某些谓词节点在没有遍历到的情况下便已经通过索引结构得到了匹配结果,可以先查看该谓词节点是否已经存在匹配结果(行15).如果没有结果再对其进验证(行16),然后按照其匹配结果为所在索引上的相关节点进行赋值(行17).通过对匹配树进行遍历,我们可以获得更新事件相匹配的所有的条件表达式.通过条件表达式与订阅请求的关系,便可以得到与更新事件相匹配的所有订阅请求,并将更新事件发送到相应的订阅请求.在匹配树验证阶段,匹配树验证的时间复杂度与每次访问验证的谓词节点的数目相关.假设将匹配树平均划分为若干子树,根据整数划分原理每棵子树包含的节点数量尽可能相等.子树上的每个谓词节点的验证消耗包含访问和谓词验证两部分的时间消耗.对于任意子树中的第j层的第i个谓词节点nij,遍历的复杂度可以表示为其中:pk为从根节点到nij的路径上第k个谓词验证结果为真的概率;p为已知nij验证结果的概率;costvi为访问的时间消耗;costve为谓词验证的时间消耗.简单起见,我们假设条件表达式中仅包含等值谓词,设K是事件所包含的属性个数,V是每个属性可以取值范围,S是子树涉及的条件表达式集合,C(S)是事件与该子树进行验证的期望时间.利用上文介绍的整数划分原理将匹配树尽可能均匀的划分为若干子树.假设所有的事件是等可能发生的,且每个订阅请求与事件相匹配的概率是相同的.当并行地将大量事件与匹配树进行匹配时,订阅请求集合将均衡分布于各个子树,根据概率论可以得到每个事件将以相似的概率与子树中的订阅请求相匹配,从而保障并行化过程的负载均衡.的期望时间C(S)满足C(S)2(k+1)|S|1-λ(lnV+ln(K+1))×costvi+(k+1)|S+1|1-λ(lnV+ln(K+1))×costve(2)其中,λ··=lnV基于此并行化方式,匹配任意一个事件所消耗首先考虑访问的时间消耗.引理1.对于等概论出现的VK个事件,存在引理2.最多有Vη个节点满足证明.满足Cvi(S)=VK-η的节点只存在于第η层.根据匹配树的构建方式,最坏情况下第η层所Page13有节点都需要匹配.这种情况下,最多有Vη个节点满足Cvi(S)=VK-η.显然可得:易知,一个树最多含有(K+1)×|S|个节点.将一棵树的所有节点按照costvi(n)排序,设f(n)表示第n个节点的代价cost.根据Cvi(S)=∑costvi(n)有Cvi(S)=∑(K+1)×S设g(x)=(Ax+B)-λ,其中:f(j)表示第j个节点的访问次数,则有如下引理.引理3.f(x)g(x).证明.对于任意0iK,正整数j满足∑p=0,1,…,i-1∑p=0,1,…,i由于f(j)表示第j个节点的访问次数,且f(j)为V(K+1)-η的节点个数最多为(K+1)×[(K+1)×V]η,所以f(j)V(K+1)-i.根据等比数列求和公式:g∑p=0,1,…,ig(K+1)×[(K+1)×V]i+1-1根据g(x)定义(g∑p=0,1,…,i由于g(x)是非增函数:f(j)V(K+1)-i=(g∑p=0,1,…,i推论1.证明.Cvi(S)2(k+1)|S|1-λ(lnV+ln(K+1))×costvi.=V-K(A(K+1)|S|)1-λ-B1-λ=V(K+1)((V(K+1)|S|-|S|+1)1-λ-1)costvi由于(V(K+1)|S|-|S|+1)V(K+1)|S|,V(K+1)1-λ=(K+1),V2,K1,于是V×(K+1)V×(K+1)-14因此:Cvi(S)V(K+1)[(K+1)|S|1-λ-1][lnV+ln(K+1)]×costvi2(k+1)|S|1-λ(lnV+ln(K+1))×costvi.证毕.Cve(S)(k+1)|S+1|1-λ(lnV+ln(K+1))×costve.5实验与评价同理可得本节首先对SDaaS方法与现有流数据共享和重用的方法进行分析对比,然后从性能角度比较这几种方法在服务响应时间和系统负载方面的差别.5.1实验数据及环境本文实验使用真实的交通信息数据集及模拟数据集.近年来,本文所在团队搜集了来自市交管局的ANPR数据(S1)以及来自某出租车公司的GPS数据(S2).根据GPS数据集,我们模拟了GPS数据集,并将其划分为某公司的GPS数据集(S3)和多个私人的GPS数据(S4等).表2展示相应的交通数据集.名称ANPR(S1)cid,vid,timeGPS(S2)GPS(S2)GPS(S4)实验在拥有5个节点的集群上进行,所有节点均为装有CentOS-6.4的虚拟机,jdk版本为1.70.集群所使用的Spark版本为1.1.0,Hadoop版本为2.3.0.集群的详细信息见表3.其中主节点、工作节点1及工作节点2作为流数据服务实现的服务端;工作节点3用来模拟传感流数据源;工作节点4用来模拟应用的不同请求.Page14节点角色主节点IntelXeonE312xx66工作节点1IntelXeonE312xx66工作节点2IntelXeonE312xx33工作节点3IntelXeonE312xx33工作节点4IntelXeonE312xx335.2服务评价指标数据服务进行评价.延迟(ServiceLatency,SL)可被定义为本文参考文献[31]定义了以下几个指标,对流(1)服务延迟.流数据服务sds对用户i的平均其中:tij_in表示服务接入数据记录rij的时间;tij_rec表示用户i接收到数据记录rij的时间;n为用户i接收到的数据记录数目.服务延迟由两部分的时间延迟组成,分别为原始的流数据服务接入流数据服务到其输出新的流数据的时间延迟以及流数据服务输出流数据到应用获取到数据的时间延迟.(2)系统负载.系统负载指用户在调用流数据服务sds时的系统负载情况,主要分为CPU,内存以及网络的负载状况.(3)事件匹配率.给定流数据服务sds,假定m个用户同时对服务sds进行请求,其中,事件匹配率(EventMatchingRate,EMR)表示流数据服务单位时间内(s)能够处理的事件数目.5.3服务效果分析为了模拟传感流数据的共享和重用,我们选取了一天的ANPR数据和GPS数据并遵循其事件约束各自随机生成1000个不同的订阅请求.我们将具有相同属性的订阅请求视为一类数据需求,表4展示了订阅请求所包含的数据需求种类数目.我们按照数据记录的产生时间将其转换为流数据,然后使用不同的方式实现传感流数据的服务化.现有的传感流数据服务化方法主要有:采用传统服务模型的服务化方式(TS)[5]、基于主题的Pub/Sub机制(TB_P/S)[15]和基于内容的Pub/Sub机制(CB_P/S)[16]的服务化实现方式.表5展示了使用不同服务化方式封装服务的效果分析.服务化方式服务数目是否需要进一步处理数据DSaaSTB_P/SCB_P/S采用传统服务模型的服务化方式需要为每一类数据需求创建一个流数据服务,基于主题或者内容的Pub/Sub机制需要创建4个主题分别对应不同的传感流数据.相比较而言,SDaaS方法仅需要创建2个数据服务犵犲狋犃犖犘犚及犻狀狋犲犌犘犛便可以满足不同用户的订阅请求,其中,犻狀狋犲犌犘犛服务对原始的3个GPS数据进行了融合操作,输出一个完整的GPS数据流.对于基于主题的Pub/Sub机制,它会向任一个主题提交订阅请求的用户都会获取该主题上的所有数据,用户需要对其获取的数据进行处理才能够获取其需求的数据.虽然基于内容的Pub/Sub机制能够向用户发送其所需的数据,但对于对所有GPS数据都有需求的用户来说,仍需要对其获取的数据进行融合才能得到完整的数据.相比较而言,使用SDaaS方法用户无需对其获取的数据进行进一步的处理.为了验证SDaaS方法的效果,我们将其与采用传统服务模型的服务化方式进行比较,以检验SDaaS是否能够按需的将数据分发给不同订阅请求.我们首先将传感流数据的数据频率设为1000Hz,将用户的订阅请求数目设置为250,分别测试在订阅请求包含不同谓词数目情况下,服务端和用户端接收数据量的情况.实验表明在相同的订阅请求数目下,本文的SDaaS方法和采用传统服务模型的服务化方式能够接收到相同的数据.此外,由于用户定义在同一个服务上的订阅请求并不是完全独立的,通过对服务输出事件与订阅请求的匹配过程进行优化,我们可以进一步提高用户获取数据的时效性.在本文的实验环境下,当传感流数据的频率设置为10000Hz时,传统的服务方式在单个服务节点上仅能同时支持950个用户的订阅请求,而SDaaS方式可以支持2697个订阅请求,并且服务延迟保持在30ms以内.5.4服务性能评价5.4.1请求数目对服务性能的影响本节采用传统的服务化方式,基于主题及基于内Page15容的Pub/Sub方式作为基准,与本文方法(SDaaS)进行了对比.我们随机选择1000条订阅请求,分别利用4种服务化方式获取数据.对于Pub/Sub机制,定义在GPS数据上的订阅请求需要同时向3个GPS源提交请求.我们将流数据的频率设置为10000Hz,订阅请求的数目设置为100、200、400、600、800和1000,分别计算4种方式下的平均服务延迟和系统负载.图8(a)展示了服务响应时间的比较,可以看出基于主题的Pub/Sub机制具有最低的服务响应时间,这是因为基于主题的Pub/Sub机制并不对用户的订阅请求进行任何处理,直接将所有的数据转发给用户,因此具有最低的响应时间.图8(b)、(c)、(d)分别展示了订阅请求数目对系统负载的影响,其中由于TS,TB_P/S与DSaaS方式的网络负载相同,因此图8(d)中仅展示了DSaaS的变化曲线.由图8(b)、(c)可以看出基于传统服务模型的服务化图8订阅请求数目对流数据服务性能的影响5.4.2事件匹配算法对服务性能的影响本文中的事件匹配方法是保障流数据服务能够高效的将数据分发给不同应用的关键,本节对本文采用的事件匹配方法(ImprovedTree)与普通的匹配树(NormalTree)[21],谓词索引算法(PreIndex)[28]以及简单的事件匹配方法(BruteForce)进行比较.方法具有最高的内存和CPU负载,这是因为这种方式对于每一个订阅请求都要建立一个服务实例来进行相应的处理,每个服务处理之间是彼此独立的.由图8(d)可以看出,基于主题的Pub/Sub机制具有最高的网络负载.这是因为基于主题的Pub/Sub机制需要将所有的数据转发给用户,而其他方法可以仅向用户传输其所需要的数据,因此基于主题的Pub/Sub机制具有更高的网络负载,而且用户还需要对其获取的数据进行进一步的处理.基于内容的Pub/Sub机制和DSaaS方法具有较低的系统负载和较少的服务响应时间,其中由于DSaaS方法采用了更高效的事件匹配机制和分布式的数据处理框架,因此具有更高的效率和较低的系统负载.在1000个并发订阅请求的情况下,服务响应时间一直维持在20ms以内.实验说明SDaaS方法能够支持在多用户并发请求的情况下在毫秒级别内将数据发送给相应用户.为了能够应对大规模的应用并发的向流数据服务发起订阅请求,本文还实现了事件匹配方法的并行化,并与基于子匹配树数目均匀划分的策略进行比较.我们首先将流数据服务输出的流数据频率设置为10000Hz,订阅请求数目设为100,比较在订阅请求包含的谓词数目对不同事件匹配方法效率的影Page16响.然后将订阅请求包含的谓词数目设为6,比较不同数目的订阅请求对事件匹配算法效率的影响.最后我们将订阅请求的数目设置为1000,比较两种不同的并行化方式的事件匹配率.如图9(a)、(b)所示,当订阅请求数目或者订阅请求包含谓词数目较大时,BruteForce算法的效率最低,普通的匹配树和谓词索引分别在订阅请求数目较大和谓词数目较大时效率次低.本文采用的改进的匹配树的事件匹配算法由于采用了多级索引结构,利用谓词之间的关系减少了不必要的匹配使得该算法的效率在不同的谓词数目和不同的订阅请求数目下均具有较高的事件匹配率.如图9(c)所示,随着并行度的增加,两种并行化方式下的事件匹配率均得到提高,而基于谓词的划分策略具有更高的事件匹配率.这是因为不同的子匹配树所包含的谓词数目并不相同,简单的将所有的子匹配树均匀的划分不能保证每个分块中的事件匹配过程的均衡.然而,虽然相比较对子匹配树均匀的划分来说,本文的划分策略能够保证每个分块中包含近似数目的谓词,却仍不能保证分块中进行访问验证的谓词节点数目的均衡.在后期工作中我们会针对该问题对划分策略进行进一步的优化.6总结为了实现传感流数据在不同应用之间的共享和重用,本文提出了一种面向传感流数据的服务化建模方法SDaaS,能够在流数据源和应用系统之间部署可配置的流数据服务,并借鉴Pub/Sub机制实现传感流数据的按需分发.本文基于SparkStreaming实现了对流数据加工操作的封装,能够对原始流数据进行转换融合,以服务的方式公布给外界;由于借鉴基于内容的Pub/Sub系统,相比较于传统的服务模型,能够更好的实现流数据服务的重用,减少系统需要维护的服务数量;对传统匹配数算法进行了改进并实现了高效的流数据内容分发.实验验证了流数据服务能够实现对不同应用请求实时、按需的发送数据,相比于现有的服务化方法具有更高的时效性和更低的系统负载.
