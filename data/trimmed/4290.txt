Page1基于区域上下文感知的图像标注邱泽宇方全桑基韬徐常胜(中国科学院自动化研究所模式识别国家重点实验室北京100190)(中国-新加坡数学媒体研究院新加坡119615)摘要随着互联网的发展,网络图像指数般增长,图像理解技术变得日益重要.其中图像标注技术作为其关键技术得到广泛关注和研究.现有的图像标注技术大多是在图像层次上训练标签模型,忽略了图像区域之间的关系及其标签之间的关系.为了解决这个问题,文中提出了一种新的算法,结合区域之间的位置关系及其标签之间的共生关系辅助标注图像.具体而言,算法首先使用支持向量机对部分可确定区域赋予语义标签,然后利用区域位置关系帮助聚类标注未知区域.得到一幅图所有的区域标签后,我们提出两种模型对标签共生关系建模辅助修正标签集,一个是随机游走模型,另一个是条件随机场模型.最终算法输出每幅图像的文本标签集.在对图像集NUS-WIDE的标注实验中显示,上述方法和单纯考虑区域关系的方法相比,标注效果和性能有了较好的改善,证实该方法是一种稳定、有效的标注算法.关键词图像标注;上下文信息;随机游走;条件随机场1引言随着互联网的不断发展以及移动终端的兴起,网络中的图像数量呈现指数般的增长.根据TheNextWeb的记录,2009年,Flickr拥有40亿张图像,到2011年为止上升到了60亿.Facebook在2009年存有150亿张图像,两年的时间上升了450亿张.图像数据大规模的增长对图像理解处理技术提出了更多的要求.图像标注作为提供图像语义文本信息的关键技术,在诸如图像检索、存储、分类等方面有着广泛的应用价值[1].现实中的图像是多种多样的,每一张图像可以对应一个或者多个标签.现有的方法把图像标注视为图像到标签的映射过程,他们都是把标签与完整的图像进行对应.例如潜在语义模型[2-3],跨媒体关联模型[4]等等.为了更好地理解和分析图像,仅仅是图像层次的内容是不够的,更需要图像区域层次的信息.因此图像区域标注应运而生.例如对象概率模型[5]、周边纹理模型[6]、多目标学习模型[7]等都在区域层次的图像标注上取得了显著的效果.近年来,区域标注算法常常借助图像区域周边的信息辅助标注.根据视觉相似对应标签相似的原理,研究者结合不同的关联图像提出了相应的算法[8-9];根据区域的视觉相关和语义相关的原理,研究者利用不同的方式挖掘区域间联系辅助标注[10-12];根据区域的空间位置分布规律,研究者也提出了相应的算法辅助标注[13-14].但是图像区域标注无法完全替代图像标注,它的实际对象或区域相对独立,无法获取整体语义信息.因此有许多研究者把图像区域标注的算法引入图像标注工作中[15-16],图像区域标注算法中利用区域之间的位置关系能够很好地帮助理解图像层次的语义信息.但现有工作中很少同时考虑一个区域与多个区域之间空间位置分布关系的方法,更没有同时考虑语义标签之间的共生关系来帮助进行图像标注的工作.为了解决这个问题,本文提出了一种综合使用区域间相对位置关系及其标签共生关系辅助标注的算法———基于区域上下文感知的图像标注算法.算法先使用支持向量机分类并标注可确定类别的区域.对无法确定类别的未知区域,引用分类结果建立未知区域与周围确定区域的空间相对位置关系描述符,然后结合未知区域自身的图像特征信息进行聚类.为了获得未知区域的标签,需要在待标注的图像集中混入带有人工标签的已标注图像,由此聚类后通过标签传播的方式即可对未知区域进行标注.得到一幅图的所有候选标注集后,本文使用两种模型实现引入标签之间的共生关系辅助确定图像标注集.这两种模型分别是随机游走模型和条件随机场模型.随机游走模型引入标签共生信息使得标签之间的联系更加紧密.条件随机场模型结合标签概率和标签共生关系推断图像标注,使得图像标签整体分布更加合理.本文使用图像数据集NUS-WIDE[17]进行图像标注实验,结果表明本文提出的算法相较于其他算法,标注效果得到了显著的改善.通过对比发现使用条件随机场模型的效果要优于随机游走模型,这说明引入越多的标签共生信息,对图像标注的帮助越明显.2基于区域上下文感知的图像标注算法图像的标签可以是带有具体指向的标签,也可以是高层语义的标签,使用本文算法既能标注出具体对象或区域的标签,也能标记出高层语义信息的标签.在使用本文提出的算法进行图像标注之前需要对待标注图像集进行预处理.预处理包括在图像集中加入带有人工标签的已标注网络图像、图像分割、特征提取.此后使用基于区域上下文感知的图像标注算法标注图像集,就能得到每张图像对应的标签集.算法具体描述如下.算法1.基于区域上下文感知的图像标注算法.输入:未标注图像和带标签图像的混合区域集输出:所有图像对应的标签集1.使用支持向量机识别分类图像区域并标注.2.对未知区域建立上下文描述符,并结合图像视觉特3.引入标签共生信息对每幅图的标签集进行修正.2.1识别区域类别任何未标记的图像中都混杂着许许多多或复杂或简单的区域.通过识别和标注这些区域,可以得到图像内部信息甚至高层次的语义信息.为了标注这些区域,本文首先使用训练好的支持向量机对图像所有区域进行识别分类.理想情况下,图像分割能够准确地提取出一个图像中的各个区域,然后对各个区域进行分类标记,就能得到每个区域对应的标签.但实际情况下由于受到图像分割水平的限制,并不能得到完整的区域.因此,需要先对每幅图像进行多重分割,再将所有的分割都当作独立的区域进行处理,这样可以提升区Page3域识别的准确率.此外由于受分类器分类数目的限制,实际中不可能得到每个区域对应的标签.因此对于不属于分类器识别范围内的区域暂定为未知区域,在后续步骤中进行处理.本文首先使用一组训练集训练N个支持向量机分类器犆={c1,c2,…,cn}.分类时输入图像区域的视觉特征,输出为每个区域对应不同类别的概率,一个区域s对应一个分类ci的概率为P(ci|s).如果一个区域很有可能属于一个已知的类别,那么它对应的分类ci的概率P(ci|s)会很高,而对应其他类的概率会很低.而不属于任何已知类别的区域对应所有类别的概率会比较平均.因此,在得到所有区域的类别概率后,本文通过计算区域对应类别的不确定程度来判断该区域是否确定为某一类别.本文设计了一个熵函数E(式(1))来计算和衡量区域s的不确定程度,其中熵值越低的区域的确定性越大;反之,熵值越高的区域不确定性越大.熵值函数的值域为[0,log2N],本文把判定确定区域和未知区域的阈值简单地设为值域的中点.当熵值小于阈值时把该区域当作确定区域,当熵值高于该图1上下文描述符示意图本文算法没有单纯地把最大概率的类别作为表示区域的节点值,而是把每个区域对应所有类别的概率组成的概率直方图作为节点值,然后根据已知区域和未知区域的距离远近计算权重.具体来说对于每一个未知区域s,结合它邻近的已知区域的类别概率直方图构建上下文描述符,其中每个直方图表示区域s附近的某一个区域r对应每一个类别的概率分布.由于区域之间上下方向的相对位置关系比较固定,因此选择与区域s邻近的上下两个方向的已知区域作为邻近区域.连接所有的直方图{r=0,…,R}得到上下文描述符:其中H0(s)表示未知区域本身的概率直方图.已经确定的区域也有可能是错误分类的结果,但是相似的区域会产生相似的错误,所以用概率直阈值时把它视为未知区域.对于确定区域,使用对应的分类器类别标签对其进行标注.接下来对于未知区域进行处理.2.2聚类标记未知区域现实中的图像区域多种多样,仅仅依靠分类数量有限的分类器是难于满足标注需求的.对那些不属于分类器识别范围内的区域,本文引入带有人工标签的网络图像区域帮助标注其标签.在得到所有的未知区域后,通过聚类能得到一定数量的区域集合,在这些集合中含有许多带有标签的网络图像区域,然后利用标签传播的方式对未知区域进行标注.为了提高聚类精度,本文参考文献[18]引入了上下文描述符辅助聚类.上下文描述符是一种表现确定区域和未知区域之间位置关系的图像特征.算法通过构建以未知区域为中心的邻近确定区域的关系图作为描述未知区域的一种特征,如图1所示.在关系图中,节点表示区域,边表示的是已知区域和未知区域间的距离,它表现了未知区域和相邻区域之间的关系拓扑结构.根据这种结构,算法可以根据两个未知区域在对象层次上和周围区域的关系有多大的相似度来判断是否可以被分到同一个类别中.方图描述一个区域能够减小上一步分类错误带来的影响.最终构建的上下文描述符是一个((R+1)×2N)维的向量,其中R表示所选取的确定区域的数目,R值越大意味着引入的辅助区域越多.由于未知区域的相似程度和他们的上下文相似程度成正比,因此上下文描述符可以用于辅助聚类.得到未知区域的上下文描述符后,结合区域的视觉特征信息对其进行聚类可以得到相似区域的集合.为了计算两个区域之间的相似程度,本文引入一个结合区域视觉特征和上下文描述特征的相似度函数:K(sm,sn)=1其中sm和sn表示未知区域,g(sm)和g(sn)表示它们Page4对应的上下文描述符.au(sm)和au(sn)表示其视觉特征信息.Kχ2(·,·)表示两个直方图之间的χ2核函数,如式(4)所示.通过计算每一对未知区域之间的相似度,可以得到一个相似度矩阵,然后送入聚类算法中聚类.理想情况下,未知区域和其相似的未知区域能够分到同一个聚类集合中.Kχ2(x,y)=exp-1其中i表示直方图中区间的个数.在得到聚类子集后,算法利用预先混入图像集中的带有用户标注的网络图像帮助标注未知区域.由于网络图像是同待标记图像一起进行处理的,经过聚类后的区域集合中一定含有带标签的图像的区域.通过统计的方法确定集合的标签,然后把这些标签赋值给待标注的未知区域.2.3标签修正在得到一幅图像的确定区域和未知区域的标签集合后,把这些标签整合成一个图像标注向量狉=[p(a1),p(a2),…,p(an)],其中p(an)表示该图像被标注为标签an的概率.本文引入另一种上下文信息辅助进一步的标注,利用标签之间的共生关系对图像标注向量进行修正,最终确定图像的标注集.本文使用两种模型实现该步骤,它们分别是随机游走模型和条件随机场模型.2.3.1随机游走模型一幅图的标签集可以表示为一个带有N个结点的标签关联图,然后根据实际情况加强或减小标签之间的联系,改变标签概率,最终根据新的概率就能确定图像最终标签集合.一幅图像完整的标注向量为狉=[p(a1),p(a2),…,p(an)],我们使用犆表示一个n×n的标签转移矩阵.其中cij表示从标签i转换到标签j的可能性,具体计算如式(5)所示.其中f表示对应标签出现的频率.由此可以构建随机游走函数:其中vj表示最初的标签概率向量狉中的第j个标签概率.α是一个(0,1)之间的权重参数,本文使用网格搜索的方式确定其值.经过式(6)的迭代处理,标签之间的联系将会强化,孤立标签的标注概率将会减小,最终依据概率高低确定图像标签集.接下来通过推导得到随机游走表达式,使用矩阵重构式(7).因此可以得到式(8).狉π=limn→把转换矩阵犆的每一行归一化到1.如果对于0<α<1,存在γ<1,且α<γ,就可以得到因此(α犆)n中按行求和后为0.代入式(8)可得通过随机游走表达式(式(9))可以计算图像标注的唯一解狉f.通过把标签概率向量和标签转移矩阵代入式(9)进行计算,得到新的标签概率向量,根据此向量最终确定图像标注.通过随机游走函数修正后,图像区域的标注集合更符合实际情况,准确度也会提高.2.3.2条件随机场模型自条件随机场被提出以来,已经有不少研究者将其引入图像标注算法中[19-20],本文结合标签共生信息构建适合的条件随机场模型辅助图像标注.条件随机场模型是一个无向图模型,其中图中的点表示标签,连接两点的边表示两个标签之间的关系.使用条件随机场模型可以充分地结合标签的先验知识和标签间关系的先验知识辅助图像标注,它是图像标注算法中一个强有力的武器.本文借鉴文献[20]的思想提出了一种条件随机场模型辅助图像标注.与前面提及的随机游走算法不同,条件随机场算法不是单纯地利用标签之间的共生关系修正标签概率向量,而是把标签概率向量当做一种标签的先验,构建标签关系图并重新估计图像的标签概率向量.算法构建所有标签的关系无向图,并构建无向图的边势函数(式(10))和点势函数(式(11)),其中点的势函数由标签概率向量所确定,边的势函数由学习训练集标签所得的标签关系所确定.例如“天空”出现了f1次,“草地”出现了f2次,它们同时出现的次数为f3次.那么“天空”和“草地”的联合概率求解如式(12)所示.Page5其中p(ai)表示由先前步骤获得的图像标签概率.在得到无向图中各个点和边的势能后,求取最佳的图结构就能得到最终的图像标注集{a1,a2,…,an}.其中最佳图结构是图势函数值最小时对应的图结构,即式(13)的值最小的图结构.其中λ表示点势函数和边势函数的权重关系,本文通过交叉验证的方法确定λ,它的值一定小于1,因为边的数量总是大于点的数量.使用条件随机场模型,不仅考虑了所有标签之间的关联,而且引入被前面步骤除去的标签重新判断,增加了修正前面错误步骤的机会,增加了本文算图2标签分布示意图本文选取带有区域标签的图像集MSRC-V2训练支持向量机,MSRC-V2共有591张图片,23个区域类别,使用时剔除区域较少的类别,共训练了19个分类器对图像区域进行分类.在使用基于区域上下文感知的图像标注算法对图像进行图像标注的过程中,本文选取了图像的颜色、纹理和形状特征对区域进行识别分类,并选取了文献[21]中的谱聚类算法对未知区域进行聚类.实验选取500张图像作为带有标签信息的混入图像,500张图像作为待标记图像.在实验的过程中,每次标注选择400张图像作为训练集,使用交叉验证的方式确定模型参数,然后使用训练好的模型标注剩下的100张图像.图3(a)显示了使用本文算法和α=0.3的随机游走模型实现图像标注,然后按照选取关键字的标法的鲁棒性.条件随机场模型使得标签之间的共生信息在图像标注发挥了更大的作用,极大丰富了图像标注集的可能值.3实验结果与分析本文使用NUS-WIDE图像数据集对算法进行验证.NUS-WIDE包含有269648张图像和425059个标签.其图像来源于网络,内容丰富多样,适合多标签标注.本文选取其中含有81个人工标签的数据集作为实验标注数据.根据NUS-WIDE26万图片对应的81个标签分布状况,抽样得到了1000张代表性图像作为标注算法测试图像.实验图像标签分布如图2所示.准选取5个标签作为图像标签的实验结果.从图中可以看出本文提出的算法得到了丰富的图像内部区域和对象的信息,而且还获取了一些高层语义信息.图3(b)显示了使用本文算法和λ=0.05的条件随机场模型实现图像标注,然后按照与上面一致的标准选取标签的实验结果.从图中同样可以得到本文提出的算法有效性的证明.相比于噪声较大的人工标签,我们算法实现的标注效果会更好些.由于本文是基于图像中存有多种对象或区域的假设提出的算法,因此引入评价指标F-score来衡量算法的标注效果.F-score是一种综合考虑正确率和召回率的评价指标,它是一种常用的衡量标注效果好坏的指标,具体计算如式(14)所示.Page6图3两种模型实验结果示意图为了对比标注效果,本文引入另外3种方法对选取的图像进行标注.方法1是利用支持向量机分类标记图像的算法.方法2是在支持向量机分类的基础上引入视觉相似约束标注图像的算法.方法3是在方法2的基础上加入空间相对位置约束辅助标注的算法.对比实验结果如图4所示,从图中可知仅仅使用SVM对网络图像进行识别标注有很大的局限性.方法2的得分要明显高于方法1,这证明了利用区域视觉相似约束辅助标注的有效性.进一步,方法3通过引入图像区域的空间信息后,可以得到更鲁棒的区域聚类,从而提高了图像标注的效果.本文提出的算法在所有方法中获得了最优的标注效果,验证了在图像区域层同时考虑区域空间关系和标签共生关系的优势.进一步,条件随机场模型又比随机游走模型要好一些.随机游走模型只是利用标签之间的共生信息修正概率,条件随机场模型是把标签概率和标签之间的共生信息融合到一个势函数中,更加全面和鲁棒,因此算法性能有所提高.图4中显示只用一个标签标注图像时,各个算法的准确度都不高,因为在各个算法中标注概率最高的是最常见的标签,而不是图像最主要标签.随着选择的标签数的增加,图像标注的准确度不断的提高,本文算法的优势得以凸显.基于区域上下文感知的图像标注算法结合空间区域相对位置关系和标注共生关系,得到比原有方法更高的精准度.而且由于标签共生关系的引入,得到了更符合实际的标签集,由此证明本文算法的有效性.我们提出的两个模型的效果不同说明如何对标签共生关系建模进行标签修正对于图像标注也十分重要.本文提出的算法是结合图像区域的相对位置关系及其标签共生关系辅助图像标注.在两种模型的实现过程中,我们发现标签共生关系的强弱对随机游走模型有很大的影响.当有标签对是强关联关系时,得到的标签集会有较大的偏差,使得图像标注集偏向于强关联的标签集.条件随机场模型通过转化重新推断标签概率向量,使得标注集更倾向于信息Page7量大的标签集,有助于提高标注效果.但实验过程中发现当参数λ大到一定程度时,条件随机场模型也会出现与随机游走模型相类似的情况,造成图像标注效果下降.虽然通过实验证明了引入标签信息的有效性,但是如何合理地挖掘和利用共生信息还难以把握,还有诸如如何去除无用处的标签,确定每张图像特有的标签等问题都还有待我们思考和解决.4总结与展望本文提出了一种结合区域空间相对位置关系和标签共生关系的图像标注新方法.该方法首先使用分类器对图像区域进行分类.对能确定类别的区域进行标注,对无法确定类别的区域则利用它周围的确定区域对其构建上下文描述符,然后结合上下文描述符和图像视觉特征信息对其聚类,引入网络图像标签集标注未知区域.在得到图像标签集后,引入两种模型实现借助标签的共生关系对标签集进行修正,最终得到更符合实际的图像标注集,从而提高图像标注精度.通过实验证明,本文提出的算法是有效的,引入图像标签之间的共生信息是有助于图像标注的.在未来的研究中将使用标签数量更多的图像集进行标注,测试本文算法的好坏,也将提出更好的模型对图像上下文信息建模进行图像标注.同时将尝试把算法和网络搜索相结合,得到更多的图像周围信息辅助标注.致谢在此诚挚地对给本文提出建议和意见的师兄、老师、审稿人表示感谢!
