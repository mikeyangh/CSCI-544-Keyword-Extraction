Page1基于集成学习和二维关联边条件随机场的Web数据语义标注方法丁艳辉李庆忠董永权彭朝晖(山东大学计算机科学与技术学院济南250014)摘要大规模Web信息抽取需要准确、自动地从众多相关网站上抽取Web数据对象.现有的Web信息抽取方法主要针对单个网站进行处理,无法适应大规模Web信息抽取的需要.调查研究表明,有效地实现Web数据语义自动标注,结合现有的包装器生成技术,可以满足大规模Web信息抽取的要求.文中提出一种基于集成学习和二维关联边条件随机场的Web数据语义自动标注方法,首先,利用已抽取的信息和目标网站训练页面中呈现的特征构造多个分类器,使用Dempster合成法则合并分类器结果,区分训练页面中的属性标签和数据元素;然后,利用二维关联边条件随机场模型对Web数据元素间的长距离依赖联系和短距离依赖联系进行建模,实现数据元素的自动语义标注.通过在多个领域真实数据集上的实验结果表明,所提出的方法可以高效地解决Web数据语义自动标注问题,满足大规模Web信息抽取的需要.关键词Web信息抽取;语义标注;集成学习;条件随机场;长距离依赖1引言随着WWW的快速发展,Web网页中已经存放了涵盖各个领域的大量有价值的信息.Web数据对象正是这样一类由多个数据元素及可选的数据属性标签按照特定模式组织在一起的半结构化数据对象[1].通过Web信息集成技术将来自不同网站的Web数据对象进行有效的集成,可以进一步提高互联网上信息的利用率,提高其利用价值.大规模Web信息抽取是Web信息集成系统中的关键步骤之一,大规模Web信息抽取与传统的Web信息抽取区别在于:待抽取的网站众多,自动化程度要求比较高.如何准确、自动地从众多相关网站上抽取Web数据对象,为Web信息集成系统提供必要的数据支持,是一个亟待解决的问题.很多研究学者和研究机构对Web信息抽取开展了大量的研究工作,按照Web信息抽取的自动化程度可以分为3类:手工建立、手工标记自动学习和全自动抽取程序[2].但是,现有的大部分方法主要针对单个网站进行处理,对于大规模Web信息抽取来说,主要存在以下几点不足:(1)手工建立方法和手工标记自动学习方法均需要人工参与,对于大规模Web信息抽取来说,代价太高,不适合使用.(2)全自动抽取程序对目标网站具有一定的要求,要求待抽取页面具有相同的展示模板[3];或要求待抽取页面为列表页面[1].但是,对于Web信息集成系统来说,一方面,列表页面和详细页面都需要进行信息抽取;另一方面,由于来自相同网站的网页可能由多个模板产生,导致页面间的同模板检测代价过高[4],不适合应用到大规模Web信息抽取中.(3)从一个特定网站中学到的包装器(Wrapper),不能够被应用到新网站中,即使它们属于同一领域.这反映了现有抽取方法的适应性不强[5],不能满足大规模Web信息抽取的需要.综上所述,现有的大部分Web信息抽取方法不适合完成大规模Web信息抽取任务.调查研究表明[5],通过对目标网站上的训练页面进行语义标注,即为识别出的每个数据元素分配一个有意义的标签来表示该数据元素的语义,可以方便地得到目标网站的训练样例,结合现有的包装器生成技术,可以自动地为目标网站生成包装器,完成信息抽取任务.为了适应大规模Web信息抽取的需要,本文提出一种基于集成学习和二维关联边条件随机场的Web数据语义自动标注方法,通过利用已抽取信息和目标网站训练页面中呈现的特征,自动、准确地完成对众多网站上训练页面的语义标注,为下一步自动构造包装器,完成大规模Web信息抽取提供保证.本文的创新点主要体现在以下几个方面:(1)提出一种适合大规模Web信息抽取的Web数据语义自动标注方法;(2)提出基于集成学习的判别方法,充分利用已抽取信息的特征和目标网站训练页面中的特征,完成对Web数据对象中属性标签和数据元素的区分;该方法具有良好的扩展能力;(3)提出2DCC-CRFs模型,综合利用Web数据元素间的长距离依赖联系和短距离依赖联系,提高语义标注的准确性;(4)通过在多个领域真实数据集上的实验表明,所提出的方法能够较好地完成大规模Web信息抽取任务.2相关工作在Web信息抽取领域,已经提出了许多自动/半自动的生成Wrapper的方法.文献[1]和文献[6]是两种独立于模板的Wrapper生成方法,Lerman等[6]利用详细页面中的信息分隔列表页面中的信息,并构造相应的Wrapper进行抽取.Zhai等[1]利用字符串匹配以及一些视觉特征来挖掘页面中数据记录.但是,文献[1]和文献[6]抽取出的数据均不包含语义标签.Embley等[7]利用本体加上一些启发式规则的方法在包含多条Web数据记录的文档中自动地抽取数据,并进行语义标注.但是,对于不同领域的本体必须手工创建.Mukherjee等[8]利用一些展示规则和相关元素的空间位置关系进行语义标注,这个过程仍然依赖于领域知识.Arlotta等[9]提出一种完全自动地对搜索结果中的数据项标注有意义标签的方法,利用结果页面中距离数据项最近的标签进行标注.但是,这个方法具有一定的局限性,因为很多网站没有将相关标签在结果页面中显示出来.Page3基于D-S证据理论的集成学习策略已经被多次提出[10].Altincay和Demirekler[11]提出利用D-S证据理论对基于等级的分类器进行组合.同时,D-S证据理论也被应用于对以boosting方法构造的分类器进行组合[12].在本文中,将该策略应用于解决大规模Web信息抽取问题.条件随机场是利用序列特征处理序列数据分割与标注问题的经典机器学习方法,在自然语言理解、信息提取等多个领域得到了广泛的应用.针对Web数据元素间的二维序列特征,Zhu等[13]提出二维条件随机场模型(2DCRFs),用于解决Web数据语义标注问题.但是,2DCRFs并没有考虑Web数据元素间的长距离依赖联系[14].发现并利用数据间的长距离依赖联系的想法,已经被一些方法提出.Sutton等[15]提出Skip-CRFs模型,利用文档中相同的单词之间的长距离依赖联系,提高实体识别的准确率.但是,对于单条Web记录来说,并不具备类似的长距离依赖联系,导致该方法不能直接应用于Web数据语义标注.黄健斌等[16]针对Web记录集成中的模式匹配问题,提出了混合链条件随机场模型(MSCRFs),通过在内容相似的Web数据元素之间建立跳边,加强了对长距离依赖关系的处理.但是,在很多情况下,单条Web数据记录中并不包含内容相似的数据元素对,导致无法有效地建立Web数据元素间的长距离依赖联系.针对大规模Web信息抽取任务,目前开展的工作还比较少.Wong等[5]提出一种Web信息自适应抽取方法,通过利用贝叶斯模型实现网站间包装器的适应性学习以及发现新属性.但这种方法仅能将页面中存在的属性标签赋予相应的数据元素,对于页面内没有相应属性标签的数据元素不做标注.而本文提出的方法,将对两种情况都进行标注.3Web数据语义标注本文将主要研究如何准确、自动地完成对众多网站中待标注页面(训练页面)的自动语义标注,为大规模Web信息抽取提供基础支撑.大规模Web信息抽取是Web信息集成系统的关键步骤之一,将为其提供必要的数据基础.如图1所示,在大规模Web信息抽取系统中,包含众多待抽取网站,需要Web信息抽取系统自动地完成相应网站的信息抽取工作.首先,从待抽取网站中选择多个页面作为训练页面;其次,自动完成训练页面中Web数据对象的语义标注,形成训练样例;然后,利用自动标注后的训练样例,结合包装器生成技术[17]自动地生成相应网站的包装器;最后,利用包装器完成对相应网站的自动信息抽取.Web数据语义标注(图1中右上矩形框所示)主要分为3个阶段:第1阶段,找出训练页面中的主数据区域[18],识别出待标注文本;第2阶段,对待标注文本进行自动判断,区分出属性标签和数据元素;第3阶段,利用训练页面中包含的属性标签和已抽取信息中包含的属性名称,对数据元素进行自动语义标注.第1阶段的任务比较简单,利用现有的技术可以完成;第2阶段的任务,利用本文提出的集成学习策略完成;第3阶段的任务,利用本文提出的二维关联边条件随机场模型完成.3.1识别待标注文本Web网页中包含了大量的信息,其中一部分是用户感兴趣的Web数据对象信息,例如图书的基本信息、招聘的基本信息等;而另一部分是杂质信息,例如广告、导航信息、交互表单等.为了提高Web信息抽取的准确性和效率,将首先定位网页中的主数据区域(MainBlock)[18],主数据区域中包含着用户感兴趣的Web数据对象信息.将网页解析成DOM树,主数据区域对应DOM树中的一棵子树T,子树T中所有文本叶子节点上的内容被称为待标注文本.3.2区分属性标签和数据元素识别出待标注文本后,要对待标注文本进行判断,区分出Web数据对象中的属性标签和数据元素.本文提出一种基于集成学习的判别方法,首先,利用已抽取信息的特征和目标网站训练页面中呈现的特征构造多个分类器;然后,利用构造的多个分类器对待标注文本进行独立判断;最后,利用基于D-S证据理论的合成法则,对所有的分类器结果进行合并,得到每一个待标注文本的最终分类结果,完成属Page4性标签和数据元素的区分.3.2.1构建分类器在集成学习中,强调分类器的多样性.相关研究[19]指出,基于不同特征的分类器组合会产生较好的结果.在本文中,将利用已抽取信息的特征和待标注页面中呈现的特征,构造基于不同特征类型的分类器,对待标注文本进行判断.3.2.1.1基于已抽取信息的分类器Web信息集成通常是对某一领域内的信息进行集成,不同网站上的信息具有一定的联系.通过利用已抽取信息的特征,可以对目标网站的信息抽取提供指导.假设Web信息抽取系统利用现有的抽取方法(自动的方法或手工标注的方法)已经对个别网站完成了准确的抽取工作,那么将获得领域内的大量结构化信息,包括已抽取的Web数据对象的属性名称列表以及对应的数据元素值.通过对现有的属性名称列表和数据元素值进行分析,可以获得现有数据的特征.例如,对于图书来说,ISBN是属性名称,对应的属性值是一个10位或13位的数字;出版日期是日期型字段等;在表1中,列出了部分在实验中使用到的已抽取信息的特征.对象属性名称属性值3.2.1.2基于目标网站训练页面中特征的分类器在同一网站中,训练页面中的Web数据对象会呈现出一定的特征,例如,属性标签的展示格式趋于相同;数据元素的展示格式趋于相同;属性标签通常会在多个训练页面中重复出现;而不同Web数据对象中的数据元素趋于不同等.在表2中,列出了部分在实验中使用到的特征.待标注文本的路径熵待标注文本的信息熵反映了待标注文本在训练页面集在网页中的位置展示格式两个待标注文本的相对位置包含超链接与页面内已知的属性标签具有相同的路径与页面内已知的数据元素具有相同的路径3.2.2分类结果合并由于在Web信息集成中需要对众多相关网站进行抽取,信息的特征会得到不断的补充,例如,属性名称列表在不断丰富;新属性值的特征被不断发现,这些将导致为不同分类器固定权重的方法不再适合,需要动态调整不同分类器的权重,为其分配在当前情况下最适合的权重值.由于D-S证据理论[20]可以有效地调整分类器的权重值,所以,本文在分类结果合并策略中,选择基于D-S证据理论的合并方法.3.2.2.1Dempster-Shafer证据理论Dempster-Shafer证据理论[20]是由Dempster首先提出,并由Shafer进一步发展起来的一种处理不确定性的理论.在D-S证据理论中,首先将待识别对象有可能结果的集合所构成的空间识别框架记作Θ,并把Θ中所有子集组成的集合记作2Θ.对于2Θ中任何假设集合A,有m(A)∈[0,1],并且其中,为空集,m称为2Θ上的概率分配函数,m(A)称为A的基本概率分配(BasicProbabilityAssignment,BPA).D-S证据理论定义了信任函数Bel和似然函数Pls来表示问题的不确定性,即Bel:2Θ→[0,1],Pls(A)=∑B∩A≠在有多证据存在的情况下,可以使用Dempster组合法则对多个BPA进行合成,即其中K=∑∩Ai≠∏1inPage5BPA.3.2.2.2基于D-S证据理论的多分类器集成首先定义识别框架Θ={O1,O2,…,On},其中Oi代表不同的分类类别;在系统中,将构造多个基本分类器(BasicClassifier),分别表示为BC1,BC2,…,BCm.每一个分类器具有n个输出,每个输出j指向类别Oj.在分类器集成系统的构建阶段,将为每个基本分类器的任一输出赋予一个BPA,一个BPA赋予输出j,代表了当一个待标注文本text进入集成系统时,被分类为Oj的可信程度.每一个BPA表示为mi(Oj),其中i代表分类器BCi,j代表输出类型Oj.mi(Oj)的值有多种计算方法,在本文的实验中,采用查准率作为BPA的值.在分类器集成系统构建阶段,完成了对基本分类器性能的第一次评价,分类器的性能评价基于在训练集中正确分类的个数和错误分类的个数.mTrainingi(Oj)用于记录基本分类器BCi的任一输出j的BPA.为了使评价更为准确,在测试集上对每个基本分类器的任一输出进行二次评价,获得每个基本分类器在任一输出上的BPA,记为mTesti(Oj).通过利用D-S证据理论对于同质特征的合并规则[10],得到一个唯一的BPA,使用以下公式计算出来,mi(Oj)=1-(1-mTrainingi(Oj))(1-mTesti(Oj))基本分类器加上推理机构成完整的集成学习分类系统[10].当一个新的待标注文本输入系统时,各个分类器将产生多个输出类别,所有这些输出类别将通过推理机进行综合处理.如果多个分类器均指向同一输出类型,那么不需要进行任何推理工作;当多个分类器指向不同的输出类型,需要进行推理,计算出最终输出类型.推理过程分成两步进行,第1步,各个基本分类器独立进行,使用的组合规则是D-S证据理论基于冲突证据的组合规则[10].第2步,将不同分类器的分类结果利用Dempster组合法则(式(5))进行合并.3.3数据元素的语义标注当Web数据对象中的数据元素和属性标签成对出现时,利用已有的一些启发式规则,可以很好地进行标注.例如,属性标签和数据元素在页面上位置相邻;属性标签一般位于数据元素的前方或上方等.但是,当数据元素和属性标签未成对出现在页面上时,现有标注方法的标注准确率将会降低.例如,2DCRF[13]是进行语义标注的经典方法,但是,它仅考虑了Web数据元素间的短距离依赖联系,当页面中出现同模式的数据元素时,准确率会大大降低.本文提出一种基于二维关联边条件随机场的数据元素语义标注方法,通过在2DCRF模型的基础上增加关联边,实现对Web数据元素间的长距离依赖联系和短距离依赖联系的充分建模,提高Web数据元素语义标注的准确率.3.3.1二维关联边条件随机场由于2DCRFs(图2(a))没有考虑Web数据元素间的长距离依赖联系,本文提出一个新的二维关联边条件随机场(two-DimensionalCorrelative-ChainCRFs,2DCC-CRFs)模型,如图2(b)所示,通过在2DCRFs模型上叠加关联边来处理数据元素间的长距离依赖联系.定义1.设G=〈X,Y〉是一个二维条件随机场,X是序列观测数据随机变量,Y是状态标注序列随机变量.Yi,j是Y在位置(i,j)上的组成元素.如果存在Yi,j,Ym,n,且Yi,j∈Y,Ym,n∈Y,|i-m|>1,|j-n|>1,使得Ym,n依赖于Yi,j,则称边(Yi,j,Ym,n)是一条关联边,并称包含关联边的二维条件随机场模型为二维关联边条件随机场.在本文提出的模型中,关联边分为两种类型:Page6CU型关联边和UU型关联边,具体定义如下.定义2.设(Yi,j,Yi,j)是一条关联边,在推理过程之前,如果Yi,j具有确定的语义标签yi,j,而Yi,j不具有确定的语义标签,那么称关联边(Yi,j,Yi,j)为Certain-Uncertain型关联边,简称为CU型关联边.定义3.设(Ym,n,Ym,n)是一条关联边,在推理过程之前,如果Ym,n和Ym,n都不具有确定的语义标签,那么称关联边(Ym,n,Ym,n)为Uncertain-Uncertain型关联边,简称为UU型关联边.令E={(Yu,v,Yu,v)}是关联边的集合,则在给定观测序列x的条件下,标注序列y的概率分布p(y|x)为p(y|x)=1其中,fk,gk和hk是定义在不同团(例如,普通边、结点和关联边)上的特征函数,λk,μk和γk是特征函数的权重值,将利用训练集训练得到.Z(x)是归一化因子,表示为Z(x)=∑y3.3.2基于二维关联边条件随机场的Web数据元利用二维关联边条件随机场模型完成对Web数据元素的语义标注,需要完成以下3方面工作:(1)建立关联边;(2)参数估计;(3)推理.3.3.2.1关联边关联边将在推理过程之前建立,构造关联边的关键在于选择关联边的始末结点.通过找出能够确定语义标签的数据元素,就可以构造出所有的关联边,包括CU型关联边和UU型关联边.目前,存在很多种方法[21]可以判断出Web数据元素Ri,j标注语义标签lt具有较高的置信度.在2DCC-CRFs模型中,将主要利用已有数据库的结构化信息和记录特征以及训练集中样本数据的文本特征来判断某一Web数据元素标注不同语义标签的置信度[22].如果Web数据元素Ri,j与数据库中的数据记录具有很好的匹配,包括内容匹配或模式匹配;或者Web数据元素Ri,j对于某个语义标签具有一个足够高的发射概率,那么可以认为Web数据元素Ri,j标注语义标签lt具有较高的置信度.例如,如果存在以下统计结果,p(lt="conference"|Ri,jcontains那么当Web数据元素Ri,j为"inproceedingsofSIGMOD08"时,Ri,j标注为"conference"这个语义标签.构建关联边的算法如下.算法1.输入:一条Web数据记录R和语义标签集合L输出:CU型关联边集合Ecu和UU型关联边集合Euu1.对于lt∈L,Ri,j∈R,计算数据元素Ri,j标注语义标签lt的置信度ci,j(lt);2.如果Ri,j标注语义标签lt的置信度大于阈值,即ci,j(lt)>ω,那么将Ri,j添加至语义标签已确定元素的集合CertainElements;否则,将Ri,j添加至语义标签未确定元素的集合UncertainElements;3.对于Ri,j,Ri,j且Ri,j∈R,Ri,j∈R,如果Ri,j∈CertainElements,Ri,j∈UncertainElements,那么将(Ri,j,Ri,j)添加至CU关联边集合Ecu;4.对于Rm,n,Rm,n且Rm,n∈R,Rm,n∈R,如果Rm,n∈UncertainElements且Rm,n∈UncertainElements,那么将(Rm,n,Rm,n)添加至UU型关联边集合Euu;5.返回Ecu和Euu.3.3.2.2参数估计在2DCC-CRFs模型中,参数估计分为两个部分,一部分是针对普通边(不包括关联边在内的邻接边)和结点上特征函数的参数估计,另一部分是针对关联边上特征函数的参数估计.与传统的链式CRFs和2DCRFs的参数估计相似,2DCC-CRFs模型中使用最大似然估计来估计针对普通边和结点上的特征函数的权重参数.即在给定一个具有概率分布为p~(x,y)的训练集D={(yi,xi)}Ni=1上,估计参数Φ={μ1,μ2,…;λ1,λ2,…}的值,使得该训练集数据的对数似然函数L(Φ)达到最大.似然函数表示为由于L(Φ)为凹函数,导数为零时为最值点.故对Φ求导,则偏导数公式为,令式(10)、(11)等于0,函数L(Φ)取得最大Page7值.可以看出,每个特征对模型的约束为“特征的样本期望值等于其模型期望值”.Ep(y|x,Φ)[fk]和Ep(y|x,Φ)[gk]如果直接计算需要很大的计算量,可以使用动态规划的方法求解,如向前-向后(Forward-Backward)算法.为了避免对大量参数估计时出现的过拟合问题,对数似然函数经常需要将参数作先验分布调整,采用高斯先验调整后,式(9)转化为L(Φ)=∑i其导数变为L(Φ)λk=Ep~(x,y)[fk]-Ep(y|x,Φ)[fk]-λkL(Φ)μk=Ep~(x,y)[gk]-Ep(y|x,Φ)[gk]-μk其中,σ2表示先验方差.于是Φ的参数估计问题可以用最优化方法解决,可以使用GIS、IIS等迭代方法.本文的实验使用L-BFGS算法[23]实现对目标函数的优化求解.L-BFGS是一种充分利用以前的梯度和修改值来近似曲率值的二阶方法,可以避免准确的Hessian矩阵的逆矩阵的计算.在2DCC-CRFs模型中,针对关联边上的特征函数的参数估计比较简单,CU型关联边(Yi,j,Yi,j)上的特征函数的权重值等于语义标签对〈yi,j,yi,j〉的互信息[21]MI(yi,j,yi,j).MI(yi,j,yi,j)=p(yi,j,yi,j)log2p(yi,j,yi,j)其中,N代表训练集的大小,N(yi,j)代表语义标签yi,j出现的次数,N(yi,j,yi,j)代表语义标签对〈yi,j,yi,j〉同时出现的次数.对于CU型关联边,yi,j是唯一的,而yi,j可以有多个值,在本文的实验中,通过阈值来控制yi,j的取值个数.对于UU型关联边(Ym,n,Ym,n)上的特征函数的权重值初始为Δ,在本文的实验中,Δ=1中,|L|代表语义标签集的大小.3.3.2.3推理推理算法的时间复杂度将对模型的性能产生重要的影响.在2DCC-CRFs模型中,由于二维表格中包含环,并且环的距离可能比较长或发生重叠,导致精确推理算法的时间复杂度呈指数级增长,所以,精确的推理算法不再适合.本文使用LoopyBeliefPropagation算法[24]进行近似推理,LoopyBeliefPropagation算法是对向前-向后算法的归纳.向前-向后算法的时间复杂度为O(n2T),其中n代表状态集合的大小,T代表观察序列的长度.由于在2DCC-CRFs模型中增加了对关联边的处理,并且对单条关联边进行处理的代价等同于向前-向后算法中对单条邻接边的处理代价[24].因此,在2DCC-CRFs模型中,LoopyBeliefPropagation算法的时间复杂度变为O(|L|2·(T+M)),其中|L|代表语义标签集合的大小,T代表一条Web记录中数据元素的个数,M代表关联边的条数,M与T的平方成正比.Loopybeliefpropagation算法是一个迭代算法,尽管它不保证收敛,但是相关研究[23]和本文的实验均表明,其在实际应用中具有较好的近似推理效果,可以有效地推断出最有可能的语义标注序列.4实验评价在本文中,预定义的关系数据库作为已抽取的信息库使用,通过收集多个领域的真实数据集,对提出的方法进行测试,主要通过4个方面进行分析评价:(1)基于D-S证据理论的集成学习方法与其它方法的比较;(2)2DCC-CRFs模型与传统条件随机场模型的比较;(3)数据库参与与否对2DCC-CRFs模型性能的影响;(4)数据库规模对2DCC-CRFs模型性能的影响.4.1测试数据集真实数据集:以下是对所提出的方法的性能进行综合评价的(1)在线图书数据集(Bookdataset,简称B)该数据集由从30个在线图书网站上收集的2000条不同格式的Web图书记录组成,数据经手工标注后,随机选择1000条作为训练数据,剩余部分作为测试数据.另外,从http://www.textbookx.com/网站上随机抓取1万条图书记录,存入预先定义的关系数据库表中,作为图书数据库.(2)台式机数据集(Desktopdataset,简称D)该数据集由从FROOGLE在线购物网站收集Page8的3500条异构台式机记录构成,数据经手工标注后,将其中的2000条记录录入预先定义的关系数据库表中,作为台式机数据库.在其余的1500条记录中,随机选择700条记录作为训练数据,剩余部分作为测试数据.(3)论文参考文献数据集(Paperreferencedata-set,简称P)该数据集由800条论文记录构成,是用来评价数据抽取系统的基准数据集之一,数据集来源于http://www.cs.umass.edu/~mccallum/data.从该数据集中随机选择400条作为训练数据,剩余部分作为测试数据.另外,从ACMDigitalLibrary中随机抓取2万条论文记录,作为论文数据库.4.2评价标准本文采用检验Web数据语义标注结果的常用标准:查全率、查准率、测度F1和实例标注准确率,对实验结果进行评价,具体的定义如下:设A表示待标注的数据元素数;B表示正确标注的数据元素数;C表示错误标注的数据元素数.(1)查全率(Recall)、查准率(Precision)和测度www.digitalguru.comwww.halfpricecomputerbook.comwww.bookpool.comwww.amazon.comwww.adebooks.comwww.discount-pcbooks.com表3DSE与RoadRunner++对比结果Precision/%Recall/%F1/%基于DSE的结果实验结果表明DSE具有较RoadRunner++优越的性能.从结果中发现,两种方法在查全率方面结果相似,但是RoadRunner++在查准率方面准确度大大降低.其主要原因在于RoadRunner++从目标网站中抽取出大量信息,仅依据编辑距离对其进行语义标注,它不考虑其它特征,例如数据模式、展示特征等,导致较低的查准率.字段表4在数据集B上的语义标注结果2DCRFs标注结果TitleAuthorISBNPagesPublishDates76.4882.5879.4181.2586.6783.8781.3187.2984.19OriginalPrice36.5753.2343.3537.6955.2244.8173.2173.2873.24CurrentPrice62.2745.3952.5169.7849.9458.2268.1776.4272.06Yousave79.5768.7573.7688.0573.3379.9992.0281.0786.20AverageF1F1,其计算公式分别为(2)实例标注准确率.每个数据元素均被正确标记的Web数据对象占总的测试对象的比例.4.3实验结果与分析4.3.1基于D-S证据理论的集成学习策略与其它RoadRunner[3]是经典的全自动Web信息抽取方法,但它不能对抽取的数据项进行语义标注,所以,本文在实验中将使用RoadRunner++[5]进行比较.首先,选择图书领域的6个网站,分别为DigitalGur.com、HalfPriceComputerbooks、Book-pool.com、Amazon.com、Abebooks.com、Discount-PCBooks.com.然后,基于D-S证据理论的集成学习方法(简称为DSE)和RoadRunner++分别对这6个网站进行抽取和语义标注.实验结果如表3所示.4.3.22DCC-CRFs与传统条件随机场模型的比较本文在3个数据集上通过实验比较了2DCC-CRFs与Linear-ChainCRFs、2DCRFs模型在Web数据语义标注上的性能.基于Linear-ChainCRFs和2DCRFs的语义标注方法详见文献[13].表4、表5和表6显示了在每个字段上的查全率、查准率、F1值以及平均F1值.65.24Page9表5在数据集D上的语义标注结果2DCRFs标注结果BrandOperatingSystem65.4183.1773.2366.6783.3374.0774.1386.8980.10DVD/CDDrive91.8483.4787.4692.7183.3387.7889.5086.7188.07ProcessorMainFrequency91.8161.7273.8293.7562.5075.0284.1987.3985.76RAMHardDriveAverageF1表6在数据集P上的语义标注结果2DCRFs标注结果字段AuthorTitleEditorBookTitle48.8974.8759.1550.0075.4860.1566.6763.1064.84DateJournalVolumeTechInstitution72.9887.9279.7673.7488.6780.5279.7182.3180.99PagesLocationPublisher56.7183.4967.5457.1483.1567.7360.6480.6169.21AverageF1从表4~6中可以看出,基于2DCC-CRFs模型的方法在Web数据语义标注上的总体性能要优于基于Linear-ChainCRFs和2DCRFs模型的方法.与2DCRFs相比,F1的平均值在3个数据集上分别提高了7.81%、4.03%和6.07%,并且每个字段的F1值均有所提高.实验表明,通过增加关联边,可以充分利用Web数据元素间潜在的长距离依赖联系,进一步降低Web数据语义标注的错误率.另外,对于一些数据模式完全相同的字段,语义标注准确性的增长尤为明显.例如,对于数据集B上的OriginalPirce、OurPrice、YouSave3个字段,F1值的平均增幅达到16.2%.分析其主要原因在于,通过对数据库中的数据记录进行规则挖掘发现,如果在一条记录中同时出现3个价格,价格之间存在一定的大小关系,并且两个价格之和等于第3个价格,那么可以较准确地确定3个数据元素的语义标签.另外,我们也发现2DCC-CRFs模型在部分数据字段的查全率或查准率并没有同时被提高,单个指标出现了下降.例如,在数据集B上,相比2DCRFs模型,Author字段的查全率提高了10.91%,但是查准率却降低了3.44%,这反映了在查全率和查准率之间存在着相反的相互依赖关系.通过观察进一步发现,在数据集D和P上,79.9467.71Linear-ChainCRFs和2DCRFs模型的语义标注性能相差不大,主要原因在于,数据集D和P上的数据元素间不存在二维依赖联系.而数据集B上的数据元素间存在二维依赖联系,所以,相对于Linear-ChainCRFs、2DCRFs模型在不同属性上的标注准确性都有所提高.在图3中,显示了2DCC-CRFs和其它两个模型在实例标注准确率这个指标上的性能比较.从图中可以看出在3个数据集上,相对于Linear-ChainCRFs和2DCRFs、2DCC-CRFs的实例标注准确率均有不同程度地提高.相对于2DCRFs模型,2DCC-CRFs模型的实例标注准确率分别提高了9.43%、5.18%和6.15%.其中,数据集B上的增幅最为显著,主要原因在于,通过增加对长距离依赖联系的处图3Linear-ChainCRFs、2DCRFs和2DCC-CRFs模型Page10理,有效地降低了对OriginalPirce、OurPrice、YouSave3个字段的标记错误率,提高了实例标注准确率.4.3.3数据库参与与否对2DCC-CRFs模型性能在数据集B上,通过实验分析了在数据库参与和数据库不参与两种情况下,对Web数据语义标注性能的影响.参与模型训练的样本数据由随机抽取的1000条图书记录(简称L)组成,用于测试的是另外1000条图书记录.图书数据库(简称DB)主要用表7包含数据库和不包含数据库两种情况下的语义标注结果51.2546.0376.6273.6777.7870.1770.9784.7568.89TitleAuthorISBNPagesPublishDatesOriginalPriceOurPriceYousaveAverageF1从表7中可以看出,第2组实验由于包含了数据库,绝大多数属性的查全率、查准率和F1这3个指标都有明显提高,F1的平均值提高了约4.16%.性能提高的主要原因在于,数据库的结构化信息及记录特征较手工标注训练集中的样本数据的文本特征更为准确地确定了相关数据元素的语义标签,进而准确地建立关联边,有效地利用了Web数据元素间潜在的长距离依赖联系.结合表4可以发现,与2DCRFs模型相比,即使没有数据库的参与,2DCC-CRFs模型的标注性能也有所提高,F1的平均值提高了约3.65%.但是,也发现有一些字段的F1值有所降低,例如Author、publicationdates字段.分析实验数据发现,仅根据图4数据库规模对F1的平均值和实例标注准确率的影响(基于数据集P)于确定部分Web数据元素的语义标签,不作为训练集使用.实验分成2组:第1组数据库DB不参与,用在L上训练得到的2DCC-CRFs模型对测试记录进行语义标注;第2组,数据库DB参与,2DCC-CRFs模型是在DB和L组成的联合样本数据上训练得到.表7给出了在这个数据集上选择的8个典型字段的语义标注结果.每个字段的性能使用查全率、查准率和F1这3个指标来评价,同时也计算了平均F1值.手工标注训练集中的样本数据的文本特征,导致一些数据元素的语义标签被错误识别,进而导致生成了一些错误的关联边,导致一些字段的F1值下降.该实验进一步表明,准确地确定关联边,建立Web数据元素间正确的长距离依赖联系,对于模型的性能有着重要的影响.4.3.4数据库规模对2DCC-CRFs模型性能的影响为了进一步验证使用数据库信息的有效性,通过实验测试了数据库记录的增加对模型标注性能的影响.从论文数据库中随机选择了0条、5000条、10000条和20000条记录来得到不同规模的数据库,在每个数据库上执行同样的实验.图4(a)和(b)分别展示了F1的平均值和实例标注准确率两个指标Page11随着数据库规模变化而发生变化的曲线.通过观察发现,F1的平均值和实例标注准确率随着数据库规模的增大逐步提高.但是,两条曲线均随着数据库规模的增大而逐渐变得扁平.这个实验表明,是否使用数据库对于2DCC-CRFs模型的语义标注性能有着明显的影响;但是,随着数据库规模的继续增大,使用数据库所展示出的有效性在逐步降低.5结论本文提出了一种基于集成学习和二维关联边条件随机场的Web数据语义标注方法,通过结合现有的包装器生成技术,可以有效地解决大规模Web信息抽取问题.该方法首先利用已抽取信息和目标网站训练页面中呈现的特征构造多个分类器;接着,利用构造的基于不同特征的分类器对待标注文本进行判断;然后,利用基于D-S证据理论的集成学习方法对多个分类器的分类结果进行合并,完成对待标注文本的判断,识别出属性标签和数据元素;最后,利用2DCC-CRF模型完成对数据元素的自动语义标注.
