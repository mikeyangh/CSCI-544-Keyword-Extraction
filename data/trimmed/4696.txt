Page1概率图模型的稀疏化学习刘建伟崔立鹏罗雄麟(中国石油大学(北京)自动化研究所北京102249)摘要利用稀疏化学习得到的概率图模型结构简单却保留了原始概率图模型中重要的结构信息,且能同时实现结构和参数学习,因此近几年来概率图模型的稀疏化学习一直是研究的热点,其中概率图模型的第一种稀疏化学习方法是图套索.文中总结了概率图模型的稀疏化学习方法,包括概率图模型的L1范数罚稀疏化学习、概率图模型的无偏稀疏化学习、概率图模型的结构稀疏化学习和概率图模型的多任务稀疏化学习.最后,文中还指出了概率图模型的稀疏化学习未来有意义的研究方向.关键词概率图模型;稀疏化学习;结构和参数;图套索;精度矩阵;机器学习1引言套索模型(Lasso)[1]由估计损失项和L1范数罚项组成,其通过L1范数罚实现稀疏化学习.自从套索模型被提出后,稀疏化学习方法迅速发展,其中一Page2图模型的稀疏化学习问题本质上是对精度矩阵的稀疏化学习问题,该问题又被称作稀疏化协方差选择(covarianceselection)[2]问题.第一种对概率图模型进行稀疏化学习的方法是将套索的罚函数L1范数罚嵌入到概率图模型的极大似然估计中以实现精度矩阵的稀疏化,从而实现概率图模型结构的稀疏化,该稀疏化学习方法被称作图套索(GraphicalLasso).本文系统综述了概率图模型的稀疏化学习问题,包括概率图模型的L1范数罚稀疏化学习、概率图模型的无偏稀疏化学习、概率图模型的结构稀疏化学习和概率图模型的多任务稀疏化学习.其中概率图模型的L1范数罚稀疏化学习主要应用在高斯无向图图1概率图模型稀疏化学习分类概率图模型的稀疏化学习的必要性体现在如下几个方面:(1)极大简化网络结构,提高概率图模型的可解释性.概率图模型的结构和参数学习,需要学习的空间维数很高,需要遍历的网络结构数随着顶点变量的个数呈指数增长,使得找到最适合数据样本的网络结构和最优的模型参数问题非常困难.由于概率图模型经过模型稀疏化学习后既结构简单又保留了原始概率无向图模型中重要的结构与参数信息,因此近几年来概率图模型的稀疏化学习问题越来越受到学者的重视.(2)概率图模型的稀疏化学习能够通过学习精度矩阵而同时实现网络结构和参数的学习.(3)提高泛化能力.从统计观点来看,概率图模型的稀疏化学习可以解决过拟合问题,从而使得模型更具有普适性和提高泛化能力.另外,概率图模型的稀疏化学习在一定的附加条件下能够保证学习得到的概率图模型拥有较好的统计特性.(4)更有效地利用已知的先验信息.对复杂对象建模时,通常具有先验信息,也叫先验偏置,更好地利用这些先验信息,对于改善模型的统计特性和模型的推理和学习都有好处,概率图模型的稀疏化模型[3-6]、部分随机变量不可观测的图模型[7-9]、有向无环图图模型[10-11]和伊辛模型[12-13]中,概率图模型的无偏稀疏化学习包括SCAD图套索[14-15]、自适应图套索[15]、贝叶斯无偏图套索[16-17]和幂法则图套索[18],概率图模型的结构稀疏化学习包括Lq,1范数组结构图套索[19-20]、LF,1范数组结构图套索[21]、双稀疏图套索[22]和局部共性图套索[23],概率图模型的多任务稀疏化学习主要包括多任务两两融合图套索[24]、多任务有序融合图套索①和多任务组结构图套索[25].概率图模型稀疏化学习的分类图如图1所示,各稀疏化学习方法对应的参考文献也列入了图1中.学习问题本质上是一个正则化问题,正则化项对应先验信息,根据不同的先验信息设计不同的正则化项会得到不同特点的稀疏解,从而可实现对概率图模型各种复杂的稀疏化学习,例如概率图模型的组结构稀疏化学习、概率图模型的重叠组结构稀疏化学习、概率图模型的树组结构稀疏化学习、局部共性结构稀疏化学习、节点和边同时稀疏的结构稀疏化学习等.(5)概率图模型稀疏化学习的优化问题的求解可借助于大量现成的有效求解算法.稀疏化学习问题已经被广泛研究,其对应的优化问题的求解算法众多而且已经较为成熟,这些优化问题的求解算法使得概率图模型的稀疏化学习对应的优化问题的求解不再成为难题.例如对伊辛模型进行稀疏化学习的邻域选择方法[26](neighborhoodselectionmethod),将概率图模型的稀疏化学习问题转化为求解一系列的套索问题,可利用现成的求解套索的各种解法(最小角回归算法[27]等)进行求解.(6)使得概率图模型可处理大规模复杂推理和学习问题,对概率图模型的推理和学习更加方便.①Fusedmultiplegraphicallasso.http://arxiv.org/abs/1209.Page3从后续的分析和算法设计的观点来看,概率图模型的稀疏化学习极大降低了参数个数,使得后续对概率图模型的各种分析和算法处理方面变得较为容易,一定程度上消除了算法设计面临的算法复杂性难题.2概率图模型的稀疏化学习2.1概率图模型的犔1范数罚稀疏化学习2.1.1高斯无向图图套索令无向概率图模型对应的数据矩阵为犡∈犚N×P.假设每个样本犡(N)都服从独立同分布的P维高斯分布NP(μ,Σ):其中μ∈犚P为均值,Σ∈犚P×P为协方差矩阵.令Θ=Σ-1表示协方差矩阵Σ的逆矩阵,并将其称作精度矩阵.精度矩阵Θ中某个元素Θij为零(不为零)表示无向概率图模型中两个节点i和j之间不存在(存在)一条边,即代表了变量Xi和Xj是条件独立(不是条件独立)的.不妨假设均值μ=0,且下文中如无特别说明均默认均值μ=0.由于精度矩阵同时包含了无向概率图模型中的参数信息和结构信息,因此学习无向概率图模型结构和参数的问题就转化成了学习精度矩阵Θ=Σ-1的问题.令犛表示数据矩阵犡∈犚N×P的样本协方差矩阵犛=∑N,则关于精度矩阵Θ=Σ-1的极大似然估计问题为其中Θ0表示矩阵Θ的元素均大于零,tr(·)表示矩阵的迹,Θ表示矩阵Θ的行列式.但是,极大似然估计方法不能产生稀疏解,因此得到的模型复杂度过高,不具有现实的可解释性.针对上述问题,在式(2)的基础上添加L1范数罚便得到图套索[3-6]:Θ^=argmax其中λ0,精度矩阵Θ∈犚P×P为正定矩阵,Θ表示矩阵Θ的行列式,tr(犛Θ)=〈犛,Θ〉表示矩阵犛和Θ乘积的迹(即矩阵犛和Θ的内积),Θ1=PPi=1∑j=1∑意,该矩阵的L1范数罚形式与当前国内大多数教材中矩阵的L1范数罚不同,该范数罚为对精度矩阵中全部元素的绝对值求和.由于使用了L1范数罚,因此式(3)的解Θ^是稀疏的(即精度矩阵Θ^中零元素占的比例较大),Θ^中为零的元素Θ^Xi和Xj之间是条件独立的,即在无向图中随机变量Xi和Xj之间不存在边连接,因此大大简化了无向概率图模型的结构,并且同时实现了概率图模型的参数学习.式(3)中的图套索是第一种被提出用来对概率图模型进行稀疏化学习的方法,为与下文各种概率图模型稀疏化学习方法区分,本文将其称作朴素图套索.实际上朴素图套索服从贝叶斯理论,朴素图套索可以被表示为先验信息下的层次后验估计形式,该层次后验估计形式被称作贝叶斯图套索[28],其中精度矩阵中非对角元素的罚函数部分对应于后验估计中的拉普拉斯先验分布,对角元素部分对应指数先验分布,且该层次后验估计中的超参数可以利用吉布斯抽样方法求解.Banerjee等人[29]考虑了贝叶斯图套索后验分布的收敛率(convergenceratesofposteriordistributions)问题.2.1.2部分随机变量不可观图套索除了将L1范数罚用于高斯无向图模型的稀疏化学习,大量的研究还将L1范数罚应用到其他图模型的稀疏化学习中.Chandrasekaran等人[7-9]研究了某些随机变量不可观测时概率图模型的稀疏化学习问题,他们将协方差矩阵和精度矩阵分别进行如下分解:其中O为可观测随机变量的下标,H为不可观测随机变量的下标.Chandrasekaran等人令珔犛=ΘO,珚犔=ΘOH(ΘH)-1ΘHO,则根据schur补(schurcomple-ment)可得(ΣO)-1=珔犛-珚犔,其中假定珔犛和珚犔分别为稀疏矩阵和低秩矩阵,对稀疏矩阵珔犛施加L1范数罚珔犛1,对于低秩矩阵珚犔施加迹范数罚tr(珚犔),此即矩阵的低秩稀疏分解(lowrankandsparsedecompo-sition)问题,Chandrasekaran等人通过求解正则化项为γ珔犛1+tr(珚犔)的罚极大似然估计问题得到珔犛和珚犔,进而得到(ΣO)-1,从而学习出概率图模型可观部分的结构与参数信息,其中γ为调节L1范数罚珔犛1和迹范数罚tr(珚犔)之间比例大小的可调参数.2.1.3有向无环图图套索Shojaie等人[10]利用L1范数罚学习有向无环图图模型,但他们事先假定有向无环图具有已知的自然序(naturalordering),故其本质上是对有向无环图骨架的学习,并不能学习出有向无环图中的因果方向.针对上述问题,Fu等人[11]利用L1范数罚方法Page4结合实验干预法同时学习高斯有向无环图的参数信息、稀疏结构和因果方向,其中L1范数罚的作用为实现对因果高斯有向无环图的参数学习和稀疏结构学习,实验干预法的作用为进行因果方向的推断.2.1.4伊辛模型图套索Ravikumar等人[12-13]利用L1范数罚学习一种特殊的马尔可夫网络———马尔可夫随机场中随机变量为二元取值的伊辛模型(Isingmodel),他们利用伪似然函数(pseudo-likelihood)作为该马尔可夫网络似然函数的近似,然后利用邻域选择方法求解,即分别对每个节点和其邻域内节点之间的结构进行学习,将该情形下概率图模型的学习问题转化为求解P个独立且易于求解的L1范数罚逻辑斯蒂回归问题,其中P为随机变量的个数.2.1.5其他图模型的L1范数罚稀疏化学习有学者[30-32]将无向图模型中服从高斯分布的随机变量替换为服从多维高斯分布的光滑函数,将正态分布推广为非参数正态分布(nonparametricnormaldistribution,简写为nonparanormal),于是将高斯无向图模型推广为半参数高斯无向图模型,然后利用L1范数罚对其进行稀疏化学习.Voorman等人[33]将可加模型与概率图模型结合,利用L1范数罚对该半参数类型的概率图模型进行稀疏化学习,并将其推广到节点之间的自然序(naturalordering)已知的有向图的情形下.Allen等人[34]将概率图模型推广到随机变量服从泊松分布的无向图模型———泊松无向图模型,并且利用邻域选择方法对其进行稀疏化学习,将问题转化为P个独立且易于求解的L1范数罚对数线性模型问题.Yang等人[35]将概率图模型推广到随机变量服从指数分布族的情形,并将该概率图模型称作基于广义线性模型的概率图模型,然后利用邻域选择法对其进行稀疏化学习.Hill等人①还利用L1范数罚同时实现基于模型的聚类和概率图模型结构的稀疏化学习.Maurya[36]在L1范数罚的基础上增加了一项迹范数罚(tracenormpenalty)tr(Θ),该罚函数的含义为矩阵Θ的全部特征值之和,叠加该罚函数后的学习效果(例如稀疏性和误差方面)往往比单纯利用L1范数罚要好.2.1.6小结与分析利用L1范数罚可以实现对概率图模型结构和参数的同时学习,因此自从基于高斯无向图模型的朴素图套索被提出后,该方法迅速被推广到大量其他概率图模型的稀疏化学习中.但仅利用简单的L1范数罚对概率图模型进行稀疏化学习往往是不够的,L1范数罚的估计有偏,并且很多时候概率图模型中随机变量之间往往具有某种复杂的结构,学习该类复杂结构需要结构化的罚函数,简单的L1范数罚无法处理,上述缺点都有待于改进,这也是本文后面几节所述的核心内容.最后必须指出,L1范数罚是非凸的L0范数罚的凸放松形式,由于L0范数罚构成的优化问题难以求解,所以才对其进行凸放松得到L1范数罚,但L0范数罚能够得到比L1范数罚更稀疏的模型,因此最近又有学者[37-38]重新提出利用L0范数罚图模型进行稀疏化学习且均给出了求解非凸L0范数正则化问题的有效求解算法.2.2概率图模型的无偏稀疏化学习2.2.1SCAD图套索SCAD罚为Fan等人[39]提出的非凸罚,其具有估计无偏性.为了实现无偏估计,将朴素图套索中的L1范数罚替换为SCAD罚便得到具有稀疏性和无偏估计性的SCAD图套索[14-15].已知式(1),SCAD图套索要求解的问题为Θ^=argmax其中Θij为矩阵Θ中的第i行第j列的元素,SCAD罚为pλ,a(θ)=λI(θλ)+其中λ0,a>2,I(·)为指示函数.当a=时,SCAD罚就退化为L1范数罚,此时SCAD图套索也就退化为朴素图套索.另外,Abegaz等人[40]还将SCAD罚应用于时间序列链图模型(timeserieschaingraphicalmodels)的稀疏化学习中.2.2.2自适应图套索除了SCAD图套索外,自适应图套索[15]是另外一种具有无偏估计特点的图套索,已知式(1),自适应图套索要求解的问题为Θ^=argmax其中λ0,P为随机变量个数,ωij=1/Θ重,γ>0,Θ素.当P<N时令Θ当PN时令Θ模型求解本质上分为两步:(1)求得样本协方差矩①Network-basedclusteringwithmixturesofL1-penalizedPage5阵或朴素图套索的解Θ~确定权重ωij=1/ΘΘ图套索对于矩阵Θ的权重,对于矩阵Θ大的权重,从而减小对于无向概率图模型中重要边的惩罚,加大对于不重要边的惩罚,最终实现无偏估计.另外,Peterson等人[41]还利用自适应图套索对代谢网络(metabolicnetworks)进行稀疏化学习.2.2.3贝叶斯无偏图套索与朴素图套索类似,自适应图套索也具有贝叶斯理论中的形式,其可以被表示为先验信息下的层次后验估计形式,其中精度矩阵中非对角元素的罚函数部分对应于后验估计中的拉普拉斯先验分布,对角元素部分对应指数先验分布,该层次后验估计形式被称作贝叶斯自适应图套索[16].与自适应图套索类似,贝叶斯自适应图套索在其先验分布中给精度矩阵的不同元素分配不同的权重,因而贝叶斯自适应图套索可实现无偏估计.Wong等人[17]也引入了一个层次贝叶斯模型来对高斯图模型进行稀疏化学习,但他们将拉普拉斯先验替换为Jeffreys先验这种无信息先验分布(non-informativepriordistri-bution),因而避免了概率图模型稀疏化学习中需要利用交叉验证方法选择可调参数的问题,并且指出该层次贝叶斯模型中的后验估计式中的似然函数是非凸的,具有估计的无偏性.Orchard等人①利用GWishart分布(GWishartDistribution)作为先验分布,然后利用哈密顿蒙特卡罗方法(HamiltonianMonteCarlo)进行采样学习.2.2.4幂法则图套索另外,L1范数罚不适用于无标度网络的学习.在无标度网络中大部分节点只和少数几个节点相连,极少数节点(中枢节点)与很多节点相连,而且无标度网络中节点的自由度分布服从幂法则.由于L1范数罚对概率图模型中各个节点的惩罚程度是相同的,因此不具有识别出中枢节点的功能,于是Liu等人[18]将L1范数罚替换成幂法则罚∑i中εi为一正数,并且指出新的幂法则图套索优化问题等价于一系列再权L1范数正则化(reweightedL1regularization)问题,对各个节点惩罚的权重合理调整,使得自由度高的中枢节点的惩罚权重大大减小,从而促使中枢节点的出现.2.2.5小结与分析式(3)中的朴素图套索采用了L1范数罚,虽然具有稀疏性,但是其得到的解是有偏估计.L1范数罚导致有偏估计的原因为其对精度矩阵中的每个元素施加同等程度的罚,不具有对重要元素施加较小程度的罚而对非重要元素施加较大程度罚的自适应特性,针对该缺点而进行改善的方法大都从调整不同元素被惩罚的程度大小入手,例如本节所述的SCAD图套索、自适应图套索、贝叶斯无偏图套索和幂法则图套索.2.3概率图模型的结构稀疏化学习2.3.1Lq,1范数组结构图套索Lq,1范数组结构图套索有两种,一种为L,1范数组结构图套索[19],另一种为L2,1范数组结构图套索[20].已知式(1),L,1范数组结构图套索要求解的问题为mg=1其中∑示先对分组Gg中的元素进行L范数运算,然后再横跨全部组进行L1范数运算.已知式(1),L2,1范数组结构图套索为mg=1其中∑先对分组Gg中的元素进行L2范数运算,然后再横跨全部组进行L1范数运算.Lq,1范数组结构图套索的提出是因为有时希望概率图模型中某些边作为一个整体同时存在或者同时消失,故组结构图套索需要事先人为将精度矩阵Θ中的全部元素分为m个组{G1,…,Gm},导致Lq,1范数组结构图套索具有令精度矩阵中元素成组地进行稀疏的效果.Cheng等人②和Lee等人③将Lq,1范数组结构图套索应用到既有随机变量服从连续分布又有随机变量服从离散分布的混合概率图模型中进行结构稀疏化学习.①②③Page62.3.2LF,1范数组结构图套索假设概率图模型中每个节点都为多属性节点,即每个节点对应的是一个多维随机向量而不是单个随机变量,则LF,1范数组结构图套索[21]要求解的问题为Θ^=argmax其中Θab表示多属性节点a和多属性节点b在密度矩阵中对应的元素块,罚函数∑a,b块先进行F范数(Frobenius范数)运算,再横跨全部元素块进行L1范数运算,其作用为实现精度矩阵的块稀疏化(即组稀疏化).LF,1范数组结构图套索背后的原理为:由于两个多属性节点之间是否相互独立等价于其偏典型相关系数(partialcanonicalcorrelation)是否为零,而偏典型相关系数是否为零又等价于两多属性节点在精度矩阵中对应的元素块是否为零,故基于多属性节点的概率图模型的稀疏化学习问题等价于精度矩阵的块稀疏化学习问题.2.3.3双稀疏图套索Honorio等人[22]提出了边和节点同时稀疏的双稀疏图套索,双稀疏图套索在假设无向概率图模型中边存在稀疏现象的同时还假设无向概率图模型中只有一小部分的节点与其他节点存在相互依赖的关系(存在边相连),而大部分节点都是孤立的,即大部分节点与其他全部节点都不存在相互依赖关系(没有边相连).对于孤立的节点来说,其在精度矩阵Θ中对应的行和列中的元素除对角元素非零外其他非对角元素全部都为0,例如如图2(a)所示,假设某无向概率图模型有4个节点n1、n2、n3和n4,其中节点n2与其他3个节点n1、n3和n4之间都不存在边相连,则对应的精度矩阵如图2(b)所示,其中×表示对应位置的元素非零,0表示对应位置的元素为零.已知式(1),双稀疏图套索要求解的问题为Θ^=argmax其中λ10,λ20,犛为样本协方差矩阵,且Θ1,q=∑L1范数罚Θ1的作用为实现边的稀疏,Θ1,q表示对精度矩阵Θ中第i行中除对角线元素外其他全部非对角线元素组成的向量进行Lq范数运算,其作用为产生孤立的节点,即实现节点的稀疏.显然,若令式(11)中的λ1=0,则可以得到双稀疏图套索的一种特殊情况:只使得节点稀疏的图套索;而若令式(11)中的λ2=0,则可以得到双稀疏图套索的另一种特殊情况:只使得边稀疏的图套索,即2.1节中的朴素图套索.必须指出,节点稀疏图套索在本质上就是将与某节点相连的所有边作为一个组并且令该组中的全部边同时存在或同时消失,因此节点稀疏图套索是组结构图套索的一种特殊形式.2.3.4局部共性图套索在有些情形下,概率图模型中相邻的节点之间往往具有某种共性,因而在对其进行稀疏化学习时也希望保留相邻节点之间的这种共性,Honorio等人[23]针对该问题提出对精度矩阵中相邻元素之差进行惩罚以学习出概率图模型中局部存在的共性,再叠加L1范数罚实现稀疏性.本文将该方法称作局部共性图套索,已知式(1),局部共性图套索要求解的问题为其中λ1>0,λ2>0,而其中“”运算表示矩阵之间对应元素的相乘即(犃犅)ij=aijbij.犑(犇)为对矩阵犇的Iverson括号算子,例如对于犇中位于第i行j列的元素来说其Iverson括号算子为Jij(犇)=[dij=0],该括号算子具体含义为当矩阵犇中的元素dij=0时则犑(犇)中元素Jij(犇)=1,否则Jij(犇)=0.矩阵犇的构造方法为:(1)若概率图模型中节点m与节点n相邻,则令矩阵犇第i行中dim=1和din=-1,同时令第i行中其他元素全部为0;(2)将第(1)步中的方法遍历全部相邻的节点,填满整个矩阵犇.该方法实际上是对精度矩阵中相邻元素之差进行惩罚,能够在实现稀疏化学习的同时揭示出概率图模型中相邻节点之间的共性.2.3.5小结与分析将稀疏化学习应用到概率图模型的学习中已经是某种意义上的结构稀疏化(图结构稀疏化),进一步地,若在图模型的稀疏化学习中边或节点在被置零时又具有某种结构化的特点,则称该问题为概率Page7图模型的结构稀疏化学习.概率图模型的结构稀疏化学习大都采用结构化的罚函数,结构化的罚函数是结构稀疏化学习的本质,其原理为事先假设对象具有某种稀疏化结构,然后将该稀疏化结构作为先验信息来构造稀疏化罚函数,进而进行结构稀疏化学习.结构稀疏化近年来一直是研究的热点,譬如近年提出的组套索(GroupLasso)[42]、组之间元素重叠的组套索(overlapGroupLasso)[43]和树结构组套索(tree-guidedGroupLasso)[44-45]等,但这些结构稀疏化的模型都是针对回归模型的,并不涉及概率图模型的结构稀疏化学习,未来将重叠组结构等其他结构化的罚函数引入到概率图模型的稀疏化学习中是非常有前景的研究方向.2.4概率图模型的多任务稀疏化学习假设有K个无向概率图模型犡(1),…,犡(K)犚Nk×P,其中Nk为关于第k个无向概率图模型犡(k)的样本数,P为随机变量数.令Θ个无向概率图模型犡(k)的协方差矩阵的逆矩阵,Θ^(1),…,Θ^(K)代表对Σ-1k=1,…,K.假设全部样本都是相互独立的,且同一个无向概率图模型对应的全部样本是独立同分布的:且假设μk=0,第犚个无向概率图模型犡(k)的样本协方差矩阵为珔犛(k),令{Θ}={ΘΘ基础上介绍各种多任务图套索.2.4.1多任务两两融合图套索(1),…,Θ多任务两两融合图套索[24]的罚函数为L1范数罚和两两融合罚[46-47](pairwisefusedpenalty)的组合,已知式(15),多任务两两融合图套索要求解的问题为{Θ^}=argmaxΘλ1Φ1(Θ其中λ1>0,λ2>0,且为横跨K个精度矩阵的L1范数罚,其作用为实现稀疏解,另一项Φ2(Θ(k1ij-Θ为两两融合罚,能够使得不同数据集对应的精度矩阵Θ^(k)=Σ-1据集对应的精度矩阵Θ^(k)=Σ-1一位置.2.4.2多任务有序融合图套索Yang等人(见本文第2页脚注①)利用有序融合罚对多个概率图模型进行多任务稀疏化学习,与多任务两两融合图套索不同,他们假设多个概率图模型之间是有序的,只对相邻的图模型施加有序融合罚[48](sequentialfusedpenalty).已知式(15),多任务有序融合图套索要求解的问题为{Θ^}=argmaxΘ其中λ1>0,λ2>0,且为横跨K个精度矩阵的L1范数罚,其作用为实现稀疏解;另一项Φ2(Θ为有序融合罚,其作用为促使相邻的概率图模型结构一致.另外,Zhang等人①也利用有序融合罚对概率图模型进行多任务稀疏学习,在对照实验(controlledexperiments)中,当某些实验条件变化时图模型的结构也会发生变化,Zhang等人利用L1范数罚叠加有序融合罚来对概率图模型的结构变化进行稀疏化学习,其中L1范数罚实现模型稀疏化学习,有序融合罚抑制噪声带来的结构和参数的不一致性,使得两次不同实验条件下的两个图模型的结构和参数平坦变化.2.4.3多任务组结构图套索多任务组结构图套索为L1范数罚与Lq,1范数罚的组合,已知式(15),多任务组结构图套索要求解的问题为{Θ^}=argmaxΘ其中λ1>0,λ2>0,∑的L1范数罚,其作用为实现稀疏解;当Θq,1为L2,1范数罚Θ2,1=∑①LearningstructuralchangesofGaussiangraphicalmodelsinPage8范数罚多任务组结构图套索[24];当Θq,1为L,1范数罚Θ,1=∑L,1范数罚多任务组结构图套索[24-25].L2,1范数罚和L,1范数罚能促使不同概率图模型对应的精度矩阵Θ^(k)=Σ-1此外,Guo等人[49]针对概率图模型的多任务Kk=1学习提出了一种具有两层结构的罚函数λ1∑i≠jλ2∑i≠j∑(k)ij,其中i≠j且i,j∈{1,…,P},k=1,…,K.该θijγ罚函数相当于在两层水平上进行稀疏学习:θij若非零(为零)则全部K个概率图模型中的节点i与j之间均存在(不存在)一条边,此为第一层水平上的稀疏学习;在θij非零的前提下,γk个概率图模型的节点i与j之间存在(不存在)一条边,此为第二层水平上的稀疏学习.显然,θij的作用为促使各概率图模型间具有类似的结构,而γ的作用为促使各概率图模型在某种程度上还具有自己独有的特性.另外还有研究指向一种较为特殊的多任务稀疏化学习问题———随机变量所服从的概率分布随时间变化的概率图模型的多任务稀疏化学习表1概率图模型的各稀疏化学习方法比较早被提出的概率图模型稀疏化学习方法的稀疏化学习,本质为矩阵的低秩稀疏分解解P个独立的L1范数罚逻辑斯蒂回归问题通过使用无偏SCAD罚实现无偏稀疏化学习L1范数罚稀疏化学习无偏稀疏化学习结构稀疏化学习问题[50-52].2.4.4小结与分析概率图模型的多任务稀疏化学习方法主要采用两种罚函数:一种为融合罚,包括两两融合罚和有序融合罚,前者对全部元素两两之间的差的绝对值都进行惩罚,而后者则假设元素是有序的,只对前后相邻的两个元素之差的绝对值进行惩罚;另一种为L1,q范数罚,包括L2,1范数罚和L,1范数罚.当有多个结构上具有某种共性的概率图模型需要进行稀疏化学习时,若对这些概率图模型分别独立进行稀疏化学习则无法揭示其内在的联系,所以必须对这些概率图模型联合进行稀疏化学习以揭示出其内在共性,此即图模型的多任务稀疏化学习.3概率图模型的稀疏化学习中常用的求解算法概率图模型稀疏化学习本质上是一个最优化问题,该最优化问题由两部分组成:似然函数和正则化项,不同概率图模型的稀疏化学习对应的优化问题的求解算法不同,各求解算法适用的条件也不尽相同,如表1所示.各自特点Page9多任务稀疏化学习模型对应的精度矩阵具有类似的稀疏结构高斯无向图图套索是第一种被提出的概率图模型的稀疏化学习方法,因此研究其求解算法的文献较多,其求解算法有组坐标下降方法[5,53-54](BlockCoordinateDescentMethod)、非精确内点算法[55](InexactInterior-PointMethod,IIPM)、投影子梯度方法[21](ProjectedSubgradientMethod)、贪心坐标上升算法[56](GreedyCoordinateAscentApproach)、交替线性化方法[57](AlternatingLin-earizationMethods)和二次近似算法[58](QuadraticApproximation).高斯无向图图套索对应的优化问题实际上是一个对数行列式半定规划问题(logdetermi-nantSemidefiniteProgrammingProblems,log-detSDP),但由于该问题往往是高维甚至超高维的,因此传统的半定规划求解算法(如SDPT3[59]和SeDuMi[60])并不适用.针对该问题,文献[55]给出了一种非精确内点算法(InexactInterior-PointMethod,IIPM)来求解该半定规划问题,该非精确内点算法在确定搜索方向时为了减少算法的空间复杂性和时间复杂性,通过非精确方式(数值迭代)求得搜索方向的近似替代公式,因此该非精确内点算法非常适用于处理高维的概率图模型稀疏化学习问题.Duchi等人[20]将高斯无向图图套索的优化问题进行对偶变换,然后利用投影子梯度法求解其对偶问题.组坐标下降算法的前身是坐标下降算法,该算法在求解优化问题时每次只涉及单个坐标块,同时令其余全部坐标块保持不变,因此大大简化了优化问题.文献[5]中利用组坐标下降算法求解概率图模型稀疏化学习对应的优化问题时,每次更新精度矩阵中的第i行和第i列(精度矩阵为对称矩阵,其第i行和第i列中元素相同),即固定精度矩阵中的其他全部元素的同时,只关于精度矩阵中的第i行和第i列求解优化问题.显然,该方法将复杂的多维优化问题转化为容易求解的低维优化问题,文献[5]中给出的求解高斯无向概率图模型的稀疏化学习对应的优化问题的算法中,将多维优化问题转化为每次求解一个L1正则化问题,可以直接利用套索(Lasso)的各种高效解法(例如最小角回归算法)来求解该L1正则化问题.各自特点但值得注意的是该方法得到的精度矩阵可能不是对称的,尤其在正则化参数被选定为较小的数值时非对称性更加明显[55],而精度矩阵的非对称性会造成负的特征值,给后续应用主成分分析等分析方法造成了困难.因此,文献[61]中给出了解决精度矩阵非对称问题的方法,例如可以根据得到的精度矩阵的上三角部分转置后作为下三角部分,同时上三角部分保持不变,从而把非对称精度矩阵转化为对称精度矩阵.(块)坐标下降算法是求解概率图模型稀疏化学习对应的优化问题的最广泛的解法,文献[62]中还利用组坐标下降算法对协方差矩阵而不是其逆矩阵进行稀疏学习.Scheinberg等人[56]提出一种贪心坐标上升算法,该算法直接对高斯无向图图套索的优化问题求解,不像Friedman等人[5]的组坐标下降算法和Duchi等人[20]的投影子梯度算法等算法那样求解其对偶优化问题;另外,该算法在每次迭代中只关于精度矩阵中的一个对角元素或两个对称的非对角元素求解优化问题,不像Friedman等人的组坐标下降算法那样每次迭代时关于精度矩阵中对称的一行和一列求解优化问题.交替方向乘子法[63]也是求解图套索问题的一种重要算法,其一般要求解的优化问题形式为其中狓∈犚n,狕∈犚m,犃∈犚q×n,犅∈犚q×m,犮∈犚q,写出其增广拉格朗日函数为Lρ(狓,狕,狔)=f(狓)+g(狕)+狔T(犃狓+犅狕-犮)+因此其求解步骤一般如下:其中ρ>0.Scheinberg等人[57]提出一种交替线性化方法,该方法实际上是一种交替方向乘子法的改进方法,与交替方向乘子法的不同之处在于该方法在每次迭代时都在当前点处将函数g(狕)替换为一Page10个一阶线性项与另一近似项之和,而且每次迭代时求解的子问题都具有显式解.Hsieh等人[58]提出一种二次近似(QuadraticApproximation)算法,该方法同时结合了二次近似、牛顿方法和坐标下降的思想,其首先利用二阶泰勒展开公式对原优化问题的目标函数进行二次近似,然后利用坐标下降方法和Armijo规则分别得到牛顿下降方向和步长,故该方法为二阶方法,而且具有超线性收敛(superlinearlyconvergent)的特点.其他概率图模型稀疏化学习对应的优化问题的求解算法如下所述.Ye等人①利用划分Bregman方法(SplitBregmanMethod)[64]求解部分变量不可观图套索,该方法通过引入辅助变量解决部分变量不可观图套索的目标函数中变量不可分离的问题,并且收敛速度快.Liu等人[18]将幂法则图套索对应的优化问题等价地转化为一系列再权L1范数正则化(reweightedL1regularization)问题,然后利用MM算法[65](Majorize-Minimizationalgorithm)求解该问题,该方法用求解一系列近似子问题来逼近原目标优化问题.Yang等人(见本文第2页脚注①)利用谱投影梯度法[66]求解多任务有序融合图套索,谱投影梯度法是对投影梯度算法的改进,主要用于克服前者收敛速度慢的缺点.投影梯度算法存在两方面的问题:一是每次选择最速下降方向会导致收敛速度变慢;二是投影步骤的计算复杂度过高.谱投影梯度法在迭代过程中采用非单调线搜索技术,不要求每次迭代后目标函数值都下降,只要求在规定的最近某些次迭代目标函数下降即可,并且结合谱梯度法的Barzilai-Borwein步长来选择谱投影梯度法在迭代过程中的步长.谱投影梯度法适用于投影步骤计算高效的情形,因此投影步骤的计算方法非常关键.文献中已有的概率图模型的稀疏化学习对应的优化问题的求解算法如表2所示,值得指出的是SCAD图套索在应用组坐标下降算法前需要对其目标函数中的SCAD罚函数进行局部线性近似[67](LocalLinearApproximation,LLA),具体说来就是在已知点w0将SCAD罚函数pλ,a(w)用如下的近似表达式表示:pλ,a(w)≈pλ,a(w0)+pλ,a(w0)(w-w0)其中pλ,a(w)=套索的求解需要利用吉布斯抽样(Gibbssampling)方法,文献[24]中利用交替方向乘子法求解多任务两两融合图套索和多任务组结构图套索,而L,1范数组结构图套索的求解算法利用了投影子梯度法[20],文献[11]中利用组坐标下降算法求解有向无环图图套索.值得指出的是,伊辛模型图套索的求解利用了邻域选择方法[26](neighborhoodselectionmethod),该方法在对伊辛模型稀疏化学习时依次将每个随机变量作为输出变量而其余全部随机变量作为自变量,即转化为利用套索求解关于一系列回归模型的变量选择问题.各算法的特点如表3所示.表2文献中提出的对概率图模型稀疏化学习的求解算法稀疏化学习方法高斯无向图图套索部分随机变量不可观图套索划分Bregman方法有向无环图图套索伊辛模型图套索SCAD图套索自适应图套索贝叶斯自适应图套索幂法则图套索L,1范数组结构图套索LF,1范数组结构图套索双稀疏图套索局部共性图套索多任务两两融合图套索多任务有序融合图套索多任务组结构图套索表3概率图模型稀疏化学习的求解算法的特点算法组坐标下降算法非精确内点算法投影子梯度法贪心坐标上升算法二次近似算法交替方向乘子法交替线性化方法吉布斯抽样方法MM算法划分Bregman方法谱投影梯度法①EfficientlatentvariablegraphicalmodelselectionviasplitPage11文献[58]中对求解高斯无向图图模型的各种算法进行了比较:(1)实验数据为人工产生的链图,其精度矩阵为:非对角元素为Θi,i-1=0.5且对角元素为Θi,i=1.25.设定算法迭代的停止条件为ε=10-6且可调参数λ=0.4时的实验结果如表4所示,其中P表示随机变量个数;(2)实验数据为人工生成的随机稀疏图(随机产生的具有一定稀疏结构的概率图模型),设定算法迭代的停止条件为ε=10-6时的实验结果如表5所示,其中P表示随机变量个数.从表4和表5可以看出,在该实验中二次近似算法在六种算法中最快,而贪心坐标上升算法非常慢,交替线性化方法对于本实验中生成的链图来说速度较快而对于随机稀疏图来说速度很慢;投影子梯度方法与组坐标下降算法速度适中,非精确内点算法比投影子梯度方法和组坐标下降算法慢一些.表4和表5中的“-”表示迭代时间超过30000s.表4求解高斯无向图图套索优化问题的算法比较(链图)二次近似算法非精确内点算法投影子梯度方法组坐标下降算法贪心坐标上升算法交替线性化方法算法二次近似算法非精确内点算法投影子梯度方法组坐标下降算法贪心坐标上升算法交替线性化方法4存在的问题与未来研究方向4.1存在的问题虽然概率图模型的稀疏化学习问题近年来得到了广泛研究,但仍然存在大量需要研究的问题.例如,目前概率图模型的无偏稀疏化学习只利用了无偏的SCAD罚,然而还有许多种无偏罚未被考虑,例如p∈(0,1)时的Lp范数罚、MCP罚[68]和截断L1罚[69].目前对概率图模型中随机变量服从负二项分布、均匀分布和指数分布等诸多分布时的稀疏化学习缺乏研究.概率图模型的结构稀疏化学习当前也只涉及到组结构而并未涉及近年来新提出的重叠组结构和树组结构.许多概率图模型的稀疏化学习方法被陆续提出,但人们往往只是给出了一种稀疏化学习方法,忽视了该稀疏化学习方法的统计性质的讨论(参数估计一致性等).在算法方面,概率图模型对应的优化问题的求解还未考虑过具有低计算复杂度、小的存储空间和对数据较强的适应能力的在线学习算法.4.2未来研究方向4.2.1新的无偏稀疏化学习方法将SCAD罚用于无向概率图模型的稀疏化学习中得到的SCAD图套索具有无偏估计的特点,未来将p∈(0,1)时的Lp范数罚、MCP罚和截断L1罚等其他可实现无偏估计的非凸罚应用到无向概率图模型的稀疏化学习中是否会比SCAD图套索的稀疏化学习效果更好?这都是值得研究的问题.4.2.2将概率图模型的稀疏化学习方法在其他概目前概率图模型的稀疏化学习问题逐渐从最初的无向高斯图模型向着有向、非参数和随机变量服从其他分布的方向发展,该研究方向尚有大量需要完成的工作,例如,随机变量服从均匀分布和指数分布等诸多分布下的概率图模型的稀疏化学习问题尚未有学者进行研究,而且将可实现无偏估计的SCAD、MCP罚和截断L1罚应用到这些概率图模型下进行无偏稀疏化学习的问题尤其值得研究.4.2.3拓展概率图模型的结构稀疏化学习本文中所述Lq,1范数组结构图套索对精度矩阵中元素利用了L2,1范数罚,双稀疏图套索对精度矩阵中的元素施加了L2,1范数罚和L1范数罚,此两种结构化的罚函数均为组之间不具有重叠元素的罚函数,如何将具有重叠组结构的罚函数应用到概率图模型的结构稀疏化学习中是一个有待于解决的问题.另外,组结构图套索和双稀疏图套索由于利用了不可实现无偏估计的L2,1范数罚和L1范数罚,所以其一致性等性质不好,而利用结构化的复合非凸罚函数则可解决该问题,复合组桥罚[70]和复合MCPage12罚[71]是两种典型的结构化复合非凸罚函数,猜想将该两种罚函数引入到概率图模型的结构稀疏化学习中会解决上述问题,但遗憾的是尚无学者对该问题进行深入研究.4.2.4概率图模型稀疏化学习方法的统计性质虽然目前有很多形式的图套索被陆续提出,但其统计性质仍然缺少理论上的论证,例如,双稀疏图套索的一致性等统计性质有待于理论上的研究和证明,将邻域选择方法应用到泊松图模型中进行稀疏化学习时泊松图模型重建的一致性和模型参数估计的一致性未被论证,局部共性图套索的模型选择一致性未被研究,该方面仍有大量的理论工作需要完成.4.2.5向在线学习领域推广在线算法以低计算复杂度、小的存储空间和对数据较强的适应能力而被广泛应用,目前套索的在线算法[72-75]和组套索[76]的在线学习算法已经被提出并且在实践中验证了其优势,未来图套索及其各种变种的在线学习算法是很有意义的研究方向.5结语国内已经有学者研究稀疏学习优化问题[77],而国外稀疏学习研究逐渐从单纯的无结构稀疏学习发展到各种结构化的稀疏学习,其中概率图模型的稀疏学习是近年来研究的热点之一.经过稀疏学习后的概率图模型结构简单却保留了原始概率图模型的重要结构信息,大大简化了概率图模型的结构,同时实现了结构和参数学习,未来概率图模型的稀疏化学习势必在机器学习等领域中发挥越来越重要的作用.
