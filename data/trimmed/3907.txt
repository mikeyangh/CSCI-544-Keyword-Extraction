Page1面向用户观点分析的多分类器集成和优化技术林煜明朱涛王晓玲周傲英(华东师范大学软件学院上海市高可信计算重点实验室上海200062)摘要网络上用户生成的数据(User-GeneratedData)富含用户的观点(情感),自动识别这些用户观点对很多的Web应用具有重要的作用,例如推荐系统和电子商务/政务智能系统等.但用户的观点表达通常与领域是相关的,因此对于不同的分析领域,用户难以选择到效果最好的分类器.文中针对用户观点分析问题设计了一个三阶段的多分类器集成框架,在此框架下用户只需指定可用的分类器,系统将自动选择一组最优的分类器组合,将它们的预测结果整合为最终分类结果,同时能够保证分类效果优越于最好的单分类器.针对分类器组的选择过程中面临的组合爆炸问题,文中在考虑分类器的准确度和多样性的基础上,设计了一个贪心算法选择成员分类器,并证明该算法是2-近似的.最后,在不同领域的真实数据集上进行了充分的实验,实验结果验证了文中提出的框架和算法的有效性.关键词观点分析;集成学习;分类准确度;多样性;近似算法1引言随着Web2.0技术的普及与发展,越来越多的用户喜欢通过各种社交平台(如微博、论坛、评论网站等)浏览、发布和转发消息.这些富含用户观点的用户生成数据(User-GeneratedData,UGD)在网络上逐步占据主导地位,也是网络上口碑(WordofMouth,WOM)形成的主要依据,对企业和用户的决策制定具有重要的参考价值.2011年美国Cone公司的调查①指出64%的用户会通过阅读商品的相关评论了解商品信息,87%的用户在阅读了肯定的评论后做出了购买的决定,而80%的用户在阅读了否定的评论后放弃了购买的意向.因此,有效识别用户对目标对象持有的观点(情感)对很多现实应用具有重要的意义,如推荐系统、网络舆情监控、电子商务/政务系统等.观点分析也称为情感分类、观点挖掘,它的主要目标是识别用户的观点倾向.目前该领域的研究主要集中在识别两类观点[1-6]或三类观点[7-9]:肯定的(positive)、中性的(neural)和否定的(negative).在采用机器学习的方法进行观点分析时,当用户确定特征类型、特征加权方法和分类方法时,就构成一个概念上的分类器.在此基础上通过标注样本对此概念分类器训练则生成一个分类器实例(以下简称分类器),但由于构成分类器的3种基本因素的可选项很多,而且对于不同的分析领域,效果最优的分类器通常是不同的,这使得用户难以做出选择.文献[4]中的实验结果也验证了这一结论.多分类器集成的方法是解决该问题的有效途径.文献[4,10-11]在预先确定的特征类型、加权方法和分类算法的基础上通过标注样本集训练不同的分类器,将这些分类器的预测结果通过不同的策略整合为最后的预测结果,但并未解决如何选择分类器的问题.文献[12]设计了一个基于分类器的准确度和多样性进行选择的目标函数,通过最大化该目标函数值选取分类器,但面临着组合爆炸问题.本文在用户指定可用的特征类型、特征加权方法和分类算法基础上自动选取一组最优的分类器,通过集成学习的方法将这些分类器的结果整合起来.这种方法的效果比最好的单分类器方法更佳.相对于以往的工作,本文具有如下贡献:(1)提出一个三阶段的多分类器集成学习框架,该框架能够自动选择一组优化的分类器,利用这些分类器的预测结果进行二次学习得到集成分类器,通过该集成分类器将成员分类器的预测结果进行最终的整合;(2)设计了一个基于分类器准确度和多样性的分类器组选择贪心算法,并证明了该算法是2-近似的,从而避免了由组合爆炸导致的算法在实际应用中不可用的问题;(3)在多个领域的真实数据集上进行充分的实验,实验结果表明文中提出的分类器选择算法和多分类器集成框架具有良好的效果,并从实验上对比了两种不同的集成方法的性能.本文第2节介绍相关工作;第3节详细叙述提出的多分类器集成框架和成员分类器的选择算法;第4节通过实验验证文中提出方案的有效性;最后,第5节进行总结.2相关工作观点分析以往的研究主要是集中于机器学习的方法.文献[1]首次将机器学习的方法应用于电影评论的观点分析,文中对比了不同的特征类型(unigram、bigram、POS),特征加权方法(频率、出现与否)和分类算法(朴素贝叶斯分类器、最大熵分类器、SVM(SupportVectorMachine))组合的分类结果,其中通过频率在unigram上加权,使用SVM分类取得的效果最好.本文的分类器主要也是基于上述因素构成.文献[13]针对观点分析问题比较了经典的TFIDF(TermFrequency-InverseDocumentFrequency)及其变体的作用,并指出文本中的情感信息有助于提升情感分类的效果.与此类似,文献[14]提出了一种专门用于观点分析的特征加权方法———ΔTFIDF,与TFIDF不同的是它利用了特征在肯定文档和否定文档中出现的次数差异信息.文献[15]中通过特征与情感极性标签的互信息确定特征的情感分值,从而更准确地捕获到文本中特征的情感信息,进一步提高了分类的准确度.这两种特征加权方法在本文实验中也将作为确定分类器时的备选加权方案.多分类器的集成学习(ensemblelearning)[16]利用多个分类器可以获得比仅用一个分类器更强的泛化能力.文献[10]利用在不同领域的标注实例上训练①http://www.conecomm.com/2011coneonlineinfluencetrend-Page3分类器,再通过这些分类器的预测结果训练下一级的分类器,从而实现评论的观点分类.文献[11]在实验上对比了情感分类中不同的分类器集成技术.文献[10-11]都是在预先确定的分类器上进行集成,并未解决如何选择这些分类器的问题,而分类器的选择对最终的分类结果具有很大的影响.文献[12]中针对分类器的选择问题进行了探讨,当备选的分类器数量较少时,这种方法能够有效地选择最优的分类器组合,但是当可选分类器的数量增多时,该方法将面临着组合爆炸的问题,而本文设计了具有2-近似的贪心算法进行分类器选取,从而大幅度地降低了时间复杂度.图1三阶段的多分类器集成学习框架3.1概念分类器的训练给定一个特征类型集F={fi|i=1,…,NF}、加权方法集W={wj|j=1,…,NW}以及分类方法集C={ck|k=1,…,NC},其中NF、NW、NC分别是可选的特征类型数、加权方法数和分类方法数,由这3种基本因素就构成了一个概念上的分类器Cfi,wj,ck.在文本分类中,特征除了常用的unigram、bigram等之外,还可以通过信息增益(InformationGain)、互信息(MutualInformation)、χ2统计和词语的强度等方法选定[17].观点分析中常用的特征加权方法包括特征出现的频率、特征出现与否(0/1)、ΔTFIDF等,这些加权方法的效果随着分析领域的变化而有所不同.SVM由于其良好的性能,常被用于观点分析,如文献[1,4,8-9,13],但通常单一分类器具有各自局限性,其它分类方法(如最大熵分类、决策树分类等)的预测结果有可能作为SVM的补充,因此在多分类器集成学习的集成学习框架中,我们并不仅局限于使用SVM.如上所述,本文提出的框架中用户只需要指定可选的概念分类器,然后使用标注的样本训练得到多个备选的分类器实例.3基于分类器最优组合的集成学习针对用户面临的分类器选择困难问题,我们提出一个三阶段的多分类器集成学习框架,如图1所示.该框架主要包括:概念分类器的训练阶段、分类器组合的选择阶段和集成学习阶段.首先通过标注样本训练所有可用的概念分类器得到分类器,然后在这些分类器中选择最优的分类器组合,最后以分类器组合的预测结果作为标注样本来训练一个集成分类器.3.2最优分类器组的选择在机器学习关于分类的文献中,可以找到大量的分类器,这些分类器中每个都具有自身的特点和针对性,并不存在一个分类器能在所有领域中效果都是最佳的.而集成学习利用多分类器可获得比仅使用单一分类器更强的泛化能力.对于多分类器的集成,选择哪些分类器成为了一项非常重要的任务.通常认为有效地产生泛化能力强、分类器间差异大的成员分类器是集成学习算法的关键[18].用于集成的成员分类器并非越多越好,因为随着成员分类器数量的增多,它们之间的差异性就会越来越小.因此需要有效的方法选择最佳的成员分类器组合,本文从分类器的准确度和分类结果多样性的角度出发进行成员分类器的选取.假设选取k个成员分类器,可选的分类器集合D={Ci|i=1,…,N},A(Ci)表示分类器Ci的准确度,1-κ(Ci,Cj)表示分类器Ci和Cj间分类结果的差异度,其中κ(Ci,Cj)为Ci和Cj分类结果的Fleiss-Kappa值[19],则选择的成员分类器集合S应该满足Page4Ψ(S)=λ∑Ci∈S其中λ(0λ1)为调整准确度和多样性权重的参数.当可选的成员分类器数量增多时,可能的分类器组合数急剧增长,使求该目标函数的最优解变得不可行,因此文中设计一个贪心算法求近似解.设集合S∩G=且S,GD.为了叙述方便,令dist(Ci,Cj)=1-κ(Ci,Cj).定义集合的多样性函数为dist(S)=∑Ci,Cj∈S∑Ci∈S,Cj∈GCu∈D-S,distCu(S)=∑Cv∈SA(Cu)分别为加入分类器Cu后分类器集合S的多样性增益和准确性增益,则ΨCu(S)=λACu(S)+(1-λ)distCu(S)为加入分类器Cu后总的增益.根据式(1)和(2)的目标函数,我们设计的选择成员分类器组的贪心算法CSGA如算法1所示.算法1.ClassifierSelectionGreedyAlgorithm(CSGA).输入:可选分类器集合D,选择的分类器数k,权重参数λ输出:被选分类器的集合S1.S=;2.WHILE(|S|<k)DO3.从D-S中选择分类器Cu,使式子λ4.S=S∪{Cu};5.ENDWHILE6.RETURNS.接下来我们算法CSGA是2-近似的,为此首先给出以下定义.定义1.单调性(monotonicity).函数f:2V→R是单调的,若任意ABV都满足f(A)f(B).定义2.次模性(submodularity).函数f:2V→R是次模的,若任意ABV且e∈V\B都满足f(A∪{e})-f(A)f(B∪{e})-f(B).令Φ(S)=λ∑Ci∈S定理1.函数Φ(S)具有单调性和次模性.证明.任意集合TGS,有Φ(T)=A(Ci),Φ(G)=λ∑Ci∈Gλ∑Ci∈T=λA(Ce)-λA(Ce)=0.器Ci的准确度,A(Ci)0且TG,所以Φ(T)Φ(G).根据定义1可知Φ(S)是单调的.任意集合TGS,Ce∈S\G,设T=T∪{Ce},G=G∪{Ce},则(f(T∪{Ce})-f(T))-(f(G∪{Ce})-f(G))(=λ∑Ci∈T(λ∑Ci∈G根据定义2可知Φ(S)是次模的.证毕.由文献[20]可直接得出以下结论.引理1.给定两个不相交集合G、S和距离函数dist,则(|G|-1)dist(G,S)|S|dist(G)成立.假设O是最优的分类器组合,S是由算法CSGA得到的近似解,Si是CSGA第i(i<k)次循环后得到的解,设A=O∩Si,B=Si-A,C=O-A,则A、B和C是两两不相交的集合.为叙述方便,我们将λ2∑Ci∈SA(Ci)记为Φ(S).类似文献[21],下面证明CSGA算法是2-近似的.证明.当k=1时,显然CSGA的解就是最优解.若|C|=1,则i=k-1且SiO.设Cu为下一次循环选择的分类器,则对任意的Cv∈D-S,有由此可知ΨCu(Si)=λACu(Si)+(1-λ)distCu(Si)因此Ψ(S)1当k>1且|C|>1时,由引理1可得(|C|-1)dist(B,C)|B|dist(C)dist(B,C)|B|(|C|-1)dist(A,C)|A|dist(C)|C|-|B|(|A|-1)dist(A,C)|C|dist(A)Page5i(|A|-1)k(k-1)dist(A,C)i|C|由O=A∪C,A∩C=得dist(A,C)+dist(A)+dist(C)=dist(O)i|C|k(k-1)(dist(A,C)+dist(A)+dist(C))=i|C|k(k-1)dist(O)由式(3)+(4)+(5)+(6)结合|A|=k-|C|和|A|+|B|=i得dist(A,C)+dist(B,C)-i|C|(p-|C|)i|C|k(k-1)dist(O).由k>|C|且dist(A,C)+dist(B,C)=dist(Si,C),所以有dist(Si,C)i|C|类似定理1可证ΦCu(S)=λ和次模的,因此有∑Cv∈CΦCv(Si)Φ(C∪Si)-Φ(Si)Φ(O)-Φ(S),则有ΨCv(Gi)=∑Cv∈C∑Cv∈C=∑Cv∈CΦCv(Si)+(1-λ)dist(C,Si)(Φ(O)-Φ(S))+(1-λ)i|C|设Cu是第i+1步选择的分类器,则有ψCu(Si)1因此Ψ(S)=∑k-1由此可得Φ(S)+(1-λ)dist(S)根据上面的证明可得知算法CSGA是2-近似的,而且2是近似的上界,我们后面的实验表明在观点分析实验中由CSGA算法得到的目标函数近似值非常接近最优值.3.3时间复杂度分析假设需要从n个可选的成员分类器中选择k个分类器构成最佳的分类器组合,一般情况下n都远大于k.当选择的分类器数k是固定常数时,如果采用穷举法搜索,则需要比较每一种可能组合的目标函数值,这种情况的时间复杂度为O(nk).如果采用文中提出的贪心算法CSGA,进行第i(1ik)次选择分类器时,则需要进行n-i+1次比较,因此算法CSGA的时间复杂度为O(n).由此可见,算法CSGA具有线性的时间复杂度,这使该算法可在实际中应用.3.4基于Stacking技术的多分类器集成采用选定的一组成员分类器对测试样本进行预测后,需要对多个成员分类器的预测结果进行集成.最直观的方法就是投票,但投票的方式无法纠正那些大部分分类器都错分的样本的预测结果.文中采用基于Stacking技术[22]的集成学习方法,该方法将分类器的预测结果作为训练样本进行二次学习生成一个集成分类器,具体过程如算法2所述.首先将训练的样本集划分成大小不等且不相交的两部分T1和T2(|T1||T2|,第1行);为了使成员分类器具有好的泛化能力,将T1用于训练成员分类器(第4行);使用成员分类器对T2中标注样本进行预测,得到的预测结果结合样本的真实标签构成新的训练样本(第6行);最后用这些新的训练样本训练一个集成分类器Cassembling(第9行).算法2.AssemblingClassifiersbyStacking(ACS).输入:被选分类器的集合S,标注数据集T输出:集成分类器Cassembling1.将T划分为T1和T2两个集合,|T1||T2|;2.Tmeta=;3.FORi=1TO|S|Page64.使用T1的数据训练分类器Ci(Ci∈S);5.FORj=1TO|T2|6.Tmeta=Tmeta∪{(Ci(tj),ltj)};//tj∈T27.ENDFOR8.ENDFOR9.使用Tmeta中的样本训练集成分类器Cassembling;10.RETURNCassembling.对于未标注样本的预测,则首先将成员分类器对每个未标注样本的预测结果形成新的未标注样本,然后将该新样本作为集成分类器Cassembling的输入,从而得到来标注样本的最终预测结果.应该注意的是,由于ACS算法需要训练集成分类器,因此只能用部分标注样本训练成员分类器,而投票的方式则是使用所有的标注样本来训练成员分类器,这可能会导致ACS算法中成员分类器比投票方式的成员分类器效果稍差,但这些下降的性能会在ACS算法中的第二阶段学习中得以补偿.此外,为了使集成分类器得到更多的训练样本,在生成集成分类器的训练样本时可以采用交叉验证的方法.4实验本节在真实的数据集上针对多个不同领域的评论进行一系列的观点分析实验,以验证本文提出方法的有效性.4.1实验设置本文将Amazon①上的评论作为观点分析的对象,包括4类商品:书籍(B)、厨房用具(K)、电子产品(E)、DVD(D).将4星和5星的评论作为肯定的评论,1星和2星的评论作为否定的评论,由此可得到关于每类商品的肯定和否定评论各1000个②.文中对评论做了以下预处理:过滤所有的标点以及出现次数少于5的词(仅对unigram而言);由于我们采用的一些特征加权方法需要考虑词的情感因素,因此将所有单词转为小写;将类似don’t的否定词删除,为位于否定词和后面第一个标点之间的每个词加上标记“not_”,例如句子“Itdoesn’tworksmoothly”将变为“Itnot_worknot_smoothly”.特征类型采用观点分析中最常用的unigram、bigram以及这两者的混合.特征的加权方法包括频率、出现与否、ΔTFIDF和文献[15]中提出的方法.简单起见,对于最后两种加权方法文中只考虑unigram.分类算法采用最大熵分类、朴素贝叶斯分类以及SVM.通过上述3种因素的不同组合训练可得到24个成员分类器.值得注意的是,文中提出的是一个通用的框架,并不局限于上述特征类型、特征加权方法和分类算法,其它类型和方法都可以方便地整合到此框架中.文中的集成分类算法采用最大熵分类③,通过5折交叉验证的方法进行二次学习时的训练样本生成和观点分析实验.4.2实验结果和分析本文采用多分类器集成学习来解决用户难以选择分类器进行观点分析的问题.首先使用文中提出的CSGA贪心算法选择一组分类器,然后将这组分类器的预测结果通过算法ACS整合为最后的预测结果.投票的方式是最常用的多分类器集成方法,因此文中将其与算法ACS进行比较,以此来验证算法ACS的有效性.另一方面,为了验证文中提出的方法在不同的分析领域中都能发挥好的效果,我们针对4.1节中提到的多个不同领域的评论进行实验.图2给出在不同的领域中情感分类准确度的比较,图例说明如下:(1)avg_single表示24个分类器的平均预测准(2)best_single表示最好的单分类器预测准(3)random_ACS表示随机选择一组成员分类(4)CSGA_voting表示使用CSGA算法选择成(5)CSGA_ACS表示使用CSGA算法选择成器后使用ACS算法集成;员分类器组合后通过投票的方式进行集成;员分类器组合后通过ACS集成分类的结果.确度;确度;如果没有特别说明,在本文后面的实验中默认选择的成员分类器个数为5,调整准确度和分类结果多样性权重的参数λ取值为0.8(对于DVD评①②③Page7论,λ=0.9).如图2所示,采用多个分类器集成的方法比单分类器方法对于所有领域在分类准确度上都有较大的提高,应当注意的是通常情况下用户很难选择到分类效果最好的分类器,而文中提出采用多分类器集成方法的效果在不同的分析领域都优越于最好的单分类器方法.另一方面,对于使用ACS算法集成的两种途径,随机选择分类器组合方法的准确度低于使用CSGA算法选择成员分类器的方法,这说明CSGA算法能够选出更好的成员分类器.此外,对于CSGA算法选择的分类器组合,在大多数情况下通过ACS算法集成比通过投票方式集成的效果好,除了在厨房用具领域,两种集成方法的效果基本一致.这可能是由于对于此领域中的数据,单分类器的性能都比较高,成员分类器的分类结果间差异性不大,因此两者的效果相差不大.但对于单分类器性能不是很高的领域,例如书籍和DVD的评论,通过ACS算法集成的准确度比投票的准确度有较大的提升.文中在选择分类器成员时主要考虑分类器的准确度和分类结果的多样性,这两者之间通过参数λ调整各自的比重.下面分析不同领域中在采用CSGA的基础上分别通过ACS和voting进行集成时λ对分类准确度的影响.如图3和图4所示,对于两种集成方法在所有领域中,当λ为0.8或0.9时分类的准确度达到最高值.这意味着λ值比较稳定,方便用户的设定.这也是文中算法的优点之一.同时由此也可以看出在选择成员分类器时应该更侧重于准确度.从图3和图4都可以看出仅仅从准确度的角度(λ=1)或只从多样性的角度(λ=0)出发选择成员分类器都并非最佳方案.另一方面,λ=1时的实验结果也说明了效果最好的单分类器上与其它分类器构成的组合的最终分类效果均差于同时考虑准确度和多样性时分类器组合的效果.由此可见,不管采用什么样的集成方法,准确度和多样性都在选择成员分类器时发挥着重要的作用,因此我们的目标函图3使用ACS集成时λ对分类准确度的影响数从这两者出发选择分类器是合理的.图4使用voting集成时λ对分类准确度的影响接下来分析成员分类器的数量对分类准确度的影响.使用ACS算法进行多分类器的集成时分类器数量对最终分类准确度的影响如图5所示,在所有的领域中,成员分类器数量从3增加到7时并未使分类效果发生大的变化(变化范围在1%内).这是因为成员分类器数量的增多使得它们间的差异性会越来越难以获取,因此分类的效果也不会发生大的变化.当采用投票的方式进行集成时,由图6可以看出成员分类器数量对最后预测的准确度影响较大(在所有领域中变化范围均大于1%).从这个角度看,使用ACS算法进行集成要优越于使用投票的方式进行集成.图5使用ACS集成时分类器个数对分类准确度的影响图6使用voting集成时分类器个数对分类准确度的影响衡量近似算法的一个最重要的指标就是近似率(最优值/近似值).文中根据式(2)计算出24个分类器中所有5个分类器组合的值,选择其中的最大值作为最优值.表1给出4个领域中采用不同λ值时Page8CSGA算法选出的成员分类器组合对应近似值的近似率.在3.2节我们证明了CSGA算法是2-近似的,但应该注意的是2是上界.表1中的实验结果表明,在本文的观点分析实验中CSGA算法选择的成员分类器组对应的目标函数值非常接近最优值,进一步说明了文中提出的贪心算法是有效的.如前所述,当λ为1.0时分类器的选择只考虑准确度,由式(2)不难看出这时的近似解就是最优解.λ1.01.001.001.001.000.91.011.011.001.000.81.011.011.001.010.71.021.011.001.010.61.031.021.011.010.51.031.021.011.020.41.041.031.011.020.31.051.041.011.020.21.051.051.021.030.11.061.051.021.030.01.071.061.021.045总结用户生成的内容在Web数据中占据的比重越来越大,这些内容富含用户的观点信息,自动识别这些内容中包含的用户观点是很多智能应用系统的关键环节,也是目前的研究热点之一.传统的方法通过在选定的特征类型、加权方法和分类算法的基础上训练分类器,但对于不同的分析领域,效果最佳的分类器通常不固定.因此用户难以选择到效果最佳的方案,特别是对于领域知识缺乏的用户.本文针对用户观点分析中用户对分类器难以选择的问题,提出一个三阶段的多分类器集成学习框架,在该框架中用户只需指定可用的特征类型、特征加权机制和分类方法,由系统根据各分类器的准确度和分类器间分类结果的多样性自动选择一组最优的分类器组合,通过集成学习的方法将这组分类器整合起来,这使得最终的预测在准确度上相对于可选分类器中最好的单分类器有较大的提高.针对选择分类器组合时面临的组合爆炸问题,文中设计了一个2-近似的贪心算法,大大降低了该选择过程的时间复杂度.实验结果表明本文提出的方案具有较好的效果.分类器间多样性是选择分类器的一个重要的标准,如何有效地度量和利用这种差异性是值得进一步研究的问题.此外,文中进行集成时候采用的方法仍需预先设定,因此集成学习方法的领域适用性问题也有待进一步探索.
