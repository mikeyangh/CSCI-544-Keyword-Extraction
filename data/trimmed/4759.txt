Page1基于大规模变量分解的多目标粒子群优化算法研究邱飞岳1),2)莫雷平1)江波2)王丽萍3)1)(浙江工业大学信息工程学院杭州310023)2)(浙江工业大学现代教育技术研究所杭州310023)3)(浙江工业大学信息智能与决策优化研究所杭州310023)摘要含有大规模变量的多目标优化问题是目前多目标进化算法领域的研究重点.多目标粒子群优化方法具有收敛性良好、计算简单和参数设置少等优点,但随着优化问题决策变量的增多,“变量维度”成为了瓶颈.针对上述问题,文中提出的变量随机分解策略,增加关联变量分配到同组的概率,使得算法更好的保留变量间的关联性,并将合作协同进化框架融合到算法中,提出了基于大规模变量分解的多目标粒子群优化算法(CCMOPSO).将该算法在经典标准测试函数ZDT1、ZDT2、ZDT3、DTLZ1、DTLZ2变量扩展后进行仿真对比实验,采用加法二进制ε指标和超体积指标(HV)对算法收敛性和多样性进行对比分析,实验结果表明,在解决大规模变量的多目标函数中,变量维度越高,该算法比经典多目标算法MOPSO、NSGA-II、MOEA/D以及GDE3越具有更好的多样性与收敛性,同时使得计算复杂度明显降低.关键词粒子群优化;大规模变量;随机分解;合作协同;全局优化1引言多目标进化算法(Multi-ObjectiveEvolutionaryAlgorithm,MOEA)利用进化算法求解多目标优化问题,它不仅具有良好的全局最优性,而且单次运行能够提供多个候选解.其中,多目标粒子群算法(Multi-ObjectiveParticleSwarmOptimization,MOPSO)以其良好的收敛性、简单的计算和较少的参数设置,被众多学者关注.但随着实际应用问题的复杂化,多目标粒子群优化算法已经难以满足实际应用问题的需要,许多实际应用问题中含有成百上千个变量.如商品回收中逆向物流网络的设计,目标为最小化供应链中的物流成本以及缺货或库存成本,因此制造商在一定区域内将设计几十个回收点和处理点,由此产生上千个决策变量.这对多目标粒子群优化算法遭遇的“维度灾难”是一种考验,因为其优化性能随着变量的增加而显著下降.为了解决这一瓶颈问题,现有的学者试图从变量分解的角度进行研究.变量分解方法首先将大规模变量分解为若干个维度适中的变量组,然后将每组变量视为一个子种群,再通过子种群间的合作协同实现问题求解.这种“分而治之”的思想即合作协同进化(CooperativeCo-evolution,CC)[1]显著地提高了现有进化算法在大规模变量优化问题上的求解效率,因而备受关注.根据目前已有的研究成果,进化算法中的变量分解方法分为4类:(1)固定分解.这类方法将变量分解为固定的几个分组,为每个变量组分配一个子种群,再通过子种群间的合作协同进行搜索.此类方法实际上是合作协同进化(CooperativeCo-evolution)方法[1]的原型.其主要代表有Potter和DeJong,在最早提出的合作协同进化算法中,人们就为每个变量分配一个种群.而在多目标优化中,Keerativuttitumrong等人[2]率先提出为每个变量分配一个子种群.文献[3-4]中所提出的进化多目标优化方法也同样使用了类似的分解机制;(2)随机分解.这类方法是在没有任何先验信息的情况下,通过将变量进行随机分组来实现问题的分解.这种思路在合作协同进化方法中也受到了广泛关注[5-6].如Yang和Yao等人[7]率先提出的随机分组(RandomGrouping)策略;基于高频率随机分组的分解策略[8];Li和Yao[9]进一步提出了基于动态高频率随机分组的分解策略.最近Antonio和CoelloCoello[10]将随机分组策略用于求解含有大规模变量的多目标优化问题,但是他们对多目标粒子群算法没有进行改进;(3)扰动分解.这类方法是在给定关联变量间所要满足的条件下,不断地扰动变量来发现关联变量.此类方法在合作协同进化方法研究中也受到了关注.比如,基于变量相关系数的分解策略[11]、基于最优个体选择的变量交互学习(VariableInteractionLearning)[12]、基于统计概率的变量交互学习[13]以及最近提出的基于差分分组的变量交互学习方法[14],但其计算复杂度显著增加;(4)关联自适应分解.这类方法先从遗传算法染色体的二进制编码水平上发现基因间的关联,再为包含关联变量的个体赋予较高的选择概率[15].该类方法与扰动方法的不同之处是直接在进化过程中来实现变量分解[16].现有的变量分解方法大多采用固定分组的模式,且缺乏发现变量相关性的有效办法,况且变量分解方法大多集中在单目标优化问题上.本文引入变量随机分解策略,研究了变量分解的关联性,并将合作协同框架融合多目标粒子群算法(MOPSO),提出了基于变量分解的多目标粒子群优化算法(CCMOPSO),该算法与经典算法NSGA-II、MOEA/D、GDE3在测试函数ZDT1、ZDT2、ZDT3、DTLZ1、DTLZ2中进行仿真实验和性能测试对比.2背景知识2.1多目标优化概念针对多目标优化问题,我们可以假定一个含有n维决策变量,m维目标变量的多目标优化问题[17]可以概述为式(1)中,fn(x)(k=1,…,n)为目标函数,gi(x)(i=1,…,p)和hj(x)(i=1,…,q)分别为目标函数所满足的约束.Page3x=(x1,x2,…,xn)∈X,y=(y1,y2,…,yn)∈Y.定义1(可行解集合)[18].对于一个x∈X,如果符合约束条件gi(x)(i=1,…,p)和hj(x)(i=1,…,q),则称x为可行解,由X中的所有可行解组成的集合称为可行解集合,记为Xf且XfX.定义2(Pareto占优)[18].假设xA,xB∈Xf是多目标优化问题中的可行解,则称与xB相比,xAPareto支配xB,当且仅当定义3(Pareto最优解)[18].一个解x∈Xf称记为xAxB,也称xA占优xB.为Pareto最优解,当且仅当满足以下条件:2.2多目标粒子群优化算法粒子群优化算法(ParticleSwarmOptimization,PSO)[19]是由Kennedy和Eberhart于1995年提出的一种受鸟群觅食和社会交互启发的新型智能优化算法.PSO利用粒子个体的个体认知和社会交互来引导群体收敛到潜在的全局最优区域.最早提出的粒子群算法通常用式(2)~(3)更新粒子状态.vid=vid+c1r1(pid-xid)+c2r2(pgd-xid)(2)式(2)和式(3)中:c1和c2为正常数,我们称之为学习因子;r1和r2是介于[0,1]间的随机数;vid∈[-Vmax,Vmax],Vmax是粒子飞行的最大速度,表示个体每代更新的最大步长.式(2)中,vid是指个体的当前速度对自身下一代速度的影响.(pid-xid)表示的是个体认知能力(个体历史最优位置)对粒子学习步长的影响;(pgd-xid)是指个体的社会交互能力对学习步长的影响,即当前种群中的全局最优位置对粒子的影响.粒子个体的飞行方式如图1所示.在粒子群优化算法中,引导粒子的选择对算法的收敛性起着重要的作用.将其引入多目标优化领域时,由于多目标优化问题的解是一群最优粒子,因此引导粒子的选择变得复杂.如何保证这群粒子均匀分布并从中选择全局最优个体,从而引导粒子群的“飞行”,也是多目标粒子群优化算法的关键.现已提出的多目标粒子群优化算法主要是通过引入精英保留策略,即设置外部种群,用于存放历代获得的非支配解,利用小生境技术、拥挤距离法、Sigma方法等控制外部种群中粒子的分布.另一方面,在不损失算法收敛性的同时,引入新的变异策略,以一定概率对当代种群进行变异,从而增加粒子群的多样性.2.3合作协同进化框架进化算法中对于大规模变量的处理机制始于Potter和DeJong[1]在1995年提出的“分而治之”(divideandconquer)策略,又称为合作协同进化(CooperativeCo-evolution,CC).Potter和DeJong提出的合作协同进化策略与传统的进化算法的最大不同在于:它先通过将一个完整的n维变量分解为m个s维(n=m×s)的子变量集合(如图2所示),而后使用一定数量的种群在每个子变量集合的可行域中进行搜索,再将在每个子空间上搜索到的局部解结合成为一个完整解.现有研究表明这种“分而治之”的思想在处理大变量函数时具有良好的效果.3基于变量分解的多目标粒子群优化算法(CCMOPSO)3.1变量随机分解策略综述国内外研究现状,目前有关多目标优化中的变量分解研究成果并不多见.尽管早期已有合作协同框架的“分而治之”的思想,且在解决大规模变量优化问题时有较好的效果,但是有文献提出,当变量之间不是相互独立时,使用合作协同框架的效果并不理想,主要原因为变量分解是固定的,而在绝大多数的大规模变量多目标优化问题中,变量之间往往存在着内在的关联.固定的变量分解会导致这些内在关联信息大量丢失.本文所给出的变量随机分解方法,目的是通过挖掘变量间的内在关联信息,使关联变量尽可能的被归在同一组中.本文提出的一种变量随机分解策略,如图3所示.将D维的决策向量组随机分配到S个子元素,这里使用随机分组的目的是增加关联变量分到同一组Page4的概率,每个子元素的维度为m,满足D=m×S.将S个子元素设成每个有NP个粒子(个体)的子种群.3.2算法框架描述为了更好地描述种群间的协同方法,现设yi为粒子i当前的个体最优位置,y^为各子种群当前的全局最优位置,所有粒子的速度和位置vi和xi分别按式(2)、(3)进行更新.图5算法流程各子种群间个体的速度和位置更新方法如下:先对其进行适应度评估,b(j,z)为适应度函数,定义为b(j,z)=(P1y^,…,Pj-1y^,z,Pj+1y^,…,PSy^)(4)其中,z=Pjxi是子种群j中的粒子i当前搜索到的位置.z=Pjyi表示为子种群j中粒子i的个体最优位置.z=Pjy^表示子种群j搜索到的全局最优位置.由得到的适应度代入,可得到目标函数f1(b(j,z)),f2(b(j,z)),对其按照NSGA-II中的非支配排序方法对其进行非支配排序,随机选择非支配排序等级最高的粒子中的一个作为子种群j的最优位置.以子种群1为例,种群间的协同过程如图4所示.算法框图如图5所示,子种群1到S用多目标粒子群优化算法进行优化,对各子种群的解进行非支配排序,若满足终止条件,则将各个子种群的最优非支配解作为输出结果.若不满足终止条件,则进入下一轮迭代,将父代子种群的最优非支配解集用于子代的协同.Page53.3算法流程算法流程如图6所示.步骤1.初始化D维变量,每个子种群粒子个数为NP,初始化粒子的速度和位置,计算粒子的适应度值,对粒子进行非支配排序,随机选择非支配等级最高的粒子中的一个作为gbest,设定最大周期Cyclemax,子种群数量NumEspmax,种群最大迭代次数Genmax;步骤2.Cycle=1,周期开始执行,对D维变量随机分解成NumEspmax个子种群,每个子种群粒子个数为NP;步骤3.NumEsp=1,对子种群中的第1个进行迭代处理;步骤4.Gen=1,对子种群进行迭代,以粒子当前位置为个体最优位置,步骤1中的gbest为全局最优位置,按照式(2)和式(3)更新粒子的速度和位置,用式(4)对粒子进行适应度评价,按照NSGA-II中的非支配排序方法对粒子进行排序,随机选出非支配等级最高粒子中的一个作为gbest,更新个体最优和全局最优,进入下一次的迭代,Gen=Gen+1;步骤5.满足Gen=Genmax,进行外部种群维护,则NumEsp=NumEsp+1,进入下一个子种群处理,下一个子种群处理中,将上一个子种群中得到的gbest作为全局最优进行更新,其他操作和步骤4相同;步骤6.当NumEsp=NumEspmax时,重新进行变量随机分解,重复执行步骤3、4、5;步骤7.一般情况下,当满足Cycle=Cyclemax时,则输出结果,程序结束.该算法的程序框架如算法1所示.算法1.CCMOPSO算法程序框架.REQUIRE:NP,Cycles,Gmax,NumEspENSURE:SolutionSetPobs←Populations(NP,NumEsp)SOLUTIONSET←ObtainNon-DominatedSet(Pobs)RETURNSolutionSet4仿真实验及结果分析本文选择常用二维测试函数ZDT1、ZDT2、ZDT3和高维目标测试函数DTLZ1、DTLZ2(如表1),选取NSGA-II、MOEA/D和GDE3算法,与Page6CCMOPSO算法进行对比.性能评价采用统计前沿,加法二进制指标ε,超体积指标(HV),算法运行时间.各算法对每个测试函数分别独立运行20次.选取NSGA-II、MOEA/D以及GDE3算法进行对比的目的为:(1)NSGA-II[20]算法是多目标优化的经典算法;(2)MOEA/D[21]是目前处理大变量优化问题的一种有效算法;(3)GDE3(差分进化算法)[22]表1测试函数函数名称ZDT1f1(x)=x1;f2(x)=g(1-f1/槡g);g(x)=1+9∑nZDT2f1(x)=x1;f2(x)=g(1-(f1/g)2);g(x)=1+9∑nZDT3DTLZ1DTLZ2文中所有仿真的实验平台为Intel(R)Core(TM)2DuoP8600,2.0GBRAM,实验环境为MATLAB7.12.0.ZDT1、ZDT2、ZDT3算法的种群大小为200,DTLZ1、DTLZ2算法的种群大小为500,分别将测试函数ZDT1~ZDT3的变量个数分别扩展为100、300、500、1000.将DTLZ1、DTLZ2的变量扩展为200、500,目标维度M设为3.对应的迭代次数为500,分别独立运行20次.CCMOPSO中的变异概率为0.1,学习因子c1、c2为1.495,惯性权重为0.729,这里我们选取分组大小为50进行仿真实验.4.1Pareto前沿对比分析4.1.1二维目标测试函数20次实验得到的统计Pareto前沿对比图如图7~图9所示.ZDT1测试函数的Pareto前沿如图7所示.其中图7(a)、(b)、(c)、(d)分别为变量个数为100,300,500,1000的NSGA-II、MOEA/D、GDE3、CCMOPSO的Pareto前沿对比图,其中经过多代改进,是近年来提出的并被证明是解决大规模优化问题的有效算法.本文以CoelloCoello的多目标粒子群优化算法为基础,采用变量随机分解策略,融合CC框架,目的在于解决大规模变量问题的“维度灾难”.经过实验测试发现,MOPSO算法无法处理大规模变量问题(当测试函数变量个数超过100时,无法获得Pareto前沿).i=2xi/(n-1)xi/(n-1)0xi1;i=2CCMOPSO变量分组为S=50.同理,ZDT2测试函数的Pareto前沿对比如图8所示,ZDT3测试函数的Pareto前沿对比如图9所示.从图7~图9的Pareto前沿对比图中可以看出,通过CCMOPSO得到的Pareto在变量个数为100、300、500、1000时均明显优于NSGA-II.从图7(a)、图8(a)、图9(a)可以看出,当变量个数为100时,通过CCMOPSO所得到的Pareto前沿在多样性上优于MOEA/D,但是在收敛性上比MOEA/D差,两者各有优劣;CCMOPSO与GDE3相比,ZDT1和ZDT2测试函数的Pareto前沿收敛性和多样性略差,ZDT3的Pareto前沿略好.但是随着变量数目的增加,如图7(b)~(d)、图8(b)~(d)以及图9(b)~(d)所示,MOEA/D和GDE3的Pareto前沿明显恶化,通过CCMOPSO得到的Pareto前沿在解集的收敛性和多样性方面明显优于MOEA/D和GDE3.除此之外,传统MOPSO算法在大变量情况下难以得到Pareto前沿.Page7图7测试函数ZDT1的Pareto前沿对比图8测试函数ZDT2的Pareto前沿对比Page8图9测试函数ZDT3的Pareto前沿对比4.1.2三维目标测试函数20次实验得到的统计Pareto前沿对比图如下所示.DTLZ1测试函数的Pareto前沿如图10所示.其中图10(a)、(b)、(c)、(d)分别为变量个数为200时NSGA-II、MOEA/D、GDE3、CCMOPSO所求Pareto前沿对比图,图10(e)、(f)、(g)、(h)分别为变量个数为500时NSGA-II、MOEA/D、GDE3、CCMOPSO所求的Pareto前沿对比图,其中CC-MOPSO变量分组为S=50.同理,DTLZ2测试函数的Pareto前沿对比如图11所示.从图10、图11的Pareto前沿对比图中可以看出,当目标维度增加后,通过CCMOPSO得到的Pareto前沿的多样性和收敛性在DTLZ1、DTLZ2变量个数为200,500时均明显优于NSGA-II、MOEA/D以及GDE3.综上所述,从Pareto前沿的角度分析可以得出:在处理大规模变量的多目标优化问题时,CCMOPSO相对于MOPSO有了明显的提升,而且比算法NSGA-II和MOEA/D以及GDE3的效果更好.为了更客观的说明该算法的性能,本文将通过加法二进制ε指标值、超体积指标值(HV)和算法运行时间进一步说明.4.2算法性能分析4.2.1ε指标值对比ε指标[23]是由Zitzler等人提出的一种用于评价解集收敛性能的指标,该指标使用任意给出的两个优化问题的解集A和B来判断解集的收敛性,其中IA=Iε+(A,B)=Infε∈IB=Iε+(B,A)=Infε∈以最小化为例,以上公式中,对于ε>0当且仅当1in时,有z1于输出对(IA0,IB>0),表示A严格优于B;(IA>0,IB>0)表示A与B无法相互比较,但如果有IA<IB,则可以判断A弱优于B;同理可得,如果有(IA<IB0),则可以认为A弱优于B.在对比实验中,本文用字母C、N、M和G来分别表示4种算法CCMOPSO、NSGA-II、MOEA/D、GDE3所产生的解集.加法二进制ε指标值如表2,在CCMOPSO与NSGA-II的对比中,所有测试函数的I(C,N)<0,且I(N,C)>0,这说明在所有情况下,CCMOPSO所求解集均严格优于NSGA-II.在CCMOPSO与MOEA/D的对比中,当ZDT1、Page9图10测试函数DTLZ1的Pareto前沿对比Page10图11测试函数DTLZ2的Pareto前沿对比Page11ZDT2、ZDT3的变量个数为100时,I(C,M)>0,I(M,C)<0,这说明当变量个数为100时,MOEA/D优于CCMOPSO.但是当ZDT1、ZDT3变量个数为300、500、1000时,I(C,M)<0,I(M,C)>0,这说明CCMOPSO严格优于MOEA/D,另外,当ZDT2变量个数为300、500时,I(C,M)<0,I(M,C)<0,I(C,M)<I(M,C),这说明当ZDT2变量个数增加表2加法二进制指标值ZDT1ZDT2ZDT3DTLZ1200-0.8220.820DTLZ2200-1.4611.259综上所述,由加法二进制ε指标值的对比结果可以得出:CCMOPSO在大规模变量优化问题上产生的解集要优于NSGA-II、MOEA/D、GDE3产生的解集.4.2.2超体积指标值(HV)对比超体积是指被非支配解集覆盖的目标空间区域大小.超体积度量方法,也被称为Lebesgue测度,在理论上具有良好的数学性质,即在所有的一元测度中,它是一个能够判定非支配解集X不比另一个非支配解集Y差的方法[24].对于一个前沿上的解集Pfront,超体积的计算公HV(Pfront)=Λ(∪p∈Pfront上式中,Λ即Lebesgue的测度,xref为参照点.对于两目标优化问题,HV是坐标区域的面积;对于三目标优化问题,HV是三维空间构成的体积;对于大于三个目标的优化问题,HV表示为超体积值.HV的值越大,解集的质量越高.为了同时评估算法的收敛性和多样性,本文采用超体积指标(HV)对CCMOPSO、NSGA-II、式为时,CCMOPSO优于MOEA/D.当目标维度为3时,I(C,M)<0,且I(M,C)>0,这说明在DTLZ1和DTLZ2问题下,CCMOPSO所求解集均严格优于MOEA/D.同理,在CCMOSPO与GDE3的对比中,ZDT1、ZDT3变量为100和ZDT2变量为100、300的情况下,CCMOPSO弱优于GDE3,其他情况均严格优于GDE3.CCMOPSO与MOEA/DI(C,M)I(M,C)0.076-0.293-0.160-0.114-0.7090.694-0.3930.292-0.8890.896-0.5120.436-0.9981.157-0.6650.5370.103-0.193-0.257-0.143-0.151-0.081-0.407-0.014-0.101-0.032-0.6330.395-0.0271.828-0.7080.4610.215-0.399-0.209-0.021-0.6210.406-0.5320.406-0.8130.632-0.7950.649-0.8250.766-0.8150.782-0.3290.385-0.1410.159-0.3210.376-0.2200.235-0.4890.785-0.3140.209-0.5301.126-0.6310.512MOEA/D以及GDE3所求解集进行对比.算法分别独立运行20次,得到的超体积对比结果如图12~图15所示.由于MOPSO算法难以产生Pareto前沿,故认为超体积指标为无穷小.图12为分别对测试函数ZDT1在100、300、500、1000变量大小情况下,用NSGA-II、MOEA/D、GDE3和CCMOPSO独立运行20次,得到的超体积指标值对比图.与ZDT1相同,图13和图14分别是测试函数ZDT2和ZDT3的超体积指标值对比图.图15为分别对测试函数DTLZ1和DTLZ2在200、500变量大小情况下得到的超体积指标值对比图.表3是20次仿真结果所产生解集的超体积指标平均值.对比结果显示:通过变量随机分解策略,CCMOPSO算法所得解集的超体积指标值均优于NSGA-II.当变量个数为100时,MOEA/D求得的解集的超体积指标略优于CCMOPSO,GDE3求得的解集的超体积指标略差于CCMOPSO,但随着变量增加到300、500、1000时,MOEA/D所得解集的超体积指标值明显减小,而CCMOPSO所求解集的超体积指标值仍保持较大值,明显优于MOEA/D和GDE3所求解集.Page12图12测试函数ZDT1用NSGA-II、MOEA/D、GDE3和CCMOPSO算法得到的超体积指标对比图13测试函数ZDT2用NSGA-II、MOEA/D、GDE3和CCMOPSO算法得到的超体积指标对比Page13图14测试函数ZDT3用NSGA-II、MOEA/D、GDE3和CCMOPSO算法得到的超体积指标对比图15测试函数DTLZ1/DTLZ2用NSGA-II、MOEA/D、GDE3和CCMOPSO算法得到的超体积指标对比Page14超体积指标平均值CCMOPSONSGA-IIMOEA/DGDE3ZDT1ZDT2ZDT3DTLZ12000.9940.6810.7820.853DTLZ22000.9860.5760.6830.768综上所述,由超体积指标值的对比结果可以得出,NSGA-II、MOEA/D、GDE3大规模变量全局优化问题上产生的解集比CCMOPSO所产生的解集差.4.2.3算法运行时间衡量一个算法优劣的重要指标为算法的运行效率.为了比较4种算法的运行效率,本文统计了20次4种算法在变量为100、300、500、1000时,ZDT1、ZDT2、ZDT3、DTLZ1、DTLZ2测试函数运行至500代所耗费的时间的平均值(单位:s),如表4所示.算法运行时间/sCCMOPSONSGA-IIMOEA/DGDE3ZDT1ZDT2ZDT3DTLZ1200164.2331.7285.4243.9DTLZ2200177.4368.6327.2286.2综上所述,NSGA-II算法的运行时间大于其他3种算法的运行时间.随着优化问题中决策变量数目的增加,NSGA-II、MOEA/D、GDE3的运行时间呈递增趋势,而CCMOPSO的运行时间相对保持平稳,决策变量数目的增加对算法的运行效率影响较小.其原因是CCMOPSO采用了变量分解策略,当变量数目增加时,平均每一组的变量增加数目相对要少,因此非支配排序所消耗的时间影响较小.综上,CCMOPSO相比NSGA-II、MOEA/D和GDE3,算法复杂度明显降低.4.2.4对比实验结果从Pareto前沿、加法二进制ε指标、超体积指标值(HV)、算法运行时间的对比结果表明:引入变量随机分解策略的CCMOPSO在求解含有大规模变量的优化问题的求解精度以及算法的运行效率整体上均优于NSGA-II、MOEA/D、GDE3,随着变量维度的增加,优势更加明显.MOPSO在大规模变量优化问题的求解上难以收敛到最优前沿,且求解精度差于CCMOPSO.综上,CCMOPSO算法在解决大规模变量的多目标函数中,变量维度越高,它比多目标算法MOPSO、NSGA-II、MOEA/D以及GDE3具有越好的多样性与收敛性,同时使得计算复杂度明显降低.5结论本文提出的变量随机分解策略,将合作协同进化框架融合于多目标粒子群优化算法(MOPSO),提出了基于变量分解的多目标粒子群优化算法(CCMOPSO).通过对标准测试函数ZDT1、ZDT2、ZDT3、DTLZ1、DTLZ2的变量个数扩展后进行的仿真实验,与多目标进化算法NSGA-II、MOEA/D、GDE3进行对比,用加法二进制ε指标、超体积指标(HV)和算法运行时间对算法性能进行分析,实验结果表明:CCMOPSO相比NSGA-II、MOEA/D和GDE3,在求解精度和运行效率上都有显著提升.但实验表明,当目标函数为多模态时,还是会存在传统粒子群优化算法易陷入局部最优的缺陷,该算法在求解此类问题上仍有待进一步深入研究.
