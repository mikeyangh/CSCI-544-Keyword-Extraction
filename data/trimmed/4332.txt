Page1贝叶斯预测型进化算法姜允志1),2),3)郝志峰2),4)张宇山2),5)黄翰6)王映龙1)何火娇1)1)(江西农业大学软件学院南昌330045)2)(华南理工大学计算机科学与工程学院广州510006)3)(悉尼科技大学量子计算与智能系统中心高级分析研究所悉尼澳大利亚2007)4)(广东工业大学计算机学院广州510006)5)(广东商学院数学与计算科学学院广州510320)6)(华南理工大学软件学院广州510006)摘要提出了一种新型进化算法即贝叶斯预测型进化算法,该算法是有效解决遗传算法中的连锁和欺骗问题的一种新方法,其主要特点是:(1)该算法基于最优解的概率分布和贝叶斯定理预测最优解所在的子空间;(2)该算法能高效利用所有先前代蕴含的信息,可以方便地引入专家知识;(3)该算法模型比较简单并且能以很快的速率收敛到最优解子空间.从理论上分析了贝叶斯预测型进化算法的收敛性、收敛速率和逆收敛算子.理论分析与在14个标准的测试函数上的仿真实验显示了该算法求解较为精确、稳定和快速.关键词贝叶斯定理;逆收敛算子;进化算法;遗传算法;分布估算算法1引言遗传算法[1](GeneticAlgorithm,GA)是通过模拟自然界中生物基因遗传与种群进化的机制而产生的一类群体导向自适应概率搜索方法.在20世纪80年代以后,许多改进的遗传算法[2]被广泛应用在各种各样的工程优化问题[3]中并且取得了令人非常满意的效果.不但如此,GA还在一些硬件资源受限制的场合比如微型控制器和商业机器人[4]等领域有良好的应用前景.但是,使用二进制编码的遗传算法仅仅通过随机性很大的选择和重组操作很难把好的积木块集中在一起,并且往往不能准确地映射原解空间的性质.此外,连锁问题[5]也严重地妨碍了GA求得最优解的效率.为了克服这些缺陷,目前世界上有两个主流研究方向.一个方向是混合遗传算法(HybridGeneticAlgorithms,HGAs):HGAs在不改变遗传算法的基本流程的情况下,或者结合相关领域知识优化编码方案,或者通过采用自适应策略优化遗传算子,或者融合神经网络、模糊逻辑或模拟退火等启发式搜索技术来提高其求解效率[6-10].HGAs目前存在的问题:流程复杂繁琐,在大量实际问题中求解效率较低,不如分布估算算法(EstimationofDistributionAlgorithms,EDAs)好.另一个方向就是分布估算算法:它是进化算法的重大发展,它是把统计学习方法与遗传算法的思想相结合,利用概率模型的学习和采样来代替遗传算法的交叉和变异算子的一类算法.EDAs按照概率模型的复杂程度可分为变量无关的PBIL、UMDA和cGA、cDE[4],双变量相关的MIMIC、BMDA和多变量相关的ECGA、FDA、BOA等[11-13].此外,文献[14]提出的基于云模型的进化算法(CloudModelBasedEvolutionaryAlgorithm,CBEA)不需要二进制的编码解码工作,也不考虑变量间的相关性,本质上也是一种EDA算法.在文献[15]中提出的一种交叉算子效率很高,是因为它借鉴了类似于EDAs的统计学习的思想方法.EDAs目前尚存在如下问题:所需设计的概率图模型较复杂,尤其是对于连续域概率图模型的构造较困难,计算复杂度比较高等等.GA和HGAs是通过对基因的微观操作来实现种群的进化;EDAs是通过构造优选解的概率模型从宏观上指导群体的进化.它们具有一个共同的特征:一般是利用第t代信息进化到(t+1)代,却很少利用(1~t-1)代所蕴含的信息.针对上述情况,本文基于最优解的概率分布和贝叶斯定理提出了贝叶斯预测型进化算法(BayesianForecastingEvolutionaryAlgorithm,BFEA).它是从宏观上对人类预测思维的模拟.在本文中我们使用了一种新的理论分析方法去分析BFEA,没有采用进化算法惯常使用的Expectedfirsthittingtime[16]方法,也没有采用EDAs常用的Firsthittingtime[17]时间复杂性分析方法.本文第2节详细地介绍BFEA的原理、特色和流程;第3节从理论上仔细地分析BFEA的收敛性、收敛速率以及逆收敛算子;第4节是关于BFEA的实验,显示算法的优点;第5节总结全文,探讨该算法的进一步发展方向.2贝叶斯预测型进化算法原理和流程2.1与BFEA算法相关的定义和符号表示本文研究的问题可用数学语言描述为式(1):其中,f(X)是Ω上的可测函数,ΩRD,D表示所需要求解问题的解空间维度,任何一个解可以用一个D维向量(x1,x2,…,xd,…,xD)来表示.定义1.犉犮犞犲犮狋狅狉[狀]:把式(1)所表示的求解问题解空间的d维度Ω[d]划分为满足式(2)要求的n个子区间.用FcVector(i)表示d维度第i个子区i包含最优解d维分量的概率,则求解问题解间a[d]空间的d维度概率预测向量犉犮犞犲犮狋狅狉[狀]为下式:(FcVector(1),…,FcVector(i),…,FcVector(n)).Page3B[d]:含有u个最优解d维分量的集合,B[d]表示其中的任意元素,B[d]={B[d]标[d]表示d维度,下同;构成了d维度的犉犮犞犲犮狋狅狉[狀];i:d维度的第i个子区间;a[d]i:在a[d]A[d]t:t=0,1,2,3,…表示代数;i:在a[d]m[d]P(A[d]P(A[d](t)Popsize:种群规模;i|:在子区间a[d]|a[d]最优解d维分量的个数.2.2贝叶斯预测型进化算法原理众所周知,各种进化算法都是迭代搜索的,所有已经产生的种群都蕴藏了许多先验知识(或者称为经验).而且贝叶斯学派也有理论认为:使用当前抽样的数据以及先验分布,再根据贝叶斯公式建立后验分布,以后的一切统计推断都可以在后验分布的基础上进行.因此,可以借助于经验贝叶斯估计方法去预测在某个可行解子空间中包含最优解的概率.BFEA中预测方法的数学模型如下文描述.量B[d]存在的先验概率.由第t代种群计算得到的在子区间a[d]符号P(B[d]|A[d]采取不同的计算方法.符号P(A[d]抽样结果与先验信息而计算得到的后验概率,它是在最优解d维分量B[d]出现的情况下对P(A[d]修正或重新认识.第t代的P(A[d]式(4)更新为第t+1代的P(A[d]中就可以根据犉犮犞犲犮狋狅狉[狀]来指导对最优解d维分量的搜索.根据上述原理,需要把可行解空间的任意一维度d分成满足式(2)的n个子区间a[d]法如下:对于连续解空间(对于离散解空间,可以类推得到),假设d维分量的取值范围是[α,β],则第n个子区间的取值范围为符号P(A[d][α+(i-1)×(β-α)/n,α+i×(β-α)/n],其中i=1,2,…,n.求解问题的可行解d维分量就是一些满足一定条件的随机数.在任意一个子区间中产生的这些随机数都是符合均匀分布的(这是本文实验部分采用的策略),需要产生随机数的数目需要根据式(3)确定.P(A[d](t+1)接下来,根据贝叶斯假设初始化犉犮犞犲犮狋狅狉[狀],然后经过若干代(具体需要多少代根据具体问题特点而定)产生的解来得到最优解d维分量在第n个子区间中出现的概率,这个概率在以后的迭代中使用式(4)更新它.只是在实验过程中发现犉犮犞犲犮狋狅狉[狀]中的绝大部分分量会很快收敛到0.同时也发现,如果犉犮犞犲犮狋狅狉[狀]收敛的快,则包含最优解d维分量的子空间就不容易被正确地发现,以至于后期迭代搜索效果极差.针对这个问题,可以设计一个逆收敛算子来应对它.逆收敛算子实际上是一个双随机矩阵犘,构造方法如式(5),其中s=1+2+…+n.本算法中令犉犮犞犲犮狋狅狉[狀]=犉犮犞犲犮狋狅狉[狀]×犘r,则当自然数r=0时,犘不会对犉犮犞犲犮狋狅狉[狀]产生任何影响;当r慢慢地增大的时候,犉犮犞犲犮狋狅狉[狀]相应地趋于均匀分布.我们会在3.3节分析犘的作用原理以及这样做的原因.如果某些实际问题对求解精度要求较高,BFEA算法可以再在预测得到的含有最优解d维分量的子区间(即一级子区间)中进行二级、三级划分.预测方法与在一级子区间中相同.读者可借助4.1节的实验体验本算法的优越性.2.3贝叶斯预测型进化算法流程第1步.所要求解问题的可行解空间的每一维度被分成满足式(2)的n个一级子区间.第2步.当t=0时,根据贝叶斯假设初始化各个维度的一级子区间的概率预测向量犉犮犞犲犮狋狅狉[狀].第3步.根据式(3)产生第t代的各个维度的一级子区间应该产生的可行解个数,按照相同的原则产生相应的二级、三级子区间应该产生的可行解个数.接着产生第t代种群.第4步.采用某种准则对第t代解的质量进行评估.如果求得最优解则转到第7步,否则接着执行第5步.第5步.如果第t代一级子区间的概率预测向Page4量犉犮犞犲犮狋狅狉[狀]中的第i个分量FcVector(i)>0.5时,算法就会把第i个一级子区间再划分成n个二级子区间;类似地,可以划分出三级子区间.在二级和三级子区间中,预测方法和概率预测向量的构造原则与一级子区间的相同.更新第t代每一个维度的一级、二级和三级子区间概率预测向量.第6步.采用变异算子对随机挑选的10个个体和暂时得到的最优个体进行变异运算;令t=t+1;然后转到第3步.在2.4节给出了变异算子的详细描述.第7步.算法终止运行,输出最优解.3种算法GA、EDAs和BFEA的基本流程的比较见图1,从中我们可以很容易地看出它们的区别与联系.图1算法GA、EDAs和BFEA之基本流程比较2.4子区间的划分与变异算子在2.3节BFEA流程的第5步,选择第i个一级子区间划分为二级子区间时,划分阈值为什么设定为0.5?原因如下.在其他条件不变的情况下,求解问题的解空间各个维度被划分的子区间数n(nPopsize)越多,求得最优解的精确度就越高,但是此时BFEA的时间空间复杂度也会越大.因此,我们需要对选定的第i个一级子区间划分为n个二级子区间的条件进行限制,这样算法就可以在包含最优解概率较大的子空间进行搜索,更大程度地节约了计算资源.此外,划分阈值设定为0.5还能够确保本算法一次最多只选择一个一级子区间进行划分.在选择某个一级子区间进行划分后,算法在没有被选定的一级子区间继续搜索,这样就不会漏掉可能出现最优解分量的区间.若在以后的迭代中发现FcVector(i)0.5,则把这n个二级子区间重新合并成原来的一级子区间.我们应该根据求解问题的特征对子区间级数的划分进行适当的限制.有两点原因:其一,子区间划分的级数越多,算法的复杂度也将随之越大;其二,子区间划分的级数过多,相应的可行解子空间数目会随之增多,有时候会导致子空间个数大于种群数量,以至于某些子空间没有包含任何个体.但是,限制子区间级数的划分可能会影响算法求得最优解的精确度.针对这种情况,本文设计一种基于合作方法的变异算子来应对.文献[18]提出了一种高效率的各个维度合作的方法,本文结合它而设计出的变异算子的流程如下,其中Indiv[D]表示需要变异的个体.第1步.合作的方法[18].第2步.设置一个数组ParaAlter[D],该数组第3步.其他(D-1)维先固定不变,仅对其中的每个分量初始化为1.一个维度d按如下流程局部寻优:WHILEnotstop{Indiv(d)=Indiv(d)+ParaAlter[d];}ENDWHILE3贝叶斯预测型进化算法理论分析3.1收敛性BFEA是根据求解问题可行解的先验分布对最优解进行预测.为了便于讨论,我们直接把解空间Ω划分成N个一级子空间(N=nD),并且满足式(6).对解空间进行多级划分的情况的分析思路与此类似.当本文研究的问题(1)表示连续参数优化问题时,文献[19]假设它满足3个条件.据此,我们假设问题(1)的解空间可以分解成满足式(6)的N个子空间,其中每一个子空间ai的范围都足够小,并且满足两个条件:(1)任意一个子空间最多仅包含一个最优解.(2)若B∈ai,对ε>0,子空间Page5满足M(ai)>0.M表示Lebesgue测度.于是,我们得到定理1.定理1.在贝叶斯预测型进化算法中,如果种群进化的代数足够多,那么它就一定能搜索到全部的含有最优解的子空间,并且有式(7)成立.limt→∑u在式(7)中,包含最优解的子空间总个数用u(u1)表示.u(u1)个最优解的子空间分别为a1,a2,…,au.符号Aj代表aj子空间中包含最优解,Ai代表ai中不包含最优解.证明.符号mi代表在子空间ai中从第0代到当前第t代的最大值,在本文理论分析和实验分析中P(B|Ai)的计算均采用式(8)的模式.由上述的分析可以得到含有全局最大值的子空间的P(B|Ai)用符号bi代表;不含有全局最大值的子空间的P(B|Ai)用符号ci代表.于是所有子空间的P(B|Ai)可以按照如下方式排列:其对应的P(Ai)为把含有全局最大值子空间的P(B|Ai)排在一块是为了方便下文讨论,这不影响算法的执行.下面我们分两种情况考虑:(1)当t的值较小时,u个最优解的子空间a1,a2,…,au中相应的u个最大值m1,m2,…,mu尚不完全相等时,此时可设由式(8)得可以假设0c1,c2,…,cN-ub1b2…bu1.则不论FcVector[N]中各元素的值如何分布,易证式(10)成立,且当P(B|Ai)=1/N或u=N时式(10)中的等号成立.证明如下:i=1i=1j=1∑uP(A(t+1)=∑u∑N-u∑u∑N-u=∑u1-∑u=∑u∑u(2)当t→时,P(B|Ai)的值渐渐地趋于稳定,当它可真实地反映第i子空间含有最大值的概率时,有下式成立由式(8)得可以假设0c1,c2,…,cN-ub1=b2=…=bu1.于是,P(A(t+1)j)=b(t)j=1j=1由式(10)和(11)都可得到算法随着t的增加,∑u∑N-uP(A(t)i=1Page6此时于是P(A(t)此时就证明了式(7)正确.3.2收敛速率下面针对BFEA在最坏情况下的收敛速率和最好情况下的收敛速率两种情况来讨论.假设求解问题的整个解空间仅仅存在一个最优解.(1)最坏情况下的收敛速率分析根据定理1,BFEA首先需要选定一个可能含有最优解的一个一级子空间.随着算法的迭代运行,当发现最优解出现在另外的一级子空间时,BFEA就会立刻选中这个一级子空间.如此反复,最坏的情况下BFEA需要遍历全部N个一级子空间才能最终确定一个含有最优解的一级子空间.接下来,把选中的这个一级子空间进行二级划分.同理,在最坏的情况下选定一个二级子空间、三级子空间……也需要经历上述的过程,这时就需要BFEA迭代很多次才能够求得最优解.这种情况下算法的收敛速率即是最坏情况下的收敛速率.不过,从第4节的实验可以看出实际中BFEA算法出现此种情况的概率极小.(2)最好情况下的收敛速率分析定理2.在最好的情况下,贝叶斯预测型进化算法依概率收敛到含有最优解的子空间的速率为(1/N)α.我们把需要求解的问题的解空间Ω进行L级划分.一级划分是指直接把Ω平均分成N个一级子空间.当进行二级划分时,只是把含有最优解的这个一级子空间再划分成N个二级子空间,…,L级划分时把含有最优解的这个(L-1)级子空间再划分成N个L级子空间.直到Ω的每一个子空间都满足3.1节叙述的两个条件.BFEA将以式(15)的速率收敛到含有最优解的子空间a.证明.在不影响求解精度的情况下,假设gα表示第α级划分中P(B|Ai)能真实反映解空间中的最优解概率分布时需要进化的最大代数,t表示当前的进化代数.于是我们可以假设:当α=1时,BFEA至多需要经过g1代就可以选择出含有最优解的一级子空间a(1)Ω×(1/N);当α=2时,BFEA至多需要经过g2代就可以选择出含有最优解的二级子空间a(2)有最优解的子空间限定为Ω×(1/N)2,以此类推.当BFEA进化了一定数量的代数(g1+g2+…+gL)后,我们就可以得到含有最优解的子空间a=Ω×(1/N)L.于是得到式(15)和(16),vconv代表贝叶斯预测型进化算法的收敛速率.t>g1+g2+…+gL,P{Ω→a}=1(16)3.3逆收敛算子保持BFEA种群中的个体多样性可以扩展搜索空间,提高搜索到最优解的效率.本文设计的逆收敛算子可以使种群中的个体保持适当的多样性,以达到多样性与算法的收敛性之间的平衡.我们已经在2.2节初步介绍了逆收敛算子的构造方式,下面分析其功能原理.引理1.Markov链遍历性定理.设{X(n),n=1,2,…}是具有s个状态a1,a2,…,as的齐次Markov链,如果存在正整数n0使对一切i,j=1,2,…,s有Pij(n0)>0,那么这个Markov链一定是遍历的.如果某个Markov链具有遍历性,并且当转移的步数r充分大时,那么从系统的任意一个状态出发,转移至状态aj的概率都会与初始状态ai无关,并且这个概率趋于一个常数πj.式(17)是它们的矩阵表示.limr→犘(r)=limr→犘r(1)=定理3.概率预测向量在逆收敛算子犘的作用下,有下式成立limr→犉犮犞犲犮狋狅狉[狀]×犘r=[1/n,1/n,…,1/n](18)其中r为非负整数.证明.犘可以看成具有n个状态的齐次Markov链的状态转移矩阵,而且对任意的i,j=1,2,…,n,都有Pij(1)>0成立,根据引理1,此链具有遍历性.由此得到式(19),limr→犘(r)=limr→犘r(1)=limr→犘r=因为犘r(1)是双随机矩阵,我们有同理,即当r→时,犘r中各个元素都趋于相等.因此,Page7limr→犉犮犞犲犮狋狅狉[狀]×犘r=犉犮犞犲犮狋狅狉[狀]×limr→犘r=[P(A1),P(A2),…,P(An)]×[=(1/n)×∑n=[1/n,1/n,…,1/n]limr→犉犮犞犲犮狋狅狉[狀]×犘r=[1/n,1/n,…,1/n]证毕.在实验中发现,不需要犘r中各元素都达到相等或者都达到近似相等的情况,也就是说r只需要取很小的值就可以抑制算法的快速收敛,从而保持种群中个体的多样性.实验中也发现,如果不采用这样的策略,仅仅是简单的重新初始化犉犮犞犲犮狋狅狉[狀];则会丢失掉所获得的最优解概率分布信息.4贝叶斯预测型进化算法实验与分析采用14个经典的具有不同特性的测试函数进行实验,用以观察BFEA算法的实际效能.(1)F1(DeJongFunction),连续性、单峰f(狓)=∑3狓=(0,0,0),minf(狓)=0.(2)F2,含有多个极大值、变峰、非等距、非等高f(x)=e-2×ln2×((x-0.1)/0.8)2×sin6(5π(x3/4-0.05)),狓={0.0797,0.2467,0.4506,0.6814,0.9339},f(狓)∈{0.9991,0.9545,0.7662,0.4809,0.2217}.(3)F3(DeJongFunction),单峰、凸凹性f(x)=∑D-1xi∈[-2.048,2.048],狓=(1,1,…,1),(4)F4(Schaffer2Function),有无数个局部极小点f(x1,x2)=0.5+sin2x12+x2槡2-0.5x1,x2∈[-10,10],狓=(0,0),f(狓)=0.(5)F5(ShubertFunction),多峰f(x1,x2)=∑5该函数共有760个局部最小点.在局部最小点中,有18个点是全局最小点,它们的值为-186.731.(6)F6(Shekel’sFoxholesFunction),多峰f(狓)=xi∈[-65.536,65.536],狓=(-31.9783,-31.9783),(犪ij)=[-32,-16,0,16,32,…,-32,-16,0,16,(7)F7(EazomFunction)f(x1,x2)=-cos(x1)cos(x2)×x1,x2∈[-100,100],狓=(π,π),minf(狓)=-1.(8)F8(Golddtein-priceFunction)f(x1,x2)={1+[x1+x2+1]2×[19-14x1+3x2h(x1,x2)={30+[2x1-3x2]2×[18-32x1+12x2f(x1,x2)=f(x1,x2)h(x1,x2),x1,x2∈[-2,2],(9)F9(Six-HumpCamel-BackFunction)f(x1,x2)=4x2狓=(0.08983,-0.7126),(-0.08983,0.7126),(10)F10(StepFunction)f(狓)=∑Dxi∈[-0.5,0.5),minf(狓)=0,D=4.(11)F11(needleinhaystack:TypeI)f(x1,x2)=a(12)F12(needleinhaystack:TypeII)maxf(狓)=1+∏Dxi∈[-3π,3π];i=1,2,…,10;α={2,4,6,8};(13)F13,单峰Page8xi∈[-5.12,5.12],minf(狓)=0,D=100.(14)F14,多峰f(狓)=-20exp-0.21xi∈[-32,32],minf(狓)=0,D=100.4.1单变量的函数优化问题实验图2是著名的测试函数F12(D=1,α=2)(Syrjakow,Michael,etal.,1999)的图像.图3、图4和图5是函数F12当t=0,t=2,t=5时包含最优解子区间(空间)的解空间个体分布的显示图.图3当t=0时F12函数解空间个体分布图(含最优解)在这个实验中BFEA参数设置如下:令Popsize=100,r=0,我们把解空间每一维度平均分成10个区间.易于观察到当t=5时100个个体都集中在区间[2,6]中,当x=3.9992得到最优解max=20.2435(注:在原始文献中当x=4时,max=20.2432).4.2关于欺骗问题的实验GA详细的参数设置参见4.3节,在BFEA中解空间的每个维度被平均分成7个区间.两种算法的最大运行代数T=200,每种情况下的实验重复图4当t=2时F12函数解空间个体分布图(含最优解)图5当t=5时F12函数解空间个体分布图(含最优解)100次.我们选择3个具有模式欺骗性的经典函数进行实验.它们的特点如下:(1)F3是一个典型的线性不可分函数,呈现病态并且易于出现早熟现象,难以进行全局极小化.(2)F4是线性不可分函数,最优值在区域中心并且与邻域次优解的目标函数值差异非常小,有无数个局部极小点,具有极强的模式欺骗性.(3)F11是一个大海捞针函数,当a,b取不同的值时,它会形成不同严重程度的欺骗问题.欺骗吸引子为局部最优解并且不是全局最优解位串的补运算结果.实验中a=3.0,b=0.05,maxf(0,0)=3600;有4个局部极值点(-5.12,-5.12)、(-5.12,5.12)、(5.12,-5.12)、(5.12,5.12),并且它们的函数值都为2748.78.在成功求得最优解的实验中,算法收敛到最优解的代数的平均值用d1表示.算法收敛到最优解的概率用d2表示.不考虑随机因素对实验结果的影响,我们从表1和表2中能够得出如下结论:BFEA比GA具有更强大地克服欺骗性的能力.我们从表3能够得到如下结论:在测试函数F11的实验中,当种群规模较小的时候BFEA和GA算法克服欺骗性的能力差不多;但是当种群规模的较大的时候,Page9BFEA表现出比GA更好的性能.这是因为种群规模越大,越有助于BFEA预测最优解的概率分布.种群规模d1_GAd1_BFEAd2_GA/%d2_BFEA/%60175.38118.5052.1761.5380185.4478.4557.8165.27100177.9576.4055.4978.19120179.5063.2160.1980.35160158.0552.4866.5788.62200151.7453.2765.4989.24种群规模d1_GAd1_BFEAd2_GA/%d2_BFEA/%60179.9353.1330.8942.9380168.8261.9538.9137.88100169.5650.3837.2841.48120176.3355.7143.7157.76160143.0138.8651.3672.92200139.6129.8453.4584.55种群规模d1_GAd1_BFEAd2_GA/%d2_BFEA/%60195.44186.5760.8154.7080179.14187.8561.5351.98100182.48191.1075.1168.34120180.50172.1172.4973.63160143.55184.3974.8580.59200147.65138.4679.5888.364.3低维函数优化实验在4.3节和4.4节,我们对GA、BOA、CBEA和BFEA算法进行了对比实验.实验硬件环境配置:Compaq笔记本电脑,内存512MB,CPU频率1.6GHz;软件:MicrosoftWindowsXP,MicrosoftVisualC++6.0.4种算法的公共参数配置:最大运行代数T=200,Popsize=500;它们各自的参数配置如下:GA算法配置:采用二进制编码方案,每个变量的染色体长度设置为20.采取适应值比例选择策略、精英个体保留策略.本实验中的交叉算子和变异算子分别选用两点交叉算子和均匀变异算子.交叉概率和变异概率分别设置为0.5和0.05,详细情况参见GA[1].BOA算法配置:采用二进制编码方案,贝叶斯网络结构的学习采用基于BD测度的贪婪算法(k=4,K2metric),本实验中的选择机制使用截断选择机制,详细情况参见BOA[20].CBEA算法配置:详见文献[14]的实验一部分.BFEA算法配置:r设置为1,解空间每一维度平均分为10个子区间,其他参数的详细设置上文已给出.接下来我们分别从快速性、可靠性、精确性3个方面进行实验,比较4种算法优化低维函数的性能.每种情况分别进行100次实验.表4中各个评价指标的含义如下:Inds表示当最优解首次出现时算法已经生成的个体数的平均值;Hits是指成功求得最优解的次数;Mean表示每次成功实验所求得的最优解的均值;Stddev是指每次成功实验所求得的最优解的标准方差;Time是指求得最优解的所有的实验所花费的平均时间/s.Ave的含义见式(20).式(20)中T表示总的实验次数,V(t,i)代表第t代种群第i次实验的最优值.通过表4我们可以看出,在总体上BFEA表现的比较优秀,特别是在时间方面.F1F6F7F2F5算法IndsHitsMeanStddevTimeGA182911009.85804E-065.24930E-065.202BOA90751003.83928E-073.93457E-065.047CBEA65091004.02719E-052.43268E-046.314BFEA48271003.09014E-077.67422E-071.375GA7153969.99103E-017.84068E-061.279BOA32341009.99104E-014.38118E-061.186CBEA35871009.99092E-015.73643E-061.079BFEA12511009.99107E-013.09300E-060.182GA7169778-1.8673091E+025.11655E-029.278BOA5964473-1.8673097E+025.08359E-025.064CBEA4818089-1.8673092E+027.25846E-026.575BFEA4229789-1.8673100E+028.27108E-032.764GA352361009.98004E-013.33766E-072.354BOA215531009.98004E-010.00000E+001.652CBEA208861009.98004E-010.00000E+002.438BFEA27271009.98004E-010.00000E+000.174GA4173287-9.99409E-013.56961E-034.584BOA4109692-9.99968E-014.42856E-035.526CBEA3486493-9.99292E-015.28815E-045.495BFEA2874897-9.99292E-015.28815E-043.406GA554231003.00012E+001.97050E-043.023BOA345331003.00032E+002.00499E-043.701CBEA415781003.00016E+002.24409E-043.433BFEA226961003.00030E+002.11285E-041.389GA8370795-1.03159E+003.90741E-054.290BOA6519497-1.03159E+004.30116E-055.828CBEA5965492-1.03159E+005.50162E-054.174BFEA38236100-1.03161E+001.13039E-051.841GA71173850.00000E+000.00000E+006.345BOA55134920.00000E+000.00000E+006.371CBEA51868890.00000E+000.00000E+005.335BFEA13251900.00000E+000.00000E+001.297GA95185512.13279E+015.09902E-047.746BOA59131922.13275E+017.71581E-045.663CBEA61328872.13283E+014.85064E-044.071BFEA60493822.13281E+012.67285E-042.128图6中共包括10幅子图,其中图6(a)~(i)是各个函数的适应值收敛性质比较图.图6显示,相对F12F10F8F9Page10图6函数的适应值收敛性质比较图Page11于其他3种算法,BFEA收敛速率一般比较快,而且收敛精度一般也比较高.图6经过局部放大处理后还可以观察到下面的结论:(1)BFEA算法收敛速度较快,并且求精能力较佳.图6(a)、图6(f)和图6(i)经过局部放大处理后可以观察到下面的结果.对于测试函数F1,使用GA算法在平均第48代收敛到9.24797E-05,使用BOA算法在平均第24代收敛到3.0858E-06,使用CBEA算法在平均第18代收敛到9.75E-06,而使用BFEA算法在平均第14代收敛到3.52004E-06;说明BFEA算法收敛速度较快.而测试函数F8在约80代以后的变化以及测试函数F12在141代后的变化说明了BFEA具有较佳的求精能力.(2)种群规模的大小会较大程度地影响BFEA算法的收敛速率.比如:图6(i)显示BFEA收敛速率稍慢,是由于在算法迭代的初期测试函数F12的最优解的概率分布比较难以预测正确.但是当BFEA算法种群规模增大时或者已经生成了较多的个体时就能体现出它的优势.图6(j)显示的就是在不同的种群规模Popsize下,用BFEA求解测试函数F12(D=4)时的收敛性质比较图(每种情况做20次实验,Popsize分别取值为500,1000,1500和2000).(3)如果测试函数的定义域范围较大,BFEA算法在初期对最优解的概率分布就比较难预测准确.但是随着迭代的进行,产生的个体数越来越多,可行解的经验抽样分布就会越来越逼近它的理论抽样分布,此时BFEA的特色就表现出来了.比如图6(e)经过局部放大后,我们可以观察到在BFEA的早期迭代中测试函数F7的收敛速度比BOA和CBEA要慢,但是在约第80代以后的变化显示BFEA具有较佳的求精能力.4.4高维函数优化实验本部分实验检验BFEA优化高维函数的能力.(1)F3,维度D取值为30和100;(2)F12,维度D取值为30和100;(3)F13,维度D取值为30和100;(4)F14,维度D取值为30和100.每种情况分别进行50次实验,实验数据见表5.各个评价指标的含义同4.3节.从表5可以观察到如下结果:(1)BFEA算法求解的时间明显少于其他3种(2)当D取值为30时,BFEA对4个函数的求算法.F3D=30F12D=30F13D=30F14D=30F3D=100F12D=100F13D=100F14D=100解效果都非常好,其次是BOA、CBEA、GA.(3)如果求解函数的定义域范围较大,则BFEA预测其最优解的概率分布较难,这一特点和优化低维函数时一样.对测试函数F14的求解精度稍差也正是这个原因造成的.(4)当D取值为100时,BFEA对测试函数F3、F12和F13的求解虽然取得了较满意的结果,但是这4种算法求解时都不如D取值为30时稳定.5总结本文所提出的BFEA的特点是通过预测最优解所在的子空间来导引算法的搜索;它可以方便的引入专家先验知识,并且可以充分高效利用所有先前代蕴含的信息.BFEA比各类HGAs和EDAs的模型更简单,计算复杂度更低.本文实验结果显示,和GA、BOA、EDAs比起来,BFEA可以更大程度上避免算法在非最优解空间的搜索,有效地节约了计算资源.需要注意的是,使用本算法处理式(1)所Page12描述的问题的前提是把求解问题的解空间按照文中第3节的要求进行划分.本文只是提出了BFEA的一个通用的框架.如果对本算法做局部改进、对本算法中的某些参数进行优化和对具体问题增加相应的先验知识,则可以进一步提高算法的性能.在未来的工作中我们将使用本算法去求解彩色图像自动多阈值分割问题.我们也会把BFEA的原理应用到粒子群算法、蚁群算法、量子计算等智能算法中去处理更复杂的组合优化问题,等等.致谢衷心感谢匿名审稿专家以及在悉尼科技大学留学期间操龙兵教授、Wei-ChangYeh教授、刘波师兄、肖燕珊师姐和林智勇师兄对本文提出的宝贵建议!
