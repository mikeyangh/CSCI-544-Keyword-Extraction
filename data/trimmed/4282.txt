Page1基于自然手势跟踪的直接操作型三维人机交互范式冯志全杨波徐涛唐好魁吕娜(济南大学信息科学与工程学院济南250022)(山东省网络环境智能计算技术重点实验室济南250022)摘要针对自然手势单通道条件下建立统一交互模型的难点问题和关键问题,该文提出一种基于二级行为模型的3D手势跟踪和交互方法,实现了一种基于自然手势的直接操作型3D人机交互界面范式原型系统.首先,建立了二级行为模型,然后,以行为模型为基础,设计并实现了一种基于行为模型的三维人机交互界面范式.文中主要创新点在于:建立了基本手势库的二级行为模型;用“令牌环”技术捕捉用户的交互意图;建立“多选一”的交互模型;用“替身”技术解决人手模型与不同物体的抓取过程中的多样性和复杂性问题,建立了抓取和释放操作的统一范式并提出了相关算法.文中算法在多个交互型虚拟装配平台上得到了验证.实验结果表明,与现有相关算法相比较,文中算法在时间开销和跟踪精度等方面得到了明显改善.关键词三维手势跟踪;人机交互界面;行为模型1引言近年来,三维(3D)自然手势交互技术已经在手语识别[1]、手指鼠标[2]、虚拟物体控制[3]、家电遥控[4]、Windows命令控制[5]、手指绘画[2]、机器人控制[6]等领域得到应用.自然、高效、智能化、无障碍的人机交互界面(Human-ComputerInterface,HCI)已经成为新一代智能HCI的主要发展方向,建立智能化的、自然的、和谐的、人性化的人机界面已经成为新一代HCI发展的主要趋势.1.1手势跟踪基于操作型3D手势直接交互的首要前提是实现对3D手势的实时性跟踪,手势高维结构是影响实时跟踪的主要瓶颈之一.因此,怎样有效处理手势跟踪问题中的高维问题这个主要矛盾是该领域的研究难点和热点问题之一[7].沿着梯度方向进行采样是降低采样数量的典型方法之一.陈睿等人[8]首先根据Hessian矩阵估计样本的不确定性方向,然后根据不确定性方向进行采样.Bray等人[9]提出了一种基于StochasticMeta-Descent(SMD)的链结构体跟踪方法,这是一种梯度下降方法,通过改进步长的设置而改善了跟踪的速度和精度.Bray等人[10]沿特征深度方向进行采样,在迭代过程中在模型表面随机选择少量样本点,以降低时间开销,同时利用模型约束条件降低状态维数.他们进一步将SMD方法与粒子滤波器(PF)相结合,提出了智能粒子滤波算法[11],以较少的样本跟踪高维链结构.后来,他们又对该方法进行改进,在多个基于SMD的跟踪器周围设计一个粒子滤波器,经过基于简单系统动态模型的粒子传播之后,这些跟踪器可以用比原来少得多的粒子实现高维链结构体的跟踪[12].此外,采用搜索策略可以缩小采样范围,从而减少采样数目.清华大学的崔锦实[13]博士提出一种基于回归-优化方法的关节式物体的姿态估计方法.该方法把回归分析与全局优化搜索相结合,保证了估计的精度和连续性;针对现有滤波器在高维非线性多峰跟踪问题上的困难,将粒子滤波器与全局搜索算法的演化粒子滤波器方法相结合,提高了高维跟踪的精确度.Zhao等人[14-15]提出两步滤波算法实现对目标位置和方向的实时控制.结合行为模型解决高维手势跟踪中的实时性问题是近年来的另一个研究特点.Stefanov等人[16]根据交互主要由结构化的行为所构成这样一个事实,用手势模型向量序列对手势行为进行表达,把退火算法和变长马尔科夫模型(VLMM)融入到PF跟踪器中,其中,VLMM通过训练方式可以得到.VLMM可以局部优化模型的记忆长度,有效地捕获行为的高阶时序依赖和低阶时序依赖问题.Li等人[17]建立一个通信手势库,用GPDM统计方法学习手势行为模型,从而在手势运动参数空间和低维隐空间之间建立映射关系.Feng等人[18]以认知行为模型作为切入点,提高了手势跟踪的速度和精度.多信息融合是改善跟踪速度的有效方法之一.Kim等人[19]中提出了一种基于人手肤色和运动信息的人手跟踪;刘棠丽等人[20]融合三维人手结构、运动学、动力学及自遮挡特性等降低计算复杂度,Ge等人[21]使用概率神经网络(PNN)为静态手势分类建立了一种基于非线性降维方法的手势识别与跟踪视觉系统;Pan等人[22]采用基于多线索特征流的思想,结合速度模型与贝叶斯肤色模型,采用基于速度权值的特征点流与肤色模型多模式的方法对手势进行跟踪.随着Kinect设备的广泛应用,基于深度图像的手势跟踪研究成为近年的研究热点.Oikonomidis等人[23]依靠无标记的视觉观察来跟踪两手手指的自然的复杂运动,他们把这种运动跟踪看做一个54维参数空间的优化问题,并采用粒子群优化(PSO)来最优地解释一个RGB-D传感器(Kinect)提供的观察,以此找出两只手的组态,利用双线程实现算法对双手达到了实时性跟踪的目标.Kim等人[24]将一个深度传感器戴在手腕上,该传感器由一个红外相机以及两个红外LED等所组成.该系统可以感知用户自然手势的3D结构,基于人体运动学模型从手势离散数据出发恢复手势的全自由度结构,而这些离散点是利用一个专门的信号处理管道实时获取的.该系统在特征跟踪方面的鲁棒性、重建3D手势模型的精度以及在使用方面的便捷性已经在手机等移动设备上得到了验证.1.2手势交互对手势的交互语义进行分类和界定,是手势交互研究中的重要问题之一,是深入手势交互研究的基础工作,界定工作涉及人机界面、行为学、认知心理学等多个领域[25].Pavlocvic等人[26]从行为学角度出发,将手的动作分为两类:无意识动作与手势;进而从认知心理学的角度,对实际生活中包含交互语义的手势再进行细分,将手势分为通信型手势与操作型手势.通信型手势[27]如手语,是一种天生的交互工具,具有强大的信息表述功能.基于通信型手势交互的核心在于手势识别和语义定义.Aristidou等Page3人[28]等通过计算手的位置和速度来识别动态变化,并利用贝叶斯分类器对这些手势分类,实现与机器人交互.操作型自然手势交互有两个基本内涵:(1)人手不必装备任何附加装置或标记;(2)交互行为符合人手的交互行为习惯,即操作型手势的交互语义集合是自然人手操作物体时的交互语义集合的子集.手势的识别与跟踪问题在面对操作型手势交互需求时更加困难,原因在于自然人手进行操作物体的交互语义集合更加庞大和复杂.本文主要探讨基于操作型手势的自然交互界面范式问题.基于传感设备或颜色标记的手势交互已经在虚拟现实、人机交互等领域发挥关键作用[20-21],尤其是在游戏领域,得到了很好的应用[22].任天堂公司的Wii游戏机[23]利用重力传感器测量手的空间运动,实现了手势与场景的交互.Microsoft公司的XBOX360[24]采用了腕带式的传感装置,通过测量人手在屈伸动作中手臂肌肉的不同紧张程度来间接获得手的抓握等手势状态.IBM采用带绿色的手套作为标记,通过双面摄像头获取手势进行识别以操纵虚拟的商品和导航仪,实现虚拟购物和虚拟故宫导航[25].麻省理工学院的6Sense系统[26]以不同颜色的指套和拼色手套虚拟操纵投影或实景中的目标,通过头戴式的摄像头捕捉并识别手势.Wang等人[27]使用打印了特定图案的棉质手套作为标记实现操作型手势交互.Aristidou等人[28]利用光学运动系统跟踪3D人手,该系统要求在手的关键部位打上标记.但是,使用传感设备或标记手套影响交互的自然性,所以,人们把研究重点集中到手势的自然交互上,很多基于3D自然交互的原型系统也应运而生.东芝公司推出的笔记本电脑Qosmio[29]可利用3种手势进行交互.英国牛津大学和剑桥大学研究人员开发了基于手势的机器人控制系统[30],但该系统只能识别一种手势.Torige等人[31]在3D场景中用手指控制机器人.Rehg和Kanade[32]实现了27DOF的基于手势跟踪和交互的DigitEyes系统.Brckl-Fox[33]开发出了基于手势轮廓分析的VirtualSquash系统.Becker和Pentland[34]实现了StayingAlive系统,该系统采用3D手势的Blob模型,基于HiddenMarkovModel(HMM)实现手势识别.Freeman等人[35]实现了一个基于手势交互的游戏系统,该系统利用图像矩识别技术和特定的硬件系统.Zeller等人[36]利用3D手势进行生物大分子建模.O’Hagan等人[37]利用手势交互实现虚拟场景导航,就像在现实中一样可以用手开关车门.Li等人[38]设计了3D虚拟中国象棋,用户可以用自然手势与计算机下棋.目前,这些应用系统主要受到手势识别数目的限制.近年来,研究者从不同应用角度提出了基于操作型手势的自然交互范式,在很多方面取得了突破性研究进展,戴国忠等人[39]所领导的研究团队对基于笔手势的手势识别和人机交互技术进行了深入的理论研究和应用研究,提出了基于eGOMS模型的PIBG交互范式,它是一种建立在心理学之上的Post-WIMP范式.武汇岳等人[40]以人类注意的信息加工模型为理论依据,提出了一个可扩展的视觉手势交互模型,并基于该模型提出了一个视觉手势识别框架,并结合认知心理学从手势检测、跟踪和识别等几个方面对该框架的各个组成模块的关键技术进行了研究.3D操作型界面范式研究的重点在于对场景中的物体进行选择(ObjectSelection)和操纵(Manip-ulation)两个方面[41].从“选择”技术来看,有最早的语音选择[42]、基于方向和范围的选择[43-44]、Ray-casting选择[45]和Spotlight选择[46]等多种实现技术;从“操纵”技术来看,典型的操纵技术有基于映射方式的分类[47-48]、基于任务分解的分类以及基于隐喻的分类[49]等多种形式.Schlattmann等人[50]使用三个摄像机,在六自由度手势条件下研究了点击菜单项、选择对象、耦合与解耦对象的运动以及抓住和释放等关键问题,他们采用仿真2D鼠标左右键的方法实现物体选择操作.Zachmann[51]通过语音命令或者在某一个事件发生的条件下(例如手势与物体发生了碰撞)把场景中的虚拟物体“绑定”在3D虚拟手势上的方法实现物体“抓取(Grab)”操作;在同样的事件条件下完成物体“释放(Release)”操作.根据DeBoeck等人[52]的方法,一旦虚拟手势与虚拟物体发生碰撞,采用隐喻技术实现物体的移动、旋转和形变等操作.一旦虚拟手势与用户的物理手势发生耦合,这种操作变得非常直观,因为它与人们日常操作物体的方法非常相似.但是,这种方法的主要缺点是对于物体缩放以及虚拟物体距离虚拟手势较远条件下的方便性和交互精度难以解决.为此,Frees[53]进一步提出根据用户的行为识别用户的意图,动态捕捉人与物体之间的关系,据此调整交互速度和精度.我们注意到,目前大部分交互界面的“选择”和“操纵”都是在多通道或限制手势自由度或利用辅助设备等条件下完成的,在自然手势这种单一通道条件下如何有效、高效地构建直接操作型人机界面的研究尚不多见,本文以捕捉用户的交互意图为切入点、以改善用户体验为目标,研究单通道条件下基于Page4自然手势跟踪的直接操作型三维人机交互范式.1.3本文内容组织本文第2节建立交互模型,重点建立“选择”和“操作”模型;第3节描述结构化行为模型,重点建立用户的二级行为模型;第4节给出交互算法;第5节给出实验结果,并将本文算法与几种相关算法进行比较;最后一节给出结论和研究展望.2交互建模在基于操作型手势的人机交互系统中,操作者具有明确的认知任务,其手势具有一定的结构特征和功能特征,也就是说,用户手势不应该出现漫无目的的乱动.在这种前提下,用户首先需要在若干个候选对象中选择一个被操作的物体或对象,然后对该对象施加基本操作(例如移动,旋转等),最后将其放下,这样就完成一次交互任务.这个过程反复进行直到所有的认知任务都完成为止.于是,基于操作型手势交互的基本模型可以概括为:选择-操作-释放(Selection-Operation-Release),本文将其简称为SOR交互模型.2.1“选择”建模认知心理学是研究人在科技活动领域中的心理活动规律与特点的一门科学,它用信息加工的观点研究人的认知过程,已经成为研究HCI过程的重要理论之一.一方面,利用认知行为模型,可以对人的行为进行预测或学习;另一方面,在人机交互界面研究中,不可能完全依靠规定或约定等程序化模式完成人机交互,因为人机交互过程本质上是一个用户根据交互环境和交互任务等多因素进行的分析和决策过程,也是一个心理活动和认知活动过程———这个过程也是一个信息处理过程.本文把用户为了完成认知任务而进行推理和决策的过程中所使用的基本信息资源称为认知信息.“多选一”是SOR交互模型中的基本过程之一,也是在基于自然手势这种单通道条件下用户进行意图表达以及计算机捕捉用户意图的难点问题之一.“选择”对象的性质往往具有多样性,它包括:(1)操作对象的选择;(2)对操作结果反馈信息的反应.本文给出一种基于认知信息的“多选一”交互模型(图1).图1中,“用高光显示拥有令牌的候选体”、“显示运动的模型轨迹”以及“用虚线显示选择体”都是可以指引用户行为的认知信息,这里,我们把反馈信息作为一种特殊的选择项.该模型表达了与人机交互有关的不变过程和行为特征.将场景物体组成环状逻辑结构,用一个“令牌”在该环状结构中轮询直到有候选体被选为止,“令牌”所在的候选体用高光显示之.本文采用隐喻的方法选择“令牌”[54],从多种不同的隐喻技术中用实验统计方法确定最佳隐喻技术———往复运动.图2给出了确定这种隐喻的具体过程:(1)如果检测到被跟踪的人手图像做一次小幅度的上下往复运动,则当前“令牌”所在的候选体被选中;(2)如果检测到被跟踪的人手图像没有全局移动而作一次握拳运动,则当前“令牌”所在的候选体被选中.我们从平均精度、平均时间开销和平均愉悦度3个方面对上述两种方法进行评价.其中,精度定义为式(1)中,H为三维人手模型在图像平面上的投影与对应图像之间的Hausdorff距离(本文中λ=0.01).为了深入研究基于往复运动的隐喻选择技术,我们从往复运动轨迹的对称性、时间控制以及用户愉悦体验等方面,进行实验和分析.对称性表明手势能够以高精度回到原来的手势运动轨迹上;良好的用户体验意味着让用户感到更自然、更轻松、更舒适,也意味着用户只需以小的代价就可以顺利地把操作意图传递给计算机,从而计算机可以对人手进行准确的预测和跟踪.图3中给出了在20次实验Page5图2两种不同隐喻技术的比较:往复运动和握拳运动中,往复运动的平均运行轨迹、平均运行时间以及用户的平均愉悦度.从图3(a)中看到,基于往复运动的运动轨迹具有理想的对称性,且沿x,y,z3个方向具有固定的轨迹模型,其数学表达式为其中,Ax=0.01306,Bx=-2.029,Cx=622;Ay=图3进行20次往复运动,得到的平均性能统计0.07083,By=-10.44,Cy=798.4;Az=0.02385,Bz=-3.566,Cz=-218.2.从图3(b)可以看到,往复运动的时间开销基本上服从正态分布t~N(3343ms,68927ms).图3(c)可以看出,当“令牌”的停留时间为4000ms时,用户感到最舒适.上述结果几乎与不同用户和不同场景任务无关.2.2“操作”建模2.2.1场景对象表达形式的统一场景中物体大小的差别往往给“抓取”操作的跟踪带来困难———因为很难对这种行为模型进行统一Page6描述.例如,对于尺寸太大或太小的物体,人手是抓不住它的,如果通过直接在3D手势模型与物体之间进行碰撞检测,必然要降低交互的自然性和愉悦感.为此,我们用半透明的附着在物体上的“替身”代替被抓物体,“替身”具有统一的尺寸,从而进一步规范、统一了人机交互的过程,进而更容易建立简洁的行为模型.具体地讲,我们用尺寸固定的半透明3D小球作为替代物(注:小球半径变化条件下对有关参数的影响另文研究),并建立替代物与物体之间的运动关系,通过替代物容易计算出其对应物体的位置和方位(图4).图中的圆代表对象的“替身”.图4用统一的形式表达差异性很大的场景对象这样,就可以建立与场景对象的外观和尺寸无关的统一的“抓取”和“释放”模型.2.2.2“抓取”和“释放”模型在数字手套和位置跟踪器的帮助下,通过统计实验方法,发现在按照中等速度进行操作的条件下,“抓取”过程可以用如下的数学模型进行描述:其中:θ表示手势的关节角度,t表示时间,a1,a2,b1,b2,c1,c2是模型参数,其取值近似呈高斯分布.在不同速度下,模型参数不同.在中等速度下,a1=48.12,b1=147,c1=37.52,a2=50.47,b2=101.7,c2=58.99.实验表明,“释放”模型可以近似看成是“抓取”模型的逆运动.2.2.3基本手势识别算法(简称BGR算法)“抓取”、“释放”、“平移”是系统中的基本操作,除了建立其模型外,还需要建立基本操作手势库并对其进行实时识别.本文将手势的整体表观特征与手势关节化的变化特性结合起来提取手势的分布特征,基本手势识别算法[55]为算法1所示.算法1.基本手势识别算法.输入:视频手势帧图像输出:动态手势的分布特征1.用深度优先搜索算法找出所有肤色区域,去除人脸、小块类肤色区域,获得手势候选区域,得到手势的最小包围盒,实现搜索窗口初始化;2.利用CAMSHIFT算法对视频流中手势进行跟踪;3.计算当前手势的重心(x-,y-);4.计算各目标像素点到(x-,y-)的最大距离Dmax,以重心(x-,y-)为圆心、Dmax为半径获得手势外接圆,并等距离地将该外接圆划分为N个子图像区域;5.用随机采样方法,得到子区域编号u和v(1u,vN);6.统计u与v之间各子图像区域内目标像素的总数Si(1iN),并找出Si的最大值:7.对采样区间计算密度分布特征向量分量r,dr:dri=8.统计第i(uiv)个区域上手势分布特征向量犪狉犮的各个分量并归一化:其中,1u,vN;9.形成手势图像密度分布向量;犺犱犳=(r1,r2,…,rN;dr1,dr2,…,drN;arc1,arc2,…,arcN)其中,(r1,r2,…,rN)表示把手势图像等距离划分为N个子图像区域后,每个子图像区域内目标像素点的相对密度,(dr1,dr2,…,drN)表示每个子图像区域的目标像素点在极坐标方向上的相对密度的一阶数值差分,(arc1,arc2,…,arcN)表示每两个手指间非肤色区域的长度.10.形成每个动态手势的分布特征:其中,犺犱犳i表示手势中第i(1iL)个帧图像的密度分布向量,L是手势长度.3行为模型的结构化描述3.1一级行为模型一级行为模型由手势标识号、手势特征向量以Page7及手势变量之间的时空关系所构成(图5).每个手势具有明确的语义和唯一标识号.手势特征向量是手势识别的基本依据.手势可以定义为一个帧时间序列犌=(犘1,犘2,…,犘L),犘k=(β1,β2,…,βn),其中,n是手势的自由度(DOF),βs是手势参数,其中,1kL,1sn,本文n=26.显然,在时间L内,βs对应一条曲线,在时刻k,对应于βs上的一个点犚,在βs上的犚点邻域内,用一次或二次曲线对该邻域进行拟合,这种拟合表达式称为犚点的局部运动模型,用y(k,s)表示第s个参数在时刻k的局部运动模型.y(k,1),y(k,2),…,y(k,n)这n条局部模型曲线之间可以相互表达.我们用可以找到一组基函数{y(k,j1),y(k,j2),…,y(k,jq)},1jin,使得其中,1i<q,由式(11)所确定的一组关系集合称为手势变量之间的时空关系.3.2二级行为模型手势中的每个状态变量可以用更低层次的属性及其关系进行描述,我们用二级行为模型来描述这些属性及其关系.例如,状态变量的运动速度、加速度、增减性,运动轨迹特征等都是二级行为模型的描述对象.图6所示的二级行为模型中,如果该变量是不变量,则不变量标识=TRUE,否则不变量标识=FALSE.例如,对于一个单纯的平移手势,除了3个平移变量外,其余状态变量均为不变量.一阶导数dx(t)/dt和二阶导数d2x(t)/dt2的不变量特征序列形成不变特征向量.这些不变特征甚至包括方向符号.例如,导数的正负号就是重要的分析特征之一.3.3构建行为模型的方法我们设计了一个3D虚拟装配平台,让8名研究生参与实验.实验者的手上带上数字手套和位置跟踪器以获取实验过程中手势参数数据.每个参与者独立完成各平台装配任务,而且同样的实验每人重复10次.然后,提取出基本操作(例如“抓”,“放”,其中每种分为两指和五指两种情形),对每次实验进行建模分析,这样,同一个操作得到若干模型,在不同的层面和角度上寻找同类模型的共性特征,得到一级行为模型和二级行为模型.因此,行为模型是对不同实验者在不同时间完成同一个基本操作过程中一般特征的描述.4基于行为模型的手势交互算法基于二级行为模型的手势交互算法(TwoLevelBehavioralModels,TLBM)用伪码形式描述如下:TLBM(){初始化3D交互场景;初始化手势二级行为模型;初始化3D手势;While(所有操作任务没有完成){{//跟踪当前手势犌i:输出犵i.}}每个手势粒子对应一个三维手势模型,将其投影到对应时刻的帧图像上,得到投影点集犃.当前帧图像的手势图像特征,形成点集犅.利用犃与犅之间的Hausdorff距离就可以计算出每个粒子的权值[56].在算法中,把发生碰撞事件作为一个基本手势的结束以及下一个基本手势的开始标志.5实验结果及其分析5.1实验环境我们设计了4个实验平台,让3个实验者分别进行实验,对TLBM算法进行验证并在相同的实验条件下完成参考实验,进行性能对比.实验所用普通个人计算机的基本配置为Intel?,CoreTM,QuadCPUPage82.66GHz,4GB内存;在自然光照条件下,采用一个普通单目摄像头(SONYMVC-CD1000)和数据采集卡(DH-CG410)获取手势视频数据;采用基于生理特征的3D人手模型和基于认知行为模型的三维人手模型初始化方法实现手势模型的初始化[56];采用基于多尺度的方法快速提取手势观测图像特征[57].5.2实验方法和实验结果5.2.1实验1我们用TLBM算法实现一个虚拟烤箱的组装,图7(a)是实验现场,图7(b)~(d)是装配过程截图,其中,小圆球代表零件“替身”.虚拟烤箱由不同的部件所构成,用户的任务是把这些分散的部件组合在一起形成一个完整的烤箱.该实验表明,用户采用基于手势的自然交互方式可以顺利地完成装配任务.由于采用了“替身”技术,用统一模式实现三维手势对烤箱不同部件的抓取和释放操作.我们重点分析“多选一”交互过程(图8).图8采用往复运动作为隐喻实现的“多选一”过程在该案例中,用户完成上一次操作后,要从剩下的3个零件中选择任意1个零件进行组装.图8中的三维小球为“令牌”,它在这3个零件之间依次停留和传递,等待用户的选择.“令牌”是一种认知信息,通过它把用户和零件联系起来,用户只需将手势做一个简单的往复运动,“令牌”所在的零件就被选中,从而实现一次交互过程.这种往复运动不仅简单、自然,而且不会影响手势原来的位置和姿态.从手势初始化到完成一个样机部件的装配任务,整个交互过程分为5个阶段:(1)初始化阶段:用时间3671ms;(2)选择“令牌”:用时9724ms;(3)向上方向运动:所用时间为1553ms;(4)向下方向运动:所用时间为1810ms;(5)把被选择的部件放到正确位置,用时14527ms(图9).在该过程中,第3个阶段所用时间比较固定,其他阶段所用时间具有不稳定性,受操作场景和用户操作速度变化等因素的影响.阶段(3)和阶段(4)形成一次往复运动.Page9我们将本文提出的TLBM算法分别与近几年的几种主流算法和部分经典算法进行比较,由同一人完成所有实验(包括比较实验),各算法分别运行15次,对每帧的平均时间开销和平均跟踪精度进行统计和分析.(1)TLBM与SMD[11]的比较在15次实验中,TLBM算法的粒子数目在5~10之间变化;在SMD实验中,λ的变化范围在0.7~1之间,μ的变化范围在0.05~0.25之间.TLBM的平均时间开销在160ms/Frame左右,SMD的平均时间开销在200ms/Frame左右;除了在第10次实验中TLBM与SMD的跟踪精度相同外,在其他9次中,TLBM的跟踪精度明显优于SMD(图10).(2)TLBM与GPDM[17]的比较GPDM的主要思想是从一个小的训练数据集学习概率手势.在TLBM算法的15次实验过程中,粒子数目为10;在GPDM算法中,αi(1i4)的变化范围在0.3~0.7之间,βi(1i4)的变化范围在0.5~1之间.实验结果表明,在精度接近的条件下(图11(b)),TLBM的跟踪速度快于GPDM(图11(a)).从图11(a)还可以看到,TLBM的时间开销变化比较平稳,而GPDM的时间开销波动性比较大.(3)TLBM与VLMM[16]的比较VLMM用不同的模型处理不同的手势,通过可变长度的隐马尔科夫模型实现它们之间的转换,VLMM与n阶马尔科夫模型相比,它的时间尺度是可变的,据此实现优化模型的记忆长度.在VLMM实验中,最大记忆长度ωu=4,阈值ε=0.00001.在TLBM算法中,粒子数目为10.在TLBM和VLMM精度相近的条件下(图12(b)),TLBM的时间开销低于VLMM(图12(a)).图10在15次实验中TLBM与SMD的比较实验结果图11在15次实验中TLBM与GPDM的比较实验结果Page10图12在15次实验中TLBM与VLMM的比较实验结果(4)TLBM与PF[58]的比较我们再给出TLBM与PF算法的比较实验结果(图13),在15次实验中,所用粒子数目为10.在精度相近的情况下,TLBM比PF具有更快的跟踪速度.PF的平均时间开销为190.0667ms,TLBM的平均时间为159.1333ms.我们注意到,PF的性能比预期的要好,这是因为在本实验中,我们按照轨迹高斯模型进行预测和采样,该模型是在数字手套等设备的帮助下通过训练以后得到的,从而用很少的粒子数目就可以得到很高的精度.(5)TLBM与GroundTruthData的比较我们针对“抓取”过程进一步实验,分别将TLBM和SMD的跟踪结果与从数字手套得到的数据(GroundTruthData)进行比较(图14).SMD的实验结果与GroundTruthData的平均误差为1.156996,TLBM与GroundTruthData之间的平均误差为0.613165.与SMD相比较,TLBM算法的平均误差降低了47%.图13在15次实验中TLBM与PF的比较实验结果图14在“抓取”过程中,将TLBM和SMD跟踪结果与5.2.2实验2改变零件尺寸大小和零件数目,我们让另一个实验者在两种不同的Selection-Operation-Release平台下针对不同的交互任务对TLBM算法进行验证(图15).实验表明,TLBM算法可以自然、高效地完成跟踪和交互任务.在图15(a)中,被操作物体很Page11大;在图15(b)中,不仅需要装配物体的数量有所增加,而且物体的尺寸很小.利用“替身”技术,操作者可以地完成对物体的选择和抓取操作.图15改变交互场景、交互任务、零件尺寸和数量,TLBM算法仍然可以有效地进行工作(为清晰起见,隐藏了“替身”)5.2.3实验3我们将三维场景及操作任务进一步复杂化,并让第3个实验者进行实验.本实验的认知任务是用自然手势完成一个三维虚拟样机的装配,该样机由5个部件构成(图16).将TLBM和SMD各重复15次实验,计算各帧的平均时间和平均精度.实验表明,TLBM算法具有稳定的优良性能(图17).图17中,TLBM和SMD的平均时间开销分别为150ms/Frame和220ms/Frame,它们的平均精度分别为0.64和0.53.5.2.4实验4最后,对BGR算法在不同角度下的动态手势识别率进行实验.因为在手掌法线方向基本保持与相机光轴垂直的条件下,动态手势的分布特征犎犇犉对于手势的平移、旋转和缩放具有不变性.因此,重点对手掌法线方向与相机光轴之间发生偏转的情形进行实验.取10种不同手势,保持手掌向前方向与相机光轴垂直,改变手掌法线方向与相机光轴之间的偏转角.实验表明,识别率可以基本保持在90%图16用TLBM算法实现一个更加复杂的基于自然3D手势的人机交互界面(其中,(a)、(b)中的左上角是在线实时帧图像,右侧是3D操作场景,其中的半透明小球代表“令牌”.为清晰起见,隐藏了“替身”Page12以上,近一半手势的识别率为100%;可以识别的最大偏转角大约为15°左右,不同偏转角下的识别率如表1所示.可以识别的最小分辨率为200×150.表1在10次实验中BGR算法在不同偏转角度下的动态手势识别率偏转角0°10093.759310087939310010020°8080.002045°4020.0005.2.5实验分析对于操作型人机交界面,只需有限个语义手势就可以完成整个系统的交互任务,一级行为模型为手势识别节省了时间;二级行为模型采用更低层或更局部的属性及其关系来描述手势状态变量,为高精度跟踪所识别出的一级行为模型手势提供了更多信息,用少数粒子就可以得到高精度估计,与传统的需要大量粒子才能刻画状态的后验概率分布相比较,TLBM算法极大地降低了时间开销.6结论和展望本文对操作型3D手势交互界面中的部分关键模型和核心算法进行了研究.利用“令牌”技术,构建了“多选一”的交互模型;针对三维场景中物体大小不一给抓取操作带来的不便,利用了“替身”技术,构建了统一的“抓取”和“释放”行为模型;提出了基于二级行为模型的手势实时跟踪和交互算法.本文研究表明,面向交互任务,把手势跟踪和交互相互融合,不仅可以有效地解决手势的实时性跟踪问题,而且有助于构建自然、直接、方便、和谐的3D人机交互界面范式.深入研究相似性手势的识别问题,扩大手势数据库和行为模型库,并对手势跟踪算法进行优化,提出新的界面评价机制,将是我们下一步的研究重点.
