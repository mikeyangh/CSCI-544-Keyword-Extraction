Page1面向MPI代码生成的Open64编译器后端赵捷1)赵荣彩1)韩林1)李宝亮2)1)(解放军信息工程大学数学工程与先进计算国家重点实验室郑州450001)2)(国防科学技术大学计算机学院长沙410073)摘要随着计算机体系结构的发展,分布式存储结构以其良好的扩展性逐渐占据了高性能计算机体系结构市场的主导地位.为了将现有的串行程序转换为能够在高性能计算机上运行的并行程序,研究人员提出了并行化编译器.然而,当前面向分布存储并行系统的编译器发展却相对较慢,而面向共享存储并行系统的编译器及其相应技术已逐渐成熟.一种开发面向分布存储并行系统编译器的可行方法是改进现有的面向共享存储并行系统的编译器,使其自动生成能够在分布存储结构高性能计算机上运行的MPI(MessagePassingInterface)并行程序.因此,该文为面向共享存储并行系统的编译器Open64设计并实现了一个支持MPI代码生成的后端.根据分布式并行化编译的特点,主要从自动生成计算划分、改进循环优化和自动生成MPI并行代码3个方面对Open64进行了改进,使其能够实现面向分布存储的并行化编译.实验测试利用带有MPI后端的Open64对串行程序进行编译,生成的MPI并行代码可直接运行在具有分布存储结构的高性能计算机上.通过将该MPI并行代码的执行效率与传统面向分布存储并行系统编译器生成的MPI代码效率进行比较,并行效率有明显的提升.关键词高性能计算;分布存储;并行化编译系统;Open64编译器;MPI代码1引言从近五年TOP500公布的超级计算机的体系结构发展趋势不难看出,分布存储结构已占据了高性能计算机体系结构的绝对主导地位.分布存储结构具有良好的可扩展性,能够更好地适应不同用户的需求.但相对于并行硬件的发展而言,并行软件的发展相对滞后.如何充分利用飞速发展的并行硬件资源,主要面临的一个问题就是如何将现有的串行程序转换为能够在高性能计算机上运行的并行程序.目前,解决这一问题最有效的方法就是利用并行化编译系统.根据体系结构的特点,并行化编译器可以分为向量化并行编译器、面向共享存储并行系统的编译器和面向分布存储并行系统的编译器.虽然面向分布存储并行系统的编译器研究也取得了一些成果,但仍有许多问题亟待解决.面向分布存储并行系统的编译器开发比较困难,目前大多数研究都是基于面向共享存储并行系统的编译器进行改进,使其能够生成适于分布存储结构的并行程序.Kwon等人基于SUIF编译器[1]实现了面向MPI并行的后端[2],依靠局部插桩技术来分析原来SUIF后端生成的代码的信息.Ferner[3]基于SUIF编译器设计了分布存储并行编译工具Paraguin,实现了在已知计算划分前提下MPI通信的求解算法,在后端通过符号不等式系统完成了并行代码的自动生成.这两项工作都基于SUIF编译器开发,主要缺点在于:前者未考虑分布存储与共享存储之间的区别,未实现改进编译器的优化,后者则在处理全局数组时总是收集所有数据,造成冗余通信,生成的代码效率不够理想.另外,国内南京大学开发的JAPS[4]是一个运行于NOW环境下的Java程序自动并行化系统,实现了从依赖关系分析到程序并行执行的全自动过程,能够进行复杂的任务并行性开发,但由于其针对Java程序开发,适用性受到了一定的限制.从上述几个关于面向分布存储并行系统的编译器研究不难看出,基于现有的面向共享存储并行系统的编译器开发分布式并行的方式具有一定可行性,在一定程度上能够解决分布式并行化编译的需求.基于这种思想,本文为面向共享存储并行系统的编译器Open64[5]设计并实现了一个支持MPI代码生成的后端.Open64是当前最先进的产品级优化编译器,能够自动挖掘程序中的并行性,生成面向共享存储结构的OpenMP并行代码.该优化编译器能够将C、C++和Java多种语言作为输入语言,并且优化效果明显,挖掘并行性的能力强,在多数情况下,生成的并行代码与其他并行编译器相比,能够获得更好的加速比效益.因此,基于Open64开发面向分布存储的并行编译器,得到的MPI代码性能可能会更好.根据分布存储结构和消除传递代码编程特点,本文主要从自动生成计算划分、改进循环优化和自动生成MPI并行代码3个方面对Open64进行了改进,使其成为面向分布存储并行系统的编译器,称为SW-VEC.本文的主要贡献有:(1)利用凸多面体结构,自动获得程序的计算划分和数据分布信息,为最大限度挖掘程序的并行性和降低MPI程序通信开销奠定了基础.(2)通过在依赖测试阶段添加新的依赖测试方法,提升了Open64依赖分析的能力,同时针对分布存储结构改进了循环优化中的并行识别过程,使并行识别的结果更适于分布式并行代码的生成.(3)为Open64编译器提供了一个MPI代码生成模块,使其能够生成适于在分布存储高性能计算机上运行的并行代码.利用SW-VEC系统对串行程序进行编译,生成的MPI并行代码可直接运行在具有分布存储结构的高性能计算机.将该MPI代码的执行效率与传统分布式并行化编译工具Paraguin生成的MPI代码效率进行比较,并行效率得到了明显的提升.2支持MPI代码生成的后端对于面向共享存储并行系统的编译器Open64而言,要为其设计一个能够支持MPI代码生成的后Page3端,需要添加两个功能模块:计算划分模块和MPI代码自动生成模块.另外,由于目标体系结构的差异,需要对Open64优化模块进行调整和改进,从而使后端生成的MPI代码更适合于在分布存储结构计算机上运行.如图1所示是SW-VEC系统的主要功能模块示意图,虚线连接并带有阴影区域的模块为本文工作研究的部分.其中,计算划分模块(decomposition)和MPI代码自动生成模块(MPI)是为Open64新添加的功能模块,分别用于自动获得串行程序中的计算划分信息和自动生成能够在分布存储结构高性能计算机上直接运行的并行MPI程序.面向分布存储结构而对Open64优化功能进行改进的工作主要集中在循环优化模块(LoopNestedOptimization,LNO),调整和改进该模块功能主要是为了使优化后的代码更适于分布存储结构的特点.分布存储并行编译与共享存储并行编译最大的不同在于:分布存储除了要考虑共享存储必须考虑的数据分布外,还需要考虑计算划分.分布存储体系结构中,各个处理器拥有自己独立的地址空间,处理器在访问远程数据时要通过消息传递的方式进行通信.对于一种基于消息传递方式的并行程序而言,通信的开销往往是影响程序并行效率的关键因素之一.图2两级映射模型因此,分布式并行化编译需要同时考虑计算划分和数据分布,以期使不同计算之间,即各处理器之间通信降至最少,从而提高并行程序效率.计算划分模块就是自动分析程序中的计算划分和数据分布信息,在优化前将这些信息附加到编译器的中间语言中,从而保证后面各个优化都能以这些信息为基础而进行.在LNO模块中,Open64主要以嵌套循环为基本单元对程序实施优化,这些优化包括循环倾斜、循环合并[6]等等.对LNO进行调整和优化的原因具体来讲有以下两个方面:首先,由于MPI程序通信开销较大,因此更适合于粗粒度并行.Open64是支持OpenMP代码生成的并行化编译器,对于规模较小的循环,只要符合并行循环的条件,也会识别为并行循环.然而,只有那些规模较大的循环,采用消息传递并行的方式才更有可能得到较好的收益.其次,根据中间语言中附加的计算划分和数据分布信息,需要根据并行识别的结果计算出不同计算之间需要进行通信的数据.Open64能够自动生成OpenMP并行程序,但OpenMP并不适合在分布存储结构上直接运行.因此,为Open64添加一个MPI代码自动生成模块.在这个模块中,主要根据中间语言中附加的计算划分和数据分布信息,确定计算之间需要生成通信函数的位置.在此基础上,将LNO阶段中计算出的通信数据正确写入通信函数中,并完成MPI代码的自动生成.除此之外,还需要根据不同的需求,对生成的并行代码进行优化,从而提升生成并行代码的效率.下面分别介绍如何设计和实现这3个模块.3计算划分与数据分布计算划分和数据分布采用如图2所示的两级映Page4射模型[7]:第一级映射为虚拟映射,完成将对准的计算和数据映射到一个规模不受限的虚拟处理器阵列上;第二级映射为物理映射,完成虚拟处理器阵列到物理处理器阵列的映射.两级映射模型中的虚拟处理器空间为解决自动计算划分与数据分布问题提供了一个中间层的、与硬件平台无关的映射模板,方便开发人员将注意力集中于设计和优化第一级映射算法.计算划分和数据分布分别需要对循环迭代空间与处理器空间的映射关系和数据空间与处理器空间的映射关系进行分析.可以将这些空间之间的映射关系抽象成多维整数空间的映射关系,从而进行代数分析.在实际应用程序中,这些多维整数空间往往呈现出凸多面体的性质,因此,可以以凸多面体来表示迭代、数组下标和处理器空间.3.1凸多面体表示以图3为例,迭代空间记为I,由深度为l的嵌套循环构成,空间中的点(i0,i1,…,il-1)代表嵌套循环的一次迭代;A代表由一个m维数组构成的数据空间,数组的一个元素可以用该空间中的点(a0,a1,…,am-1)表示;一个n维处理器阵列由处理器空间P表示,点(p0,p1,…,pn-1)代表一个处理器的位置.嵌套循环中存在对数组array的访问,数组下标表达式构成了迭代空间I到数据空间A的映射,即数组访问仿射函数.定义1.假设在深度为l的嵌套循环中存在对某个m维数组array的访问,其数组访问形式为array[f00i0+f01i1+…+f0,l-1il-1+f0][f10i0+f11i1+…+f1,l-1il-1+f1]…[fm-1,0i0+fm-1,1i1+…+fm-1,l-1il-1+fm-1],则数组访问仿射函数被定义为迭代空间I到数据空间A的一个映射,表示为f(犻n)=犉m×l·犻n+犽fn,其中犉=是一个m×l的线性转换矩阵,fxy∈犣(0xm-1,0yl-1),犽fn=在第一级映射中,计算划分描述从迭代空间I到处理器空间P的映射,记为计算划分仿射函数c;数据分布描述从数据空间A到处理器空间P的映射,记为数据分布仿射函数d.定义2.设嵌套循环深度为l,处理器阵列维数为n,则计算划分仿射函数c(犻n)=犆n×l·犻n+犽cn被定义为从迭代空间I到处理器空间P的映射,其中c00c01…c0,l-1熿犆=cn-1,0cn-1,1…cn-1,l燀性转换矩阵,cxy∈Ζ(0xn-1,0yl-1),犽cn=熿燀fn定义3.设数组维数为m,处理器阵列维数为n,则数据分布仿射函数d(犪m)=犇n×m·犪m+犽dm被定义为从数据空间A到处理器空间P的映射,其中犇=熿dn-1,0dn-1,1…dn-1,m燀的线性转换矩阵,dxy∈Ζ(0xn-1,0ym-1),犽dm=计算划分、数据分布和数组访问仿射函数三者之间的关系如图4所示.计算划分模块就是通过对程序的分析,自动生成c和d函数中的系数矩阵和常量,即分别给出矩阵犆、犇和对应的常向量.第二级映射,即从虚拟处理器到物理处理器空间的映射,可采用Block、Cyclic和Block-Cyclic这3种方式,采用的方法与课题组前期研究工作[7]相Page5同,此处不再赘述.3.2划分一致性分析计算划分和数据分布的一致性在很大程度上决定了并行效果.因为只有计算划分和数据分布一致,处理器对远程数据的访问量才能减少,这样在后端生成的MPI消息数量才能够降至最低.下面给出判定计算划分和数据分布一致性的理论方法.定理1.当条件犽cn=犇n×m·犽fn+犽dm与条件犆n×l=犇n×m·犉m×l同时满足时,称计算划分和数据分布对齐一致.证明.设程序中某次计算的迭代空间为犻n,计算中访问的数据空间为犪m,则由定义1可知由定义2,经计算划分仿射函数后的迭代空间为再由定义3,经数据分布仿射函数后的数据空间为d(犪m)=犇n×m·犪m+犽dm欲使经仿射后的迭代空间和数据空间完全一致,即那么犆n×l·犻n+犽cn=(犇n×m·犉m×l)犻n+犇n×m·犽fn+犽dm,即犆n×l=犇n×m·犉m×l,犽cn=犇n×m·犽fn+犽dm.证毕.定理2.当条件犆n×l=犇n×m·犉m×l满足时,称证明.同定理1,非对齐一致即计算划分和数计算划分和数据分布非对齐一致.据分布与迭代空间无关,那么只需与迭代空间无关,即在MPI并行代码中,通信是影响并行程序效率的一个主要因素,因此自动并行化应尽量高效地保证数据和计算划分映射到一起,来减少通信的次数.若要保证划分一致,在进行划分时可以按照定理1提出的条件进行划分,这样就能够保证数据和计算完全映射到一起.然而,在实际应用中,很难达到全局的对齐一致,因此,通过定理2证明了非对齐一致的条件.按照定理2的条件,数据和计算能够在整体趋势上映射到一起,处理器之间需要通信时只需要通信因偏移产生的非一致数据,这样也远比完全不一致产生的通信代价小得多.4LNO调整与优化并行化编译器提高生成代码执行效率的重要手段就是利用重排序变换[6].重排序变换是任何这样的程序变换,它仅改变代码的执行序,不增加或取消任何语句的任何执行.而根据依赖的基本定理可知,任何一个重排序变换必须保持程序中的每个依赖才是一个合法的变换.因此,本节首先分析Open64中的依赖测试.4.1依赖测试依赖测试是并行化编译器的一个基础,对于任何一个并行化编译器而言,依赖测试的能力直接影响了其挖掘程序并行性的能力.这是因为:对于一个引用对,并行化编译器如果无法判断他们之间是否有依赖,那么就会保守地认为这对引用之间有依赖,否则,即编译器认为他们之间没有依赖时,如果该引用对之间真的存在依赖,而编译器实施优化时对程序进行了重排序变换,那么就有可能破坏该引用对之间的依赖.因此,如果一个并行化编译器的依赖测试强大到能够判断任何一种依赖关系,那么就会消除原有的保守测试带来的伪依赖,从而能够更大限度地实施优化,挖掘程序的并行性.Open64中使用的依赖测试方法有GCD测试[8]和Omega测试[9].由于GCD和Omega测试都是针对线性数组下标的依赖测试,因此,Open64依赖测试主要存在的问题是无法处理非线性数组下标.通过对SPEC2000和Perfect等基准测试集的程序分析发现,在实际应用中,含有二次下标的数组表达式在这些程序中比较常见,而且远比其他更高次非线性下标常见,因此,我们针对二次下标表达式研究了一种相应的依赖测试方法.定理3.任意二次下标表达式的依赖关系都可以通过二次规划模型判定,其中矩阵犅是由n个边界不同的数组系数组成的矩阵.证明.由于二次规划模型求解要求式(1)中的矩阵犎n×n为对称矩阵,因此,先证二次下标表达式的矩阵一定可以写成对称矩阵.考虑如图3所示例子,判断数组下标之间是否有依赖,即判断Page6f(i0,…,in-1)=h(i0,…,in-1)-g(i0,…,in-1)=0是否有整数解,将式(2)中的常数项去掉,即可得到式(1)中的目标函数.式(1)目标表达式的二次项为f2(i0,…,in-1)=h00i2即矩阵犎为犎n×n=2×此时,对任意0i,jn-1,都满足hij=hji.再证任意下标表达式都可以写成式(1)的形式.显然,当h11>0时,要判定的二次表达式与式(1)相同;当h11<0时,依赖测试等价于求解将式(4)取反,即可得到式(1)的形式.证毕.确定了任意二次下标表达式都可以通过二次规划模型(1)判定后,要解决的问题就是如何求解二次规划模型.求解二次规划模型分为两个步骤:首先,要判定矩阵犎是否为半正定矩阵,这可以通过判定矩阵犎的主子式是否大于0确定.其次,如果犎不是半正定矩阵,那么无法确定二次规划模型的极值,给出保守结果,即认为有依赖.如果犎为半正定矩阵,则利用Lemke方法[10]求解目标函数的极值,来判断目标函数是否有可能等于0,如果不可能,则说明所测试的引用对一定无依赖;否则,再利用分枝定界法[11]求解目标函数在整数范围内是否有可能等于0以及等于0时是否是整数解来判定依赖关系.在文献[12]提出了一种基于整数区间理论的非线性依赖测试方法,该方法的主要缺点是无法处理混合多项式,那么对于二次下标,该方法能够处理的模型为其中犎0n×n=2×hii0对任意的0in-1成立.对于这种模型,判断矩阵犎0是否为半正定矩阵,可以用如下定理.定理4[13].矩阵犎0是半正定矩阵,当且仅当证明.见文献[13].4.2并行识别优化在优化依赖测试的基础上,考虑到SW-VEC是面向分布存储体系结构这一目标,需要针对程序的并行识别进行改进.如前文所述,只有对一些规模较大的循环,采用消息传递并行的方式才有可能得到较好的收益.通过分析程序中嵌套循环结构的特点,我们将程序中的嵌套循环进行了分类[14],分为完美嵌套循环(PerfectNestedLoop,PNL)、简单嵌套循环(SimpleNestedLoop,SNL)和一般嵌套循环(OrdinaryNestedLoop,ONL).三者之间的包含关系如图5所示.Open64中针对任意嵌套循环均采用了相同的处理方式,我们对嵌套循环进行分类,并分别针对这3种不同的嵌套循环设计了不同的并行识别方法.首先,针对完美嵌套循环,可借助中间工具WRaP-IT[15]识别其并行性,同时,该工具可以利用Polyhedral模型将一些非完美嵌套循环转换为完美嵌套循环;其次,对于简单嵌套循环,如果为完美嵌套循环,或者能够转换为完美嵌套循环,则采用上一方法,否则,再利用Open64中的并行识别方式进行识别;最后,对于一般嵌套循环,如果是简单嵌套循环,则按照上一种方法进行识别,否则,由于其结构中可能含有过程调用等复杂结构,需要借助Open64的IPA(Inter-proceduralAnalysis)模块进行分析,再通过传递交互文件的方式识别并行性.由于采用了交互方式进行识别,这种并行识别方式应该属于半自动并行识别.对于非专业人员来讲,如果模型法和遍历法已经识别出足够多的并行循环(如一个嵌套循环内至多允许识别出适合MPI并行的循环个数为n,n可以预先进行设定,而模型法和遍历法已经识别出n个并行循环),那么无需再调用交互法,因为采用MPI函数调用的分布存储并Page7行化编译,其通信开销较大,再进行并行识别可能会带来过多的通信开销,导致并行效率降低;否则,再调用交互法进行半自动的并行识别.对于专业人员,由于对程序结构和算法特点十分熟悉,可以直接利用交互法进行调优识别,从而获得更高的并行效益.4.3通信数据求解在LNO阶段,需要为后面MPI代码生成模块计算好用于MPI消息传递的通信数据.在实际应用程序中,两次计算之间只有至少一个循环被识别为并行时,这两次计算之间才有可能发生通信.定理5.面向分布存储结构的并行化编译中,两个循环之间有可能进行通信的充分条件是两个循环中至少有一个被并行执行.证明.假设程序并行执行时至少由两个或两个以上进程执行,否则并行无意义.设L1和L2为所考察的循环,要确定L1和L2之间是否需要通信,须先判断L1和L2的并行性.如果L1和L2都串行执行,那么由于分布存储并行编译中,串行执行程序时都由主进程处理,因此执行两个循环的进程在同一处理器上,两者之间不需要进行通信;如果L1和L2中有且仅有一个并行执行,那么两者之间必然要进行通信;如果L1和L2都并行执行,那么分两种情况:一种是各处理器上分配到的L1和L2计算划分和数据分布对齐一致,即各处理器上L1和L2计算相关的数据都恰好在当前处理器上,那么此时L1和L2之间就不需要进行通信;否则L1和L2之间就需要进行通信.因此,L1和L2之间可能进行通信的充分条件是至少有一个循环并行执行.在计算划分模块中,已经将计算划分和数据分布的信息附加到中间语言中,因此,在求解两个计算之间的通信时,可以根据中间语言的附加信息来求解通信数据.此时,需要处理的情况可以分为过程间通信数据求解和过程内通信数据求解.对于Open64而言,编译的基本对象是一个PU(ProgramUnit),如果直接在LNO阶段处理过程间信息,无法获得其他过程的信息.因此,当Open64要注销当前PU信息时,将当前PU的信息保存下来,在遇到要发送数据的目的地址计算所在的PU时,再读取保存的PU信息,这样就可以求解过程间的通信数据.对于过程内通信数据求解,如果两次计算有且只有一个为并行,那么由于串行循环拥有引用数组的全部数据,而并行循环只拥有一部分,因此按照并行循环所需数据量传递数据.如果两个计算都为并行,那么判断计算划分,如果非对齐一致,则只需计算因偏移产生的偏差,按照偏差传递数据;否则将源计算的数据进行全通信.最后,将计算好的通信数据信息写入到中间语言结构当中,通过中间语言传递给后端代码生成模块.5MPI代码生成MPI代码生成模块,是本文MPI后端最重要的部分.该模块的功能是根据前一部分工作进行由源代码到源代码的翻译工作,包括正确生成含有划分信息的并行循环、生成MPI消息和通信代码优化3部分.下面重点介绍如何正确生成被划分的循环边界,后两者只介绍基本原理和实现方式,具体结果将在实验部分给出.5.1带有划分信息的并行循环自动生成划分信息的并行循环边界.对于下面这个例子为便于说明,下面举例说明如何生成带有计算for(i1=0;i1<=5;i1++)for(i2=0;i2<=10-i1;i2++)根据第2节中介绍的凸多面体表示方法,其嵌套循环可以表示成如下形式:将其写成凸多面体形式即假设计算划分模块中划分外层嵌套循环,由于内层循环没有划分,那么将式(6)中去掉与i2无关的系数后得到矩阵Page8即得到i2的边界为现假设划分外层循环时,得到的划分结果为pid×blkszi1pid()+1×blksz-1,其中,blksz表示划分块大小,pid代表处理器的编号.此时,将blksz和(pid×blksz)整体,分别看成是未知符号变量,将这些变量和它们的系数,作为新的元素分别加入式(6)的矩阵和向量中,再从中去掉式(7),就可以得到新的矩阵熿00010500-100-1010燀-111-10取式(8)中i1系数为1的部分,得到[000100-1010·即与i1下界有关的不等式为所以,i1的下界为同理取式(8)中i1系数为-1的部分,得到i1的上界为因此,带有计算划分信息的并行循环边界为5.2MPI消息代码生成在计算划分模块和LNO优化模块,分别将并行循环的信息和通信数据的信息写入到了中间语言中.并行循环信息主要是用于确定插入MPI消息函数的位置,基于此再根据LNO阶段写入的信息生成MPI消息函数.在中间语言中,信息存放在抽象语法树的结点当中.对于计算划分写入的信息,在对应的循环结点上设置了一个是否进行划分的标志位,计算划分模块中,如果对应该结点的循环进行计算划分,那么就改变该标志位.在确定MPI消息函数的插入位置时,如果两个循环之间存在数据的访问,那么就检查和这两个循环对应的结点的标志位就可以确定是否需要在该处插入MPI消息函数.根据MPI编程规范可知,到目前为止,除了MPI通信类型无法确定外,其它参数都可以从计算划分和LNO写入中间语言的信息确定.对于MPI通信类型,主要包括全交换(alltoallv)、点到点(sendrecv)、广播(bcast)、收集(gatherv)、归约(reduce)、全归约(allreduce)等,这些类型可以通过判断两个需要进行消息传递的循环并行性决定.如当消息发送循环是并行循环、接受循环是串行循环时,通信类型就是收集(gatherv).5.3通信优化研究表明[16-17],许多程序如果不实现通信优化很难得到令人满意的并行效率.根据通信优化的类型,通信优化可以分为消除冗余通信数据、通信隐藏、消息合并等几种.本文主要对生成的代码实现了通信延迟隐藏和消息合并策略.(1)通信延迟隐藏通信延迟隐藏是指在通信开销不可避免的情况下,通过合理安排通信,使得通信在使用交互网络的同时,处理器可以完成与这个通信无关的计算,即达到计算和通信的互相重叠,实现通信开销的隐藏,提高程序的执行效率.根据MPI编程规范提供的MPI消息函数类型,可以利用非阻塞通信函数(mpi_isend、mpi_irecv和mpi_wait)实现通信延迟隐藏.具体实现方式就是将消息的发送和接收分离,将发送操作前移,使与该通信无关的计算与通信重叠,同时调整接收操作,以保证接收操作与发送操作能够正确匹配,从而达到通信延迟隐藏的目的.(2)消息合并MPI消息传递函数通信开销较大,除了将消息从发送方发送到接收方需要耗费时间外,还有一个原因是MPI消息存在消息启动开销.对于通信本身而言,一次通信的开销可以表示为[7,18]其中Tcomm是总的通信时间,Tstart是通信启动时间,对于一个确定的目标系统而言,是一个常数.Tcopy(n)是通信的发起方建立一个消息或通信的接收方从一个消息中接收数据的时间,它是消息长度n的函数,Ttransit(n)是消息的通信传输时间,也是消息长度的函数.从这个公式中可以看出优化通信的还有一个方法,即减少Tstart.对于n个消息,需要启动n次MPI消息,那么就需要n个Tstart.消息合并就是在条件允许的情况Page9下,将多个消息进行合并,从而原来的n个消息只需要启动1次MPI消息,那么Tstart就减少了.具体实现方法就是将n个消息的发送缓冲区进行合并,然后将多个消息的发送数据依次添加到合并后的发送消息缓冲区内,对于接收方,只需建立一次接收消息即可.6实验测试实验分为正确性验证、优化效果测试和性能测试3部分.正确性验证是验证该优化编译器生成的MPI并行代码的正确性,只有保证MPI程序运行正确,才能进行优化和性能测试;优化效果测试主要针图6rhs.f文件生成MPI代码前后的代码段用SW-VEC编译器对Perfect、SPEC2000和NPB测试集进行MPI源源变换,将生成的MPI程序用mpich2编译后在SunWay集群上运行,运行结果如表1所示.表1SW-VEC生成的MPI代码正确性验证结果测试集程序数正确执行正确翻译失败成功率/%Perfect1268450.00SPEC2000261620661.54NPB3.21189272.73对文中提出的改进方法进行对比测试;性能测试是指将MPI并行代码的运行时间,与串行代码时间对比计算加速比,测试性能.实验平台建立在SunWay集群系统上,配备Linux操作系统,版本为ReadhatEnterprise5,mpich2的版本为1.2.5.该集群由20个节点组成,每个节点配置4个主频2.8GHz的处理器.6.1正确性验证将生成的代码用mpich2编译,以NPB测试集下BT程序中rhs.f文件为例,如图6所示为该文件并行化前后的串行和并行代码片段.其中,并行化后循环依次执行了循环展开和循环合并操作,因此,rhs.f的并行程序代码段比串行程序更简洁.其中,正确翻译表示SW-VEC能够正确转换,但运行结果报错的程序个数,成功率由正确执行个数与程序总数相比求得.导致代码运行出错的原因在于Open64的whirl2f/whirl2c模块本身存在问题,因为Open64的中间语言whirl是一种多层语言,从高到低依次为VeryHighwhirl,Highwhirl,Midwhirl,Lowwhirl和VeryLowwhirl.实施程序优化时所在whirl层次越高,从中间语言转换成Fortran/C语言的正确率越高,出错的概率也就Page10越低.VeryHighwhirl阶段可直接重新翻译成Fortran/C的程序.而在LNO阶段,中间语言已降至High层.程序正确翻译但运行结果出错则是由于部分激进的程序优化和从中间语言到高级语言进行翻译时的错误共同所致.这是因为,LNO优化必须在-O3选项下才能够实施,此时在翻译时容易出现全局变量和局部变量的混淆、类型翻译出错等错误,导致翻译通过,但运行失败.表1结果说明,SW-VEC能够对Perfect、SPEC-2000和NPB测试集中的大部分程序进行面向分布存储的MPI并行代码自动生成.6.2优化效果测试6.2.1依赖测试利用4.1节中提出的二次数组下标的依赖测试方法QP测试对Perfect测试集中含有二次数组下标引用的程序进行测试,结果如表2所示.表2使用QP测试前后Perfect测试集程序依赖测试结果程序名称DYFESM473396OCEAN3502530QCD2448154TRFD7674表2说明,对于Perfect程序中含有二次数组下标引用的程序,QP测试能够对这些程序中的二次数组下标引用给出正确的依赖测试结果.为说明QP测试对循环并行识别的影响,针对Perfect测试集中其它几个含有二次数组下表引用的程序也使用带有QP测试的编译器进行了翻译并运行,结果如图7所示.图7使用QP测试前后程序并行循环个数对比图其中,带有“+”号的数据项表示该程序使用QP测试之后并行循环和串行循环的个数.从图7中可以看出,对这些程序而言,使用QP测试之后,并行循环的个数有所增加,仅ARC2D程序并行循环个数没有发生变化,这是因为,对于程序中的一些循环,虽然使用QP测试之后能够消除部分伪依赖,但还有一些QP测试无法处理的数组下标导致其仍无法并行.6.2.2并行识别将4.2节提出的并行识别方法添加到SW-VEC系统中,对NPB测试集中的5个核心程序进行测试,得到并行循环识别结果如表3所示.表3并行识别优化前后并行循环识别个数对比程序名称CG3799741704-EP83311400-FT39661061607-IS175533801-MG721414332012013-其中,“前”“后”分别表示优化前和优化后循环的个数.表3中仅Invalid一列是本文不能识别的循环个数,其不仅包含本文不能进行并行处理的循环,还包括那些包含跳转和过程返回语句的一般嵌套循环,而优化前的并行化编译器只能识别PNL和少数的SNL循环.从中不难发现,优化后的并行识别方法能够识别更多的并行循环.6.2.3通信优化将生成的MPI代码进行通信优化,其中通信优化前阻塞方式的消息传递函数已被非阻塞方式函数替换,并对多个类似消息进行合并.将NPB和SPEC2000中部分程序实施通信优化前后的MPI程序运行在SunWay集群上,记录4进程下运行时间得到加速比示意图如图8所示.图8结果表明,对于被测程序而言,实施通信优化后,生成的MPI代码能够获得性能提升.在实施优化前,平均并行加速比为2.50,优化后可达到2.74,性能提升约10%.6.3性能测试将上述部分正确执行的测试集程序在实验平台上运行,同时,为了说明性能提升,记录Paraguin编Page11译后的程序运行时间,得到4进程下的加速比如图9所示.图9Paraguin与SW-VEC的MPI程序加速比对比图9结果表明,对这些程序而言,由Paraguin生成的并行程序平均加速比可达2.31,而SW-VEC生成的程序平均加速比可达2.74,性能提升18.6%.结果说明,与Paraguin相比,利用SW-VEC编译后生成的MPI程序能够在SunWay集群上运行时间更短,能够获得更好的性能.7结论相对于向量化和面向共享存储并行系统的编译器而言,面向分布存储并行系统的编译器发展相对落后.为了利用并行化编译器自动生成能够在分布存储结构上运行的MPI并行代码,本文为当前最先进的面向共享存储并行系统的编译器Open64设计并实现了一个支持MPI代码生成的后端.计算划分模块介绍了如何自动确定计算划分和数据分布信息,对于如何判定计算划分和数据分布的一致性给出了理论依据.循环优化模块,为Open64依赖测试部分设计了能够测试含有二次下标表达式的依赖测试方法,优化了Open64的依赖测试能力,同时,通过改进Open64中的并行识别过程,提升了Open64的并行识别能力.在MPI代码生成模块,通过利用中间语言传递信息,确保Open64能够正确生成MPI并行代码,并对生成后的MPI代码进行了优化,提升了MPI并行代码的执行效率.与文献[2]工作相比,本文工作除了注重后端MPI代码生成的正确性和代码的执行效率,还对循环优化部分进行了改进,使SW-VEC更适于分布存储结构的并行;与文献[3]工作相比,SW-VEC系统能够更好地处理过程间和全局调用时的通信数据,生成的MPI代码效率更高;与文献[4]工作相比,本文研究平台Open64编译系统本身允许多种语言作为输入,在后端MPI代码生成时考虑了对这些语言的支持,因此适用范围更广.类似的研究工作还有MichaelClassen和MartinGriebl在凸多面体模型下,针对分布存储结构的代码生成[19]和Kwon等人[20]提出的方法,前者因实验测试环境无法进行对比,适用性受限,而后者是将OpenMP程序转换为MPI程序,是一个从并行到并行的过程.实验测试分别从MPI代码的正确性、系统优化效果和性能测试3个方面进行了验证,结果表明:本文为Open64设计的MPI后端能够生成可直接在高性能计算机上运行的MPI程序,与传统面向分布存储并行系统的编译器相比,利用本文设计的编译器生成的MPI程序执行效率更高.由于面向分布存储的并行化编译粒度较粗,而Open64是面向共享存储并行系统的编译器,部分优化方法还不完全适合于基于消息传递的并行编程语言,如循环交换过程,Open64是将并行循环尽量移动到最内层,而对于MPI程序而言,并行循环越靠近外层,生成的并行代码执行效率就越高.因此,本文下一步研究工作是调整和改进这些优化方法,使其更适合于MPI并行代码的生成.致谢在此向在百忙之中抽出时间评阅本文和提出宝贵修改意见的评审专家、同行和编辑部工作人员表示感谢,向为本文提供研究基础的前辈致敬!
