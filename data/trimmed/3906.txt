Page1众包质量控制策略及评估算法研究张志强逄居升谢晓芹周永(哈尔滨工程大学计算机科学与技术学院哈尔滨150001)摘要随着Internet技术的快速发展,众包作为一种灵活有效的解决问题方式,开始受到人们越来越多的关注.由于众包的自由松散组织模式,使得如何有效地控制任务完成质量,并将欺骗类型工作者识别出来,成为目前众包研究中一个急需解决的问题.文中基于对众包工作者提交结果的评估与分析,提出了一种阶段式的动态质量控制策略,同时给出了一个组合式众包结果质量评估方法框架.经过实际数据的测试,文中提出的质量控制策略和众包结果质量评估方法具有较好的效果.关键词众包服务;分阶段质量控制;检测点;评估算法1引言众包(crowdsourcing)是互联网带来的一种分布式问题解决和生产组织模式.所谓众包是指一个公司或机构把过去由员工执行的工作任务,以自由自愿的形式包给非特定的大众网络的做法.HowePage2满足于未来能够获得更多报酬的前景.尤其对于软件业和服务业,众包提供了一种组织劳动力的全新方式①.众包和普通意义上的外包不同点在于,众包的任务外派给不确定的群体,而外包则是外派给确定的个体.此外,外包强调的是高度专业化,而众包则反其道而行之,更注重自由和创意,跨专业的创新往往蕴含着巨大的潜力.众包的具体实施模式可以多种多样,目前已经有很多成功的商业案例.例如,法国的网络媒体eYeka网站②(爱可网)采用“用户制作内容”的工作理念,在品牌和创作人之间搭建起一个桥梁.Amazon的Mturk平台③,则是基于经济奖励制度的方式让大众解决实际难题.搜狗拼音输入法是优秀的免费协作案例.Foodpickle④则通过将众包与微博结合产生了关于食品的即时问答平台.随着众包技术的不断发展,众包在很多领域中都得到了广泛的应用,例如,在机器翻译(MachineTranslation[2])领域中,如果手工对机器翻译结果进行质量评估代价会非常高,而且评估的过程很缓慢,这时可以采用众包的方法完成此项工作.另外,在信息检索领域的图片搜索[3]、相关性评估[4-5]、数据挖掘[6]、社会化搜索[7]、微博信息的可信计算[8]等方面,都可以将工作以众包的方式分发给在线的网络用户,这样的手段既经济又实用.在语音研究方面也有众包的应用,例如,AudioExample[9]是一种iPhone的应用,它通过语音帮助盲人完成一些曾经需要人眼支持才能完成的功能.另外,在常见的众包分类案例中[10],可以通过人工的协助实现对图的分类和搜索[11].在数据库研究领域也有众包应用的案例,例如DBExampleCrowdDB系统[12],就是利用大众网络来响应数据库的查询.由于众包采取面向不确定大众群体的工作方式,而且承接任务的志愿者具有独立匿名的特点,导致众包结果的质量难以控制,具有较大的不确定性.随着众包技术的广泛应用,众包的质量控制问题变得越来越重要.2众包的质量控制众包的工作方式,可以帮助任务需求者(Requester)获得大量自由工作者(Worker),通过利用这些工作者的智慧解决实际问题.然而,有的众包工作者为了使自己的利益最大化,没有认真地为任务需求者工作,所提交的结果质量低下,违背了需求者发布任务的初衷,甚至产生了适得其反的结果.然而,准确识别出欺骗类型的工作者是一项具有挑战性的工作,而且识别欺骗类型工作者的过程,也需要任务需求者投入大量时间.众包虽然使得我们比以前更容易收集到大规模的数据,但是正如LeaseMatthew[13]所指出,如果关心数据的质量,则必须考虑质量控制问题.最近两年,国内外的学者开始关注如何评估和保障工作者提交结果质量的问题.2.1低质量结果产生的原因伴随众包平台及其应用的日益发展和普及,有越来越多的大众用户参与到众包工作中来,这些大众用户也日益变得多样化.起初,很多的工作者在众包平台上挑选一些众包任务来做,完全是出于自己的兴趣或无聊地打发时间,他们一边能够有事可做,并获得一些经济上的回报;一边又可以解决别人的困难,一举多得.金钱方面的回报对于这样的工作者来说是次要的吸引力.如今,受金钱奖赏所吸引的用户占据众包工作者相当大的比重.2008年,AndyBaio在AmazonMturk众包平台上做了一项实验⑤,任务需求是上传一张工作者自己的照片,这张照片要含有一段手写的纸条,说明其登录Mturk平台的目的.最终实验结果显示,任务共计有30名工作者参与,10位女性,20位男性,年龄在20~40岁之间.有21人说明访问Mturk网站是为了赚取一些零花钱,其余9人说明他们的目的是为了好玩、消磨时间.有一些任务工作者可能受自身技能条件所限,完成的任务结果质量不是很理想.但更常见的是,受利益报酬驱使的工作者越来越多,存在着大量欺骗类型工作者为了使得自身利益最大化,尽可能付出最少的劳动.出现了任务被快速完成提交的情况,这样的情况导致所提交的结果中包含大量随意的答案.由于人工对工作者提交结果进行验证,工作量十分巨大,现实当中根本不可行.这也从客观上加剧了出现更多的欺骗类型工作者提交虚假结果.因此,解决众包应用中结果数据的质量问题变得越来越迫切.2.2相关工作目前众包质量控制方面的研究工作主要集中在3个方面:(1)结果质量评估方法研究.目的是通过各种方法对工作者提交的结果进行评估,以此来识①②③④⑤Page3别恶意工作者;(2)工作者的组织模型.这类工作从建立一种更好的工作者组织管理模式角度出发来控制众包结果的质量;(3)众包任务的设计.这类工作则从如何设计一个好的众包任务角度出发,达到获得高质量结果的目标.在结果质量评估方面,最简单的一种方法就是使用黄金标准数据(Goldenstandarddata)评估工作者完成的质量①,黄金标准数据是指拥有标准答案的一类数据,通过将工作者提交的结果与标准答案的比较可以检测出那些欺骗类型工作者,并拒绝他们提交的结果.另外,还有一类工作是利用冗余信息标识正确答案的方法,例如Ipeirotis等人[14]指出直接用EM算法[15]得到的误差率评估工作者结果的质量有失偏颇,因为其受到工作者个人偏好的影响,工作者本身固有的误差率才是评估工作者的恰当度量,进而提出了一种消除个人偏好,恢复固有误差率的方法,从而获得更可靠的质量评估结果.Alonso等人[16]则详细考察了众包如何更好地应用在TREC相关性评判的领域,并采用了Kappa[17]等手段分析二元判断模型和多级判断模型下工作者提交结果的一致性.工作者组织模型方面,Kochhar等人[18]使用了一种传统的类似于公司人员管理方式的工作者组织模型.完成任务的工作者中既包含长期签约的工作者,也包含自由的志愿者.这些签约工作者从比较容易的任务开始做起,根据其对任务的理解和完成任务的表现,被提升安排到不同的岗位上担任不同的角色,承担一些更加困难的任务.系统可以有效地标识出那些最可靠的签约工作者,并让他们担任管理者的角色.这使得有相当一部分的任务管理开销被这些管理者所承担.任务需求者将任务派发给这些管理者,这些管理者再将任务分发给各个工作者,并负责对他们进行考核.这个模型的有效性已经在Google和MetaWeb的知识图谱应用中得到证实.而Davis等人[19]则走向了另一个极端,将人看作一种计算处理单元HPU帮助机器获得更好的结果,就像GPU和CPU一样.这里人不再是使用计算机这个工具来指导计算任务的指挥者,而是真正用来完成任务的一个工具.在这两个极端之间还有很大的工作者组织模型(LaborModel)设计空间,可以寻求新的方式自动化完成更多的工作,更好地构造任务和组织工作者.在众包任务设计方面,Sorokin等人[20]做了一项图像标注的众包应用实验,并对该应用的可行性进行了研究.所做的众包任务是图像中的人脸识别,在一系列的实验中,他们改变每个任务设置的奖励额度,分析赏金刺激对结果质量所产生的影响.最终他们发现奖励额度和结果质量之间有很强的依赖现象,以极低薪酬发布的任务会导致任务的接受速度很慢,很少有人会对此项任务感兴趣;又发现以较高奖励额度发布的任务会更容易吸引那些效率低下的欺骗类型工作者.2011年,Eickhoff等人[21]对众包任务的构造采取了反恶意策略,他们通过一系列实验分析出欺骗类型工作者在众包平台中所占有的比率,以及健壮性众包任务应具有的标准.分别对众包任务类型、用户接口形式以及工作者类型等3个方面做了相关实验.在众包任务类型与欺骗工作者的关系中,他们发布了两种不同类型的任务,一种是网页和查询词的相关性评估实验;另一种是根据以往指导儿童上网的经验做一份简短的调查问卷,要求工作者依据网页内容对不同年龄段儿童浏览内容的合适程度做出判断.这两种众包实验的差别在于任务的复杂度和新颖度.相关性判断是一种相对简单直接的任务类型,工作者很容易对网页内容做出判断,完成起来比较容易.网页适宜度调查,则是一项比较新颖的任务类型,需要工作者进行一定的思考,并具备一定的创造力.实验结果显示,网页适宜度调查实验中欺骗类型工作者占总体工作者的2.0%,而相关性判断任务中欺骗类型工作者所占比例为38.0%.关于众包任务类型,作者得出结论,一项复杂度较高,工作者需要具有创造力的任务,将对那些只想简单快速完成任务的工作者缺乏吸引力.最后,作者研究了众包工作者的组成形式,结果显示那些只接受发达国家工作者承接的众包任务,可以获得较高质量的结果,但同时也要付出时间上的代价,原先可以在几个小时内完成的任务,改变限制条件之后完成时间延长了一周.实验又进一步提升对工作者接受率的限制,从95%提高到99%,结果显示这项要求对欺骗类型工作者所占比例影响不大.关于众包工作者,作者给出了两个结论:(1)过滤掉一部分工作者可以明显减少欺骗类型工作者,但会延长任务的完成时间;(2)工作者之前完成任务的接受率并不能够有效地控制此工作者的可靠程度.2.3存在的问题尽管已有一些关于众包结果过滤和欺骗检测方①http://en.wikipedia.org/wiki/Gold_standard_(test)Page4面的研究工作,但是质量控制方法仍受到如下几个因素的限制:任务类型、时间、经济花费和工作者.首先,目前的技术很难推广到任意类型任务中,尤其是主观型任务,比如写一段评论、文本翻译等.其次,众包平台是一种缺少声誉的系统平台,绝大多数情况下众包任务的工作者均为匿名用户,能够为任务需求者留下的交流信息很少.因此,在某一次实验中,很难得出有多少不诚实的工作者参与任务.另外,经济成本也是一项敏感的因素,前文已经叙述过,付较高的薪酬不一定会收到质量较高的结果,反而会明显地吸引欺骗类型工作者.但设置较低的薪酬又会延长任务的承接时间.目前黄金标准数据在众包应用质量检测方面被广泛地使用,然而创建黄金标准数据的时间和经济耗费也比较高.任务工作者来自不同地域,具有不同的知识背景,他们对任务需求的理解不一样,最终也会导致任务完成结果参差不齐.当前采取的限制策略虽然可以取得一些效果,但是也都存在着一定的局限性和不足之处,如果设立的条件对能力要求过高会让工作者的兴趣程度降低,参与难度提高;而对于国籍的限制会使得参与的工作者数量明显减少,积极程度会降低;薪酬设置的过少,也同样会影响到用户的参与程度.而且,这些策略并不能排除掉所有欺骗类型工作者,尚缺乏一个比较系统的众包质量控制策略.对于任务的需求者来说,其最终关心的是提交结果的质量,所以想要很好地解决众包质量的问题,还需要从提交结果本身的正确性和可靠性上出发.3众包质量控制策略及评估算法3.1众包任务选择本文工作主要研究如何依据工作者提交的结果来识别欺骗类型工作者.在实际当中,有很多的任务属于简单直接类型,如相关性评估,而这类任务往往更能吸引那些欺骗类型工作者的参与,所占比例也会比较高.如果单纯依靠对任务进行新颖性设计的手段来降低恶意用户的参与度,不仅需要额外的开销和时间,而且还会增加任务的复杂度和完成时间.因此,需要研究新的质量控制策略和评估方法.本文选取相关性评估作为此次研究的众包任务.相关性评估,是信息检索系统中数据收集的重要组成部分,也是信息检索中比较困难和代价较高的工作.信息检索系统能够帮助用户在浩瀚无尽的信息中找出有用的数据,为了评估这类系统的性能,理想的办法是确定提交查询和每个检索出文档之间的相关程度.标准的评价办法是用已知的相关性结果测试集来评估.为了建立这种真值已知的文档集,需要获得相关性判断集合,或是用户对文档和查询所表达信息相关程度的主观认知.常见的方法是,具有专业背景知识的标注者人工对前Top-k排名的文档做出相关性判断,其判断的过程耗时又耗力.反之,作为一种替代专业型人才获取测试集查询词和文档相关性的方法,可以利用在线匿名的Web用户做出相关性判断,因此众包成为了一种有效解决此问题的手段.通过众包平台,可以在短时间内以较低的成本获得大量工作者的相关性判断结果.然而,通过众包方法获取的相关性结果质量却是令人怀疑的,因为在众包平台中,充斥着未知的工作者,这些工作者当中很有可能存在恶意的、质量低下的工作者,这些工作者也许只是为了薪酬而完成工作,欺骗类型工作者随意地生成相关性判断结果,这样的结果会造成与真实相关性的不一致,增加错误估计的偏差,甚至有可能导致相应查询/文档在测试集中失去实用价值.TREC为相关性给出如下定义[22]:如果关于某一主题的文本内容包含有查询词的信息,那么认为此文档和查询之间具有相关性.一般地,标注者需要做出二元相关性判断(即“相关”或“不相关”).早期的相关性评估工作,是由一组志愿编辑者,通常是在校的研究生,精心地阅读语料库中的每一篇文档,然后对测试查询集做出相关性评估.这样的评估过程较为困难,并且建立的测试集合规模也较小,所以传统的评估方法有许多的局限性.为了评估本文提出的质量控制策略和评估方法,我们搭建了一个B/S架构的小型众包平台,在此平台上运行TREC数据相关性评估实验,工作者登录系统接受任务并完成判断,系统自动收集这些自由工作者完成的相关性评估任务结果.在此项众包任务中,质量控制环节是核心问题,需要知道这些自由工作者是否认真工作,而不是为了领取相应赏金而随意地点击答案,提交糟糕的结果.3.2阶段式动态众包质量控制策略与目前的黄金标准数据评估策略和反恶意策略的静态特性不同,本文提出基于对工作者提交结果的评估,实施阶段式动态质量控制策略.换句话说,在工作者完成全部所分配的任务过程中,设立分阶段的检测点(Checkpoints)来评估其上一阶段完成Page5任务的质量,如若发现其提交结果质量不合格,则停止其继续参与本次众包任务的工作资格,并删除其在这一阶段所提交的结果,同时选择新的工作者来继续完成遗留的任务.与当前完成全部任务后进行的一次性整体评估策略不同,本文提出的阶段式动态评估策略可以更早地发现那些欺骗类型工作者,图1阶段式动态众包质量控制流程目前在任务设计与分配,以及工作者组织与管理等方面的研究成果可以在这两部分得到应用.本文工作主要集中在第3部分,而且关注的重点是自动评估.与现有众包应用一样,任务请求者首先需要发布任务请求,招募工作者形成工作者池.本文策略在开始阶段不是为工作者池中所有的工作者都分配任务,而是从这些工作者中选择一些工作者作为活跃工作者并给他们分配任务,任意时刻只有活跃工作者能够获得任务并提交完成结果.系统在各个检测点调用质量评估算法对每个活跃工作者提交的结果进行评估;当发现有工作者表现不合格时,系统启动替换规则,从工作者池中剩下的工作者中选择新的工作者来替换那些不合格的工作者,将原来分配给不合格工作者的任务转而分配给这些新的工作者,这些新工作者成为活跃工作者.与此同时,从任务结果集合中去除不合格工作者上一阶段所提交的结果.在本文的质量控制策略下,有些工作者不再是从头到尾参与整个众包任务,而是依据其提交结果的质量会动态调整,在某个检测点评估中不合格的工作者将会被终止合作.为了顺利实现上述质量控制策略并获得好的结果质量,在结果评估与替换部分需要做好以下几方面的工作:(1)质量评估算法.质量评估算法主要是用来对工作者提交结果进行评估,进而评判一个工作者是否合格,算法的好坏将会影响众包任务最终的完成质量.已有的质量评估算法,如前面介绍的黄金标并停止其工作,减少最终结果中不可信结果所占比例,提升结果的整体质量.图1描述了本文提出的众包质量控制策略的实施流程,第4节的实验也是依据这个流程来实施的.主要包括任务设计与管理、工作者组织与管理和结果评估与替换3个部分.准数据方法、EM算法和Kappa一致性检测等方法,以及文献[18]中提到的人工或半人工评估手段都可以应用到这里.而且还可以采用多种方法组合的方式进行评估,以克服单一方法的片面性.本文组合使用了两种质量评估算法来实现对工作者结果的评估.并且着重考察了EM算法在阶段式动态质量控制策略中的适用性和可行性.(2)替换规则.当检测出不合格工作者之后,需要从工作者池中选择新的工作者替换这些不合格工作者.这里的选择规则可以有多种,例如随机选取,或者选取以往信誉度比较好的工作者,再或者优先选取发达国家的工作者等.目前已经有的一些反恶意策略可以在此处得到应用,同样也可以将多种规则组合应用.由于本文招募的工作者均为在校计算机专业的学生,具有相类似的背景,因此本文实验中采用了最简单的随机选取原则.(3)检测点设置.检测点的设置也可以有多种方式,例如依据任务的等距划分(即按照整体任务的规模进行等分),或者按照工作者提交结果的时间点,甚至是针对不同工作者的个性化设置等.本文由于分配给每个工作者的任务数量不是太多,任务完成的时间跨度在72h之内,且这些工作者具有类似的背景因素,因此采用了等距划分的原则,如每20个任务为一组.后面的实验结果显示出,不同的检测点设置方式,对最终结果的质量确实有影响.图2给出了本文提出的阶段式动态众包质量控制策略实施流程.Page6A={活跃工作者集合},C={检测点集合}输入:D={任务集合},K=活跃工作者人数输出:众包结果集合1.A←.2.While|A|<kdo3.从工作者池中挑选新工作者加入到活跃工作者集合A中.4.End-While5.将D中的任务分配给A集合中的工作者.6.Fori=0toi<|C|do7.ForA中的每一个工作者wdo8.调用质量评估算法评估工作者w的在检测点[i-1,i]期9.Ifw提交的结果不合格then根据替换规则,从工作者池中选择一个新工作者w代10.End-If11.End-For12.End-For13.返回众包结果集合.图2阶段式动态众包质量控制策略实施流程3.3众包结果的质量评估方法为了能够更加准确地评估工作者提交的结果,本文采用了一种组合式评估手段,通过使用不同的评估方法来评估工作者提交的结果,一个工作者需要通过全部方法的测试才能继续工作,否则将被替换.这里可以采用多种评估方法,本文则选用了两种方法,首先研究分析在众包环境下工作者行为的特点,标识出两种最常见的欺骗工作者类型:随意类型和统一类型,并将其进行替换;其次,采用期望最大值算法估计出结果并计算出工作者的误差率,低于标准的工作者会被拒绝,满足标准的工作者被采纳.3.3.1工作者类型为了发现那些欺骗类型工作者提交的垃圾结果,我们研究不同类型工作者提交结果的策略,从而分析出各种类型工作者所具有的特点.勤奋/道德型工作者听从指挥,遵循任务需求者发布的相关说明,这种类型工作者的目标是产生富有实际意义、有价值的结果.而粗心大意,草率的工作者可能也具有良好的意图,但提供了质量低劣的判断.反之,低质量的任务结果可能源于工作者不能够执行任务的要求,或是工作者的参照标准不同;这种类型的工作者提交的结果经常与完成同一任务的其他工作者提交的成果不一致.分析欺骗类型工作者选择分类的行为,故意随机提交任务结果的工作者是一种类型,对于任务需求者来说,他们很难发现这样的工作者的不诚实性.还有一种是统一类型的欺骗类型工作者,他们使用固定的分类选择模式.这种类型的工作者没有打算真心地提交任务结果,也没有采用先进的欺骗策略,只是重复提交相同的分类结果.这种类型的工作者比较容易被识别出来.3.3.2检测随机类型的工作者一个良好的欺骗检测机制在能够找出所有欺骗类型工作者的同时,将拒绝勤奋工作者的可能性降到最低,为了减少误报的情况,我们需要一个在复杂众包平台环境的测量方法.本文方法基本思想就是利用相关性的特征距离计算每个工作者w的随机分数.假设W为所有工作者的集合,T为所有需要进行相关性判断的(查询/文档)对集合.Jwj表示工作者w对(查询/文档)j所做的相关性判断,Jj,w-表示其他工作者(非w)对(查询/文档)j所做的相关性判断集合,disij表示关于相同的(查询/文档)对,工作者w和其他工作者i之间在(查询/文档)j上所做判断的差异距离.若两者所做的判断相同则disij=0,若所做的判断不同则disij=1.工作者w与所有其他工作者在所有(查询/文档)判断上的差异距离采用如下式(1)计算得到.3.3.3检测统一类型的工作者统一类型的欺骗工作者常常选择固定的分类模式,简单常见的方式:只选择单独的一类标记.在真实值倾向于某种类型的分布情况中,例如,本文的相关性评估实验,绝大多数的评估任务的相关性应为不相关,相关的相对较少(这与TREC数据的真实情况一致).与随机类型欺骗工作者提交结果的情况相比,统一类型的工作者所提交的结果更能影响到预计的正确答案,这种类型的工作者提交的结果和真实的相关性一致程度比较高,因而不能用取大多数原则,即简单的少数服从多数方法来鉴别工作者提交的结果质量.Kouritzin等人[23]做了一项关于检测掷硬币虚假序列结果的实验,提出来一种新颖的检测方法,此方法主要关注当前掷硬币的正反情况与之前硬币所掷出序列的差异性.同理,识别统一类型的欺骗类型工作者也可以适用于此方法.UniformSpamw=∑s∈S|s|·(fs,Jw-1)∑j∈Js,w∑i∈Jj,w-S是所有分类可能的序列s的集合,由于我们的实验平台中一个网页中含有5项评估任务,我们Page7设置集合S的长度为5,即|S|=5.disagreeij表示关于同一(查询/文档)对j,工作者w所做的相关性判断Js,w(在序列s中出现的分类)与其他工作者w-提交的不一致数,fs,Jw表示工作者w标记的查询/文档序列s在其所做判断集合Jw中出现的频数.根据以往的实验经验,式(1)选取评判分数0.7,式(2)选取评判分数1.6,能够有效地发现随机类型和统一类型的欺骗类型工作者.3.3.4期望最大值算法估计工作者的误差率本文与文献[14]一样,都采用了Dawid等人[15]提出的期望最大值算法(EM算法)思想,对多个观察者观测数据的误差率进行极大似然估计,推测出每个工作者对观察数据所做分类的误差率,算法不断迭代直到收敛.同样,在多个工作者所需完成众包任务的实际情况中,可以利用极大似然估计方法,估计出工作者提交结果的误差率,从而实现对工作者众包任务完成质量的自动评估.下两个步骤:EM算法不断循环迭代直到收敛,主要分为以(1)利用多个工作者所做的标记分类(相关或不相关),估计出每项任务的正确答案.(2)通过工作者提交的答案与估计得到的正确答案进行比较,得到对工作者提交结果的整体质量评价.算法的最终输出结果是每项任务估计出的正确答案和每个工作者的“混合矩阵”.根据所得“混合矩阵”的元素,能够得到每个工作者的总体误差率,这个结果作为每个工作者质量评价的一个标量值.首先输入N项众包任务的一个未知的真实分类标记T(On),分类的取值范围是1和0,分别表示相关和不相关.每一项任务被提交给多个不同的工作者进行相关性评估,每个工作者会最终得出任务评估结果质量的标量.为了测量每个工作者最终完成任务的质量,算法赋予工作者(k)一个“混合矩阵”ij,这个矩阵给出了,当一项相关性评估任务的真π(k)实分类是i,工作者(k)将其分到类j的概率.定义1.考虑共计有K个工作者,工作者的符号标记为k=1,…,K,这些工作者均要完成I项评估任务,评估任务的符号标记为i=1,…,I.nk作者k对评估任务i做出的相关性评价结果是l的次数.定义2.{Tij:j=1,…,J}是相关性评估任务i的一组指示变量,如果已知某一项评估任务的相关性结果为q(1qJ),即该任务的真实答案是q,则Tiq=1,Tij=0(j≠q).定义3.本文实验中的相关性评估任务是从众多任务中随机挑选而出,pj表示随机挑选出真实相关性是j的相关性评估任务的概率.考虑单独一项众包任务与单独一个工作者的情况.如果q是评估任务的真实相关性,那么每种相关性标记的次数服从二项分布,似然函数如下:由于所有工作者之间完成任务是相互独立的,则当Tiq=1的条件已知时,评估任务i的相关性标记次数的似然函数如下:Tiq=1的限制条件未知情况下的似然函数:式(5)是单独一项任务的全数据情况下的似然函数,函数由J项乘积组成,但是其中有J-1项的值为1(当Tij=0,j≠q),剩余一项的形式是:p(data|Tiq=1)p(Tiq=1).又由于所有工作者之间不受影响相互独立,则全数据情况的似然函数如下:若式(6)中n(k)都已知,则可以计算极大似然估计,得到每一个变量的估计值:而当概率值pj(j=1,…,J)未知时,可以估计出pj的值:当工作者的个人误差率{π(k)已知,而评估任务的真实相关性未知时,可以应用贝叶斯理论获取到指示变量Tij(j=1,…,J)的估计值.已知先验概率,p(Tij=1)=pj.如果所有评估任务的相关性结果数据都已知,依据贝叶斯理论:p(Tij=1|data)=p(data|Tij=1)p(Tij=1)/p(data)=∏K在实验中,如果事先不知道每项评估任务的真实相关性,即相关性答案Tij(j=1,…,J)未知,则全数据的似然函数为Page8由于存在隐藏变量{Tij;i=1,…,I,j=1,…,J},很难计算出p和π的极大似然估计.但可以根据EM算法不断迭代,计算出p和π的估计值.因此可以做如下处理:然估计值.计算T的新估计值.(1)初始化估计数T的值.(2)利用式(7)和式(8),计算p和π的极大似(3)利用式(9)和上一步估计出的p和π的值,(4)重复步(2)和步(3),直到结果值收敛.在步(3)中计算Tij的估计值等于E(Tij|data)=p(Tij=1|data).则估计值Tij可被表示为评估任务i的真实相关性是j的概率.最终p和π的估计值为式(10)计算出的极大似然估计,T的最终估计值是每个评估任务的真实相关性的概率.工作者质量估计的期望最大值(EM)算法如关性T(On),每个相关性分类C的先验概率Pr{C}图3所示.输入:工作者(k)标记评估任务On的数据元组犾[k][n]输出:每个工作者(k)混合矩阵π(k)Begin1.初始化每个工作者(k)的误差率矩阵.2.初始化每个评估任务的正确相关性T(On).3.While没有收敛do4.根据工作者对评估任务On做出的相关性结果犾[·][n],5.根据上一步估计出的正确相关性T(On)和相关性分类6.对应每个相关性C,估计其先验概率Pr{C}.7.End-While8.return估计出的每个工作者(k)的误差率矩阵π(k)每个评估任务On的正确相关性T(On),估计出的每个相关性分类C的先验概率Pr{C}.9.End根据初始的分类数据,我们可以设置Tiq的初始值,一般采用大多数原则,即通过设定Tiq的初值,算法开始执行多步迭代,分别对p和π进行极大似然估计,计算得出每一种分类的边缘概率和每个工作者的分类误差矩阵,在很多实际环境中,关联误差率矩阵表示法要比个人误差率矩阵显得更加直接,通过pjπ(k)作者的关联误差率.矩阵对角线元素的和是一个工作者提交结果正确情况下的概率估计值,对角线上下元素(非对角线元素)的和反映出工作者的误差概率.硬件:方正电脑一台,4GB内存,4核处理器,主软件:MyEclipse8.5、Tomcat6.0、MySQL5.1、4实验与结果分析4.1实验环境频3.2GHz;STATA软件包.4.2实验数据实验的数据来源于“TREC-7adhocandTREC-8filteringtopics”中的4个主题,分别是:Number:351Falklandpetroleumexploration,Number:357territorialwatersdispute,Number:358blood-alcoholfatalities,Number:360druglegalizationbenefits.根据TREC会议已知的文档相关性结果,从提供的ForeignBroadcastInformationService数据中,选取了1380条文档作为任务候选文档集合,其中含有1120条不相关文档,260条相关文档.4.3实验结果分析实验分为以下3个部分:(1)黄金标准数据方法评估;(2)结果质量评估方法的有效性;(3)阶段式动态质量控制策略可行性.4.3.1黄金标准数据方法评估黄金标准数据在众包中的应用,传统的做法都是在众包任务集合中参杂一定数量的黄金标准数据.由于这些数据已知标准答案,通过将工作者提交结果与标准答案的对比,可以评估工作者提交结果的质量.本文则采用另外一种用法,我们将一定比例的黄金标准数据重复掺杂在工作者的任务中(选择那些比较简单可以很容易确定答案的数据).这样既可以通过黄金标准数据来检测工作者提交结果的质量,又可以通过考察工作者在回答相同题目前后结果的一致性,来考察工作者的认真态度,直观来讲如果工作者对重复题目的回答前后一致性越高,则表示其工作态度越认真;反之,则表示工作者的态度越不认真.但是其对全部结果的质量会发生怎样的影响,以及和工作者完成的任务数量、完成相同任务的不同工作者数目等几个因素之间的关系并不清晰,下面通过实验来考察这些因素对最终结果误差率的影响.我们招募了50名工作者参加该项测试,并且从1380个文档中选择了10文档作为黄金标准数据,Page9然后利用这10个文档与剩余的其它1370个文档构造了3类测试集合,分别包含10个文档、20个文档和30个文档,其中每一类都按照黄金数据所占10%、20%、30%、40%和50%等不同比例构造一组测试集.由于我们选择黄金标准数据的数量为10,因此对于30个文档的这一类测试集合,只能构造到30%的比例,由于要求黄金标准数据重复的出现在工作者的任务中,因此其所占比例最高就是50%.在真实的众包工作环境中,一般要避免让工作者意识到“黄金标准数据”的存在,否则其可能会有针对性的造假,无法对其工作进行准确和客观的评价.为了在实验中更好地模拟这种真实情况,我们将测试用的10个文档、20个文档和30个文档打包在规模为100个文档的任务包中,并且让这些重复的图4评估10个任务的平均误差率图5评估20个任务的平均误差率黄金标准数据文档出现的间隔比较大,尽可能降低其被发现是重复问题的概率.当工作者完成这100文档相关性判断任务后,我们考察其在事先设定的文档集上提交的结果.从图4~图6中可以观察到“黄金标准数据”所占比例与平均误差率之间并没有显示的关联关系.但是我们在小规模任务集上测试结果显示,随着黄金数据所占比例的增大,平均误差率呈现降低的趋势,这是因为在小规模的数据集中,工作者很容易发现有重复题目出现,因此他们会因此而有针对性地回答.这个实验也给我们提供了一个很有意思的提示,那就是可以让工作者事先知晓存在黄金标准检测数据,但很难确定其具体在何处,这有些类似于高速公路上的超速摄像头起到监督作用,促进工作者保持认真的态度.该思想可以体现在任务的设计过程中.Page10图6评估30个任务的平均误差率参加任务的工作者人数与平均误差率之间表现出了一些关联.3组实验结果均显示,每个任务由10名工作者来完成,所得结果的平均误差率最低.并非工作者人数越多结果误差率就会越小,由于受限于实验的规模,尚未了解更多人数参与时平均误差率的变化情形.但是实验结果至少告诉我们,在给定任务的前提下,如何选择恰当数量的工作者使得在费用开销与结果质量等多方面获得最优目标是一个值得深入探索的问题.另外,从图4~图6中也可以看出,当任务数量和工作者数量达到一定规模后,平均误差率的变化趋于平缓稳定.这是因为,当工作者人数和任务规模较小时,个别工作者和个别问题的偶然性因素对整体会产生较大的影响,而随着规模的增大,这种影响逐渐被弱化,从而使得结果趋于稳定.4.3.2结果质量评估方法有效性我们在ForeignBroadcastInformationService提供的1380条判断文档信息的基础上,随机抽取出35条相关文档,65条不相关文档,共计100条文档(均具有相关性判定的标准答案),打包成一项众包工作,然后将此项工作分派给网络在线的76名具有计算机背景的学生来完成相关性判定.首先检测工作者的类型,根据工作者类型评分公式,得到相应的分数,表1给出了前几位工作者的类型分值.从工作者类型检测实验结果来看76名工作者都通过了工作者类型测试.这些工作者都没有故意对所有文档随机选择答案或选择一种答案的情形出现,但是却有个别工作者对小部分文档采用了随机选择答案或选择默认值的方式,由于这些文档数量很少,因此对整体影响不大.工作者ID下面我们考察EM算法估计答案的准确性,表2给出了EM算法根据76名工作者提交结果所得估计答案的准确率.从表中可以看出,对相关性文档的估计准确率为82.8%,对不相关文档的估计准确率为81.5%,全部100个文档的总体估计准确率为82%.这个结果并不是很高,主要是因为工作者的平均准确率比较低.由于EM算法是依据工作者提交结果来估计答案的,而估计的答案是偏向于那些被更多人所做的选择.通过对76名工作者提交的结果分析可以看到,在一些文档的相关性判断上,大量的工作者都做出了错误的选择,而这直接影响到EM算法对这些文档估计答案的准确性.另外,为了确定前文提出的阶段式动态质量控制策略是否具有实际可行性,需要考察两点:Page11(1)EM等评估算法是否能够有效找出不合格的工作者;(2)阶段式动态质量控制策略是否能够提升结果的质量.在阶段式动态质量控制模型中,需要依据EM算法估计的答案来对工作者是否合格进行判断,因此必须要考察工作者在EM估计答案下的准确率与在标准答案下的准确率之间是否具有一致性.如果不一致,则意味着EM算法不适合用来衡量工作者提交结果的质量.表3给出了这76名工作者提交结果在标准答案下的准确率和在EM估计答案下的准确率.表3工作者在标准答案和EM答案下的准确率工作者ID1.0.790.6939.0.800.782.0.570.5940.0.670.673.0.600.4841.0.870.814.0.650.6542.0.630.595.0.710.6543.0.730.696.0.470.5744.0.650.637.0.660.6845.0.700.688.0.730.7146.0.470.419.0.720.7247.0.830.7910.0.720.7648.0.780.7811.0.340.3849.0.720.6612.0.590.6150.0.760.7213.0.790.7551.0.690.5714.0.700.7052.0.710.6515.0.870.8353.0.490.5316.0.750.7154.0.740.7217.0.410.3555.0.840.7818.0.430.4556.0.410.3719.0.780.7457.0.820.7620.0.400.3858.0.840.7621.0.480.4259.0.610.6522.0.780.6660.0.480.4623.0.530.4761.0.550.5924.0.670.6362.0.810.7525.0.770.6563.0.840.7826.0.790.7964.0.840.7827.0.370.3565.0.780.8228.0.700.7266.0.660.7229.0.720.7467.0.830.7730.0.680.6668.0.800.7031.0.700.7469.0.810.7732.0.530.4770.0.720.7433.0.510.4971.0.820.7634.0.680.6272.0.800.7235.0.640.6473.0.730.6936.0.690.7374.0.810.7737.0.450.4375.0.430.3938.0.800.7276.0.830.85标准答案下的平均准确率EM答案下的平均准确率从表3可以看到,全体工作者在标准答案下的平均准确率为0.677,换句话说平均误差率为0.323.在76人当中准确率低于0.60的有19人,占总共作者人数的25%.通过与这些工作者交流发现导致准确率不高的主要原因有两点:(1)所有的相关性判断文档均为英文,且含有很多的专业词汇,语言是个障碍;(2)所选文档涵盖石油勘探、领海争端和毒品合法化等主题,工作者对这些领域都十分陌生,几乎没有人拥有这几个领域的背景知识.在进行相关性判断时,很多工作者都是利用了各种电子词典来辅助进行判断,但生词太多内容仍然不易理解,导致判断起来比较吃力.如果所分发的任务属于熟悉的领域,如计算机领域,则准确率将会得到显著提高.为了更直观地观察所有工作者在标准数据答案下的准确率和在EM算法估计答案下的准确率之间的一致性程度,我们将工作者在两个答案下的准确率绘制成图,如图7所示.可以看到两者的变化趋势十分一致,76名工作者在两个答案下准确率的平均绝对值差仅为0.044.这说明在不同检测点阶段应用EM算法估计的答案来对工作者进行评估是可行和有效的,这也使得本文提出的阶段性动态质量控制策略在实际中具有良好的可行性.图7工作者在评估结果与标准结果下的准确率4.3.3阶段式动态质量控制策略评估下面将通过实验来验证阶段性动态质量控制策略确实可以提升整体的结果准确率.为此,我们设计了如下实验方案:首先,选择50名工作者来完成100个文档的相关性判断任务,考察其在不设阶段检测点的情况下最终结果的准确率.这里我们选择了3组50名工作者集合的不同样本,最终使用3组样本的准确率平均值进行比较.其次,我们对检测点的设置考察了3种情况:每10个文档设置一个检测点,每20个文档设置一个检测点和每50个文档设置一个检测点.为了评价结果质量评估算法在各个检测点的有效性,本文提出了两个度量:淘汰召回率和淘汰准确率,其定义分别如下:Page12淘汰召回率=算法找到的不合格人数淘汰准确率=算法找到的不合格人数淘汰召回率越大,意味着算法可以更好地识别不合格工作者,这也意味着最终结果的质量会越高;淘汰准确率越高,意味着算法能够更准确地识别合格工作者.理想情况是这两个度量值都等于1.本文实验中采用的淘汰阈值为0.6,即如果工作者在某一阶段的准确率低于0.6,那么他将被认为不合格而被替换.表4~表6分别给出了3种检测点设置情况下,各个阶段使用EM算法淘汰不合格工作者的结果,其中最后一列表示在这个阶段中EM算法给出的估计答案的准确率.总体来讲EM算法的淘汰召回率达到了0.8以上,也就是说可以找到绝大多数的不合格工作者.同时,我们也发现淘汰准确率只有0.62,说明算法在检测点处淘汰了过多的合格工作者,这也意味着,我们需要招募更多的工作者放到工作者池中,任务完成的时间延迟相应也会大.因此,在保障结果质量的前提下,如何提高算法的淘汰准确率是一个值得研究的问题.阶段淘汰1~10180.770.550.811~2040.681.000.921~3071.000.290.631~4060.680.330.841~50160.830.311.051~60120.700.580.961~7050.831.001.071~8050.831.001.081~9061.000.000.791~10021.001.000.8平均率阶段淘汰1~20110.770.910.8021~4080.570.500.7041~60131.000.230.8561~8090.901.000.9081~10040.680.500.80平均率阶段淘汰1~50150.920.800.6651~10090.680.440.88平均率表7则给出了在不采用阶段式动态质量控制策略情况下,3个不同样本所得结果的准确率.通过观察表4~表7,可以看到检测点的选择对最终结果的质量确实是有影响的.本文实验中,每10个文档设置一个检测点的方式获得了最高的结果准确率85%,而不采用阶段式动态检测方法的结果准确率为80%,提高了5个百分点.每20个文档设置一个检测点的方式结果准确率为81%,结果的质量仅略有提升.每50个文档设置一个检测点的方式结果准确率为77%,比不设置检测点的方式结果准确率还有所降低.经过仔细核查实验数据和流程之后,我们发现上述3组实验过程中,最后一个阶段91~100、81~100和51~100完成后,都没有执行评估和淘汰的检测步骤,在这一阶段中不合格工作者的结果并没有去除掉,这对最后的结果质量造成了影响.显然,最后一阶段的任务所占比例越大,这种影响就会越大,上述实验结果恰好也体现了这一点.事实上,阶段式动态质量控制策略无论怎样都会存在这样一个最后阶段,因此最好的解决方案就是减少检测点之间的间隔,使得最后一个阶段的影响变小.理论上检测点之间的间隔越小,最终结果的质量就会越高.但是间隔小就意味着我们需要进行更多的检测,需要招募更多的工作者来替换那些被淘汰的工作者,同时检测环节的增多也会增加任务完成的时间.在保证结果质量、成本要求和完成时间的前提下,如何合理设置检测点是今后需要深入研究的一个问题.5结论本文针对众包质量控制问题开展了相关研究工作,提出了阶段式动态众包质量控制模型,该模型的流程主要是“结果评估-工作者替换”的迭代操作,其中结果评估是整个流程的关键部分,为此本文提出了组合式的工作者提交结果质量评估方法.实验结果证明了该模型和结果质量评估方法的可行性和实用性,为后续的众包质量控制方面的研究奠定了基础.本文方法由于设定了检测点,因此需要多花费Page13一些时间来进行检测和替换,这样会延长一些完成任务的时间,也是为了获得更高的结果质量付出的代价.如果根据工作者提交可接受任务结果数量来付费的话,我们的方法其实并没有为此多付费,因为虽然分阶段质量控制策略会比正常情况下多招募一些工作者,但是所有工作者提交任务结果的总数并没有增加(每位工作者提交的结果的平均数量会少).当然为了缩短任务完成的时间,也可以通过多招募一些工作者和多支出一些费用来更快地完成任务.另外,本文提出的黄金标准数据应用方法和阶段式动态质量控制策略对工作者组织方式和任务设计方面的研究也具有一定的借鉴意义.在后续工作中,我们将对以下几个问题进行探讨:(1)如何依据用户的背景和任务要求进行个性化的任务分配;(2)考察多种不同的结果评估算法之间差别,设计更好的组合式评估方法;(3)在保证结果质量、成本要求和完成时间的前提下,如何合理设置检测点;(4)考察本文方法在不同任务类型下的实际效果.
