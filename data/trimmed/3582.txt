Page1非对称多核处理器上的操作系统集成调度陈锐忠齐德昱林伟伟李剑(华南理工大学计算机系统研究所广州510006)摘要相对于对称多核处理器,非对称多核处理器具有更高的效能,将成为未来并行操作系统中的主流体系结构.对于非对称多核处理器上操作系统的并行任务调度问题,现有的研究假设所有核心频率恒定,缺乏理论分析,也没有考虑算法的效能和通用性.针对该问题,该文首先建立非线性规划模型,分析得出全面考虑并行任务同步特性、核心非对称性以及核心负载的调度原则.然后,基于调度原则提出一个集成调度算法,该算法通过集成线程调度和动态电压频率调整来提高效能,并通过参数调整机制实现了算法的通用性.提出的算法是第一个在非对称多核处理器上结合线程调度和动态电压频率调整的调度算法.实际平台上的实验表明:该算法可适用于多种环境,且效能比其他同类算法高24%~50%.关键词绿色计算;非对称多核处理器;操作系统调度;并行任务调度;动态电压频率调整;负载均衡1引言IT行业作为全球增长最快的行业之一,其能耗也随着行业的增长而不断增长.文献[1]指出:2008年IT设备总共消耗8680亿度电,占全球总耗电量的5.3%;按照目前的增长趋势,到2025年,IT行业平均能耗会达到2006年的5倍.能耗问题已成为信息系统持续发展的重大障碍.如何提高计算机的效能,实现绿色计算,是当今的一个研究热点.随着芯片集成规模极限的逼近以及能耗和成本等因素,多核处理器逐渐占据了市场[2].相对于对称多核处理器(SymmetricMulti-coreProcessor,SMP),单一指令集非对称多核处理器(AsymmetricSingle-ISAMulti-coreProcessors,AMP)具有更高的效能,更符合绿色计算的要求,将成为未来的主流[3-4].现有操作系统调度器从单核处理器发展而来,并为SMP做了相应扩展,不能发挥AMP的效能优势.这为操作系统调度带来了新的机遇和挑战.随着多核技术的发展,并行程序日益普及[2,5].由于AMP上每个核心支持同一指令集结构,任务可以在不同核心上正确执行;而由于核心间的性能异构性,并行度不同的任务在不同核心上的执行效率却是不同的.如何利用并行任务的同步特性和AMP的非对称性,实现高效能的操作系统调度,是该形势下的一个关键问题.近年来有一些研究关注这一问题,但都假设所有核心频率恒定,没有建模分析影响调度的各个因素,也没有考虑算法的效能和通用性,不能很好地解决该问题.其中:文献[6]没有考虑任务的同步特性;文献[7]需要频繁地迁移任务,从而带来巨大开销;文献[8]假设系统运行的线程总数不大于核心总数,但现实中这一假设往往难以满足.因此,本文以效能和通用性为目标,为AMP上操作系统的并行任务调度问题建立了非线性规划模型,分析了任务的同步特性和核心的非对称性,得出调度应遵循4个原则:(1)同一任务的各个线程在同类核心上运行,但不在同一个核心上运行.(2)各核心负载均衡.(3)协同调度同一任务的各个线程.(4)使参与协同调度的各个核心频率相等.在此基础上,本文提出一个集成调度算法,其特点如下:(1)集成线程调度和核心动态电压频率调整(DynamicVoltageandFrequencyScaling,DVFS),保证4个调度原则,提高系统效能.(2)提供参数调整机制,以适应多种机器配置.(3)通过状态监控机制和任务集合分解降低调度开销.据我们所知,还没有研究对该问题进行建模分析,本文是第一个在AMP上结合线程调度和DVFS的算法.本文在Linux2.6.27和多种配置的AMDOpteron2384上对算法的效能、通用性和开销进行比较分析,实验证明了该算法的有效性.本文第2节对问题进行描述和建模分析,给出调度的目标和原则;第3节详细描述集成调度算法;第4节对所提出的算法进行实验和比较分析;第5节介绍相关研究;最后是总结以及对未来工作的展望.2问题描述与建模2.1问题描述题,关注的目标如下:本文研究AMP上操作系统的并行任务调度问效能:最小化系统的EDP(EnergyDelayProd-uct)[9].EDP是系统的能耗与执行效率之比,EDP越低,系统效能越高.通用性:适用于核心性能差异程度不同的AMP平台.下面通过一个简单的例子来说明该问题.示例中的AMP包含8个核心(如图1,图2):Core1~Core3是快核心,Core4~Core8是慢核心,快核心的计算能力是慢核心的2倍.该平台上运行4个任务(P0,P1,P2和P3),每个任务包含2个线程:T1和Page3T2属于P0,T3和T4属于P1,T5和T6属于P2,T7和T8属于P3.每个线程优先级相等,属于同一任务的2个线程每隔2个单位时间就要同步一次,然后继续运行.文献[7]表明:由于parallel-for、fork-join等结构在并行编程中的广泛使用,并且程序员倾向于平衡各个并行线程的负载,同一任务的各个线程计算量趋向于相等.图1给出一个现有操作系统中的线程调度示例.现有操作系统调度器没有考虑核心的非对称性,将线程随机映射到低负载的核心上,这不符合绿色计算的要求:当属于同一任务的几个线程分配到性能不同的核心上执行时,将导致快核心上的线程等待慢核心上的线程同步的情况,此时快核心仍在消耗能量,从而降低效能(如图2中T1和T2同属于P0,却分别映射到异类核心Core1和Core4上,导致等待;P1和P2亦然).图2给出了理想的操作系统调度示例.(1)它将属于同一任务的线程调度到类型相同的核心上运行,从而避免了线程空等的情况,并将节省下来的CPU时间用于调度其他线程(如图2中的Tx),从而提高了效能.(2)当无法保证同一任务的所有线程在同类核心上执行时,它将运行这些线程的快核心频率降低到与慢核心相等(如图2中的Core3),在不影响任务完成时间的情况下降低了能耗.本文提出的调度算法实现了这种调度.下一节将对AMP上操作系统的并行任务调度问题进行建模分析.2.2调度模型我们可以为AMP上操作系统的并行任务调度问题建立非线性规划模型:设T=T1,T2,…,T{n个线程的任务,所有线程每隔一定时间间隔需进行同步,线程Ti可根据同步间隔分为Ni个阶段T1i,T2i,…,TNi{操作,Tkic表示Tki计算操作的工作量,Tkist表示Tki同步操作所需的时间.根据文献[7],本文假设同一任务的各个线程具有相等的计算量.C=C1,C2,…,C{个核心的单位时间计算能力为Ci.为了避免频繁上下文切换带来的巨大开销,我们假设式(1)成立:一个任务包含的线程数,不大于物理核心总数.T的调度可抽象为一个时空映射M=(s,t),其中s是一个空间映射,表示将T的各个阶段映射到核心上;t是一个时间映射,表示将T的各个阶段映射到核心的时间片上.设t(Tmk)表示Tmk的开始时间,即Tmk分配到的时间片,由任务执行的时序关系,只有所有前驱阶段都完成了,一个新阶段才能开始,即式(2)成立,其中TmkcTmk的核心的性能Ci相关.TimeM(T)表示映射M下T的完成时间,它等于T最后阶段中运行最慢线程的完成时间,满足式(3).EDPM(T)定义为系统的能耗与执行效率之比[9],即式(4),其中Energy_Con-sumed表示系统的总能耗,Instructions_per_Second表示单位时间执行的指令数,Averge_Power表示系统的平均功率,Total_Instructions(T)表示任务T指令总数.因此我们可得该问题的非线性规划模型如下:MinimizeEDPM(T)但在现实中由于缺乏Tmic和Tmist的先验知识,加上求解该问题带来的开销,无法求得该问题的最优解.因此我们采用启发式算法来求问题的近优解.由于式(4)中的Total_Instructions(T)是定值,故最小化EDPM(T)等价于最小化Averge_Power和TimeM(T).Averge_Power可通过DVFS技术[10]动态调节,文献[4]预测未来的AMP将由少量复杂stTC烄maxkt(Tmk)+Tmkcfor0<k,l<Tandm<nTimeM(T)=maxkt(TNkk)+TNkkc烅EDPM(T)=Energy_Consumed=Averge_Power×Time2M(T)烆Page4核心(快核心)和大量简单核心(慢核心)组成,而出于成本、芯片面积等方面的考虑,简单核心很可能不具备DVFS功能.故本文假设简单核心的功率固定,Averge_Power的变化来源于复杂核心功率的变化(通过DVFS).下面我们研究在操作系统中通过线程调度和快核心的DVFS来降低EDPM(T).由式(2),(3)可推出等式(5).TimeM(T)=∑p其中p是任务T的阶段数目,由T本身属性决定,无法通过调度优化.结合式(4),可见AMP上操作系统的并行任务调度应遵循的原则如下:(1)同一任务的各个线程在同类核心上运行,但不在同一个核心上运行.同类核心指性能相等的核心.由式(2),(3)和等式(5)可知任务完成时间取决于运行最慢的线程,如果将同一任务的各个线程放到性能不同类的核心上运行,即Tmkc核心上的线程同步的情况(如图1的示例).而当同一任务的各个线程放在同一核心上运行时,任务变成串行执行,完成时间TimeM(T)=∑pk{TjkcCi+Tj该原则.(2)各核心负载均衡.由式(2)可知任务每一阶段的完成时间取决于运行最慢的线程.当负载不均衡时,轻负载核心将空转,而重负载核心的调度周期将延长,这降低了系统的效能,并使本阶段的Tmkst和下一阶段的t(Tm+1k)增大,进一步增加了运行最慢的线程的完成时间.因此各核心应保持负载均衡.(3)协同调度同一任务的各个线程.协同调度(co-schedule)指保证属于同一任务的所有线程同时运行;独立调度指调度时把线程看成一个独立实体单独运行,不考虑该任务的其他线程.协同调度在减少线程同步时间的同时,将带来优先级反转、处理器碎片等问题[11],增加开销.同一任务的各个线程计算量接近[7],并且同步较多,需要协同调度来减少Tmkst.串行任务可看成是单线程任务,此时协同调度等同于独立调度.该原则在减少同步时间的同时,使没参与协同调度的核心可运行其他任务,这避免了协同调度的碎片问题[11],提高了系统效能.(4)使参与协同调度的各个核心频率相等.随着多核技术的发展,并行程序日益普及[2,5],由于系统包括少量快核心和大量慢核心[4],容易出现多数任务的线程数超过快核心个数的情况,此时原则(1)和(2)将无法兼顾,这无法通过纯粹的线程调度来解决.由式(2)可知任务每一阶段的完成时间取决于运行最慢的线程.因此当异类核心同时参与协同调度时,我们通过DVFS将快核心频率降低到与慢核心相等,以避免快核心线程的等待,在保证TimeM(T)不变的同时降低Averge_Power,从而降低EDPM(T).3集成调度算法文献[4]表明:由少量快核心和大量慢核心组成的AMP具有很好的效能.因此本文假设AMP上有两类核心:少量快核心和大量慢核心.如何推广到n种核心是我们下一步研究的内容.该算法由4个模块组成:状态监控机制、重调度、负载均衡、任务执行,执行模型如图3所示.其中状态监控机制观察每个任务的线程数,当任务线程数发生变化时,调用负载均衡模块;当某个任务的类型(详见3.1节)发生变化时,调用重调度模块调整各个核心的任务队列.任务执行模块则负责同步执行同一任务的所有线程.3.1状态监控机制在运行过程中,任务的线程数将动态变化[7-8].本文根据任务当前运行的线程数把它们分成3类,定义如下:FCT=P|TLP(P)N(FCSCT=P|N(FC)<TLP(P)N(SCACT=P|TLP(P)>N(SCPage5其中:P表示一个任务,TLP(P)表示P当前运行的线程数;N(S)表示核心集合S包含的核心数目;FC表示快核心集合;SC表示慢核心集合.根据调度原则1)、2)和3),属于FCT的任务可以把所有线程映射到快核心上,因此适合在快核心上运行;属于SCT的任务线程数介于快核心数目和慢核心数目之间,没法把所有线程映射到快核心上,只好映射到慢核心上;属于ACT的任务线程数较大,只能同时映射到快核心和慢核心上,因此可在低负载的核心(快核心和慢核心都可以)上运行.任务迁移需要一定的开销[6],应尽量避免.状态监控机制是控制任务迁移的有效手段,它在线监测各个任务当前包含的可运行线程数,当任务线程数发生变化时,它调用负载均衡模块调整核心的运行队列;当任务的线程数变化触发了类型变化时(例如从FCT变成SCT),它调用重调度模块对该任务的线程进行重新映射.算法伪代码描述如下.算法1.状态监控机制.输入:任务P输出:无if(任务P的线程数发生变化){if(PreType(P)!=Type(P)){//P的类型发生变化}else{}}3.2负载均衡对于调度原则2),由于同类核心属于对称多核处理器,可使用现有操作系统的负载均衡算法,只需要加上调度原则1)作为限制;本文主要关注异类核心间的负载均衡.为了实现非对称多核处理器上的负载均衡———核心的负载与其计算能力成正比[6],本文定义SF(Ci)为核心Ci的比例系数(ScaledFactor,SF),即核心Ci当前频率与平台最低核心频率之比.设Load(Cj)表示核心Cj的负载(在Linux中可直接读取队列的成员变量load得到),核心集合S的平均负载AvgLoad(S)定义如式(7).当式(8)成立时,调度原则2)成立.其中α用于调整负载均衡,α趋向于0时,算法对负载均衡要求严格;α趋向于1时,算法可容许负载不均衡.AvgLoad(S)=AvgLoad(FC)∈(1-α)×AvgLoad(SC),1负载均衡模块主要在核心负载发生变化时调用,基本思想是通过快、慢核心间的线程迁移使式(8)成立.为了提高效率,算法对任务集合进行分解———为每种类型的核心S(本文为FC和SC)维护3个任务集合:set1(S),set2(S)和set3(S).set2(FC)=set2(SC),存放属于ACT的任务.set1(S)存放有线程在核心集合S上运行的SCT类的任务,set3(S)存放有线程在核心集合S上运行的FCT类的任务.当快核心负载过高时,算法按set1(FC)→set2(FC)→set3(FC)的次序选择任务迁移到慢核心上;当慢核心负载过高时,算法按set3(SC)→set2(SC)→set1(SC)的次序选择任务迁移到快核心上.算法伪代码描述如下.算法2.负载均衡.输入:无输出:无if(AvgLoad(FC)>AvgLoad(SC)/(1-α)){while(AvgLoad(FC)>AvgLoad(SC)/(1-α)){//快核心负载过高}}elseif(AvgLoad(FC)<AvgLoad(SC)(1-α)){//慢核心负载过高while(AvgLoad(FC)<AvgLoad(SC)(1-α)){Page6}}3.3重调度根据调度原则1)和2),重调度模块的基本思想是在兼顾负载均衡的情况下,将属于FCT的任务的各个线程映射到快核心上,将属于SCT的任务的各个线程映射到慢核心上,将属于ACT的任务的各个线程映射到低负载的核心上.算法伪代码描述如下.算法3.重调度.输入:任务P输出:无将P的线程移出各核心的运行队列,并更新AvgLoad(FC)if(Type(P)=FCT){AC=FC中TLP(P)个负载最轻的核心;}elseif(Type(P)=SCT){AC=SC中TLP(P)个负载最轻的核心;}else{AC=所有核心中TLP(P)个负载最轻的核心;}将P包含的可运行线程分别映射到AC的每个核心上;更新AvgLoad(FC)和AvgLoad(SC);balance();//负载均衡3.4任务执行我们将参与协同调度的核心分成发起者和协作者.设CT(Ci)表示核心Ci正在运行的线程,算法操作如下:若CT(Ci)属于一个多线程程序,Ci成为发起者,发送核心间中断到其他核心,收到中断的核心(成为协作者)将执行与CT(Ci)同属一个任务的其他线程;否则CT(Ci)单独运行.根据调度原则4),当快、慢核心同时参与协同调度时,算法将快核心频率降低到与慢核心相等.当TLP(CT(Ci))小于核心总数时,没参与协同调度的核心可运行其他任务,这避免了协同调度的碎片问题[11],提高了系统效能.算法伪代码描述如下.算法4.协同调度的发起者及独立调度.输入:核心Ci输出:无if(CT(Ci)属于多线程程序){if(Ci∈FC){//根据调度原则4)调整核心频率if(Type(CT(Ci))!=FCT){}Threads=与CT(Ci)同属一个任务的线程集合;cores=Threads所在的核心集合;for(cores中的每个核心C){//发送核心间中断到cores,以同步执行Threads;}}else{CT(Ci)在Ci上执行;}算法5.协作者.输入:核心C,线程集Threads输出:无T=C上属于Threads的线程;if(C∈FC){//根据调度原则4)调整核心频率if(Type(T)!=FCT){}elseif(C频率与慢核心相等){}}在C上执行T;3.5参数调整机制如前所述,AMP上的操作系统调度需要综合考虑核心性能、核心负载、任务并行性等因素,其中核心性能和负载在不同架构的处理器上优先级不同.为了使算法在各种核心性能差异程度不同的平台上都获得高效能,需提供优先级调整的机制.算法提供了参数α用于调整优先级(见式(8)).参数应根据实际情况设置,比如对于核心性能差异很大的AMP,核心性能优先级较高,α应取接近1的数;对于核心性能差异较小的AMP,α应取接近0的数,以通过负载均衡提高效能.3.6算法运行开销设M表示任务总数,N表示核心总数,算法需要为每类核心维护任务集合,空间复杂度为O(M).算法的时间开销主要来自以下3个方面:(1)负载均衡.该模块时间复杂度为O(MN),但现实中基本只需要迁移一两个任务即可实现负载均衡,并且任务集合分解提高了线程迁移效率,因此该模块的平均时间复杂度接近O(N).(2)重调度.该模块时间复杂度为O(N).(3)任务执行.协同调度在减少线程同步时间的同时,将带来额外的上下文切换.不过算法采用了协同调度和独立调度相结合的方法,使没参加协同调度的核心可以运行其他任务,这避免了碎片问题.此外,状态监控机制有效避免了不必要的负载均衡和重调度,特别是重调度只在任务类型发生变化时使用,因此算法的开销并不大.这将在4.2.2节的实验中得到进一步验证.Page74实验与分析4.1实验平台与方法本章将集成调度算法(IntegratedAlgorithm,IA)与Agebased[7]、PA[8]、FF[6]和Linux自带的调度器[12](CompletelyFairScheduler,CFS)进行比较.其中CFS没有对处理器的非对称性做处理.本文采用Linux2.6.27来实现和运行上述各个算法.本文的实验平台是一台2路AMDOpteron2384服务器.AMDOpteron2384是对称多核处理器,包含4个2.7GHz的核心.本文用Linux提供的cpufreqgovernors调整各个核心的频率,以体现非对称性.本文使用了3种配置,如表1所示.其中Conf1和Conf2是AMP,用于测试算法的效能、通用性和参数灵敏度;Conf3是SMP,用于测试算法的开销.α的取值结合测试平台配置和经验确定,α取其它值时算法的表现详见4.2.3节.测试程序选自PARSEC[13].由于测试平台包含2个快核心和6个慢核心,为了更加全面地比较各个算法在不同平台配置下的效能,我们设计了多种类型的并行程序组成的测试程序集,如表2所示.为了使负载均衡机制生效,我们使每个程序集的线程总数大于平台的核心总数.测试程序后括号中的数字n表示该程序包含n个线程.根据研究文献[6,8]的实验方法,我们把每个程序集在每个调度算法下分别运行3次,取相应指标的平均值作为度量;实验中我们发现每次运行结果差异不大,每个算法都体现较好的稳定性,因此我们没有对稳定性进行单独分析.平台αConf10.32个核心运行在2.7GHz下,Conf20.12个核心运行在2.7GHz下,Conf308个核心都运行在2.7GHz下.程序集W1canneal(2),freqmine(2),blackscholes(6),dedup(8)W2x264(2),bodytrack(3),blackscholes(5),dedup(8)W3fulidanimate(4),facesim(6),swaptions(8)W4canneal(2),fulidanimate(3),streamcluster(6),ferret(7)W5freqmine(2),blackscholes(8),swaptions(8)4.2实验结果与分析4.2.1效能与通用性分析每个程序集在不同算法上的EDP比较如图4、图5所示.为了便于比较实验结果,本文以CFS的EDP为基准对数据进行归一化处理,小于1表示EDP小于CFS,否则反之.图4给出了Conf1配置下各算法的相对EDP比较.由于快、慢核心的频率相差近1倍,核心性能差异对效能影响较大,核心负载次之,我们设定α=0.3.结果显示,IA的EDP比CFS低43%~50%,也比Agebased低24%~31%;EDP上Agebased比CFS低22%~34%,PA比CFS低17%~26%,FF比CFS低17%~23%.图5给出了Conf2配置下各算法的相对EDP比较.由于快、慢核心的频率相差0.7GHz,核心负载对效能的影响大于Conf1,我们设定α=0.1.结果显示,IA的EDP比CFS低43%~48%,也比Agebased低27%~33%;相对于CFS,Agebased能把EDP降低16%~23%,PA能降低10%~17%,FF能降低10%~16%.相对于没有针对AMP特性做处理的CFS,IA、Page8PA、Agebased、FF的效能都有不同程度的提高.这说明高效能的操作系统调度必须利用核心的特性.各算法按效能从高到低排序为:IA,Agebased,PA,FF,CFS.其中Agebased需要频繁地把进度最慢的线程迁移到快核心上,当处理存储密集型任务(如W4)时,将带来巨大的开销,使其效能低于PA.相对于其他算法,IA在每个程序集上都有明显的效能优势,这是因为它保证了4个调度原则,综合考虑核心非对称性、核心负载和任务同步特性进行线程映射和核心频率调整.当核心性能差异减小(如Conf2)时,PA、Agebased、FF相对于CFS的效能优势有所下降,而IA仍保持着43%~48%的EDP降幅.这得益于IA的参数调整机制,使其能根据不同环境调节核心性能差异和负载的优先级,从而在每个环境下都有效能提高.这说明了IA的通用性.4.2.2开销分析该实验运行在Conf3平台上.Conf3是SMP,我们使各个算法假设仍在有2个快核心和6个慢核心的平台上运行,以此来分析各个AMP上的调度算法相对于CFS带来的额外开销.测试程序在每个调度算法下分别运行3次,取完成时间的平均值作图6Conf3上各程序的相对完成时间4.2.3参数灵敏度分析该实验分析α的取值对IA效能的影响.图7,8分别给出Conf1和Conf2配置下各程序集实际EDP随α取值的变化.可见Conf1配置下IA在α=0.3时取得最优效能,Conf2配置下IA在α=0.1时取得最优效能.不同平台上,核心性能和负载的优先级不同,要取得好的效能需要平衡两者;在Conf1(Conf2)平台上,α=0.3(0.1)正好平衡了这两个因素.如图7、8所示,当α取值过大或过小时,效能都会降低.由此可见,IA提供的参数调整机制有效提高了算法的通用性和灵活性.为度量.当其中某个程序提前完成时,我们让其重新运行,以保持测试环境的稳定性.为了便于比较实验结果,本文以CFS的完成时间为基准对数据进行归一化处理,超过1表示算法的开销.实验结果如图6所示,包括每个程序的相对完成时间以及每个测试集的平均相对完成时间(图6中的geo-mean列).各算法按完成时间从小到大排序为:IA,CFS,FF,PA,Agebased.其中IA的开销很小,因为状态监控机制有效限制了线程迁移,任务集合分解提高了线程迁移效率,并且协同调度带来的收益大于其开销———即使在SMP上,完成时间相对于CFS的降幅可达到17%.Agebased、PA和FF没有协同调度,因此在SMP上完成时间都大于CFS.FF的开销主要来源于当快核心空闲时,将线程从慢核心迁移到快核心上,在各核心负载均衡的情况下,这种迁移并不多,因此开销略大于CFS.PA则由任务线程数的改变触发任务迁移,开销处于FF和Agebased之间.由于Agebased需要频繁地将剩余时间最长的线程迁移到快核心上运行,它的开销最大,特别是对于存储密集型任务(如W4).这验证了3.6节的算法开销分析,也进一步解释了各算法在4.2.1节中的效能表现.Page94.3实验小结基于以上实验,我们可以得出以下结论:(1)效能.相对于其他调度算法,集成调度算法具有明显的优势,能把系统的EDP降低24%~50%.(2)通用性.当核心性能差异减小时,其他AMP上的调度算法的效能优势有所下降,而集成调度算法仍保持着43%~48%的EDP降幅,这说明该算法具有很好的通用性.(3)开销.集成调度算法的开销优于其它算法,而协同调度的开销远小于其收益,即使在SMP上仍有良好的性能表现.5相关工作对于操作系统调度问题,之前的研究主要集中于SMP,这类平台上的调度算法主要是处理公平性、负载均衡[14]等,没有对AMP的非对称性做处理,无法发挥其优势.对于AMP上的调度问题,之前的方法[15-16]都依赖于任务执行时间等参数已知,但在操作系统中这些参数无法直接获得.因此,这些方法无法解决操作系统调度问题.本文讨论的AMP上操作系统的并行任务调度问题,近年来也有一些研究工作.其中文献[6]在保证核心负载与其计算能力成正比的同时,优先使用快核心,并对NUMA节点间的线程迁移做限制.该方法利用了AMP的特性,但没有考虑并行任务的同步特性,从而影响效能.文献[7]假设同一任务的所有线程运行时间相等,把剩余时间长的线程优先调度到快核心上运行.该方法利用了AMP的非对称性和并行任务的同步特性,但容易造成频繁的线程迁移,从而带来巨大开销.而本文的状态监控机制和任务集合分解有效控制了调度开销.跟本文比较相关的是文献[8],其提出的PA算法按照线程级并行度将任务分成3类:MP为并行度不大于快核心数目的任务;HP为并行度大于快核心数目的任务;SP为HP类任务的串行阶段.任务按使用快核心的优先级从高到底排列为:SP,MP,HP.该算法利用了AMP和并行任务的特性,开销也比较小.但本文和PA算法存在以下不同:(1)PA假设系统运行的线程总数不大于核心总数;本文则假设一个任务的线程总数不大于核心总数,这大大放宽了PA的限制.(2)PA没有同步执行同一任务的线程,这将导致线程间的互相等待;本文则协同调度同一任务的所有线程.并且文献[6-8]都是针对系统性能,假设所有核心频率固定,没有考虑算法的通用性,也没有对AMP上操作系统的并行任务调度问题进行建模分析.本文以效能和通用性为目标为该问题建立了非线性规划模型,结合线程调度和DVFS有效降低了系统的EDP.另外,有一些研究从不同于本文的角度研究AMP上的操作系统调度问题,文献[17]将计算密集型的任务调度到快核心上运行,将存储密集型的任务调度到慢核心上运行.这些方法针对串行任务,没有考虑并行任务的特性;而随着多核技术的发展,并行程序日益普及[2,5],并行任务的特性是操作系统调度必须考虑的.本文的方法和这些研究并不冲突,可以互相结合,文献[18]朝这个方向做了尝试,这也是我们下一步研究的内容.6结论与展望本文对AMP上操作系统的并行任务调度问题进行研究,建立了非线性规划模型,分析得出4个调度原则,并基于调度原则提出了集成调度算法.据我们所知,本文是第一个对该问题进行建模分析的研究,提出的算法是第一个在AMP上结合线程调度和DVFS的调度算法.实际平台上全面的对比实验表明:集成调度算法的效能、通用性和开销都优于其它同类算法.集成调度算法的效能优势来源于它综合利用了核心非对称性、核心负载和任务同步特性以及对线程调度和DVFS的有效集成,这也验证了调度原则的有效性;通用性来源于参数调整机制,它可灵活调节核心负载和非对称性的优先级,从而适Page10用于核心性能差异不同的多种机器配置;开销优势是因为状态监控机制控制了线程迁移,任务集合分解提高了迁移效率,并且协同调度带来的收益大于其开销.如何控制系统温度,以降低制冷设备的能耗,也是绿色计算的一个关键问题.研究操作系统调度对AMP温度的影响,将是我们下一步的工作重点.
