Page1使用联合链接相似度评估爬取Web资源张乃洲李石君余伟张卓(武汉大学软件工程国家重点实验室武汉430072)(武汉大学计算机学院武汉430072)摘要如何从Web上获取感兴趣的资源是许多Web研究领域重要的研究内容.目前针对特定领域Web资源的获取,主要采用聚焦爬行策略.但目前的聚焦爬行技术在同时解决高效率爬行和高质量的爬行结果等方面还存在许多问题.文中提出了一种基于联合链接相似度评估的爬行算法,该算法在评估链接的主题相似度时,联合使用了关于链接主题相似度的直接证据和间接证据.直接证据通过计算链接的锚链文本的主题相似度来获得,而间接证据则是通过一个基于Q学习的Web链接图增量学习算法获取.该算法首先利用聚焦爬行过程中得到的结果页面,建立起一个Web链接图.然后通过在线学习Web链接图,获取链接和链接主题相似度之间的映射关系.通过对链接进行多属性特征建模,使得链接评估器能够将当前链接映射到Web链接图的链接空间中,从而获得当前链接的近似主题相似度.在3个主题域上对该算法进行了实验,结果表明,该算法可以显著提高爬行结果的精度和召回率.关键词聚焦爬行;主题相似度;链接评估;Web链接图;Q学习1引言随着Web规模日益扩大,Web已经成为一个巨大的资料库.如何从海量的Web资源中发现感兴趣的信息,是目前许多Web研究领域(如Web信息检索和Web信息集成)重点研究的问题.该任务首先要在Web上获取目标数据集,然后再对目标数据集做进一步处理,如索引、信息提取、信息集成等.对目标数据集的获取,目前主要采用智能代理程序(也称为Spider或Crawler)来自动收集Web页面.Crawler的主要原理是:从给定的一些种子URL出发,采用一定的搜索策略,沿着Web超链结构进行爬行,最后达到遍历整个Web图的目的.根据任务的性质不同,Crawler的搜索策略主要分为两种[1-3]:一种是宽度优先搜索(breadth-firstsearch),另一种是最好优先搜索(best-firstsearch).前者典型的应用是通用搜索引擎,其爬行的目标是目标数据集尽可能地完备(即尽可能地遍历整个Web图),并且可以通过设置最大爬行深度,来有效地控制爬行的进程.后者典型的应用是垂直搜索引擎,主要用于搜集一些特定领域的信息.由于Web的规模呈指数式的增长,并且Web内容具有很强的动态性,这使得搜集特定领域信息的任务变得越来越具有挑战性.这种挑战性主要体现在:(1)如何自动发现和定位包含特定领域信息的Web页面;(2)如何进行高效率爬行;(3)如何获得高质量的爬行结果.要同时解决以上3个方面的问题,需要设计合适的爬行策略和精确的页面分类器.相对于Web的规模来说,特定领域的信息具有很强的稀疏性.在这种情况下,采用宽度优先搜索的策略势必造成爬行效率的低下、系统存储空间和网络带宽的浪费.此时,采用最好优先搜索是一种必然的选择.而聚焦爬行(focusedcrawling)[1-5]是最好优先搜索策略的一种实现.聚焦爬行的主要目标是:在Web上只爬取与主题相关的Web页面.理想的聚焦爬虫能够获取最大的相关页面集合而同时遍历最小数量的不相关Web文档集合[3],即能够获得最大收益率(harvestrate)[1-2].聚焦爬行实现最好优先搜索策略的基本方法是采用优先队列来存储待爬行的链接①(URL),该数据结构在聚焦爬行框架中也被称为边界管理器(frontiermanager)[1-2,4].当聚焦爬虫分析当前Web页面时,该页面所包含的链接(针对未被爬行过的URL)被赋予一个权值,该权值代表了链接将被爬行的优先级.由此可知,聚焦爬虫的关键技术是如何设计高效的链接评估(linkevaluation)函数,该函数用于分配链接的爬行优先级.然而在聚焦爬行过程中,最困难的问题恰恰是:在当前链接对应的页面被下载之前,如何判断该链接是否主题相关.此时,常用的方法是对当前链接的特征进行分析,然后做出优先级预测.这些方法包括对链接所对应的锚链文本、URL字符串、链接环境(Context)进行主题相似度分析.本文称这些方法为链接主题相似度的直接证据分析.但直接证据分析却无法解决普遍存在的延迟收益(delayedbenefit)问题.延迟收益[1-2,4-5]问题是指使用直接证据分析当前的链接,得出该链接主题无关.但实际上该链接经过若干个链接之后,又到达了目标页面(主题相关).延迟收益问题会降低系统的爬行收益率.对于链接评估函数的设计,当前研究最多的是基于机器学习的框架[1-5].虽然目前对聚焦爬行问题已经进行了深入的研究,并且取得了不少的研究成果,也有一些成功的系统被运用于实际.但这些研究和系统在同时解决前面提到的3个挑战方面,还存在不少问题,如系统的精度和效率不高、可复用性差等.本文研究的内容是作者当前一个研究课题的组成部分.该课题的主要任务是以产品搜索为背景,构建一个面向多信息域聚合的产品搜索引擎.该系统的一个重要研究任务是如何构建一个高效的可运用于不同产品域的通用聚焦爬虫.针对当前研究任务的设计目标,本文对聚焦爬行问题进行了系统的研究,提出了一种基于联合链接相似度评估的爬行算法———JLSE(JointLinkSimilarityEvaluation).本①这里所使用的术语“链接”与超链接、URL具有相同的语Page3文的主要贡献如下:(1)提出了一个有效的基于机器学习的链接评估器算法.该算法联合使用了关于链接主题相似度的直接证据和间接证据.直接证据是通过计算链接的锚链文本的主题相似度来获取.间接证据获取的过程为:首先链接学习器根据爬取的结果页面,构造出一个Web链接图,然后采用Q学习算法学习一个函数Q(i),该函数将Web链接图中的链接i映射为该链接的优先级.所有的链接被建模为一个多维向量,当聚焦爬虫分析当前Web页面中的一个链接u时,系统会将u与Web链接图中的每个链接进行比较,然后选择其中相似度最大的链接v作为u的近似.此时u的爬行优先级可以通过Q(v)来计算.实验表明该算法可以显著提高链接评估器的精度.(2)系统具有较高的自动化程度.除了在系统运行前需要提供一定数量的训练样本之外,系统在运行过程中不需要进行人工干预.(3)系统具有很好的可复用性.当需要将系统运用到不同的产品域时,只需修改系统的配置文件,就能满足对多个产品域的Web资源爬取.本文第2节介绍相关的研究工作,包括各种聚焦爬行算法的思想及优缺点;第3节给出系统的整体框架以及各主要部件的设计思想和算法,其中重点介绍了链接评估器和链接学习器的设计原理;第4节是实验和分析部分;最后是结语以及对未来工作的展望.2相关的工作Chakrabarti等人[1]于1999年系统地提出了聚焦爬行的基本概念和框架,该框架设计了一个页面分类器,用于评估一个Web页面与聚焦主题的相似度.相似度的大小使用一个概率模型进行计算,并以此控制爬行的方向.该系统的主要问题是采用假设:一个Web页面内所有链接的爬行优先级等于该页面与主题的相似度.这使得链接爬行优先级分配粒度较粗,没有考虑Web页面可能包含多个主题的问题.随后,Chakrabarti等人[2]又对此问题作了进一步改进,如使用基于监督学习的组件———学徒(appren-tice)来在线学习链接分类器,该方法引入了反馈机制,以提高链接爬行优先级的分配精度.在链接分类器的设计方面,Diligenti等人[3]提出使用环境图的方法来增强聚焦爬行.其思想是先根据k个种子文档构造n层环境图,然后根据环境图构建n+1个分类器.在进行爬行时,对一个给定的Web页面分别使用这些分类器将其分类到合适的队列中.该算法的主要缺点是没有有效利用链接自身的特征.Rennie和McCallum[5]探讨了使用强化学习的思想来训练链接分类器,并用以评估一个给定链接的回报.Assis等人[6]提出了一个基于类型感知的聚焦爬行算法,该算法综合利用网页的内容和类型信息来引导爬行过程.Wang等人[7]提出了一个基于质心向量的增量式主题爬行算法.该算法使用TFIDF22模型以及Max、Ave、Sum3个启发式规则计算文档特征权重和质心特征权重,并在此基础上构建与根集文档相对应的质心向量,利用它作为前端分类器指导聚焦爬行.以上提到的文献主要采用以内容分析为主的方法,而该领域另外一个研究方向是基于链接分析的方法.基于链接分析的聚焦爬行策略借鉴了PageRank和Hits算法的思想,在聚焦爬行过程中,通过分析Web超链结构,对待爬行的URL分配适当的优先级.如Abiteboul等人提出了OPIC算法[8],该算法使用Cash表示页面重要度,类似PageRank,通过对Web超链结构的分析,对每个页面的Cash进行在线动态分配.Guan等人[9]改进了OPIC算法,提出了OPIE算法,该算法在分配Cash时,采用了偏置(bias)的方法,而不像OPIC算法采用平均分配Cash的策略.这使得Cash的分配更倾向于主题相关的URL.该方法的优点是结合了内容分析和链接分析,但缺点是计算未下载链接的主题相似度所采用的方法较简单,只是对链接环境主题相似度和链接所在页面的主题相似度进行加权计算.Peng等人[10]探讨了聚焦爬行中的隧道穿越(tunneling)问题,提出了两种方法来分别解决灰色隧道和黑色隧道穿越问题.而针对Web上较稀疏的地理位置信息,Ahlers和Boll[11]给出了一个基于贝叶斯分类器的方法来提取Web页面和链接图的地理空间属性,从而能够精确发现和索引Web上与地理位置信息相关的文档.而Yang等人[12]提出了一个基于站点层知识(site-levelknowledge)的方法来增量爬行Web论坛.该方法通过挖掘Web论坛内的站点链接结构来获取站点层的知识.Alam等人[13]给出了一个基于分步PageRank(FractionalPageRank)算法的聚焦爬虫,用于爬行重要的Web页面.该算法的主要思想是:一个Web页面的分步PageRank值Page4等于从种子页面到该页面的所有路径的概率总和.对深网(deepWeb)的聚焦爬行方面,Barbosa和Freire[4]给出了一个有效的爬行特定领域的深网表单框架.爬虫在爬行过程中,能够自动学习“有希望”的链接模式,并调整它的爬行策略.3系统框架及算法本节给出基于JLSE算法的系统框架,并对系统各主要部件的功能做详细的讨论.该系统的主要框架如图1所示,系统的主要工作流程如下:(1)首先,以手工方式构建样本数据库.该数据库中提供了特定主题域的样本页面,样本页面包括正例和反例.(2)使用样本数据库训练页面分类器.(3)提供少量种子URL,这些URL是系统爬行图1基于联合链接相似度评估的聚焦爬虫架构3.1页面分类器和结果页面分类器页面分类器主要用于判断当前下载的页面是否主题相关.在整个系统中,页面分类器扮演着非常重要的角色.首先它被用于发现主题相关的页面.其次,被用于发现哪些页面可能包含潜在的主题相关链接.对于后者,本文所采取的策略是:只爬取主题相关的页面.为了证明该策略的合理性,先给一些相关的定义.定义1.文档定义为集合D={w|w为文档中出现的词}.定义2.主题定义为集合T={D1,D2,…,Dn},其中Di是文档,并且T中所有文档描述相同的语义概念.定义3.设一个Web页面u是一个文档,则u与主题t的相似度定义为一个函数f:S×Θ→其中,S是文档的集合,Θ为主题的集合,的入口,并被添加到边界管理器(frontiermanager)中.边界管理器采用优先队列来存储待爬行的链接,每个链接被赋予一定的优先级.种子URL被设置为相同的优先级.(4)如果边界管理器为空或结果页面数据库中的记录数达到预设的数量,则转入(6);否则,系统从边界管理器中取出优先级最高的URL,并使用页面下载器下载对应的Web页面,然后调用页面分类器对该页面进行分类.如果该页面被分类为反例,则丢弃该页面,返回到(4);否则继续使用结果页面分类器判断该页面是否是目标页面,如果是,将该页面加入结果页面数据库中,返回到(4);否则转入(5).(5)提取当前Web页面中所包含的所有URL,然后使用链接评估器分配这些URL的爬行优先级,并将URL插入到边界管理器中,然后转入到(4).(6)系统停止工作.数集.页面的主题相似度函数f(u,t)用来度量页面u与主题t在内容上相似的程度.本文的页面主题相似度计算采用了概率模型的方法(参见本节式(1)).定义4.对页面u和v,如果|f(u,t)-f(v,t)|<Δ,则称u和v内容相似.其中,Δ为一阈值.假设1.如果页面u到页面v存在链接关系,则u与v内容相似.下面说明假设1的合理性.由超级链接的定义①和Web页面设计常识可知,一般说来,当页面作者将超级链接添加到Web页面,其意图是:(1)对当前页面的内容或其中的一些概念做进一步补充说明;(2)表明该页面内容的引用来源;(3)列出与当前页面内容相关的页面链接等.但无论何种情况,都能说明:当前页面和链接所对应的页面之间一定是①http://en.wikipedia.org/wiki/HyperlinkPage5关于同一主题的,且对该主题,两个页面的主题相似度相差不大,即在内容上是相似的(定义4),否则无法解释页面作者添加该链接的动机.但在现实条件下,却存在其它一些情形,使得假设1不能完全成立.如目前的Web页面往往出于商业目的或其它动机,在网页模版中包含了许多与主题无关的链接,如导航栏、广告链接、友情链接等.在这种情况下,对于一个主题相关的页面来说,如果它包含了这些“噪音”链接,那么显然假设1对这些链接是不成立的.但此时一个基本事实是:这些链接的存在不会影响该页面中其它链接的主题相似性.又如目前许多Web页面往往包含多个主题概念块(页面块),它们分属多个主题.在这种情况下,针对某个主题,页面中主题相关的链接可能只包含在某个或几个主题相关的主题概念块中.因此,在上述条件下,要获取一个主题相关页面中所有主题相关的链接,需要在假设1的基础上,结合对链接本身的相关特征信息分析,来进一步判断链接的主题相关性.这也是本文的基本思路.从假设1可知,如果页面u主题无关,则u中包含的任意链接i对应的页面v主题无关(因为u与v内容相似).即本文采用的只爬取主题相关页面的策略是合理的.分类器的设计主要采用文本分类技术,如支持向量机(SVM)、朴素贝叶斯(NB)、决策树(DT)、人工神经网络(ANN)等方法.本文涉及的页面分类主要是两类分类问题(主题相似与不相似),页面分类器采用了朴素贝叶斯分类器(NaveBayesClassifier),其计算公式为P(ci|dj)∝1其中,dj为待分类的Web文档,ci表示类别.dj的特征表示为向量〈w1,w2,…,wn〉,wi为文档中出现的词.为了减少计算复杂度,在计算概率时采用了一元模型的假设,即不考虑词在文档中的顺序关系,词与词在文档中的出现是相互独立的.P(di)在计算过程中是一个常数,而P(wk|ci)的计算方法为其中,N(wk,ds)表示词wk在文档ds中出现的次数.V表示ci类的词汇表.式(2)使用了平滑技术,避免了词分布的稀疏性带来的零概率的问题.本文对目标页面的判断使用了一个基于支持向量机(SVM)的结果页面分类器.本系统的目标是获取产品数据页面,以便提取其中的产品信息.为了使结果页面适合充当产品数据的信息提取页面,我们将产品数据页面分为两类:链接页(LinkPage)和细节页(DetailPage).链接页的特点是:页面具有较多的链接而文字较少,适合Crawler进行爬取.而细节页以文本为主,适合产品信息的提取.因此本系统的结果页面应当属于细节页.但由于目前的细节页出于商业目的,在网页模版中往往包含了许多与主题无关的链接,如导航栏、广告链接等,因此仅靠简单统计页面的链接数和文本数并不能做出准确判断.根据观察,我们使用三元组〈TextDegree,LinkDegree,Aggregation〉来表示这两种类型的页面特征,每个分量的含义如下.(1)TextDegree(页面文本度).TextDegree=log2(plaintexts/k).其中,plain-Texts表示整个文档中去除链接文本后的文本数(单词数),k为一经验常数.TextDegree越大,该页面属于细节页的可能性越大.(2)LinkDegree(页面链接度).LinkDegree=log2(linknums/TotalWords).TotalWords代表整个文档中的文本数(单词数),linknums表示该文档中的链接数目.LinkDegree越大,该页面属于LinkPage的可能性越大.(3)Aggregation(文本聚集度).一般DetailPage的显著特征是文本在页面中以文本块(block)的方式出现.因此,Aggregation越大,该页面属于DetailPage的可能性越大.该特征主要是通过计算整个文档中文本块(block)的个数和大小获得的.基于SVM的结果页面分类器的工作过程如下:(1)构造结果页面训练样本集.该训练样本集只包含正例和反例.关于结果页面训练样本集的具体情况可以参看4.1节的数据集部分.(2)对每一个训练样本,使用前面提到的三元组页面特征向量进行特征表示,并加上类别标注(如正例标注为1.0,而反例标注为0.0).(3)在训练样本集上训练SVM分类器,最后得到训练模型.系统采用高斯径向核函数作为空间变换函数.(4)对于待分类的页面,先进行如同(2)的特征表示,然后使用训练成功的模型进行分类.Page63.2链接评估器链接评估器是整个系统的核心,它用于预测当前页面中的链接与主题的相似度.由于此时链接对应的页面还未被下载,无法直接计算其页面的主题相似度,所以对链接与主题相似度的分析通常采用基于链接特征的分析方法[2,14].常用的链接特征有锚链文本(AnchorText)、URL字符串、链接环境(Context)以及当前页面.链接环境是指包围在当前链接周围的页面元素,如文本、链接等.在这些特征中,当前页面的主题相似度常常被采用.为了说明这种方法的有效性,给出定理1.定理1.对任意页面u,可以用u的主题相似度来估计u中任意链接i对应的页面v的主题相似度.证明.对一特定主题t,设u和v的主题相似度分别用f(u,t)、f(v,t)来表示.由假设1可知,u与v在内容上相似,即f(u,t)=f(v,t)+Δ,其中,Δ为一较小正实数.即可以用u的主题相似度来估计v的主题相似度.定理1表述了这样一个思想:在Web上,两个有链接关系的页面具有相似主题的概率远远大于两个随机选择的页面.Davison[14]的研究也证明了定理1的正确性.这为预测Web页面中链接的主题相似度提供了一个基本的方法.实际上,许多聚焦爬行算法都使用了定理1所阐述的思想[1-3].其它的特征中,由于URL字符串包含的信息较少,所以在使用上比较困难.链接环境有一定的分类作用,但如果链接环境包含的主题与链接主题不一致,则会产生偏差.而锚链文本具有比较大的分类价值[14].如引言中所述,在实际应用中,如果只使用上述的直接证据分析,将无法解决延迟收益(delayedbenefit)问题.因此,本文在设计链接评估器时,采用了联合评估的策略,链接主题相似度的计算采用如下公式:sim(u,t)=max{simanchor(u,t),simpredicted(u,t)}其中,sim(u,t)为当前页面中,某一链接u与主题t的相似度.simanchor(u,t)为采用锚链文本为度量所得到的主题相似度,它提供了主题相似度的直接证据.simpredicted(u,t)为u的预测主题相似度,它提供了主题相似度的间接证据.计算simanchor(u,t)的算法描述如下.算法1.GTSAT(GettheTopicSimilarityofAnchorText)算法.输入:当前链接u的锚链文本,样本数据库输出:当前链接u的锚链文本主题相似度simanchor(u,t)Begin1.从样本数据库中获取每一样本页面在父页面中所对应的锚链文本(手工构建样本数据库时,已经获取了该信息).2.对该锚链文本进行分词,去除停用词等处理,然后获取所有的词汇,并保存为一个正例文档或反例文档.3.对当前链接u的锚链文本进行分词,去除停用词等处理,获得所有词汇.4.使用式(1)计算当前链接u是否属于正例(主题相似),如果是,将式(1)计算的结果作为simanchor(u,t);如果属于反例,则将一较小的实数(如0.01)赋给simanchor(u,t).5.返回simanchor(u,t).End.而simpredicted(u,t)的计算需要借助链接学习器学习到的Web链接图G狑的知识.G狑提供了成功的爬行路径信息,本文使用该信息来预测当前链接的主题相似度.下面先给出G狑的定义.定义5.一个Web链接图G狑是一个有向图〈V,E〉,其中V为顶点的集合,V={v|从结果页面数据库中的记录出发,反向构造出到种子URL的路径,v为路径上的一个节点}.E为有向边的集合,E={〈u,v〉|u,v∈V,且u到v存在链接关系}.G狑中对应于结果页面数据库记录的顶点称为叶节点.3.2.1URL建模为了计算simpredicted(u,t),本文将任意链接u建模为一个三元组:式中,AnchorText为链接u的锚链文本,Url为链接u对应的URL字符串.Context表示链接u在当前页面中的环境.Context可以通过设置一个窗口尺寸δ(与u的距离)来获取.文本使用DOM树来表示一个Web页面,然后获取所有与链接u的距离小于等于δ的DOM树节点的文本.根据相关文献中的数据[2]和我们的实验分析,在实际应用中,δ设置为4~6为宜.若δ设置得过小(如小于4),那么获取的Context文本可能会太少,导致无法获取足够的Context信息.而如果δ设置得过大(如大于6),又可能会引入与链接主题不一致的Context信息.定义6.给定一个链接u,按式(4)中的第i个特征,提取其中相应的文本,并对其进行分词、去除停用词等处理后,可以得到一个文档,称该文档Page7为d(i)u.定义7.D(i)idf(t)f(t,d(i)的顶点}.3.2.2simpredicted(u,t)的计算对于当前待计算优先级的链接u,先分别计算u、d(2)出d(1)索模型来分别对这3个特征进行计算:sim(d(i)∑t∈d(i)式中,d(i)同的是v只能取G狑中的顶点.f(t,d(i)v出现的次数.ld(i)d(i)W中所有文档的平均长度.对于一个确定的G狑来D(i)说,该值是一个常数.k1和b是常数,通常取k1=2,b=0.75.idf(t)表示转置文档频率,采用如下公式计算:u其中,N为D(i)词t至少出现过一次的文档的数量.相似度矩阵:对链接u按照式(5)进行计算后,可以得到一个其中犪i=(sim(d(i)vn))T,n=|D(i)d(i)给定一个权重向量狑=(w1,w2,w3)T,w1+w2+w3=1,最后可以得到一个关于链接u的评分向量:式中,si表示链接u与G狑中的顶点vi的加权平均相似度.取狊犮狅狉犲中的最大分量值sj,设其对应于G狑中的顶点vj,则将vj作为链接u在G狑中的最相似节点.通过反复进行多组实验,最终权重向量狑设为(0.5,0.2,0.3)T.从狑的分配可以看出,在分类作用方面,锚链文本最大,链接环境次之,URL字符串最小.为了说明simpredicted(u,t)的计算,这里先对链接学习器的主要工作过程做一简要介绍.链接评估器工作在两个不同的阶段.第1阶段,链接评估器主要使用样本数据库中的数据,采用simanchor(u,t)进行链接主题相似度的评估.此时式(3)中,simpredicted(u,t)=0,因为当前结果页面数据库的数据还没有达到给定的数量,链接学习器还未开始工作.第2阶段,链接学习器从结果页面数据库中构建Web链接图G狑,然后使用Q学习算法学习系统的最优策略π,即给出一个函数Q(v),该函数将G狑中的一个链接v映射为v的爬行优先级.在前面的描述中,我们已经将链接u映射到了G狑空间中的节点vj,它与vj的相似度为sj.此时链接u的simpredicted(u,t)采用下面的公式计算:关于链接学习器将在下节做详细的讨论.重新考虑式(3),式(3)取simanchor(u,t)和simpredicted(u,t)之中的最大值作为链接u的主题相似度.但目前还存在一个问题:对于两个分属不同页面的链接u1和u2,如果按照式(3),它们取得了相同的主题相似度,那么如何区分u1和u2的优先级的大小?这里,给出推论1.推论1.如果页面u的主题相似度大于页面v的主题相似度,则u中所包含的链接的主题相似度大于v中所包含的链接的主题相似度.证明.对一特定主题t,设u和v的主题相似度分别用f(u,t)、f(v,t)来表示.任取u中的一个链接i和v中一个链接j,由定理1可知,链接i和链接j的主题相似度可分别用f(u,t)+Δ和f(v,t)+Δ来表示,其中,Δ为一较小正实数.已知f(u,t)>f(v,t),所以链接i的主题相似度大于链接j的主题相似度.推论1表明:计算页面内链接的主题相似度时应当考虑当前页面的主题相似度.由此,本文采用如下公式来计算最终一个页面k中的所有链接的爬行优先级:priority(i)=sim(i,t)其中,sim(i,t)为采用式(3)计算所得到的当前页面k中,链接i的主题相似度.Ok={v|v为页面k中的链接}.P(cj|dk)为使用式(1)计算所得到的当前页面k的主题相似度.式(10)的思想与Guan等人采用的策略[9]类似:一方面考虑不同的页面主题相似度对所包含链接的主题相似度的影响;另一方面,也考虑到在同一页面中,优先级的分配应该倾向于主题相似度大的①http://en.wikipedia.org/wiki/Probabilistic_relevance_Page8链接.另外,该公式也反映了链接结构对相似度的影响,即当前页面中包含的链接(链出)越多,则各链接分配到优先级越低(类似PageRank).该策略使得爬虫在页面主题相似度相同的情况下,优先爬取链出较少的页面.以上所讨论的链接优先级计算的算法描述如下.算法2.GPAOGP(GetthePriorityofAllOutlinksonaGivenPage)算法.输入:当前页面k,样本数据库,G狑输出:当前页面k中所有链接的优先级Begin1.使用式(1)计算当前页面k的主题相似度P(cj|dk).如果当前页面k是反例,则丢弃该页面,转到步10;否则使用结果页面分类器,判断当前页面是否是目标页面.如果是,则将其加入结果页面数据库,转到步10;否则使用链接提取器,提取当前页面k中包含的所有链接.2.取当前页面k中包含的任意一个未被计算的链接u,使用算法1计算simanchor(u,t).3.使用式(4)对u建模,生成d(1)4.使用式(4)对G狑中任意顶点v建模,生成d(1)v.5.使用式(5)计算链接u和G狑中的任意顶点v的相似和d(3)度,得到式(7)所描述的相似度矩阵犃.6.使用式(8)计算关于链接u的评分向量狊犮狅狉犲,取狊犮狅狉犲中的最大分量值sj.设sj对应G狑中的节点为vj,则使用式(9)计算链接u的simpredicted(u,t).7.结合步2的计算结果,使用式(3)计算链接u的sim(u,t).步2;否则,转到步9.似度priority(i).8.如果当前页面k中还包含未被计算的链接,则转到9.使用式(10)计算当前页面k中任意链接i的主题相10.返回当前页面k中所有链接的优先级.End.3.3链接学习器该节我们将详细介绍链接学习器的工作原理.在上节关于链接评估器的讨论中,我们知道链接评估器在计算一个给定链接的主题相似度时,需要用到Q(v),而Q(v)正是链接学习器的输出.链接学习器的主要工作集中在G狑的生成以及对G狑的学习,其中核心算法是基于Q学习的Web链接图学习算法.3.3.1Web链接图的生成Web链接图的含义可以参见定义5.使用Web链接图的动机是利用聚焦爬虫在爬行过程中产生的目标页面,给系统提供一个反馈,以提高链接评估器的精度.爬虫产生的目标页面提供了成功的爬行路径信息,这种信息是可以被系统所利用的,并可以用于解决延迟收益(DelayedBenefit)问题.定义8.当结果页面数据库中的记录数N达到一个给定的常数cf时,系统启动链接学习器对G狑进行构建和学习.之后,每当N达到cf的倍数时,系统会再次启动链接学习器对G狑进行重新构建和学习.这里,称常数cf为增量学习因子.由定义8可知,对Web链接图,系统采用了增量构建和学习的策略.增量学习因子cf的取值通过实验确定,在后续的实验部分,我们将对增量学习因子的实验情况做详细讨论.图2是一个G狑的例子,其中深色节点代表叶节点(结果页面).G狑的生成并不复杂.在系统的数据库设计中,有两个表可以用于G狑的生成.一个是LinkTable〈ID,url,parentID,depth,anchorText〉,另一个是ResultTable〈ID,urlID〉.其中,LinkTable用于保存链接结构的信息,而ResultTable用于保存结果页面.ResultTable中的urlID为LinkTable中的ID.这样,便可以从ResultTable中的记录出发,利用其urlID,在LinkTable中找到与之对应的parentID,然后再在LinkTable中找到该parentID的parentID,依此类推.由此便可以反向构造出所有的从结果页面到种子URL的路径.3.3.2Q学习算法构造Web链接图之后,应该如何有效利用成功的爬行路径信息,来进行链接相似度预测呢?基于强化学习(reinforcementlearning)的思想[5,15],为利用Web链接图提供了一个有效的途径.强化学习使用一个能够感知环境的代理(Agent),通过环境的反馈,学习最优的动作.强化学习本质上属于马尔科夫决策过程MDP(MarkovDecisionProcess),其基本框架如下:(1)基本定义状态集合S={s0,s1,…,sn};动作集合A={a0,a1,…,an};状态转换函数:δ:S×A→S;立即回报函数:r:S×A→.其中,为实数集.Page9(2)基本原理在t时刻,当Agent在一个给定的状态st,选择了一个动作at后,环境会立即给出当前的回报rt=r(st,at),并迁移到下一个状态st+1=δ(st,at).Agent的基本任务是学习一个策略:π:S→A,并且使得该策略最优.为了描述最优策略,给出关于累积回报的定义:其中γ为折扣率,0γ<1.式(11)表示Agent从开始状态st使用策略π进行动作选择,在经过若干步之后获得的回报之和.因此,最优策略π应该为:Agent从任意状态s出发,该策略都能使累积回报达到最大.因此π可以表示为π=argmaxπVπ(s)(3)Q学习式(12)却无法直接使用.在实际应用中,是通过引入Q评估函数来进行最优策略的学习.Q函数定义为又因为Q和Vπ存在如下关系:所以式(13)可以改写为Q(s,a)=r(s,a)+γmaxaQ(δ(s,a),a)(15)式(15)使用了递归定义,所以可以采用动态规划算法来进行有效地计算.而最优策略π为对〈s,a〉(状态-动作对),可用式(15)进行若干次迭代计算.设第n次迭代得到的当前Q(s,a)的近似值表示为Q^n(s,a),则当满足特定的条件时,随着n的增加,Q^n(s,a)会收敛到全局最优值Q(s,a).该特定条件为:(1)系统可以建模为一个确定性的MDP;(2)立即回报值有界;(3)每个状态-动作对都被无限频繁地访问.收敛性证明的关键是最大误差项的更新误差按因子γ减小.Mitchell[15]给出了收敛性的严格证明.3.3.3学习Web链接图链接图的学习算法.首先定义如下的基本概念:基于Q学习算法的思想,我们设计了一个Web(1)状态集合S={u1,u2,…,un}.在Web链接图中,顶点代表一个状态.(2)终点状态集合T={u1,u2,…,us}.在Web链接图中,一个叶节点代表一个终点状态.(3)动作集合A={e1,e2,…,em}.在Web链接图中,一个有向边代表一个动作,有向边ek可以表示为〈ui,uj〉.(4)状态转换函数:在Web链接图中,如果顶点ui到顶点uj存在一个有向边〈ui,uj〉(动作),则输出状态uj.(5)立即回报函数:在Web链接图中,如果一个有向边〈ui,uj〉的端点uj∈T,则给出立即回报rd(非零实常数);否则给出立即回报0.0.基于以上的定义,对式(15)进行改写,得到Web链接图中任意顶点的Q(ui,〈ui,uj〉)的计算公式:Q(ui,〈ui,uj〉)=r(ui,〈ui,uj〉)+γmax〈uj,um〉∈EQ(uj,〈uj,um〉)(17)然后计算Q(ui):下面给出基于Q学习的Web链接图学习算法算法3.QLAWLG(QLearningBasedAlgo-描述.rithmforWebLinkGraphic)算法.输入:Web链接图G狑输出:Q(ui,〈ui,uj〉),Q(ui)Begin1.初始化G狑,对任意〈ui,uj〉,设置Q(ui,〈ui,uj〉)=0.0.2.对Q(ui,〈ui,uj〉)进行k趟更新操作.设置计数器Counter=0和更新标志bFlag=false.3.取G狑中除叶节点外的任意一个在该趟尚未被计算的顶点(状态)ui,使用式(17)计算Q(ui,〈ui,uj〉).对于立即回报函数r(ui,〈ui,uj〉),如果uj∈T,立即回报取rd(非零实常数);否则立即回报取0.0.如果ui的当前Q值与计算值不同,则更新ui的Q值,并设置更新标值bFlag=true.否则,不作更新操作.4.如果当前G狑中除叶节点外的所有顶点在该趟都已经被计算一遍,转到步5;否则回到步3.5.判断更新标志bFlag是否为true,如果不是,则转到步7;否则转到步6.6.判断是否Counter=k,如果是,转到步7;否则Count-er加1,设置更新标值bFlag=false,转到步3.7.对于G狑中的任意顶点ui,使用式(18)来计算Q(ui).8.返回Q(ui,〈ui,uj〉),Q(ui).End.Page10对算法3来说,显然它满足收敛性的3个特定条件:(1)G狑中每个状态转换过程是确定的,是一个确定性MDP;(2)立即回报值有界:rd取0.0或一非零实常数;(3)G狑具有有限状态,系统可对G狑的每个状态-动作对进行无限频繁地访问.下面对算法3的算法复杂度进行分析.设生成的Web链接图中:节点数为n,叶节点数为m,边数为e,算法更新操作的趟数为k.每个节点的平均出度l定义为其中,Oi表示G狑中第i个节点的出度.对算法3来说,由于很难准确估计一个Web链接图中每个节点的实际出度,所以这里使用了平均出度的概念.(1)时间复杂度.从式(17)可知,对于任意一个状态-动作对〈s,a〉,计算一次Q(s,a)共需要:计算一次回报值,求l个数中的最大值和一次加法计算.又由算法3可知,一共需对(n-m)个节点做k趟更新操作,设每个基本操作的时间复杂度为O(1),则算法的时间复杂度为O(k(n-m)l).对于一个边稀疏的图来说,ln,并且随着n增大,l减少.而G狑具有边稀疏的特性,通过对生成的多个G狑的统计,l在1~5之间.同时,相对与n,mn.因此,算法3的时间复杂度实际上主要由节点数n和更新操作的趟数k决定.最终算法的时间复杂度为O(kn).考虑到在k趟更新操作的过程中,Q值可能会提前收敛(算法3设置了更新标志),所以实际的计算时间可能会更少.(2)空间复杂度.算法3的空间复杂度主要体现在G狑的存储数据结构上.在实际设计中,我们采用邻接表来表示G狑.该邻接表由n个顶点节点和e个边节点组成,因此,算法的空间复杂度为O(n+e).由于邻接表中的顶点节点存储了有关该节点(链接)的特征信息(参见式(4)),属于一个复杂对象节点,且G狑具有边稀疏的特性,所以算法的空间复杂度主要由顶点节点的个数n决定,最终算法的空间复杂度为O(n).为减少G狑节点数量的增加对系统内存空间的占用,我们采用了对象缓存(Cache)和序列化(serializable)技术来解决这个问题.从以上对算法3的算法复杂度理论分析以及算法3的实际运行情况来看,算法3是可行的.例1.为了说明以上的算法,这里给出一个计算实例.在图2所示的Web链接图的例子中,给出了10个顶点和11条边,其中顶点3、6、10为叶节点.rd设置为100.00,γ=0.9.在图2中,各条边所标注的数值是最终计算出的Q(ui,〈ui,uj〉)值.很显然,最后有:Q(1)=90.0,Q(2)=100.0,Q(4)=90.0,Q(5)=100.0,Q(7)=90.0,Q(8)=90.0,Q(9)=100.0.为使式(3)中simpredicted(u,t)和simanchor(u,t)具有可比性,应将simpredicted(u,t)的值映射到[0,1).为此,只需将立即回报常数rd设置为1.0即可.因此在本文中,rd被设置为1.0.4实验与分析为了验证本文提出的JLSE算法的有效性,我们使用Java语言在Eclipse平台上实现了该算法的原型系统———JLSECrawler.该原型系统的输入是特定领域的样本集合、一组种子URL,输出是主题相关的结果页面集合.实验环境为CPU(IntelCeleron2.66GHz)+RAM(2GB)+WindowXP+Eclipse3.4.4.1数据集实验一共用到4个数据集:(1)页面分类器训练样本集WebSet1;(2)结果页面分类器训练样本集WebSet2;(3)种子URL数据集URLSet;(4)目标页面URL数据集TargetSet.TargetSet主要用于评估聚焦爬行的目标召回率(参看4.2节).前3个数据集为手工方式构建,而TargetSet为半自动方式创建.为了比较算法在不同领域的爬行效果,我们分别在3个主题域(手机、数码相机、笔记本电脑)上进行了实验.表1显示了数据集WebSet1的构成情况.这里,需要对表1中3个主题域的反例数据来源做一说明.在随机选择反例的过程中,为使反例更加具有代表性,应尽量使反例的选择较均匀地分布在除该主题域之外的其他主题域.数据集WebSet2和URLSet的构建比较简单.TargetSet分为3个子数据集,分别包含了与手机、数码相机和笔记本电脑有关的目标页面URL.表2给出了WebSet2、URLSet和TargetSet3个数据集的情况.Page11表1页面分类器训练样本集犠犲犫犛犲狋1http://mobile.sina.com.cn/http://mobile.pconline.com.cn/http://mobile.it168.com/http://mobile.zol.com.cn/http://tech.sina.com.cn/digital/http://dc.pconline.com.cn/http://dcdv.zol.com.cn/http://tech.sina.com.cn/notebook/http://notebook.pconline.com.cn/http://notebook.it168.com/http://nb.zol.com.cn/主题域数码相机12451229笔记本电脑11761142数据集集合大小数据来源WebSet2正例(细节页):667URLSet6个URLTargetSet4.2实验设计为了评价JLSE算法的实际运行效果,我们选取其它4种爬行策略进行对比实验.这4种爬行策略分别是BFS(Breadth-FirstSearch)、ATA(AnchorTextAnalysis)、CFC(ContextFocusedCrawler)[3]和OPIE[9].5种算法中,除BFS外,其它4种均采用了聚焦策略.CFC是一种经典的聚焦爬行算法,它利用环境图的知识指导爬行过程.在本实验中,CFC的参数设置为环境图的深度,设置为4,并且每层最大文档数不超过300;NB分类器的个数为5,队列数为6.ATA算法的设计除了在式(3)上与JLSE不同外,其他部分与JLSE完全相同.ATA没有利用Web链接图的知识,只采用了直接证据分析,即sim(u,t)=simanchor(u,t).设计ATA的目的是为了验证JLSE利用Web链接图知识的爬行效果.由于是在真实的Web环境下进行实验,基于Web的规模,我们无法获取有关某个特定主题确切的相关文档集合,所以传统的信息检索指标如精度(precision)和召回率(recall)无法直接使用.我们对实验结果的评价采用以下两个近似指标:(1)平均收益率(averageharvestrate).该指标正例用于模拟精度指标(precision).其定义如下[9,16-17]:式中,harvest_rate@N是指在t时刻,系统已爬取的页面数量为N时的收益率.V是当前系统已经爬取的页面集合.ri代表页面i与主题的相似度,如果页面i与主题相似,则ri取1,否则取0.(2)平均目标召回率(averagetargetrecall).该指标用于模拟召回率指标,其定义如下[9,16-17]:式中,T是指目标页面URL的集合,在本文中该集合为数据集TargetSet.Ct代表系统已爬取的结果页面所对应的URL集合.4.3实验结果及分析按照4.2节的实验设计,我们对5种爬行策略分别进行了系统实现,并在3个不同的主题域(手机、数码相机、笔记本电脑)上进行了实验.其中,增量学习因子cf设置为150.实验结果如图3~图5所示.下面分别对实验结果进行分析.(1)平均收益率分析图3显示了5种爬行策略在3个不同的主题域上取得的平均收益率情况.图3横坐标表示系统已爬行的网页数量,纵坐标表示在系统已爬取的页面数量为N时的平均收益率.从图3可以看到,5种爬行策略随着N的增加均出现了下降的趋势,但不同策略下降幅度并不相同.其中JLSE和OPIE的下降趋势较平缓,而BFS则较陡峭.出现下降趋势的主要原因是聚焦主题具有很强的稀疏性,在爬行过程中,已发现的主题相似页面的数量和系统已爬取的页面数量的增量幅度不同,很显然前者是小于后者的,所以造成平均收益率总体上出现下降.从图3中还可以看到,JLSE的平均收益率最高,在0.68~Page120.55之间.由于使用了联合链接相似度评估的策略,使得很多具有延迟收益的链接能够被爬取,因此提高了平均收益率.而OPIE平均收益率次之,在0.65~0.51之间.ATA的平均收益率在0.67~0.38之间,CFC在0.57~0.31之间.BFS的平均收益率最低,仅在0.26~0.03之间.由于BFS未采用聚焦策略,所以随着已爬取的页面数量的增加,其平均收益率下降得较快.图3JLSE、BF、CG、ATA、OPIE5种爬行策略在(2)平均目标召回率分析图4显示了平均目标召回率的情况.图4横坐标表示系统已爬行的网页数量,纵坐标表示在系统已爬取的页面数量为N时的平均目标召回率.从图4中,可以看到5种爬行策略随着N的增加出现上升趋势.从式(21)可以看出,随着N的增加,|T∩Ct|趋于上升,即系统爬取的主题相关的页面数量增加,因此平均目标召回率也随之增加,这是造成平均收益率总体上出现上升的原因.而不同策略上升幅度不同的原因与平均收益率有关.在N相同的情况下,平均收益率越高,|T∩Ct|越大,则平均目标召回率越高.从图4中可以看到,JLSE的平均目标召回率最高,在0.02~0.28之间,而OPIE平均目标召回率次之,在0.02~0.26之间.ATA平均目标召回率在0.02~0.22之间,CFC在0.02~0.18之间.而BFS平均目标召回率最低,仅在0.01~0.1之间.从式(21)可知,增加系统的爬行时间,可以提高系统的平均目标召回率.但当爬行时间超过一定阈值,|T∩Ct|会趋于一个常数,所以平均目标召回率曲线会逐渐趋于与X轴平行.这也与图4情况基本吻合.另外,尽管JLSE的平均目标召回率最高,但也仅有0.28.造成平均目标召回率总体偏低的原因是:实验是在开放的Web环境下进行的,而与聚焦主题有关的网页分布具有很强的稀疏性.从式(21)可知,平均目标召回率与数据集TargetSet的选取有较大关系.因此,平均目标召回率的大小只具有相对意义.而在TargetSet确定的情况下,平均目标召回率的大小与链接评估器的精度、实验提供的种子URL的数量、种子URL的代表性(覆盖性)、爬行时间等因素有关.增加种子URL的数量、选择有代表性的种子URL以及增加爬行时间,均可以在一定程度上提高平均目标召回率.但提高平均目标召回率的根本方法在于提高链接评估器的精度.图4JLSE、BF、CG、ATA、OPIE5种爬行策略在(3)增量学习因子的影响对Web链接图,系统采用了增量构建和学习的策略.增量学习因子cf的取值对Web链接图生成的时间以及学习的效果会产生影响.图5给出了不同的cf值对JLSE算法的平均收益率的影响.图5横坐标表示增量学习因子的取值,纵坐标表示在系统已爬取的页面数量为N时的平均收益率.N代表系统已爬取的页面数量.从图5可以看到,对同一组cf,随着N的增加,平均收益率均呈下降趋势,原因与前面的平均收益率分析相同.另一方面,当cf分别取50、100、150时,随着cf增加,不同参数N的平均收益率曲线均呈上升趋势.但当cf增加到200时,与cf=150相比,所有的平均收益率曲线却都出现了下降趋势.其原因可能是:一般说来,cf取得越大,一次学习到的Web链接图的节点越多,那么链接学习器学习到的模型精度越高,这样会提高链接评估器的精度,其结果是提高了爬取到的结果页面的数量.但如果cf取得太大,则会延长链接学习器进行下一次学习的时间间隔,这样又会降低链接评估器精度提高的速度,使得在这个时间段的爬行中,“漏掉”的目标页面的数量增加,从而降低了平均收益率.所以在实际使用时,cf的取值设置为150比较合适.Page13(4)学习Web链接图的作用从图3和图4还能看到JLSE算法利用Web链接图的知识对爬行效果的影响.从图3中,可以看到随着已爬行的网页数量的增加,ATA的收益率下降得比较明显,总体上低于JLSE和OPIE.图4中也显示了类似的结果:ATA的平均目标召回率低于JLSE和OPIE.因此可以说,利用Web链接图的知识对改善JLSE爬行效果的作用是明显的.尽管学习Web链接图和计算联合链接相似度增加了系统的开销,但却较明显地提高了系统爬行的平均收益率和平均目标召回率,这种代价是值得的.5结语采用聚焦爬行策略从Web上获取感兴趣的资源是许多Web研究领域的热点问题.本文提出一种基于联合链接相似度评估的爬行算法,该算法在评估链接的主题相似度时,同时使用了关于链接主题相似度的直接证据和间接证据.通过在3个主题域上进行实验,我们发现该算法可以显著地提高爬行结果的精度和召回率.然而本文提出的方法还存在一些不足,需要在未来的工作中加以解决.首先,算法的过程比较复杂,涉及到很多在线的计算,这使得系统运行效率还有待提高.下一步拟采用分布式计算的方法,将比较耗时的系统组件分布到多台机器上进行并行工作,以提高系统的计算效率.其次,需要进一步提高页面分类器和结果页面分类器的工作效率和精度.
