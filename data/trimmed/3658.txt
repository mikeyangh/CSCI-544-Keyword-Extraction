Page1基于差分演化算法的软子空间聚类毕志升王甲海印鉴(中山大学信息科学与技术学院广州510006)摘要软子空间聚类算法的性能主要取决于其目标函数和搜索策略.文中提出了一种基于差分演化算法的软子空间聚类算法DESC.首先,设计了一个结合模糊加权类内相似性和界约束权值矩阵的新目标函数.然后,提出了新的隶属度计算方法.最后,引入了一种有效的全局搜索算法———复合差分演化算法,并运用该算法优化新目标函数和搜索子空间中的聚类.实验表明,新目标函数和复合差分演化算法的引入有效地提高了软子空间聚类算法的性能,新算法较已有软子空间聚类算法有明显优势.关键词高维数据;子空间聚类;差分演化;模糊聚类;文本分类1引言聚类分析是数据挖掘中一种常用的无监督分析方法.它根据数据样本的相似程度将数据样本划分为若干个簇,使得同一个簇中的样本相似性大,不同簇间的样本相似性小.随着数据挖掘研究的发展,聚类分析被广泛地运用在统计学、模式识别、机器学习等众多领域中[1].信息技术的发展使得数据采集和存储变得更加快捷和简单,也由此产生了大量维数多、规模大的复杂数据集.不同于低维数据集,在高维数据集中存在数据稀疏性以及“维数灾难”等问题.此外,不同Page2类别的样本往往与不同的属性子集(子空间)相关.因而,受到冗余和不相关属性的影响,传统的聚类算法无法有效解决高维数据集上的聚类问题[2].为了解决上述问题,国内外学者提出了各种特征转换和特征选择的方法[3],子空间聚类就是其中一个重要分支.子空间聚类是一种寻找隐藏在不同低维子空间中的聚类的技术[4].它将数据样本划分成簇的同时,搜索各个簇所在的子空间.在每一个簇中,各个属性被赋予不同的权值,用于度量属性与簇的相关性.子空间就是这样一个加权的属性空间.根据加权方法的不同,子空间聚类可分为两大类:硬子空间聚类和软子空间聚类[5].在硬子空间聚类中,属性权值为0或1;而在软子空间聚类中,属性依据其与簇的相关程度被赋予[0,1]区间上的权值.权值越大,属性与簇的相关性越高.相比硬子空间聚类,软子空间聚类不仅反映了属性与簇是否相关,而且反映了各个相关属性在相关程度上的差异.子空间聚类算法能有效减少冗余和不相关属性对聚类过程的干扰,从而提高高维数据集上的聚类效果.文献[6]对子空间聚类算法有详细介绍.本文仅关注软子空间聚类算法.近年来,国内外出现了很多新的软子空间聚类算法[4-10].然而,这些算法仅关注于提出新的目标函数.在搜索策略上,它们普遍采用与k-均值(k-means,KM)[11]算法相似的算法结构[12],通过在KM中加入计算权值的额外步骤,迭代地优化目标函数值.因此,这类算法都保留了KM依赖于初始解以及容易陷入局部最优的缺点.为了弥补这些不足,Lu等人[12]通过引入全面学习的粒子群(ComprehensiveLearningParticleSwarmOptimizer,CLPSO)[13]算法,提出了基于粒子群算法的子空间聚类算法PSOVW(ParticleSwarmOptimizerforVariableWeighting).此外,PSOVW的目标函数将原本对权值矩阵的等式约束放松为界约束,简化了算法的搜索过程.实验证明,PSOVW大大提高了软子空间聚类算法的性能.Lu等人[12]指出,合适的目标函数和有效的搜索策略是提高软子空间聚类算法性能的基础.基于这种思想,本文提出了一种基于差分演化(DifferentialEvolution,DE)[14]算法的软子空间聚类算法DESC(DifferentialEvolutionforSubspaceClustering).首先,我们设计了一个结合模糊加权类内相似性和界约束权值矩阵的新目标函数.然后,通过结合模糊隶属度和硬隶属度,提出了新的隶属度计算方法.最后,引入了一种有效的全局搜索算法———复合差分演化算法(CompositeDE,CoDE)[15],并运用该算法优化新目标函数和搜索子空间中的聚类.这是第一个基于DE的软子空间聚类算法.实验表明,新的目标函数和复合差分演化算法的引入有效地提高了软子空间聚类算法的性能.新算法较已有软子空间聚类算法有明显优势.本文第2节介绍软子空间聚类算法的现状;第3节介绍新的目标函数和新的隶属度计算方法,并提出新算法DESC;第4节通过实验验证新算法的性能;第5节是本文结论.2相关工作记犣=[zik]C×D为聚类中心矩阵,记录每个簇的中心位置;犠=[wik]C×D为权值矩阵,记录每个簇的属性权值;犝=[uij]C×N为划分矩阵,记录每个样本对各个簇的隶属度.其中,C为聚类数,N为样本总数,D为样本的维数.软子空间聚类算法的分类方法很多.例如:按加权方式可分为熵加权软子空间聚类算法和模糊加权软子空间聚类算法[6];按权值计算与聚类过程的结合方式可分为Wrapper型软子空间聚类算法和Filter型软子空间聚类算法[7].本文根据软子空间聚类算法的搜索策略将其分为基于局部搜索策略的软子空间聚类算法和基于全局搜索策略的软子空间聚类算法两大类.2.1基于局部搜索策略的软子空间聚类算法一般地,基于局部搜索策略的软子空间聚类算法首先提出一个加权目标函数,然后采用基于梯度下降的技术迭代地优化目标函数值,最终收敛于局部最优解.模糊子空间聚类(FuzzySubspaceClustering,FSC)算法[8]是一个经典的软子空间聚类算法.该算法模仿模糊c-均值(Fuzzyc-means,FCM)[16]算法中的模糊隶属度和模糊因子,定义了模糊权值和相应的模糊因子,并通过提出一个加权目标函数,利用与KM相似的算法结构求解软子空间聚类问题.FSC的目标函数如下:JFSC=∑Cs.t.uij∈{0,1},∑C0wik1且∑D其中,ε0是避免属性零散度时出现除零错误而引入的常数,β是模糊因子.wβ所属簇中心的距离进行加权.由于wβPage3FCM中模糊隶属度的加权方法相同,这种加权方法被称作模糊加权法.使用这种加权方法的软子空间聚类算法被归类为模糊加权软子空间聚类算法[6].FSC的更新公式如下:uij=1,i=argminq=1,…,C∑Dwik=FSC的算法流程如下.算法1.FSC.输入:聚类数C,样本维数D输出:划分矩阵犝,聚类中心矩阵犣,权值矩阵犠1.在数据集中随机选择C个样本作为初始聚类中心,2.运用式(2)计算划分矩阵犝;3.REPEAT4.运用式(3)计算聚类中心矩阵犣;5.运用式(4)计算权值矩阵犠;6.运用式(2)计算划分矩阵犝;7.UNTIL(算法收敛).FSC采用与KM相似的算法结构,通过在KM中加入计算权值的额外步骤(步5),迭代地优化目标函数值,因而保留了KM算法复杂度低和收敛迅速的优点.正因为其目标函数以及算法结构与KM极为相似,被称为KM型软子空间聚类算法.熵加权k-均值(EntropyWeightingk-means,EWKM)算法[5]是另一个KM型软子空间聚类算法.它引入了最大熵理论,通过同时优化加权类内距离和权值熵求解软子空间聚类问题.EWKM的目标函数如下:JEWKM=∑Cs.t.uij∈{0,1},∑C0wik1且∑D其中-wiklnwik称为权值熵,表示属性k与簇i相关的确定性,熵加权k-均值算法也因此得名.若属性k与簇i的相关性明确,即属于簇i的样本在属性k上的分布非常集中或非常分散,则wik的权值熵较小;反之,其相关性不明确,权值熵较大.参数γ用于平衡类内相似性和权值熵对目标函数值的影响.如果仅要求提高类内相似性(式(5)中γ=0),将导致式(5)达到局部极小时各个簇所在的子空间仅仅由极少数甚至单一属性构成.因而,EWKM引入了权值熵,在最大化类内相似性的同时最大化权值熵,以确保权值维持在一个不为零的合理范围,从而使更多的属性包含在子空间中,为各个簇合理地保留更多信息.式与FSC相同,犝和犠的更新公式如下:EWKM的算法流程与FSC一致,犣的更新公uij=1,i=argminq=1,…,C∑D在以往的软子空间聚类算法中,类内距离作为类内相似性的度量被广泛运用,而类间相似性却一直被忽略.针对这一现象,Deng等人[6]提出了增强的软子空间聚类(EnhancedSoftSubspaceCluste-ring,ESSC)算法.该算法在EWKM基础上,结合用于度量类间相似性的加权类间分离度(WeightingBetween-clusterSeparation),进一步提高了软子空间聚类算法的性能.ESSC目标函数定义如下:JESSC=∑Cγ∑Cη∑Cs.t.0<uij<1,∑C0wik1且∑D其中,通过引入类间相似性,ESSC的聚类效果明显优于FSC等仅考虑类内相似性的软子空间聚类算Page4法.然而,ESSC因此引入了一个新的参数η.ESSC的算法流程与EWKM一致,其更新公式如下:其中,dij=∑Dσik=∑N在上述算法中,权值的更新方法通过梯度下降法从目标函数直接推导求得,权值的计算与聚类中心矩阵紧密结合,属于Wrapper型软子空间聚类算法.然而,Wrapper型软子空间聚类算法只能是KM型算法[7].传统聚类算法中的其它优秀算法,如层次聚类算法和谱聚类算法,都无法通过这种方式运用到软子空间聚类中.为了解决这个问题,Boongoen等人[7]将数据可靠性引入到软子空间聚类中,提出了一种Filter型软子空间聚类技术,并运用该技术提出了一系列Filter型软子空间聚类算法.记Nαjk为样本j在属性k上与其α个近邻的平均距离,Dαjk为样本j在属性k上的“样本-属性”相关度.ASαjk与ASαDαjk的大小反映了属性k上在样本j附近的样Dα本密集程度.Dα越密集,则样本j与属性k的相关性越高,ASα大;反之亦然.显然,对任意给定的k、j和α,ASα与样本的分布有关,与聚类中心矩阵无关.基于数据可靠性的k-均值(Reliability-basedKM,RKM)算法是其中一种运用该技术的Filter型软子空间聚类算法,其目标函数如下:JRKM=∑Cs.t.uij∈{0,1},∑C算法初始化时,随机选择C个样本作为初始聚类中心.设样本j被选为簇i的中心,则簇i中各个属性的权值定义为在算法的迭代过程中,犠的更新公式如下:其中,Ci是属于簇i的样本的集合.由于权值仅通过jk计算,因而不依赖于聚类中心矩阵.ASαRKM的算法流程以及犝和犞的更新公式与EWKM相同.2.2基于全局搜索策略的软子空间聚类算法除了上述几种算法,近年国内外还出现了许多软子空间聚类算法[4,9-10].这些算法均采用局部搜索策略,因而算法十分依赖于初始解且容易陷入局部最优.为了弥补这些不足,Lu等人[12]提出了PSOVW.该算法引入了CLPSO[13]求解软子空间聚类问题.由于CLPSO是一种全局搜索算法,能解决以往算法依赖于初始解以及容易陷入局部最优的问题.在PSOVW中,子空间聚类问题被描述为“变量加权问题(VariableWeightingProblem)”,犠被看作是问题的解.算法为每一个簇中的每一个属性寻找最优的权值,并在加权的属性空间中寻找聚类.PSOVW的目标函数如下:JP=∑Cs.t.uij∈{0,1},∑CPSOVW的约束条件中不包含对犠的等式约wik=1,而是通过在目标函数中显式包含犠束∑D的归一化,使得∑D影响算法效果的前提下将目标函数对犠的等式约k=1Page5束放松为界约束,使得算法中犠的更新变得更加简单[12].PSOVW中犝和犣的更新公式如下:不同于EWKM等局部搜索算法,PSOVW仅通过梯度下降法推导出犝和犣的更新公式,而犠的更新通过CLPSO的搜索策略完成.在CLPSO中,算法的搜索过程被形象地描述为一组粒子(particle)在解空间中运动的过程.一个粒子i包含以下三方面的信息:粒子在解空间中的位置狓i,g,在解空间中运动的速度狏i,g,曾经找到的最好的位置(个体历史最优解)狆犅犲狊狋i.对于整个种群,CLPSO记录一个全局最优解犵犅犲狊狋.在求解软子空间聚类问题时,粒子i在解空间中的位置狓i,g=(xi,g,1,…,xi,g,d,…,xi,g,C×D)是长度为C×D的向量,对应一个权值矩阵犠.同时,算法为粒子保留其对应的聚类中心矩阵犣以及划分矩阵犝.在一次迭代中,算法对所有粒子完成一次演化.其中,粒子i的演化过程如下.首先构造粒子i的学习范例犆狆犅犲狊狋i,g:index(i,d)=其中,rand是[0,1]区间上均匀分布的随机数,m1和m2是[1,M]上随机选择的两个相互独立的自然数.Pci是学习概率,用于平衡粒子向自身学习和向其它粒子学习的几率.为了提高算法的搜索能力,每个粒子的学习概率并不相同.在式(25)中,狆犅犲狊狋m1优于狆犅犲狊狋m2是指狆犅犲狊狋m1对应的聚类结果拥有比狆犅犲狊狋m2更低的目标函数值.index(i,d)记录了粒子i第d维的学习对象.在算法运行过程中,仅当粒子连续多次迭代均没有找到比个体历史最优更好的解时,index(i,d)才会重新生成.在每一次迭代中,算法根据index(i,d)构造犆狆犅犲狊狋i,g.得到犆狆犅犲狊狋i,g后,粒子i的速度以及位置通过以下方式更新:vi,g+1,d=ρvi,g,d+a·rand·(CpBesti,g,d-xi,g,d)其中,0ρ1是惯性因子,随着算法的运行线性递减.rand是[0,1]区间上均匀分布的随机数.a是加速因子.之后,根据式(22)、式(23)和式(21)计算粒子新的犝、犣以及目标函数值,并更新其个体历史最优解以及全局最优解.至此,粒子i完成一次演化.重复上述演化步骤直到算法满足终止条件.可见,运用CLPSO求解软子空间聚类问题时,犠的更新不再受到犝和犣的影响,有利于算法跳出局部最优和减少算法对初始解的依赖.3新的基于全局搜索的软子空间聚类———DESC合适的目标函数和有效的搜索策略是提高软子空间聚类算法性能的基础.因此,我们设计了一个结合模糊加权类内相似性和界约束权值矩阵的新目标函数.然后,通过结合模糊隶属度和硬隶属度,提出了新的隶属度计算方法.最后,引入了CoDE,并运用该算法优化新目标函数和搜索子空间中的聚类.3.1目标函数借鉴FCM和ESSC,我们将式(21)扩展到模糊聚类.新的目标函数如下:JD=∑Cs.t.0uij1,∑C且0wik1式(29)是式(21)在模糊聚类上的扩展.当m=1且uij∈{0,1}时,式(29)与PSOVW的目标函数相同;当β=0时,式(29)与FCM的目标函数相同.它既保留了PSOVW将犠的等式约束放松为界约束的优点,又实现了PSOVW向模糊聚类的扩展.参数m>1称为模糊指标(FuzzyIndex).当m→1时,DESC退化为硬聚类;当m→时,样本对各个聚类中心的隶属度趋向相等[17].参数m和β控制算法对划分矩阵犝以及权值矩阵犠的变化的敏感度.在DESC中,我们建议两者均取较小的值(取值为2).这是因为在实验中我们发现,较大的取值将大大增加算法的运算时间,却并不能提高算法的效果.另一Page6方面,犝和犠都是软子空间聚类的目标且在目标函数中相互影响,所以建议m和β取值相等.基于新的目标函数,DESC的更新公式为其中,与PSOVW相同,在DESC中权值矩阵犠被看作是算法的解,运用CoDE的搜索策略进行更新.式(30)~(32)既是式(22)~(24)在模糊聚类上的扩展,又是FCM在软子空间聚类上的扩展.通常,模糊聚类描述了样本隶属于不同类别的不确定性,比硬聚类更能反映客观世界[16,18].然而,在高维稀疏数据集上,模糊聚类的运算时间随着维数的增加快速增加[19].此外,由于样本点对之间的距离差异小,一个样本到各个簇的隶属度趋同,使得算法容易陷入位于数据集中心的局部最优[20].因此,模糊聚类在高维数据集上不如其在低维数据集上有效.另一方面,软子空间聚类不能直接运用在模糊聚类上.这是因为,模糊聚类容易陷入位于数据集中心的局部最优,此时软子空间聚类算法会寻找整个数据集的相关属性而不是为每一个簇寻找与其相关的属性.因此,结合模糊聚类和软子空间聚类的关键在于如何在算法陷入位于数据集中心的局部最优前为每一个簇寻找到足够小的子空间.当前,硬聚类下的软子空间聚类取得了良好的效果[5-7,12].这是因为硬聚类能敏感地捕捉到样本点对的距离差异.在高维稀疏数据集上,一个倾向于硬聚类的聚类算法往往比一个倾向于模糊聚类的聚类算法更有效[20].基于以上分析,如果在算法的初始阶段倾向于硬聚类,算法有可能快速得到较优的簇及其所在的子空间.然后,随着不断迭代,算法逐步从硬聚类过渡到模糊聚类.此时,模糊聚类将在一个较小的子空间中运算,有可能得到较好的聚类效果.基于这一思想,借鉴改进的抑制式模糊c-均值(ModifiedSuppressedFuzzyc-means,MSFCM)[19]算法,我们提出了结合传统硬隶属度和模糊隶属度的新隶属度计算方法:其中,t是当前迭代次数,MaxIter是最大迭代次数,η>0是一个控制参数,用于控制算法从硬聚类过渡到模糊聚类的速度.显然,对于式(33)有∑C当t=0时,有α(t)=0,此时式(33)等同于式(22).当t=MaxIter时,有α(t)=1,此时式(33)等同于式(30).当0<η<1时,uij中模糊隶属度ufuzzy_ij的权重将迅速增大,算法运行过程中更多地受到模糊聚类的影响;当η>1时,uij中模糊隶属度ucrisp_ij的权重增加缓慢,算法运行过程中更多地受到硬聚类的影响.直接将算法分成硬聚类和模糊聚类两个阶段可以令算法更加简单.例如,在算法的前β×MaxIter次迭代中令uij=ucrisp_ij,之后的迭代中令uij=ufuzzy_ij,其中0<β<1.然而,通过实验我们发现,这种隶属度从硬聚类突变到模糊聚类的计算方法会影响算法的收敛,通过更为平稳的方式从硬聚类过渡到模糊聚类,令犝和犠在过渡中逐渐调整是一个不可缺少的过程.式(33)中uij的定义与MSFCM中隶属度的定义相似.两者都通过参数α建立了硬聚类和模糊聚类的联系.两者的主要区别在于:式(33)中的α随算法的运行逐渐增大,算法在最后阶段完全过渡为模糊聚类;而MSFCM则始终处在硬聚类和模糊聚类之间.这是因为本文的方法运用在子空间中,引入α是为了通过其变化实现算法从硬聚类到模糊聚类的过渡,提高模糊聚类在高维数据集上的性能.而MSFCM始终在全空间中搜索,并未通过降低属性空间的大小避免FCM在高维空间的不足.3.2DESC算法流程DE是Storn和Price[14]提出的一种基于群体的全局搜索算法.在每一次迭代中,DE通过对个体间的差异进行加权重组实现种群的演化.它包含变异(mutation)、交叉(crossover)和选择(selection)3个主要算子.DE的性能很大程度上依赖于其试验向量的生成策略以及控制参数的选取[21].近年出现了大量关于试验向量生成策略和控制参数的研究.各种生成策略和参数组合各有优势,适用于不同类型的问题.为了充分运用这些研究成果,弥补单一参Page7数组合和生成策略不能全面覆盖各类问题的不足,Wang等人[15]系统地综合了多种试验向量生成策略和参数组合,提出了复合差分演化算法(CompositeDifferentialEvolution,CoDE),实现了不同试验向量生成策略和参数组合的优势互补.不同于其它DE,在每一次迭代中,CoDE通过随机选择的方式在控制参数池中选择参数值,并运用3种不同的生成策略为每一个个体生成3个试验向量.因此,算法对不同类型的问题都有较高的适应性.CoDE是一种简单有效的全局搜索算法,因此本文运用CoDE求解软子空间聚类问题.在运用CoDE求解软子空间聚类问题时,CoDE中的一个个体对应于软子空间聚类问题的一个可行解.与PSOVW一样,DESC以权值矩阵犠作为问题的解.记Pg={狓1,g,狓2,g,…,狓M,g}为第g代种群,一个个体狓i,g=xi,g,1,…,xi,g,d,…,xi,g,C×度为C×D的向量,对应于一个权值矩阵犠,其中每D维对应于一个簇中D个属性的权值.同时,算法为每一个个体保留其对应的聚类中心矩阵犣以及划分矩阵犝.在算法的初始化阶段,为每一个个体在数据集中随机选择C个样本作为初始聚类中心,犠=[wik]C×D=[1/D]C×D.然后运用式(33)和式(29)得到划分矩阵犝以及个体的目标函数值.种群Pg通过以下搜索策略进行演化:对于每一个个体狓i,g,通过3种不同的生成策略,生成3个试验向量狌i_1,g+1、狌i_2,g+1以及狌i_3,g+1:(1)“rand/1/bin”:vi_1,g+1,d=xr1,g,d+F·(xr2,g,d-xr3,g,d),ui_1,g+1,d=vi_1,g+1,d,randCr或d=drand(2)“rand/2/bin”:vi_2,g+1,d=xr1,g,d+rand1·(xr2,g,d-xr3,g,d)+ui_2,g+1,d=vi_2,g+1,d,randCr或d=drand(3)“current-to-rand/1”:ui_3,g+1,d=xi,g,d+rand·(xr1,g,d-xi,g,d)+其中,rand和rand1是[0,1]区间上均匀分布的随机数.drand是[1,C×D]上随机选择的自然数,以保证式(38)中狌i_1,g+1≠狓i,g以及式(39)中狌i_2,g+1≠狓i,g.F是比例因子,Cr是交叉概率.这两个控制参数的取值从下列3种组合中随机选取:[F=1.0,Cr=0.1],[F=1.0,Cr=0.9]以及[F=0.8,Cr=0.2].得到狌i_1,g+1、狌i_2,g+1以及狌i_3,g+1后,令其对应的中心矩阵犣与狓i,g的中心矩阵相同.然后,通过式(33)和式(31)更新3个试验向量的犝和犣,并通过式(29)计算目标函数值.选择狌i_1,g+1、狌i_2,g+1、狌i_3,g+1以及狓i,g中目标函数值最小的一个作为狓i,g+1,添加到下一代种群Pg+1中.重复上述演化步骤直到算法满足终止条件.DESC的算法流程如下.算法2.DESC.输入:种群规模M;最大评价次数MaxFES;试验输出:最优解对应的犝,犣,犠1.g=0;2.生成初始种群P0,对其中的每一个个体狓i,0,在数据3.FES=M;4.REPEAT5.Pg+1=;6.FOR每一个个体狓i,gDO7.对试验向量生成策略池中的每一种策略,从控8.令狌i_1,g+1、狌i_2,g+1以及狌i_3,g+1对应的中心矩阵9.运用式(33)计算3个试验向量的划分矩阵犝;10.运用式(31)计算3个试验向量的中心矩阵犣;11.运用式(29)计算3个试验向量的目标函数值;12.选择狌i_1,g+1、狌i_2,g+1、狌i_3,g+1以及狓i,g中目标函13.Pg+1=Pg+1∪狓i,g+1;14.FES=FES+3;15.ENDFOR16.g=g+1;17.UNTILFESMaxFES.3.3算法复杂度在DESC中,犣和犠是C×D的矩阵,犝是C×N的矩阵.对于每一个个体,生成试验向量(步7)的时间复杂度为()OCD.之后,对所有样本进行重新划分(步9),时间复杂度为O(NCD).为每一个个体重新计算聚类中心(步10)的时间复杂度为O(CD).因此,对每一个个体而言,算法的主循环(步7~14)的时间复杂度是O(NCD),其中N是样本总数.假设算法收敛需要的迭代次数为T,种群规Page8模为M,则DESC的时间复杂度为O(MNCDT).可见,DESC的时间复杂度随数据集的维数、聚类数以及样本总数线性增加.3.4DESC的优势DESC是一种运用全局搜索策略的软子空间聚类算法.与KM型软子空间聚类算法相比,拥有不依赖于初始解以及不易陷入局部最优的优点.与PSOVW相比,DESC基于模糊聚类对其进行了扩展.在现实生活中,不同簇之间往往并没有明确的分界.模糊聚类能很好地反映这一现实,因而模糊聚类往往能获得比硬聚类更好的效果.此外,CLPSO需要更多的控制参数以及维护额外的个体速度和个体历史最优解.因而CoDE比CLPSO更简单,DESC也因此比PSOVW更易于实现.4实验为了验证DESC的算法性能,我们将对DESC和PSOVW[12]、KM[11]、MSFCM[19]、RKM[7]、EWKM[5]以及ESSC[6]进行比较.同时,为了验证搜索策略、目标函数以及新隶属度对算法的影响,我们对搜索策略、目标函数以及新隶属度进行了4种组合,如表1所示.算法表1搜索策略、目标函数以及新隶属度的4种组合DESC-crispCoDE式(21)式(22)DESC-fuzzyCoDE式(29)式(30)PSOVW-fuzzyCLPSO式(29)式(30)PSOVW-NFCLPSO式(29)式(33)由于DESC和PSOVW是基于群体的算法,而EWKM等是单点搜索算法,本文采用最大评价次数MaxFES作为所有测试算法的终止条件.令MaxFES为500,所有基于群体算法的种群规模为20.其余参数设置如表2所示.算法DESCDESC-fuzzyPSOVW-fuzzyPSOVW-NFPSOVWDESC-crispMSFCMRKMEWKMESSC测试环境为2.66GHzCPU,4GB内存,所有算法在WEKA平台[22]下开发.4.1性能指标本文采用两种性能指标对聚类效果进行评价:RandIndex(RI)[23]和NormalizedMutualInfor-mation(NMI)[24],其定义如下:NMI=∑K其中,K是类别数,C是聚类数,N是样本总数.f00是不属于同一个类并被分配到不同簇的样本点对的数量,f11是属于同一个类并被分配到同一个簇的样本点对的数量.ni是属于类i的样本数,nj是属于簇j的样本数,nij是属于类i并被分配到簇j的样本数.两个性能指标都是越大越好.4.2实验结果本文采用来自UCI①、生物医学②以及NIPS2003特征选择挑战赛③的13个数据集对各个算法进行测试.UCI数据集用于考察算法对低维数据集的兼容性.生物医学以及NIPS2003特征选择挑战赛的数据集用于检验算法在高维空间的聚类性能.数据集的详细信息见表3.每一个算法独立运行30次,实验结果如表4~8及图1、图2所示.每一个数据集的最好结果在表中加粗表示.KDDsyntheticcontrol600606Leukemia-ALLAMLProstatetumorvsnormaltrain102126002依据表4~7,我们有以下结论.首先,对比DE-SC-crisp和DESC-fuzzy以及PSOVW和PSOVW-fuzzy可以看出,直接将软子空间聚类从硬聚类扩展到模糊聚类的效果并不理想.在低维数据集中,这种①②③Page9表4DESC、PSOVW以及4种不同组合算法30次运行的实验结果(犚犐)KDDsyntheticcontrolMean0.82870.81810.87650.82410.84990.8853LeukemiaALLAMLLungharvardMean0.57980.50630.53440.56410.50080.5724LeukemiaLungmichiganMean0.65790.53410.51540.65340.50910.5476ProstatetumorvsnormaltrainBreastcancerMean0.49740.49830.52450.50910.50240.5278LeukemiastjudeMean0.69470.66860.75300.68270.70870.7404表5DESC、KM、MSFCM、RKM、EWKM以及ESSC30次运行的实验结果(犚犐)KDDsyntheticcontrolMean0.88530.86880.88090.86950.82900.8523LeukemiaALLAMLLungharvardMean0.57240.56820.50770.56330.57420.5764LeukemiaLungmichiganMean0.54760.66050.56840.61470.70510.7065ProstatetumorvsnormaltrainBreastcancerMean0.52780.51170.50160.49810.49780.4980LeukemiastjudeMean0.74040.66980.66490.68140.32120.2068MSFCMRKMEWKMESSCPage10表6DESC、PSOVW以及4种不同组合算法30次运行的实验结果(犖犕犐)KDDsyntheticcontrolMean0.66180.57760.70560.63900.64260.7406LeukemiaALLAMLLungharvardMean0.31040.14050.20430.26310.15180.2840LeukemiaLungmichiganMean0.07850.03280.10680.12780.04690.1440ProstatetumorvsnormaltrainBreastcancerMean0.03890.00790.04390.03540.01220.0518LeukemiastjudeMean0.27860.05430.24250.24180.05860.3411表7DESC、KM、MSFCM、RKM、EWKM以及ESSC30次运行的实验结果(犖犕犐)KDDsyntheticcontrolMean0.74060.73770.69790.73600.66980.7016LeukemiaALLAMLLungharvardMean0.28400.27300.16840.26960.27150.2974LeukemiaLungmichiganMean0.14400.06680.01440.12830.13510.1259ProstatetumorvsnormaltrainBreastcancerMean0.05180.03730.01150.04770.04370.0464LeukemiastjudeMean0.34110.28430.25190.29620.09120.0632MSFCMRKMEWKMESSCPage11表8DESC、DESC-fuzzy、PSOVW、KM、MSFCM、RKM、EWKM以及ESSC30次运行的平均运行时间(单位:s)KDDsyntheticcontrol3.69404.27130.36270.27373.83230.85592.359473.2477SegmentVehicleLeukemia-ALLAML13.803319.47007.43832.621717.35439.759726.8448444.8639Lungharvard205.1150232.036343.125321.8050215.224079.3096168.55575222.9100Leukemia-MLL53.145749.721722.04105.820746.354518.715251.68761203.9746Lungmichigan25.757724.81608.08673.854323.050313.146435.6785453.6368Prostatetumorvsnormaltrain46.517746.774016.40738.488343.241628.843067.9280742.2579Breastcancer58.058786.485734.403316.348349.930045.8059125.93871304.3037Leukemiastjude308.5667510.151774.332342.4197498.2954142.1722345.87622115.6487Arcene59.419772.928716.564313.820767.117042.2878107.15211059.6873图1DESC在不同的η取值下RI评价值图2DESC在不同的η取值下NMI评价值扩展确实提高了算法的效果.但是,在高维空间中DESC-fuzzy和PSOVW-fuzzy都不如其硬聚类版本理想.在NMI指标下这种差异尤为明显.这是因为FCM在高维数据集上存在不足[20],DESC-fuzzy和PSOVW-fuzzy通过式(30)更新隶属度,保留了FCM的这种不足.其次,对比DESC和DESC-fuzzy以及PSOVW-NF和PSOVW-fuzzy,可以看到新的隶属度计算方法能有效提高算法效果.在算法的初始阶段倾向于硬聚类,有利于算法快速找到较优的簇及其子空间.然后随着不断迭代,算法逐步从硬聚类过渡到模糊聚类.此时,模糊聚类将在一个较小的子空间中运算,能充分发挥模糊聚类的性能,避免其在高维空间中的不足.在这里,算法的初始阶段相当于为后续的Page12模糊聚类寻找合适的初始解.而算法的后续阶段则是在这个基础上进一步寻优.再次,对比基于CoDE的算法以及基于CLPSO的算法,前者效果优于后者.最后,无论是RI还是NMI,DESC是所有算法中效果最好的算法.无论是搜索策略、新的目标函数还是新的隶属度计算方法,都有效地提高了软子空间聚类算法的效果.表8是DESC、DESC-fuzzy、PSOVW、KM、MS-FCM、RKM、EWKM以及ESSC的运行时间.比较DESC和DESC-fuzzy,可以看到新的隶属度算法并不会对算法的运行时间带来明显影响.同样是基于群体的全局搜索算法,DESC的运行时间是PSOVW的2~7倍,极个别达到10倍.这是因为DESC需要更多的时间计算模糊隶属度.波动较大是因为在PSOVW的运行过程中,由于其搜索策略自身的特点,有可能产生不满足0wik1的犠.此时,算法将不对该粒子进行评价[12],导致算法终止时实际的迭代次数高于DESC.这种现象会随着数据集维数增加而加剧,因而在高维数据集上PSOVW与DESC的时间差异小于低维数据集上两者的时间差异.在高维数据集上,DESC的运行时间低于EWKM.这是因为虽然DESC需要额外的时间来维护自身种群,但其权值的更新方式明显比EWKM简单.在高维数据集上,这种简单的更新方式有效地减少了算法的运行时间,弥补了两者运行时间上的差距.RKM的运行时间比EWKM以及ESSC短.这同样是因为在RKM中,权值的更新方式比EWKM以及ESSC简单.KM作为最简单的算法,运行时间最短.MSFCM虽然也不需要计算权值,但是其模糊隶属度的计算大大增加了其运算时间.MSFCM的运行时间是KM的7.5倍,与DESC和PSOVW的差异相当,说明DESC的时间开销比PSOVW大的主要原因是模糊聚类和硬聚类的差异而不是CoDE和CLPSO的差异.ESSC的运行时间过长,一方面是因为ESSC的更新公式较其它对比算法复杂.另一方面是因为ES-SC在运行过程中经常出现某些簇样本数量为零,以致需要运行额外的修补程序,增加了运行时间.图1、图2是DESC在不同参数取值下的实验结果.实验表明,在η取值在[0.4,10]时,DESC有较稳定的聚类效果.区间范围较广,意味着DESC对参数的设置并不敏感.5结论本文提出了一种基于差分演化算法的软子空间聚类算法DESC.在DESC中,我们首先设计了一个结合模糊加权类内相似性和界约束权值矩阵的新目标函数.然后,通过结合模糊隶属度和硬隶属度,提出了新的隶属度计算方法.最后,引入了复合差分演化算法,并运用复合差分演化算法优化新目标函数和搜索子空间中的聚类.这是第一个基于DE的软子空间聚类算法.实验表明,新目标函数和复合差分演化算法的引入有效地提高了软子空间聚类算法的性能.新算法较已有软子空间聚类算法有明显优势.后续的工作是将DESC运用在如文本聚类、图像分割等现实问题中.此外,参数的自适应也是一个研究的重点.
