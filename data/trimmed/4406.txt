Page1海量高维向量的并行Top-犽连接查询马友忠1),2)慈祥1)孟小峰1)1)(中国人民大学信息学院北京100872)2)(洛阳师范学院信息技术学院河南洛阳471022)摘要在很多应用领域中,向量的Top-k连接查询是一种很重要的操作,给定两个向量集合犚和犛,Top-k连接查询要求从犚和犛中返回距离最小的前k个向量对.由于数据的海量性和高维特性,传统的集中式算法已经无法在可接受的时间内完成连接查询任务.MapReduce作为一个并行处理框架,能够有效地处理大规模数据.由于其高可扩展性、高可用性等特点,MapReduce已经成为海量数据处理的首选实现方案,在很多领域都得到了广泛的应用.文中基于分段累积近似法对高维向量进行降维,然后利用符号累积近似法对高维向量进行分组;在此基础上,结合MapReduce框架,提出了基于SAX的并行Top-k连接查询算法.实验表明,文中所提方案具有良好的性能和扩展性.关键词高维向量;MapReduce框架;Top-k连接查询;大数据1引言在很多应用中,为了便于数据分析,处理对象经Page2要的操作,在很多任务中都有广泛应用,如聚类、副本检测、去重等.高维向量的相似性连接查询有两大挑战:一是数据的规模在不断扩大,传统的集中式处理方式已不再适用;二是向量的维度比较高,可以达到成千上万维,由于维度灾难的存在,基于索引的算法已无法奏效.相似性连接查询需要用户事先提供一个相似度阈值,然而在实际应用当中,用户往往很难知道准确的阈值.Top-k连接查询无需用户提供相似度阈值,直接返回最相似的(距离最小的)前k个向量对.Top-k连接查询在空间数据库中已经进行了深入的研究[1-2],现有的算法大都是基于某种高效的空间索引(如R树),只适合于小规模的低维数据,无法处理大规模的高维数据.MapReduce[3]是谷歌公司提出的一个并行处理框架,由于其高可扩展性、容错性和高可用性,得到了学术界和企业界的广泛关注,已经成为海量数据处理的首选方案.本文的主要工作就是基于MapRedcue框架,设计并实现了海量高维向量的并行Top-k连接查询算法,实验结果表明,本文所提方案具有较好的性能和扩展性.本文主要贡献如下:(1)提出了一种基于符号累积近似法(SymbolicAggregateApproximationtechnique)的高维向量阈值连接方法,该方法具有较好的过滤效果;(2)提出了一种基于采样的Top-k阈值估计方法,并基于估计的阈值,提出了基于SAX的Top-k连接查询算法;(3)针对真实数据集和模拟数据集做了丰富的实验,对基础方案和本文提出的方案进行了对比,实验结果表明,本文所提方案具有较好的性能和扩展性.本文第2节对相似性连接查询相关工作进行综述;第3节给出Top-k连接查询的定义,并介绍相关基础知识;第4节给出基于SAX的向量阈值连接查询算法;第5节介绍基于阈值的Top-k连接查询算法;第6节介绍基于SAX的Top-k连接查询算法;第7节进行实验分析;最后对本文进行总结.2相关工作相似性连接查询是一种很重要的操作,目前已经有大量的研究工作.庞俊等人[4]对相似性连接查询技术进行了综述,按照不同的分类标准,相似性连接可以分为不同的类别.按照数据类型来分,可以分为字符串相似性连接、集合相似性连接、向量相似性连接等;按照返回结果的不同,可以分为所有对相似性连接、阈值相似性连接、Top-k相似性连接和KNN相似性连接等.EpsilonGridOrder[5]、KDB-tree、Quickjoin[6]等主要研究了在欧氏空间中,给定距离阈值的情况下,如何快速地计算出满足距离要求的所有相似对.然而,在很多应用中,无法事先知道距离阈值,此时,如何快速找到距离最近的前k个向量对就具有重要的意义.文献[7]充分利用R-tree索引结构的过滤效果,从而快速找到最近的前k个向量对.为了降低时间复杂度,文献[8-9]在空间填充曲线技术的基础上,针对高维向量集合,提出了相应的近似算法.上述算法大都是单机环境下的算法,针对低维、小规模数据集,其性能还可以接受.但是其时间复杂度随着维度的增加往往呈现指数级增长,无法在可接受的时间范围内处理大规模、高维数据集合的相似性连接查询问题.大规模数据的连接操作是一个计算代价很高的操作,目前有一些研究工作尝试利用MapReduce框架来解决该问题,主要包括集合相似性连接[10-14]、向量相似性连接[15-16]、Top-k连接[17-18]等.从采用的主要技术来分,海量集合相似性连接可以分为3类,前缀过滤[10-11]、Word-Count-Like[12-13]和混合方案[14].Vernica等人[10]提出了一种基于前缀过滤技术的海量集合数据相似性连接方案,该方案主要由3个阶段完成,每个阶段由一个MapReduejob负责实现.其核心思想是:如果两个集合的前缀没有公共元素,那么这两个集合肯定不可能相似.基于该规则,就可以大大减少候选集合的规模.为了进一步减少候选集合的数量,Rong等人[11]提出了一种基于多前缀的集合相似性连接方案.通过多个前缀进行过滤,可以减少伪正例的个数,从而进一步减少候选对数量.但是基于前缀过滤技术的方案也存在一些固有的不足之处.一是网络传输代价较大:每个集合都要复制多次,复制的次数等于前缀的长度,因此对于较长的集合来讲,数据复制率太高,会导致网络传输代价比较大;二是重复比较次数比较多:对于任意两个集合,如果它们的前缀中有k个公共元素,则会重复比较k次.为了解决前缀过滤技术存在的问题,文献[12-13]提出了Word-Count-Like的解决方案,该方案充分利用了MapReduce框架的基本特性,基本思路类似于Word-Count程序的思路.该方案的优点是避免了重复比较,任何一个集合对只Page3需要比较一次.但是存在一些局限性:任何两个集合只要包含一个公共元素,都需要比较一次,因此候选集合的数量特别大.通过对上述两种方案的分析,文献[14]提出了一种混合解决方案,将前缀过滤技术和Word-Count-Like方案进行了结合,从而进一步提高了集合相似性连接的效率.基于集合的相似性连接技术不能直接应用于欧氏空间下的相似性连接问题.MR-DSJ[15]提出了一种基于网格划分的大规模向量相似性连接方法.该方法具有很好的并行特性,很容易在MapReduce框架下实现.其不足之处是该方法只适合于维度较低的情况,一旦维度比较高时,其性能急剧下降.为了解决更高维度向量的相似性连接问题,Fries等人[16]在MR-DSJ的基础上提出了一种新的基于MapReduce的连接方案PHiDJ,PHiDJ方案主要通过对维度分组和变长的网格划分来提高连接速度.Lu等人[17]提出了一种基于泰森多边形的KNN连接解决方案.其基本思想是:给定两个向量集合犚、犛,首先基于泰森多边形将集合犚划分成k个子集,犚1,犚2,…,犚k,然后按照一定的规则,将集合犛也划分成k个子集,犛1,犛2,…,犛k.但是对犛的划分要满足一个要求:r∈R1,KNN(r,犛)犛1.在这种情况下,集合犚中的每一个子集只需要与对应的犛的子集进行比较就可以了,从而节省大量的网络传输代价和计算代价.Zhang等人[18]基于线性化技术,在MapReduce框架下提出了一种近似的KNN连接查询方案.Liu等人[19]针对海量空间数据提出了一种新颖的、基于MapReduce框架的并行Top-k连接查询方案,该工作分别在空间连接阶段和Top-k结果获取阶段进行了优化.雷斌等人[20]提出了一种大规模概率数据上基于EMD距离的并行Top-k相似性连接算法.文献[21]在MapReduce框架下,针对直方图概率数据提出了一种基于EMD距离的阈值相似性连接方案.文献[22]是最早尝试在MapReduce框架下解决海量向量Top-k连接查询问题的研究工作,首先提出了两种串行化算法:divide-and-conquer和branch-and-bound;然后又提出了两种基于MapReduce框架的并行化算法,分别是所有对划分算法(TopK-P-MR:AllpairPartitioningAlgorithm)和关键对划分算法(TopK-F-MR:EssentialPairPartitioningAlgorithm).但是,文献[22]中的算法一般比较适合于中低维度的向量,无法高效处理超高维度向量的Top-k连接查询问题.3问题定义与基础知识3.1问题定义定义1.向量阈值连接查询.给定两个向量集合犚和犛,距离函数dist,距离阈值ε,集合犚和犛的连接查询犚犛的结果就是返回所有距离小于ε的向量对,即犚犛={〈狉,狊〉|狉∈犚,狊∈犛,dist(狉,狊)ε}.其中犚={狉1,狉2,…,狉|犚|},犛={狊1,狊2,…,狊|犛|},狉i(狊j)是d维向量:狉i=〈ri1,ri2,…,rid〉,距离函数dist采用欧几里得距离.定义2.Top-k向量连接查询.给定两个向量集合犚和犛,距离函数dist,集合犚和犛的Top-k连接查询的结果就是返回距离最小的前k个向量对.即Top_k(犚犛)={〈ri1,sj1〉,…,〈rik,sjk〉},并满足如下要求:(1)rik∈犚,sjk∈犛;(2)dist(ri1,sj1)dist(ri2,sj2)…dist(rik,sjk);(3)对于任意一对〈rim,sjm〉,如果〈rim,sjm〉Top_k(犚犛),则dist(rik,sjk)dist(rim,sjm).3.2分段累积近似法分段累积近似法(PiecewiseAggregateApproxi-mation,PAA)是由Keogh等人[23]最先提的一种有效的时间序列降维方法,后来被广泛应用于时间序列相似性查询、模式发现、相似轨迹查询等多个领域.PAA的核心思想是:将原有的时间序列从高维空间(n维)降到低维空间(m维),mn,通过在低维空间的距离计算来实现高维空间数据的过滤,从而提高计算效率.具体如下:给定一个长度为n的时间序列T=〈t1,t2,…,tn〉,把T划分成m个等宽的块,得到长度为m的序列T-=〈t-列中第i块内所有元素的平均值,即1,t-给定两个时间序列T和Q,它们的欧几里得距离是降维之后的T-和Q-距离是其中D(T-,Q-)是D(T,Q)的下界,即D(T-,Q-)Page4D(T,Q),在文献[19]中已经得到证明.3.3符号累积近似法在PAA的基础上,文献[24]中提出了一种符号化方法:符号累积近似法(SymbolicAggregateApproximation,SAX).通过将PAA中的每一个值与某个符号集合中一个符号相对应,最终可以将PAA用一个字符串来表示.文献[24]中证明SAX的距离也是原始时间序列欧氏距离的下界,即D(T-,Q-)D(T,Q).其中d(t~一个查找表直接获得,查找表一般比较小,可以直接放在内存中.关于SAX的详细信息可以参考文献[24].图1展示了一个原始向量到PAA和SAX的转换示意图:犞是一个长度为20维的向量,每4维分成一段,可以转换成一个5维的向量PAA(图1(a));图2基于SAX的向量阈值连接查询框架然后通过符号化的方法,可以将PAA再转换成一个长度为5的字符串:SAX(犞,4,4)=a1a2a3a4a3(图1(b)).4基于SAX的向量阈值连接查询已有的向量阈值连接查询工作中,为了提高效率,大都采用了某种索引结构,如KD-树、R-树等.这些方案大都是单机环境下的算法,无法有效地处理海量数据;并且这些方案只适合于低维向量,一旦维度较高时,会出现维度灾难,其性能会急剧下降,接近于穷举比较的代价.为了解决高维向量的阈值连接查询问题,基于PAA技术,Luo等人[25]提出了一种新的维度聚集近似(DimensionAggregateApproximation,DAA)方法.通过降维,把原有的高维向量用DAA来表示,在DAA的基础上,结合MapReduce框架提出了两种并行化方法:一阶段过滤-验证算法和两阶段过滤-验证算法,从而大大提高了阈值连接查询的效率.虽然通过DAA技术可以以较低的代价对原有高维向量进行过滤,但是该方案仍然没有减少比较的次数,每一对向量至少需要比较一次,比较的总次数仍然等于两个集合中向量数量的乘积,计算的代价仍然比较大.实际上,有很多向量根本不需要进行比较.为了进一步减少比较的次数,本文在DAA的基础上,结合符号累积近似法,提出了一种基于SAX的阈值连接查询方法.其基本框架如图2所示,主要包括4个阶段:数据划分、利用进行分组、计算SAX相似对、结果验证.详细执行过程如算法1所示.Page5算法1.基于SAX的相似性连接.输入:ε,n,paaSize//距离阈值,块编号,PAA大小输出:相似向量对和距离1.map(k1,v1)2.paav1←getPaa(v1);saxv1←getSax(v1);3.StringnewVal←paav1+“,”+saxv1+“,”+4.ReplicatenewValntimes;//n:thenumberof5.reduce(k2,v2)6.LinkedListsaxList1,saxList2,saxVecMap1,7.saxList1,saxList2←getUniqueSax(v2);8.saxVecMap1,saxVecMap2←9.canSaxPairs←getSaxPairs(ε,saxList1,saxList2);10.ForeachsaxPair:canSaxPairsdo11.finalVecPairs←refineVecPairs(saxPair,12.ForeachvecPair:finalVecPairsdo13.Output(vecPair.vectors,vecPair.dist);(1)数据划分由于算法采取的是嵌套循环连接方法,所以在Map阶段,整个数据集合被近似均匀地划分成若干个块,然后对任意两个块进行比较.假设共分成n个块,则共有(n×(n+1))/2个块对需要进行比较,每一对由一个reducetask负责.同时对每一个向量狏,需要计算出向量的PAA、SAX值,然后把PAA、SAX信息和原始向量信息组合在一起,复制n份.PAA、SAX的信息在reducetask中进行比较时会用到(第1~4行).(2)利用SAX进行分组根据PAA和SAX的定义我们可以发现,不同的向量经过转换之后可能具有相同的SAX字符串,因此可以利用SAX对原始向量进行分组.在每一个reducetask中,对分配到该task上的所有向量,首先统计出所有不同的SAX(第7行),然后再基于SAX对向量进行分组,即记录下每一个SAX所包含的向量集合(第8行).(3)计算SAX相似对在每一个reducetask中,针对分配到其上面的所有SAX,利用嵌套循环连接的方法,计算出任意两个SAX之间的距离,如果两个SAX之间的距离大于阈值ε,则对应的原始向量之间的距离肯定大于ε,该SAX对可以过滤掉,其所对应的所有原始向量都不需要再进行比较(第9行).因为不同的向量可能具有相同的SAX,所以SAX的数量一般会远小于原始向量的个数,因此,即使使用嵌套循环连接方法来计算相似的SAX对,其比较次数也将远少于原有的向量比较次数,因此可以大大提高计算效率.(4)结果验证计算出相似的SAX候选对以后,需要对其对应的原始向量进行进一步验证,计算出向量之间的实际距离值,如果其实际距离小于或等于距离阈值ε,则可以作为结果输出,否则就过滤掉(第10~13行).4.1代价分析这一节主要对基于SAX的向量阈值连接查询算法(SAX-HDSJ)的代价进行分析,代价与文献[25]中的定义一样,主要包括通信代价Ct和计算代价Cc.主要对SAX-HDSJ算法和文献[25]中的B-DAAOSFR算法的代价进行比较.表1显示了代价分析中用到的一些标识符.标识符ddNLMKPPAAPSAXctd传递一个向量的通信代价Ctccd一个向量对的计算代价CcCB-DAACSAXSAX-HDSJ与B-DAA的比较.因为在进行数据划分的时候,每个向量随机地分配到不同的块中,每一个块的大小基本上是一样的.块的数量一般可以根据每个Reduce任务的计算能力进行估算:K=N如下:CB-DAA=Ct+N(N+1)其中,Ct是总的通信代价,N(N+1)对之间距离的总计算代价,N(N+1)是经过DAA过滤之后,向量原始距离计算的总代价.按照前面的分析方法,我们可以得到SAX-HDSJ算法的代价如下:CSAX=Ct+M(M+1)Page6N(N+1)其中,Ct是SAX-HSDSJ算法的总通信代价,与B-DAA算法相比,除了需要传输DAA和原始向量信息之外,SAX-HSDSJ算法还需要传输SAX字符串信息,然而由于SAX字符串的长度一般要比原始向量低很多,并且数量也比原始向量少很多,因此我们可以近似认为Ct和Ct是一样的.M(M+1)SAX字符串距离的总计算代价;N(N+1)PSAX)是经过SAX过滤之后,PAA距离的总计算代价;N(N+1)滤之后,原始向量距离的总计算代价.SAX-HDSJ算法的核心是通过SAX减少PAA距离的计算次数,所以SAX字符串的数量不能太多,否则会得不偿失.因此,我们有如下定理.定理1.如果M<PSAX槡2·N,那么CSAX<CB-DAA,即SAX-HDSJ算法的代价小于B-DAAOSFR算法的代价.M<PSAX槡2·NM2<PSAX·N22M2N2<PSAXN2=M(M+M)2M2M(M+1)N(N+1)<PSAXM(M+1)M(M+1)N(N+1)如前所述,假设Ct和Ct大小相等,可以得到证明.2ccd(1-PPAA)Ct+M(M+1)N(N+1)<Ct+N(N+1)CSAX<CB-DAA.5基于阈值的Top-犽连接查询如果事先能够知道第k个向量对的距离ε,那么就可以用ε作为距离阈值,直接采用文献[25]提出的基于阈值的连接查询算法来进行计算,具体计算流程在第4节第1段已经进行了描述.然而事实上我们无法准确知道第k个向量对的距离.一种直观的方法就是可以预先选定一系列距离阈值ε1,ε2,ε3,…,其中:i<j,εi<εj.针对每一个阈值εi都执行一次阈值连接查询算法,如果在εi情况下满足条件的结果数量小于k,则以εi+1为新的距离阈值再重新执行一次阈值连接查询,直到满足距离阈值的结果对的数量大于或者等于k,则结束.阈值的选择一般根据向量集合中距离的分布情况人为确定,如可以以某一个区间递增为例:vi=0.05×i,i=1,2,….该算法实现起来比较简单,但是因为每次都需要重新执行阈值连接查询,所以会带来大量的冗余、重复性的计算工作,效率较低.为了避免冗余计算,后面提出了基于SAX的Top-k连接查询算法.6基于SAX的Top-犽连接查询第5节针对事先选择的不同距离阈值分别执行阈值连接查询算法,虽然比较直观,但是会出现大量的冗余计算.如果我们能够准确确定第k个向量对的距离ε,则执行一次阈值连接查询即可得到需要的结果.由于距离阈值ε的大小直接影响到算法的执行时间,ε越小,算法的执行时间越短,ε越大,算法的执行时间越长.因此,如何估计出第k对的距离,并使其尽可能接近真实的第k个向量对的距离,就成了一个核心的问题.在进行阈值估计的时候,最简单的方法是从原始数据集中随机采样一部分数据(如10%),然后对采集到的样本进行两两比较,求出距离最小的前k个向量对,用第k个向量对的距离作为估计的距离阈值,该阈值肯定是Top-k结果的距离下界.此方法虽然简单,但是得到的阈值往往会比较大,导致后面的计算开销也会比较大.为了使估计出的ε更加接近真实的第k个向量对的距离阈值,在采样之前,我们先对所有的向量基于SAX进行分组,然后针对每一个SAX分组中对应的向量进行采样,这样得到的采样数据之间的距Page7离一般会比较小,因为距离越小的向量越倾向于分配到同一个SAX分组中.估计出第k个向量对的距离阈值ε以后,接下来就可以利用我们在第4节中提出的“基于SAX的向量阈值连接查询”方法来进行计算,因为只需要求出前k个向量对,所以需要对第4节中的算法进行稍微修改.图3基于SAX的Top-k连接查询框架算法2描述了Job1的执行过程,在map阶段,主要负责计算出每个向量的SAX,然后以SAX作为key值,以原始向量作为value传送到reduce端(第1~4行);在reduce端,首先对每一个SAX分组里面的所有向量进行随机采样,得到样本集合(第7~11行),然后在样本集合中,计算出两两之间的距离(第12行);最后把每个距离输出(第13~14行).算法2.数据采样和距离计算(Job1).输入:ε,paaSize//距离阈值和PAA大小输出:相似向量对和距离1.map(k1,v1)2.paav1←getPaa(v1);3.saxv1←getSax(v1);4.emit(saxv1,v1);5.reduce(k2,v2)6.LinkedListsamples,vectorsPairs;7.Foreachvector:v2do8.j←Math.abs(random.nextInt())%rate;9.If(j==1)10.samples.add(vec);11.Endif12.vectorsPairs←loopJoin(samples,ε);13.ForeachvecPair:finalVecPairsdo14.emit(vecPair.vectors,vecPair.dist);基于上述思想,我们提出了基于SAX的Top-k连接查询方法,图3给出了该方案的执行框架.该方案主要由4个MapReduceJobs组成,其中Job1和Job2主要是用于阈值估计,Job3是执行基于阈值的Top-k连接查询,从而得到局部的Top-k结果,Job4主要是负责从所有局部的Top-k结果中计算出全局的Top-k.算法3描述了Job2的执行流程,其主要目的是从Job1的计算结果中找出距离最小的前k个向量对,并以此作为估计的距离阈值.算法3.Top-k距离阈值估计(Job2).输入:相似向量对和距离输出:ε//估计的Top-k距离阈值1.map(k1,v1)2.newKey←“one”;3.newValue←v1;4.emit(newKey.newValue);5.reduce(k2,v2)6.PriorityQueuepq=newPriorityQueue(k);7.intcountTotal=0;doubledist=0.0;8.For(Textval:values)9.countTotal++;10.dist←Double.parseDouble(val.toString());11.if(countTotal<=k)12.pq.add(dist);13.elseif(dist<Double.parseDouble(pq.peek().14.pq.poll();15.pq.add(dist);16.Endif17.EndforPage818.context.write(newText("thre:"),算法4描述了Job3的执行流程:基于阈值的Top-k连接查询,其基本思想是基于第4节的“基于SAX的向量阈值连接查询”.不同之处在于,由于只需要得到距离最小的前k个向量对,所以满足ε要求的并不一定都是需要的结果.因此在执行阈值连接的时候,可以维护一个长度为k的队列(第8行),把目前为止、距离最小的k个向量对及其距离存放其中.同时在计算的过程中,可以根据队列中结果的情况对阈值ε进行及时更新,如果第k个向量对的距离小于ε,则把ε更新为第k个向量对的距离(第35~37行)以更新后的ε值进行后面的计算,从而加快执行速.同时,对于候选的SAX相似对,也可以利用ε进行过滤,如果某一个SAX对的距离大于ε,则其对应的所有向量之间的距离肯定大于ε,所以可以直接过滤掉(第17行).随着计算的进行,ε的值会越来越小,其过滤效果也会越来越好,从而可以减少很多不必要的计算,提高计算的效率.算法4.基于SAX的局部Top-k计算(Job3).输入:ε,n,paaSize//距离阈值,块编号,PAA大小输出:Top-k向量对1.map(k1,v1)2.paav1←getPaa(v1);3.saxv1←getSax(v1);4.StringnewVal←5.ReplicatenewValntimes;//n:thenumberof6.reduce(k2,v2)7.LinkedListsaxList1,saxList2,saxVecMap1,8.PriorityQueuepq←newPriorityQueue(k);9.String[]vecList1,vecList2;10.Stringsax1,sax2;11.DoubledistTemp←0.0;12.IntcountTotal←0;13.saxList1,saxList2←getUniqueSax(v2);14.saxVecMap1,saxVecMap2←15.canSaxPairs←getSaxPairs(ε,saxList1,saxList2);16.ForeachsaxPair:canSaxPairsdo17.IfsaxPair.dist>ε18.continue;19.Endif20.sax1←saxPair[0];sax2←saxPair[1];21.vecList1←saxVecMap1.get(sax1);22.vecList2←saxVecMap2.get(sax2);23.Foreachv1:vecList1do24.Foreachv2:vecList2do25.distTemp←getDist(v1,v2)26.IfdistTemp>ε27.continue;28.Endif29.countTotal++;30.If(countTotal<=k)31.pq.add(dist);32.Elseif(dist<Double.parseDouble(pq.peek().33.pq.poll();34.pq.add(dist);35.if(ε<Double.parseDouble(pq.peek().36.ε←thre=Double.parseDouble(pq.peek().37.Endif38.Endif39.Emitallthepairsinpq;7实验评估本节我们对所提出的基于SAX的Top-k连接查询方案(SAX-Top-k)进行实验验证,并与基准方案:基于阈值的Top-k连接查询(Baseline-Top-k)进行性能对比,Baseline-Top-k采用的基本算法是基于文献[25]提出的一种基于MapReduce框架的算法.同时测试了两种算法在单机环境下的性能对比(SAX-Top-k-Serialvs.Baseline-Top-k-Serial).主要测试不同k值对执行时间的影响、不同数据集大小对执行时间的影响、不同维度对执行时间的影响以及阈值估计所消耗的时间.7.1实验环境实验是在一个由19个节点组成的集群上进行的,其中1个作为master节点,16个作为slave节点.节点配置如下:CPU:Q96503.00GHz,Memory:8GB,Disk:500GB,OS:64bitUbuntu9.10server.其他参数如表2所示.k集群节点map任务个数/节点reduce任务个数/节点4数据量(万)Page9实验中所采用的数据集来自于文献[25]中所用到的数据集,可以从网站下载①,具体参数如表3所示.数据集类型数量维度大小image-128真实500000128423Mimage-128-2w真实2000012818Mimage-960真实5000009603.92GImage-128-syn-1模拟200000128175.4MImage-128-syn-2模拟300000128262.7MImage-128-syn-3模拟400000128347.9MImage-960-syn-1模拟2000009601.64GImage-960-syn-2模拟3000009602.46GImage-960-syn-3模拟4000009603.28G7.2实验结果与分析7.2.1不同k对执行时间的影响图4展示了针对image-128数据集,不同的k对执行时间的影响.在执行Baseline-Top-k时,阈值依次选择为0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.45,0.5.在k较小的情况下,SAX-Top-k与Baseline-Top-k的执行时间差不多,因为在k比较小的情况下,Baseline-Top-k只需要执行一次就可以达到要求;但是随着k的增加,Baseline-Top-k往往需要执行多次才可以返回所需要的k个相似对,因此执行时间增长很快.SAX-Top-k的执行时间虽然也有所增加,但是针对所有的k只需要执行一次,所以SAX-Top-k的性能比Baseline-Top-k好很多.并且k越大,SAX-Top-k相对性能越好.图4不同k对执行时间的影响(image-128)图5展示了针对image-960数据集,不同的k对执行时间的影响.其变化规律与image-128数据集基本一致,不过在image-960数据集中,当k为15000和20000时,Baseline-Top-k的执行时间是一样的,这是因为在阈值为0.1时,返回结果的对数是10566,阈值为0.15时,返回结果的对数是30486,15000和20000都在两者之间,所以在阈值为0.15时可以同时满足15000和20000的要求,故两种情况下的时间相同.图6单机环境下的执行时间对比(image-128-2w)图6展示了在单机环境下两种算法的性能对比情况.因为是在单机下执行,所以选择的是较小的数据集(image-128-2w),k的取值分别为50、100、200、400和800.在执行Baseline-Top-k-Serial时,阈值依次选择为0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.45和0.5.从图7可以看出,SAX-Top-k-Serial的性能优于Baseline-Top-k-Serial的性能,并且随着k的增大,SAX-Top-k-Serial的相对性能更好.7.2.2不同数据集大小对执行时间的影响图7展示了数据集image-128在不同规模下的执行时间,图7(a)和(b)分别表示k=1000和k=5000情况下的执行时间对比.从图7(a)中可以看出,在所有数据规模情况下,SAX-Top-k的执行时间都要小于Baseline-Top-k方法.当数据集超过30万的时候,随着数据集规模的增加,SAX-Top-k的性能越来越好.从图7(a)中我们还可以看到一个特殊变化:Baseline-Top-k在数据集为30万时的执行时间小于20万时的执行时间,主要原因在于当数据集为20万的时候,要想得到预期数量的相似对,Baseline-Top-k就需要执行4次计算,而在30万的①http://corpus-texmex.irisa.frPage10时候,只需要执行一次计算就可以了,所以前者消耗的时间相对较长.图7(b)显示了k=5000时的执行图7不同数据集大小对执行时间的影响(image-128)图8展示了数据集image-960在不同数据规模下的执行时间,总体来看,随着数据集规模的增大,两种算法的执行时间都有所增加,但是SAX-Top-k的执行时间一直都小于Baseline-Top-k的执行时间,并且增加速度也较小.Baseline-Top-k的执行时间有时会出现波动(图8(b):30万vs.40万),其原图8不同数据集大小对执行时间的影响(image-960)7.2.3不同维度对执行时间的影响图9展示了在不同维度下两种算法的执行时间图9不同维度对执行时间的影响(k=5000,n=50万)时间对比,其变化规律与k=1000时基本一致,不过总的执行时间要大于k=1000时的执行时间.因在于Baseline-Top-k的执行时间既与每次的执行时间相关,又与执行的次数相关,而执行的次数则与具体的数据集的分布有关,所以就可能会出现在数据集比较大的情况下,执行次数比较少,相应的总的执行时间就比较短.对比,其中k为5000,向量规模为50万.从图中可以看出,随着维度的增大,两种算法的执行时间都不断增加,但是SAX-Top-k算法的时间增长速度比较平缓,并且,维度越高,SAX-Top-k算法的性能优势越明显.7.2.4阈值估计时间及效果图10展示了不同的采样规模下阈值估计所需要的时间,从图中可以看出,随着采样数量的增加,阈值估计所需要的时间也会逐渐增加;image-960所需要的时间比image-128所需要的时间长,这是因为在同样的采样规模下,image-960数据集的维度比image-128数据集的维度高,所以计算距离时Page11所需要的时间比较长,因此总的阈值估计时间也会比较长.图11展示了在不同的采样规模下,所得到的估计阈值的大小.从图中可以看出,随着采样规模的增大,估计的阈值会逐渐减小,这说明采样规模越大,得到的估计阈值越接近真实的第k个向量对的距离阈值.而image-128的阈值比image-960的阈值要大一些,这主要是与数据集的数据分布有关,与维度没有直接的关系.8结论本文基于分段累积近似法(PAA)和符号累积近似法(SAX),对高维向量进行降维、分组,然后根据原始向量的SAX分组信息对原始向量进行抽样,从而估计出距离最小的第k个向量对的距离ε,然后将Top-k连接查询转换成以ε为阈值的阈值连接查询.结合MapReduce框架,提出了基于SAXTop-k连接查询算法,实验表明,所提方案具有良好的性能.未来将对现有的方案做进一步的优化:在MapReducejob执行计算的时候,在reduce端,每一个reduce任务结束之后,第k个向量对的相似度阈值可能会发生改变,如果能够让后面的reduce任务在执行的过程利用更新后的阈值,则可以进一步提高过滤效果,加快计算速度.
