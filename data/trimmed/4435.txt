Page1一种基于逗留时间的新型内容中心网络缓存策略王国卿1)黄韬1)刘江1)陈建亚2)刘韵洁1),2)1)(北京邮电大学网络与交换技术国家重点实验室北京100876)2)(北京邮电大学北京市网络体系构建与融合重点实验室北京100876)摘要内容中心网络(Content-CentricNetworking,CCN)作为一种以内容为中心进行路由、缓存的新型未来网络体系架构受到了广泛的关注.在CCN中,关键技术问题之一是网络缓存问题,现有方案主要采用ALWAYS-LRU缓存策略,然而该策略容易出现相邻节点重复缓存的问题,使得网络整体缓存效率较低.针对这一问题,文中提出了一种基于逗留时间的新型缓存决定策略,设计了一种适用于CCN的合作缓存机制.在请求泊松到达的假设下,通过在单个缓存器对LRU(LeastRecentlyUsed)替换策略使用马尔可夫链建模,该文得到了内容在各缓存器平均逗留时间的近似计算公式.数值仿真结果显示,该方案相比传统缓存策略,有效地提升了网络缓存的效率和缓存内容的多样性,进而减少了用户请求服务的总跳数,增加了内容访问的命中率.关键词内容中心网络(CCN);逗留时间;LRU;未命中率1引言随着互联网技术与应用的飞速发展以及互联网用户的快速增长,基于TCP/IP的互联网体系架构逐渐暴露出诸多问题,主要体现在可扩展性差、安全可控性低、移动性支持不足、服务质量难以保证等方面[1].为此,国内外学术界纷纷展开了未来Page2网络体系架构的研究,从以主机为中心向以内容为中心进行转变,主要涉及的研究项目包括北美的CCN/NDN①[2-3]、DONA[4]以及欧盟的PSIRP/PURSUIT②、NetInf[5]等等.这些架构虽然在一些细节上有区别,但是网内节点缓存内容的思想已经达到了共识.CCN作为最受关注的未来网络架构之一,其基本思想从被提出之日起,就引发了学术界的一系列的研究热点如内容路由[6]、安全[7]、拥塞控制[8]及网内缓存[9-19]等,尤其是关于CCN网内缓存机制的研究受到了学术界的广泛关注.总结起来,CCN网内缓存的研究主要体现在两个方面:一方面通过建立数学模型或仿真实验的方法,评估ICN系统现有缓存策略的性能[9-13],其中,文献[9-11]重点研究了ICN在线型和树型拓扑下,缓存策略为最近最少使用(LRU)时内容在节点处的命中率表达式,Carofiglio等人[12]则给出了在CCNx原型系统上,分别采用LRU、最小使用频率(LFU)和生存时间(TTL)3种策略的性能评估方案与对比分析结果.Rossi等人[13]用ccnSIM仿真研究了在不同网络拓扑结构下,不同缓存大小的分布对CCN网络性能的影响.另一方面,大量研究致力于提出各种新型缓存策略以提升网络性能,例如清华大学提出的通过跳数感知协议得到利润值的最小利润(LeastBenefit,LB)缓存替换算法[14],以及通过设置内容老化时间以实现驱动流行内容缓存到边缘的算法[15];Chai等人[16]提出利用计算缓存器在网络中最短路径上的出现次数来设计内容放置策略的方法;Psaras等人[17]通过研究中间节点与源节点距离,中间节点到请求节点距离以及中间节点到请求者的剩余路径缓存能力,设计了内容在中间节点缓存概率的放置策略;文献[18]则提出了将大文件分块,利用Hash函数将文件块放置到不同缓存节点的方案;Cho等人[19]提出了随请求次数指数增加逐跳往边缘缓存的内容块数,实行改进的LCD(LeaveCopyDown)策略等.缓存策略的研究已有多年的历史,完整的缓存策略由两部分组成:缓存决定策略和缓存替换策略.在CCN体系架构提出之前,大多数研究都是针对缓存替换策略展开的[20],而缓存决定策略方面的研究却很少,主要有随机、LCD(LeaveCopyDown)和全存(ALWAYS)3种.随机策略是以一定的概率来决定是否在该节点缓存经过的内容,LCD策略是让返回的内容仅在第一跳节点缓存,目前,CCN采用的ALWAYS策略对所有经过该缓存器的内容(数据)都缓存.这3种策略的一个共同的缺陷就在于各节点在进行决策时均未综合考虑内容的流行度和缓存容量等因素.在上述有关CCN缓存策略的研究中[14-19],文献[15-19]都是研究缓存决定策略的,由此可见,CCN中缓存决定策略的研究已经引起了学术界的重视.但是在策略的设计方面,这些成果还有一定的改进空间.文献[15]提出了一种在已存满的节点中若无可替换的内容则不缓存新内容的策略,主要考虑了节点距用户的跳数及内容流行度的因素来设计内容的存活时间,这是一种以替换为主导的决定策略,没有直接对决定策略研究.文献[16]所提的策略需要计算全网任意两个节点对之间的路径,具有可扩展性差的缺点.为此,文献[17]提出了在线计算当前路径上各节点的缓存概率的方法,但是该方法仅考虑了节点缓存容量及节点距用户的跳数,没有考虑内容的特点.文献[18]提出分布式算法保证缓存同一内容不同数据块的节点距离不超过下界的一定的倍数,主要解决了大内容的缓存决策问题.文献[19]仅利用了内容的流行度,提高流行内容往边缘缓存的收敛速度.本文主要考虑到要尽量减少跨自治系统(Autono-mousSystems,AS)之间的流量,各AS应尽可能少地从其他AS获取内容,因此在AS内实现增加内容多样性的缓存决定策略可以减少AS间瓶颈带宽的使用.研究动机主要是为减少节点对内容的不必要的复制次数,减少域间带宽的使用,同时提高命中率.本文通过提取出刻画节点对内容竞争力的逗留时间(SojournTime,ST),设计了一种基于逗留时间的缓存决定新策略,逗留时间是指内容从缓存在节点到本次被替换出去的这段时间.本文先给出了ST决定策略的设计方法,将逗留时间加入到兴趣包或数据包中,让节点通过比较内容在相邻节点处的平均逗留时间来决定是否缓存该内容,再结合LRU替换策略,得到了完整的ST-LRU缓存策略.随后在特殊的场景下,抽象并建立出马尔可夫链模型,并利用排队论的方法推导出平均逗留时间的近似公式,该公式很好地反应了在有限的存储容量下节点对内容的竞争力.最后,本文仿真验证了新策略在复制次数,总跳数及命中率上的优势.①②Page32基于逗留时间的缓存策略2.1CCN系统模型描述在CCN中,内容被分成数个大小相同的数据块,数据块被唯一命名,被永久地存储在一个或多个服务器中.CCN的数据传输主要由数据包(DataPacket)和兴趣包(InterestPacket)完成,用户利用接收者驱动的传输协议发送兴趣包,基于名字的路由协议确保了请求被路由到合适的缓存器,每个中间节点都会跟踪该节点未命中的请求,以便将被请求的数据原路返回到接收者以及让途经的节点缓存数据,此外,中间节点还将请求聚合,即当第一个请求还未被满足时,避免转发对该同一个数据的其他请求.数据可能来自服务器或来自任何被命中的缓存器,即路径上暂时保存内容副本的节点,缓存器采用LRU替换策略.LRU机制的核心工作机理是当需要缓存内容k时,若内容k已经缓存在CS中,则将内容k移到最上面,原来在内容k上面的内容下移一位;若CS中没有内容k,则将内容k缓存在最上面,原来在CS中的每个内容下移一位,原来在CS中最下面的内容被替换出去.由于内容的总大小远大于单个节点的缓存容量,因此被缓存的内容经常会被新到的内容替换出去.因此,内容的平均逗留时间是一个有限的实数.从ST和LRU的定义不难看出,ST值应服从如下规则:(1)缓存器容量越大,在该缓存器的内容的ST值也越大;(2)内容流行度越高,ST值也会越大.显然,通过比较内容在相邻缓存器的逗留时间大小,把内容缓存在逗留时间较长(即ST值较大)的节点能够有效减少内容的复制次数,增加AS域内的内容多样性.下面用一个简单的场景来比较ST-LRU机制较ALWAYS-LRU机制的优势,如图1所示.用STk(i)表示内容k在节点i处的平均逗留时间,假设一个由两个路由器a和R2在R1中的平均逗留时间大于内容R2可以与其他AS域通信.通过对内容a及其他内容在R1和R2的到达率等因素的分析,已知内容a在R1中的平均逗留时间大于内容a在R2中的平均逗留时间,即STa(1)>STa(2).假设R1处有一个内容b的请求,内容b返回之后,b与R2中都缓存了内容b,然后R1处又有一个内容a的请求,返回的内容a在ALWAYS策略下在R1和R2中都缓存;而在ST策略下,由于STa(1)>STa(2),内容a仅缓存在R1中.显然,ST机制有效地避免了相邻节点缓存相同内容的问题,有效地增加了AS域内内容存储的多样性.2.2ST缓存决定策略在CCN中的设计CCN路由器有3个数据结构表:内容存储表(ContentStore,CS)、跟踪兴趣包表(PendingInterestTable,PIT)和转发信息表(ForwardingInformationBase,FIB).其中,CS表用来缓存所经过的内容,PIT表用来记录那些刚被请求但还没有得到回应的内容条目及其转入接口,FIB表则记录内容名对应的下一跳接口.未命中的兴趣包(CS中没有缓存被请求的内容)和它的接口被记录在PIT表中,并且通过查找FIB表将该兴趣包转发到下一跳,返回的数据包通过查PIT按兴趣包原路返回到请求者.ALWAYS缓存决定策略是将所有经过路由器的PIT中有记录的内容缓存到CS中,而ST机制设计的核心目标是让内容缓存到合适的路由器中.本文将STk加入到内容k的兴趣包和数据包中,并将该值通告给邻居节点.节点i接收到从节点j处发来的内容k的兴趣包,节点i先检查其CS中是否存有内容k,若有则直接返回内容k;若无,则查询PIT表:若PIT表中有内容k这个条目,则在该条目中加入接口j及STk(j),并且丢弃该兴趣包;若PIT表中没有内容k的条目,则创建一个新的条目,记录该内容前缀和接口j及STk(j),随后将STk(i)覆盖内容k的请求包中的STk(j),并按照FIB表的接口记录转发到下一跳.于是,改进后的PIT表设计结构如图2所示.图2基于ST机制下的CCN网络PIT表设计结构Page4当内容k从节点j返回到节点i时,首先查询PIT表中是否有内容k的条目,若无,则直接丢弃该数据包,若有,则将该数据包中携带的STk(j)与PIT表中内容k条目中记录的STk比较,当且仅当STk(i)大于其他几个STk值时,才将内容k缓存到节点i的CS中.然后将STk(i)加入到数据包并覆盖数据包中的STk(j),并将该数据包转发到PIT表记录的所有接口,具体算法流程如图3所示.图3从节点j返回的内容k在节点i的算法流程图在图3中,y(i)用于记录缓存器i中按照逗留时间挑选出的缓存内容个数,x(i)表示缓存器i的缓存容量,有y(i)x(i).在缓存器i还未接收到任何内容之前,缓存器i中没有缓存内容,故y(i)=0,开始运行之后,节点i接收到内容,先查找PIT表,如果PIT表中无该内容条目记录,说明该内容已被返回或者出错,因此丢弃该内容;如果PIT表中有该内容条目,则把PIT中记录的该内容条目对应的逗留时间与数据包携带的上游节点的逗留时间比较,若缓存器i处的逗留时间大于其他所有逗留时间,则存入节点i,同时检验按逗留时间大小缓存的内容个数y(i)是否已将缓存器存满,即判断是否y(i)<x(i),目的是要更新y(i);若缓存器i处的逗留时间不大于其他所有逗留时间,则判断CS是否已经存满,若已经存满且y(i)=x(i),则不缓存该内容;若CS未存满,则缓存该内容,以避免浪费缓存器的空间.从该算法可以看出,ST-LRU机制会让内容缓存在平均逗留时间较大的节点中,相邻节点不会缓存相同的内容,从而达到增加多样性、减少复制次数和提高命中率的目的.在两种极端情形下,节点i将决定缓存所有经过的内容,ST机制将与ALWAYS机制有一样的效果,这两种情形是:(1)仅有小于x(i)种内容的STk(i)小于邻居处的STk(即y(i)<x(i));(2)STk(i)恒大于邻居处的STk(k).这是因为当y(i)<x(i)时,新到的内容总是会被缓存;当节点i处所有内容的逗留时间都大于其相邻节点处的相应内容的逗留时间时,新到的内容也将全被缓存.2.3ST-LRU策略举例近似计算公式如下:STk(i)=x(i)其中,μk(i)=λ(i)-λk(i).其详细推导将在第3节中给出.从式(1)可以看出,ST值与流行度和缓存容量的变化关系符合2.1节所述规则.下面用一个简单的场景来描述ST-LRU机制的整个流程,并与ALWAYS-LRU策略比较.假设由两个路由器R1和R2构成的一个AS域,缓存容量分别为2和1个内容,即x(1)=2,x(2)=1.每个节点接收到内容a,b和c的请求率如图4给出.这样,通过式(1)可以算出内容的ST值如表1所示.为了便于分析ST-LRU策略,先给出ST值的内容本例仅考虑与a的请求到达R1,由于R1中没有内容a的请求到达R1,由于R1中没有内容a,请求被转发到R2,R2中也没有内容a,从而,请求被转Page5图4ALWAYS-LRU与ST-LRU缓存机制对比发到其他AS域,返回的内容a先到达R2,比较STa(2)与STa(1),有STa(2)<STa(1),然后查看CS是否已满,若否,将内容a缓存到CS中,然后转发至R1,R1采用同样的算法进行实现(如图3所示),即首先将内容a缓存到CS中,由于STa(1)>STa(2)且y(1)<x(1),y(1)自增1.接下来内容的请求过程与上述过程类似,不再赘述.初始化结束后(虚线以下),R1又收到内容a的请求,ST-LRU机制下R1就可以直接返回内容a(即命中),而在ALWAYS-LRU机制下,该请求在本地未命中,被转发到其他AS域,至少需要两跳才可以命中.而且,在虚线以下,ST-LRU策略几乎稳定,即R1缓存内容a和b,R2缓存内容c,内容a,b和c都不会再被复制,而ALWAYS-LRU机制会一直复制.显然,ST-LRU的新策略有效地提高了命中率,减少了跳数及不必要的内容复制次数.3ST-LRU方案的性能分析3.1CCN数学模型及假设本文首先建立一个具有N个节点(CCN路由器)的CCN网络模型,这N个节点在一个AS域中,网络中共有M种不同的内容,这些内容大小一样[10-12],永久地存储在该AS域外的一个或多个服务器中,即所有内容一定可以从该AS域外获得.假设节点i可以缓存x(i)个内容,x(i)远小于M.节点接收到的请求过程是由本节点的用户请求序列和邻节点的未命中(miss)序列构成的.假设节点i从用户处接收到的请求服从参数为λu(i)的泊松分布,根据随机服务系统原理,服从泊松分布的输入流的输出也服从泊松分布,因此,邻节点未命中的请求序列也服从参数为η(i)的泊松分布.因此,节点i的输入过程服从参数为λ(i)=λu(i)+η(i)的泊松分布.本文涉及到的主要符号如表2所示.符号N节点(CCN路由器)个数M内容种类数x(i)节点i缓存容量(个内容)λu(i)节点i收到用户的请求率(个/s)η(i)节点i收到下游节点miss的请求率(个/s)λ(i)节点i收到的总请求率λ(i)节点i决定存的内容的总请求率λk(i)节点i收到内容k的请求率STk(i)内容k在节点i的平均逗留时间3.2平均逗留时间的计算公式本文在分析过程中采用了经典的LRU替换策略,在进行平均逗留时间的设计之前,我们首先建立一个LRU策略的数学模型.首先,因为内容k所在位置都只与前一个位置有关,与再之前所处的位置独立,又因为请求是泊松到达的,内容k两个位置间的转移仅发生在请求的到达时刻,泊松到达仅与时间间距相关,因此,我们将LRU的工作过程抽象成为一条齐次马氏链[9],链的状态就是内容k在CS中的位置:状态0表示内容k不在CS中,状态1表示内容k在CS的最上面,状态l表示内容k在CS的第l位置.从状态l(l=1,2,…,x)转到状态(l+1)的转移率为μk,其中(x+1)表示状态0,每个状态l都可以转移到状态1(l≠1),转移率为λk(内容k的到达率)(如图5所示).于是,这条马氏链的转移率矩阵可表示为犙=这里,β=λk+μk.对于满足λk/μk<1的内容k,它对应的上述马Page6氏链是非周期、不可约、正常返的,因此,一定存在稳态概率,可通过解下面的稳态方程来求解:这里,πk是一个(x+1)维的列向量,且犲=(1,1,…,1)T是一个(x+1)维的列向量.则有其中,πkl表示稳态时内容k处在状态l的概率.由此,可以推导出内容k在缓存器中平均逗留时间的公式.命题1.缓存器收到的内容请求服从参数为λ的泊松到达,内容k的请求服从参数为λk的泊松过程(k=1,2,…,M),内容具有相同的大小,缓存容量为x个内容,则内容k在缓存器中的平均逗留时间近似公式可表示为其中,μk=λ-λk.证明.若内容k不在0状态,则可以将除内容k以外决定缓存的内容分成两类:(a)未被缓存的内容及存在内容k下面的内容;(b)存在内容k上面的内容.而如果内容k在0状态,则不需要分类.显然,只有(a)类内容及内容k的到达才会改变内容k的状态,而(b)类内容的到达不会改变内容k的状态.令ωk为内容k在缓存器中的逗留时间,Prj{ωk>t}表示在内容k处于状态j的条件下,内容k的逗留时间大于t的概率,则有CCN网络中请求到达序列与一般的排队系统到达序列的不同之处在于:对同一内容的请求可能在前一个请求还未被满足之前重复到达,这样该内容就会由(a)类内容变成(b)类内容.在本模型中,当内容k在缓存器的第j个位置等待被替换出去的时候,在下一个内容k的请求到达之前的时间t内,当且仅当有不少于(x-j+1)个不同的(a)类内容请求到达,内容k才会被替换出去.即在t这段时间内,当且仅当到达的(a)类内容请求数小于(x-j+1)时,逗留时间才会大于t,因此有将式(7)代入式(6)中,得到Pr{ωk>t}=∑x从而得到内容k的平均逗留时间:从式(9)可以发现,等号右边的表达式与x和λk正相关,与μk负相关,与我们预期的STk与这三者之间的关系一致.下面进一步分析内容k状态的向下转移率μk的取值.由上文可知,当内容k处于非零状态时,只有(a)类内容的到达才会让内容k的状态值加1,而(b)类内容的到达不会改变内容k的状态.因此,得到当内容k处在状态1时,μk取得最大值,即式(10);当内容k处在状态x,并且存在它上面的内容是最流行的(x-1)个内容时,μk取得最小值,即式(11).由于πk0是μk的不减函数,于是可以得到内容k的未命中概率区间为Page7式(5)的右侧为μk的不增函数,当内容请求的分布比较均匀(即在时间t内到达两个或以上相同内容的请求几乎不可能),并且在x(i)远小于M的情况下,(b)类内容相对于(a)类内容很少.因此,可以推得STk的近似计算公式:其中μk=μupper3.3ST-LRU方案的定性分析从上述命题的证明过程可知,当内容请求分布让短时间内重复请求同一个内容的概率很小时,式(5)更有效,即若请求服从Zipf分布,则非负参数α越小越好.此外,由于式(5)中μk的取值忽略了缓存在内容k上面的内容,即(b)类内容,因此缓存器容量x也是越小越好(x越小,缓存的内容就越少,从而缓存在内容k上面的内容也越少).由上节分析,可将传统ALWAYS-LRU机制的未命中率表示为mk(i)=λk(i)μk(i)同理,可将ST-LRU机制的未命中率表示为mk(i)=λk(i)μk(i)μk(i)=λ(i)-λk(i),Ik(i)=0,节点i不存内容k由ST-LRU策略的算法及式(13)和式(14)可以得出新策略设计的合理性如下:(1)减少了内容的复制次数,就是通过让平均逗留时间长的内容在缓存器中停留更长时间,不复制平均逗留时间较短的内容来实现的.(2)减小了总的未命中率(=∑k而减少了总跳数,这主要有两方面的原因:一方面,新策略减小了决定缓存的内容个数,即μkμk,由于未命中概率πk0随着μk的减小而减小,从而决定缓存的内容未命中率有所减小;另一方面,不决定缓存内容的未命中概率虽然为1,但是不决定缓存的内容的请求率也很小,因此有效减少了系统总的未命中率.(3)增加了AS域内的内容多样性,从而减少了AS域间的流量传输.通过相邻节点之间的比较决定是否缓存内容,有效避免了相邻节点缓存相同的内容,提高了系统的整体缓存效率.在该策略的设计中,兴趣包和数据包在原包的基础上又增加了一段空间携带该内容在前一个节点处的逗留时间数值,并且给节点增加了读取与比较相邻节点逗留时间的计算代价.该策略在传输过程中没有增加新的包,在读取的过程中也只是在原来读取内容前缀及接口的基础上多读取了一个数据———逗留时间.这些代价远远小于将相邻两个节点的缓存空间充分利用所节省的存储成本.4仿真结果与分析4.1仿真环境设置本文考虑一个具有10个节点的CCN网络模型(N=10),CS初始为空,M=1000个相同大小的内容存储在服务器中.用户和其他节点可以发送请求到他们相邻的上游节点.用户发送到节点的请求服从泊松分布(λu=5个/s),内容请求服从参数为α(i)=α,i=1,2,…,10的Zipf分布,节点i的请求概率设为qk(i)=c(i)/kα(i),其中1/c(i)=∑k为归一化参数(即内容的流行度从大到小排序,最流行的内容标识为1).由于CCN目前尚未在真实网络中部署,本文仿真是通过理论分析的数值结果验证[10-12,15],与实际结果之间可能出现偏差.在CCN中,无论采用何种网络拓扑结构,其最基本的场景都是,每个节点都接收到两种请求流:一种是与其直接相连的用户的请求,另一种是其他节点未命中的请求流之和.在网状拓扑结构中,每个节点收到的请求流也是上述两种,区别仅仅是η(i)数值上的变化.因此为便于问题的分析(不考虑路由策略),同时不影响通用性,本文仿真任意网络拓扑结构中的一条路由路径,同时假设每个节点(节点1除外)都接收到两种请求流(如图6所示).需要说明的是,第2节所述的算法完整地比较了上游与下游的ST值,本文将此算法称作STboth机制,很容易得到两种简化的机制———STup和STdown机制:STup即仅与上游ST值比较,ST值仅需添加到数据包中,节点i决定缓存内容k当且仅当STk(i)STk(i+1),i=1,2,…,9,这里假设第10个节点决定缓存第9个节点所有不决定存的内容;Page8STdown即仅与下游ST值比较,ST值仅需添加到兴趣包中,节点i缓存内容k当且仅当STk(i)STk(i-1),i=2,3,…,10,这里假设第1个节点决定缓存第2个节点所有不决定存的内容.ALWAYS-LRU策略节点i获取内容k所需hopk(i)=λk(i[)(1-πk0(i))+跳数可表示为其中,(1-πk0(i))表示在节点i命中的概率;(1-πk0(j))∏j-1中、节点j命中的概率;10N∏Ni到节点N均未命中,则需要10N跳才能命中的概率.该假设的目的是将AS域间带宽的使用程度间接转化为跳数的多少,这样,若内容需要从其他域获取,则所需跳数剧增;反之,若节点获取内容的总跳数较大,则说明大部分内容请求在本AS域中未命中,需从其他AS域获取.从式(15)可以看出,本文只考虑了一个方向的路由路径,即从节点i往节点i+1路由的场景,没能更好地利用AS域中缓存的内容,特别是节点N,它接收到的请求只能命中节点N缓存的内容,其余的请求全未命中而被转发到其他AS域(或服务器)获取内容,从而大大地增加了总跳数.与式(15)类似,ST-LRU策略中节点i获取内容k所需跳数可表示为hopk(i)=λk(i[)(1-πk0(i))+其中,πk0(i)=μk(i)4.2仿真结果分析4.2.1ST-LRU与ALWAYS-LRU机制的比较图7给出了随缓存器大小在递增情况下几种缓存策略的性能比较,图7(a)为请求分别到达所有节点处的未命中率之和,图7(b)为各个节点取得内容所需的总跳数,图7(c)为在50个请求中(每个节点从用户处接收到5个请求),每种请求获取内容所需的总跳数.可以看出,STboth和STup策略均优于ALWAYS策略,STdown与ALWAYS策略近似,这是因为在缓存容量为[5,10,15,20,25,30,35,40,45,50]时,由平均逗留时间式(5)可知,几乎所有内容在本节点的ST值都大于下游节点的ST值,即STdown几乎所有内容都存,从而STdown与ALWAYS策略几乎一样.图7(b)中虽然第10个节点处出现STboth和STup策略所需跳数大于ALWAYS与STdown策略,但是由图7(c)可知,STboth和STup策略下所有节点对同一内容的请求所需总跳数是小于ALWAYS和STdown的.因为本文的仿真只考虑了往节点10方向路由的场景,没能更好地利用AS域中缓存的内容,特别是节点10,它只利用了自己缓存的内容,未命中的请求全都到其他AS域取.所以,节点10处STboth和STup策略所需跳数将大于ALWAYS与STdown策略所需跳数.图8则给出了10个节点缓存容量分别为[6,15]之间的整数随机排列时,4种策略在未命中率、总跳数和单位时间复制次数的比较.仿真结果显示,STboth,STup和STdown策略在这3方面的性能均优于传统的ALWAYS策略.Page9图8缓存容量为[13,9,14,6,15,8,12,10,7,11]4.2.2平均逗留时间计算公式的有效性分析本文的3.2节从原理上简要阐述了平均逗留时间式(5)的适用范围,本节将从未命中率和ST值取值范围的绝对差来定量分析式(5)的适用范围.取值范围的绝对差越小,则式(5)在该场景下越有效(因为式(5)是取ST值变化范围间的某值来近似平均逗留时间).其中,未命中率的变化范围绝对差可表示为ST值的变化范围绝对差可表示为μlowerλk1-μupper图9(a)中,当α>1时,前5个最流行的内容的未命中率的变化范围绝对差都在x=10下小于x=50的情况;当α<1时,除了第1个最流行的内容外,都有未命中率在x=10下小于x=50的情况.而在x相同的情况下,α<1的未命中率变化范围绝对差小于α>1.因此,由图9(a)我们得到α<1,x=10是最佳的参数取值.图9(b)也显示α<1,x=10是最佳的参数取值.该结论与3.2节的分析相符.5小结本文提出了一个新的基于逗留时间的缓存决定策略,该策略的目标是缓存决策时尽可能地选择逗留时间较长的内容,从而有效地减少了内容的复制次数,增加了域内命中次数和减少域间带宽使用.本策略充分地考虑了缓存器容量及内容的流行度,并适用于所有网络拓扑结构.然而,该策略也带来了一定的处理负担,即节点需要读取与更新比较兴趣包或数据包携带的平均逗留时间的信息.本文在系统实现时采用了在数据包或兴趣包中添加一个逐跳更新数的方法来达到了交互的目的.事实上,对于CCN这种分布式网络架构,节点间信息交互是很自然的,同时也可以根据实际需求合理控制节点之间的交互范围.在网络鲁棒性方面,由于逗留时间会随着网络状况的变化而变化,因此在动态变化的网络中,可以增加设计逗留时间的更新,按照不断更新的逗留时间来动态地选择所缓存的内容,从而保证网络的鲁棒性.本文的策略在缓存容量较小、请求分布较均匀的场景下更有效,后续我们将通过给每个内容计时的方法,估算内容的平均逗留时间,这样该策略就能够应用到任何场景下了.此外,我们将在后续CCN网内缓存机制的研究中,尝试考虑拓扑结构、带宽等因素,从而进一步提升缓存机制的效率和命中率.
