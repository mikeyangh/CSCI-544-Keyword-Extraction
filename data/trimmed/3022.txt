Page1多Agent系统中基于认知的信任框架研究王家窻冯志勇徐超许光全(天津大学计算机科学与技术学院天津300072)摘要基于认知角度提出了一种Agent间以预动(proactive)的方式建立信任的形式化框架.在框架中首先区分了代理与非代理情形下的信任并分别给出定义.从信任的定义出发,施信方(thetrustor)针对信任建立基于认知的推理过程,并根据推理需要主动向受信方请求信息.在获得所需信息后,考虑到交互信息的可靠性问题,施信方在认知推理的基础上进行关于可靠性的模糊推理,并决定是否建立信任.通过这个框架,Agent间可以在缺乏直接交互经验或者第三方证言的情况下,以预动的方式动态地建立信任,并且在信任建立的过程中,可以纳入复杂的上下文约束.同时,通过认知推理与模糊推理的结合,可以根据场景的需要采用不同的规则,给信任的建立带来更大的灵活性.关键词信任;多Agent系统;预动1引言在多Agent系统中,很多信任模型都是从博弈论的角度出发[1],基于Agent间的交互历史或第三方证言,根据预先定义的效用函数进行博弈,从而确定是信任在多Agent交互中扮演着重要角色.目前否建立信任.但是在一些临时系统[2]中(例如在一些Page2基于多Agent系统的虚拟组织中,参与的Agent往往是为了适应快速变化的环境、寻找最好的合作机会组织在一起,如现在出现的一些发布任务的网站,任务中国、猪八戒等),Agent之间可能缺乏交互历史,也不能从第三方那里获取彼此间的信息.此外,基于博弈论的模型往往采用预先定义的效用函数,难以反映Agent在信任建立过程中的动态上下文变化.这种情况下可以考虑施信方(thetrustor)与受信方(thetrustee)间通过直接交互过程来建立初步的信任.本文从认知的角度出发提出了一个施信方通过与受信方的预动交互建立信任的形式化框架.这个框架从认知的角度入手,将Agent视为具有内部状态、输入以及输出的系统.首先利用Agent的信念、意图给出了代理情形与非代理情形下的信任定义,施信方从信任定义出发建立关于信任的推理过程,并根据推理过程的需要向受信方Agent请求信息.考虑到信息的可靠性问题,施信方接收到信息后,在基于认知推理的基础上进行关于信息可靠性的模糊推理,最终根据信任的可靠性决定信任能否建立.这种针对信任建立的交互过程一方面通过认知推理反映了信任建立时动态变化的上下文,另一方面利用模糊推理使得信任建立更具灵活性.本文第2节介绍相关的研究,主要是在多Agent领域针对信任的研究;第3节主要介绍多Agent系统(Multi-AgentSystem,MAS)中预动的信任框架,包括基于认知的信任的定义以及基于控制论的信任建立的过程;第4节通过一个场景说明如何根据本文所提出的框架在Agent间建立信任;第5节总结本文,并对进一步的工作进行讨论.2相关研究在可计算的信任与信誉方面,研究人员提出了很多模型[1].Marsh的模型从博弈论的角度出发,根据信任关系可能带来的效用及其重要性权值以及直接交互的经历计算信任[1,3].ReGerT系统也是从博弈论的角度出发,考虑直接经验、第三方证言和社会结构三种因素,通过不同的模块组成一个完整的信任模型,同时用户可以决定采用或不采用特定的模块,为信任的建立带来灵活性[1,4].此外,Histos、Abdul-Rahman与Hailes、Yu与Singh等很多模型,一般均考虑从博弈论的角度出发,根据交互经验或第三方证言来计算信任[1],计算过程较为简单,方法容易利用.但是由于多采用预先定义的效用函数,在计算过程中难以体现Agent运行中上下文的动态变化,此外,在很多基于博弈论的模型、方法中[5-7],一般需要直接交互的经验以及第三方证言.但是对于处于临时系统[2]中的Agent,往往缺乏这些信息,采用如上的方法有一定困难.Castelfranchi与Falcone的模型则从认知的角度为信任提供了一个新的视角[1,8].他们的模型主要讨论了Agent间发生任务代理关系时的信任.他们将信任定义为一些相关的信念,比如关于能力、依赖性、倾向性的信念等.通过这样的定义,信任的建立可以通过基于认知逻辑的推理来实现,在推理的过程中可以纳入Agent运行的上下文约束,提高Agent间建立信任的灵活性.本文所采用的信任的定义主要基于他们的模型.但是,他们的模型在信任建立的过程方面依然借助于博弈论的方法,此外他们没有对非任务代理情形下的信任作进一步讨论.从认知的角度来看,Agent拥有其自身的心智部件(mentalattitudes),如信念、意图等[9-10].在MAS中,通信在Agent间的协作中发挥着重要作用.Agent接收消息,而后更新自身的信念以及意图等,并发出信息作为输出.这样一个过程可以通过控制论中的状态空间方程来描述.此外,对于Agent间的行为可以通过采用预动的方式来实现,以提升Agent间协作的效率.如SharedPlans和JointIn-tention中关于Agent帮助行为的研究[11-14]以及Fan等关于Agent间进行消息预动传递的研究等[15].那么在信任建立的过程中,特别是在一些临时系统[2]中,Agent在缺乏与其它Agent的交互经历以及第三方证言的情况下,施信方与受信方就信任的建立展开预动的通信,可以有效地促进Agent间信任的建立.3Agent间预动的信任建立框架3.1框架中信任的定义通过相关工作的介绍可以看出,针对基于博弈论的方式建立信任所存在的问题,Castelfranchi与Falcone提出的基于认知的信任模型提供了一种解决办法.本文提出的框架也采用基于认知的信任定义,所采用的形式化表达基于Fan等在相关工作中[15]采用的意图语义和相关的公理、假设.本文涉及的表达式如下:信念算子Bel(相信)与MB(双方均相信)(参见文献[9-10]);意图算子IntTo(意图Page3于执行,参见文献[9-10,12])、IntTh(意图于命题成立,参见文献[9-10,12])、PotIntTo(潜在地意图于执行,参见文献[9-10,12])、PotIntTh(潜在地意图于命题成立,参见文献[9-10,12]);动作At-tempt、Inform、Request(试图、通知,请求等,参见文献[15]);表达式CONF(命题、动作间的冲突,参见文献[15])、constr(C)(上下文约束C中的要素集合,参见文献[15])、Hold(p,t)(客观成立,参见文献[15])、CBA(有执行动作的能力,参见文献[15])、recipeX(α)(AgentX用以执行α的recipe的集合,参见文献[15]).prop(X)表示与AgentX的信念、意图有关的命题表达式的集合.3.1.1代理关系中的信任首先讨论关于代理过程中的信任,即施信方将某些动作代理给受信方的过程中的信任关系.在Castelfranchi等的工作中提到信任是代理行为在精神(心智)上的对应物[8].本文对信任的定义的思想来源于他们给出的信任定义.在信任的定义中首先应该包括施信方与受信方.其次需要包括双方就什么问题建立信任.Castelfranchi等认为代理关系是指,施信方Agent需要或者希望受信方Agent能够将特定的行为纳入到自己的规划当中[8].因而在任务代理关系中的信任需要包括施信方希望受信方产生的关于在恰当时间执行代理动作的意图.此外还包括信任所处的特定上下文以及信任存在的时间.综合这些因素,关于代理过程中存在的信任通过如下算子表达:Trust(X,Y,IntTo(Y,g,tInt,tg,Cg),CTrust,t).其中X、Y分别代表信任关系中的施信方与受信方,g是X代理给Y的动作,IntTo(Y,g,tInt,tg,Cg)表明在X对于Y的信任在于:在动作应该执行的时刻tg之前的时刻tInt,Y形成执行关于g的意图.CTrust是X对于Y的信任存在的上下文约束,这些约束来自于关于信任的推理过程中涉及到的信念、意图的一些约束.t是信任成立的时刻.下面的讨论中,以X代表施信方Agent,Y代表受信方Agent.下面给出信任的语义.Castelfranchi等提出的信任定义主要是用心智部件表达了3个方面的内容:关于Y执行代理动作的能力、倾向以及X对于Y的依赖性.这里采用如下的定义给出信任的语义定义.定义1.X建立关于Y“能够意图于执行特定动作”的信任,是指X相信在恰当的时刻,Y要形成关于特定动作的潜在意图,X也要相信自己意图于让“Y能够意图于执行特定动作”成立,此外,X还要相信Y有能够用于执行特定动作的具体步骤:Trust(X,Y,IntTo(Y,g,tInt,tg,Cg),CTrust,t)=Bel(X,tInt<tIntPotIntTo(Y,g,tInt,tg,Cg∧C),t)∧Bel(X,tInt<tIntIntTh(X,IntTo(Y,g,tInt,tg,Cg),tInt,Bel(X,Rg∈recipeY(g)(CBA(Y,g,Rg,tg,Cg)∧C=Z≠Yt<tgIntTh(X,IntTo(Z,g,tInt,tg,Cg),记:BelTrust_Int_Th(t)=Bel(X,tInt<tIntIntTh(X,IntTo(Y,BelTrust_Int_To(t)=Bel(X,tInt<tIntPotIntTo(Y,g,tInt,BelTrust_CBA(t)=Bel(X,Rg∈recipeY(g)(CBA(Y,g,Rg,信任的定义主要是通过Agent的3个信念来表达的.信念BelTrust_Int_To(t)是说X相信在tInt之前的某个时刻tInt,Y能够形成关于在tg时刻在上下文约束Cg∧C下执行g的潜在意图.C是说在tg前的任意时刻t,除了Y以外,X不会意图于让其它Agent在tg时刻完成动作g.信念BelTrust_Int_Th(t)是说X相信在tg前的某个时刻tInt,X意图于在tInt时刻使得Y产生执行g的意图.信念BelTrust_CBA(t)则反映了X对于Y完成g的能力的信念.即X相信Y有能够用来完成动作g的相关的方法,并且对于这些方法中的动作,Y能够在恰当的时候形成关于这些动作的意图.关于信任如何在Agent交互中发挥作用需要进一步讨论.根据SharedPlan理论以及Fan等关于预动地传递信息的讨论,当一方AgentX要求另一AgentY执行某个动作β,或将自己规划中的某个动作β交给Y完成,在这个过程中,X应该意图于让Y意图于执行β.假定X想要完成动作α,Rα是X用以完成α的某个recipe,即Rα∈recipeX(α).而动作β∈Rα,即β是Rα中的一个动作,此时X因为某种原因希望β由Y来完成.PotIntTh(X,IntTo(Y,β,tInt,tβ,Cβ),t,tInt,Cβ)代表X在t时刻有潜在的意图,让Y在tInt时刻意图于在tβ时刻执行β.考虑到Agent往往代表不同的利益实体,因而X意图于让Y执行β,Y可能出于利益的考虑使得X的意图失败.这时就需要X通过信任,特别是信任涉及的上下文约束来约束自己的选择.也就是说,X希望通Page4过Rα来完成α,那么对于β不仅要有意图PotIntTh(X,IntTo(Y,β,tInt,tβ,Cβ),t,tInt,Cβ),还需要建立起关于Y执行β的信任,才能将潜在意图转化为意图(PotIntTh转化为IntTh).这时信任应该纳入IntTh(X,IntTo(Y,β,tInt,tβ,Cβ),t,tInt,Cβ)的上下文约束,保证在X意图成立的时候,信任也是成立的.3.1.2非代理关系中的信任除了代理关系中的信任,本文认为在Agent协作中某些非代理情形下也需要信任来约束Agent的决策.考虑在协作的过程中,其中一个AgentX的某个动作α可能会受到另一个AgentY的某个动作g的干扰而不能顺利完成.在他们协作的过程中,出于种种原因X需要完成α,并且出于协作的考虑,X需要建立关于Y不会执行g的信任,在此情况下X才选择执行α.此时X是施信方,Y是受信方.这里称这种情况为非代理情形下的信任.这种情形与代理过程中信任的不同在于:代理过程中X相信Y有能力执行g并且有意图执行g时X信任Y,而非代理情形下X相信Y有能力执行g的情况下Y不会执行g时X信任Y.这样,非代理情形下的信任通过如下算子来表达:Trust(X,Y,tInt其中X、Y分别代表信任关系中的施信方与受信方,g是导致Y与X发生冲突的动作,tInt<tgIntTo(Y,g,tInt,tg,Cg)表明在X对于Y的信任在于:在动作g应该执行时刻tg前的任意时刻tInt,Y不会形成执行关于g的意图.CTrust是X对于Y的信任存在的上下文约束.t是信任存在的时刻.这里采用如下的定义给出信任的语义.定义2.X建立关于Y“不会意图于执行特定动作”的信任,是指X相信存在某个执行该特定动作的具体步骤,能让Y用来执行特定动作,但是X相信对于任何Y用来执行特定动作的具体步骤,都有某些步骤Y不会形成执行这些步骤的意图.Trust(X,Y,tInttgIntTo(Y,g,tInt,tg,Cg),CTrust,t)=Bel(X,Rg∈recipeY(g)CBA(Y,g,Rg,tg,Cg),t)∧Bel(X,Rg∈recipeY(g)(CBA(Y,g,Rg,tg,Cg)→α∈Rg,ttαIntTo(Y,α,t,tα,Cα)),t).这里记BelTrust_CBA_N(t)=Bel(X,Rg∈recipeY(g)CBA(Y,g,BelTrust_Int_N(t)=Bel(X,Rg∈recipeY(g)(CBA(Y,g,Rg,非代理情形下的信任通过信念BelTrust_Int_N(t)和BelTrust_CBA_N(t)来表达.BelTrust_CBA_N(t)是说X相信Y有一些用来执行g的recipe,能够在tg时刻用来执行g.BelTrust_Int_N(t)信念是说对于任何能够用来在tg时刻执行g的recipeRg,其中会存在某些动作α∈Rg,在α应该执行的tα时刻,Y不会形成关于α的意图,从而阻止g的执行.首先需要说明的是,在非代理情形下的信任中,施信方因该相信受信方有能力对自己的目标造成威胁,因而需要在信任的定义中包括信念BelTrust_CBA_N(t).如果施信方X认为受信方没有能力发起能够威胁自己的行动,那么X与Y之间没有必要就g建立信任.其次是关于非代理情形下的信任如何在Agent交互中发挥作用.考虑如下情形:Bel(X,tInttgCONF(IntTx(X,prop,t,tprop,CpropIntTo(Y,g,tInt,tg,Cg),tprop,tg,Cprop,Cg),t),t<t,t<tg.其中IntTx代表IntTo或者IntTh.上面的信念是说,在时刻t,X相信X在t时刻意图于在时刻tprop执行动作prop,或者在t时刻意图于命题prop在tprop时刻成立,会与Y在tg前任意时刻意图于在tg时刻执行g相冲突.在这种情况下,X想要形成关于prop的意图,应该将Trust(X,Y,tInttgIntTo(Y,g,tInt,tg,Cg),CTrust,t)纳入到关于prop的意图或潜在意图的上下文约束当中,特别是在X、Y之间存在协作,但是各自又有不同利益的情况下.3.2基于控制论的信任建立过程上下文约束在信任中发挥着重要的作用.在文献[16]中谈到在决定是否信任的过程中,是伴随着不确定的行为的.因为如果双方行为都确定的情况下,也就不需要所谓信任的约束了.随着上下文的变化,这些不确定的行为在特定的上下文下就会给信任带来影响,因而这些纳入到信任上下文当中的因素真正反映了Agent在建立信任过程中经历的动态变化.上面所给出的信任定义考虑到了这样的上下文约束问题.以代理关系中的信任为例,Agent通过推理能够得到信任的相关信念,假定有如下规则:p1∧p2∧…∧pi∧…∧pn→BelTrust_Int_To(t),p1∧p2∧…∧pi∧…∧pn→BelTrust_Int_Th(t),p1∧p2∧…∧pi∧…∧pn→BelTrust_CBA(t).其中pi(1in)与pi(1in)以及pi(1in)是Agent的命题.当Agent知道pi、pi以及pi的Page5真值后,就能得出相关的信念从而建立信任.此外鉴于伴随信任出现的不确定性,根据Agent运行环境的变化,可能存在着某些规则影响pi、pi、pi的真值,比如存在如下规则:pi1∧pi2∧…∧pij∧…∧pik→qi并且此时Bel(X,CONF(pi,qi,tpi,tqi,Cpi,Cqi),t)(施信方X在t时刻认为pi与命题qi存在冲突);或者pi1∧pi2∧…∧pij∧…∧pik→pi.当Agent在建立信任的过程中如上规则在特定的上下文下被满足的时候,可能导致信念BelTrust_Int_To(t)(或BelTrust_Int_Th(t)、BelTrust_CBA(t))不成立.这些规则在信任建立中发挥约束作用.鉴于信任建立过程中存在不确定的因素,因而不论在上面与BelTrust_Int_To(t)、BelTrust_Int_Th(t)和BelTrust_CBA(t)相关的规则,还是发挥约束作用的规则,往往存在一些命题,Agent在建立信任的时候还不了解它们的真值,这些命题往往与受信方的信念、意图相关,表示受信方当前的状态.此时施信方Agent想要建立信任,就应该采取预动的方式,从受信方以及其它Agent那里寻求这些信息,特别是在缺乏与受信方的交互历史或第三方证言的情况下.这里采用控制论当中状态空间方程来说明这样一个预动的信任建立过程.非代理情形下的信任建立的过程与代理关系下的过程类似,这里主要以代理过程中信任为例来说明信任的建立过程.下的状态空间方程来表达.施信方与受信方间建立信任的过程可以通过如这里下标中的trustor与trustee分别代表施信方与受信方两个Agent.X(t)代表着Agent的内部状态,是一组Agent心智部件的集合.按照状态空间方程的定义,将U(t)与Y(t)则分别称为输入、输出变量的集合.这里输入变量Utrustor(t)是与Y的信念有关的表达式prop构成的集合,此时X没有“Y关于prop信念”的信念.为了形成针对Y的信任,X需要“Y关于prop信念”作为输入.而输出变量Xtrustor(t+1)则是X希望告知Y的、表达X自身的某些信念方程1.对于施信方(trustor)的Agent:Xtrustor(t+1)=F(Xtrustor(t),Utrustor(t),t),Ytrustor(t)=G(Xtrustor(t),Utrustor(t),t).Xtrustee(t+1)=F(Xtrustee(t),Ytrustor(t),t),Ytrustee(t)=G(Xtrustee(t),Ytrustor(t),t),Utrustor(t+1)Ytrustee(t).对于受信方(trustee)的Agent:的表达式,在与Y的交互中发送给Y,表达自己的意图、信念.由于X需要Y对于输入变量所代表的信念进行回复,因而输入变量也要发送给Y,在后面的讨论中假定Y(t)集合中包含有U(t),这里输入、输出变量采用二元组(prop,true_value)的形式,真值包括unknown(针对输入变量)、true和false(针对输出变量),具体定义如下:假定X为施信方,Y为受信方X的输入变量var定义为如下集合中的元素{(propi,true_valuei)|1in,propi∈prop(X),true_value=unknown}true_valuei=unknown,iffBel(X,Bel(Y,propi,t),t)=falseandBel(X,Bel(Y,propi,t),t)=false.X的输出变量var定义为如下集合中的元素{(propi,true_valuei)|1in,propi∈prop(X),true_value=true|false}true_valuei=true,iffBel(X,propi,t)=true,true_valuei=false,iffBel(X,propi,t)=true.其中propi是符合意图语义[9]的命题.开始,施信方在构建关于信任的推理的过程中,找出那些与受信方有关并且自己不能确定其真值的命题,将它们放入到Utrustor(t)中作为输入变量,同时将其包含在输出变量Ytrustor(t)中发送给受信方来寻求答案.此外施信方还可以找出可能有助于受信方得出关于输入变量的真值的信念与意图,将它们放在Ytrustor(t)中发送给受信方.受信方接受到Ytrustor(t)后,首先根据施信方发送过来的内容更新自己的内部状态,并且通过推理得出输入变量中命题的真值,放到输出变量Ytrustee(t)发送回施信方,施信方再更新自身的内部状态,完成对于信任的推理并建立信任.这里,t+1表示状态或变量真值被更新后的时间.Utrustor(t+1)Ytrustee(t)是说在施信方trustor所接收到的输入变量Ytrustee(t)中,应该包括施信方所要求的输入变量Utrustor(t)被受信方所更新后的值Utrustor(t+1).F、G、F、G分别代表X与Y为了建立信任进行的推理或计算过程.F:对于施信方AgentX,过程F表示根据内部状态Xtrustor(t)集合建立推理关于建立信任的推理过程,确定输入变量集合Utrustor(t)的成员,并且在接收到受信方AgentY发送过来的输入变量后,将内部状态Xtrustor(t)更新为Xtrustor(t+1).G:对于X,过程G根据内部状态和输入变量Utrustor(t)确定输出变量Ytrustor(t),这里输出变量包括输入变量以及根据场景需要X认为需要告知YPage6的信息.F、G的作用与F和G类似,这里主要讨论施信方针对受信方信任的建立,因而不对F、G表示的受信方的行为与推理过程进行讨论,假定受信方Y能够按照施信方X的要求给出相应信息,可以通过基于认知的推理,也可基于博弈的方式来计算.3.3信任建立过程的描述根据上面提到的步骤,首先要考虑的是建立信任的通信过程的启动.通过上一节的介绍可以看出,信任在Agent协作和交互的过程中,对于意图和行为的选择发挥着约束作用.对于代理情形下的信任而言,如果施信方Agent有潜在的意图让受信方Agent代理完成特定的动作,在这种潜在意图转化为关于代理的意图之前,应该将信任纳入到潜在意图的上下文约束当中,因此这里给出假定.假定1(代理情形).在代理情形下,X有让“Y意图执行特定动作”成立的潜在意图,那么X意图于让针对“Y意图执行特定动作”的信任成立:PotIntTh(X,IntTo(Y,g,tPot.Int.Th,tg,Cg),t,tPot.Int.Th,tTrust<tgIntTh(X,Trust(X,Y,IntTo(Y,g,tInt,tg,其中tPot.Int.Th<tg且t<tTrust<tg.假定2(非代理情形).在非代理情形下,X有执行某个动作或让某个表达式成立的潜在意图,并且X相信另一个动作的执行与X要执行的动作或希望成立的表达式有冲突,如果X相信Y有执行另一个动作的意图,那么X意图于让针对“Y不会意图执行特定动作”的信任成立.PotIntTx(X,α,t,tα,Cα)∧Bel(X,CONF(α,g,tα,tg,Cα,CTrust,tTrust),t,tTrust,CInt.Th)Bel(X,t<tαPotIntTx(Y,g,t,tg,Cg),t)→tTrust<tgIntTh(X,Trust(X,Y,tInttgIntTo(Y,g,tInt,tg,Cg),对于代理的情形,这个假定是说在当前时刻t,施信方AgentX有潜在意图想要受信方AgentY在时刻tPot.Int.Th形成关于在tg执行特定的行为g的意图,那么tg前的特定时刻tTrust,X应该产生一个关于在X和Y之间建立针对所代理动作g的意图.对于非代理情形,这个假定是说在当前时刻t,X有关于α的意图(意图于在时刻tα执行α或让α成立).此时X又相信在tα之前的某个时刻tY会形成关于g的意图(意图于在时刻tg执行g或让g成立),并且X相信α与g之间存在冲突,那么X应该产生一个关于g的非代理情形下信任成立的意图.其中tTrust根据具体需要而定.在当前时刻t,施信方AgentX形成关于信任的意图后,按照前面介绍的基于控制论状态空间的框架描述,就需要建立针对Agent的推理过程并与受信方Agent交互.规则1.当施信方AgentX意图于让针对于Y的代理或非代理情形下的信任成立,那么X形成关于执行TrustAct动作的潜在意图.其中动作TrustAct用于建立围绕施信方于受信方交互的推理过程.代理情形IntTh(X,Trust(X,Y,IntTo(Y,g,tInt,tg,Cg),CTrust,tTrust),t,tTrust,CInt.Th)→PotIntTo(X,TrustAct(X,Y,g,inputVar,outputVar,t,tRes,tTrust),t,tTrust_Act,CTrust∧CInt.Th)非代理情形IntTh(X,Trust(X,Y,tInttgIntTo(Y,g,tInt,tg,Cg),CTrust,tTrust),t,tTrust,CInt.Th)→PotIntTo(X,TrustAct(X,Y,inputVar,outputVar,t,tRes,tTrust,g),t,tTrust_Act,CTrust∧CInt.Th),其中t<tTrust_Act<tRes<tTrust.规则1是说当施信方X意图于在他与受信方Y之间建立信任(代理情形和非代理情形下)之后,X随之形成一个在时刻tTrust_Act执行动作TrustAct的意图.TrustAct动作负责建立关于信任的推理过程,查找输入输出变量,并请求Y对与输入变量中命题的真值进行回答,其定义如下.定义3.outputVar,g,t,tTrust),tRes,tTrust,CTrustRes)TrustAct(X,Y,g,inputVar,outputVar,t,tRes,tTrust)=((t<tRes)?;ConstructTrust(Y,inputVar,outputVar,g,t))?;Request(X,Y,ε,TrustResponse(Y,X,inputVar,X在t时刻执行动作TrustAct,要求X在时刻t之前完成关于信任的状态空间构建,包括输入输出变量的查找,查找所得到的输入输出变量分别放在input-Var与outputVar中.这里inputVar相当于状态空间中的Utrustor(t),而outputVar相当于Ytrustor(t).在状态空间构建成功之后在时刻tResX要求Y在tTrust时刻之前执行TrustResponse动作,这个动作要求Y根据接收到的输入变量inputVar,得到X所要求的输入变量的值并放在outputVar中,然后返回给X.首先来看与构建状态空间相关的Construct-Trust动作.这里将ConstructTrust作为原子动作.以代理过程中建立信任为例.由于X形成关于Page7Trust(X,Y,IntTo(Y,g,tInt,tg,Cg),CTrust,tTrust)的意图,根据Trust的定义1,X要通过规则得到信念BelTrust_Int_To(t)、BelTrust_Int_Th(t)和BelTrust_CBA(t)以及相应的上下文约束.通过这些规则,可以构建一个树状推理过程.这里假定Agent采用的规则均采用Horn子句的形式.在树形推理结构中根节点是信任对应的表达式,其子节点是信任定义中的信念.每个节点对应一个命题prop,父节点对应的命题propi与子节点对应的命题propij之间有如下关系:propi1∧propi2∧…∧propij∧…∧propin→propi.对于propij所对应的子节点同样可以根据规则propij1∧propij2∧…∧propijn→propij进一步扩展,不断递归这个过程直至没有新的规则可以加入到树状结构中.这样就建立起一个关于信任的推理过程.建立Trust(X,Y,IntTo(Y,g,tInt,tg,Cg),CTrust,tTrust)的过程中可能对应多个树状推理结构.这个过程的建立可以考虑采用反向链接算法来实现.但是前面谈到过,信任伴随着不确定的因素.在针对上面所建立的树状推理结构中,往往会因为上下文的变化,影响到某些节点上所对应的命题propi的真值.针对propi,在X的推理规则中可能存在如下规则:propi1∧propi2∧…∧propij∧…∧图1包含约束规则的信任推理过程对于存在约束的节点,通过约束得到的真值可能与通过实线连接对应的规则得到的真值发生冲突,此时Agent需要进行一致化(reconciliation)的propin∧propi→⊥,或者propi1∧propi2∧…∧propij∧…∧propin→propi,而此时X相信CONF(propi,propi,ti,ti,Ci,Ci).这里元谓词CONF[15]意味着在时刻ti成立的propi与时刻ti成立的propi存在冲突.这些因素的出现会导致关于信任的推理不成立.因而这些因素可以看作是对与各个节点所对应命题的上下文约束,进而可以看作是对于信任是否成立的上下文约束.在针对信任的推理过程中纳入更多这样的约束,可以使得信任的建立更加可靠.发挥约束作用的规则在这里称为约束性规则.因而,需要对上面介绍的树状推理过程做进一步扩充.首先,按照如上过程建立树状推理结构,而后让树状结构中对应的各个节点均对应一个二元组〈prop,Cprop〉,其中prop是节点对应的命题,Cprop则是对于prop成立与否的一些约束:prop1∧prop2∧…∧propi∧…∧propn∈Cprop,ifprop1∧prop2∧…∧propi∧…∧propn∧prop→⊥or(prop1∧prop2∧…∧propj∧…∧propn→prop,andBel(X,CONF(prop,prop,t,t,C,C),t).对于纳入到Cprop中的prop1∧prop2∧…∧propi∧…∧propn,每个命题propi通过虚线与prop联系起来,最终构成如图1所示的推理过程.过程,即定义规则决定何种情况下选择何种真值.比如施信方偏向于冒险,则选择节点对应命题为真的情形,如果偏向保守,则倾向于选择对应命题为假的Page8情形.通过上面的过程,ConstructTrust动作完成了关于信任Trust(X,Y,IntTo(Y,g,tInt,tg,Cg),CTrust,tTrust)的推理过程的构建,这个推理过程即基于控制论的信任框架中的状态空间.此时,对于树状推理结构中的每个命题,X均了解其真值,那么是否与Y建立信任就可以通过推理得出.然而,很多情况下由于信任中涉及的不确定性因素,推理中往往存在一些命题,特别是关于受信方Y的一些情况,X不了解其真值(不知道真值,或怀疑与Y的信念不一致,即X持有某些信念,这些信念与X相信“Y持有某信念”有冲突,故而X没有“Y持有某信念”的信念.“Y持有某信念”可以考虑作为输入变量,真值为unknown),需要从受信方那里收集情况,根据收集到的情况完成针对信任的推理.这些X所不了解真值的命题可以考虑作为输入变量.此外X在推理过程中也可以选择一些X相信有助于Y得到输入变量相关信息的命题作为输出变量.这里需要假定的是,所确定的输出变量是X认为Y能够给予回复的并且X认为有必要向Y需求答案的命题.在X的输入、输出变量确定完成,并将其放在TrustAct中指定的inputVar、outputVar中后(out-putVar包含inputVar,因为要发送给Y),Con-structTrust完成了主要的工作.而后X将请求Y执行TrustResponse动作,随着请求Y接受到output-Var作为自己的输入inputVar,其具体定义如下.TrustResponse(Y,X,inputVar,outputVar,g,t,tTrust)=var=(prop,true_value)∈outputVar,Inform(Y,X,ε,Bel(Y,prop,t),t,tTrust),ifftrue_value=trueInform(Y,X,ε,Bel(Y,prop,t),t,tTrust),ifftrue_value=falseInform(Y,X,ε,Bel(Y,prop,t)∧Bel(Y,prop,t),t,tTrust),ifftrue_value=unkonwn.TrustResponse的作用在于:Y得到的关于输入变量集合inputVar后,对其中包含的X请求的输入变量在时刻tTrust向X作出回复.在Y接受到对应的请求后,形成有关于Trus-tResponse的意图,比如:定义4.PotIntto(Y,α,t,texeR,CTrustRes),其中t<texeR<tRes<tTrust.其中TrustResponse动作作为动作α的一部分.此外α还负责获得输入变量中各个命题的真值,并将Bel(Y,tpast<tIntTh(X,IntTo(Y,TrustResponse,t,tRes,CTrustRes),tpast,t,CTrustRes),t)→这些真值放在outputVar中.这些真值可以是通过查找Y自身的信念或者通过推理得出.当然,Y可以选择忽视X的请求,但是这样的选择会影响到X对于Y信任的建立.Y在接受到X发送过来的输出变量后,需要根据输出变量中表达的X的信念等来更新自己的信念、意图等.此外,在Y发送回输入变量相关的真值后,X首先更新自己的信念、意图等等.在双方更新自己信念的过程中会涉及到信念修正(Beliefrevi-sion)的问题.这里可以采用一些已经提出的信念修正算法[17-18].由于信念修正是一个复杂的过程,将在以后的工作中进行讨论,这里假定双方对于接受到的信念直接转化为自身的信念.3.4模糊推理与认知推理结合的信任建立在X接收到Y发送过来的输入变量,并更新自身的状态后,X可以根据输入变量的相关信息,完成图1所示的关于信任的推理过程,最终决定是否建立信任.在X完成关于信任推理的过程中,完全采用真假二值来确定信任是否成立可能会缺乏一定的灵活性.例如假定在代理情形下,X有如下两条规则:prop1∧prop2∧…∧propn→BelTrust_Int(t),prop1∧prop2∧…∧propn→BelTrust_Int(t).前一条规则的前提比较难以满足,但是得出的结论“更可靠”,后一条前提相对容易满足,在前一条规则无法满足的情况下,可以考虑后一条规则,但是得出关于BelTrust_Int(t)结论“不如前一条规则可靠”.在基于博弈论的信任建立过程中往往存在这样有一定模糊性的描述,而完全采用二值逻辑的推理缺乏区分这些模糊表达的能力.而基于博弈论的方式通过数值表达的方式则相对灵活.因而在信任推理树的基础上,这里提出的信任建立过程中也引入数值方式表示各个表达式的可靠性.这种情况下可以考虑在如图1所示的基于认知的推理过程的基础上,结合模糊推理来完成信任的建立.由于要在基于认知的信任建立过程的基础上结合模糊推理的过程,两种推理的过程之间要有一定相似性,即信任推理树中的规则与模糊推理规则之间有一定对应关系.这里采用文献[19]中利用模糊推理建立信任时采用的模糊推理过程.首先定义如下语言变量(x,U,W(X),G,M)来描述规则以及表达式的可靠性:其中x代表模糊变量的名字;U=[0,5],是模糊变量的可靠性取值范围,采取已有的方法,可靠性通过0~5之间的实数值来表示;Page9W(X)={weak_reliable,reliable,strong_reliable}是一组术语的集合,术语用以表达规则或表达式的可靠性,weak_reliable用来表达“不太可靠”,relia-ble表示“可靠”,而strong_reliable表示“非常可靠”;G是为x生成语言值的语法规则的集合,这些规则取决于信任推理树中表达的规则;M是x的语义规则,将可靠性取值与语言值对应起来,通过如下的隶属度函数表达,根据隶属度函数计算得到的模糊值反映可靠性在多大程度上属于“不太可靠”等语言值:M(weak_reliable)=[weak_reliable],[weak_reliable](u)=-1M(reliable)=[reliable],[reliable](u)=M(strong_reliable)=[strong_reliable],[strong_reliable](u)=在X接收到Y所发送过来的输入变量后,对每个输入变量赋予一个可靠性值.按照语言变量的定义,可靠性值处于0~5之间,数值越大表明可靠性越高.这个赋值受到很多因素的影响(例如来自于具体场景中X对上下文的观察和他可能持有的经验),这时这些可靠性值就可以结合特定的博弈论模型来计算.具体的结合方式将在今后的研究中逐步加入.模糊推理规则都是基于信任推理树中基于认知的推理规则.首先定义一些模糊规则中需要的表达.针对一些输入变量:〈Bel(Y,prop,t),weak_reliable〉表示输入变量〈prop,true〉“不太可靠”;〈Bel(Y,prop,t),weak_reliable〉表示输入变量〈prop,false〉“不太可靠”;〈Bel(Y,prop,t)∧Bel(Y,prop,t),weak_reliable〉表示〈prop,unknown〉“不太可靠”.输入变量“可靠”与“非常可靠”有类似的表达.为了表达方便起见,这里用〈prop,weak_reliable〉表示“prop为真”的可靠性通过语言值weak_relia-ble来描述(“不太可靠”),〈prop,weak_reliable〉表示“prop为真”的可靠性通过语言值weak_reliable来描述.reliable与weak_reliable的情形类似.通过这些表示,可以对信任推理树中所包含的规则进行扩展.以前面提到的规则r1:prop1∧prop2∧…∧propn→BelTrust_Int_Th(t)为例,在这个规则的基础上可以定义如下模糊规则:r1_f1:〈prop1,strong_reliable〉and〈prop2,strong_relia-ble〉and…and〈propn,strong_reliable〉then〈BelTrust_Int(t),strong_reliable〉.模糊规则r1_f1是说对于规则r1而言,如果前提中每个表达式propi(1in)为真的可靠性都可以用strong_reliable(“非常可靠”)来描述,那么结论BelTrust_Int_Th(t)为真也可以用strong_reliable来描述.通过模糊规则的定义,不但将输入变量的可靠性引入到信任建立过程,也考虑到了信任建立中存在的模糊因素.在前面的讨论中,规则r1与r2能够得到相同的结论,但是r1得到的结论“更加可靠”.这种区别可以通过模糊规则的定义来体现.对于规则r2可以定义如下模糊规则:r2_f1:〈prop1,strong_reliable〉and〈prop2,strong_reliable〉and…and〈propm,strong_reliable〉then〈BelTrust_Int(t),reliable〉.模糊规则r2_f1是说如果前提中每个表达式propi(1im)为真的可靠性都可以用strong_relaible(“非常可靠”)来描述,那么结论BelTrust_Int_Th(t)为真可以用reliable(“可靠”)来描述.这样就可以对规则r1与r2的结果加以区分.通过这种方法,信任推理树中的每条规则被扩展为一组模糊规则,从推理树中的叶节点开始,通过模糊规则推理出父节点的可靠性值,通过自底向上的方式,在信任推理树的基础上进行模糊推理,模糊推理的过程如图2所示.其中,叶节点包括输入变量对应的表达式以及约束性规则的前提中的相关表达式.在图2中,对于形如prop1∧prop2∧…∧propn→prop,模糊化的过程是指以propi(1in)的可靠值作为输入,通过隶属度函数将可靠性值映射为模糊值,这些语言值和相应的一组模糊规则一起,在模糊推理引擎中进行推理,获得描述prop可靠性的模糊值.而后prop的可靠性值还要用于进一步的模糊推理,因而需要将描述prop可靠性的模糊值再映射为描述prop可靠性值.从信任推理树的叶节点开始,对于树中的节点,都可以通过其子节点根据规则进行的模糊推理获得一个描述其可靠性的值,而这个值被用来进行针对该节点的父节点的模Page10糊推理,通过这样自底向上的方式,最终能够得到关于信任的可靠性值.X为信任能否成立设定一个阈图2针对信任推理树中一条规则的模糊推理的过程4场景分析本节中通过一个场景的分析来说明如何利用前一节所提出的框架在Agent间建立信任.假定某家机构X提供某项科研课题等待申请,有一家公司Y希望能够申请对此课题的研究.只有当X信任Y能够按照X期望的情况来完成该课题,X才会同意将课题交给Y去研究.而此时在X不熟悉Y,而且很难获得Y的一些相关信息的情况下(比如Y是刚刚创业的公司),那么X与Y如何建立信任?一般来说,Y需要就X所提出的一些问题进行答辩.此时,X根据建立trust的需要主动提出问题要求Y进行回答.首先对场景做一个详细的说明.X所要达成的目标是“按照合同书的要求完成各项内容”,这里用g表示.此时X要将课题交给提出申请的Y,X对Y要建立如下所示的信任:Trust(X,Y,IntTo(Y,g,tInt,tg,Cg),CTrust,t),即X信任Y会在时刻tInt意图于在tg时刻按照合同完成项目.此时假定在上下文约束CTrust中包含有两类约束:有一个比较完善的实施方案,有一个合理的人员配置.关于实施方案的约束包括如下内容:对于目标g,Prob(g)={prob1,prob2,…,probn}是所要解决的问题的集合,而Tech(g)={(prob1,tech1),(prob1,tech2),…,(probn,techn)}是Y计划用来解决Prob中的问题的技术的集合.此时上下文约束中可能需要考虑如下的一些约束:对于probiY打算采用什么样的techi来解决?techi是已有技术还是针对probi提出来的新技术?如果是已有技术,那么是在什么文献中被提出来的,最初用于解决什么问题,在解决probi时需要有什么改动?如果是针对probi值,就可以根据信任的可靠性值决定是否信任Y.根据这些上下文约束的条件,假定X有如下提出来的,是否存在类似的技术,他们之间有什么差别?如果发现techi不能解决probi,有什么备选方案?在人员安排的约束方面需要考虑的约束有:参与人员的数量以及基本信息,包括研究领域、发表的论文、以前参与的项目等等,此外还有参与人员的变动,比如退休等如何影响人事安排?对于所采用的技术techi,参与人员的熟悉情况如何等.假定X面对Y的申请,有潜在的意图让Y承接项目并达成目标g.根据假定1以及规则1,在X有意让Y完成项目的时候,X需要建立对于Y的信任,并由此形成关于TrustAct的意图,最终在推理得出信任成立的前提下,才能将g代理给Y.首先X需要建立针对信任的推理过程,并确定输入、输出变量.规则:r_X1:Bel(X,ProperDoc(Y,g),t)→Bel(X,tInt<tIntPotIntTo(Y,g,tInt,tg,Cg∧C),t),C=Z≠Yt<tgIntTh(X,IntTo(Z,g,tInt,tg,Cg),规则r_X1是说在当前时刻t,如果X相信Y为达成目标g准备了完善的文档(项目申请书等),那么X相信在上下文约束Cg与C下Y在tInt之前的某个时刻形成关于目标g的潜在意图.谓词ProperDoc(Y,g)代表Y为目标g准备了完善的文档.C是说除了Y以外,X不会让其它Agent来代理完成目标g.其它规则与涉及的谓词不再详细说明,参见表1与表2.其中r_X4、r_X5、r_X7起着约束性规则的作用.通过这些规则可以构建关于信任的推理过程,首先,根据规则r_X1、r_X2、r_X3、r_X6,X可以构建出一棵与图1类似的推理树:规则的结论做为父节点,与前提中∧连接的各个命题之间以实线连接,t,tInt,Cg).Page11表1场景中涉及的规则规则名r_X2当前时刻t,X相信Y准备了详细的申请文档,并针对课题中的一些问题提出了新的技术,参与项目的人员应该有充足的时间,这r_X3当前时刻t,X相信Y有关于g的潜在意图,并且相信Y对于g进行了充分准备,那么X形成信念BelTrust_Int_Th(t).r_X4当前时刻t,X相信可能有某些参与g的研究人员researcheri会出国学习,那么X认为有研究人员没有充足时间参与g.r_X5r_X6当前时刻t,X相信对于Y所提出的针对各个问题probi的技术techi,如果都能被Y用以解决对应的问题,那么X认为Y有一个用r_X7当前时刻t,X相信有某些Y所提出的针对各个问题probi的技术techi是成熟的技术,但以前未被用以解决问题probi,如果Y没有以达成g的recipeRg,对于中的Rg的各个动作α,Y会在动作应该执行的时刻tα之前某个时刻t形成关于α的意图.表2场景中涉及的谓词techi是现有技术Trust(X,Y,IntTo(Y,g,tInt,tg,Cg),t)做为父节点,与r_X1、r_X3、r_X6的结论之间以实线连接.此外鉴于Bel(X,researcheri(Participant(Y,researcheri,g)∧WillStudyAbroad(researcheri),t)与Bel(X,researchi(Participant(Y,researcheri,g)∧EnoughTime(researcheri,g)),t)(记为prop)之间存在冲突,因而在prop对应的节点〈prop,Cprop〉上,上下文约束Cprop中应该包括.Bel(X,researcheri(Participant(Y,researcheri,g)∧Will-StudyAbroad(researcheri)),t)类似地由规则x_R5、x_R7得到相关信念的约束,最终得到如图3所示的信任推理过程(为展示方便,图中忽略了规则x_R1以及Trust与BelTrust_Int_To(t)的相关分支,部分节点忽略其约束上下文,部分节点忽略信念算子Bel).在图3所示的推理树当中X首先确定输入变量,随着X请求(Request)Y执行TrustResponse的动作发送给Y.Y在接受到X的请求和输出变量Ytrstor(t)(Y自己的输入变量)后,首先根据接受到的输入变量更新自身的状态.如果Y决定就X的请求做出回复,那么Y首先通过查找自身信念或通过推理,获得X所请求的输入变量的真值(true、false、unknown),并将其放在输出变量Ytrustee(t)中,进而执行TrustResponse.X在接受到这些变量的真值后,更新图3所示的推理过程,最终决定信任是否建立.这里模糊推理的过程鉴于篇幅不再详细给出.5结语本文首先从认知的角度出发给出代理与非代理情形下的信任定义,而后给出了一个Agent间预动的建立信任的信任框架.在这个框架中,Agent被看作是具有内部状态、输入以及输出的系统;同时,通过受控系统的状态空间方程来描述Agent间为了建立信任进行的通信过程:首先,施信方建立针对信任的推理过程,而后就推理过程中缺乏的信息与受信方进行交互,最终结合模糊推理完成针对信任的推理并决定是否建立信任.该框架主要针对在MAS中,施信方Agent在缺乏与受信方的交互历史或关于受信方的第三方证言的情形下,与受信方建立信任存在困难情况.此外,框架在推理的过程中可以纳入Agent运行中复杂的上下文变化,避免了基于博弈论的信任模型中采用预先定义的效用函数而缺乏灵活性的问题.Page12图3场景的信任推理过程在本文提出的框架中还有一些问题需要进一步研究.首先,尽管采用基于认知的推理可以对复杂的上下文变化进行推理,但是在关于信任的推理规则,以及交互中消息的可靠性方面,会涉及模糊的因素,如何通过模糊推理来与基于博弈的信任模型进行结合以及模糊推理中去模糊化的过程,对于施信方与受信方之间交互中涉及的信念更新问题,还需进一步研究.
