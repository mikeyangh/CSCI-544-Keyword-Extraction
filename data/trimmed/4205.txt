Page1RocketTC:一个基于FPGA的高性能网络流量分类架构付文亮1)嵩天1)周舟2)1)(北京理工大学计算机学院北京市海量语言信息处理与云计算应用工程技术研究中心北京100081)2)(中国科学院信息工程研究所信息内容安全技术国家工程实验室北京100093)摘要基于深包检测技术的流量分类方法可以达到95%以上的识别率和准确率.然而,由于计算复杂性高、存储消耗大等原因,主流软件方法只能提供百兆(线速率)处理能力,而且不能处理大量流并发的情况.文中提出一个基于深包检测技术的芯片级流量分类架构RocketTC,通过对应用层协议特征、匹配引擎和流管理策略进行优化,使其支持万兆级数据吞吐率.RocketTC具有两个核心模块:基于FPGA的流管理器和动态可重构的分类引擎阵列,前者实现万兆吞吐率下的流表管理,后者快速检测流量特征并支持动态协议特征更新特性.文中提出的分类方法使用轻量级DPI方法,通过缩小检测范围和特征长度进一步减少计算复杂度和存储消耗.我们使用XilinxVirtex-5FPGA对上述设计进行实现与在线流量测试,结果表明RocketTC可以对92种网络协议进行识别,准确率达到97%,而且稳定提供20Gbps线速处理能力.关键词架构设计;网络流量分类;FPGA;多级流水;部分动态可重构(PDR)1引言网络流量分类是网络管理、流量工程和网络安全行为分析等网络研究和应用的基础,也是网络研究的重点内容之一.同时,准确的从应用层角度了解网络也是下一代互联网设计的基础.网络流量分类研究发展至今,衍生出多种分类方法,从不同角度对网络数据流的特征进行分析与识别.这些方法主要有基于端口号、基于有效载荷、基于主机和基于机器学习等.基于端口号的分类方法通过检测数据包端口号进行流量识别,实现简单、速度快、延迟低,然而,由于大量使用非标准或随机端口号通信,该方法仅能提供不足70%的识别准确率[1].基于有效载荷的分类方法[1-6],又称深包检测方法(DPI),主要通过检测数据包中协议特征字符串进行分类.这种方法能够达到较高的识别率和准确率,但是计算复杂性高,存储开销大,且不能识别加密数据流.基于主机的分类方法[7-9]通过分析数据流的社会特征进行分类.由于不涉及有效载荷且计算复杂度不高,这种方法不仅可以识别加密流,还能提供较高的数据吞吐率.基于机器学习的方法[10-11]将网络中的数据流统计特征(如平均到达时间、数据包的个数)进行抽取,形成网络协议特征集作为流量分类的标准.其中,后两者的分类准确率远低于基于有效载荷的分类方法.总的来看,在良好的协议特征支持下,基于有效载荷的分类方法可以提供最佳的识别率和识别准确率.此外,虽然DPI方法需要较高的计算和存储开销,但其实现简单、鲁棒且更符合实时性的要求.基于深包检测的分类方法,本文设计并实现了一个基于FPGA的流量分类架构,其主要具有以下几个特点:(1)高吞吐率.在高速网络环境中,实时流量分类设备必须具备相应的处理能力.例如,OC-192(10Gbps)网络满负荷工作时,要求接入的实时设备每秒处理3125万个最小包(以太网包长64字节).如果在线接入设备处理能力不足,就会出现丢包等现象.RocketTC提供数据吞吐率高达20Gbps,满足万兆级高性能网络的要求.(2)芯片级设计.受到计算和存储资源的限制,现有涉及芯片的流量识别方法中,不是使用软硬件相结合的方式[12],就是仅支持特定应用类型数据流的硬件方法[13-15](如多媒体数据流).为了达到万兆级吞吐率,我们针对FPGA芯片的特性设计了基于片上存储器(BlockRAM)的高效流表管理策略和具有部分动态可重构特性[16](PDR)的分类引擎阵列,使用硬件设计解决流量分类问题,减少系统瓶颈.(3)轻量级DPI方法.为了提高检测效率、降低资源使用率,RocketTC采用简化的DPI方法,仅针对部分有效载荷(前32字节)进行特征检测.理论上,这种轻量级深包检测方法可覆盖95%以上的协议特征字段[12].(4)精简协议特征集.良好的协议特征是保证DPI方法高准确率的关键.为了达到这个目的,我们设计了一套针对部分有效载荷(前32字节)的协议特征集.实验表明,在这套协议特征集的支持下,RocketTC的分类准确率可达97%.(5)在线更新特性.RocketTC使用了动态可重构和菊花链式引擎配置的方式实现匹配单元和协议特征的在线更新,在整个动态更新过程中,系统始终处于正常工作状态.本文第2节介绍相关研究情况;第3节对RocketTC整体架构进行描述;第4、5节介绍流管理单元和流分类引擎阵列的详细设计;第6节实验结果及相关分析;第7节总结全文.2相关研究近年来,很多研究者尝试将FPGA等可编程芯片引入流量分类系统以解决系统在吞吐率方面的瓶颈.Luo等人[13]将C4.5决策树作为突破点,在FPGA上实现决策树快速查找,理论上大大提高了系统吞吐率.然而,他们并没有将算法进行硬件实现,无法对引入FPGA的影响做全面评估.Canini等人[12]提出了一个软硬件结合方案.他们将流量分类系统中计算复杂性高、内存消耗大、实时性较低的协议分类模块用软件实现,实时性高的流表查找模块用硬件实现.在NetFPGA平台上的实验表明,系统吞吐率最高可达8Mpps,基本达到千兆线速率的要求.然而,其软件部分仍成为系统的瓶颈,不仅增加了整个系统的延迟,还不支持大量数据流并发的情况.Jiang等人[14]设计了一个基于FPGA的多媒体流量分类系统.这个系统使用FPGA实现近似K最近邻算法以增加吞吐率.最终测试表明,在保证高准确率的前提下,系统吞吐率可以达到约80Gbps(64字节Page3数据包).但是,这个硬件方法只能处理多媒体数据流,具有较大限制.此外,Khan等人[15]提出一个基于FPGA的流量疏导图(trafficdispersiongraphs)方法.测试表明,系统平均吞吐率可达7.4Mpps,平均每个疏导图包涵10K个数据流.综上可见,目前涉及芯片的流量分类方法,不是基于软硬件相结合的思想,就是仅针对某种特殊应图1RocketTC架构及数据通路帧聚合模块(FrameAggregation,FA)将以太网帧进行拆分,并以固定位宽将IP数据包送入包头及有效载荷提取模块(HeaderandPayloadExtraction,HPE).HPE提取数据包五元组,将其转发到流管理模块(FlowManagement,FM)并等待处理结果.如果该数据包未被识别,则将其信息送入流分类引擎阵列(TrafficClassificationEngineArray,TCEA);否则不对该数据包做进一步处理(该包所属数据流已识别).FM管理数据流应用信息,快速过滤已识别数据包.其对数据包五元组做Hash运算,并由所得Hash值索引流表.根据命中情况,FM单元维护流表状态,并将查找结果反馈到HPE单元(数据流由五元组区分).这部分内容将在第4节详细描述.TCEA模块通过特征字符串匹配的方式对数据包有效载荷进行检测.如果识别成功,TCEA将结果反馈给FM模块,并促使后者记录相关数据流信息.这部分将在第5节详细介绍.4流表管理策略流量分类结果(流信息和应用标识)以条目的形式存储在流表,其高性能组织是影响在线设备性能的主要瓶颈之一.我们设计了基于片上存储器的流表管理策略.功能上看,流表管理主要包括如下内用的硬件分类方法.目前还没有一个协议覆盖较为全面的芯片级解决方案.3RocketTC架构RocketTC是一个芯片级高吞吐率流分类系统架构,如图1所示.其中,网络数据由以太网控制器送入帧聚合模块.容:(1)查询流表,(2)添加条目和(3)维护条目有效性.FM模块负责维护系统流表,储存已识别的数据流信息和分类结果.通过查询流表,RocketTC可以快速过滤已被识别的数据包,极大的提高了系统效率.为了达到条目管理高性能,FM模块采用片上存储器和Hash索引的方式快速定位流表条目,并通过分块的方式减少Hash冲突率.针对成功识别的流信息和应用标识,FM模块为其添加条目并存储到流表中.同传统的“先添加,后识别”方法[12]不同,RocketTC采用“先识别,后添加”的设计,不仅减少了流表数量,降低了流表维护的难度,还避免了可能针对流表的DDOS攻击.换句话说,系统只关心那些已识别的数据流.当一个流表条目失效(其标记的数据流生命周期结束),FM模块应尽快将其删除以减少误报.传统遍历流表的方法不适用于高吞吐率的情况(以32768个条目,存储器存取周期8ns为例,一次遍历需要约524μs,在万兆吞吐率下造成至多5000个数据包丢失).因此,我们设计了一个高效的流表管理策略,其中包含两个重要内容:高性能流表数据结构和高效的条目管理机制.4.1流表设计合理的数据结构是实现高速查找表的关键.FM模块使用片上存储器(on-chipblockRAM)存Page4储流表条目,并通过Hash索引的方式进行快速查找.流表条目由部分五元组Hash值(流特征)、流类型(应用层协议编号)和时间标记组成,如图2所示.为了实现高速查找,我们使用Hash函数将一个M位(此处为数据包五元组的数据位宽,共104位)数值均匀映射到N位(64位)索引值.具体到RocketTC中,我们使用循环冗余检验算法(CRC)作为Hash函数,因为CRC算法具有相对较好的唯一性[17],而且具有很高的计算性能①.如图2所示,我们将流表存储在FPGA的片上存储器,由五元组Hash值的低15位进行索引,最多可存215个块(bucket).此外,为了降低冲突率,每个块可以存放4个条目(具有相同的Hash索引值),整个流表最多可存储217个条目.具体来说,每个条目存储48位数据,包括32位流特征(signature),8位协议号(自定义)和8位的时间戳(由高位到低位).其中32位流特征为五元组Hash值的高32位,与索引流表的Hash值低15位并不重复.进行索引时,FM模块将Hash索引的一个块数据(4个条目)取出进行比对,一个时钟周期得到结果.由于采用了Hash索引,流表管理中可能产生冲突问题(两个不同的数据流得到相同的Hash值),这种情况我们称为假阳性错误.Prodanoff等人[18]证明,最好情况下,Hash冲概率突问题符合经典的生日悖论模型.基于此结论,我们由以下公式估算冲突概率:Pcollision=1-m!其中,m是Hash值总数量,n是已经被占用的条目数量.为了更清晰的展示和评估冲突率可能产生的影响,我们将流表使用率作为参数,计算得到Hash冲突率.由表1所示:当流表占用率为50%时,添加新条目的冲突概率为1.5×10-5;当流表全部被占满时,冲突概率依然保持在6.1×10-5.流表条目中,除了32位的流特征外,还包括8位协议号和8位时间戳.协议号标明该数据流属于哪个网络应用.由于硬件资源限制,RocketTC支持92个应用,我们使用8位对其进行标记.条目中的时间戳记录了条目添加或最后访问的时间,是流生命周期管理机制的关键标记,在4.2节中详细介绍.流表查找和添加操作针对具体条目进行.数据包进入系统后,FM模块根据其五元组Hash值索引流表.如果条目已存在,将返回已识别信号并结束查找;如果不存在,则指示HPE将数据包相关信息送到TCEA模块进行识别.TCEA模块将识别成功的分类信息反馈给FM模块,并促使后者添加流表条目.4.2生命周期机制由于数据流具有时效性,流管理模块必须定期将过期条目进行标记和删除(常用数据流有效期为60s).为了达到这个目的,FM模块维护一个全局时钟,每隔一定时间递增(10s).由于系统资源的限制,我们将计数器位宽设为8位,这个颗粒度为10s的全局时钟经过2560s(10×28)循环一个周期.添加条目时,流管理模块将系统时间作为标记插入条目.当索引到条目时,系统通过比较当前系统时钟与条目建立时间的方式验证条目实效性.流管理模块采用触发检查和定期清理两种方法维护流表实效性.系统索引到某条目时,首先判断其实效性,如果过期,则删除.这种触发式的删除方法可能会出现某些记录长时间没有被访问,一个全局时钟周期后仍有效的假阳性错误.针对这种情况,FM模块采用了定时清空机制,在每个全局时钟周期固定时间清空流表条目,以减少假阳性错误.系统流表共有215个块,清理1个块需要1个时钟周期,①Xilinx.“Vertex-5CyclicRedundancyCheck(CRC)Wizard?Page5共需215个周期完成清理操作.在芯片时钟周期为8ns的情况下,整个清理操作耗时约262μs.FM模块判断条目有效性和定期清空机制算法如算法1所示.查找开始后,系统先检查全局时钟是否循环了一个周期(是否重新开始计数).如果是,则清空所有流表条目开始新循环,并将当前数据包送入识别引擎进行识别;否则进行条目查找.算法1.超时算法伪代码.1.IFGlobeTimer=0,THEN2.clearAllFlowRecord3.forwardHash&PayloadtoTCEA4.ELSE5.IFFlowRecord5-tupleHashexistsTHEN6.λ←|Timecurrent-Timetimestamp|7.IFλθTHEN8.deleteFlowRecord5-tupleHash9.forwardHash&PayloadtoTCEA10.ELSE11.updateTimetimestamp12.reporthit13.ENDIF14.ELSE15.forwardHash&PayloadtoTCEA16.ENDIF17.ENDIF系统找到相应流表条目后,计算其时间戳与全局时钟的差λ,并与阈值θ比较:如果λ大于θ,则表明此流表已过期,删除此子条目,并将相应数据转到TCEA;否则返回查找成功信号.在RocketTC中,θ的默认值设为6(流表条目生命周期为60s)与通常使用的数据流生命周期一致[7].5流分类引擎阵列协议识别在流量分类引擎阵列(TCEA)模块完成.TCEA模块的设计主要使用轻量级深包检测方法,具有高准确率,低延迟及高可扩展性等特点.5.1轻量级分类方法为了达到高准确率,TCEA模块采用DPI方法对数据包进行分类.然而,传统DPI方法(如Aho-Corasick算法)将数据包的全部有效载荷作为检测对象,FPGA有限的硬件资源无法承担由此带来的高计算复杂度和存储消耗.因此,我们设计了一个轻量级DPI方法,在保证高准确率的基础上,大幅度缩小数据检测的范围,从而在检测准确率与资源消耗之间达到平衡.轻量级DPI检测方法要求数据检测更具针对性.Aceto等人[3]对当前流行的正则表达式分类器L7-filter做了深入的分析发现,几乎所有成功识别的数据包中,协议特征字符串大多开始(99.98%)并结束(90.77%)于有效载荷的前32个字节.由此可知,轻量级DPI方法的准确率理论上可以达到90%.我们采用的轻量级分类方法具有以下几个特征:首先,轻量级分类方法仅检测数据包有效载荷的前32个字节;其次,模式集由针对固定位置的协议特征构成,而不是复杂的正则表达式.通过对协议规范及当前流行分类方法进行分析,我们总结了可支持92个协议的特征集,涵盖了包括网页浏览、P2P下载(如电驴)、FTP、即时通信(QQ、MSN等)、流媒体、VOIP、网络游戏等主流网络应用,见表2.网络应用HTTPHTTP/1.1.200QQ20100x020x1b0x550x00FTP220.ftpCVSBEGIN(AUTH|VERIFICATION|GSSAPI)POP3(\+ok|-err)SSH0x530x530x480x2dTonghuashunfdfdfdfd注:表示特征从用户有效载荷的第一个字节开始.5.2流分类引擎阵列凭借FPGA的高并行性和部分动态可重构特性,我们设计了一个高性能、支持在线更新的TCEA架构,如图3所示,整个模块由配置与控制单元(Configure&Control,CC)和并行排列的多条分类引擎流水线组成.(1)配置与控制单元(CC).CC单元主要负责两部分工作:首先,配置和管理静、动态引擎单元,保证流水线正常工作;其次,处理CE返回的匹配结果,并将其反馈到流管理单元.CC单元支持在线配置动态引擎协议特征,且在配置过程中不影响其它模块工作.此外,TCEA的分级流水引擎只有在本单元没有匹配成功的情况下,才将数据转到下一个单元,具有固定的优先级.当不同流水线上相同优先级的引擎单元报告匹配时,CC单元中内置的仲裁器可以根据协议优先级做出最终裁决,保证得到最优匹配结果.(2)分类引擎(CE).CE单元以多流水方式配置:每个引擎单元独立识别一个网络应用特征,多个CE单元串连起来组成流水线,多条流水并行组成Page6图3流量分类引擎阵列TCEA的数据通路.当有数据进入TCEA模块时,CC单元将待匹配数据同时发送到所有并行的流水线.由于仅针对部分有效载荷进行处理,分类引擎单元采用掩码加特征字符串的方式进行识别,前者标识特征位置,后者存储特征内容.TCEA分为静态和动态两个区域.静态区域由系统固化的CE单元组成,这些静态引擎不支持动态可重构技术,但可以通过读写寄存器的形式对协议特征和掩码进行修改,从而改变所识别协议特征.与静态引擎不同,动态区域的CE单元可以在系统工作的任何时候进行重构(重新分配资源,更有识别针对性),且在更新过程中不会影响其它流水线工作.动态可重构功能是RocketTC的一个重要特点,图4分类引擎如果某CE单元匹配成功,则将本单元对应协议号和五元组Hash值反馈到CC单元,且不再转发数据(到下个CE单元);如果匹配不成功,则将待测流数据和相关控制信号传递给本流水线下个CE继续检测.流水线式的设计使CE单元功能相对独立,它使RocketTC具有在线配置芯片资源的特性.此外,如果用户配置的单元超过最大可配置单元数,TCEA模块会按照优先级挑选用户最关心的协议.RocketTC系统支持92个网络应用的识别,分散在各个引擎单元中.如何合理的部署引擎是一个值得研究的问题.例如,一个数据流可能既属于Gnutella又属于HTTP,当两者的CE单元同时报告匹配成果时,CC单元根据优先级做出裁决,将高优先级的匹配结果反馈给FM.我们在设计TCEA单元时,将协议优先级与协议号相对应,简化设计.数据通路和控制通贯穿整个CE流水线,如图4所示.数据通路负责传递数据流的Hash值和有效载荷(前32字节),控制通路负责传递控制信号.从而获得高扩展性.在CE单元的设计中,我们使用引擎计数器判断流水线的终端.引擎计数器在数据进入流水线时被赋值,并随着流水线进程递减.当变量为0时,表明数据已到当前流水线的终点.综上所述,TCEA是一个快速、轻量级、高准确Page7率且可扩展的结构化设计.当前实现的原型系统具有4条流水线,支持多达92个协议的识别.6性能评估我们基于赛灵思Virtex-5FX200TFPGA的可编程芯片平台实现了RocketTC原型系统.本节主要就RocketTC的具体性能进行评估与分析,所有测试均在实际网络环境中进行.6.1实验设置(1)性能指标.由于RocketTC属于芯片级设计,我们的考核指标不仅包括准确率等软件分类器的性能指标,还对芯片资源消耗等参数进行测量.具体性能指标如下:①准确率:正确识别流量与总流量的比例.②吞吐率:每秒处理数据包的数量(pps).这个参数与数据包大小相乘便得到每秒传输的数据位(bps).③延迟:处理一个数据包的平均时间.(2)数据集.本文采用某高校网络出口采集的30min网络数据集进行评测.这个学校的有效用户约千人,主要由研究人员与学生组成.数据集包含了所有进出数据流,具体描述如表3所示.日期时间IP地址数据流字节2010-05-1030min1709525130627.49GB(3)方法.为了在真实环境下测试RocketTC的各个性能参数,我们使用Tcpreplay软件重放测试数据集,在线部署原型系统.本实验采用L7-filter软件测试结果作为流量分类结果的真值.6.2系统吞吐率和资源使用率首先,我们对RocketTC进行吞吐率测试.在TCEA模块中,4条流水线并行工作,每个流水线23级流水(CE),可识别92个应用.同时,我们还将两条流水线划入动态区域,测试系统的动态部分可重构性能.整个系统的实现情况如表4所示.Virtex-5FX200T芯片共有16Mb片内随机存储器,分为912个块(block).我们使用了其中452个存储块,实现了一个可存储13.1万条目的流表.由于引入双口随机存储器(dual-portRAM)和多级流水等特性,RocketTC最高工作频率为220MHz,系统吞吐率可达70Mpps(或20Gbps,包大小为64字节).#Slices11179.03072036#BRAMs452.091249块内存储器(Mb)7.61647TCEA可以通过动态重构支持更多的协议.换句话说,只要有足够的硬件资源,TCEA可以通过动态更新的方式更改分类引擎中的协议特征.实际上,CE单元的LUT使用量与特征字符串的复杂度有关,协议的特征字符串越复杂,耗费的资源就越多.在资源使用方面,CE单元所耗费的LUT数量从58(5个特征字符串)到252(16个特征字符串)不等,平均为135.从这个趋势来看,如果使用百万LUT级别的新型FPGA,RocketTC可以支持最多达7000个网络协议,完全满足未来几年人们对流量识别系统的要求.另外,充足的FPGA资源还可以为RocketTC添加数据测量和网络应用管理等更复杂的功能.6.3系统延迟在平均处理延迟的问题上,我们将RocketTC与其它分类方法进行对比.本实验以如下几种方法作为参考:(1)纯软件解决方案,包括L7-filter和PortLoad[3]和(2)结合硬件的实现方案AtoZ[12]和基于LSH的多媒体分类器[14].运行L7-filter的计算机采用2.83GHz的IntelCore2QuadCPU,装配4GB内存.我们以最快速度响应数据捕获以测量实际延迟.结果归纳如表5,在整个测试过程中,RocketTC始终保持很小的延迟(450ns),且没有明显的丢包现象.这个结果表明,同L7-filter相比,RocketTC的延迟要比前者低两个数量级.需要注意的是,在这些分类方法中,只有LSH的性能稍高于RocketTC,主要有下面两个原因.首先,LSH实现方法并没有集成网络接口,因此减少了数据进出网口的延迟.其次,LSH使用机器学习的方法,针对多媒体三大分类进行处理,其计算复杂度和识别协议数量远低于基于DPI方法的RocketTC.此外,同RocketTC识别90%以上的通用流量分类器不同,LSH仅识别多媒体数据流.分类器平均延迟/μs方差/μs2加速比L7-filter206.9228532.58RocketTC0.45PortLoad[3]6.99AtoZ[12]17.00LSH[14]0.11N/A1880.1Page86.4识别准确率为了强化对RocketTC的测试,我们以1min为跨度对准确率进行测量,如图5所示.从测试结果来看,RocketTC具有很强的鲁棒性,成功识别超过95%的数据流,且准确率高于97%.由分析可知,RocketTC不能识别或错误识别数据流的原因主要有以下几点:(1)计算五元组Hash值产生Hash冲突(即不同的五元组得到相同的Hash值),流表管理模块使用冲突的Hash值索引流表导致假阳性错误;(2)协议特征出现在检测范围之外,RocketTC不能对这些特征的识别,产生伪阴性错误;(3)RocketTC所使用的DPI方法不能识别加密数据流.图5Rocket原型系统的协议识别率与准确率7结束语针对当前数据流分类系统的不足,我们提出一个基于深包检测的芯片级架构,其在满足实时流量分类系统高吞吐率和高识别率的要求下,提供较强的扩展性,适合当前复杂的高速网络环境.由于使用了深包检测的方法,RocketTC可以提供比其他方法更佳的识别准确率和颗粒度.同时,由于使用了轻量级深包检测检测方法,RocketTC流量分类架构更适合硬件实现.另外,由于使用了高效的流管理策略和高并行的分类引擎阵列,RocketTC理论上可以提供高达20Gbps的数据吞吐能力.实验表明,以L7-filter作为参考,RocketTC支持近百个协议,识别了超过95%的网络流量,且识别率不低于97%.同时我们认为,即将上市的百万LUT级FPGA必然可以为RocketTC的性能带来较大提升.后续的研究可以从以下方面展开.首先,通过重构,RocketTC可以支持更多应用协议.其次,将RocketTC集成到网络基础设备中,进行更贴近实际的测试.最后,我们还准备对RocketTC架构做修改,使其成为具有针对性的网络测量和流量管理系统.
