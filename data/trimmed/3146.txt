Page1通过相似度支持度优化基于犓近邻的协同过滤算法罗辛欧阳元新熊璋袁满(北京航空航天大学计算机学院北京100191)摘要个性化推荐系统能基于用户个人兴趣为用户提供定制信息.此类系统通常使用协同过滤技术实现,其中一种广泛使用的经典模型是基于用户评分相似度的k近邻模型.使用k近邻模型需要预先计算出用户或者项目的k个最近邻居,k值过大时会导致计算量过大而影响推荐产生的实时性,而k值过小则会导致推荐精度下降.为解决此问题,该文中提出了一种新的最近邻度量———相似度支持度.基于相似度支持度,该文提出了数种能够在保持推荐精度和密度的前提下维持合理规模的k近邻的策略.在真实大规模数据集上的实验结果表明,相比传统算法,该文提出的策略能够在保证推荐精度的前提下大幅降低计算复杂度.关键词个性化推荐;协同过滤;相似度支持度;k近邻;近邻关系模型1引言个性化推荐系统能基于用户个人兴趣为用户提供定制信息.此类系统通常使用协同过滤技术实现[1].在基于协同过滤的推荐系统中,用户对于相关项目的兴趣以一个用户-项目评分矩阵表示,其中较高的评分对应较强的用户兴趣.故而协同过滤推荐的问题可被看作矩阵缺失值估计问题:根据用户-项目评分矩阵中已有的评分值,对未知的评分值进行估计.根据在协同过滤领域内的最近研究成果,构造协同过滤推荐系统时最常用的两类模型是近邻关系模型[2-5]和隐向量模型[6-8].近邻关系模型通过构建用户与用户之间,或者项目与项目之间的关联,从而建立起相应实体的近邻关系;进行推荐时,推荐系统根据当前用户的近邻已做出的评分,或当前项目的近邻已获得的评分来进行预测.与近邻关系模型不同,隐向量模型使用矩阵因式分解技术来对评分矩阵进行分析:其将用户和项目映射至相同维数的隐向量空间,并根据已有的评分训练相应的隐向量;进行推荐时,推荐系统使用相应隐向量对的内积作为对未知评分的预测.相较于近邻关系模型,隐向量模型能够更充分地描述数据的多方面特性.然而,近邻关系模型具备更高的灵活性,更易与其它模型整合,并且其推荐结果也更加直观、易于理解[5].因此,在实际应用中,大部分推荐系统采用基于近邻关系模型的协同过滤技术.在基于近邻关系的协同过滤模型中,一种被广泛采用的经典模型是k近邻模型,其工作原理是利用评分相似度来构造用户或者项目的k近邻集合[1-5],再使用k近邻集合进行推荐.使用k近邻模型需要预先计算出用户或者项目的k个最近邻居,k值过大时会导致计算量过大而影响推荐产生的实时性,而k值过小则会导致推荐精度下降.本文立足于优化基于k近邻的协同过滤推荐模型,提出一种新的k近邻度量———相似度支持度,并基于该度量,提出了一系列对k近邻模型的优化策略.本文的主要贡献包括:(1)假设在基于k近邻的协同过滤推荐系统中,k的最优值取决于该推荐系统内的项目总数;并对该假设进行了实验验证.(2)提出一种新的k近邻度量———相似度支持度,并基于此度量提出了一系列对k近邻模型的优化策略,能够在优化k近邻规模的同时提高推荐质量.(3)在大规模真实数据集上,对本文提出的优化策略进行了实验验证.本文第2节讨论相关工作,并提出问题定义;第3节介绍本文的策略;第4节给出实验结果及分析;最后在第5节中做出结论.2相关工作和问题定义协同过滤推荐问题的定义如下:给定用户集U和项目集I,则用户对于项目的兴趣可以表示为一个|U|×|I|的矩阵犚,在该矩阵中,每一行向量表示一特定用户的评分集合,每一列向量表示一特定项目的被评分集合,每一元素rui∈犚表示用户u对于项目i的评分(通常评分越高,代表用户对该项目兴趣越强).一般情况下,犚中已知评分的数量远远小于未知评分的数量.给定评分集T犚(T犚)作为训练集,根据T中已知的评分,构造一个推荐系统,该系统需要能以最小的累积误差来对犚中未知的评分进行预测.推荐系统的累积误差将在验证集V上进行验证.为避免过度拟合,验证集V中的数据不能够用于推荐系统的训练过程,即V犚且V∩T=.实现协同过滤推荐系统时,一类常用模型是近邻关系模型.在近邻关系模型中,对于未知评分进行预测的前置条件是对用户与用户之间,或者项目与项目之间的关系进行建模.根据所建模的关系种类,近邻关系模型可进一步细分为基于用户的近邻关系模型和基于项目的近邻关系模型两类.由于在实际应用中,项目数量更加稳定,并往往远低于用户数量,因此,对项目之间的关系进行建模是更为常用的方法[2-5].k近邻模型是一种被广泛采用的经典近邻关系模型[1-5].在k近邻模型中,项目间的关系使用评分相似度rs表示.评分相似度通常使用余弦相似度、Pearson相关相似度和修正余弦相似度进行度量[1-2],其中Pearson相关相似度运用最为普遍.在k近邻模型中,对于指定项目i,系统将项目i与系统中其他项目j∈(R-i)之间的评分相似度按照从高至低的顺序进行排序,并记录下与项目i具备最高评分相似度的k个项目,该k个项目就是项目i的k近邻集合,记为kNN(i).当需要为用户u进行推荐时,对未知评分rui的预测,是在用户u在kNN(i)上的已知评分和kNN(i)中已经被用户u进行过评分Page3的项目与项目i的评分相似度这两者的基础上做出的,表示为其中^rui表示推荐系统对于未知评分rui的预测值,R(u)表示用户u的已知评分集合,rsij表示项目i和项目j之间的评分相似度.使用Pearson相关相似度计算rsij时,计算方法如下rsij=∑u∈R(i)∩R(j)(rui-ri)槡2·∑u∈R(i)∩R(j)其中R(i)和R(j)分别表示已知的对项目i和项目j的评分集合,ri和rj分别表示在项目i和项目j上的平均评分值.基于式(1)的未知评分预测规则可以通过预先移除全局平均评分和相应实体相对于全局均值的观察偏差来进行改进[5],表示为^rui=μ+bu+bi+其中μ表示训练集的全局平均评分,bu表示用户u相对于μ的观察偏差,bi表示项目i相对于μ的观察偏差.参数μ、bu和bi可以用如下方式进行估计:μ=∑(u,i)∈Tbi=∑(u,i)∈Tbu=∑(u,i)∈T其中β1和β2是使用交叉验证方法确定的常量.令bui=μ+bu+bi,Rki(u)=kNN(i)∩R(u),代入式(3),可将其简化为推荐规则(5)具有相当的合理性:对于与当前用户给予较高评分的项目具备高评分相似度的项目,系统将会给出较高的用户评分预测值.然而,在为每个项目构造k近邻集合时,却面临着两难抉择:k值过小,会导致推荐系统的性能急剧降低;k值过大,则会导致在进行推荐时计算量过大而影响到推荐产生的实时性.根据现有研究成果.k的最优值取值应在[30,60]区间内,如果k的取值超出该区间的范围,推荐系统的性能将很难继续提高[2-5].然而我们在实践中发现,当推荐系统中的项目总数逐渐上升时,上述k的最优值区间将会逐渐失准.根据上述情况,本文提出假设如下.假设1.在基于k近邻模型的协同过滤推荐系统中,k的最优值依赖于在推荐系统内相互间存在评分相似度的项目总数.对于该假设的实验验证将在下一节中给出.此外,现有的k近邻模型仅根据评分相似度来构建各个项目的k近邻集合.在实际应用中,当两个项目间评分重叠率非常低时,往往会导致这两个项目间具备非常高的评分相似度,从而使这两个项目互相属于对方的k近邻集合.Herlocker等的研究表明,这些基于极少样本计算出的最近邻往往会导致十分荒谬的推荐结果[9].k近邻模型的上述两点缺陷事实上是由同一个原因引起的,即项目的k近邻集合仅由评分相似度决定,具备很大的片面性.从这点出发,我们提出了一种新的k近邻度量———相似度支持度,其定义如下.定义1.相似度支持度ss,是评分相似度的支持样本数量.项目i和j间的相似度支持度就是同时对项目i和j进行评分的用户数量,表示为ssij=|Uij|,其中Uij表示同时对项目i和j进行评分的用户集.事实上,如果我们使用无向图来表示项目间的关系,那么图上每一条边的权值可以表示为一个由评分相似度和相似度支持度组成的二元组,如图1所示.在构造各个项目的k近邻集合时,若两个项目之间的评分相似度较高,说明这两个项目被评分集的匹配度较高;若两个项目之间的相似度支持度较高,则说明这两个项目代表的用户兴趣点重叠度较大.如果我们能够整合评分相似度和相似度支持度,在构造项目的k近邻集合的过程中同时使用这两种Page4度量,将很有希望提高k近邻集合的质量,从而提高推荐系统的性能.近年来,国外也有研究人员针对优化k近邻模型中k近邻集质量的问题进行了研究.Herlocker等在文献[9]中,使用两个用户共同评分项目的数量除以事先约定的阈值得到一个相似度缩放系数,并使用该系数对用户间的评分相似度进行修正.Bell等在文献[4]以及Koren在文献[5]中,都提出了对具备较少支持样本数量的评分相似度进行缩减控制的规则.上述方法与本文提出的优化策略相比,主要存在以下不足:(1)没有提出对支持度相似度的明确定义;(2)都需要预先定义一个阈值,该阈值只能通过交叉验证方法来确定,将导致计算更加复杂;(3)只能对少数缺少样本支持的评分相似度进行调整,不能反映整个数据集上相似度支持度的分布情况.与现有方法相比,本文提出的优化策略不存在上述弊端.在下一节中,我们将对本文提出的优化策略进行详细阐述.3基于相似度支持度的犽近邻优化策略在本节中,我们将首先对前文提出的假设1进行实验验证,然后对本文提出的策略进行阐述.3.1假设1的实验验证相关研究认为,在基于k近邻模型的推荐系统中,建立项目的k近邻集合时,k的最优取值应在[30,60]区间内;如果k超出该区间范围,推荐精度将几乎不会提高[2-4].然而我们在实践中发现,当推荐系统中相互之间存在评分相似度关系的项目数量逐渐上升时,该论断将会逐渐失准.因此,本文提出了假设1,并设计了以下实验进行验证.实验数据集.实验在MovieLens10K数据集(以下简称ML10K)上进行.该数据集由明尼苏达大学GroupLens研究小组通过MovieLens网站收集,包含了943个用户对1682个项目的10000条评分信息.所有的评分值分布在[0,5]区间内,越高的评分值代表越强的用户兴趣.实验评判度量.实验使用平均绝对误差MAE和推荐覆盖度Coverage作为推荐系统性能的评判度量.其中MAE是被广泛采用的用于评判推荐系统预测精度的度量[10].在计算推荐系统的MAE之前,首先需要计算用户平均绝对误差MAUE.MAUE的计算方法如下式所示MAUEu=∑i∈IP(u)∩IR(u)|^rui-rui|/|IP(u)∩IR(u)|其中IP(u)是推荐系统为用户u推荐的项目集,IR(u)是用户u在测试数据集上进行评分的项目集.计算出每个用户的MAUE后,就可以计算出该推荐系统的MAE,如下式MAE越低,代表推荐系统的预测精度越高.而Coverage是一项被广泛使用的用以评价推荐系统推荐覆盖度的评判度量,指的是推荐系统为用户推荐的项目集对用户兴趣的覆盖范围[10],其计算方式为Coverage=∑u∈UCoverage越高,代表推荐系统对用户兴趣的覆盖能力越强.实验设置.为了检验k的最优取值随着项目数量的增多是否会有相应的变化,实验分为3个阶段,每个阶段分别从ML10K数据集中随机选取100个项目、500个项目和1000个项目以及这些项目相应的评分作为实验数据集.这3个子数据集被分别记为I100、I500和I1000.在每个子数据集上,实验按照90%~10%的比例构造训练-测试数据.在实验中,项目间的相似度使用式(2)中的Pearson相关相似度进行度量.实验在基于经过改进的k近邻模型的推荐系统上进行,该推荐系统将使用式(5)对未知评分进行预测.实验结果.图2、图3和图4分别给出了在I100、I500和I1000这3个数据集上k值对于MAE的影响.可以看到,在I100数据集上,由于当k值大于60时,推荐系统的MAE几乎不会再继续降低,Page5图4在I1000数据集上k值对MAE的影响故而在I100数据集上k的最优值是60,此时,现有研究建议的k最优值取值区间[30,60]仍然适用;然而在I500数据集上,k的最优取值为200;在I1000数据集上,k的最优取值则为350,均不在[30,60]区间内.图5、图6和图7分别给出了在I100、I500和I1000这3个数据集上k值对于Coverage的影响.在I100数据集上,当k值大于70时,Coverage将停止上升;而在I500和I1000数据集上,Coverage将分别在k=200和k=300时达到峰值.就Coverage而言,无论是在I100、I500还是I1000数据集上,k的最优值均不在[30,60]区间内.图5在I100数据集上k值对Coverage的影响图6在I500数据集上k值对Coverage的影响图7在I1000数据集上k值对Coverage的影响基于以上实验结果,我们可以得出以下结论:(1)使用MAE和Coverage这两项评判度量对基于k近邻模型的推荐系统进行性能评判时,k的最优取值将很有可能位于[30,60]的取值区间之外;(2)在基于k近邻的推荐系统中,当项目数量上升时,k的最优取值也有上升的趋势.综合上述结论,我们可以判定假设1是正确的.3.2使用相似度支持度改进犽近邻模型从定义1中可以发现,相似度支持度实际上代表了项目间评分相似度的可信度,若相似度支持度较大,说明评分相似度支持样本数量较多,可信度较高;反之,则说明评分相似度支持数量较少,可信度较低.若能够在建立项目k近邻的过程中,能够同时从项目间评分相似度和相似度支持度两方面进行全面的考虑,将很有可能提高项目k近邻的质量,从而最终提高推荐系统的性能.从这点出发,本文设计了以下几种整合应用评分相似度和相似度支持度,来构造项目k近邻集的策略:SSR(相似度支持度排名)策略.SSR策略完全使用相似度支持度来构造项目的k近邻集合.经过SSR策略调整的k近邻模型将会把当前项目的近邻按照与当前项目间的相似度支持度的高低进行排序,并选取与当前项目具备最高的相似度支持度的Page6前k个近邻构成当前项目的k近邻集.在使用SSR策略的k近邻模型中,相似度支持度对未知评分预测过程没有影响:在对未知评分进行预测时,推荐系统仍然只使用评分相似度来产生预测.SSR策略实际上就是利用相似度支持度对项目间评分相似度的可信度的代表性,对k近邻模型进行改进.这与现实生活中的人际关系十分相似:基于寥寥可数的几次接触,人们往往很难对他人给出合理、可信的评价;反之,如果两人之间频繁联系,相互熟悉,则他们对彼此的评价将更具备代表性.根据相似度支持度来选取当前项目的k近邻集也是基于类似的原理:与当前项目具备较高的相似度支持度的近邻就是与当前项目“联系”频繁的对象,因而这两个项目之间的评分相似度应具备更强的代表性,所蕴含的信息也更多.ISW(相似度支持度加权)策略.ISW策略在构造项目的k近邻集合时,将会根据当前项目与其近邻间的相似度支持度,为当前项目的每个近邻分配一个相似度支持度权重sw,其计算公式为其中swij表示项目i和项目j间的相似度支持度权重,min(ss)和max(ss)分别表示在训练集上相似度支持度的最小值和最大值.计算出的相似度支持度权重将会用于对评分相似度进行调整,如下式所示调整后的相似度支持度将会被用以构造当前项目的k近邻集合,并在式(5)中替换原始评分相似度进行未知评分预测.ISW策略将会以如下方式构造项目k近邻集:综合考虑当前项目与其近邻间的评分相似度和相似度支持度,并优先选择在这两种度量上同时具备较高数值的近邻.由于不同项目间的相似度支持度差异很大,故而使用ISW策略调整后的评分相似度可能会存在数量级上的差别.但由式(5)可知,评分相似度的数值变化会因为除法运算而抵消,因此,使用ISW策略不会导致推荐系统对于未知评分的预测结果间存在数量级的差异.事实上,ISW策略将会极大弱化当前项目的近邻集中具备较低相似度支持度的近邻项目对未知评分预测的影响,反之亦然.GW(相似度支持度高斯加权)策略.GW策略根据当前项目与其近邻间的相似度支持度,为当前项目的每个近邻分配一个高斯权重,用以调整其与当前项目间的相似度支持度.使用GW策略来构造项目的k近邻集时,首先需要使用高斯分布N(μ,σ2)来拟合项目间的相似度支持度.其中参数μ和σ2可以使用极大似然估计法进行估计,如下式所示^μ=珋s珋s=1其中N表示在给定训练数据集上训练得到的相似度支持度的数量.对项目间的相似度支持度进行拟合后,就可以对每个评分相似度根据其相似度支持度赋予一个支持度高斯权重,该权重由拟合得到的高斯分布的概率分布函数决定,如下式所示gwij=F(ssij^u,^σ2)=∫ssij其中gwij表示项目i和项目j间的相似度支持度权重,F(ssij|^u,^σ2)表示高斯概率分布函数,f(ss|^u,^σ2)则表示高斯概率密度函数.gwij的值实际上代表在当前训练数据集上,项目i和j之间的相似度支持度大于等于其它项目间相似度支持度的概率.最后,类似于ISW策略,我们将评分相似度与对应的高斯权重相乘,从而对评分相似度进行调整调整后的相似度支持度将会被用以构造项目的k近邻集合和评分预测.GW策略将会以如下方式构造项目k近邻集:综合考虑当前项目与其近邻间的评分相似度和相似度支持度,并优先选择在这两种度量上同时具备较高数值的近邻;大部分相似度支持度值在均值附近的近邻,其高斯权值均位于中间值0.5左右,因而这些近邻在当前项目的近邻集内的相对排序不会受到太大影响.4实验结果及分析实验数据集.为了检验本文提出的优化策略在不同数据集上的效果,我们分别在两个数据集上进行了实验.第一个数据集是3.1节中用以验证假设1的ML10K数据集的全集.第2个数据集取自Net-flix数据集,该数据集是Netflix公司举办Netflix竞赛时所使用的数据集,其中包含了Netflix公司随机挑选的48万名匿名客户对1万7千个项目超过1亿条的评分数据.该数据集中的所有评分值分布在区间[1,5]内.我们的实验在Netflix数据集中前1000个项目的被评分数据上进行.该子数据集总共Page7包含约40万名用户在这1000个项目上超过5百万条的评分数据,简称为NF5M数据集.实验评判度量.实验使用3.1节中提到的MAE和Coverage作为推荐系统性能的评判度量.实验设置.在每个实验数据集上,实验按照90%~10%的比例构造训练-测试数据.在实验中,项目间的相似度使用式(2)所示的Pearson相关相似度进行度量.实验使用基于经过改进的k近邻模型的推荐系统作为基准参照方法,该推荐系统根据式(5)对未知评分进行预测.然后实验分别使用SSR策略、ISW策略和GW策略对基准参照方法进行优化,并与基准参照方法对比,以验证这3种优化策略的实际效果.实验结果.图8和图9给出了在ML10K数据集上的实验结果,图10和图11则给出了在NF5M数据集上的实验结果.在所有图例中,CF表示基准参照方法;SSR-CF、ISW-CF和GW-CF则分别表示使用SSR策略、ISW策略和GW策略对基准参照方法进行改进后的推荐系统.首先我们看在ML10K数据集上的实验结果.图8给出了实验中各推荐系统在ML10K上的MAE对比情况,而图9则给出了Coverage对比情况.如图8和图9所示,使用基于相似度支持度的优图8实验中各推荐系统在ML10K数据集上的MAE比较图9实验中各推荐系统在ML10K数据集上的Coverage比较图10实验中各推荐系统在NF5M数据集上的MAE比较图11实验中各推荐系统在NF5M数据集上的Coverage比较化策略能够显著地提升推荐系统的性能.与基准参照方法相比,使用SSR策略、ISW策略和GW策略改进后的推荐系统都能达到更低的MAE值.更重要的是,使用优化策略改进后,推荐系统的收敛速度要远远快于改进前.在本文提出的3种优化策略中,效果最好的是GW策略:在k=200时,使用GW策略优化的推荐系统就能获得比参照基准方法在k=1000时更高的推荐精度和非常接近的推荐覆盖度,如表1所示.这意味着GW策略在提高推荐质量的同时还降低了80%的计算量.表1实验中各推荐系统在ML10K数据集上的性能比较推荐系统CF0.7573100.0SSR-CF0.7569100.0ISW-CF0.7554100.0GW-CF0.7521图10和图11分别给出了实验中各推荐系统在NF5M数据集上MAE和Coverage的对比情况.NF5M上的实验结果和ML10K上十分相似,GW_GF仍然有最佳的表现,在k=100时,使用GW策略优化的推荐系统就能获得比参照基准方法在k=500时更高的推荐精度和非常接近的推荐覆盖度,Page8如表2所示.表2实验中各推荐系统在NF5M数据集上的性能比较推荐系统CF0.872699.3SSR-CF0.871699.7ISW-CF0.872099.3GW-CF0.872297.9在实验过程中,我们注意到,使用ISW策略和GW策略优化的推荐算法,除了收敛速度明显加快外,预测精度也有较为显著的提高.这是由于这两种策略均使用了经过修正的评分相似度进行未知评分预测.从实验结果来看,GW策略对评分相似度的修正方式能产生更好的推荐效果.复杂度分析.基于实验结果,我们发现使用基于相似度支持度的优化策略对基于k近邻模型的推荐算法进行优化,在进行推荐时,不但可以显著地降低计算复杂度,还可以提高预测精度.然而,引入相似度支持度将会提高推荐系统训练过程中的计算复杂度.在基于k近邻的推荐系统中,训练的时间复杂度和空间复杂度均为O(n2).引入相似度支持度后,会在以下两个方面增加训练时的计算复杂度.对相似度支持度的存储,额外需要大小为O(n2)的存储空间,因此引入SS后,推荐系统在训练时的空间复杂度为O(2n2).使用ISW策略和GW策略时,由于系统需要根据相应的相似度支持度对每个评分相似度进行修正,就需要在全部的评分相似度上迭代一次,因而推荐系统在训练时的时间复杂度为O(2n2).5结论在基于k近邻模型的协同过滤推荐系统中,一项最为关键的任务是为每个项目构造用以进行未知评分预测的k近邻集.在这个过程中,面临着对k值的两难选择:如果k值过大,会导致系统在进行推荐时计算量过大,从而影响推荐产生的实时性;如果k值过小,则会导致推荐系统的性能急剧下降.以往研究认为k的最优取值区间应在[30,60]区间内,如果k值超出该区间的范围,推荐系统的性能将会很难再继续提高.但我们在实践中发现k的最优值事实上与推荐系统中的项目数量密切相关,当推荐系统中的项目数量上升时,为了获得较好的推荐效果,k的取值也需要有相应增加.为了能够在维持推荐系统性能的同时维持合理的k近邻集规模,本文提出了一个新的k近邻度量———相似度支持度.基于对相似度支持度和评分相似度的综合考虑,本文提出了SSR、ISW和GW三种对基于k近邻模型的推荐系统的优化策略.在大规模真实数据集上的实验结果表明,使用本文提出的优化策略优化后的基于k近邻模型的推荐系统,其进行推荐时的计算复杂度显著降低,并且能提供更好的推荐效果.
