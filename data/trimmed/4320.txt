Page1基于特征子集区分度与支持向量机的特征选择算法谢娟英1)谢维信2)1)(陕西师范大学计算机科学学院西安710062)2)(深圳大学信息工程学院ATR国家重点实验室广东深圳518060)摘要考虑特征之间的相关性对于其类间区分能力的影响,提出了一种新的特征子集区分度衡量准则———DFS(DiscernibilityofFeatureSubsets)准则.该准则考虑特征之间的相关性,通过计算特征子集中全部特征对于分类的联合贡献来判断特征子集的类间辨别能力大小,不再只考虑单个特征对于分类的贡献.结合顺序前向、顺序后向、顺序前向浮动和顺序后向浮动4种特征搜索策略,以支持向量机(SupportVectorMachines,SVM)为分类工具,引导特征选择过程,得到4种基于DFS与SVM的特征选择算法.其中在顺序前/后向浮动搜索策略中,首先根据DFS准则加入/去掉特征到特征子集中,然后在浮动阶段根据所得临时SVM分类器的分类性能决定刚加入/去掉特征的去留.UCI机器学习数据库数据集的对比实验测试表明,提出的DFS准则是一种很好的特征子集类间区分能力度量准则;基于DFS与SVM的特征选择算法实现了有效的特征选择;与其他同类算法相比,基于DFS准则与SVM的特征选择算法具有非常好的泛化性能,但其所选特征子集的规模不一定是最好的.关键词特征选择;支持向量机;相关性;特征子集区分度;特征区分度1引言特征选择是模式识别、数据挖掘等领域的重要研究内容,它通过选择原始特征集合中的重要特征构成特征子集,达到降低数据维数,同时保持或提高系统分类性能的目的.与特征提取不同,特征选择保留的是原始物理特征,因此,可以真正地降低存储需要、测量需求、计算开销等;而特征提取所保留的特征是原始特征的线性组合,降维后的特征与原始每一个特征都相关,因此特征提取保留下的特征没有任何物理意义,这对癌症等疾病诊断研究没有任何意义.另外,特征提取也不能降低存储需要、测量需求、计算开销等,不具有特征选择的这些优点[1].特征选择对于构建一个简洁、高效的分类系统有重要作用.它不仅可以揭示系统所隐藏的潜在模式和规律,并使分类结果的可视化成为可能[1].因此,特征选择,特别是基于最具有泛化能力和最小错分率的学习机———支持向量机(SupportVectorMachines,SVM)的特征选择研究备受关注[2-9].现有特征选择研究主要着眼于选择最优特征子集所需要的两个主要步骤[10]:特征子集搜索策略和特征子集性能评价准则.经典的特征子集搜索策略包括:顺序前向搜索(SequentialForwardSearch,SFS)[11]、顺序后向搜索(SequentialBackwardSearch,SBS)[12]、顺序前向浮动搜索(SequentialForwardFloatingSearch,SFFS)[13]、顺序后向浮动搜索(SequentialBackwardFloatingSearch,SBFS)[13]4种.特征子集性能评价准则有独立于分类器的评价方法、以分类器分类准确率评价的方法,以及将两者相结合的评价方法.特征选择方法依据其与分类器的关系分为Filter方法、Wrapper方法和Embedded方法3类[14-16].Filter[14]方法根据每一个特征对分类贡献的大小,定义其重要度,选择重要的特征构成特征子集.该方法独立于学习过程,时间效率较高,但是该方法需要一个阈值作为特征选择的停止准则.Filter方法选择的特征子集的分类性能不仅与特征重要性计算方法,即特征排序准则有关;而且与特征搜索策略,以及特征选择过程的停止准则密切相关.Wrapper[15]方法依赖于学习过程,将训练样本分成训练子集和测试子集两部分.Wrapper方法中的学习算法完全是一个“黑匣子”,仅以每一组特征子集训练所得分类器的分类准确率作为该组特征分类性能的度量.为选择出性能最好的特征子集,Wrapper算法需要的计算量巨大;而且该方法所选择的特征子集依赖于具体学习机;容易产生“过适应”问题,推广性能较差.另外,确定搜索策略以搜索所有可能的特征组合,评价学习机的性能以引导或停止搜索,以及选择具体的学习算法是Wrapper方法的关键.Embedded[16]方法将特征选择集成在学习机训练过程中,通过优化一个目标函数在训练分类器的过程中实现特征选择.该方法不用将训练数据集分成训练集和测试集两部分,避免了为评估每一个特征子集对学习机所进行的从头开始的训练,可以快速地得到最佳特征子集,是一种高效的特征选择方法,但是构造一个合适的函数优化模型是该方法的难点.Filter算法和Wrapper算法相结合的混合特征选择方法集成了Filter方法的高效与Wrapper方法的高准确率,可得到更优的特征子集[17-19],是目前特征选择方法研究的一个新趋势.然而,现有特征选择研究多集中于考虑单个特征对于分类的贡献,以此来评价特征的重要性,从而依次选择重要的特征构成特征子集.这样进行特征选择忽略了特征之间的Page3相关性对于分类的影响,或者对特征之间的相关性考虑不足,特征之间的联合作用对于分类的贡献经常被忽略.Hall的CFS(CorrelationbasedFeatureSelector,CFS)[20]特征选择方法基于特征之间的相关性考虑,通过计算特征之间的相关性,以及特征与类标的相关性,来实现特征选择,从而使得被选特征子集的特征之间尽可能不相关,而与类标高度相关.但是HALL的CFS计算特征相关性的方法只适用于离散型数据,非离散的数据需要进行离散化预处理;另外,特征之间的相关性只注重了特征两两之间的相关性,对于多个特征对于分类的联合贡献考虑不足.本文基于特征之间相关性的考虑,提出DFS(DiscernibilityofFeatureSubsets,DFS)特征子集区分度衡量准则,通过计算特征子集中特征的联合F-score值来判断特征子集的类别间区分能力大小,以此作为特征子集对分类贡献大小的度量,并结合SFS、SBS、SFFS和SFBS4种特征搜索策略,以SVM为分类工具引导特征选择过程,实现特征选择.UCI机器学习数据库数据集的实验测试表明,本文提出的DFS准则是一种有效的特征子集类间区分能力度量准则;基于DFS与SVM的特征算法实现了有效的特征选择,具有很好的泛化性能;但是所选择的特征子集的规模不一定是最好的.2特征子集评价准则现有特征选择研究中特征重要性的评价多是计算单个特征的类间区分能力,选择对分类贡献大的特征构成特征子集,而忽略了特征之间的相关性对于特征类间区分能力大小的影响,或者对特征之间的相关性考虑不足.Hall[20]通过计算特征之间的相关性、特征与类标的相关性提出CFS特征子集评价准则,CFS计算整个特征子集的类间区分能力实现特征选择,使得被选特征子集中的特征之间尽可能不相关,而与类标高度相关.但CFS[20]只适用于离散型数据;另外,CFS更注重了特征两两之间的相关性,对于多个特征对于分类的联合贡献考虑不足.为此,本文首先将Pearson相关系数引入CFS,以计算特征两两之间的相关性,使得CFS可应用于实值特征;然后将Pearson相关系数所表达的正、负相关性进行统一,不区分正、负相关,只考虑相关,从而得到CFSPabs(CorrelationbasedFeatureSelectorbasedontheabsoluteofPearson’scorrelationcoefficient,CFSPabs)特征子集评价准则.其次,本文在文献[19]对单个特征的类间区分能力,即对分类的贡献的研究基础上,考虑多个特征对于分类的联合贡献,提出DFS特征子集评价准则,并结合4种特征搜索策略SFS、SBS、SFFS和SFBS,提出4种基于DFS特征子集评价准则的特征选择算法.2.1CFS特征子集评价准则CFS特征子集评价准则[20]的定义如式(1)所示:式(1)中的Ms度量了包含k个特征的特征子集S的类别辨识能力,rcf表示特征f(f∈S)与类别c的相关系数的均值,rff是特征之间的相关系数均值.式(1)的分子表达了特征子集S的类预测能力;分母表示了特征子集S中特征的冗余程度.因此分子越大表示特征子集S的类预测能力越强,分母越小表示该特征子集的冗余性越小.特征选择,就是选择一组特征构成特征子集,该子集与类别高度相关,但是子集中的特征之间高度不相关[12].由此可见Ms的值越大,当前特征子集S对于分类的贡献越大,是优良的特征子集.我们使用Pearson相关系数计算相应特征之间的相关性,以便CFS准则可应用于任意类型的特征值.Pearson相关系数的计算公式如式(2)所示.r=∑犡犢-∑犡∑犢其中,犡,犢表示待求相关系数的两个向量,可以是两列特征向量,或者一列特征向量与一列类标向量,N是样本个数.2.2CFSPabs特征子集评价准则由于Pearson相关系数可能为正值,也可能为负值,也即待判断相关程度的两向量可能正相关,也可能负相关.而无论正相关还是负相关,相关系数的绝对值越大,也即相关系数越接近+1或-1,则相关性越强;相关系数越接近于0,则相关度越弱.因此,我们将式(1)所示CFS准则中计算相关系数的Pearson相关系数进行改进,取其绝对值,得到特征子集评价准则CFSPabs.CFSPabs准则中的相关系数计算公式如式(3)所示.Page4r=∑犡犢-∑犡∑犢2.3DFS特征子集评价准则设m维实空间犚m中的两类分类问题,训练集样本的规模为n,正类和负类的样本数分别为n+和n-.即训练集是{(狓k,yk)|狓k∈犚m,m0,yk∈{1,-1},k=1,…,n},‖{yk|yk=+1,k=1,…,n}‖=n+,‖{yk|yk=-1,k=1,…,n}‖=n-.则含有i(i=1,2,…,m)个特征的特征子集的区分度DFS的定义如式(4)所示.DFSi=∑ik=1其中,x-集上的均值,在正类数据集上的均值和在负类数据集上的均值;x(+)征的值;x(-)式(4)可以简记为式(5).DFSi=n+-1∑n+1其中,‖X-Y‖表示向量犡,犢之间的距离;狓-,狓-(+),狓-(-)分别为包含i个特征的特征子集在整个数据集上的均值向量,在正类数据集上的均值向量和在负类数据集上的均值向量;狓(+)样本点对应于当前i个特征的特征值向量;狓(-)第k个负类样本对应当前i个特征的特征值向量.分析式(4)和(5)可知,分子表示正类、负类对应当前含有i个特征的特征子集的均值向量与整个样本集对应当前i个特征的特征子集的均值向量的距离平方之和;分母表示正类、负类对应当前i个特征的特征子集的方差之和;分子值越大表示对应当前i个特征的特征子集的类间越疏;分母值越小表示对应当前i个特征的特征子集的类内越聚.因此DFSi值越大,表明包含当前i个特征的特征子集的类间区分能力越强,也即类别辨识能力越强.对于l(l2)类分类问题,设训练样本集规模为n,样本空间维数为m.即训练样本集为{(狓k,yk)|狓k∈犚m(m维实空间),m0,yk∈{1,…,l},l2,k=1,…,n}.其中,第j类的样本数为nj,即‖yk|yk=j,k=1,…,n‖=nj,j=1,…,l,则含有i(i=1,…,m)个特征的特征子集的区分度DFSi定义为式(6).其中狓-,狓-(j)分别为包含当前i个特征的特征子集在整个数据集上的均值向量,在第j类数据集上的均值向量;狓(j)征的特征值向量.式(6)的分子表示l个类别中各类别对应包含当前i个特征的特征子集的样本中心向量与整个样本集对应当前i个特征的中心向量的距离平方和,其值越大,类间越疏.式(6)的分母表示各个类别对应包含当前i个特征的特征子集的类内方差.方差越小,类内越聚.因此,式(6)定义的DFSi表示了当前i个特征的特征子集的类间距离和与类内方差之比,其值越大表明包含当前i个特征的特征子集的类别辨识力越强.当i=1时,DFSi蜕化为单个特征的类间区分能力度量准则———改进的F-score准则[19],如式(7)所示.式(7)中x-的均值,在第j类数据集上的均值;x(j)k个样本点的第i个特征的值.式(7)分子表示l个类中第i个特征的各类中心到整个样本集中心的距离平方和,其值越大,类间越疏.式(7)的分母表示各个类第i个特征的类内方差.方差越小,类内越聚.因此,Fi近似表示了第i个特征的类间距离与类内方差之比,其值越大表明第i个特征的辨识力越强.3基于DFS与SVM的特征选择算法将本文提出的特征子集区分度衡量准则DFS结合SFS、SBS、SFFS和SFBS特征搜索策略,以SVM为分类工具,提出4种不同的特征选择算法.Page5算法1.基于DFS与SVM的顺序前向混合特征选择算法.该算法采用SFS搜索策略,以DFS度量相应特征子集的类间区分能力,以SVM分类模型的分类正确率作为最终依据选择相应特征子集.特征选择从空集开始,第一次加入类间区分能力最强的一个特征,然后依次迭代加入与已选择特征组合构成类间区分能力最大的特征子集对应的那个特征.该过程一直进行,直到所有特征都被加入.最后选择训练集分类正确率最高时对应的特征子集为被选择特征子集.算法的伪代码描述如下.输入:当前的训练集和测试集.输出:特征子集C设S={fi|i=1,…,m}为全部特征构成的集合,C为被选择特征构成的子集,初始为空集,即C=;根据式(7)计算训练集上每个特征的类间区分能力;选择最重要的特征fmax=max{Fi,i=1,…,m};令S=S-{fmax};C=C∪{fmax};使用C中特征训练SVM,得到一个SVM分类模型;以该模型对训练集、测试集进行分类,记录相应的分类正确率;WHILES≠DOBEGINmaxDFS=min;maxtempC=;FOReachf∈SDOBEGINEND//endofforC=maxtempC;S=S-{selectedfeature};END//endofwhile算法2.基于DFS与SVM的顺序后向混合特征选择算法.该算法利用SBS搜索策略,以DFS度量相应特征子集的类间区分能力,SVM的分类准确率引导特征选择过程.算法从特征全集开始,每次剔除当前余下特征中最差的一个,即剔除该特征后的剩余特征构成最具有类间区分能力的特征子集.以训练集分类正确率不再上升时对应的规模最小的特征子集为被选择特征子集.算法的伪代码描述如下.输入:当前的训练集Xtrain和测试集Xtest输出:特征子集S设S={fi|i=1,2,…,m}为全部特征构成的集合;WHILES≠DOBEGIN以S中特征训练Xtrain,得到一个SVM分类模型;maxDFS=min;featuresubset=S;S=S-{deletefeature};END//endofwhile算法3.基于DFS与SVM的顺序前向浮动混合特征选择算法.该算法将DFS特征评价准则与顺序前向浮动搜索策略SFFS结合,以SVM为分类工具,首先加入最具有类间区分能力的一个特征,然后每次迭代加入与已选择特征组合最具有类间区分能力的相应特征,之后浮动部分依据加入特征之后的特征子集对应SVM分类器的分类正确率判定刚刚加入的特征是否保留.若当前特征子集训练所得SVM分类模型的训练分类正确率上升,则保留刚加入的特征,否则删除刚刚加入的特征.该过程一直进行,直到所有特征都被测试过.最后留在特征子集中的特征构成最佳被选择特征子集.算法伪代码描述如下.输入:当前训练集和测试集输出:特征子集C设S={fi|i=1,2,…,m}为全部特征构成的集合,C为被选择特征构成的子集,初始为空集,即C=;根据式(7)在训练集上计算每个特征的区分能力;选择最重要的特征fmax=max{Fi,i=1,2,…,m};令S=S-{fmax};令C=C∪{fmax};使用C中特征训练SVM,得到一个SVM分类模型;Page6记录该模型对训练集、测试集的分类正确率acctrain和acctest;WHILES≠DOBEGINmaxDFS=min;maxtempC=C;FOReachf∈SDOBEGINEND//endofforC=maxtempC;S=S-{selectedfeature};preacctrain=acctrain;preacctest=acctest;IFacctrainpreacctrainTHENBEGINEND//endofifEND//endofwhile算法4.基于DFS与SVM的顺序后向浮动混合特征选择算法.该算法将DFS特征子集区分度评价准则与SVM结合,以顺序后向浮动搜索策略SBFS进行特征搜索,特征选择从全集开始,根据DFS值剔除当前余下特征中最差的一个特征,即剔除该特征使得剩余特征构成的特征子集对应的DFS值最大.浮动部分以被选择特征子集的SVM分类模型的分类正确率判断刚刚剔除的特征是否需要收回,若剔除该最差特征后导致训练集的分类正确率下降,则将刚剔除的最差特征召回;否则剔除.该过程一直迭代,直到所有特征都被测试过,最后留下的特征构成被选特征子集.算法的伪代码描述如下.输入:当前训练集Xtrain与测试集Xtest输出:特征子集C设S={fi|i=1,2,…,m}为包含全部特征的集合,C={fi|i=1,2,…,m}为被选择特征构成的子集;WHILES≠DOBEGIN以C中特征在Xtrain训练得到一个SVM分类模型;maxDFS=min;featuresubset=S;S=S-{deletefeature};preacctrain=acctrain;preacctest=acctest;IFacctrainpreacctrainTHENEND//endofwhile4实验结果与分析实验采用UCI机器学习数据库[21]的10个数据集①iris,dermatology,glass,handwrite,ionosphere,WDBC(WisconsinDiagnosticBreastCancer),WPBC(WisconsinPrognosticBreastCancer),wine,thyroid-disease和heartdisease.其中,dermatology数据集,删去了8个含有缺失数据的样本;glass数据集分成了windowglass和non-windowglass两类;handwrite数据集只选择了semeionhandwrittendigit数据集的前两类;WPBC数据集删去了4个含有缺失数据的样本;thyroid-disease数据集是其中的new-thyroid,即thyroidglanddata数据集;heartdisease数据集使用了其中的processedcleve-land数据集,并删去了6个含有缺失数据的样本.数据集详细信息如表1描述.实验环境为DellVostro①http://www.ics.uci.edu/~mlearn/MLRepository.htmlPage71450笔记本电脑,IntelCorei5-24502.50GHzCPU,4GB内存,Win764位操作系统,Matlab应用软件.数据集样本个数特征数类别数dermatology358handwrite323255ionosphere351WDBCWPBCthyroid-disease215heartdisease297为得到具有统计意义的实验结果,采用5折交叉验证实验.同时,为了得到随机的实验数据,采用将样本顺序随机打乱,每一类样本依次逐个加入到5个初始为空的样本集合,直到这一类的每一个样本都被加入,实现将样本随机均匀划分为5份的目的.以1份样本为测试样本集,其余4份为训练样本集,并以每1份都做过测试集结束5折交叉验证实验.样本随机打乱的方法是:随机生成一个5000×2的2维数组,数组每一元素的值在1~数据集规模之间;交换数组每一行两个元素值对应的两个样本.数据集原始特征数被选择特征数iris数据集原始特征数被选择特征数irisglassdermatology3432.231.231.895.5229593.6160496.094381.1718893.0290782.533540handwrite25536.0127.8110.898.7784198.4565997.2349952.500705800.8215585.649ionosphere3419.819.221.292.2937693.1468891.730380.7963042.1165881.974555WDBC3027.011.424.464.6802663.6121664.692571.3253632.3989881.910676WPBC3328.48.210.876.2955576.2955575.795550.4981471.6876161.542187winethyroid-disease53.84.03.277.6744275.3488476.279070.0257490.0164010.018775heartdisease1312.010.611.253.8819453.8819453.881940.2159780.2172540.173576表2DFS、CFS和CFSPabs特征子集评价准则的顺序前向特征选择算法的5折交叉验证实验结果glassdermatology3433.231.424.295.5229592.5124491.678251.0595121.5258411.553808handwrite25537.2139.413.698.7784198.7594798.4517841.260441965.3691922.932ionosphere3420.818.818.892.2937692.0080593.150910.7402450.9797450.945958WDBC3028.014.015.064.6802663.0904263.090421.3162941.5848821.532996WPBC3329.45.66.276.2955577.3353675.782730.4662180.7947590.797613winethyroid-disease54.84.24.277.6744276.2790776.279070.0319250.0197460.021291heartdisease1313.011.812.453.8819453.8819453.881940.1991130.18534340.161913表3DFS、CFS和CFSPabs特征子集评价准则的顺序后向特征选择算法的5折交叉验证实验结果实验采用林智仁教授等开发的SVM工具箱[22],核函数采用RBF(RadialBasisFunction)核函数[23].为了更客观地比较基于不同特征子集评价准则的特征选择算法的性能,对各特征子集评价准则进行性能比较,本文各算法的核函数参数均采用默认值.为测试提出的DFS特征子集评价准则的有效性,将其与CFS以及提出的CFSPabs特征子集评价准则进行实验比较.3种分别基于DFS、CFS和CFSPabs不同特征子集重要性(区分度)评价准则与SVM的特征选择算法的实验结果如表2~表5所示.表中数值为各算法5折交叉验证实验对应实验结果的平均值,加重和加下划线的被选择特征数、测试集分类正确率、运行时间(以s为单位)分别表示最小的特征子集规模、最高的分类正确率、最快的运行速度.为了更清楚地展示特征依次被选入(或依次被剔除)时,相应SVM的正确率变化情况,以说明选择到多少个特征时才是最好的,图1、图2分别展示了基于SFS、SBS搜索策略,并分别以DFS、CFS和CFSPabs为特征子集重要性(区分度)评价准则,以SVM为分类工具的相应特征选择算法的训练正确率和测试正确率变化曲线.其中的训练正确率与测试正确率变化曲线是5折交叉验证实验的平均正确率曲线.Page8glassdermatology3414.212.011.094.7359592.0103096.665380.9844290.6531620.505920handwrite2559.09.65.498.7737595.6771695.3599928.7375616.176669.902686ionosphere349.69.48.292.5835091.4406493.440640.6530620.3525740.334499WDBC308.86.26.269.1804574.9611474.961141.1037490.7232700.737452WPBC338.84.43.876.2955577.3353675.782730.4294130.2295710.212909winethyroid-disease54.44.24.277.2093076.2790776.279070.0241290.0178870.016580heartdisease1310.08.89.053.8819453.8819453.881940.1924410.1504920.155060表5DFS、CFS和CFSPabs特征子集评价准则的顺序后向浮动特征选择算法的5折交叉验证实验结果数据集原始特征数被选择特征数iris表4DFS、CFS和CFSPabs特征子集评价准则的顺序前向浮动特征选择算法的5折交叉验证实验结果数据集原始特征数被选择特征数irisglassdermatology3413.816.414.492.7130088.2902290.752681.3922213.9073373.215710handwrite2559.630.621.098.4612597.8362598.437552.188665838.7565656.66ionosphere3415.215.415.292.0120794.0080594.004020.8367112.6018332.362460WDBC304.03.02.662.9195862.7425962.919581.9093392.5219802.434949WPBC334.21.82.876.2955576.2955576.795550.5419721.6365161.524585winethyroid-disease52.23.22.478.6046578.6046575.348840.0303790.0179020.018788heartdisease133.44.63.653.5486153.8819453.548610.3052350.2629790.244258时间优于CFS和CFSPabs准则;而CFSpabs准则表2基于SFS搜索序策略的5折交叉验证实在3个数据集上较优;CFS准则在2个数据集上验结果显示,提出的DFS特征子集评价准则在iris,dermatology,handwrite,WDBC,thyroid-disease和较优.以上对于表2实验结果的分析得出:提出的heartdisease6个数据集上选择的特征子集的分类正确率高于等于CFS、CFSPabs准则选择的特征子DFS特征子集评价准则无论运行时间还是所选择集的分类正确率;CFS准则在glass,WPBC和wine特征子集的分类性能都较优,但所选择的特征子集3个数据集上的分类正确率超过DFS和CFSPabs规模不是最优的.然而从handwrite这一较高维数据集的实验结果来看,提出的DFS特征子集评价准准则;CFSPabs准则只在ionosphere一个数据集上则优于Hall提出的CFS特征子集评价准则.的分类正确率超过DFS和CFS准则.特征子集规模比较显示:CFSPabs准则选择的特征子集规模优表3基于SBS搜索策略的实验结果显示,在所选特征子集的分类正确率、相应特征选择算法的运于DFS和CFS准则.其中,在dermatology,glass,行时间两个指标的平均值比较上,提出的DFS特征handwrite和wine4个数聚集上优于DFS和CFS准则,在ionosphere和thyroid-disease数据集上等子集评价准则优于CFS和CFSPabs准则;另外,CFS和CFSPabs准则相比,后者优于前者.从选择的特于CFSPabs准则,优于提出DFS准则选择的特征子集规模;DFS准则只在iris数据集上与其他两个征子集规模来看,虽然提出的DFS特征子集评价准准则持平,在其他9个数据集上都不如其他两个准则只在handwrite数据集上较优,但是3个特征子集评价准则的比较可见,DFS准则在handwrite数据则;CFS准则在WDBC,WPBC和heartdisease共3个数据集上优于其他两个准则.运行时间比较显示:集上选择的特征数远远少于CFS和CFSPabs准则提出的DFS特征子集评价准则优于其他两个特征选择的特征数.虽然CFS准则在7个数据集上选择子集评价准则,特别体现在handwrite这类较高维的特征子集规模优于其他两准则,但是特征子集的规模差别不像DFS与CFS、CFSPabs在handwrite数据集的特征选择上,基于DFS特征子集评价准则的特征选择算法明显优于其他两个准则.10个数据数据集选择的特征子集规模差别那么突出.集的运行时间显示,DFS准则在5个数据集上运行以上表2和表3实验结果的分析得出:提出的测试集Page9Page10图1基于SFS搜索策略的DFS、CFS和CFSPabs特征子集评价准则的5折交叉验证实验的平均训练和测试正确率Page11Page12图2基于SBS搜索策略的DFS、CFS和CFSPabs特征子集评价准则的5折交叉验证实验的平均训练和测试正确率Page13DFS特征子集区分度衡量准则最好.其选择的特征子集不仅泛化性能好,而且对于较高维数据集的降维效果特别突出;另外,基于DFS特征子集评价准则与SVM的特征选择算法的运行效率较高.表4基于SFFS搜索策略的实验结果显示:提出的DFS特征子集区分度衡量准则在3个数据集iris、handwrite和thyroid-disease上选择的特征子集的分类正确率最高;CFS准则在glass、WPBC和wine3个数据集上选择的特征子集具有较高的分类正确率;改进的CFSPabs准则在Dermatology、ionosphere和WDBC3个数聚集上选择的特征子集分类正确率最好;对于heartdisease数据集,DFS、CFS和CFSPabs3个特征子集评价准则选择的特征子集具有相同的分类性能.特征子集规模分析可见,改进的CFSPabs准则在dermatology、glass、handwrite、ionosphere、WDBC、WPBC、wine和thy-roid-disease共8个数聚集上选择的特征子集规模不超过DFS准则和CFS准则,其中在WDBC和thyroid-disease两个数据集上与CFS准则相同;CFS准则只在heartdisease数据集上最优;提出的DFS准则只在iris数据集上选择的特征子集规模优于其他两准则.表5基于SBFS搜索策略的实验结果显示,提出的DFS特征子集区分度评价准则性能最优,因为基于DFS准则的顺序后向浮动特征选择算法的5折交叉验证实验,无论其选择的特征子集平均规模,还是其选择的特征子集的平均分类正确率,还是其平均运行时间都优于基于其他两个特征子集评价准则CFS与CFSPab的特征选择算法.表2~表5的实验结果还显示:对于较高维数据集进行特征选择,SFS特征搜索策略的运行时间低于SBS,SFFS搜索策略需要的时间低于SBFS.另外,从handwrite数据集的5折交叉验证实验的运行时间明显可见,除了采用SFFS搜索策略的特征选择算法外,其他以SFS、SBS、SBFS为搜索策略的3个特征选择算法,DFS特征子集评价准则明显优于CFS和CFSPabs准则.所得分类器在该数据集的泛化性能,无论采用那个搜索策略,DFS特征子集评价准则选择的特征子集的分类性能都最好.图1关于特征依次被选入时在10个UCI数据集的5折交叉验证实验的平均训练和测试正确率比较显示,提出的DFS特征子集重要性评价准则选择的特征子集具有更好的泛化性能,CFSPabs准则能选择到规模较小的特征子集.图1展示的详细实验结果与表2所示的实验结果一致.图2关于特征依次被剔除时的5折交叉验证实验的平均训练和测试正确率的详细结果与表3展示的实验结果一致.从图2实验结果的比较看出,提出的DFS特征子集评价准则选择的特征子集的泛化性能优于CFS和CFSPabs准则.另外,在handwrite这一较高维数据集,DFS特征子集评价准则不仅选择的特征子集的泛化性能很好,而且选择的特征子集的规模也小于CFS和CFSPabs准则.以上5折交叉验证实验的结果分析揭示:本文提出的DFS特征子集区分度衡量准则是一个很好的特征子集类间区分能力度量准则,基于该准则的特征选择算法所选择的特征子集具有很好的泛化性能,且对于较高维数据集,该准则不仅大大降低数据维数,还具有很高的运行效率,需要的运行时间最少.我们对CFS准则改进得到的CFSPabs特征子集评价准则所选特征子集的泛化性能与CFS准则选择的特征子集的泛化性能差别不大,但是基于CFSPabs准则的特征选择算法运行时间效率较高,且选择的特征子集规模优于CFS准则选择的特征子集的规模.5结论与应用前景展望本文提出了DFS特征子集区分度评价准则,该准则充分考虑特征之间的相关性,通过计算整个特征子集对于分类的联合贡献克服了单个特征区分度准则在衡量特征的类间辨别能力大小时,没有考虑特征之间的相关性对于单个特征辨别能力大小影响的缺憾,以及Hall提出的CFS特征子集评价准则对于特征之间相关性考虑不足和不适于连续性数值的缺陷.在此基础上,以DFS准则作为特征选择依据,提出基于不同特征搜索策略与SVM的4种混合特征选择算法.UCI机器学习数据库的10个经典数据集的5折交叉验证实验表明:提出的DFS特征子集区分度评价准则是一种有效的特征子集辨识能力衡量准则,基于该准则与SVM的混合特征选择算法选择的特征子集具有很好的分类效果,其泛化性能优于分别基于CFS和CFSPabs特征子集评价准则的特征选择算法,达到了保持数据集辨识能力情况下进行维数压缩的目的,特别是对较高维数据集,DFSPage14特征子集评价准则特别有效.实验结果同时显示:我们改进的CFSPabs特征子集评价准则优于CFS准则.本文实验还揭示,提出的DFS特征子集区分度衡量准则选择出了分类红斑鳞状皮肤病等疾病的有效特征子集,实现了对相应疾病的诊断.另外,伴着计算机网络带来的文本大数据,以及医疗诊断大数据和社会大数据,还有随着分子生物技术发展产生的癌症基因大数据,特征选择是对这些大数据进行分类分析的首要和关键步骤.本文提出的特征选择方法及其变种将在这些蓬勃兴起的大数据领域发挥重要作用.继本文之后,我们已经开展了关于癌症基因数据集的特征选择方法研究,并取得了很好的实验结果.
