Page1面向热点话题时间序列的有效聚类算法研究韩忠明1)陈妮1)乐嘉锦2)段大高1)孙践知1)1)(北京工商大学计算机与信息工程学院北京100048)2)(东华大学计算机科学与技术学院上海200051)摘要聚类热度时间序列是揭示和建模网络热点话题形成与发展的重要过程.Leskovec等人在2010年提出面向话题时间序列的K_SC聚类算法,其精确度较高且能较好地刻画话题内在发展趋势特征.但K_SC算法具有对初始类矩阵中心高度敏感、高时间复杂度等特性,使其难以在实际高维大数据集上应用.文中结合小波变换技术,提出一个新的迭代式聚类算法WKSC,主要提出两个创新:(1)用Haar小波变换将原始时间序列进行压缩,降低原始时间序列的维度,从而降低了算法的时间复杂度;(2)在Haar反小波变换中,将低维聚类返回得到的矩阵中心作为高维聚类的初始矩阵中心,在迭代聚类过程中优化了对初始矩阵中心高敏感性的问题,提高了聚类的效果.文中分别采用国内外3个数据集作为测试样本,进行了大量的实验.实验结果表明WKSC算法能显著降低聚类的时间复杂度,同时改进聚类效果.WKSC算法可很好的应用于大量高维热点话题的模式分析.关键词聚类;时间序列;热点话题;小波1引言交互式网络(WEB2.0)上的热点话题不仅极大地影响着虚拟网络社会中各种事件的形成与发展,同时也影响着真实人类社会中人们对于事件的看法和判断,甚至于影响着政府与司法机构对事件的判决.热点话题中的参与数量(如发帖数、转发数、评论数)是衡量话题热度的重要度量,这些度量随着时间而变化,呈现为一个时间序列.不同来源、不同媒介的网络热点话题的热度随着时间的发展呈现一定规律的变化[1-4],不同类型话题的发展趋势具有不同的规律性,如图1所示.其中图1(a)是关于劫持事件话题的热度序列图,有数个高峰,衰减速度比较缓慢;图1(b)是关于艺人大婚话题的热度序列图,只有一个高峰,人们对该事件的关注度很快下降,具有“高挥发性”的特点.由此可见网上的话题呈现出丰富的时态信息.对热点话题的热度时间序列进行聚类并建模分析[5-6],从而了解话题的传播模式,这个研究方向已经引起了大量学者的高度兴趣.对热点话题聚类通常采用的方法有两种:(1)基于内容对热点话题聚类;(2)基于时序特征对热点话题聚类.基于内容的话题聚类技术可以有效地识别和跟踪具有相似内容的话题,被广泛地应用在TDT和文本分析领域.但是这类方法无法刻画话题的发展趋势,难以满足对话题建模的需要.而基于时序特征对热点话题聚类则将焦点定位于话题的发展趋势,较少考虑话题内容.这类方法的聚类结果可以刻画话题的发展趋势,为话题建模和预测奠定基础.Yang等人[7]致力于基于时序特征对热点话题进行聚类,提出了基于话题热度趋势的K_SC聚类算法.K_SC算法为了刻画两个话题发展趋势的内在规律特征,提出了新的时间序列差异度公式,保证任意两个时间序列的相似性只与它们的趋势走向有关,而和它们的峰值数值以及在何时达到峰值无关.实验表明该算法对话题聚类具有很好的效果,但其对初始类矩阵中心的高度敏感、高时间复杂度使其难以在大数据集上应用.本文针对K_SC的高时间复杂度、对初始类别矩阵中心高度敏感特性进行了一系列改进.在其基础上融合了小波变换技术的思想[8],采用了降维、逐层更新各个类的矩阵中心的方法,提出新的聚类算法WKSC(Wavelet-BasedK_SCAlgorithm),并采集实际数据进行了大量的实验分析.实验结果表明WKSC算法在与K_SC算法同一实验条件,同一数据集的前提下能有效降低聚类的时间复杂度并提高聚类的质量.本文第2节回顾相关研究工作;第3节深入描述和分析WKSC时间序列聚类算法;第4节进行两个算法的复杂度理论分析;第5节描述本文的实验设置与实验结果分析;第6节进行总结并探讨下一步可能的研究方向.2相关研究2.1时间序列聚类相关研究时间序列聚类是一种完全根据数据自身所提供的信息进行分类的一种方法,因而要求面对数据挖掘的聚类算法应具有一定的自适应性.文献[9]提出了分割时间序列的方法,对分割后的子序列进行聚类、分类、异常检测、时间序列建模;文献[10]提出了用OLS算法实现对在线时间序列的分割,OLS算法能够有效地在线检测出数据挖掘应用中感兴趣的关键变化点,而且“过拟合”程度低;文献[11]提出了将时间序列进行线性划分的方法,利用线段来近似表示时间序列从而获取时间序列的变化趋势,这一研究工作让后来的研究者产生了如何通过降维的时间序列最大程度地保留原时间序列的信息的想法;文献[12]对文献[11]提出线性划分方法进行了详细的评述并予以扩充;文献[13]提出了基于斜率提取Page3边缘点的时间序列分割.2.2热点话题建模与聚类相关研究近年来,大量研究者对网络上的话题与行为进行了深入研究,这些研究表明用户的行为(话题)可以被建模和理解,但首先需要对话题进行聚类.文献[6]开启了人们对互联网上人类行为动力学的研究,指出人类行为的特性不能用传统的泊松过程进行描述,可能存在复杂的动力学机制.随后学者们展开了大量的相关性研究和考证.文献[14-15]研究了人们在博客系统和评价网络中的级联行为,结果都非常符合文献[14]提出的长尾理论;文献[16]打破了前人用局部特征表征整个序列的方法,提出了基于全局相似性的GSClu算法,用来进行序列的聚类.但是要对互联网上人们的行为进行建模却是一件很困难的事,因为隐藏在这些背后的行为是高度不可预测的[5-7].从海量的数据中挖掘有价值的信息是数据挖掘研究的目标,数据聚类是数据挖掘中最常用、最有效的手段之一.层次聚类算法和基于划分的K-Means聚类算法是最主要的两种聚类方法.层次聚类算法通用性强,但只能被应用在小数据集上;基于划分的K-Means聚类算法简单、快速而且能有效地处理大数据集,但需要事先定义类的数量,距离矩阵公式不合理且时间复杂度高.针对K-Means算法应用在时间序列问题上的主要缺点,文献[7]提出了K_SC算法,定义了新的时间序列差异度公式和更新矩阵中心(简称距心)的公式,但并没有解决高时间复杂度的问题.3WKSC时间序列聚类算法3.1相关定义热点话题.对于一条消息(帖子、微博),如果该消息在其所在的网站被标注为热点话题,或者评论(转发、回复)超过5000,我们称之为热点话题.热度.对于一个热点话题,在时间间隔Δt内被关注(用户发表评论和对该热点话题的报导)的次数称为该热点话题在时间间隔Δt内的热度.热度序列.通过记录一定时间范围内的热度值能得到关于该话题热度的时间序列,称为热度时间序列,简称热度序列.根据话题热度序列,可以画出热度时间序列图,表示该热点话题的关注度发展趋势,即该话题受到的关注度是怎么随着时间的推移而发生改变.中心曲线.聚类结果的每一个类别中所有时间序列成员共同形成的矩阵中心曲线称为中心曲线,每一个类的矩阵中心表示该类成员的共同模式特征.我们旨在用比K_SC算法更短的执行时间将具有相同发展趋势特征的时间序列聚在同一个类里,不同趋势特征的时间序列聚在不同类,其中第i个类用Ci来表示.3.2K_SC算法分析文献[7]为了刻画两个话题趋势的内在规律特征,提出了新的时间序列差异度公式,保证任意两个时间序列的相似性只与它们的趋势走向有关,而与它们的峰值数值以及在何时达到峰值无关.K_SC算法采用了基于划分的聚类方法,先随机地把所有的时间序列进行分类,根据矩阵中心计算公式计算出每个类的矩阵中心.再根据算法定义的差异度矩阵,把所有的时间序列归类到和它差异度最小的类中,最后更新该类的矩阵中心.K_SC算法是一个迭代过程,其停止条件是每类中的成员不再变化或达到预定义的迭代次数.最后形成的聚类成为最优分类.(1)差异度公式其中,狔(q)表示时间序列狔经过q个时间单位的平移后所形成的时间序列,并且狔(q)和时间序列狓的峰值处于同一时间点上;α为比例系数,即将狓和狔(q)置于同一时间轴时,峰值的比例系数,y轴的最大值量化为1.式(1)表明任意两个时间序列的相似性只与它们的趋势走向有关,而和它们的峰值数值以及在何时达到峰值无关.(2)更新矩阵中心公式其中犕=∑狓i∈CK之后的矩阵中心,狓i表示第i类的各个成员.式(2)本质在于找到该类中的新矩阵中心,使其和类中所有成员的平方和最小,降低了类中离异值的影响.3.3WKSC算法K_SC算法的时间复杂度很高,对于100个具Page4有128个时间点的序列,算法迭代过程中每次都需要100×1283=2097152000次的差异度计算.此外,K_SC算法对初始类的选择很敏感,如果初始类选择较差,则聚类的收敛过程非常缓慢.如何在聚类过程中进行降维,提高算法对初始数据的有效选择以致降低聚类算法的时间复杂度是本文算法研究的出发点.本文在小波变换[8]的基础上提出了改进的K_SC算法,称为WKSC(Wavelet-BasedK_SCAlgorithm)算法.WKSC可以分为两步:(1)小波分解;(2)还原高维并聚类.WKSC算法利用小波技术对高维数据进行分解,可以实现高维数据的降维,在低维数据上进行聚类,具有很高的效率,再把低维聚类的结果作为迭代的基础就能有效解决K_SC算法对初始类别的敏感性问题.我们采用Haar小波实现高维数据的降维[8],Haar小波是通过把维度为N的时间序列的两个相邻值取平均值的方法,得到一个平滑的、N/2维度的新时间序列,并记录这两个相邻值的差异值,用作反小波变换的参数.WKSC算法通过将所有的热度时间序列都进行完全小波变换,即经过logN2(N指时间序列的维度)层的变换,最终一个时间序列的维度为1,如图2所示.然后从低维序列开始进行聚类,聚类算法采用K_SC的核心.由于数据维度很低,所以聚类将很快完成,但是低维数据无法刻画原始序列的趋势和特征,聚类得到的成员和中心曲线效果都可能较差,所以我们根据反小波变换,将序列逐步进行高层次的还原,对高层次的序列进行聚类,并采用低维聚类结果作为高层聚类的初始矩阵中心.图2热度时间序列的Haar小波变换过程示意图算法在迭代过程中,采用两种结束条件:(1)如果低层时间序列的聚类情况在高层聚类时没有发生改变则跳出整个循环,迭代结束,聚类完成.(2)指定算法在反小波变化到指定层次时,迭代结束,聚类完成.具体算法描述如算法1所示.算法第1行到第3行进行不同层次的离散Harr小波变换,得到每次变化的结果,存储形式为向量.第4行到第10行对不同层次的时间序列进行聚类.首先对最高阶的变换结果进行反小波变换,得到压缩比例最高的序列,对其进行K_SC算法聚类,其值作为下一次聚类的初始值,然后依次循环,直到算法结束条件为真.算法1.WKSC算法描述.输入:N个维度为L的时间序列,K个随机类C=输出:K个类的矩阵中心定义:起始层用S表示1.fori=1toNdo2.狕i←DiscreteHaarWaveletTransform(狓i);3.endfor4.forj=Stolog2(L)do5.fori=1toNdo6.yi←InverseDiscreteHaarWaveletTransform7.endfor8.(C,μ1,…,μk)←K_SC(狔,C,K);9.if(finish(C))break;10.endfor11.returnC,μ1,…,μk.4复杂度分析在评价K_SC与WKSC聚类算法的时间复杂度时,我们均做如下假设:有N个时间序列,每个时间序列的维度为L,初始定义类的个数为K.4.1K_SC算法复杂度分析在更新每个类的矩阵中心步骤时,计算每个时间序列的矩阵犕(见式(2))及其特征值的时间复度为O(L3),那么计算全部类的矩阵中心的复杂度为O(max(NL2,KL3)).挑选出每个类所属成员需要花费O(KNL),所以执行一次K_SC算法的聚类时间复杂度为O(max(NL2,KL3)).由于K_SC算法对初始矩阵中心的高度敏感性,通过调用K_SC算法多次,反复更新矩阵中心才能达到聚类最优,最终聚类完成.假设需要迭代的次数为P,则其时间复杂度是O(P×max(NL2,KL3)).4.2WKSC算法复杂度分析在WKSC算法中,计算每个时间序列的完全Haar小波变换需要耗费O(L)的时间,设L=2n.当Page5对处于i层的时间序列(维度为2i)进行WKSC算法聚类时,同样需要计算每个时间序列的矩阵犕和犕的特征值,其复杂度为O((2i)3).设Li=2i,所以Li=L/2n-i,那么第i层计算每个时间序列的矩阵犕和其特征值的复杂度为O(Li)=O((L/2n-i)3)=O(L3/23×(n-i)),所以执行一次WKSC算法的聚类时间复杂度为相对于K_SC算法的聚类时间复杂度而言,由于WKSC算法中参与聚类的时间序列的维度比原始时间序列的维度缩减了很多,从而降低了复杂性的阶数.WKSC算法和K_SC算法初始的矩阵中心都是随机的,但不同之处在于WKSC算法将低维聚类矩阵中心作为高维聚类初始矩阵中心,这就让矩阵中心在低维时间序列的聚类中逐渐趋于最优值,在WKSC算法运行到高维时间序列时,调用聚类算法的次数也将显著减少.5实验比较与分析5.1实验设置实验共使用3个数据集,前两个数据集均来自Stanford大学①.MemePhr数据集选自博客和网站上的1000个热门帖子和新闻,以每小时的评论数作为热度,维度为128;Twhtag数据集选自twitter上的1000个热门帖子,以每小时该话题被提到的次数作为热度,维度为128;第3个数据集来自我们从天涯和百度贴吧上采集的314个热门话题(简称为ChinDt),以每小时的评论数作为热度,记录热度时间序列,维度为256.本文的实验均在同一平台之下进行,我们采用matlab实现WKSC聚类算法②.MemePhr数据集的大小为125KB,Twhtag数据集为120KB.ChinDt原始数据集大小为11.8MB,经过预处理后的结果为771KB.5.2实验结果与分析我们对K_SC和WKSC算法分别进行了不同粒度上的效率和效果评价实验.文献[7]的实验中,类别个数设为6,为了客观比较,本文也选择聚类的类别个数是6.5.2.1K_SC算法和WKSC算法效率比较因为K_SC算法无法对维度进行分层处理,所以需要将2个算法在同一个维度下进行实验.数据集ChinDt计算到维度256,其它两个数据集计算到维度128.对K_SC和WKSC算法在3个数据集下进行聚类所消耗时间结果如图3所示,其中时间单位为s.图32个算法在3个数据集下的消耗时间结果从图3上可以看出两个结论:(1)相对于K_SC算法而言,WKSC算法所消耗时间对不同的数据集都有了较大的改进,至少减少了30%的时间;(2)K_SC算法对序列的维度和发展变化特性的敏感性高于对序列个数的敏感性.如Twhtag数据集中的序列个数要比ChinDt数据集中序列个数多2.18倍,但是K_SC算法所需时间并没有显著减少.其原因是ChinDt数据集中序列变化趋势比Twhtag数据集中的序列变化趋势复杂、维度高.由于WKSC算法采用了降维和提高初始类比精度的策略,所以虽然ChinDt数据集的维度较高,但是也能在短时间内进行聚类.话题热度序列聚类的目的是探索其发展趋势,可以用中心曲线来直观地展示聚类的效果,表示出每个类中成员的共同模式特征.图4~图9给出了两个算法对不同数据集聚类得出的中心曲线.中心曲线结果图上每一个曲线代表一个类.从图4~图9上可以看出,MemePhr数据集下K_SC和WKSC算法的类别对应关系分别为(a)-(f),(b)-(b),(c)-(e),(d)-(a),(e)-(c),(f)-(d).Twhtag数据集下类别对应关系为(a)-(f),(b)-(a),(c)-(e),(d)-(b),(e)-(d),(f)-(c).ChinDt数据集下类别对应关系分别为(a)-(e),(b)-(c),(c)-(b),(d)-(f),(e)-(d),(f)-(a).说明:对应关系中前者为K_SC算法对应的类,后者为WKSC算法对应的类.从中心曲线上分析,K_SC和WKSC算法得出的类别趋势基本相同,尤其是对于MemePhr和Twhtag数据集.对于ChinDt数据集,存在部分差异,但是每个类的发展趋势相同,差异在于趋势过程中的一些波动,但并没有造成序列趋势的改变.WKSC算法在反小波变换的过程中可以在任意维①②Page6图4K_SC算法在MemePhr数据集下的中心曲线图5WKSC算法在MemePhr数据集下的中心曲线图6K_SC算法在Twhtag数据集下的中心曲线Page7图7WKSC算法在Twhtag数据集下的中心曲线图8K_SC算法在ChinDt数据集下的中心曲线图9WKSC算法在ChinDt数据集下的中心曲线Page8度层次进行停止,我们计算了WKSC算法在不同维度层次下所消耗的时间,如图10所示.图10中x轴表示不同数据集的维度,y轴表示运行时间,单位为s.图10WKSC算法在3个数据集、不同维度下的消耗时间从图10上可以看出WKSC算法对于低维数据可以在很短的时间之内聚类完成,对于MemePhr图11低维MemePhr的中心曲线图12低维Twhtag的中心曲线和Twhtag数据集,维度为64时,WKSC所消耗的时间基本为K_SC算法的50%.对于ChinDt数据集,维度为256时,也比K_SC算法减少50%的时间.另外,当维度增大时,WKSC算法基本成线性比例增长.这说明WKSC算法对于高维数据具有较好的处理能力,可以在大量的实际高维话题聚类中使用.WKSC算法在低维层次聚类时具有很高的效率.那么,能否在低维层次就取得与K_SC算法相似的中心曲线,从而刻画话题趋势?我们选择MemePhr和Twhtag数据集在维度为64、ChinDt数据集在维度为128的情况下,算法得到的中心曲线,分别显示在图11~图13上.Page9图13低维ChinDt的中心曲线从图11~图13可以看出,WKSC算法在低维层次进行聚类时,得出的类别趋势与相同数据集高维层次下的结果一致,话题的发展趋势与波动均能清晰表达.这表明WKSC算法在低维层次聚类能够满足分类话题、发现话题趋势的目标.这个特性对于高维话题聚类具有重要意义,当话题的维度和数量很大时,可以用低维数据代替原始数据进行聚类,得出的中心曲线趋势能够刻画话题的发展趋势.5.2.2K_SC算法和WKSC算法聚类效果分析和作为一个聚类算法,不仅需要考虑到聚类的效率,还需要考虑类中的成员是否合理,也就是聚类结果的合理性问题.我们用2个指标分别从类内和类间评价了两种算法聚类结果的合理性.(1)F-Value(F值).F-value的计算方法如式(1).F-value刻画了每个类内部成员的紧凑度,F值越小表示聚类效果越好.(2)D-Value(D值).D=∑d^(μi,μj)2,其中μi是类i的矩阵中心,μj是类j的矩阵中心.D-Value代表类与类之间的差异性,类与类的矩阵中心D值越大表示聚类效果越好.表1给出了K_SC和WKSC算法在3个数据集下最高维度层次聚类的F值和D值.从表1中可以看出,无论类中成员的紧凑度还是类与类之间的差异度,WKSC算法的值都优于K-SC算法.这表明WKSC算法在降低时间复杂度的同时还改进了聚类效果,其原因在于WKSC算法改进了聚类的初始矩阵中心.表1两个算法在不同数据集下的犉值和犇值MemePhr数据集聚类算法F值D值K_SC83.83.47K_SC64.93.68K_SC36.010.1WKSC72.63.94WKSC56.24.36WKSC28.210.6如5.2.1节分析,WKSC算法在低维层次聚类时,效率和中心曲线都具有较好的表现.现在分析WKSC算法在不同维度层次的聚类效果,我们将3个数据集、不同维度层次下聚类算法的F值和D值列在表2中.表2WKSC算法在不同维度层次下的犉值和犇值MemePhr数据集维度F值D值32109.72.023260.33.896461.98.236475.83.506457.34.0312843.410.1612872.63.9412856.24.3625628.210.6通过表2的结果,我们可以看出随着Haar小波反变换到越高的层次,F值越小,说明各类成员的紧凑度越高;同样类与类之间的差异值越大,表示聚类划分的界限越清晰.在最高维度(也就是原始的时间序列)时,WKSC算法效果最好,但是时间复杂度也最高.从表2的数据还能看出,WKSC算法对MemePhr和Twhtag数据集在64/128维度之间、ChinDt数据集在128/256维度之间的聚类差异并不显著,说明了WKSC算法在较低维度时已经取得了较好的聚类精度,却可以降低较多的运行时间.这个实验结果同样表明了对于高维时间序列,WKSC聚类算法可以通过降维来获得好的效果和效率.Page106结论与总结分析和建模交互式网络上的热点话题是一个具有很大挑战性的研究问题,而对话题热度进行聚类则为建模提供了一个有效的手段,本文针对热点话题的热度时间序列聚类开展了一系列研究与实验.首先总结了已有的聚类算法以及目前的应用研究热点,分析了K_SC算法的优点以及高时间复杂度等特点,基于小波变换提出了WKSC算法.我们在3个各具代表性的话题上进行了大量的实验,从不同角度分析和对比了K-SC算法和WKSC算法的性能.实验结果表明WKSC聚类算法可以有效降低聚类时间复杂度,平均意义下可以节省50%的消耗时间.WKSC算法可以满足高维大数据集的聚类需求,在实际使用时能取得很好的效果.利用WKSC算法对互联网上的海量热点话题进行聚类,从而发现更科学合理的话题类型、应用话题的中心曲线进行建模分析都将是未来值得研究的问题.在大规模数据上应用WKSC算法时,如何根据话题数据特征,自动设定与调整K值,也是值得进一步研究的问题.
