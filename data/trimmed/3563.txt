Page1基于Bayes规则与HMM相结合的步态识别方法研究余涛邹建华(西安交通大学系统工程研究所西安710049)(西安交通大学系统工程国家重点实验室西安710049)摘要提出一种将Bayes规则与HMM相结合的步态识别方法.检测环节通过采用重心变化作为特征序列来削弱时间差分算法中运动实体目标存在中空的负面影响,通过对检测出的目标特征序列采用直线拟合提取对称轴,并等效转化为具有方向性的点线距序列,来简化运算,降低失真度.步态训练中,通过初始化的修正使训练出的HMM接近全局最优,并给出Bayes相关先验学习方法.步态识别中,应用HMM的前-后向算法,并融合Bayes规则,客观性增强,最终结果经中国科学院CASIA的原始步态视频测试,达到比较高的识别率,且对衣着具有一定鲁棒性.该文方法主要针对视角在0°~180°间的室内监控直道行走场景.关键词HMM;Bayes规则;步态;识别;序列1引言步态作为一种生物特征中的行为特征,对其检测和识别不需要身体接触,可在低分辨率图像序列中进行,是唯一一个可在远距离识别的生物特征且难以伪装和隐藏,这些特点使得有关步态识别的研究近年来备受关注[1].步态识别的基本任务是根据拍摄的人的行走视频,自动提取表征步行特征的视觉线索,通过人体走路的方式来鉴别人的身份.其主要环节包括:步态预处理、步态检测、步态特征的提取与表征和步态特征识别.步态预处理是将前景运动目标从背景中分割出来.主要方法:背景减除法、时间差分法和光流法[2].步态检测是用知识或统计的方法对步态建立模型,比较所有可能的待检测区域与步态模型的匹配度,从而得到可能存在步态的区域[3].主要检测步态周期,而且步态轮廓的有效分割对于后期处理也非常重要.常用方法:差分图像、互相关分析、时空梯度[4]等.步态序列的特征提取及表征主要分为两类:结构化(模型)方法和非结构化方法.前者对人的身体结构或运动进行建模,通过提取图像特征并且映射它们到模型的结构分量或导出体元的运动时间轨迹来识别个体[3].常对人体建立2D或3D模型[5-6];后者不考虑潜在结构,而是特征化人体整个运动模式以得到简洁的运动特征表达[3].通常输入的步态特征维数较高,一般要选取如主元分析(PCA)[7]、多元判别分析(MDA)[8]等适当方法来降维.步态特征的分类识别通常也分为两类:模板匹配方法(TM)和状态空间方法(SSA).前者将图像序列转换为一组静态形状模式,然后在识别过程中和预先存储的行为标本比较,以某种相似度作为分类标准[9-11];后者定义每个静态姿势为一个状态,状态间通过某种概率联系起来.任何运动序列可看作这些静态姿势的不同状态间的一次遍历过程,在遍历期间计算联合概率,其最大值被选择作为分类标准[9].常用隐马尔可图1本文的步态检测及识别总体框架夫模型(HMM)[12-13]、动态时间规划(DTW)[14]、神经网络(NN)[15]、支持向量机(SVM)[16]等.由于目前计算机视觉领域中从运动目标的检测跟踪到目标识别,每个环节的问题都还没有完全解决,所以很多实际步态识别框架跳过了检测跟踪环节的实时性、精确性要求,用已经预处理过的,图像分割较好的运动目标且从多参数多维空间的角度进行研究.当前,时间序列问题成为运动行为识别分析研究的热点方向,以HMM为代表的状态空间法已被广泛应用于时间序列的检测、估计和预测识别中.而在识别时,无论是选择何种特征,随着样本数量增多,不同样本间的特征相似的可能性自然会增大,这时若仅依靠现有的特征去判别,很有可能识别错误,此时若能合理地融入一些有利于区别个体的先验客观因素,适当兼顾识别问题的实际客观背景情况,将更有利于准确识别.同时,对这种先验的获取,若能从实际历史的训练学习中获得,而不是主观设定,也将会有利于确保先验知识的客观性.本文直接从原始步态视频入手,对实际目标先通过时间差分方法进行检测跟踪;通过检测目标的重心变化,得到相应特征序列;再对该特征序列通过自适应滤波、中值滤波、直线拟合、等效旋转、规则化、最近邻聚类和周期提取一系列处理后,作为特征观测序列;在进行身份识别时,根据事先通过Baum-Welch算法训练好的(训练前,初始的状态观测矩阵犅,通过Veterbi算法,结合相应观测序列O,被统计修正)若干HMM,通过前向-后向算法,并结合带有训练学习获得的先验知识的Bayes规则,对目标进行身份识别;最终通过用中国科学院的标准CASIA视频库的一些原始视频进行了相关实验,得到较高的识别率,且对衣着具有一定的鲁棒性.该方法适合于视角在0°~180°范围之间的室内监控直道场景.2方法原理本文的步态检测及识别的总体框架如图1所示,Page3主要包括两部分:步态特征的检测与提取;(HMM+Bayes)规则的训练和识别.以下将对框架中的两部分分别阐述.2.1步态特征的检测及提取在对目标的检测跟踪环节中,先将原始视频图像转换为单通道灰度图像,再进行高斯滤波平滑图像,然后采用类似文献[17]中的三帧差分转化为二值图,具体计算如下:式中:Tn(x)表示在像素位置x处的具有统计意义的描述灰度变化的域值.当某像素位置x处的灰度值In(x)相对上一帧In-1(x)和前一帧In-2(x)都有较大变化时,则认为该点像素属于运动目标,这样将运动目标从背景中分离出,重复操作即得到一系列前景目标图像.由于该方法对检测出的运动目标区域内部通常产生中空,而目标重心的计算公式中的求和运算具有正负抵消的作用,这样一定程度上消除了中空对特征检测的影响,因此后续的目标特征选取为目标的重心变化,计算如下:x重(i)=1依次求出每一帧图像的目标重心,就可绘出目标的重心特征的运动轨迹,如图2所示.图(a)为原始视频截图,图(b)是将上述时间差分法得到的运动目标的灰度图转换成彩色图,并连续描绘出过去时间内的运动重心变化的特征曲线.将此特征序列处理如下:由于目标在开始进入场景及最后即将离开场景时,只有部分轮廓可以检测到,所以那段时间得到的特征点为不规则点,因此首先通过设定域值去掉首尾两端部分的不规则点.然后滤波去噪.由于特征序列信号的周期变化形式多种多样,所以这里采用由文献[18]提出的一种自适应最小均方误差算法进行滤波,即自适应滤波,滤波原理如图3所示.结合本文应用,图3中:X(n)对应检测出的特征序列的横坐标(或者称为时间顺序号),Y(n)对应该序列的纵坐标,A为标量权系数,W(n)对应图像或视频中常见的高斯噪声信号,通常W(n)为平稳随机干扰信号且与X(n)互不相关,可看出:{利用Y(n)和X(n)可得到S(n)的估计,相应的自适应估计算法如下:^S(n)=^A(n)X(n)^A(n+1)=^A(n)+2μ(Y(n)-^A(n)X(n))X(n选择^A(n)的初始值^A(0),根据文献[18],只要满足:0<μ<1/R,其中:R=E[x(n)x(n)T](5)^A(n)总可以收敛于最佳值A(n),^S(n)也逐渐收敛于S(n).本文实验中发现:对检测出的特征序列按照上述自适应估计算法迭代两次(其中,第2次滤波各点的输入是在第1次滤波的末端点值的基础上继续累加)就得到比较平稳且原信号变化失真较小的特征序列,如图4中点划线所示.可看出,虽然由于滤波迭代计算中的初始累加,使得滤波后的信号幅度整体略大于滤波前,但相对变化趋势基本得以保持,本文研究的正是信号的这种相对变化特征.图4对特征曲线进行滤波前后的效果比较图自适应滤波后,再采用中值滤波进一步去除由噪声引起的序列局部抖动误差,或称为序列中的毛刺误差,具体将原序列中的每一点的值和其邻近两Page4侧值进行比较,三者中按大小排序,取中间值作为当前点滤波后的值,然后依次类推.滤波结果如图4中实线所示.上述滤波完成后,再利用最小二乘法对序列进行直线拟合以求出曲线的拟合中心轴,拟合计算如下:x-=1烄x2=1烅k=(xy-x-·y-)烆其中:M为特征序列点数目,k为拟合直线斜率,b为拟合直线截矩.通常在得到曲线的拟合中心轴后,需要计算出该直线倾角,再按照该倾角大小根据对应象限,将序列各点反向旋转,即将曲线的中心轴旋转至水平轴上,这样的计算效果往往累积误差较大,失真度较严重.本文采用的方法是直接计算出特征序列的各点至该拟合直线的距离,以这些距离作为新的序列值的绝对值,以原特征序列的各点相对拟合直线上对应各点的高度正负作为新的序列值的正负号,这实际上相当于实现了原特征序列的中心轴向水平轴的旋转,相应原理如图5所示,计算如下:其中,li为重心序列中某点x重(i),y重(i())距拟合直线的距离,上式去掉绝对值后,正负号表示特征序列相对拟合直线的上下变化式(7)即为新的特征序列的计算公式.之所以要等效完成这样的旋转是因为实际监控通道的方向往往相对监控终端界面的坐标轴有所倾斜,通过上面的变换等价于旋转监控通道方向轴,使其与监控终端界面的坐标轴平行.从而减小了由实际的通道倾斜使目标特征检测误差增大的影响.然后将上述经过等效对称轴旋转后的序列,按下式所示,通过除以序列中最大幅度的绝对值实现归一化:最后,根据步态的周期性,对得到的归一化序列,按图6所示,实现观测值的最近邻聚类,本文设定9种状态值,5种观测值.图6中可看出,观测值在对称轴附近为1,然后依次向对称轴两侧等间隔划分,观测值大小依次递增.这种划分与实际步态特征序列的变化幅度方向相一致,使其对步态信息的反映更直观.这样就得到一组观测值序列,其式如下:argminoi∈Oli-o()i=oi,0iT(9)本文在训练阶段,采用多个特征观测值序列训练,每个序列多个周期,这样使训练中的样本尽量充分;在识别阶段,采用单个特征观测值序列识别且对该序列只抽取一个周期.对于周期的确定,结合图6可以看出,需要求解出任一最高观测值与相邻的最低值的间距,考虑到实际曲线可能出现的非正规对称,这里是以某个最高观测值(或最低观测值)为基准,取其两侧当中相距较远的最低观测值(或最高观测值)对应的间距,将此间距乘以4倍即为一个周期.即式(10)所示:式中:no5,no1为上图中相邻的最高、最低观测值在观测序列中的对应序号.2.2HMM与Bayes规则的相结合的训练及识别本文在对HMM训练中,参考了文献[19-20],主要综合应用了文献[20]中为克服可能因结果过小出现“下溢”现象而引入比例因子加以修正后的Page5HMM相关的3种基本算法,即前向-后向算法,多序列训练的Baum-Welch算法和Viterbi算法,并设计出相关的修正初始化,实现了对HMM:λ=(π,A,B)的训练.这里设状态数目为N;每个状态有M个观测值;π=(π1,π2,…,πN)为各状态初始向量;犃=(aij)N×N为状态转移概率矩阵;犅=(bij)N×M为状态观测概率矩阵;犗={o1,o2,…,oT}为观测值序列;犙={q1,q2,…,qT}为状态序列.对HMM的整个训练流程如图7所示.由于实际对HMM训练时,不同初始模型将产生不同的训练结果,而训练算法是在使P(犗/λ)局部极大时得到模型参数,因此应选取适当初始模型,使最后求出的局部极大尽量接近全局极大.因为通常πi,A的初值选取对HMM的训练影响不大,而犅的初值影响较大,所以本文训练中的初始修正也主要针对状态观测概率矩阵犅.图7中,在最初始的HMM中,犃,犅和π都采用随机阵列表示,且满足下式条件:然后根据各样本的观测序列,通过Viterbi算法得到相应状态序列,再结合状态序列和观测序列,得到部分状态观测的统计频率值,用此统计频率值代替最初犅中相应的元素,从而修正犅中部分元素,对于未修正的元素,仍采用最初的随机数表示.最后用这种经过部分修正的犅,代替最初的犅,结合原先的犃,π,作为初始化的HMM,通过Baum-Welch算法进行训练.修正犅的示例如下:假设对某个HMM,给定观测序列犗及最初在满足式(11)的前提下,通过随机设置给定犃,犅和π,如下所示(假设状态种类数N为3,观测种类数M为3):犗:132232132犃:0.200.600.200.250.250.500.250.500.250.200.300.500.350.150.500.450.050.50π:0.500.250.25根据上述犗,犃,犅,π,通过Viterbi算法得出对应的状态序列犙为结合上述观测序列犗和对应状态序列犙可以看出:需对状态1,2的观测概率分布(对应上述矩阵犅的前两行)进行修正,而状态3的观测概率分布保持不变,则对上述矩阵犅修正如下:犅:将新的矩阵犅,结合上述的犗,犃,π作为初始值,通过Baum-Welch多序列训练算法并结合前向-后向算法判断P(犗/λ)的收敛性,即可得出模型参数犃,犅,π的最终估计值.从原理上可看出,该方法要求样本的观测序列要尽量充分.后面的实验会发现:在较充分的样本下,该训练方法得到使得对应的P(犗/λ)接近全局最大的比较精确的HMM:λ.由于HMM实质上是一种统计意义下的有限状态机,当前它已被广泛应用于对时间序列的识别过程中[21].人的步态可看作是从一个具有结构化概率本质关系的序列中采样的一个姿态集合,这些被个体采样的姿态可作为HMM的状态,它们对于个体来说具有典型代表性,因此可作为个体的判别手段[12].结合本文研究目标,在步态识别中可以对每一个人建立一个HMM:λ=(π,犃,犅),即用3种参数Page6综合表示一个人的步态身份.犗表示步态序列在某一时刻的特征观测向量.随着步态运动的延续,产生犗1,犗2,…,犗T等一系列的观测向量,这里的目标就是通过这一系列的观测向量序列,寻找产生这一观测序列在概率意义上最大的HMM:λ.如果不考虑先验知识P(λ),通过前向-后向算法所求得的最大P(犗/λ)对应的HMM:λ,将作为相应身份识别的结果.如果考虑先验知识P(λ),根据Bayes规则,进一步求取:P(λi/犗)=P(犗/λi)P(λi)/P(犗)所求得最大的P(λ/犗)对应的HMM:λ将作为相应身份识别的结果.可以看出,考虑先验知识时,此时,某HMM:λ产生某观测序列犗的概率P(犗/λ)最大时,也并不意味着该观测序列属于该模型的概率P(λ/犗)最大,它还与P(λ)有关.联系到步态识别中,某人产生某种步态特征观测序列的概率P(犗/λ)最大时,也并不意味着该观测序列属于该人的概率P(λ/犗)最大,还与该人以往出没于该场景的概率P(λ)即先验知识有关.由此看出,先验知识的涉及将使得识别出的身份更加客观合理,后面的实验将进一步验证该性质.当然,此处要求事先对检测场景的以往历史中,出没的各种身份的人的概率进行统计,统计方式为多种.计算某人的出没概率时,通常有两种方式:(1)可按照某段时间内,目标出现的时间长度所占比率来表示.(2)可按照某段人流量中,目标出现的次数所占比率表示.上述统计还要求可在线更新.这里,在步态序列训练的过程中,同时对应用的Bayes规则中的相关先验P(λi)也进行了学习,其方法原理如下:假设总目标数为M个,最初每个被识别目标的训练样本数目相同,皆为m个,即各目标出入场景的次数均等,皆为m次,根据统计学中的贝努里定理,事件发生的频率以概率收敛于事件的概率,即当试验次数很大时,事件发生的频率与概率有较大偏差的可能性很小,此时,便可用事件发生的频率来代替事件的概率.而本文的训练样本,可认为是各目标的全部历史事件,即可认为试验次数充分大,则各目标出入场景的概率P(λ)=m/(mM)=1/M,若对应某人(i)的目标的训练样本数目增加了Δm个,则此时对应该目标(i)的出入场景概率P(λi)=(m+Δm)/(mM+Δm),其余目标(j)的出入场景概率P(λj)=m/(mM+Δm),j≠i.反之,若某人(i)的训练样本数目减少了Δm个,则将上述式中加号换成减号即可.对于其它目标的样本数目变化情况,可依次类推,这样就实现了对所有目标的对应先验P(λ)的学习.综上所述,本文对步态特征序列训练及识别的理论框架如下:(1)步态序列训练时,对随机初始化的观测矩阵犅通过Viterbi算法,结合相应观测序列犗,进行统计修正,然后用Baum-Welch算法训练出与各类观测序列对应的HMM:λi=(πi,Ai,Bi),i=1,…,M中的相关参数,同时根据各类λi的样本数目,对Bayes规则相关的先验知识P(λi)进行学习,最后对训练出的各类λi的相关参数及相关先验P(λi)建立数据库Database.(2)步态序列识别时,对前面训练中建立的Da-tabase库中的每一类λi,结合相应被测试的观测序列犗,通过前向-后向算法得出P(犗/λi).(3)将上述结果结合Database中的相关先验知识P(λi),再通过Bayes规则(即式(12))得出P(λi/犗).(4)比较各P(λi/犗),其中最大P(λi/犗)对应的λi其对应识别出的身份结果.3实验测试方案及结果分析在对整个检测及识别框架的测试中,本文以Pentium1.73GHz单CPU的台式机为平台,在VC6.0环境下编程实现其功能,通过标准的原始视频步态数据库,模拟测试在真实环境下对监控通道中实际目标的检测识别.最终,将相应结果的统计数据进行了曲线描绘,并进行了相关分析.本文的测试视频库采用的是中国科学院的CASIA步态数据库中的DatasetB[22].该数据集是一个大规模多视角的步态库,采集于2005年1月,共有124人,每人有11个视角(0°,18°,36°,…,180°),在3种条件下(穿较单薄的春夏季服装,穿较厚重的冬季服装及携带包裹)行走.其中第1种每人6个样本,第2和第3种每人各2个样本,因为本文主要研究基本步态,所以主要针对未携带任何物品的人的行走步态,即对前两种行走条件进行识别.试验中,对步态数据库B中的原始视频,选择样本数124人(即全部人数),视角选择是在18°~162°范围内以18°为间隔划分成几个常见视角.这里Page7分为样本模型的先验知识相同和不同两种情况分别测试.前者主要测试本文的训练HMM方案所对应的结果模型的精确性及最初的检测环节对识别效果的影响,同时验证前向-后向算法的精度,后者主要测试前者在融合了Bayes规则的客观合理性后对识别率的影响.(1)样本模型的先验知识相等的情况.此时Bayes规则对各模型的影响均等,因此从某种意义上,可认为Bayes规则此时不起作用,影响最终结果相对大小的,除最初检测环节外,识别环节只有前向-后向算法起作用.这里主要进行两项测试,并与文献[12-13,23-24]的典型方法进行比较,而且这些文献又各有两三种方法,这里选择它们各自当中识别率最大的方法对应结果进行比较.表1先验知识相等时第1种行走条件的不同视角下对应识别率方法本文方法95.5197.7696.393.690.5592.1395.4597.5494.23文献[12]方法91.1292.0392.892.9693.7592.8993.5893.3793.27文献[13]方法90.7592.4792.393.5992.3593.2293.1792.6991.93文献[23]方法80.0377.8676.979.1283.0480.2178.7877.9379.78文献[24]方法97.4397.5498.197.2797.6798.3298.2598.0897.86表2先验知识相等时第2种行走条件的不同视角下对应识别率方法本文方法80.3586.2481.2078.6572.4675.7683.2385.8877.69文献[12]方法10.4412.0911.6010.4512.029.799.9311.648.89文献[13]方法7.088.576.898.3511.049.537.796.566.35文献[23]方法9.7810.1210.4011.1612.469.258.875.357.67文献[24]方法22.3430.5625.1030.0236.2325.6826.9529.7327.46结合图8和图9,对比各视角可看出:视角在36°和144°附近时,如图9(b)、(h)所示,被测试的人的正面轮廓和侧面轮廓,几乎同时可以较完备地作为该人的整体轮廓观测出来.这样正面的手臂和肩图8Bayes规则先验知识相等时不同视角下的识别率比较第1项测试是在第1种行走条件下采用留一校验方法(leave-one-outcrossvalidation),取每人6个样本的中的5个用于训练,第6个用于识别,求出识别率,然后调换样本顺序,重复实验,最后求出识别率平均值;第2项测试是将第1种行走条件下全部样本用于对HMM训练,第2种行走条件下全部样本用于识别,然后求出识别率,以测试该方法对个体衣着的鲁棒性.相应测试结果如表1、表2所示,图8为对应两表的相关变化曲线.可以看出:本文方法在多个视角下的识别率总体普遍较高.这说明前面训练出的HMM具有较强的识别泛化能力,使得对应的P(O/λ)逼近了全局极大.也说明本文的检测识别框架具有一定合理性.识别率/%识别率/%部的左右摆动及侧面两腿的前后摆动,都会影响此时的整体轮廓大小、形状的变化,从而影响轮廓的重心位置的变化.也就是说,此时目标的重心特征序列的变化,相对其它视角,包含了更多的人体步态运动Page8图9不同视角下目标步态的重心特征曲线检测图正面和侧面两方面的个性化特征信息,个性化信息越强,从而使得特征序列间的区别增大,所以此时识别率相对其它视角较高.视角在90°附近时,如图9(e)所示,由于主要是侧面轮廓影响重心特征变化,目标正面的步态特征如手臂,肩部在正面的摆动几乎未刻画出来,从而特征间的差异相对其它视角有所减小,识别率较低.实验测试中还发现,人的步态多样性主要表现在每个人的步态对称性是不一样的.有些人的步态对称性在通常的视角范围基本可以观测到(具体又在幅度、周期及多种波的交替往复上存在差异),有些人的步态对称性在某一非常规方向才可以观察到,此时在常规方向的观测结果成杂乱无章的序列,从而使得这类人的步态在常规方向无法进行识别.当样本数量增多时,这类人出现的数量随着增大,从而使得识别率降低.因此可以设想:如果将步态特征曲线在三维空间中描绘时,可能会对各类人的步态得到更精确且更合理的特征描述,也将会使得试验对于大样本的识别率有所上升.在和其它典型同类方法的比较中,除在特征检测环节中各有不同外,文献[12]用背景减除的二值化图像作为特征向量,用分别基于向量差分正则化的1范数(SAD),2范数(Euclid)和向量正则化内积(IP)的3种不同距离矩阵,来度量特征向量间的相似度,从而估计相关的观测序列,用于HMM判别.文献[13]利用二值化侧面轮廓作为图像特征,分别采用直接(direct)训练HMM和通过生成低维的帧与样本的距离向量FED间接(indirect)训练HMM两种训练方法.两文献在对犅的初始修正都是在某种事先确定的函数下选取,最终识别率虽在不同视角下变化较小,但总体水平次于本文方法.文献[23]用自组织映射的码本向量及经过PCA降维后的向量两种特征向量分别来训练离散HMM(Dhmm)和连续HMM(Chmm),且未进行任何初始化,其识别结果总体上明显低于本文方法.文献[24]其特有的参数形HMM(Fhmm)特征级融合与并形HMM(Phmm)决策级融合的结构,很大程度上补偿了初始化犅的影响,这使得其在表1中总体效果优于本文方法,但在表2中的结果同其它3个被比较文献皆次于本文方法,即对目标衣着变化的鲁棒性方面性能均较弱.图8中的Max表示选取实验中识别率最大的文献对应处理方式进行比较。(2)样本模型的先验知识不等时,按前文所述,此时各HMM对应的目标出没于同一场景的概率Page9不同.这里对前述相等时的两项试验中那些检测出的相似度较大的特征曲线对应的测试样本进行区分(因为相似度较小时,测试样本的差异较大,通过前向-后向算法区别已经很显著,此时,Bayes规则虽然有作用,但无法直观看出,即此时起作用的因素很多,无法验证是哪个起作用),以针对性地验证Bayes规则的合理性.实验中将前面试验中部分识别错误的目标对应的训练样本数目改变,在对相应的HMM重新训练的同时,按第2节中先验的学习原理,此时需同时将所有训练出的HMM的先验知识概率按前述计算方法进行相应改变,最后全部测表3第1种行走条件的不同视角下Bayes规则先验变化的识别率比较Bayes影响Bayes规则先验相同95.5197.7696.393.690.5592.1395.4597.5494.23Bayes规则先验不同96.7999.0197.4596.6993.5695.4496.3798.8297.58表4第2种行走条件的不同视角下Bayes规则先验变化的识别率比较Bayes影响Bayes规则先验相同80.3586.2481.278.6572.4675.7683.2385.8877.69Bayes规则先验不同88.2194.5191.2588.3782.5685.1588.1292.2287.49图10Bayes规则先验变化时不同视角下的识别率比较考虑到实际监控环境中,被检测的各个目标在很多情况下其相关Bayes先验大都是不同的,因此用实际信息与历史信息相结合的方法来推断当前,使得识别结果更加客观而准确,从而提高了目标识别率.而此时个别的识别错误,主要是由于在前面环节中,对个别目标的检测部分及后续的前向-后向算法的误差相对偏大,使得Bayes先验概率的补偿有所降低造成.至于在某些情况下是否会使识别率降低,从统计概率理论的意义上讲,若先验知识准确可靠,则融入Bayes规则后,识别率应该是可靠性增强,即识别试样本再次进行识别,并与之前进行比较.结果如表3和表4所示,图10为相应比较图.可看出,在Bayes规则中先验不同情况下,从总体样本的测试来看,相比先验相同情况,识别率普遍提高,分析如下:根据各HMM对应的先验知识,当某人(对应λ)在过去的时间里,出没于某场景的概率较大时,则P(λ)较大,此时若该目标产生当前特征观测序列O的概率P(O/λ)也较大时,式(12)中右式的值变大,则对应的P(λ/O)值变大,即该观测序列属于该目标的概率增大.识别率/%识别率/%率提高,若先验知识不可靠,则无法保证识别结果的正确性.而本文是在假设具有可靠先验知识的前提下进行研究的.4结论本文通过对步态视频中运动目标的重心变化特征信息的获取及相关滤波、标准化、规则化、聚类等一系列处理后,根据Baum-Welch算法训练过的HMM,通过前向-后向算法,结合具有训练学习过的先验知识的Bayes规则实现了人体步态的身份识Page10别,由于融入Bayes规则后识别的客观性质增强,加上检测环节中重心特征曲线的检测减轻了时间差分算法目标中空的影响,检测出的曲线拟合的等效旋转简化了计算,降低了失真度.这些使得整个框架对直道类型的监控通道,具有较高的识别率,且对衣着具有一定的鲁棒性.由于从单个角度的获取步态信息仍具有局部性,本文的下一步工作将从多个角度同时获取步态信息,并对多种信息进行实时三维刻划及融合来对目标身份进行更准确的识别,并进行相关的行为理解.
