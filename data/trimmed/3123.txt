Page1PaSeM:并行无冲突的网络流量会话管理张建宇1)周渊2)邹维1)1)(北京大学计算机科学技术研究所北京100871)2)(国家计算机网络应急技术处理协调中心北京100029)摘要网络会话管理是网络流量监控、状态防火墙、入侵防御、网络地址转换、负载分流等网络在线业务的关键共性技术,对于准确、快速、灵活地跟踪、分析和处置网络流量中的协议交互过程、端对端行为和通信内容起着基础性支撑作用.近年来,随着P2P(Peer-to-Peer)、VoIP(VoiceoverIP)、网络流媒体等新兴应用的快速发展,网络流量和会话呈现爆炸式增长,如何实现高效的会话管理成为人们面临的一项挑战.文中提出了一种适用于并行执行环境的网络会话管理方案PaSeM(ParallelSessionManagement),采用基于散列表的无锁会话表设计和多种并行策略,讨论并解决了在高速网络环境下面临的各种并行冲突问题,给出了会话表查询和动态管理的高效并行算法,实现了对报文和会话的并行无冲突的高效处理.基于G/G2/n1排队模型和空竭服务多重休假M/G+D/1排队模型对PaSeM的性能进行了理论分析,对于稳态下并行处理单元(PE)数量、任务队列长度、存储开销与报文到达速率、会话到达速率之间的关系以及其它关键参数应满足的条件给出了定量计算方法.最后,采用基于IXP2400网络处理器的硬件平台进行了原型开发和实验.实验结果表明,PaSeM对于会话管理和报文处理具有较好的并行加速效果,理论计算值与实验值能较好地吻合,报文处理的并行效率均值接近1,当会话管理单元个数为4时,会话处理并行效率为65.4%(亦即加速比为2.62),当会话管理单元个数为8时,会话处理并行效率仍然达到了48.3%(加速比为3.86),能够满足当前高速网络环境流量处理的性能要求;在最大吞吐量负载下队列长度及其变化幅度都处于合理范围,会话表垃圾比率维持在较低的水平上(实验结果为小于9%),与已有的工作相比为优.关键词网络流量;会话管理;会话表;并行处理;并行冲突1引言随着P2P(Peer-to-Peer)、VoIP(VoiceoverIP)、流媒体、移动数据业务等网络应用日新月异的发展以及网络带宽的迅猛增长,网络基础设施和网络系统面临许多新的挑战.例如,网络流量监控、入侵检测和防御、状态防火墙、网络地址转换(NAT)、负载分流等网络在线业务均需要围绕网络会话实现对流量的实时、复杂的管理和控制[1-3],高速网络环境中网络会话往往达到几百万甚至上千万规模,其核心是实现高效的会话管理.一段时间区间内在两个通信端点(endpoints)之间产生的连续报文称为一条“会话(session)”.会话中的报文含有相同的关键码,如源IP地址、目的IP地址、源TCP/UDP端口、目的TCP/UDP端口和IP协议号.如图1所示,从时间轴上观察,每条会话的生命周期都包括开始、结束和老化等几个关键点[4-5].会话管理对每条会话的生命周期和状态变化进行跟踪,在会话表(sessiontable)中记录并及时更新每条会话的信息,包括时间戳、会话状态以及各种业务模块所需的参数,并针对流经的每个报文查询会话表,找到报文所属会话记录.业务模块根据这些信息对会话和报文实施各种处理操作,实现对流量的细粒度、精确及基于状态和时间的管理控制[1-2,5].当会话结束后,则要及时删除回收会话表中过期的会话记录.与常见的单向(unidirectional)“网络流(flow)”[4]不同,网络会话是双向(bidirectional)的,会话的第一个报文传输的方向一般定义为会话的“正向”,反之称为“反向”,即一条“会话”包含正向和反向两条“流”.两者的应用领域和应用场景有较大的差别.前者广泛应用于网络测量领域[6-9],所涉及的测量任务往往比较简单,需要记录的流信息较少且对于少量的分类和查询错误不敏感,因而网络流管理的研究重点在于:流表结构的设计,即如何将信息压缩保存到容量小、速度快的存储器件中,以降低I/O访存开销、提高性能以及依托于这些流表结构的高效的查询算法;报文采样[6,10]和流采样[7,9]技术,研究如何在减轻负载的同时保证测量的精度.后者则主要应用于许多复杂的在线业务,特别是一些网络安全业务[2-3,11-14],以实现对协议交互过程、端对端行为和通信内容的准确、快速、灵活的跟踪、分析和处置.例如,状态防火墙需要通过检查TCP连接三次握手交互过程的完整性来抵御SYN洪泛攻击[1];入侵检Page3测系统需要通过将会话正反两方向的状态信息和检测结果进行关联分析来避免误检[3,15];网络地址转换(NAT)在进行IP和TCP/UDP端口资源的动态分配时,也必须以会话为粒度,否则无法保持端对端通信的正确性.这些业务与上述基于流的网络测量任务不同,通常需要记录比较多的会话属性信息和状态信息,而且不允许出现会话记录和信息的缺失,因而会话表往往需要占据较大的存储空间.另一方面,这些业务对于流经的每条会话和每个报文都要进行检测和处理,不允许出现遗漏和错误[16].在这种情况下,随着会话和报文规模的增加,会话表添加、删除和查询的效率往往迅速下降,成为系统主要的性能瓶颈.因此,如何实现高效的会话管理成为一项非常具有现实意义的研究课题,其重点在于会话表结构以及会话表的动态管理机制和查询算法[5,17-18].针对大规模网络流量会话管理问题,本文提出了一种适用于并行执行环境的网络会话管理方案PaSeM(ParallelSessionManagement),采用基于散列表的无锁会话表设计,讨论并解决了在高速网络环境下面临的各种并行冲突问题,给出了会话表查询和动态管理的高效并行算法.基于G/G2/n1排队模型和空竭服务多重休假M/G+D/1排队模型对PaSeM的性能进行了理论分析,对于稳态下并行处理单元(PE)数量、任务队列长度、存储开销与报文到达速率、会话到达速率之间的关系以及其它关键参数应满足的条件给出了定量计算方法.最后,采用基于IXP2400网络处理器的硬件平台进行了原型开发和实验.PaSeM在保证业务灵活性的前提下实现了对会话和报文的高速无冲突并行处理.2相关工作对于诸如网络流计数、流报文计数[19-20]等简单的网络流量测量任务来说,精确跟踪和记录每条流的状态是没有必要的,因此人们常采用bitmap或Bloomfilter[21]来压缩记录流信息,并将其置于SRAM等高速存储器件中,从而以较小的存储空间开销和I/O访存开销来获得处理效率的提升.例如,Estan等人提出了一组基于bitmap的流计数算法,以满足网络测量、拒绝服务攻击检测、端口扫描检测和调度等不同应用的需要[19];Kumar和Xu等人提出了带多组散列函数的SCBF(Space-CodeBloomFilter)并采用多个具有不同采样概率的SCBF对报文进行计数,再基于最大似然估计和平均值估计两种方法对流大小(flowsize)进行估算[20].为了实现流状态跟踪,Bonomi等人提出了一种改进的计数型Bloomfilter,对少量流状态信息进行压缩存储和模糊查询,每个Bloomfilter单元除了计数器外还包含一个流状态字段(一般少于20bits),并增加了一个DK(Don’tKnow)状态作为产生碰撞时的查询结果[22].Chang等人则通过扩展Bloomfilter单元来缓存报文分类或路由查找的结果(如下一跳的输出设备接口位图),同时采用两级散列的Bloomfilter结构改善冲突,实现了报文分类和路由查找的加速[23].上述“紧凑型”结构具有节省存储空间、减少I/O访存开销方面的优势,适用于一些高速链路上的简单处理任务,不过也存在非常明显的局限[22,24]:(1)能够存储的信息量太少;(2)不支持对流状态信息的精确跟踪、记录和查询;(3)难以实现记录的删除操作和超时老化机制,因此往往必须周期性地对流表进行重建;(4)涉及位级内存读写操作,如果存储器件不支持并行和位级寻址的话,则实际存储带宽开销仍然是比较大的.因此,从实用性和灵活性角度考虑[25],散列表仍然是最常见的流表结构[5-6,9,12-14].NetFlow[6]是Cisco路由器中广泛采用的流缓存与测量技术,其底层流表结构和流表管理的技术细节尚未公开,有文献宣称是基于散列表的实现[9,22],在高速网络环境中通常需要采用报文采样[6,10]或流采样[7,9]技术来减轻负载.Xu等人详细研究了高速QoS路由器中的流表设计,针对分布式线卡和集中式转发引擎两种路由器体系结构,分别提出了硬件和软件两套流表设计方案[5],其中硬件流表采用多路组关联缓存,通过动态组关联机制显著降低了缓存溢出比率,并采用流水线设计以实现100+Gbps的吞吐量;软件流表则采用散列表形式,基于随机模型对过期会话记录(垃圾)回收机制的性能和存储开销进行了分析,但是对于流表本身的查询性能反而没有做深入研究,而且所采用的实验数据集中网络流规模只有6.5万条左右,与当前实际网络环境的状况存在比较大的差异.流量监控、状态防火墙、入侵防御、网络地址转换(NAT)、负载分流等等复杂业务的网络会话表也通常采用散列表的结构,在高速网络环境中往往存在比较严重的性能问题.开源项目Netfilter[12]基于散列表结构实现了一个比较典型的面向网络在线业Page4务的会话管理机制Conntrack,具有良好的业务可扩展性,但是由于存在如下一些问题而导致其性能表现相当不尽如人意:(1)采用表级全局锁进行会话表的读写互斥,这种大粒度的锁机制造成了严重的性能瓶颈;(2)会话表的查询(快通道任务)与会话记录的添加、删除(慢通道任务)串行执行,导致大量报文的执行路径过长,不仅使得系统吞吐量受到很大影响,而且会带来处理时延的抖动问题;(3)没表1NetfilterConntrack的性能(桥转发模式,报文大小1024字节)启用NetfilterConntrack前启用NetfilterConntrack后为了提高散列表的查询命中率、减少查询开销,文献[18]采用计数型Bloomfilter对散列表进行改进,其基本思想是:为每个散列桶维护一个计数器(可保存在片上多通道SRAM等高速存储器件中);添加记录时,将关键码输入到k个散列函数中进行计算得到散列索引,然后修改散列索引对应的计数器并将记录插入到对应的散列桶或者计数最小的散列桶中;查询时先判断散列表中是否已存在对应的记录(即报文关键码对应的k个散列桶的计数器均不为零)后,再在散列桶中执行顺序匹配,找到对应的记录.这种方法虽然减少了散列表查询失败次数,但是以牺牲增量更新的效率为代价,导致每次添加和删除操作都需要对k个散列桶中的所有记录进行扫描处理.文献[26]则针对快速报文分类转发业务,提出在查询散列表之前先进行端口比较和端口匹配:通过端口比较,将生命周期较短的流识别出来,直接进行过滤匹配而无需保存记录,以节省存储空间;通过端口匹配,对散列表中是否存在对应的记录进行初步判断,以减少查询失败次数.为了更好地利用存储空间并避免查表时间开销的抖动,文献[22]采用d-left散列对散列表进行负载均衡,即将散列表切分成d个相同大小的子表,散列桶大小固定,采用一个小的TCAM(TernaryContentAddressableMemory)来处理溢出,每个子表对应独立的散列函数,添加记录时从各子表对应的散列桶中选择负载最小的那个散列桶.这种方法虽然比计数型Bloomfilter占用更少的存储空间,但是在进行查询操作时需要同时对d个子表进行查询.为了降低散列表的碰撞率、减少散列函数的计算开销,JenkinsJr对散列算法进行了研究,提出了一种针对IP地址和TCP/UDP端口的散列算法有考虑和利用软硬件平台的SMP(SymmetricalMultiprocessing)、硬件多线程、多核、内核多线程以及多通道内存等并行机制来改善性能.表1给出了采用双核IntelXeon1.86GHz处理器的Linux系统在启用NetfilterConntrack前后桥转发的性能变化情况,可以看出,启用NetfilterConntrack后系统支持的最大并发会话速率下降了59.78%,吞吐量下降了63.78%,而CPU负载则增加了一个数量级.28.2/235.810.2/85.4(jhash)[27]并已被Linux内核所采纳.Xu等人则研究了适合于动态组关联硬件流表的散列算法,对位提取(bitextraction)、线性散列函数、CRC、Rabin散列函数和H3等散列算法进行了比较分析,指出H3算法适于硬件实现且具有良好的性能[5].综上所述,高速网络环境中网络业务的会话管理机制面临着业务弹性与处理性能两个方面的挑战.实际的应用系统通常为了满足业务的复杂性和灵活性要求而忽视了性能;已有的研究工作则一般着眼于性能而舍弃了业务的弹性,而且往往过于强调局部操作的性能(如查询命中率).因此,我们将研究的焦点集中于在多核/多线程处理器、软件多进程/多线程等并行执行环境中如何通过并行机制优化会话管理机制性能,并同时保持良好的业务弹性,从已有的文献来看,这方面的研究还开展得比较少.3会话表设计3.1会话表结构如图2所示,PaSeM采用与Netfilter[12]相似的、基于散列表的会话表结构,散列表长度为L,散列桶为单向链表结构,采用拉链法解决散列碰撞.为了实现访问并行,散列表和散列桶均不设访问互斥锁.Page5每条会话记录同时存在于两个散列桶之中,这主要是考虑到实际应用[12,28]中网络地址转换、四层交换、负载分流等业务涉及对报头IP地址、TCP/UDP端口等会话关键码字段的修改,另一方面,会话关键码中也可能包含有诸如输入设备接口[12]等与流量相关的信息,导致会话正向关键码和反向关键码分别映射到不同的ID(即散列索引)上.3.2回收缓冲区会话记录采用动态存储分配,并设置一个会话记录回收缓冲区,如图3所示,以先进先出队列(称为to-be-freelist)的方式进行组织,并设置全局锁实现对缓冲区的读/写互斥.缓冲区中最多包含Sf条回收的会话记录,当一条会话记录从会话表中删除回收时,暂时先不释放其存储空间,而是放置到缓存区的队尾,直至该条记录到达缓存区队首并且队列长度超过了Sf时,才将其从队列中摘除并释放它的存储空间.Sf可以根据当前会话到达速率、会话表垃圾回收速率(稳态下,与会话到达速率一致)以及报文的处理时延进行动态调整.3.3会话记录和状态机如表2所示,会话记录通常包括如下一些信息:(1)正向关键码(FK)和正向链表指针(Next),其中关键码字段存储从报头中提取的字段信息或其散列值,链表指针指向散列桶中的下一条会话记录;(2)反向关键码(BK)和反向链表指针(reNext);(3)报文链表头尾指针(Pktlist),用于在创建会话记录的过程中缓存到达的报文;(4)状态信息,包括会话记录建立时间(Starttime)、最近报文到达时间戳(Timestamp)、会话状态(Sessionstate)、老化时间间隔(Agetime)、会话记录状态(Recordstate)等;(5)业务参数(Actionpara)和统计信息(Statinfo);(6)互斥写锁(Wlock),用于对会话记录字段和报文链表的互斥写.其中,Sessionstate字段保存了会话本身的状态信息,通常与会话的协议类型相关;Agetime字段则与会话的协议类型和Sessionstate字段密切相关,一般需要针对不同协议类型以及会话的不同状态设置不同的老化时间间隔,以反映特定应用的特点和需求;Recordstate字段则保存了会话记录本身的状态,各状态的定义如表2所示.字段flNext回收缓冲区中下一条会话记录指针FK会话正向关键码Next正向链表中下一条会话记录指针BK会话反向关键码reNext反向链表中下一条会话记录指针Pktlist报文链表头尾指针Starttime会话记录建立时间Timestamp最近报文到达时间戳Agetime老化时间间隔Sessionstate会话状态Recordstate会话记录状态Actionpara业务参数,如下一条路由、访问控制规则ID等Statinfo统计信息,如报文技术、平均报文长度等WlockPktlist、Sessionstate、Recordstate、Actionpara、定义1.“FREE”状态.会话记录在空闲缓冲区中,未被分配使用.定义2.“CREATING”状态.会话记录正处于创建过程中,还不能正常使用.定义3.“WORKING”状态.会话记录已创建完毕,可正常使用.定义4.“HALF-DELETED”状态.会话记录已经从正向或反向链表中删除,正等待从另一条链表中删除后回收.此状态用于会话记录回收过程中正反向两个链表操作的同步.4并行无冲突的会话管理4.1基本思想PaSeM针对多核/多线程处理器、软件多进程/多线程等并行环境,通过并行机制来实现高效的会话管理和高速网络流量的处理,主要思想包括:(1)通过快慢通道任务分离实现“任务并行”.即将针对报文的快通道任务和针对会话的慢通道任务分别交给不同的独立运行模块执行,前者主要包括会话表的查询和会话记录字段信息的更新,后者则主Page6要涉及会话记录的添加和删除回收;(2)采用多个处理单元(PE)负责快通道任务的高速并行处理,实现“报文并行”.PE遵循先来先服务(FCFS)的原则处理报文;(3)采用多个PE负责慢通道任务的高速并行处理,将会话表切分成不同的子表,交由不同的PE来负责管理,实现“会话并行”;(4)将会话表的不同子表分别放置于多通道存储器件的不同存储单元中,通过“I/O并行”来提高访存效率;(5)不同模块以及不同PE之间采用异步通信机制,通过队列(ring)传递消息或者报文,进一步提高操作的并行度.4.2PaSeM并行处理框架基于上述基本思想,提出PaSeM的处理框架,如图5所示.分类查询模块(CM)中包含n1个PE,图5PaSeM并行处理框架在会话表中添加一个会话记录涉及“正向”和“反向”两条会话记录链表的插入操作.CMPE先通过散列索引确定正向会话记录链表的写者是哪个MMPE,然后通过该MMPE的SR队列向其发送一个至少包含报文指针、散列索引信息的消息(记为MSGnew).MMPE收到这个MSGnew消息后,创建一条会话记录并将其插入正向会话记录链表头,然后再通过CR向负责反向会话记录链表插入操作的MMPE发送消息(记为MSGins消息),通知其将会话记录插入反向会话记录链表头.同样地,从会话表中删除一条会话记录也需要分成两步完成,两个MMPE各自通过检查会话记录状态将会话记录从链表中删除,不需要通过消息通信进行异步协同.会话记录的老化回收也由MMPE负责.MMPE定期或不定期对会话表中的会话记录进行扫描检查,将已经超时老化的会话记录删除回收.4.3并行冲突为了保证并行逻辑的正确性并取得较好的并行效率,必须解决高速网络环境下的各种并行冲突问题,包括互斥、同步和死锁.这些PE从输入队列(RR)中取走报文,以报头中包含的关键码信息代入散列函数,根据计算得到的散列索引找到会话表中对应的散列桶(会话记录链表),然后将报文的关键码依次与会话记录链表中各会话记录的关键码进行比较,如果关键码相等且会话记录状态Recordstate为“WORKING”或“CREATING”,则表明找到了报文对应的会话记录,将报文交给后续的业务模块进行处理即可;否则,CMPE通知会话表管理模块(MM)创建并添加新的会话记录.MM中同样包含n2个PE,每个PE都拥有自己独立的输入队列(记为SR1,SR2,…,SRn2),以避免与其他MMPE的访问竞争.此外,每个MMPE还各自拥有一个与其他MMPE通信用的队列(CR),记为CR1,CR2,…,CRn2.4.3.1MMPE间写互斥首先,MMPE之间存在对散列桶的写互斥(即对链表的插入和删除操作互斥),设置会话表的全局锁或散列桶级锁的做法都会造成很大的性能损失.为此,PaSeM将会话表切分成若干子表,如图5所示,每个MMPE各负责其中一个子表的管理,包括会话记录的插入和删除,以确保每个散列桶都只有固定且唯一的写者.4.3.2MMPE间通信死锁其次,MMPE之间如果不是通过CR队列而是通过SR队列进行通信,则可能造成死锁.设想如下情况:有两个MMPE,PEi和PEj,它们各自的SRi和SRj队列都已满,如果PEi要向PEj发送MSGins消息,必须先等待PEj从SRj队列中取走MSGnew或MSGins消息,同样PEj向PEi发送MSGins消息也必须先等待PEi从SRi队列中取走MSGnew或MSGins消息,导致这两个MMPE进入相互等待的死锁状态.为此,如前所述,为每个MMPE增设一个独立的通信队列CR,并规定:(a)CR的长度大于n2γ(γPage7为大于等于1的常数因子);(b)CR队列的优先级高于SR队列,即MMPE必须优先处理CR队列中的MSGins消息;(c)MMPE每次只能从SR队列中取走并处理一个MSGnew消息.下面给出无死锁证明.证明.采用反证法证明.如果发生了死锁,则存在一个由m个(2mn2)MMPE组成的封闭环路,它们的CR队列都已满,且每个MMPE都因为试图向环路中它的前驱MMPE的CR队列发送MSGins消息而进入等待状态.注意到MSGins消息是在处理MSGnew消息的过程中产生的,因此只有在此过程中MMPE才可能进入死锁状态.设PEm为在时刻tm最后一个进入等待状态的MMPE,它进入等待状态前最后一次从SRm队列取走MSGnew消息的时刻为tm.PEk为封闭环路中PEm的后继,它进入等待状态的时刻为tk,tktm.由限定(b)和(c)可知,只有在tm时刻CRm为空时,PEm才能从SRm队列中取走一个MSGnew消息进行处理.由此可知tk必定落在[tm,tm]区间内,且CRm必须在[tm,tk]区间内被填满,否则PEk就不能在tk时刻进入等待状态.设MMPE从SR队列中取走一个MSGnew消息进行处理到向CR队列发送MSGins消息所费时间的下限和上限分别为Ta和Tb(TaTb,且Tb/Ta=γ),即一个MMPE往CR队列发送MSGins消息的时间间隔至少为Ta.从而有与限定条件(a)矛盾.因此不会产生死锁.证毕.4.3.3CMPE与MMPE间读写互斥CMPE与MMPE之间同样存在对会话记录链表的读写互斥,为此在执行链表插入和删除操作过程中通过“写”原子指令和严格规定的指令次序确保对于CMPE(读者)来说任一时刻链表结构的完整性.如果MMPE(写者)要在会话记录A和C之间插入一个新的会话记录B,则应先读取A的Next/reNext字段(即C的地址),然后用“写”原子指令将读取的值填入B的Next/reNext字段,再用“写”原子指令将B的地址填入A的Next/reNext字段.同理,当要删除会话记录A和C之间的会话记录B时,首先应读取B的Next/reNext字段(即C的地址),然后用“写”原子指令将读取的值写入A的Next/reNext字段.此外,在从链表中删除会话记录B的过程中,可能有一些CMPE正在读取B的信息(如查询链表时正好“经过”B),而将B删除回收后仍然可能存在一些正“使用”B的报文还没有处理完.为了减少不必要的互斥开销并防止产生脏数据,B删除后将先暂时存入会话记录回收缓冲区中,并且不释放内存空间,也不清空其中的数据(包括Next/reNext字段),而是等到B被移出会话记录回收缓冲区时再执行清空和释放内存空间的操作.为了给上述对B的访问留出足够多的时间,设置会话记录回收缓冲区大小的阈值Sf,如图3所示,使得会话记录回收缓冲区中一直保留有Sf个回收的会话记录,从而保证B被回收后不会即刻被重新分配出去.稳态下,Sf的取值与会话到达速率以及CMPE处理报文的服务时间相关.4.3.4重复的MSGnew消息快慢通道任务并行的策略以及CMPE与MMPE之间的异步消息通信机制还可能导致产生重复的MSGnew消息.UDP或ICMP等非连接通信、TCP报文重传或者“洪泛”攻击等都有可能使得会话首报文与同方向后续报文之间到达间隔过小,MMPE来不及创建会话记录并将其插入正向会话记录链表,从而导致CMPE连续发送相同的MSGnew消息给MMPE.由于散列桶的写者固定且唯一,因此重复的MSGnew消息依然会按照先后次序交由同一个MMPE处理.为此,MMPE需要在处理每个MSGnew消息前确认一下链表中是否已存在对应的会话记录,如果已经存在,则丢弃重复的MSGnew消息.由于新会话记录总是插入会话记录链表的头部,因此重复消息的查询开销基本可以忽略不计.另一方面,反向报文与会话首报文之间存在协议交互时延,足够让系统完成添加会话记录的工作,因此会话的反向流量通常不会触发重复的MSGnew消息.4.3.5包序控制最后,并行处理还会带来报文的包序控制问题.为了保证输入和输出的报文次序一致,在创建和添加会话记录时PaSeM将已经到达的报文按照先后次序缓存到Pktlist链表中,等待会话记录添加完成后再按照次序将报文交给后继的业务模块处理,从而保证在这个阶段中会话的报文次序.在快通道任务执行阶段,由于CM对输入的报文采取FCFS的策略,且快通道任务相对比较简单且执行分支少,各执行分支的时间开销粒度通常比较均匀,属于同一Page8条流的报文的处理时间不会有太大波动,因此CM基本能够保持同一条会话同方向的报文次序.4.4并行查询算法会话表的并行查询算法如下.算法1.会话表并行查询算法.h:散列函数,L:散列表长度R.key:会话记录中的FK或BK字段1.forallCMPEPi,i=1,2,…,n12.从队列RR中取出一个报文PK3.j←h(PK.key)%L4.for散列桶bucket[j]中的每个会话记录R5.if(R.key=PK.key)then6.获得R.Wlock锁,rs←R.Recordstate7.if(rs=WORKING)then8.更新R.Sessionstate,R.Timestamp,9.elseif(rs=CREATING)then10.将报文PK插入R.Pktlist链表尾11.endif12.释放R.Wlock锁13.if(rs≠CREATING)then将报文交给后14.exit15.endif16.endfor17.if(在bucket[j]中找不到对应的会话记录)18.k←j%n2//计算该散列桶对应的MMPE编号19.向队列SRk发送一个包含j和PK指针的20.endif21.Endforall各个CMPE从队列RR中取出报文,根据报文的关键码查询会话表.如果查询命中(hitting),则将报文交给后继业务模块,根据会话记录的Recordstate字段执行不同的处理.当Recordstate为“HALF-DELETED”或“FREE”时,表明有MMPE正在执行或已经完成该会话记录的删除回收操作,不过会话记录的数据还暂时不会被清空,因此并不会影响到CMPE的执行.如果查询失败(missing),则CMPE向对应的MMPE发送MSGnew消息,创建和添加新的会话记录.各个CMPE之间的查询操作可以完全并行,CMPE与MMPE之间也没有散列桶的互斥读写问题,两类PE可以各自并行无冲突地工作.整个过程中只有在修改会话记录的状态和统计信息以及报文链表Pktlist时,才需要加上写锁.4.5会话表的动态管理MMPE按照优先处理CR队列(每次处理完队列中的所有MSGins消息)、其次处理SR队列(每次处理1个MSGnew消息)、最后执行垃圾回收(扫描会话表、删除回收过期会话记录)操作的次序循环工作,算法如下.算法2.会话表动态管理算法.R:MSGins消息所指向的会话记录j:MSGins消息所指向的反向会话记录链表(散列桶)的1.forallMMPEQi,i=1,2,…,n22.while(队列CRi非空)3.从队列CRi中取走一个MSGins消息,4.将会话记录R插入散列桶bucket[j]的链表5.endwhile6.if(队列SRi非空)then7.从队列SRi中取走一个MSGnew消息8.执行会话记录的创建和添加操作9.else10.执行扫描会话表、删除回收过期会话记录的11.endif12.endforallMMPE利用“空闲”时间扫描它负责的会话子表,将超过老化期限(当前时刻—Timestamp>Agetime)或者Recordstate为“HALF-DELETED”的会话记录从会话表中删除,并放置到回收缓冲区.为了控制一批次垃圾回收操作开销的粒度,避免CR和SR队列发生溢出,可指定一次扫描的散列桶个数(Sr).此外,为了控制老化扫描的频率、避免耗费过多的I/O访存开销,可采取一定的保护措施,如限定MMPE扫描一遍会话子表的最小时间间隔.4.5.1创建添加会话记录在会话表中添加一个会话记录涉及到正向和反向两条会话记录链表的插入操作,需要分别由对应的两个MMPE(记为PEi、PEj)来完成.PEi先创建新的会话记录并将其插入到正向会话记录链表中,然后通过CRj向PEj发送MSGins消息,由PEj将会话记录插入反向会话记录链表.完整的算法如下.算法3.创建添加会话记录.PK:MSGnew消息所指向的报文k:MSGnew消息所指向的正向会话记录链表(散列桶)Page9l:MSGins消息所指向的反向会话记录链表(散列桶)的h:散列函数,L:散列表长度1.PEi从队列SRi中取走一个MSGnew消息2.if(查询bucket[k]找到对应的会话记录)then3.忽略重复的MSGnew消息,根据会话记录对PK4.endif5.创建一个新的会话记录R6.R.FK←PK.key,R.Recordstate←CREATING7.R.Starttime,R.Timestamp←now8.将PK插入R.Pktlist链表尾部9.将会话记录R插入散列桶bucket[k]的链表头部10.填写会话记录R的其它字段11.l←h(R.BK)%L,j←l%n212.向CRj队列发送一个包含l和R的指针的MSGins13.获得R.Wlock锁14.从头至尾依次释放并处理R.Pktlist链表中的报15.R.Recordstate←WORKING16.释放R.Wlock锁为了检查重复的MSGnew消息,MMPE需要先查询一次散列桶(见算法第2步),如果散列桶已经存在对应的会话记录,则可知当前的MSGnew消息为重复发送的消息.由于新建的会话记录总是插入到散列桶会话记录链表的头部,因此重复的MSGnew消息的处理开销很小,基本可以忽略不计.而对于非重复的MSGnew消息,考虑到会话首报文的数量通常在总流量中只占较小的比例,因此多余一轮会话记录链表的扫描查询开销还是可以承受的.在创建一个新的会话记录时,如果存储空间不足,可以采取丢弃报文的“抑制”策略.从安全性的角度来考虑,对于过载的流量通常都采取丢弃的做法.如果是正常的突发业务流量导致的网络会话激增,则TCP协议的重传机制可保证峰值过后业务会话仍然能够正常建立;如果是由于拒绝服务攻击所导致的,则这种策略在一定程度上能够起到类似于“首报文丢弃”的防御效果.4.5.2删除回收会话记录同理,在会话表中删除回收一个会话记录也需要对正向和反向两条会话记录链表进行操作.PEi负责将会话记录从一条记录链表中删除,PEj负责将会话记录从另一条会话记录链表中删除并回收到会话记录回收缓存区中.为了避免死锁,PEi执行删除操作后不会向PEj发送同步消息,即PEi、PEj各自通过扫描所负责的会话子表完成删除和回收过程.这样做虽然会增加过期会话记录删除回收的平均时延,但是并不会增加最坏情况下的时延.具体算法如下.算法4.删除回收会话记录.i:MSGnew消息所指向的正向会话记录链表(散列桶)j:MSGins消息所指向的反向会话记录链表(散列桶)的h:散列函数,L:散列表长度1.PEi将会话记录R从它负责的会话记录链表中2.获得R.Wlock锁3.if(R.Recordstate=HALF-DELETED)then4.R.Recordstate←FREE5.elseif(R.Recordstate≠FREE)6.R.Recordstate←HALF-DELETED7.endif8.释放R.Wlock锁9.if(R.Recordstate=FREE)then10.将R回收到缓冲区中,并保留会话记录的数据11.if(会话记录回收缓存区已满)then12.将缓冲区链表头的会话记录摘除,并释放其13.endif14.endif5性能分析评价5.1性能评价模型报文到达具有自相似性,假定报文到达为时间间隔服从均值为ab/(a-1)、方差为ab2/[(a-1)2(a-2)](其中a>2)的Pareto分布,报文到达平均速率λ1=(a-1)/(ab).对于会话的首报文和后续报文,CMPE在查询会话表时将产生失败(missing)和命中(hitting)两种不同的情况,其服务时间也将遵循两种不同的分布,因而CM构成了G/G2/n1型排队系统,如图6(a)所示,其中G2表示CMPE对于RR队列的服务时间独立且服从两类一般概率分布,n1为CMPE的数目.文献[5]和文献[29]中指出,在骨干网层次观察,网络会话到达和活跃会话数量并没有呈现自相似特性,会话的到达仍然可以视为平均速率为λ2的泊松过程,到达时间间隔服从参数为1/λ2的负指数Page10图6性能评价模型分布.假定各SR和CR队列输入独立同分布,均值为λ2/n2(忽略产生重复MSGnew消息的情况),其中n2为MMPE的数目,亦即MSGnew和MSGins消息的处理负载将平均分担到各个MMPE上.由图6(a)可知,SR队列的输入为G/G2/n1系统的输出,视其为泊松过程,即MSGnew消息的到达时间间隔服从参数为n2/λ2的负指数分布.而CR队列的输入取决于SR队列的输出,由于CR有最高的处理优先级,因此CR中MSGins消息的等待时间可以忽略不计;又,为方便起见,假定创建添加一条会话记录的工作全部由同一个MMPE完成,而不是分由两个MMPE负责,由于各MMPE之间无差异且CR队列的服务时间TCR为定长分布,因此这个假定不会对性能评价造成影响.综上所述,每个MMPE都构成空竭服务(exhaustiveservice)、多重休假(multiplevacations)表3性能评价模型的参数参数λ1λ2L散列表长度d散列桶深度Td会话活跃时间TxTxrTp读取报文数据的时间开销Th计算散列值并读取散列表项的时间开销Tb在散列桶中查找一条会话记录的时间开销Ta会话老化时间间隔Tv执行一批次扫描和回收过期会话记录的时间开销(即一次“假期”的时长)TwMMPE“忙期”的时长Tmv两次“忙期”之间多重“假期”的时长TX队列X(X=RR,SR,CR)的服务时长Sr一次“假期”中扫描的散列桶个数,1SrL/n2注:(读SRAM次数,写SRAM次数;读SDRAM次数,写SDRAM次数;执行指令数,指令的总时钟周期开销),下同.#Tdf=44×min(L,2N)/(2N)+70×max(2N-L,0)/(2N).通常N>L,因此Td的M/G+D/1型排队系统,如图6(b)所示,其中M表示会话到达过程为泊松分布,G表示MMPE对于SR队列的服务时间独立且服从一般概率分布,D表示MMPE对于CR队列的服务时间服从定长分布.MMPE只有在SR和CR队列为空时才能进入“休假”期(即遵循“空竭服务”规则),在“休假”期间MMPE执行扫描回收过期会话记录的工作,每次“休假”时间(扫描Sr个散列桶)为独立于到达和服务过程的独立同分布.当一次“休假”结束后,若SR和CR队列仍然为空,就开始另一次“休假”(即遵循“多重休假”规则),对扫描会话子表的频率不做限制;在休假结束时,若SR或CR队列不为空,就进入新的“忙期”.性能评价模型的主要参数见表3.Page115.2性能指标主要性能指标如表4所示.除了排队模型关注的PE数目、队列长度、等待时间(waitingtime)、逗留时间(sojourntime,即等待时间+服务时间)等指标外,还包括会话表中会话记录总数和活跃会话记录的数量、垃圾比率、会话记录回收缓冲区大小等指标.指标n1CMPE数量n2MMPE数量X队列X(X=RR,SR)长度,即在队列中等待的报文/消息数LqX队列X(X=RR,SR)的等待时间WqWX队列X(X=RR,SR)的逗留时间(等待时间+服务时间)N会话表中会话记录总数均值Na会话表中活跃会话记录数量均值GR会话表的垃圾比率,即(N-Na)/NaSf会话记录回收缓冲区大小5.3报文处理性能分析RR、等待时间WqLq量n1的下限进行定量分析.下面对稳态(steadystate)下队列RR的长度给定会话表中的平均会话总数N,假设散列桶深d服从二项分布,则会话首报文查询时间的概率分布为P(Tb=xTm2N()x会话后续报文查询时间的概率分布为P(Tb=xTm以及采用递推法,可得会话表散列桶深d的期望:E(d)=∑2N∑2N∑2N2Nx=1x=1从而得到会话表散列桶查询时间的概率分布为E(Tb|missing)=∑2NE(Tb|hitting)=∑2N以及E(T2b|missing)=∑2Nb|hitting)=∑2N2N∑2NE(T2=L(Tm=(TmG/G2/n1排队系统的服务时间:TRR=Trr+Tp+Th+Tb|hitting+Tu由式(4)~(7),可计算出队列RR的服务时间的期望E(TRR)以及方差E(T2E(TRR)=P(hitting)E(TRR|hitting)+=λ1-λ2λ1λ2(Trr+Tp+Th+E(Tb|missing)+Twλ1=Trr+Tp+Th+TwTmf2Lλ1RR)=P(hitting)E(T2E(T2=λ1-λ2λ12(Trr+Tp+Th+TuE(T22(Trr+Tp+Th+TwE(T2Page12(1)当CMPE的数量n1=1时,CM为G/G/1排队系统,当ρ1=λ1E(TRR)<1时,有[30]λ1E(T2λ1(E(T2当CMPE的负载ρ1=λ1E(TRR)/n1<1且充分接近1(即处于heavytraffic状态)时,在稳态下Wq近似服从负指数分布,从而有[30-31]当CMPE的负载RR近似服从负指数分布,从而有[30-31]且充分接近1(即处于heavytraffic状态)时,在稳态下WqE(Wqλ1(n1(ab2/((a-1)2(a-2)))+E(T2又,实际情况下采用随机性足够好的散列函数且散列表足够大时,会话记录在会话表中趋向于均5.4会话处理性能分析接下来对稳态下队列SR的长度LqSR、逗留时间WSR以及MMPE数量n2进行定量Wq分析.MMPE创建添加一条会话记录所花费的总时间(即M/G+D/1排队系统的服务时间)为TSR+TCR,其中TSR=Trr+Th+Tb|missing+TcE(TSR)=Trr+Th+Tc=Trr+Th+Tc将系统中的有效会话记录(activeflowrecords)看成M/G/型排队系统中正在接受服务的“顾客”,服务时间即为会话的生命周期(sessionlifespan),则E(WqRR)=λ1(E(T2由Little公式可算出此时队列RR长度的期望为E(Lq(2)当CMPE的数量n1>1时,由文献[30,32]可知:2n1E(TRR)E(WqRR)-(n1-1)E2(TRR)匀分布,使得E(T2E(Wqλ1(n1(ab2/((a-1)2(a-2)))+E2(TRR))E(Lq同式(13),根据E(WqRR).将式(9)代入式(15),展开后可知若CM存在稳态则CMPE的数量n1应满足f+2LTu2L由文献[33]可知,系统中有效会话记录的数目服从泊松分布.假定会话的活跃期(sessionduration)Td服从均值为ea+δ2/2(其中σ>0)的对数正态分布[34],则会话的生命期均值为ea+δ2/2+Ta,由Little公式可得会话表中有效会话记录数量的均值为Na=λ2(Td+Ta)=λ2(ea+δ2/2+Ta)(22)稳态下系统内部将维持一种动态的平衡关系,即单位时间内平均新产生的过期会话记录数(亦即需要回收的会话记录数)与平均新到达的会话数量相同,均为λ2.由MMPE扫描散列桶回收过期会话记录的批处理策略(粒度为Sr)可知,稳态下MMPE在一次“休假”期间扫描会话记录的次数服从参数为Sr/L的二项分布,均值为2NSr/L.同理,稳态下MMPE在一次“休假”期间删除过期会话记录次数和回收会话记录次数也服从参数为Sr/L的二项分布,均值分别约为2(N-Na)Sr/L和(N-Na)Sr/L.因此,稳态下执行一批次扫描和回收过期会Page13话记录(即一次“假期”)的时间开销Tv的期望和方差分别为E(Tv)=SrL(2NTs对于空竭服务、多重休假的M/G+D/1排队系统,当SR)=E(Lq时,SR队列中消息数量的期望为[30,35]E(Lq则队列SR中消息等待时间、逗留时间(等待时间+服务时间)的期望分别为E(WqE(WSR)=E(TSR+TCR)+E(Wq其中E(T2录在会话表中趋向于均匀分布时,D(Tv)趋近于0;由式(19)和式(21)可知:E((TSR+TCR)2)=(2(Trr+Th+Ti又,将式(20)、式(21)代入式(25),展开后,再由NNa可得稳态下MMPE的数量n2应满足n2>λ2(2Trr+2Th+2Tiλ2(2Trr+2Th+2Ti由式(29)可知,在不限制队列SR长度的情况下,调整MMPE每批次扫描回收过期会话记录的粒度Sr不会对MMPE的数量n2造成影响.5.5存储开销分析下面对稳态下会话表大小、垃圾比率以及回收由文献[35]可知,MMPE“忙期”(添加会话记缓冲区大小做定量分析.录的时间)的平均长度为其中LS(Tv)为Tv的Laplace-Stieltjes变换;MMPE“全假期”(前后两次“忙期”之间的若干次连续“假期”之和,扫描回收操会话记录的时间)的平均长度为从而稳态下对于MMPE的一个“忙循环”(即一次“全假期”加上其后的忙期)存在平衡方程:(E(Tmv)+E(Tw))λ2n2=(N—Na)E(Tmv)SrE(Tv)L即在“忙循环”期间新产生的过期会话记录数应等于回收的会话记录数.将式(20)、(21)、(23)、(25)和式(30)、(31)代入式(32)后,展开计算得到其中,A=2λ2Tmλ2L(θ1+θ2),C=(n2L-λ2L(θ1+θ2))Na,θ1=2Tdf+Tr再由N、Na可计算出会话表的垃圾比率(gar-bageratio)[5]:GR=(N-Na)/Na.考虑一个报文从进入系统到离开的时间间隔内回收的过期会话记录数目(稳态下亦即新到达会话数目),则回收记录缓冲区大小Sf应满足6实验以IntelIXP2400网络处理器、8MBSRAM、1GBSDRAM和4个GE多模光网口组成的高速网络处理板卡为实验平台.IXP2400的工作主频为600MHz,内部包含8个微引擎(ME)和1个XScale处理器.微引擎支持32位RISC指令集,每个微引擎又包含8个有独立寄存器组的硬件线程,线程轮流获得执行权限且线程之间切换为零开销.每个硬件线程可以看做一个PE.IXP2400片外存储单元主要包括:(1)工作频率最高为200MHz的双通道QDRSRAM,每个通道的峰值带宽为1.6GB/s、最大容量64MB,支持不包括原子减操作在内的各种原子操作;(2)工作频率最高为150MHz的DDRSDRAM(4个Bank),峰值带宽为2.4GB/s,最大容量2GB.在原型系统中,散列表、会话记录写锁组成的位串(bitmap)、回收记录缓冲区头尾指针等存储在SRAM中,会话记录本身则根据所属子表分别存储Page14于SDRAM的不同Bank中.采用源IP地址、源TCP/DUP端口、目的IP地址、目的TCP/DUP端口和协议号作为会话关键码,散列表的散列算法采用jhash算法[27].对原型系统中各项操作的开销(读SRAM次数,写SRAM次数;读SDRAM次数,写SDRAM次数;操作所含指令数,操作的时钟周期开销)进行了统计,见表3,其中创建会话记录操作的平均开销达到了2920个时钟周期,要远大于其它操作的时间开销.6.1实验设置通过若干台流量发生器向实验平台发送64字节大小的UDP报文,总发包速率为λ1.其中,以均匀的时间间隔发送带新的目的IP地址和UDP端口的报文,发送速率为λ2,以这样的报文作为会话首报文,触发原型系统执行创建添加会话记录的操作;其余的报文采用轮询方式分别通过不同的UDP会话发送出去,每条会话的生命周期持续Td秒.通过调整流量发生器的参数λ1、λ2、Td以及原型系统的参数L、Ta、Sr,观察在不丢包条件下系统处于稳态时的n1、n2、N和GR,并周期性地记录SR和Sf的变化,从而对报文吞吐并行加速性RR、LqLq能、会话吞吐并行加速性能以及存储开销(队列长度、回收缓冲区大小)进行评估.6.2报文并行处理性能并行加速性能.实验1.报文到达速率λ1处于高位时的报文将λ2、L、E(Td)、Ta、Sr分别取值为1万条/s、524288、300s、60s、1个,则稳态下会话表中的活跃会话记录数Na应为360万条.实际测得会话表中的会话记录总数N约为362.5万条,垃圾比率GR为0.69%,散列桶深均值E(d)为14;所需MMPE(硬图7报文吞吐并行加速性能和排队队列长度变化情况(会话速率10000条/s)件线程)数n2为1个.定义报文处理的并行效率(parallelefficiency)=稳态下n1个CMPE的最大报文吞吐量/(n1×稳态下单个CMPE的最大报文吞吐量)测得此时单个CMPE(硬件线程)的最大报文吞吐量约为278.3Kpps.逐步增加CMPE(硬件线程)的数量n1,测试对应的最大报文吞吐量以及报文输入队列RR长度变化情况.受限于实验平台硬件本身的吞吐能力(峰值流量为4Gbps),CMPE(硬件线程)总数只能增加到21个,约占IXP2400硬件线程总数的三分之一.变化情况.随着λ1和n1的增加,Lq升,LqRR的最小值基本上保持不变且略有下降,而RR的最大值呈明显上升趋势,反映出在所有CMLqPE接近满负载的状况下等待被各个CMPE处理的报文在队列RR中产生“累积”,使得Lq幅度变大.当报文吞吐量达到5.844Mpps,接近系统流量负载峰值时,Lq21),仍然在比较合理的水平上.图7(a)给出了在不丢包情况下最大报文吞吐量随CMPE(硬件线程)数目n1的变化情况.由图中可知,最大报文吞吐量与n1呈线性增长关系,且与理论值能较好地吻合,报文处理的并行效率均值接近1.当n1=1时,最大报文吞吐量达到278.3Kpps,对比表1中NetfilterConntrack的实验结果可知,在硬件平台性能较逊的情况下,PaSeM的该项性能指标仍然超过NetfilterConntrack一个数量级.当n1=21时,最大报文吞吐量达到了5.844Mpps(约3.93Gbps).图7(b)给出了报文输入队列RR的长度LqPage15并行加速性能.实验2.会话到达速率λ2处于高位时的报文将λ2调整为5万条/s,其它条件与实验1相同,则稳态下会话表中的活跃会话记录数Na应为1800万条.实际测得会话表中的会话记录总数N约为1907万条,垃圾比率GR约为5.9%,散列桶深均值E(d)为73;所需MMPE(硬件线程)数n2为2个.测得此时2个CMPE(硬件线程)的报文吞吐量约为114Kpps(单个硬件线程的吞吐量已经小于λ2).由于此时会话表的负载因子(loadfactor)N/L较高,导致查询会话表的I/O访存开销增加,从而使得最大报文吞吐量明显降低.将CMPE(硬件线程)的数量n1从2逐步增加到16,测得最大报文吞吐量的变化情况如图8(a)所示,报文输入队列RR的长度Lq知,最大报文吞吐量与n1依然呈现线性增长关系,图8报文吞吐并行加速性能和排队队列长度变化情况(会话速率50000条/s)6.3会话并行处理性能实验3.将L、E(Td)、Ta、Sr分别取值为524288、300s、60s、1个,报文发送速率λ1固定为900Kpps.逐步增加MMPE(硬件线程)的数量n2,测试对应的最大会话吞吐量、并行效率以及队列SR长度变化情况.定义会话处理的并行效率(parallelefficiency)=稳态下n2个MMPE的最大会话吞吐量/(n2×稳态下单个MMPE的最大会话吞吐量)(36)测得此时单个MMPE(硬件线程)的最大会话吞吐量λ2约为3万条/s.将MMPE(硬件线程)的数量n2从1逐步增加至8,则对应的最大会话吞吐量、并行效率的变化情况如图9(a)所示.由图中可以看出,最大会话吞吐量与n2呈递增关系,且实验值与理论值能较好地吻合.当n2=1时,最大会话吞吐量达到3万条/s,对比表1中NetfilterConntrack的当n1=16时,最大报文吞吐量达到了920Kpps;报文处理的并行效率均值仍接近1.当n1为2时,尽管此时会话首报文数量λ2在总流量中占据了相当高的比例,达到43.85%,最大报文吞吐量的实验值与理论值仍然能够较好地吻合;另一方面,由于总流量λ1相对于n1来说并不高,Lq比较小,且依然呈现随着n1逐步递增的趋势———这两点都表明CMPE对报文的处理并没有受到MMPE的干扰,体现出PaSeM无冲突并行加速的效果是比较明显的.当n1从2增加到16时,会话首报文数量λ2在总流量中的比例逐步下降到了5.43%,但是最大报文吞吐量的实验值与理论值之间的差距反而逐步扩大到24%.这主要是由于理论分析模型并没有将I/O访存带宽的限制考虑进来,因此当I/O访存开销存在瓶颈时理论值产生了一定的偏差.实验结果可知,在硬件平台性能较逊的情况下,PaSeM的该项性能指标仍然达到了NetfilterConntrack的3.64倍.当n2=8时,最大会话吞吐量达到了11.6万条/s,会话表中的会话记录总数达到4470多万条,其中活跃会话约为4176万条,已经达到相当于100+Gbps网络流量的会话到达速率和并发会话规模[5].当n2=2,3,4,5,6,7,8时,并行效率分别为85%、73.3%、65.4%、59.7%、55.2%、51.5%和48.3%,取得了较好的会话并行加速效果.随着n2的增加,MMPE的并行效率呈递减趋势,这主要是由于会话表负载因子N/L的增长导致查询会话表的I/O访存开销增加,反过来限制了最大会话吞吐量λ2的进一步增长.图9(b)给出了队列SR的长度Lq时Lq变化幅度均呈下降趋势.SR最大值达到183,之后随着n2的增加,LqPage16图9会话吞吐并行加速性能和排队队列长度变化情况(报文速率900Kpps)6.4存储开销对实验3中稳态下的会话表规模N进行记录,并根据式(22)可算出同时活跃的会话数Na,由此可得会话表中过期会话记录以及垃圾比率GR的变化情况,如图10所示.由图中可知,在系统处于最大会话吞吐量的情况下,GR仍然处于9%以下,低于文献[5]的指标(28%).对于实验3中队列RR和SR的长度Lq进行记录并求均值,再通过Little公式和式(34)可计算出回收缓冲区大小Sf的条件值,如图11所示.采用此条件值为Sf的实验值,在实验过程中没有发生会话丢失的现象,表明计算出的条件值是合理的.随着会话吞吐量λ2的增加,Sf也需要相应地增加,当λ2达到11.6万条/s时,n2和N分别为8和4470万条,此时Sf只需设置为7548即可满足要求,仅为N的万分之1.69.7结论与展望本文的工作主要体现在如下几个方面:(1)提出了一种基于并行的网络流量会话管理方案PaSeM,基于散列表的无锁会话表设计,采用了任务并行、报文并行、会话并行、I/O并行和异步通信等多种并行策略;(2)讨论并解决了在高速网络环境下面临的各种并行冲突问题,给出了高效的会话管理和查询的并行算法;(3)基于排队理论建立了相应的性能评价模型并进行了理论分析,对于稳态下的性能指标以及关键参数应满足的条件给出了定量计算方法,与这部分类似的理论建模和分析工作还只见于与文献[5].该模型的理论计算值与实验值有较高的吻合度,对于实际应用以及今后的研究具有指导意义.(4)实现了一个PaSeM的原型并进行了实验,实验结果表明PaSeM对于会话管理和报文处理具有较好的并行加速效果,报文处理的并行效率均值接近1,当会话管理单元个数为4时,会话处理并行效率为65.4%(亦即加速比为2.62),当会话管理单元个数为8时,会话处理并行效率仍然达到了48.3%(加速比为3.86),能够满足当前高速网络环境流量处理的性能要求;在最大吞吐量负载下排队队列长度及其变化幅度都处于合理范围,会话表垃圾比率维持在较低的水平上(实验结果为小于9%),与已有的工作相比为优.与已有的研究工作相比,PaSeM在保证业务灵活性的前提下实现了对会话和报文的高速无冲突并行处理,具备很好的实用性.针对并行执行环境中大Page17规模网络会话管理问题,根据已有文献来看,这方面的研究工作还开展得比较少.进一步的方法改进和研究工作包括:(1)考虑基于松耦合分布式并行处理系统(如电信级防火墙或者运营商级流量监控系统)以及异构并行系统的应用场景,将PE之间通信信道的不可靠性因素考虑进来,对会话记录状态机和并行算法进行扩展,以满足10+Gbps~100+Gbps高速带宽下的性能要求;(2)考虑在专用硬件支持下(如TCAM、Bloomfilter、Hash硬件)的方法改进,以获得局部性能的改善,如提高散列表的查询命中率、减少查询失败开销.
