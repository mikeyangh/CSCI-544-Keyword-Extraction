Page1基于ChunkFolding的多租户数据库缓存管理机制姚金成张世栋史玉良李庆忠(山东大学计算机科学与技术学院济南250101)摘要ChunkFolding是SaaS模式下常用的存储架构之一,通过共享数据库共享架构来存储租户的数据以获取规模经济效益,但基于传统数据库搭建的ChunkFolding共享存储架构,其缓存管理机制缺乏良好的多租户特性,导致数据库性能恶化,租户的SLA得不到保障.为此,提出了基于ChunkFolding的自适应多租户缓存管理机制,该机制以租户的SLA需求作为驱动,依据租户当前访问模式,动态生成缓存单元集并计算缓存单元集的I/O效益,通过贪婪算法来选择缓存单元集,使得租户SLA得到满足的同时最小化缓存资源的消耗.通过实验分析证明了该缓存管理机制的有效性.关键词共享存储架构;多租户;缓存管理;SLA1引言软件即服务(SoftwareasaService,SaaS)是一种基于互联网的服务提供模式、企业或个人租赁服务,并通过Web浏览器或Web客户端访问这个服务.在SaaS模式下,数据存储通常采用共享数据库共享存储架构[1],从而获取规模经济效益,如UniversalTable[2-3]、PivotTable、ChunkFolding[4]等.这些共享存储架构各有其优缺点,ChunkFolding相比于Page2UniversalTable无存储空间的大量浪费,可更好地支持索引,查询时不需要处理大量的null值以及数据类型的转换;ChunkFolding相比于PivotTable减少了存储元数据和业务数据的比例,也降低了重构租户逻辑表的代价.尽管ChunkFolding对比其它共享架构具有明显的优势,但基于传统数据库搭建的共享存储架构,仍然存在着很多的不足,如额外的I/O和自然连接[4],而文献[4]指出I/O是主要因素.因此,如何缓解I/O导致的性能下降就成为改善ChunkFolding共享存储架构性能的关键;对于I/O的优化,传统数据库通常采用缓存数据块的方式,但是在多租户共享存储架构下,传统数据库的缓存管理机制存在以下两点不足之处:(1)传统数据库缓存机制以数据块作为缓存单元,而多租户共享存储架构下,任一数据块均包含了大量其他租户的无关数据,采用数据块作为缓存单元导致大量缓存资源的浪费.(2)传统数据库缓存机制缺乏多租户的概念,对于来自租户的请求,传统缓存机制会从提高数据库整体性能的角度进行缓存管理,这就会导致租户间资源分配的极为不合理,如高频访问租户抢占低频访问租户的资源,使得低频访问租户的SLA响应时间需求得不到保障.针对以上问题,本文提出了一种基于ChunkFolding的自适应的多租户缓存机制(Self-AdaptiveMulti-TenantMemoryManagement,SAMTMM).对每一个租户,SAMTMM适应当前的租户访问模式,动态生成合理的候选缓存单元,并计算其对应的I/O效益,然后具备最高效益率(缓存单元的I/O效益与缓存单元占据内存大小的比值)的缓存单元被选中放入缓存,重复上述过程直到满足租户的SLA响应时间需求.本文将上述过程形式化定义为变种的背包问题,并采用贪婪算法来选择缓存数据集.本文第2节介绍相关工作;第3节基于ChunkFolding共享存储架构的特性,给出相应的代价估计模型;第4节给出多租户的缓存机制;第5节是相应的实验环境和实验结果;最后是本文的总结.2相关工作数据库缓存作为改善数据库性能的主要因素,已经被广泛的研究[5-7].文献[5]给出了一种自调节的缓存管理机制STMM,通过为不同缓存使用者(如排序缓存、Hash连接缓存、锁缓存、缓冲池等)建立缓存消耗和时间产出效益的模型,从而使得不同使用者之间有了统一的衡量标准,并将缓存分配给产出效益大的使用者,以达到提高系统整体性能的目的;与STMM类似,文献[6]通过对每一缓存对象定义BYHR,即单位字节命中产出率,选择缓存那些高产出的缓存对象从而利用有限的缓存资源使得网络传输代价大幅度减少.文献[7]提出了Fragmentfencing用于解决具有明确QoS需求的不同类型请求的缓存分配问题,以达到最小化缓存消耗的目的.该方案假设数据库磁盘块有统一的访问频率,并基于简化的事务模型:(1)事务响应时间直接与I/O数目相关;(2)命中率与缓存的磁盘块的数目成正比.如果某一类请求的响应时间不满足QoS所指定的响应时间,则通过当前已分配的缓存、当前响应时间与QoS响应时间之间的线性对应关系就可以计算出为满足QoS响应时间所需分配的缓存大小.但是在多租户共享存储模式下,不同租户的数据共享存储在某一磁盘块中,这就导致单纯以磁盘块数目而不考虑磁盘块的数据内容作为衡量缓存命中率指标的假设存在着不合理性.随着云计算的兴起,传统数据库的缓存管理机制存在着不足之处[8].首先,租户间对共享缓存资源的竞争会导致每一租户获取的缓存资源不足以缓存其数据,从而导致低的缓存命中率和不好的用户体验.其次,对于缺乏多租户特性的共享缓存管理策略(LFU、LRU)将会倾向于将缓存分配给具备更高请求速率的租户,从而导致低请求速率租户的缓存命中率极低.据此,文献[8]指出在云计算环境下将缓存作为云服务的重要性并讨论了云缓存服务的系统原型Blaze,Blaze迭代地将缓存分配给具有最大收益的租户并采用基于CLOCK的多租户缓存替换策略,保证租户的SLA同时最大化系统性能.针对共享存储模式下,传统磁盘和缓存管理策略在处理不同服务访问模式时显著的性能下降问题,Argon[9]采用预取/回写技术、缓存划分和量化磁盘时间调度3种机制使得每一服务达到预期的有效性指标(相对于独立运行时的效率比值),使得磁盘服务的有效性得到显著提高,其中预取/回写技术以及量化磁盘时间调度与本文的研究互补,可以很好的与本文的多租户缓存管理策略相结合.在服务间的缓存划分上,Argon需要建立独立执行模式下缓存空间与I/O产出效益间的对应函数关系,其建Page3立过程时间较长,而本文的SAMTMM不需要建立此函数关系,因此没有准备阶段的资源消耗,可以更好地适应在线调整;此外,Argon关注的是服务间的存储共享,而本文关注的是服务内租户间的存储共享,共享粒度的不同导致磁盘数据组织形式的不同,因此Argon并不直接适用于SaaS模式下的多租户数据库缓存管理.与Argon不同,文献[10]采用曲线拟合建立每一服务缓存与命中率(I/O产出效益)之间的函数关系,动态地为每一服务分配缓存空间,满足每一服务QoS的同时尽可能地提高系统的整体缓存命中率;文献[11]提出了相对分化缓存服务模型,采用基于回馈的启发式缓存分配策略动态调整每一类请求所获取的缓存大小从而实现不同类别请求的缓存命中相对比.它们均不需要Argon中建立缓存空间与I/O产出效益函数的准备阶段的资源消耗,因而能够快速地适应访问模式的变化并进行在线调整.但是与本文不同,文献[10]关注的是软QoS,而文献[11]中缓存分配的最终优化目标是满足不同类型请求所指定的QoS比值,而不是满足其QoS,这与本文多租户缓存管理机制中的SLA响应时间存在着需求上的差异.在缓存替换策略方面,常用的缓存替换算法有LRU、LFU和LRU-K[12]等.这些算法通常以页面作为替换单元,并采用引用流作为单一的评价页面缓存的标准,从而最小化页面缺失率;其中最为常用的为LRU,因为它易于实现并且时间复杂度不高,但是其存在许多不足,如读取一系列的不经常使用的页面,则经常被引用的页面就会从缓存中驱逐出去,这就导致了缓冲池污染.针对这一问题,许多基于LRU改进的算法被提出,如LRU-K算法,该算法跟踪最后一次对页面进行K引用的时间,并按该信息对页面进行排序;当需要读进新的页面时,则根据缓存页面的等级剔除等级低的页面从而防止缓存池被污染;与LRU-K极为类似,MySQL/InnoDB采用带有中点策略的LRU替换策略[13],该策略的LRU缓冲池链表中包括新链表和旧链表,对每一个读进缓存的新页面,他们均被放在新链表中,当且仅当规定的时间内该页面再次被访问,那么该数据块才会被放入旧链表中;目前这些成熟的缓存替换算法均采用页面作为缓存单元,但是未考虑SaaS共享存储架构下以页面作为替换单元存在着缓存浪费,而如何给出适应共享架构的缓存单元也并未被深入研究.3多租户缓存管理的理论基础本节将介绍与多租户缓存管理相关的理论基础,为下一节基于I/O价值的动态缓存单元的多租户缓存管理机制做铺垫.首先给出ChunkFolding和租户访问模式的简化模型,然后结合ChunkFolding共享存储架构的特性及MySQL的查询优化器给出其执行计划模型;最后结合该执行计划模型给出计算任意请求的I/O次数的公式化定义.3.1ChunkFolding及租户访问模式ChunkFolding预定义一系列适当模式的Chunk表,其中预定义的Chunk表的每一属性列均有明确的数据类型.对租户个性化定制后的逻辑表,ChunkFolding采用列划分技术,将其存储到与其结构最为相近的若干Chunk表中.其中,基本表的两个元数据列(Tenant,Row)和Chunk表的4个元数据列(Tenant,Table,Chunk,Row)用于还原租户的逻辑表,此外为了加速查询速度,在元数据列上建立组合索引TR和TTCR.例1.设有一个CRM管理系统,其基本表信息包括身份证和姓名,即CRM(id,name),设有3个租户其ID为1、2、3,租户1未定制字段,租户2定制了邮编字段,租户3定制了年龄和家庭住址字段.3个租户的逻辑模式如图1(a)所示,预定义的ChunkFolding表模式为CRMbase和CRMchunk模式,其对应的共享存储架构如图1(b)所示,其中灰色的属性列是元数据列.为方便问题阐述,我们将不再区分基本表与Chunk表,即基本表与Chunk表均包含4个元数据列(Tenant,Table,Chunk,Row)和组合索引TTCR.图1租户逻辑模式与ChunkFolding映射关系为方便我们接下来的问题描述,我们将给出ChunkFolding的形式化定义.设逻辑表R,其属性集A={A1,A2,…,An},C={C1,C2,…,Cm}是采用ChunkFolding共享存储架构后台预定义的ChunkPage4表,则逻辑表R与后台ChunkFolding的对应模式映射信息定义如下.定义1.映射关系.逻辑到物理α:Ai→(Cj,k).表示关系R的属性Ai位于后台Cj块内,且为其分配的全局唯一编号为k.物理到逻辑β:(Cj,k)→{Ai,…,Ai+p}用于获取编号为k的数据块Cj所包含的属性集合.服务运营商可以跟踪一段时间内租户发起的数据库访问来获取租户访问模式,我们将其建模为一个有序对(q,wq),q=1,…,Q.其中q代表第q个请求,wq是第q个请求的频率.需要注意的是这里的Q个请求都是非事务型的,但SaaS是面向事务型的应用,所以会包括事务型的请求.对于事务型请求我们采用重写逻辑[4],将其分为两个阶段:(a)查询阶段.收集所有满足更新条件的行号(即元数据列,Tenant,Table,Chunk,Row).(b)更新阶段.更新满足更新条件的行所对应的更新列.由于数据库缓存机制只会减少读操作的I/O次数,而并不能减少写操作的I/O次数(可通过延迟写,日志记录),所以本文将只考虑事务型请求的阶段(a)的I/O代价,而通过减少阶段(a)的I/O代价也可以显著提高事务型请求的处理效率.简单起见,本文剩下的部分所有的请求集除非特别说明,将都是非事务型的.3.2执行计划为执行一个请求,查询优化器需要生成所有的图2MySQL基于嵌套索引的左深树执行计划验证执行计划,然后选择代价最小的执行表访问.主要有两种表扫描方式:顺序扫描和索引扫描.索引扫描不需要扫描整个表,而只需要访问满足条件的元组所属的磁盘块即可.使用索引扫描需要满足两个条件:(1)在对应的查询中有索引可用,(2)满足条件的元组的数目远小于表中所有元组的数目[14-15].本文的代价估计是基于嵌套索引的左深树执行计划来进行计算的,理由如下:(1)ChunkFolding共享架构下的所有请求都需要被重写添加上元数据列[4],而元数据列上均建立了组合索引TTCR,因此有索引可用.(2)ChunkFolding共享架构下Chunk表中存储了成千上万租户的数据,对于特定租户特定表的查询,满足条件的元组的数目相对于Chunk表中的元组的总数目而言很少.(3)MySQL的查询优化器的执行计划都是基于左深树的代价估计[16],对于其它数据库的代价估计则需要配合与对应的查询优化器相结合从而得出相应的I/O代价估计.(4)本文关注的重点是缓存管理机制,所以我们尽量避免由执行计划选择上的不确定性因素导致的缓存单元I/O代价估计的不准确.因此,本文中的所有请求均事先经过MySQL的analyze/explain命令进行执行计划的验证,从而保证了代价估计的准确性,其验证过程如图2所示.Page5图2中我们以典型的TPC-W中的查看产品信息请求作为示例,其中的逻辑模式与后台ChunkFolding物理模式的映射关系见5.2节.从图2中MySQL查询优化器的执行过程我们可以得出,Chunk表的访问以及表间连接是基于索引的(对应table,type列),而且每一Chunk表的访问均采用TTCR索引(对应key列),并利用过滤后的TTCR作为访问下一Chunk表的条件(对应ref列),依次类推,该过程是一个典型的基于嵌套索引扫描的左深树执行计划.为进一步验证对执行计划假设的正确性,我们分别测试了相同租户数目不同规模(租户)数据集下查询优化器的执行过程,结果显示与图2类似.图3给出了基于嵌套索引扫描的左深树的MySQL执行计划图,该执行计划共涉及到3个Chunk表.图中IXSCAN表示Chunk表的访问采用索引扫描的方式,TTCR代表使用的索引(Tenant,Table,Chunk,Row),Fetch操作用于访问Chunk表从而取得对应元组的相关的属性列,NLJOIN表示采用嵌套索引扫描的方式.对于每一个请求,本文中我们主要考虑I/O代价,也即每一个虚线框内的I/O代价之和,其中一个虚线框代表的是访问一个Chunk的代价.图3MySQL基于嵌套索引的左深树执行计划示意图3.3I/O代价估计从图3所示的执行计划示意图我们可以得出,对于一个请求,其I/O代价为所有虚线框内的FETCH操作磁盘I/O次数与每一次I/O花费时间乘积之和;对于索引扫描,FETCH操作的I/O次数与这个数据块被访问时满足条件的元组数目关系很密切,我们设第i个Chunk被扫描时,符合条件的元组的数目为ki,基于文献[14-15]给出的公式有第i个Chunk被扫描时需要的I/O次数即为E(IOi)=mi×1-Ckinid在函数(1)中,mi表示第i个Chunk占据的磁盘空间对应的数据库逻辑页面的数目,ni表示第i个Chunk中的元组的数目.对于一个请求,如果没有任何数据被缓存,则其需要的磁盘I/O次数为所有Chunk的I/O次数之和,即其中d是查询中涉及到的Chunk的数目;如果某一FETCH操作所涉及的属性集刚好全在缓存中,则对应的FETCH操作的I/O次数为0.通过式(1)和(2)我们可以计算出任意一个请求所需的I/O次数,接下来我们将给出如何计算每一次I/O的时间.本文将借鉴文献[17]给出的在随机请求情况下的磁盘驱动模型来计算一次I/O的时间,其对应的所需要的设备参数和数据库参数如表1所示.采用随机请求下的I/O时间估计是由于在共享存储模式下,租户间的数据相互交叉存储,因此每一租户的数据在磁盘上的分布是分散的,查询中所涉及的元组在磁盘上的位置呈现出随机分布的状况.表1计算一次I/O平均时间所需的设备参数单面磁盘磁道数L磁道i的扇区数Ci单盘面的扇区数M磁盘转速短寻道磁道上界Q扇区大小DB数据块大小P一次I/O所需要的时间主要包括寻道时间、旋转等待和传输时间3个部分,因此一次I/O的平均时间等于平均寻道时间、平均旋转等待和平均传输时间之和,即寻道时间与寻道长度d有关,其对应的计算公式如下:式(4)给出了寻道距离为d的寻道时间,平均寻道时间则假设磁头以相同的概率位于每一磁道上,也即1/L,那么以任意磁道作为起点的平均寻道时间之和为平均寻道时间.因此,Costseek=∑LPage6平均旋转等待时间是磁盘旋转半周的时间,因此,平均传输时间等于磁道被访问的概率与对应磁道读取单个数据库数据块所需时间代价的乘积之和,因此,Costtransfer=∑L4多租户缓存管理机制在多租户环境下,分配较多的缓存给一个租户可以减少该租户的I/O次数,但是留给其他租户的缓存就会不足;分配较少缓存给一个租户则会导致该租户的I/O次数增多,留给其他租户的缓存量会相对充裕.在本节我们将给出适应租户访问模式的多租户缓存分配策略,该策略为每一个租户分配保障其SLA响应时间需求的尽量少的缓存,从而尽可能多的缓存可被留给其他租户.4.1基于租户访问模式的缓存单元及犚犗犆值计算传统数据库的缓存单元通常是一个数据库逻辑页,但是在SaaS多租户共享存储架构中,以数据库逻辑页作为缓存单元存在诸多的不合理性,如:(1)多个租户的数据分散存储在一个共享架构中,一个数据库逻辑页中会包含大量其他租户的无用数据,仅仅出于一个租户的性能考虑而缓存整个数据库逻辑页,导致大量缓存空间的浪费;(2)在SaaS中的服务请求均是基于Web提交的,而Web页面的访问遵从Zipf分布,即仅有20%的请求是经常被使用的,而这些请求都是基于HTML模板提交的,变化的只有参数,这就说明某几个属性列被经常使用[18],也就意味着采用元组作为缓存单元同样有其不合理性.出于上述两点问题的考虑,本文采用列缓存代替传统数据库的页缓存;传统数据库的页缓存机制中以固定页作为缓存单元,而在我们的列缓存中,我们采用动态生成的列属性集作为缓存单元,我们称为列缓存单元.对于一个涉及n个属性的请求集,则其备选列缓存单元数目为2n,如果考虑所有的备选列缓存单元,则代价很高.文献[19]提出了基于访问模式驱动的缓存单元生成策略,以当前的访问模式作为输入,输出一系列缓存单元.QueryAccessSet(QAS)这个概念在文献[19]中被使用,它被定义为一个关系中被某个请求访问的属性的集合.借鉴该思路,结合ChunkFolding特性,我们给出QAS的重新定义,并将QAS作为初始候选缓存单元从而大幅减少备选缓存单元的数量.定义2.QueryAccessSet(QAS).QAS或者是一个查询中的谓词集(PredicateSet,PS),或者是一个查询中所涉及的位于同一Chunk编号的普通属性集(OrdinaryAttributeSet,OAS).将QAS作为初始候选缓存单元的理由,如图3中所示,对于一个查询,将其谓词存放在缓存中可以过滤掉不满足条件的元数据索引项,这样在进行下一个基于索引的FETCH操作时需要读取的元组数目会减少,从而I/O次数会减少;而查询中涉及到的位于同一Chunk编号的属性集作为替换单元是因为对于任意一次FETCH操作,当且仅当该查询所涉及位于一个Chunk编号的属性集作为一个整体同时被缓存才会减少I/O,而将其子集进行缓存不会达到减少I/O的效果.生成初始候选缓存单元的算法如算法1所示.算法1.生成初始候选替换单元(GenerateInitialCandidateReplacementUnits,GICRU).1.IN:D,Tenant’sdatamappinginformation2.IN:Q,QueryAccessModel3.OUT:CRU,GeneratedCandidateReplacementUnits4.BEGIN5.SETCRU··=Page76.fortheithqueryqiinQ7.foreachpredicatepofqueryqi8.CRU··=QAS(qi,α(p))∪CRU9.endfor10.forthejthchunkoftenantT’sphysicalchunk11.CRU··={β(CTj,k)∩OASi}∪CRU12.endfor13.endfor14.returnCRU15.END算法1以租户的访问模式信息及租户逻辑模式与物理模式之间的映射信息作为输入,输出对应初始候选缓存单元.对访问模式中的每一个请求(对应第6~13行),首先将其谓词添加到候选缓存单元CRU中(对应第7~9行),然后对于其它普通属性集则按租户的物理模式的分块信息进行划分,将属于同一Chunk中的属性作为缓存单元添加到初始候选缓存单元CRU中(对应第10~12行).为更形式化地描述我们的缓存单元生成算法,我们通过具体的例子来查看如何生成初始候选缓存单元.例2.逻辑表R(A1,A2,A3,A4,A5),逻辑模式与后台Chunk表的映射函数:α(A1,A2)=(C1,0),α(A3)=(C2,0),α(A4,A5)=(C3,0),也即{A1,A2}被映射到Chunk表C1,并赋予其编号0;{A3}被映射到Chunk表C2,并赋予其编号0;{A4,A5}被映射到Chunk表C3,并赋予其编号0.访问模式统计信息及生成的初始候选缓存单元如表2所示,对于每一个访问所涉及的属性分为谓词属性集(Predi-cateSet,PS)和除谓词外的普通属性集(OrdinaryAttributeSet,OAS).访问模式信息候选缓存单元算法1给出了如何计算候选缓存单元,而对于每一个缓存单元必须定义其对应的I/O效益率,也即放入缓存后减少的I/O次数和占用的缓存空间大小的比值,我们将该值定义为ROC(ReturnonConsumption),ROC的计算需要两个参数,(1)缓存单元放入缓存后占据的缓存大小M和(2)减少的I/O次数D,因此对缓存单元i,有Mi可以利用QAS内属性类型大小之和与元组数目的乘积来获得;Di可以结合式(2),利用缓存单元i不在缓存时所有请求的I/O次数减去缓存单元i在缓存时的所有请求的I/O次数:Di=∑Q其中S表示已经贮存在缓存中的属性集,S∪Ui表示将缓存单元Ui放入缓存;q为S时第q个请求的I/O次数.4.2基于贪婪算法的缓存策略上一节给出了如何计算初始候选缓存单元及其ROC值,接下来我们将给出如何选择缓存单元放入缓存以及如何动态更新候选缓存单元集和对应的ROC值.首先,选择ROC值最高的缓存单元放入缓存,并将该缓存单元从候选缓存单元集中去掉;其次,更新与刚被选中放入缓存的缓存单元有交集的那些候选缓存单元,将其交集部分去掉从而生成新的候选缓存单元;最后,计算更新后的候选缓存单元集的ROC值,其计算过程同样采用式(9).重复上述过程直到满足租户的SLA响应时间,也即其中I/O(qi)代表第i个请求的I/O次数,可以通过式(2)计算得出;Tsla代表租户的SLA响应时间需求.表3将QAS(狇1,(犆3,0))={犃4}放入缓存后的初始候选缓存单元更新候选缓存单元继续例2所示的例子,现在我们假设经过计算QAS(q1,(C3,0))={A4}的ROC值最高,因此其被选中进入缓存;由于剩下的候选缓存单元中QAS(q3,(C3,0))={A4,A5}与QAS(q1,(C3,0))={A4}的交集为{A4},所以不是空集,因此QAS(q3,(C3,0))={A4,A5}将会更新成QAS(q3,(C3,0))={A5},更Page8新后的候选缓存单元如表3所示.SetSelecting,BASS).算法2.最优属性集选择算法(BestAttribute1.IN:D,tenant’sdatastatistics2.IN:W,workloadstatistics3.IN:SLA,tenant’sSLArequirement4.OUT:AS,AttributeSetshouldbeplacedinmemory5.BEGIN6.SETAS··=7.SETCRU8.SETROC9.CRU··=GICRU(W,D)10.ROC··=ComputeROC(CRU,D,W)11.while(TAS>TSLA)12.AppCRU··=CRUwithMax(ROC)13.AS··=AS∪AppCRU14.CRU··=UpdateCRU(CRU,AppCRU)15.ROC··=UpdateROC(CRU,D,W,AS)16.TAS··=AverageI/Os(W,D,AS)×Costdisk17.endwhile18.returnAS19.END上述的缓存单元选择过程类似于经典的背包问题,唯一不同的地方在于物品和物品的价值会因放入背包的物品的不同而改变,我们称之为变种的背包问题,并采用贪婪算法来选择属性集,具体实现如算法2所示.算法以租户的访问模式信息、租户数据的统计信息以及租户的SLA响应时间需求作为输入,输出最终的缓存属性集.该算法首先计算初始候选缓存单元及其ROC值(对应第9~10行),然后重复选择ROC值最高的候选缓存单元并更新剩余候选缓存单元及其ROC值(对应第11~17行),其中第12行选择ROC值最高的作为此次应用的候选缓存单元,并将其添加到最终缓存属性集AS中(对应第13行),接着更新剩余缓存单元及其ROC值(对应第14~15行),第16行计算了针对当前访问模式下租户的平均响应时间并与租户SLA响应时间进行比较作为循环终止条件.为便于我们更好地对算法2进行时间复杂性分析,我们先定义3个参数:请求模板数目m、模板的实例化数目n(mn)和模板的平均属性数目A;所谓请求模板指的是SaaS应用中所包含的SQL模板,模板中包含若干个需要用户填充即时值的属性,对于给定的SaaS应用来说,模板数目是个常量.实际运行时用户填充即时值到对应的SQL模板中称为模板的实例化,实例化出来的不同的SQL数目称为模板的实例化数目;模板的平均属性数目是指每一个模板所包含的属性数目的平均值.通过分析算法2我们可以发现,该算法主要包含3部分:17行).(1)计算候选缓存单元(第9行);(2)计算候选缓存单元的ROC值(第10行);(3)候选缓存单元的迭代选择过程(第11~对于第1部分计算候选缓存单元(对应算法1),其时间复杂性与请求模板数目和模板属性集在后台的数据分块的分布有关,最坏情况下假设一个数据分块只含有一个属性,故其时间复杂性为O(mA).对于第2部分计算候选缓存单元的ROC值,其时间复杂性与候选缓存单元的数目以及每一个候选缓存单元涉及到的实例化模板数目有关,最坏情况下有mA个候选缓存单元,并且每一候选缓存单元与所有的实例化模板均有关,故其时间复杂性为O(mnA).对于第3部分候选缓存单元的迭代过程,其时间复杂性与迭代次数以及每一次迭代所需要的计算量有关,由于我们最多有mA个候选缓存单元,因此迭代次数最坏情况下为mA次,而每一次迭代中所需要的计算(对应第12~16行)只有第15行是耗时最多的,其它均为O(1)的,其中第15行事实上是第2部分的重复执行,其时间复杂性也为O(mnA),故该部分的时间复杂性为O(nm2A2).通过上述分析我们可以看出该算法的时间复杂性为O(nm2A2),故其时间复杂性是多项式的,因此该算法可以高效的运行.4.3自适应缓存机制的实现上一节给出了缓存替换单元的生成和选择过程,本节我们将给出自适应缓存机制的完整实现过程,主要包括两个阶段:(1)监测阶段.统计最近一段时间内租户访问模式的统计信息和每一请求的响应时间.为了预防随机噪声产生严重的震荡,我们将记录足够长的时间间隔内的平均响应时间,并将该时间和租户SLA响应时间进行比较.由于响应时间的统计差异,我们认为租户SLA没有满足当且仅当当前平均响应时间超过了容忍范围δ.如果目标SLA没有满足,那么我们将进入阶段(b),否则我们将结束当前监测并进入下一轮监测.(2)微调阶段.在这一阶段我们将采用阶段(1)Page9收集的相关信息并结合4.2节给出的缓存单元的选择过程,计算当前访问模式下的缓存属性集,剔除不应在缓存的属性集,添加尚不在缓存的属性集,并进入阶段(1).算法3.自适应多租户缓存管理算法(Self-AdaptMulti-TenantMemoryManagment,SAMTMM).1.BEGIN2.foreachtenantT3.IN:D,tenantT’sdatastatistics4.IN:AS,AttributeSethasbeenplacedinmemory5.SETQS··=6.while(thecurrenttimeslotisnotelapsed)7.if(thereisarequestQ)8.QS··=QS∪Q9.Time··=Time+Qt10.counter++11.endif12.endwhile13.TOBS··=Time/counter14.if(|TOBS-TSLA|/TSLA<δ)15.Discardcollectedinformationandstartthenext16.else17.TmpAS··=BASS(QS,D,TSLA)18.KickoutAS-TmpAS19.ReadinTmpAS-AS20.AS··=TmpAS21.endif22.endfor23.END算法3中第6~12行对应监测阶段,第13行计算对应时间段内观察到的平均响应时间,第14行判断该时间段内的响应时间是否满足租户SLA需求,不满足租户SLA需求时,则进入微调阶段对应第16~21行.5性能测试5.1实验环境的搭配本文采用TPC-W[20]作为我们的测试基准平台,采用ApacheTomcat作为应用服务器,后台采用MySQL/InnoDB作为数据存储引擎,之所以选择InnoDB作为存储引擎,是由于InnoDB对于事务型请求的加锁粒度基于行的,因此租户可以并行地访问对应的共享架构中的数据而不影响其他租户的执行.Apache服务器和MySQL数据库部署在PC机上,采用Intel酷睿2双核处理器,主频为2.33GHz,拥有2GB大小的内存和250G硬盘.硬盘具体参数如表4所示,由于希捷官网并没有公布短寻道磁道上界,而仅公布了平均寻道时间,所以这里的平均寻道时间取8ms,而平均旋转延迟和平均传输时间均可由第3节公式求得.参数单面磁盘磁道数3876168磁道扇区数63单盘面的扇区数2390311315磁盘转速7200短寻道磁道上界#扇区大小512BDB数据块大小16KB平均传输时间0.43ms平均寻道时间<8.15ms平均旋转延迟4.16ms在我们的实验中共有120个租户,也即120个零售书店,每一个零售书店允许同时在线的用户数最大为100.我们采用10个相同配置的终端来模拟外部顾客的访问请求,每一个终端可被配置用来模拟1200个顾客的针对不同零售书店的请求.每一顾客提交请求(请求均是经MySQL执行计划事先验证处理过的)并等待一个响应;在提交另一个请求之前,我们采用平均值分别为7s,14s,21s的负指数分布来模拟高频、中频和低频顾客的思考时间.5.2实验数据集我们采用TPC-W基准测试平台中的数据库模式作为我们的测试模式(即租户逻辑模式),如图4所示,括号中列出了每一个属性的数据类型,通过观察我们发现该模式共有4种数据类型(INT,DOUBLE,DATE,VARCHAR),因此我们后台的基于ChunkFolding共享存储架构的设计如图5所示,其中Chunk0包含4个业务数据属性列A1,A2,A3,A4,分别对应数据类型INT,DOUBLE,DATE,VARCHAR;Chunk1包含两个业务数据属性列A1,A2,其数据类型均为INT;Chunk2包含3个业务数据属性列A1,A2,A3,其对应的数据类型均为VARCHAR;这3个Chunk表的前4个属性列为元数据列,用于还原租户的逻辑模式,其中Tenant属性用于标记不同的零售书店,并且在这4个属性列上建立组合索引TTCR.需要注意的是由于文献[4]并未给出如何设计一个最优的基于ChunkFolding的共享存储架构,因此图5中的基于ChunkFolding的共享存储架构并不是一个针对该逻辑模式的最优的共享存储架构;同样本实验中采用的逻辑模式和共享存储模式之间的映射关系也并不一定是最优的,而只是我们目前能找到的比较紧凑的映射关系,其对应的映射关系如表5所示.Page10图4测试中采用的TPC-W中的逻辑模式表5TPC-W的逻辑模式与ChunkFolding共享存储逻辑表名CUSTOMERORDERSORDER_LINEADDRESSSTOCKα(S_I_ID,S_QTY)=(Chunk1,4)ITEMCOUNTRYα(CO_ID,#,#,CO_NAME)=(Chunk0,10)AUTHORα(A_ID,#)=(Chunk1,6)图5测试中采用的ChunkFolding共享存储架构实验中数据集,其中AUTHOR表中的A_LNAME和ITEM表的I_TITLE字段是整个模式的基本字段,采用TPC-W提供的工具程序WGEN生成,其它字段按照TPC-W规范随机产生.对于每一个租户我们生成大约20M左右的数据,不同租户的数据是随机交错的插入数据库的,也即每一个租户的数据在磁盘上是分散存储的.需要提及一点的是对于逻辑模式中的主键和外键约束,在我们的ChunkFolding共享架构中均被删除,这样可以方便我们的I/O代价估计,同时也使得影响实验的其它不确定性因素减少,从而使得我们能够更加专注于缓存机制对查询性能的影响.5.3实验结果第1个实验中我们通过变换租户的SLA响应时间需求,对比采用传统MySQL/InnoDB带有中点策略的LRU缓存策略以及本文提出的多租户缓存策略下的缓存消耗,图6给出了单租户条件下的实验结果.Page11图6不同响应时间需求,采用LRU与SAMTMM时的缓存消耗从图6中我们可以看出不同响应时间需求下,SAMTMM所需要的缓存明显低于LRU所需要的缓存.上一节我们指出每一租户的数据大小为20M,这就意味着理想情况下缓存单个租户的全部数据至多需要20M左右的缓存.从图6所示的实验结果来看,在响应时间需求为10ms时,SAMTMM使用了约16M左右的缓存从而达到了这一目标需求,其大小十分接近租户数据的实际大小,然而采用LRU缓存策略却花费了大约100M左右的缓存,造成这一现象的根本原因在于LRU缓存策略是以数据块作为缓存单元的,而在多租户共享存储架构下,数据块中存储了大量其他租户的无关数据,浪费了缓存空间.第2个实验中我们设置MySQL的缓存大小为图7采用LRU和SAMTMM策略时3种访问频率租户的平均响应时间以及对应的整体缓存消耗700M,并设租户的SLA响应时间需求均为100ms,从图6可以看出为满足这一需求,SAMTMM为每一租户分配大约5M缓存(该值不随活跃租户数目改变),而LRU为每一租户分配大约50M缓存(该值随活跃租户数目的增多会逐渐减少);依据租户的访问频率将其分为3个类别:高频访问、中频访问和低频访问(通过设置不同零售商的顾客平均思考时间来模拟实现).通过等比例地增加不同类别租户的数目(一次增加6个,低频、中频和高频各2个),对比LRU缓存机制与SAMTMM缓存机制下不同类别租户平均响应时间.从图7(a)中可以看出,LRU缓存策略下高频租户的响应时间明显低于租户SLA响应时间需求;从图7(b)和(c)中可以看出在租户数目较少时,中频和低频的响应时间均比较快,当租户数目增多的时候,中频和低频的响应时间都会明显变慢,并且远远高于租户SLA响应时间需求,此外低频租户的响应时间增长的明显比中频租户的要快很多,出现这种现象的原因在于,LRU缓存机制从数据库整体性能考虑,在初始租户数目较少的时候,缓存相对多,所以采用LRU缓存策略就将大量缓存分配给了这些租户,使得其响应时间很快(均低于SLA需求);而当租户数目逐渐增多时,缓存就变得紧张,采用LRU缓存策略就会将更多的缓存分配给了高频访问的租户,所以中频和低频访问的租户大量的缓存被抢占了,从而响应时间会Page12明显变慢;对于采用SAMTMM缓存机制时,高频、中频和低频租户的响应时间均在租户SLA响应时间附近波动,而并没有出现缓存资源分配的不合理现象.从图7(d)中可以看出采用SAMTMM缓存机制,分配的缓存数量与租户数目成线性增长,这是因为我们这里的租户除了访问频率不一样以外,其它各方面都是完全一样的,因此每一租户为满足其SLA所需要的缓存就基本相同;而对于LRU缓存机制来说,开始一段时间分配的缓存数量随租户数目成线性增长,而后期保持700M不变,这是由于起始租户数目不多时,每一租户的数据都被完全缓存,而采用块缓存导致缓存被快速消耗,随租户数目的进一步增多,LRU会替换掉低频和中频租户的缓存以留给高频租户.6总结本文我们给出了基于ChunkFolding的多租户共享架构下的缓存管理机制,通过采用自适应的缓存单元可以大幅减少由于共享架构导致的以数据块作为缓存单元导致的资源浪费;通过租户SLA作为驱动为每一个租户分配缓存可以防止租户间资源分配的不合理,如高频租户抢占大量缓存,最终使得每一租户获得满足其SLA需求的尽量少的缓存.本文假设租户进入系统后保持在一定的活跃状态,而如何监测租户的活跃程度并设定一个合理的阈值,驱逐不活跃租户的缓存空间,保证每一租户的SLA需求的同时提高整体利用率是下一步需要解决的问题.另外本文目前给出的是单节点下的缓存策略,如何考虑多数据节点下的数据分布并将其拓展到多节点上以满足多租户SLA需求是下一步需要解决的问题.
