Page1ELF:基于无用块消除和低重用块过滤的共享Cache管理策略隋秀峰1),2)吴俊敏1),3)陈国良1)唐轶轩1)1)(中国科学技术大学计算机科学与技术学院合肥230027)2)(中国科学院计算技术研究所北京100190)3)(中国科学技术大学苏州研究院江苏苏州215123)摘要当代CMP处理器通常采用基于LRU替换策略或其近似算法的共享最后一级Cache设计.然而,随着LLC容量和相联度的增长,LRU和理论最优替换算法之间的性能差距日趋增大.为此已提出多种Cache管理策略来解决这一问题,但是它们多数仅针对单一的内存访问类型,且对Cache访问的频率信息关注较少,因而性能提升具有很大的局限性.文中提出一种统一的Cache管理策略ELF,不仅可以覆盖多种访存行为,而且能够同时考虑程序中数据的临近性和使用频率信息.根据LLC中Cache块在其生命期内使用频率较低这一实验结果,ELF策略能够(1)通过基于计数的算法预测出无用块并将其尽早替换;(2)通过动态插入和提升策略过滤低重用数据,从而尽量保留那些潜在的活动数据并且使得一部分工作集免受低使用频率数据的干扰.在4路CMPs上的实验结果显示,ELF可以将全局性能平均提升14.5%,同时与PIPP和TADIP相比,可以分别达到1.06倍和1.09倍的加速比.关键词多核;共享高速缓存;插入策略;替换算法;基于计数的算法1引言随着处理器和存储器之间速度差距的日益增大,存储系统设计业已成为影响计算机系统性能的关键要素之一.当前,多核处理器普遍通过大容量、高相联度的最后一级片上Cache(Last-LevelCache,LLC,在本文中是二级Cache)来提供对最近访问过的数据的快速访问.从理论上讲,为了达到最高的Cache命中率,LLC应该采用最优替换策略OPT[1],但是由于OPT算法要依赖于数据的未来使用信息,在硬件实现上过于复杂,因此长期以来商用处理器中所广泛采用的是LRU替换策略或其近似算法.然而,近年来大量研究成果表明,在高相联度Cache中LRU和OPT之间的性能差距正在日益增大,突出表现为LRU策略对内存受限应用的性能较差,其原因在于以下几个方面:(1)LRU策略在缺失(命中)时将数据直接插入(提升)到MRU位置,这样数据在完成最后一次访问而成为无用数据后,往往需要跨越大部分Cache路而最终成为候选替换块;(2)LRU策略在选择替换块时仅仅考虑了Cache访问的临近信息而忽略了数据的访问频率;(3)负载中存在着数据的循环访问模式,若可用Cache空间不能完全容纳负载工作集,LRU策略可能导致Cache抖动.目前,围绕如何缩小LRU和OPT之间的性能差距已经开展了大量的研究工作[2-7],而解决此问题的方法之一就是将一部分工作集尽可能长时间地保留在Cache中,使得至少这部分数据可以获得较高的命中率.基于这一思想,本文提出一种基于无用块消除和低重用块过滤的共享Cache管理策略ELF,与先前工作的最大区别就在于ELF在管理LLC时考虑了数据的使用频率,并通过对Cache插入、提升和失效选择策略的优化达到缩减工作集的目的.具体地,在二级Cache和主存之间增加使用频率预测器硬件,可以根据缺失块的访问历史预测出其使用频率,针对预测结果,ELF能够(1)有效地标识出低使用频率数据块,在缺失时依概率将其插入到LRU位置,而命中时仅向前提升一个优先级位置;(2)尽早识别出无用数据块并优先将其替换出二级Cache.这样,当有足够数量的数据块被过滤和消除后,一部分由高使用频率数据所组成的工作集就可以保留在Cache中从而获得高访问命中率.评测结果显示,与传统的LRU策略相比,ELF可以将全局性能平均提升14.5%,同时与PIPP(Promotion/InsertionPseudo-Partitioning)和TADIP(Thread-AwareDIP)相比,可以分别达到1.06倍和1.09倍的加速比.2背景由于二级Cache失效会造成处理器停顿数百个周期,因此本文的研究主要集中在怎样通过有效地管理二级Cache来减少其缺失数.为了简化后文的讨论,本节将重点介绍多核负载特性、Cache插入/提升管理等背景知识及本文的部分相关工作.2.1负载特性由于部分数据访问会在一级Cache中发生命中,因此二级Cache可见的访问流经过滤后会损失一定的时间局部性,这在很大程度上降低了二级Cache中数据块的使用频率.图1给出了25个单线程应用(出自SPEC2000和SPEC2006基准测试程序集)的二级Cache块使用分布情况,其中每个应用都使用ref输入集,并分别执行具有代表性的10亿条指令.二级Cache的配置为4MB、16路组相联、基于LRU替换策略,关于仿真环境的详细描述参见第4节.Page3图1SPEC2006中部分单线程应用的二级Cache块使用分布情况对于图1中的每个应用,根据二级Cache块的使用次数将全部Cache块分成5类,类别[x,y]包含使用次数至少为x、至多为y的所有数据块,在此将使用次数只有一次的Cache块列为单独的一类.从该图中可以看出,绝大多数应用的大部分Cache块的使用次数都介于2和4之间,如在173.applu、445.gobmk和470.lbm中,几乎所有的数据块都属于这一区间;另外,还有一些应用中存在着较大比例的单一使用Cache块,通常这样的Cache块被称为0-重用块(在被插入和替换之间没有被重新引用),例如在189.lucas和459.Gems中,0-重用Cache块所占的比例几乎可以达到50%.0-重用块的产生一般是基于如下两方面的原因:首先,某些Cache块并不具有时间局部性,在进入Cache后根本不会被再次访问,将这样的数据块插入到Cache中是不会有任何收益的;其次,某些Cache块的重用距离大于图22.2Cache插入和提升传统的Cache管理策略可以被划分成3个部分:失效选择(选择被替换的数据块)、插入策略(确定新进入的数据块插入到Cache中的位置)和提升策略(如何更新命中块在所在组中的位置).图3给出了两个处理器核共享8路组相联Cache的实例,图中按照自左至右的顺序对应于MRU位置到Cache容量,导致这些块在重用前就被LRU策略替换出去了.图2(a)描绘了应用403.gcc独占4MB、16路组相联、基于LRU替换策略的二级Cache时,第0组的地址访问模式.从中可以看出,不同Cache块的访问频率差异很大,高频块的访问次数平均可占数据访问总数的80%.然而,这些Cache块的访问中间往往夹杂着对低频块的访问.图2(b)是其中100个Cache块(图(a)中非0起点)访问的放大片段,从中不难看出,在LRU策略下,大部分高频Cache块都可能被低频块替换出去.因此,当进行替换块选择时如果能够适当地考虑到数据的访问频率信息,将高频数据块尽可能多地保留在Cache中,那么在某种程度上就能够显著地降低Cache缺失数.另外,考虑频率信息对于Cache抖动问题同样也是有益的.LRU位置.在传统的LRU管理的Cache中,对块6的访问导致块C被替换出去,而新块6被插入到MRU位置;而在随后访问块B命中时,它立即被移动到MRU位置.由图1可知,许多应用中都存在着大量的0-重用数据块,LRU策略将这些块直接插入到或者命中后直接提升到MRU位置实际上延长了它们占据Cache空间的时间,但并不能带来任何Page4性能收益.文献[8]提出了LRU插入策略(LRUInsertionPolicy,LIP)的概念,即将所有新块放入到LRU位置(如图3(a)中的块6).而文献[9]则相对于传统的MRU提升(MRUPromotion,MP)提出了单步提升策略(SingleIncrementalPromotion,SIP),即仅仅将命中块向前移动一个位置(如图3(b)中的块B).LIP和SIP都可以减少无用块在Cache中停留的时间,使得一部分工作集可以长期驻留在Cache中,增加Cache的命中率从而提高其性能.2.3相关工作在微处理器设计领域,有大量研究工作是围绕对Cache性能的优化而展开的.受文章篇幅所限,在此只讨论一些与本文最直接相关的研究成果.基于大量数据块在进入Cache后就不再被重用这一实验结果,可以通过将一部分负载工作集保留在Cache中以达到对这部分工作集的高命中率来优化Cache性能,为此文献[8]提出了动态插入策略(DynamicInsertionPolicy,DIP),在这一策略中,Cache块的插入策略是根据组表决技术的结果动态确定的.新进入的块被插入到LRU位置,并且直到再次被访问的时候才会被提升到MRU位置.这样0-重用数据块能够尽快地被替换出Cache而并不会干扰组内的其它数据.然而,对于只拥有少量0-重用数据块的负载,DIP和LRU策略将展现出类似的性能.后续的研究工作在DIP基础上增加了线程感知的概念,提出线程感知动态插入策略TADIP[10],即在充分考虑每个并发应用的访存请求基础上,通过对单个应用分别设置最优的插入策略来减少共享Cache中无效数据块的数量.在多个并发线程间共享LLC通常会导致破坏性的线程间干扰,在这种情况下,避免短期冲突有时要比保留工作集更加重要.Cache划分技术[2,11]往往可以缓解此类问题,这其中最具代表性的工作就是基于效用的Cache划分(Utility-basedCachePartitioning,UCP)[2],UCP使用经典的低开销监控器电路来收集每个线程的效用度增益信息,然后通过前瞻算法以最大化加权加速比为目标对共享Cache进行划分.此外,Chang和Sohi提出多分时共享划分(MultipleTime-sharingPartitions,MTP)技术来同时优化吞吐量和公平性并且兼顾QoS[7].每个MTP划分通过收缩其它应用所占据的Cache容量可以提升至少一个应用的吞吐量,而多个不公平的划分之间分时共享Cache资源则可以达到支持不同应用的目的.Xie和Loh则在最近提出将DIP和UCP整合在一起的提升/插入伪划分方案PIPP[12],即将某个线程的Cache块插入到访问临近栈中距离LRU为m的位置上,这里m表示划分算法分配给该线程的Cache路数.同时还在插入策略中集成了概率提升策略,即将Cache命中时数据块在访问临近栈中移动的位置与一个静态概率相关联.无用块管理也是优化共享Cache性能的另一个热点研究问题,其中无用块预测技术就试图预测出对给定数据块的最后一次访问.最具代表性的是Kharbutli和Solihin提出的基于计数的无用块预测器LvP[13],在LvP中,每个Cache行都增加了一个记录数据引用次数的计数器,当其值达到阈值时对应的数据块将被预测为无效,而阈值则是在历史表硬件的辅助下动态学习获得的.基准LvP算法最初是在多发射单核处理器中提出的,并且仅用来优化二级Cache的替换块选择策略,本文则将LvP扩展到多核处理器中,并在原有算法基础上增加了对数据块插入和提升的控制,以达到将一部分包含高使用频率数据的工作集保留在Cache中的目的.而最近的一项工作正是探索如何使用无用块预测机制来改善共享Cache的替换精度[14],其思想是当某一组内需要发生替换时,选择在访问临近栈中距离LRU位置最近的无用块作为候选对象,并且只有当数据块从MRU位置迁移出来时,这一策略才会根据引用计数的历史预测出无用的数据块.3无用块消除和低重用块过滤Cache管理3.1ELF硬件结构为了描述方便,本文将Cache块从第一次被引Page5用而进入Cache直到被淘汰这段间隔内的访问次数定义为使用频率.ELF的主要思想是通过过滤低使用频率数据块和尽快消除无用数据块而达到缩小负载工作集的目的.这样,为了使用ELF策略进行LLC管理,我们需要在数据插入到Cache之前确定它的使用频率,同时能够及时地标识出哪些数据块是无用的,显然这些决定都要依赖于Cache块的未来使用信息.为此本文将文献[13]中所提出的活动时间预测器(LvP)扩展到多核处理器中,用以实现对Cache块使用频率及无用Cache块的预测.LvP预测器在Cache行被放置到高速缓存后开始记录其访问次数,当计数器的值达到门限值时,就认为该Cache行成为无用数据.ELF保留了LvP预测器对无用数据的预测,同时又利用所记录的Cache行在前一个生命期内的访问门限来预测Cache行的使用频率.图4所示的是4核处理器的ELF预测器硬件同时,我们还需要在每个Cache行中增加4个额外的域,其中引用计数器C用于计算该Cache块图4ELF的硬件架构结构,该处理器拥有w路组相联共享二级Cache,每个处理器核都有私有的一级Cache,这些一级Cache通过总线互联的方式连接在一个共享的二级Cache上.ELF策略在L2Cache和主存之间增加了一个独立的预测表结构,用来保存没有被缓存的数据的使用频率历史(4位计数器maxCstored)并且在数据重新进入Cache时恢复使用频率信息.预测表被组织成一个256×256的直接映射无标记二维矩阵结构,其中行使用Cache块的hashedPC域(导致Cache失效的指令PC按每8位异或的结果)来索引,而列则通过块地址按每8位异或的结果来索引,这种方式可以同时区分出不同的数据块和同一数据的不同程序阶段,具有较高的预测精度.另外,预测表的访问只发生在二级Cache缺失时,并不修改处理器访问共享Cache的关键路径,因此ELF并不引入额外时间开销.在整个生命期内的引用次数,而计数器maxCpast则用于保存数据在上一个生命期内的引用次数,而Page6Conf是一位的信任比特,用于标识预测表信息的可靠性,只有当该位被设置时,才能够使用预测器的结果进行插入和提升策略的选择.上述全部计数器的宽度都需要根据对典型负载的剖析结果而定,而文献[13]中则得出结论:在每个生命期内二级Cache块的平均访问次数一般相对较小,用一个4位的计数器来保存就可以保证足够的精度.为此,本文同样采用4位宽度的计数器.3.2ELF策略Cache访问的临近和频率信息对于替换策略的指定都是至关重要的,本文所提出的ELF策略同时对二者进行了考虑,ELF进一步改进了文献[13]所提出的LvP算法,在其中根据预测器的结果增加了对数据块的插入和提升策略的控制,以过滤低使用频率数据.ELF策略的算法描述如图5所示,实际上其中包括3个主要方面:插入、提升以及失效选择策略.新来块的插入策略.新块插入到Cache中的位置主要有LRU和MRU两种,ELF会根据对缺失块的使用频率预测结果来确定插入位置,对于0-重用块,直接插入到LRU位置以有效滤除;对于低使用频率块(使用频率低于3),按插入概率Pinsert插入到LRU位置,按概率1-Pinsert插入到MRU位置,文中Pinsert的值被设为3/4;而对于其它情况则都插入到MRU位置.可见,ELF策略将低使用频率数据以高概率被插入到LRU位置,缩短了它们在Cache中的停留时间,明显地起到了对数据的过滤作用(参见算法2d).命中块的提升策略.命中块的提升也有MP和SIP两种策略,ELF同样会根据命中块的使用频率预测信息在二者之间进行选择,对于低使用频率块,采用SIP策略,这样数据块在整个生命期内会随着访问频率的增加而逐渐向访问临近栈中的高优先级位置靠近,导致高使用频率数据的位置优先于低使用频率数据;而对于高使用频率块则以记录其访问临近性信息为主,在命中后直接提升到MRU位置,有利于提供更多的后续访问命中.显然,ELF策略可以同时开发出程序中数据的访问临近性和访问频率信息(参见算法1b).替换块的选择策略.根据2.1节的介绍,典型负载中存在着大量使用频率较低的数据块,它们在进入二级Cache后不久就会成为无用数据块.为此ELF算法首先试图尽早地标识出这些无用Cache块,这样在二级Cache发生缺失而需要选择候选替换块时,可以优先从ELF算法所预测出的所有无用块中随机选择一块作为候选替换块,若并未发现无用数据块,则仍然选取该组中的LRU块进行替换(参见算法2a和2b).4性能评价方法配置.本文使用事件驱动的周期精确多核仿真器Multi2sim[15]来评测ELF的有效性.基本的仿真系统是一个4路的多核处理器,具有4MB、16路组相联的共享二级Cache.每个处理器核是4发射、乱序执行的,采用x86指令集体系结构,具有私有的一级指令和数据Cache.后续实验中模拟器的相关配置信息参见表1.参数处理器核L2Cache(LLC)4MB,64Bline-size,16-way,15-cyclehit.L2存储器300-cycle访问延迟.Page7测试负载.本文采用多道负载来评测ELF策略的性能,这些多道负载是由SPEC2006和MiBench[16]中的部分应用组合而成的.本文首先对SPEC2006中每个应用程序的Cache敏感度进行了研究,并将其划分成Cache友好、Cache适宜、Cache抖动以及流媒体等4种类型,然后分别选取不同类型的应用程序组合成相应的测试负载,而MiBench的使用则参照于PIPP.表2列出了本文所使用的全部负载组合.负载mix00mix01mix02mix03mix04mix05mix06mix07sjeng,povray,wrf,tontomix08mix09对于每个负载,我们首先对Cache资源预热500M条指令,然后对负载中的每个应用都精确仿真250M条指令.当某个应用达到这一界限时,它会继续执行下去以保证对Cache资源的持续竞争.这图64路CMP系统中ELF、PIPP和TADIP的加权加速比比较ELF策略在管理LLC上的性能优越性来源于以下3个方面:(1)基于计数的Cache块使用频率预测算法可以有效地标识出LLC中的无用数据块,并且尽早地将其替换出去,从而延长那些潜在的活动数据在Cache中驻留的时间;(2)将低使用频率数据块依概率插入到LRU位置,并且在后续命中仅仅向前提升一个位置,从而保证一部分高使用频率工作集可以保留在Cache中,以贡献出较高的Cache命中率;(3)替换和插入时同时考虑了数据的临近性和使用频率信息.种评测方案与许多先前工作保持一致[11].度量指标.本文使用多核Cache设计中被普遍采用的两个度量来衡量并发调度负载的性能,分别是吞吐量、加权加速比和公平性[17].其中,加权加速比表明系统执行时间的减少,而调和平均公平性则在性能和公平性之间进行均衡.二者的定义如下:Weighted-Speedup=∑(IPCi/IPCsa,i)(2)Harmonic-Mean-Fairness=N∑(IPCsa,i/IPCi)在等式(1)和(2)中,IPCsa,i表示应用i独占整个共享Cache时的IPC.5实验结果及分析5.1性能加速比图6给出了TADIP、PIPP和ELF3种Cache管理策略的加权加速比,所有数据都是以传统的LRU策略作为基准的.对于表2中的10个多道负载,ELF策略都明显超越LRU,加权加速比的几何平均值高达14.5%;同时与PIPP和TADIP策略相比,ELF可以将LLC性能分别平均提升6.5%和9.02%.图7和图8分别给出了各种Cache管理策略的调和平均公平性度量及吞吐量度量之间的比较.从图中可以看出,除图7中的mix09之外,数据变化的趋势和加权加速比非常类似,这说明多数情况下ELF在提高性能的同时还保证了各并发线程之间的公平性.但mix09的存在提醒我们,在以性能为主要优化目标的Cache管理策略中,有时可能要以牺牲系统的公平性为代价.为此,在设计共享Cache优化策略时,要综合考虑这两方面因素.Page8图74路CMP系统中ELF、PIPP和TADIP的调和平均公平性比较图84路CMP系统中ELF、PIPP和TADIP的吞吐量比较5.2Cache块使用频率预测精度分析由第3节的讨论可知,ELF算法的实施要依赖于Cache块的未来使用频率,为此本文将文献[13]中所提出的LvP算法的硬件结构扩展到多核处理器中,用于实现使用频率预测.图9给出了在4路多核处理器上对于表2中的所有多道程序负载预测算法有效性的分析.从图中可见,对于mix00、mix02、mix07,预测算法的精度可以高达80%以上,而算法的平均预测精度也接近60%.算法之所以具有相对较高的预测精度,是因为我们同时使用数据块地址和导致数据失效的指令的PC来索引预测表,这样既可以区分出不同的数据又可以区分出同一数据的不同程序阶段.然而,由于预测表大小被设置为固定的256×256,不同数据引用指令的PC及其所需访问的数据地址按每8位异或后的结果有可能相同,这样就会导致预测表的伪命中现象.尽管扩大预测表的规模可以削弱甚至消除伪命中,从而获得更优的性能收益,但是考虑到硬件设计开销和性能之间的折衷,本文仍然采用与文献[13]中相同大小的预测表结构.5.3对Cache容量的敏感度分析Cache的性能可以通过有效地管理Cache资源或增加Cache容量两种方式来提升[8].图8给出了表2中所有负载在基准LRU和ELF两种策略下的平均每1000条指令的二级Cache缺失数(MissesPer1000Instructions,MPKI),其中Cache容量分别为1MB、2MB和4MB,并且在这些配置下二级Cache的相联度恒为16路.根据图10,在ELF策略控制下,将Cache容量图10ELF策略在不同Cache容量下的性能Page9从1MB增加到2MB,或从2MB增加为4MB可以将平均MPKI分别降低37.7%或49.4%.由此可见,ELF和LRU具有相同的容量扩展性,并且比LRU具有更好的性能而所需的硬件开销并不显著.5.4插入和提升行为ELF策略可以显著降低使用频率数据块尤其是0-重用数据块在共享Cache中的驻留时间,这主要是通过将低使用频率数据块依照概率简单地插入到LRU位置以及在后续访问命中时仅向前提升一图11ELF策略的插入和提升行为剖析5.5硬件设计开销ELF策略的存储开销主要来源于使用频率预测表及在每个Cache行中所增加的一些必要的域,详见图4.表3详细描述了ELF策略的存储开销,假设物理地址空间为32位.根据表3的计算结果,ELF所需的硬件开销有176KB,相当于片内共享LLC面积的4.18%,这样的硬件开销在半导体工艺迅速发展的今天还是十分合理的.每个Cache行所增加的额外域总共的Cache行数二级Cache中附加域的总计开销每个预测表项的开销预测表项的总数预测表的总计开销ELF策略的总开销ELF导致的LLC面积增加的百分比6结论随着片内共享最后一级Cache容量和相联度的增长,传统的LRU策略和理论最优替换策略OPT之间的性能差距日趋增大,解决上述问题的方法之一就是将一部分工作集尽可能长时间地保留在个优先级位置来实现的.图11剖析了在ELF管理的二级Cache中所有负载的插入和提升行为,从中可以看出,对于mix00、mix02、mix07等多道程序,LRU插入占有主导地位,而对于mix03、mix05和mix08,则以MRU插入为主,这说明ELF策略可以根据负载的访存行为选择合理的插入策略;提升行为并没有插入行为表现得那么明显,几乎所有负载都以MP提升为主,但SIP提升仍占据一定比例(如mix02).Cache中,使得至少这部分数据可以获得较高的命中率.基于这一思想,本文提出一种基于无用块消除和低重用块过滤(ELF)的Cache管理策略,主要完成以下几个方面的工作:(1)将基于计数的活动时间预测器LvP扩展到多核处理器中,即在二级Cache和主存之间增加了一个独立的预测表硬件,用来保存没有被缓存的数据的使用频率历史并且在数据重新进入Cache时恢复使用频率信息,从而完成对数据块使用频率的预测,算法的全部硬件开销约为4.18%.(2)提出一种针对大容量、高相联度LLC的Cache管理策略,根据预测器的预测结果标识无用数据并将其作为Cache替换的优先选择,同时将低使用频率数据块依概率插入到LRU位置,并且在后续命中仅采用单一提升策略,从而保证一部分高使用频率工作集可以保留在Cache中,以贡献出较高的Cache命中率.在4路CMPs上的实验结果显示,ELF可以将全局性能平均提升14.5%,同时与PIPP和TADIP相比,可以分别达到1.06倍和1.09倍的加速比.并发运行的应用间的显著干扰会给ELF策略的性能带来负面的影响,为此在今后的工作中,我们拟通过分治的策略解决这一问题,即将共享LLC划分成与处理器核数目相同的多个组,每个应用映射Page10到一个组中,组内可根据应用的访存行为选择适当的Cache管理策略.
