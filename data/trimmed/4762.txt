Page1基于自适应搜索中心的骨干粒子群算法王东风孟丽赵文杰(华北电力大学控制与计算机工程学院河北保定071003)摘要该文在对标准粒子群算法(ParticleSwarmOptimization,PSO)和骨干粒子群算法(BareBonesParticleSwarmOptimization,BBPSO)中粒子位置的概率密度函数进行分析比较的基础上,对BBPSO进行了改进,并证明了改进算法以概率1收敛于全局最优解.在改进算法中,主要包括如下策略:(1)基于粒子间适应值的差异,提出一种对粒子位置高斯采样均值的自适应调整策略,分析了其作用机理,提出的搜索中心自适应调整策略增加了粒子分布中心的分散度,减缓粒子在中心的聚集趋势;(2)提出了一种“镜像墙”的越界粒子处理方法,该方法能够大幅度地提高算法找到最优解的概率;(3)粒子在不同的进化时期按不同的拓扑结构选取榜样粒子:算法前期主要采用随机结构以增加群体的多样性,算法后期主要采用全局结构以使得搜索更加精细.将该文提出的算法与多种形式的改进PSO,如GPSO(GlobalPSO)、LPSO(LocalPSO)、FIPS(FullyInformedParticleSwarm)、CLPSO(ComprehensiveLearningPSO)、HPSO-TVAC(HierarchicalPSOwithTime-VaryingAccelerationCoefficients)、APSO(AdaptivePSO)、DMS-PSO(DynamicMulti-SwarmPSO)、OPSO(OrthogonalPSO)、OLPSO(OrthogonalLearningPSO)、ALC-PSO(PSOwithanAgingLeaderandChallengers)等,以及BBPSO的标准版本和改进版本,如BBJ2(BBPSOwithJumps)、ABPSO(AdaptiveBBPSO)、SMA-BBPSO(BBPSOwithScaleMatrixAdaptation)等,对CEC2013标准函数进行测试,对实验数据进行非参数检验,结果表明该文改进算法的综合表现要优于其他算法.关键词粒子群算法;骨干粒子群算法;概率密度;搜索中心;全局收敛1引言随着工程优化问题的日益复杂,传统的优化方法已经不能够满足实际的需求,智能优化算法在这种背景下产生并迅速发展.智能优化算法是建立在生物智能或物理现象基础上的随机搜索算法,包括模拟退火算法、遗传算法、人工神经网络技术、人工免疫算法和群智能算法等.其中,群智能算法通过模拟社会性动物的各种群体行为,利用群体中个体之间的信息交互和合作来实现寻优的目的,如蚁群算法、粒子群算法、混合蛙跳算法、人工蜂群算法、萤火虫算法等.在众多的群智能算法中,粒子群优化算法(ParticleSwarmOptimization,PSO)自1995年由Kennedy和Eberhart[1]提出就受到广泛的关注,其基本思想来源于鸟群和鱼群等寻找食物的行为.PSO概念简单,易于实现,已被成功应用于参数辨识、电力系统优化、神经网络训练、数据挖掘等多种领域.Shi等人[2]提出了带有惯性权重的PSO,一般将其默认为标准PSO(StandardPSO,SPSO),随后,Kennedy等人[3]研究了不同的拓扑结构对SPSO性能的影响.SPSO存在易早熟收敛,寻优精度不高的缺点,学者们从参数调节、种群拓扑结构以及与其他算法结合等多个方面对其进行了改进.在众多对SPSO的改进工作中,有一些被广泛熟知的方法,如FIPS(FullyInformedParticleSwarm)[4]、CLPSO(ComprehensiveLearningPSO)[5]、HPSO-TVAC(HierarchicalPSOwithTime-VaryingAccelera-tionCoefficients)[6]、APSO(AdaptivePSO)[7]、DMS-PSO(DynamicMulti-SwarmPSO)[8]、OPSO(OrthogonalPSO)[9]、OLPSO(OrthogonalLearningPSO)[10]、ALC-PSO(PSOwithanAgingLeaderandChallengers)[11]等.FIPS和CLPSO主要从群体的拓扑结构方面对算法进行改进.FIPS中,粒子的更新并不是仅仅利用其邻域内的最优粒子,而是使用邻域内所有成员的历史最优的加权平均值来指导更新;CLPSO中粒子的每一维随机地选择自身或其他粒子为榜样粒子,当某个粒子的停滞代数超过预设值时,重新为其选择榜样粒子.HPSO-TVAC和APSO都对算法的参数进行了调节.HPSO-TVAC中学习因子c1和c2随着算法的迭代线性地变化;APSO利用粒子之间的距离提供的信息确定种群所处的状态,根据不同的状态采用不同的参数调整策略.DMS-PSO将群体分为若干个子群,子群体每经过数代进化后进行重新分组,使得信息能够在整个种群中进行流通.OPSO和OLPSO都是将正交实验法引入PSO,OPSO利用正交实验法对群体的初始化进行改进,使得初始种群均匀分布在解空间上;OLPSO通过对粒子的个体极值和邻域内最优粒子进行正交试验,获得更有价值的榜样粒子.ALC-PSO在PSO中结合了衰老进化理论的思想,对群体的首领粒子设置寿命和年龄,根据首领粒子的领导能力调整其寿命,当首领粒子的年龄到达其寿命后,生成新的粒子对首领粒子进行挑战.以上这些改进使得算法的性能有了很大的提高,但同时也在一Page3定程度上增加了算法的应用难度.虽然SPSO的概念比较简单,但我们对粒子的位置生成仍然没有一个直观的印象,随着对SPSO算法的改进越来越复杂,了解改进算法中的粒子的运行方式也越来越困难.Kennedy[12]于2003年提出了一种更为明晰的粒子群算法的形式:骨干粒子群算法(BareBonesPSO,BBPSO).BBPSO是在对SPSO中粒子的运行轨迹进行分析的基础上提出的,算法取消了速度项,粒子的位置由服从高斯分布的随机采样直接获得.BBPSO的简单协作式的概率搜索方式能够提高算法的搜索效率和精度,并且避免了SPSO算法复杂的参数调节,已被成功应用于约束优化问题[13-14]、数据挖掘[15]、电力系统调控[16]等多种领域.BBPSO在处理单峰问题上,表现出了很好的高效性,然而在一些多峰函数上,BBPSO的效果不甚理想.为了增加种群的多样性,Krohling和Mendel[17]通过高斯分布或柯西分布产生扰动,帮助群体跳出局部最优,但不同的测试函数需要设置不同的扰动幅度.Blackwell和Majid[18-19]提出了两种带有均匀变异的BBPSO(BBPSOwithJumps,BBJ):BBJ1和BBJ2,两种算法中都是通过设置选择概率使粒子可以通过均匀分布产生变异点进行扰动,来减缓种群多样性的丧失,但是过多的变异会造成资源的浪费,过少则不利于群体跳出局部最优.Zhang等人[20]提出了ABPSO(AdaptiveBBPSO),算法根据粒子的聚散程度和种群的多样性自适应地调节高斯采样的标准差,同时采用变异算子进一步增加群体的多样性.除以上对BBPSO的改进方案外,使用重尾分布代替高斯分布产生粒子的新位置也可以增大算法跳出局部极值的机会,Campos等人[21]将t分布应用在BBPSO的框架中,提出了SMA-BB(BBPSOwithScaleMatrixAdaptation).BBPSO中粒子的更新具有非常直观的物理意义,使得我们能够很容易地去调整粒子重点搜索的范围,因此,BBPSO是一种具有潜力的算法.本文首先将某一代进化过程中粒子的可能分布位置视为随机变量,对其概率密度函数进行求取,从一个崭新的角度分析了SPSO和BBPSO中粒子的生成方式,进而说明了BBPSO在多峰函数上不足的原因.在此基础上,提出了自适应调整粒子搜索中心的策略,对BBSPO算法进行改进,并在改进算法中使用了新的边界策略,使得计算资源得到充分的利用.仿真实验表明,经过改进后的算法在保留了原BBPSO的物理意义明确和搜索高效性的基础上,具有良好的全局搜索能力.由于没有引入任何需要调节的参数,改进后的算法依然易于在实际中进行应用.2BBPSO与SPSO的粒子分布比较2.1两种算法的基本形式BBPSO是在SPSO的基础上衍生出来的,首先给出SPSO的形式,在SPSO中,粒子代表D维寻优空间中的候选解,具有速度和位置两个属性,k+1时刻粒子i的第d维的速度vid和位置xid按式(1)和(2)进行更新:vid(k+1)=wvid(k)+c1r1(pid(k)-xid(k))+式中:pid为个体i的历史最优解,即个体极值;pgd为整个群体的历史最优解,即全局极值.w为惯性权重,c1和c2为学习因子,r1和r2为相互独立的服从(0,1)间均匀分布的随机数.Clerc和Kennedy[22]对SPSO中粒子的运行轨迹进行了分析,指出粒子的运行轨迹以狆i和狆g的加权平均值为中心进行振荡.Kennedy[12]在此基础上对粒子轨迹振荡的中心和幅值进行了进一步研究,提出了BBPSO,粒子位置的更新直接通过高斯分布采样得到,如式(3)其中:N(μ,δ2)表示均值为μ、标准差为δ的高斯分布,μid=(pid(k)+pgd(k))/2,δid=|pid(k)-pgd(k)|;Xid为表示粒子i第d维位置的随机变量,服从高斯分布,新位置xid(k+1)为Xid(k+1)的一个采样点.由高斯采样对粒子i的所有维更新得到狓i(k+1)后,对个体极值和全局极值进行更新,以便进行下一代的进化.Kennedy同时提出了探索型BBPSO,粒子的每一维以50%的概率选择保留个体极值,以50%的概率进行高斯分布的采样.对以上两种形式的BBPSO进行试验时发现,当算法采用相同的拓扑结构时,探索型BBPSO要相对稳定,因此本文基于探索型BBPSO进行改进.2.2两种算法粒子位置的分布情况在SPSO中,由于式(1)中存在随机数r1和r2,得到的xid也为某一随机变量的采样点.一般分析粒子轨迹的工作都是考虑粒子进化数代的过程中作为随机数的xid的变化.Kennedy同样从该角度对粒子的运行轨迹进行了总结,在假定狆i和狆g不变的前提Page4下,SPSO中粒子进化106代,记录每一代的位置并绘制频率直方图进行分析[12],指出:“速度项是不必要的”,因而在BBPSO中直接取消了速度项.现只考虑在某一k+1时刻的情形,粒子i的第d维位置为一随机变量Xid.不同的进化策略使得Xid具有不同的分布规律,决定了粒子对某个区域的搜索能力,进而决定了不同的算法的优化性能的不同.本节对BBPSO和SPSO两种算法中粒子位置随机变量Xid的分布情况进行比较,分析简单去掉速度项对BBPSO的影响,进而在下一节提出BBPSO的改进策略.描述随机变量的统计规律性一般要用到概率密度函数.我们首先对SPSO中位置变量Xid的概率密度函数进行求取.将SPSO用随机变量的形式来表示,如式(4)~(6):式(4)中的a由k时刻的速度和位置决定,因此在特定的k+1时刻,a为常数.式(5)中,Y1为服从(0,b1)间均匀分布的随机变量,b1=c1(pid(k)-xid(k));Y2为服从(0,b2)间均匀分布的随机变量,b2=c2(pgd(k)-xid(k)).Y1和Y2是相互独立的.设Y1,Y2和Z的概率密度函数分别为fY1(y1),fY2(y2)和fZ(z).由卷积公式可得fZ(z)的计算如式(7)计算得fZ(z)为分段函数,如图1所示,分段点z1,z2,z3和z4由b1,b2计算得到,与b1和b2的大小有关,即与xid,pid和pgd之间相互的位置有关,将[0,b1,b2,b1+b2]按照从小到大的顺序进行排列,对应即得到[z1,z2,z3,z4].由式(6)可知,SPSO中,Xid的概率密度函数的形状与fZ(z)相同,只是沿着变量轴进行了大小为a的平移.也就是说,在SPSO中k+1时刻的位置更新时,k时刻的位置与当前的pid和pgd共同决定了新位置的可能分布区间大小和分布的概率,k时刻的速度则影响整个分布覆盖的位置.容易得到BBPSO中Xid的概率密度函数曲线是以μid为对称中心的钟形曲线.μid为位置参数,决定了曲线的位置,δid为尺度参数,决定了Xid落在μid附近概率的大小.由此可见,粒子的搜索区域的中心定位在pid和pgd的中间位置μid上.在进化初期,群体较为分散,δid较大,产生新位置的分布相对分散,便于进行全局搜索;在进化后期,群体较为集中,粒子则围绕μid进行精细的搜索.由两种算法中粒子位置随机变量Xid的概率密度可以看出,BBPSO中粒子的搜索范围更广,能够产生远离局部极值的变异点.但是,粒子的位置分布中心μid的位置不够灵活,限制了粒子重点搜索的区域.而在SPSO中速度项的存在则使得粒子分布沿着寻优空间可以进行一定的平移,避免群体多样性的过快丧失.虽然BBPSO本身就能够产生变异点增加群体的多样性,但是由于我们事先并不知道函数的局部最优点和全局最优点的相对位置,当群体陷入局部最优时,依靠随机产生变异点来跳出局部极值,是有一定难度的,因此,可以通过增加粒子的重点搜索区域的灵活性来进一步增加种群的多样性,进而增强算法的全局搜索能力,避免群体陷入局部极值.3基于搜索中心μ自适应调节的改进BBPSO算法:Aμ-BB我们对BBPSO的改进主要包括两个方面:一是对粒子的搜索中心μ进行自适应调节,以增加单个粒子重点搜索区域的多样性,进而增强整个种群的全局搜索能力;二是引入新的边界控制策略.本节首先详细介绍μ的自适应调节的实现方法及其作用机理,并将其应用于拓扑结构不同的两种BBPSO上,观察这一策略给算法带来的收益;接着提出了新的边界控制策略,举例说明了对算法的影响;最后基于以上两个方面,给出了基于μ自适应调节的改进BBPSO算法(BBPSOwithAdaptiveμ,Aμ-BB).3.1搜索中心自适应调节策略自适应的思想已被应用在遗传算法[23-24]、模拟退火算法[25-26]、差分进化算法[27-28]、粒子群算法[7,29-31]等多种优化算法中,使得算法能够在运行的过程中根据种群提供的信息动态地控制参数或选择个体进化的方式.自适应策略充分利用了进化过Page5程本身的信息,增强了个体的“智能”,减少了算法的性能对参数和函数的依赖,增强了算法的鲁棒性.在对BBPSO的改进中也有基于自适应思想的工作.ABPSO[20]在每个粒子的高斯分布的标准差δ上增加不同程度的正值扰动,扰动的大小取决于种群的聚散程度和粒子与全局最优粒子之间适应值的差异.ABPSO对δ的调节可以增加种群的多样性,提高BBPSO的优化性能,但在ABPSO中,并未对高斯分布的均值μ做任何改进.而从2.2节的分析中我们得知,BBPSO中高斯分布均值μ的生成方式限制了种群的多样性和算法的优化性能,因此,在本文对μ进行自适应的调整,通过对其作用机理的分析可知,本文的μ值自适应调节策略能够更大程度地增加群体的多样性.3.1.1搜索中心自适应调节的实现为了使粒子的搜索中心多样化,赋予μid一个取值范围[μmin,μmax],μid在其间按均匀分布取值.假设粒子i更新第d维变量时所用的榜样为粒子m,f(狆i)和f(狆m)分别是粒子i和m的历史最优函数值.以最小化问题为例,按照式(8)~(11)可以得到μid的取值范围[μmin,μmax]:B2=μmin=min(B1,B2),μmax=max(B1,B2)(11)式(8)中的fmax和fmin分别表示群体中所有粒子的个体极值的最大和最小值,ε是为了避免当fmax和fmin相等导致算式被零除而引入的非常小的正数,因而K的取值范围是(-1,1).当f(狆i)小于f(狆m)时,即狆i优于狆m时,K为正值,μid的取值范围在|pid-pmd|的基础上向着pid的方向扩展K倍;当f(狆i)大于f(狆m)时,即狆i劣于狆m时,K为负值,μid的取值范围在|pid-pmd|的基础上向着pmd的方向扩展|K|倍.当f(狆i)和f(狆m)的差异较大时,|K|值也较大,使得较优粒子附近比较多的区域包含在了μid的取值范围中,对较优的粒子给予了更多的关注;当f(狆i)和f(狆m)的差异较小时,|K|值较小,对狆i和狆m周围的区域给予的关注并没有很大的差别.在算法迭代初期,群体较为分散,|pid-pmd|较大,随着迭代的进行,群体趋于集中,|pid-pmd|也逐渐减小,对于同一个K值,可以理解为随着算法的进行扩展的绝对范围逐渐减少,满足算法对前期的勘探能力和后期的开采能力的要求.式(11)中的μmin或μmax越界时,进行限制如下:μmin=pmin-mod(xmin-μmin,pmin-xmin)(12)μmax=pmax-mod(μmax-xmax,xmax-pmax)(13)其中:xmin和xmax分别为寻优空间的下界和上界;pmin和pmax分别为pid和pmd中的较小值和较大值.mod()为求余函数.3.1.2搜索中心自适应调节的作用机理将BBPSO中粒子的搜索中心进行自适应调节后,粒子的位置Xid依然为一随机变量,为了观察这一策略对粒子搜索行为的影响,下面求取Xid服从的概率密度函数.为了使表达简洁且与概率论相统一,省略下标,并且将问题重新描述如下:随机变量Y在[μmin,μmax]上均匀取值,当观察到Y=y时,X~N(y,δ2),求取X的概率密度函数fX(x).其中δ为一给定值,而y则对应为高斯分布的均值μ,为[μmin,μmax]上的服从均匀分布的采样点.由问题描述可得到Y的概率密度函数fY(y)如式(14)所示:fY(y)=e-(x-y)2在Y=y的条件下,X的条件概率密度fX|Y(x|y)如式(15):fX|Y(x|y)=1由fY(y)和fX|Y(x|y)可求得Y和X的联合概率密度函数f(y,x),如式(16):f(y,x)=fX|Y(x|y)fY(y)=烄(μmax-μmin)2槡πδ烅0,烆求得f(y,x)后,可由式(17)求得关于X的边缘概率密度函数fX(x):fX(x)=∫2(μmax-μmin)erfμmax-x=1Page6其中,erf(x)为误差函数,如式(18):将上述问题还原到我们的算法中,式(17)中的fX(x)即为对μ进行调节后得到的粒子位置X的概率密度函数,μ取值的上下限影响fX(x).图2直观的展示了对μ进行调节后的粒子的分布与原高斯分布的不同.图中的GD表示原BBPSO中以(pid+pmd)/2为中心的高斯分布.图中的K是3.1.1节中的扩展系数.对μ的调节改变了粒子位置随机变量的概率密度函数,扩大了重点搜索区域.当μ的取值区间向pid的方向扩展时,K为正值;向pmd的方向扩展时,K为负值,|K|的大小则反映了对较优粒子周围区域关注的程度,这与3.1.1节的分析是一图33个典型测试函数一维图像致的.3.1.3搜索中心自适应策略在BBPSO上的应用我们将搜索中心自适应调节策略分别应用于两个版本的BBPSO上.当应用于采用全局拓扑结构的BBPSO,即GBB(GlobalBBPSO),得到Aμ-GBB(GBBwithAdaptiveμ);当应用于采用随机拓扑结构的BBPSO,即RBB(RandBBPSO),得到Aμ-RBB(RBBwithAdaptiveμ).将这4种算法应用于以下3个典型函数上进行性能测试:sphere函数、rastrigin函数和schwefel函数,3个函数的表达式分别如式(19)、(20)和式(21)所示f(x)=418.9828×D-∑D图3给出了3个函数的一维图像.sphere为简单的对称单峰函数;rastrigin具有大量局部最优点,最好的局部最优离全局最优点很近;schwefel为不可分离的函数,全局最优与最好的局部最优相距很远,算法往往朝着错误的方向收敛.3个函数的函数Page7最优解值f均为0.函数取D=10,种群大小N=10,函数值最大计算次数FEs(FunctionEvaluations)设置为5×104.每个函数独立运行30次,记录每次运行过程中群体最佳函数值与函数全局最优值的差图43个基本测试函数的算法收敛曲线由于sphere的最优解的方向非常容易找到,GBB以最快的速度向最优解收敛,对μ的调节分散了粒子的搜索空间,减缓了GBB和RBB的收敛速度;对rastrigin函数,GBB、RBB和Aμ-GBB都陷入了局部最优,只有Aμ-RBB跳出了局部最优,朝着最优解的方向发展,但收敛速度比较慢;对schwefel函数,也是只有Aμ-RBB能够将搜索区域迅速定位在最优解的附近,而且收敛速度相对较快.3.2越界粒子的处理在群体进化的初期,不同粒子的个体极值之间距离较远,用于更新位置的高斯分布的标准差δ相对较大,导致产生的新位置越过寻优空间边界的机会也较大.PSO中,除了直接将越界粒子的位置和速度均置于边界上,主要还有以下几种方法:吸收墙、反射墙、衰减墙和隐匿墙.前3种方法都是只将越界粒子的位置置于边界上,而对速度的处理不同:吸收墙将粒子的速度置为零;反射墙中粒子的速度值(f-f)的变化曲线,取30次的平均值,如图4所示,每个图的横轴为函数值计算次数,纵轴是对(f-f)取以10为底的对数,从中可以看出对μ进行调节给算法带来的影响.大小不变,方向反向;衰减墙将粒子的速度大小减小,方向反向.而隐匿墙对粒子不做处理,不参与极值的更新.在BBPSO中,粒子本身不具有“速度”这一属性,对于越界粒子,常用的处理方法是将其置于边界上.由于在BBPSO中,k+1时刻粒子的位置与k的位置没有直接的关系,同时待优化目标函数的最优解往往不在边界上,因此,简单地将越界粒子置于边界上,会造成资源的浪费.这里考虑粒子越过边界的程度,以高斯分布的期望μ为中心将越界的粒子x拉回寻优空间中得到x,对越界粒子按照式(22)进行处理.其中:xborder为x越过的边界,即当x>xmax时,xborder=xmax;当x<xmin时,xborder=xmin.分析式(22)可知,当x越过上界时,即x>xmax时,粒子被拉回时落在区间(μ,xmax)上.x越过xmax的程度越小,被拉回时就Page8越靠近xmax;x越过xmax的程度越大,被拉回时就越靠近中心μ.当x越过下界时,即x<xmin时,粒子被拉回时落在区间(xmin,μ)上.同样的,粒子被拉回的图5对越界粒子的处理我们仍然以sphere函数、rastrigin函数和schwefel函数为例来说明式(22)的边界策略对算法性能的影响.BBPSO分别采用下列两种边界策略:(1)将越界粒子直接置于边界上;(2)按式(22)处理越界粒子.函数取D=10,种群大小N=10,函数值最大计算次数FEs=5×104,每个函数独立运行100次.由于sphere函数非常简单,策略(1)和(2)的运行结果差别不大,以几乎相同的精度逼近最优解值;优化rastrigin函数时,我们发现群体中粒子越界的次数非常大,策略(1)和(2)找到最优解的成功率分别为51%和70%;schwefel函数的最优解靠近寻优空间的边界,策略(1)和(2)找到最优解的成功率分别为16%和57%.由此可见,边界处理的方式会对算法的性能带来一定的影响,本文提出的越界处理方式较大幅度地提高了找到最优解的概率.3.3Aμ-BB算法描述通过3.1.3节可以看到,如果不要求算法的收敛速度,Aμ-RBB是个很好的选择.但在实际应用中,我们尽可能的在算法的收敛速度和寻优精度之间进行平衡,因此,我们将Aμ-GBB和Aμ-RBB结合起来得到Aμ-BB.在算法迭代初期,随机结构在群体中占主体,以增大群体在整个寻优空间的搜索力度,减小陷入局部极值的可能;随着迭代的进行,全局结构逐渐占主导地位,进行精细的搜索.拓扑结构的变化通过粒子对榜样粒子的选择来实现,设置选择概率:Pc=(k/kmax)1/2,k为当前的代数,kmax为算法最大迭代次数.对每一个粒子的每一维设置一个服从(0,1)间均匀分布的随机数rc,当rc>Pc时,粒子随机从群体力度与其越过边界的程度成正比.图5展示了对越界粒子的处理,由图中可以看到式(22)所体现的类似“镜像墙”式的越界惩罚机制.中选择一个粒子作为自己的榜样粒子;rcPc时,榜样粒子为整个群体的最优粒子.第k+1代,Aμ-BB中粒子i的第d维位置更新的过程可概括为以下步骤:1.生成服从(0,1)间均匀分布的随机数r1,若r1<0.5,执行步2,否则执行步7;或(13)进行越界处理;2.计算Pc,生成服从(0,1)间均匀分布的随机数rc.若rc>Pc,榜样粒子m从种群中随机选取,否则,榜样粒子m为全局最优粒子;3.由式(8)~(11)计算得到μmin和μmax,并根据式(12)4.生成服从(0,1)间均匀分布的随机数r2,μid(k+1)=μmin+r2(μmax-μmin);5.若pid(k)=pmd(k),生成服从(0,1)间均匀分布的随机数r3,δid(k+1)=r3(xmax-xmin);否则,δid(k+1)=︱pid(k)-pmd(k)︱;6.由高斯采样N(μid(k+1),δid(k+1))得到xid(k+1),7.xid(k+1)=pid(k);8.根据式(22)进行越界粒子的处理.4Aμ-BB的全局收敛性分析执行步8;Solis和Wets[32]对随机优化算法的收敛性进行了深入的研究,给出了一般随机优化算法收敛性的判定标准,其主要结论如下.问题描述.给定一目标函数f(x):RD→R,SRD,狓=(x1,x2,…,xD)∈S.在Lebesgue测度空间定义搜索的下确界:ψ=inf(t:υ[狓∈S|f(狓)<t]>0),其中,υ(A)表示在集合A上的Lebesgue测度.在此基础上定义函数f(狓)的最优区域Rε,M:Page9Rε,M=其中,ε>0,M为充分大的正值.如果算法找到了Rε,M中的一个点,称算法找到了误差为ε的可接受点.假设1[32].若f(H(z,ξ))f(z),ξ∈S,则其中:H为产生问题解的函数;ξ为从概率空间(RD,犑,Ω)产生的随机向量.犑为RD上的一个σ代数,Ω为犑上的概率测度.假设2[32].若对S的任意Borel子集B,有υ(B)>0,则其中,Ωk[B]为第k代算法H在B上的概率测度.定理1[32].设f为一可测函数,S为RD的一可测子集,{zk}足假设1和假设2时,有limk→+P[zk∈Rε,M]=1.在此基础上,下面给出本文改进算法Aμ-BB的全局收敛性.定理2.假设Aμ-BB求解的目标函数f是可测的,其解空间S为可测子集,则算法以概率1收敛于全局最优解.证明.在Aμ-BB中,函数H可以描述为H(狆g(k),狓i(k))=pg(k),f(pg(k))f(xi(k))容易证明其满足假设1.下面证明Aμ-BB满足假设2.设种群的大小为N,在k+1时刻,粒子i的第d维xid以0.5的概率选择pid(k);以0.5的概率从随机变量Xid中采样,Xid的概率密度函数如式(17)表1本文用于详细比较的CEC2013测试函数单峰函数多峰函数复合函数所示.计算可得Ωk[B]:Ωk+1[B]=P(Xid(k+1)∈B)×0.5+由定理1,可得:Aμ-BB算法以概率1收敛于全由式(17)和(22)可得,只要υ(B)>0,便有P(Xid(k+1)∈B)>0成立;P(pid(k)∈B)的值为0或1,因此,Ωk+1[B]>0成立,从而有∏=0.因此Aμ-BB满足假设2.局最优解.5仿真实验5.1基准函数及其他用于比较的算法本文用CEC2013标准库函数[33]来测试算法的性能,CEC2013标准测试函数共28个,分为单峰函数、基本多峰函数和复合函数三类.由于篇幅所限,本文选取用于比较的各种优化算法在性能上表现出差异较大的16个函数(如表1所示),将其结果在文中详细展示.另外12个函数的运行结果列于附表1.文中所用的比较算法如表2所示,其中各个算法的参数设置均为原文献的推荐值,群体的拓扑结构也与原文献保持一致.表2中的GPSO和LPSO分别表示采用全局拓扑结构(GlobalPSO,GPSO)和局部拓扑结构(LocalPSO,LPSO)的标准粒子群算法,GPSO和LPSO中的参数设置参考Shi等人[34]的工作.表中,vmax为粒子速度的边界值,Range表示搜索区域的范围,其他各参数与原文献保持一致.函数名称Page10表2用于比较的其他优化算法及参数算法名称缩写GPSO[2]LPSO[3]FIPS[4]CLPSO[5]HPSO-TVAC[6]APSO[7]DMS-PSO[8]OLPSO[10]ALC-PSO[11]BBPSO[12]BBJ2[19]ABPSO[20]SMA-BBPSO[21]注:随机结构:CLPSO中榜样粒子为从随机选取的两个粒子中选择优胜的一个.环形结构:OLPSO中的榜样粒子由全局最优和个体最优进行正交试验得到.5.2实验结果及分析本文对测试函数分别取维数D=10和D=30进行测试.D=10时,除DMS-PSO外,种群大小N均设置为20,D=30时,除DMS-PSO外,N=40.对于不同的D,DMS-PSO选取相同的群体规模,设置3个子群,每个子群的大小均为10.计算函数值的最大次数FEs设置为D×104[33].每个函数的搜索范围和初始化范围均为[-100,100]D[33].每个算法对每个函数都独立运行51次[33],记录每次运行迭代过程中的群体最佳函数值与函数全局最优值f的偏差.由于篇幅有限,并且考虑到算法的改进方向和在12个函数上的综合性能,从表2中所示的13种算法中选取10种算法,将其运算结果详细展示在图6和表3中.除了篇幅有限,其他3种算法的结果未详细列出的原因还有:GPSO和LPSO都可以做为PSO的标准形式,并且在12个测试函数上的综合排名比较接近,而GPSO较为常见,因此LPSO的结果未详细列出;FIPS和CLPSO都是综合运用了邻域内所有粒子的个体极值的信息来对粒子进行更新,在单峰函数上,性能较差,在多峰函数上,性能较好,CLPSO的综合性能要优于FIPS,因此FIPS的运行结果未详细给出;HPSO-TVAC在所有的测试函数上都没有突出的表现,综合性能劣于同类型的APSO,HPSO-TVAC的结果未详细给出.图6为D=10时(D=30的情况与此相近),运行过程中,算法找到的最佳函数值的平均值与f的偏差的变化情况.每个图的横轴为函数值计算次数,纵轴是对每代的运行结果取以10为底的对数.表3为D=30时(D=10的情况与此相近)的运行结果,参数设置—α=0.75,pJ=0.001prob=0.7表中的Mean和SD分别表示独立运行函数51次得到的结果的平均值和标准差,Rank表示算法在某一个函数上的性能排名,如果两个算法的Mean值相同,则认为SD值较小的优于SD值较大的.位于表格最后面的Num表示算法在12个测试函数中取得最优的次数,Ave.R表示算法的平均排名,T.R表示算法总的排名,若两种算法的Ave.R值相同,则认为Num值大的算法较优.由图6可以看到,D=10时,CEC2013f5和f11是相对比较容易的,CLPSO,DMS-PSO,ABPSO,SMA-BB和Aμ-BB都找了f5的最优解,CLPSO,ALC-PSO,BBJ2和Aμ-BB都找了f11的最优解.在其他的函数上,所有的算法都没有收敛到函数的全局极值.Aμ-BB在f3,f6,f7,f10,f14,f27,f28上具有略微的优势;OLPSO在f17上取得了最好的结果,在f22上的收敛速度较快,但最后到达的解的精度与CLPSO基本相同,略微优于其他算法;ABPSO在f15和f23上表现出了较好的性能;在f2和f4取得最好的结果的算法分别为SMA-BB和APSO;各算法在f19上的性能差别是很小的.对比表3和图6可以看到,当函数的维数由10增加到30时,所有算法在测试函数上的寻优精度都有所下降.D=30和D=10时,大部分算法的优劣情况是相似的,受维数变化影响较大的算法有ALC-PSO和OLPSO.ALC-PSO在D=30时的综合性能要优于D=10时,这是由于ALC-PSO中的挑战机制使得挑战者在维数较高和群体规模较大的情况下更容易挑战成功,而在维数较低和群体规模较小的情况下,在生成成功的挑战者时会浪费大量的计算资源,使得算法会有很长时间的停滞.在Page11表3犇=30,各算法运行结果f2f3f4f5f6f7f10f11f14f15f17f19f22f23f27f28Ave.R8.124.506.316.006.754.688.935.875.435.623.75Page12图6D=10,各算法的收敛曲线OLPSO中,榜样粒子的生成需要进行正交试验,随着函数维数的增高,进行正交试验时需要计算函数值的次数也增加了,增大了计算量.同样应用自适应思想对BBPSO进行改进的ABPSO通过扩大高斯分布的标准差δ来增加群体的多样性,减缓了粒子位置分布在μ附近的集中趋势,但并没有改变搜索中心,由图2可以看到,Aμ-BB中对μ的调节不仅分散了粒子位置的分布,还使得搜索中心更加灵活.综合D=10和D=30的运行结果,从总体来看,对单峰函数,ABPSO的性能优于Aμ-BB,而对多峰函数,Aμ-BB的性能一般要优于ABPSO.在运行过程中,我们发现SMA-BB算法中的可调参数β对算法性能的影响很大,虽然SMA-BB在某些函数上的表现很好,但是,不同的函数需要设置不同的参数,限制了SMA-BB在实际中的应用.由运算结果可以看到,没有哪一种算法在所有的测试函数上能够取得优胜,Aμ-BB也并不例外,但是,Aμ-BB在所有函数上的综合性能还是要优于其他比较算法的.为了对运算结果有一个比较全面的了解,我们对Aμ-BB和其他算法在D=30时得到的结果逐一Page13进行显著性检验.由于不能够确定PSO多次优化同一函数的结果服从分布的类型,因此我们采用非参数检验方法,这里选用Mann-Whitney检验方法,显著水平α=0.05.表4详细列出了表3中用于比较的10种算法的检验数据,这里以GPSO列为例说明表中各数据的意义:GPSO列与f1行交叉的数据为“0.000↑”,“0.000”为Mann-Whitney检验的p值,“↑”表示GPSO在f1上的运行数据的秩均值大于Aμ-BB的运行数据的秩均值;若为“↓”,则表示GPSO在此函数上的运行数据的秩均值小于Aμ-BB的运行数据的秩均值;若为“→”,则表示两种算法的运行数据的秩均值相等;表中的Better行、Same行表4犇=30,Mann-Whitney检验数据f20.001↑0.608↓0.255↓0.180↓0.000↑0.181↓0.000↑0.061↓0.255↓0.041↑f30.000↑0.000↑0.000↑0.018↑0.000↑0.197↑0.000↑0.000↑0.002↑0.788↓f40.000↑0.000↑0.000↓0.000↓0.000↑0.000↓0.000↑0.654↑0.000↓0.000↓f50.000↑0.000↑0.000↑0.000↑0.000↑0.000↑0.000↑0.000↑0.062↓0.000↑f60.000↑0.000↑0.000↑0.008↑0.000↑0.000↑0.000↑0.000↑0.000↑0.000↓f70.000↑0.000↑0.000↑0.788↑0.000↑0.000↑0.000↑0.000↑0.000↑0.000↑f100.000↑0.000↑0.000↑0.000↑0.000↑0.000↑0.000↑0.000↑0.000↑0.000↑f110.000↑0.888↓0.000↑0.000↑0.000↑0.010↑0.000↑0.010↑0.000↑0.000↑f140.000↑0.033↓0.000↑0.000↑0.790↓0.000↑0.000↑0.000↓0.000↑0.000↑f150.012↑0.000↓0.010↓0.000↓0.121↑0.000↓0.000↑0.000↓0.000↓0.000↓f170.000↑0.000↓0.000↓0.000↑0.000↓0.021↓0.000↑0.000↓0.007↑0.000↓f190.000↑0.000↓0.040↓0.000↑0.005↓0.000↑0.000↑0.000↓0.407↑0.000↑f220.000↑0.000↓0.000↑0.083↑0.062↓0.504↑0.000↑0.000↓0.000↓0.000↑f230.000↑0.154↓0.000↑0.000↓0.061↑0.000↓0.000↑0.327↑0.000↓0.002↓f270.000↑0.008↑0.000↑0.000↑0.000↑0.000↓0.000↑0.000↑0.000↑0.000↑f280.000↑0.000↑0.000↑0.000↑0.000↑0.036↑0.161↑0.000↑0.000↑0.000↑Better1681110108158910Same03Worse056结论BBPSO是在对SPSO中粒子的运行轨迹进行研究的基础上提出的一种应用高斯分布进行位置更新的粒子群算法,其中粒子位置的进化形式更加清晰明了,局部搜索能力较强,搜索精度较高.通过与SPSO对比分析可知,BBPSO在单个粒子的搜索位置的多样性上有所丧失.本文对BBPSO进行了改进,对高斯分布的位置参数进行自适应的调整,使粒子的搜索中心多样化.并且在进化的前期侧重于发展粒子的多样性,搜索更多的空间,减小陷入局部极值的可能,在后期则侧重精细的搜索,以提高解的精度.为了验证算法的有效性,将其与另几种发表在权威期刊的改进粒子群算法进行比较,对CEC2013标和Worse行分别表示在显著水平为0.05下,12个测试函数中Aμ-BB优于GPSO、与GPSO无差和劣于GPSO的函数的个数.从表4中,我们可以清楚地看到,在12个测试函数上,Aμ-BB和其他算法的综合性能的比较结果,表4中未列出的3个算法的比较结果如下:Aμ-BB优于LPSO、与LPSO相同和劣于LPSO的函数个数分别为16,0,0;Aμ-BB优于FIPS、与FIPS相同和劣于FIPS的函数个数分别为12,2,2;Aμ-BB优于HPSO-TVAC、与HPSO-TVAC相同和劣于HPSO-TVAC的函数个数分别为11,3,2.以上均表现出Aμ-BB明显占优.准函数测试的结果表明,本文提出的改进算法Aμ-BB的综合性能是令人满意的.本文主要是针对基于高斯分布的BBPSO进行讨论,对于基于其他钟形分布的BBPSO的变形,本文中对单个粒子搜索位置多样性和算法的全局收敛性的分析仍然适用,做出的改进思想同样可以扩展到这些算法中.另外,在本文对BBPSO进行改进的过程中,只是对高斯分布的均值μ做了讨论,将其进行了分布位置多样性的拓展,并未对标准差δ进行讨论.而δ取值的大小直接影响到高斯分布的形状,扩大δ可以增加粒子的多样性,减小δ可以加速粒子的收敛.除了对算法本身的改进工作外,本文对PSO算法的分析角度,也为对PSO算法的改进工作提供了新的思路,粒子位置变量的概率分布情况决定了群Page14体的搜索能力,改变其概率密度函数的形式,便可以使算法具有不同的特性.致谢特别感谢审稿专家和编辑对本文的认真审阅,正是由于他们在认真仔细审阅的基础上所给出的宝贵意见和建议,才使得本文的工作得到改进和提高!感谢新加坡南洋理工大学PNSuganthan教授提供CLPSO,FIPS,DMS-PSO和FDR-PSO算法的源程序!感谢中国矿业大学张勇教授提供AB-PSO算法的源程序!由于他们的无私奉献才使得我们的工作更加顺利.
