Page1大数据环境下支持概率数据范围查询索引的研究朱睿王斌杨晓春王国仁(东北大学信息科学与工程学院沈阳110004)摘要随着数据规模的不断增长,大数据管理具有重要意义.在众多数学模型中,因为概率模型可以将海量数据抽象成少量概率数据,所以它非常适合管理大数据.因此,研究大数据环境下的概率数据管理具有重要意义.作为一种经典查询,基于概率数据的范围查询已被深入研究.然而,当前研究成果不适合在大数据环境下使用.其根本原因是这些索引的更新代价较大.该文提出了索引HGD-Tree解决这一问题.首先,该文提出了一系列算法降低新增数据的处理代价.它可以保证树结构平衡的前提下快速地执行插入、删除、更新等操作.其次,该文提出了一种基于划分的方法构建概率对象的概要信息.它可以根据概率密度函数的特点自适应地执行划分.此外,由于作者提出的概要是基于比特向量,上述策略可以保证索引以较低空间代价管理概率数据.最后,该文提出了一种基于位运算的方法访问HGD-Tree.它可以用少量的位运算执行过滤操作.大量的实验验证了算法的有效性.关键词大数据;概率数据;索引;概率概要信息;多分辨率网格1引言由大数据的3V模型可知,高效管理大数据面临两大挑战:(1)数据的高效存储;(2)事件的快速响应.例如,在环境监测系统中,通常有MB规模的传感器实时向服务器上报监测数据.假设传感器每隔5s向服务器上报一次数据,并且每条数据的净荷只有10Byte,那么服务器每周将为这些数据分配约1TB的存储空间.由于环境监测系统需要长年累月地在多个区域收集数据,存储这些数据需要耗费高昂的代价.此外,服务器如果需要针对新增数据做实时计算,计算代价也是十分巨大的.当增量算法的时间复杂度高于亚线性级别(例如:O(n2))时,系统的实时性要求将很难得到满足.综上所述,在大数据背景下,高效处理大数据面临巨大的挑战.在众多数学模型中,概率模型可以有效解决大数据管理面临的两大挑战.它可以根据实际应用对数据精度的要求自适应地将多条数据抽象成一条概率数据[1]o〈opdf,or〉.其中,opdf表示概率密度函数①;or表示o可能出现的区域.例如:在图1中,每个带阴影的矩形代表一个概率对象;矩形的边界刻画了概率对象可能出现的范围.显然,通过使用概率模型,数据规模可以有效被降低.相应地,以上两大难题也都迎刃而解.因此,在大数据环境下研究概率数据管理具有重要的理论和应用价值.本文研究基于概率数据的范围查询(简称:查询).给定查询q〈qr,qθ围qr中概率大于阈值qθ比,该查询一方面直接返回包含在qr中的对象(图1中的对象o1),另一方面验证与qr相交的对象(图1中的o2和o3)是否满足概率阈值的要求并返回满足要求的对象.鉴于验证操作需要耗费大量的计算代价,以往算法的研究焦点大多集中在寻找行之有效的概率剪枝策略过滤待验证对象从而降低验证规模[2-4].它们通常的做法是抽取对象概率密度函数的概要信息(记作SUM)并用传统的索引结构管理这些SUM.给定查询q和索引相交的概率对象.接下来,算法根据对象的SUM计算它们包含于qr的概率上界和下界.如果概率上界小于qθ否则,对象仍需被验证.在众多研究成果中,Tao等人[1]提出基于PCR(概率限定区域)的SUM.具体地,他们为每个对象构建一组PCR并将这些PCR当作对象的SUM.近一步,他们提出U-Tree管理这些PCR.实验证明:该索引可以有效降低对象验证规模.然而,它存在两大问题:(1)剪枝能力弱[5-7].该问题导致查询算法浪费大量的计算代价执行验证操作;(2)更新能力弱.由文献[1]可知,U-Tree管理的PCR规模是对象规模的m倍(m表示单个对象对应的PCR个数).当更新发生时,U-Tree的更新代价也是R-Tree的O(m)倍.显然,该索引不适用于管理更新频繁的数据.Zhang等人[5-7]提出了基于对象区域划分的SUM.近一步,他们使用R-Tree、quad-tree等索引管理这些划分.此类索引的概率剪枝能力强于U-Tree.但是,它的更新代价仍然是R-Tree等传统索引的数倍.除此之外,基于划分构建的SUM需要消耗大量的存储代价.当数据规模大时,此类索引的空间代价也是难以接受的.综上所述,由于大数据对索引性能有着较高的要求,上述索引均无法支持大数据环境下的概率数据范围查询.本文提出HGD-Tree(HybridGridDensityTree)管理大数据环境下的概率数据.为了克服上述索引存在的不足,HGD-Tree需要面对以下挑战:(1)快速更新.因为SUM的数据结构相对复杂,以SUM为基础构建的索引通常需要消耗较高更新代价(插入/删除/调整平衡).因此,如何在数据更新频繁的条件支持索引的快速更新是极具挑战的.(2)空间代价小且剪枝能力强的SUM.由于数①通常情况下,opdf存在两种表示方法:连续型和离散型.其Page3据更新频繁,对象的SUM需要快速构建.因此,在较短时间内找到空间代价低且能准确表达对象概率密度分布特征的SUM是非常困难的.针对上述问题和挑战,本文首先做出大量研究.在此基础上,本文提出多个巧妙算法应对上述挑战.具体贡献如下:(1)提出HGD-Tree管理概率数据.HGD-Tree是一种基于多分辨率网格的索引.该索引同时具备以下优点:①快速的更新能力.众所周知,网格结构是以空间划分为基础管理数据.当有数据插入时,索引可以快速定位插入位置.因此,基于网格的索引结构具有较强的动态更新能力;②相对平衡的结构.通过对传统的多分辨率网格进行改进,HGD-Tree用分辨率较高网格划分数据密集的区域;用分辨率较低网格划分数据稀疏的区域.它可以保证索引各节点维护的对象数目大致相同从而保证了索引的平衡性.为了近一步降低HGD-Tree的更新代价,本文提出一种批量更新算法.该算法通过一些事件触发机制自适应地对HGD-Tree进行维护.基于上述算法,索引的更新能力得到近一步的提升.(2)自适应的SUM构建算法.自适应性在以下方面得以体现:①自适应于概率密度分布.在构建对象SUM的过程中,本文通过挖掘对象概率密度变化的特征,找出一种新的SUM构建算法.该算法可以保证在较短时间内为对象构建过滤能力更强且空间代价小的SUM;②自适应于查询热点.在大数据环境下,由于数据更新频繁且计算资源有限,以不计成本的方式构建对象SUM是不可行的.本文提出基于区域热度的代价模型.该模型区别对待处于热点区域和非热点区域内的对象从而找到最优的SUM构建策略.(3)基于bit向量的SUM存储/访问算法.根据概率数据的特点,本文提出了一种基于bit向量的SUM存储/访问算法.由于bit向量可以高效利用计算资源和存储资源,HGD-Tree不仅可以近一步提高查询效率而且可以节省空间.本文第2节概述相关工作;第3节介绍问题定义;第4节详细介绍HGD-Tree的工作原理;第5节对所提方法的有效性进行实验分析;第6节对全文进行总结.2相关工作本节的主要内容是对国内外关于概率数据范围查询的相关工作进行概述.在介绍这些工作之前,本文首先通过表1定义一组符号.符号ooropdfapp(oi)ub(o,q)lb(o,q)由于数据存在着不确定性,不确定数据管理近年来得到广泛关注[8-12].与传统数据管理相比,因为不确定数据是以区域的形式存在,所以传统多维索引已不再适合管理不确定数据.因此,研究人员对传统索引进行适当的改造,提出了一系列经典方法管理概率数据.多维数据管理一直以来都是数据库领域的研究热点.以BD-Tree[13]、BBD-Tree[14]、BV-Tree[15]等为代表的基于空间划分建立索引;以R-Tree[16-17]、X-Tree[18-19]、M-Tree[20]、SS-Tree[21]等为代表的基于度量空间建立的索引都在多维数据管理领域占有重要地位.目前为止,主流的索引包括基于PCR的索引和基于划分的索引.基于PCR的索引.Tao等人[1]提出基于PCR的索引管理概率对象.给定任意对象o,它的PCR是根据or和特定概率阈值经收缩得到的矩形.为了处理带不同阈值的查询,Tao等人预先为每个对象构建一组PCR,并以此作为概率对象的SUM.近一步,他们提出U-Tree(其本质是一组R-Tree)管理PCR.U-Tree主要存在两个问题:(1)过滤能力弱.如文献[5-7]所示,基于PCR的SUM无法为概率对象提供紧凑的概率边界;(2)动态更新能力弱.U-Tree需要分配多个R-Tree管理基于不同阈值得到的PCR.当有更新发生时,算法需要同时维护多个R-Tree.显然,U-Tree的更新代价远高于R-Tree.基于划分的索引.Zhang等人[5-7]提出了基于区域划分的索引管理概率对象.这类索引(UI-Tree和UD-Tree)将对象区域的划分当做SUM.给定对象o,查询算法根据查询区域qr与or各子区域oi.r的拓扑信息进行概率剪枝.具体地,如果oi.r∧qr≠且oi.rqr,ub(o,q)+=app(oi);如果oi.rqr,ub(o,q)+=app(oi)且lb(o,q)+=app(oi).当查询算法遍历or各子区域后,当且仅当lb(o,q)<qθ<ub(o,q),o需要被验证.实验结果表明,基于划分得到的SUM比基于PCR得到的SUM具备更强的过Page4滤能力.然而,该索引存在以下问题:(1)空间代价大.由于划分没有迎合对象概率密度分布的特征,当分布倾斜时,此类索引的SUM需要消耗大量的空间代价;(2)更新能力差.因为这类索引需要管理所有对象的多个子区域,其管理规模远大于对象规模,所以此类索引也需花费较大的更新代价.其他索引.Aggarwal等人[2]研究了高维不确定对象的索引.因为该索引只能在对象概率密度函数呈无关分布时使用,所以它存在一定的局限性.Agarwal等人[3]使用线段树管理概率对象.该索引也存在动态更新能力弱等问题.Kalashnikov等人[4]利用网格管理[22-24]概率对象.该索引存在的问题是无法处理数据倾斜面临的问题.Zhu等人[25]提出了R-MRST索引不确定对象.他们研究了当概率密度函数呈连续时的SUM构建.然而,在大数据环境下,新增数据的分布很难快速拟合.因此,该算法不适用于管理更新频繁的概率数据.Angiulli等人[26]在度量空间上提出基于“轴”的索引管理不确定对象.该索引利用度量空间上的剪枝策略过滤概率对象.它的问题是空间代价远远大于其他索引.3问题定义多维概率对象:给定d维空间下的概率对象(简称对象)o,它可以用两种方法进行描述.第1种方法是将概率对象抽象成二元组〈opdf,or〉.其中,or表示o可能出现的区域;opdf表示关于o出现在or内任意点的概率密度函数.第2种描述方法是将概率对象表示成一组样本点si可以用二元组〈ci,pi〉表示.其中,si.c表示样本点图2HGD-Tree的框架的坐标,si.p表示si对应的概率.问题定义(多维概率对象范围查询).给定包含N个对象的集合O和概率范围查询q〈qθ回所有满足不等式app(o,q)qθ中,app(o,q)表示对象o出现在查询区域qr内的概率.根据概率对象表示方法的不同,app(o,q)的计算方式也有所不同.当对象o的概率信息用概率密度函数表示时,o出现在qr内的概率可以通过式(1)计算.其中,qr∩or表示or和qr之间的相交面积.当o的概率信息用一组样本点表示时,o出现在qr内的概率可以通过式(2)计算.其中,n2等于包含在qr∩or中o的样本点个数;n1等于||.在实际应用中,对象的概率密度函数很难拟合.因此,本文采用第2种方式表示概率数据并以此为基础研究概率数据管理.为了方便表达,本文以二维概率数据为例描述算法.4HGD-Tree4.1HGD-Tree概述本文提出一种新的索引结构HGD-Tree(混网格树)管理大数据环境下的概率对象.如图2所示,HGD-Tree是以多分辨率网格[26]为基础构建的两层索引结构.HGD-Tree的第1层被称为α层,它管理概率对象的空间信息;HGD-Tree的第2层被称为β层,它管理概率对象的SUM.Page5HGD-Tree的α层索引(简称α层索引)是基于如下观察构建的:给定平衡的树状索引T与它的节点e,e的深度e.h和它对应区域的面积e.s可以反映e中数据的密度e.ρ.即:在e.h一定时,e.s越小,e.ρ越大.相反,e.s越大,e.ρ越小.利用上述观察,本文提出基于对象数量密度的α层索引.具体地,它以空间划分为基础,用面积相对较小的节点管理数据密度较大的区域;用面积相对较大的节点管理数据密度较小的区域.显然,基于这种方法构建的索引可以满足索引平衡性的要求.此外,该方法的另一个好处是索引结构可以反应对象的空间分布.随着对象的更新,只要它们的空间分布不发生剧烈变化,即使数据更新频繁,算法也能以较少的计算代价执行更新并保持索引的相对平衡.然而,数据的分布往往随着的时间推移逐渐变化.针对这一问题,本文提出一种高效的批处理更新算法.该算法利用多种数据转移策略有效地降低了更新代价.HGD-Tree的β层索引管理对象的SUM.该层索引为每个对象分配一棵子树.每棵子树通过存储对象区域的划分刻画对象的SUM.给定对象o,β层索引用粒度较高的划分管理样本点分布不均匀的区域;用粒度较低的划分管理样本点分布相对均匀的区域.基于这种方法,β层索引可以使用较少的划分更为深刻地反映出对象概率分布特征.因此,该方法不仅可以有效降低索引的存储空间而且可以增强对象SUM的概率剪枝能力.接下来,本文将分别对α层和β层索引展开详细描述.4.2α层索引描述本节首先提出了算法MAS(MergeAndSplit)初始化HGD-Tree的α层索引.其次,本文提出BUA算法动态维护α层索引.4.2.1α层索引的构建算法在描述算法之前,本文首先定义3个参数σumin和σ0.给定HGD-Tree的α层索引min①分别表示σuσu容积;σ0表示表示基于网格|cmi|表示cm给定N个概率对象,MAS以自上而下的方式初始化MBR(最小包围矩形)并对其进行m×m(本文以m=8为例)的空间等分.此后,MAS递归地合并包含对象较少的单元格;分裂包含对象较多的单元格②.具体地,给定单元格cm寻找可以与cmi.当合并或分裂操作完成后,MAS重复上述分裂cm操作构建新层次节点.当所有节点包含对象数量均小于σ0时,构建算法结束.接下来,本文详细介绍合并和分裂操作.合并操作:cm找可以合并的单元格.这类单元格是从cm产生.给定cn者合并.如图3(a)所示,因为|A|<σi寻找可以合并的单元格.给定A的邻居B,因为它们满足上述3个条件,算法将B合并到A.(1)m=n;(2)|cm(3)c此后,MAS继续为cmk,如果cmcm间满足条件(2)和(3),MAS将cmMAS无法为cm合并操作结束.特殊地,如果cm单元格c图3α层节点的构造(σu①②Page6并的单元格.例如,如图3(b)~(d)所示,因为A,B,C,D合并成A1,算法继续为A1寻找可合并的单元格.合并结果是将A1,E1,G1合并成A2.分裂操作:cm行2×2的分裂操作.如图3(d)所示,因为|J|>σuMAS将其分裂成4个子区域.在分裂结束后,如果仍然存在cmMAS递归对这样的子网格执行分裂操作直到cm所有子单元格c都满足|c|<σu内包含对象数目小于σu作.例如,本文对J的分裂结果做合并操作.合并结果为J0和J1.为了清晰地阐明的基本流程.算法首先定义和初始化用于控制节点的构造顺序的队列dQ.接下来,算法重复执行以下操作:(1)弹出队首;(2)使用网格节点进行划分;(3)对划分结果进行分裂或合并;(4)将满足条件|e|>σ0的节点插入队尾.当队列为空时,算法结束.算法1.MAS算法.输入:对象集合O,值域输出:索引1.QueuedQ,dQ.push(2.While(dQ.empty()≠true)3.Setε=partition(dQ.pop(),m×m),4.FOR(inti=0;i<|ε|;i++)5.IF|εi|>σu6.ε←split(εi)7.ENDIF8.IF|Si|<σu9.ε←Merge(εi,ε);10.ENDIF11.ENDFOR12.FOR(inti=0;i<|ε|;i++)13.IF|εi|>σ014.dQ.push(εi)15.ENDIF16.ENDFOR17.ENDWHILE18.RETURN;根据初始化算法描述可知HGD-Tree适于管理大数据环境下的概率数据.原因如下:(1)HGD-Tree基于空间划分对概率对象进行管理,算法不必像R-Tree那样频繁更新各节点的取值范围;(2)HGD-Tree根据对象的分布密度决定节点的大小.基于这个性质,构造算法可以保证同层次节点包含对象的数目大致相同从而解决了数据倾斜带来的问题;(3)由于HGD-Tree根据概率对象的重心决定节点的维护(分裂/合并),因此,当更新操作发生时,HGD-Tree可以有效减少需要维护的节点的数量.4.2.2α层索引节点的存储结构描述HGD-Tree的α层索引构建算法虽然可以增强动态更新能力,但是它可能引起查询效率降低、丢解等负面问题.接下来,本文从α层节点的数据结构入手来解决上述问题.给定HGD-Tree的α层索引α,本节将分别介绍储结构.(1)中间节点.如图3(d)所示,给定间节点ei,其孩子节点的覆盖范围并不相同.这导致网格的优势无从发挥①从而降低了查询效率.因此,本文提出一种新的数据结构UPV(UnionProtocolVector)解决上述问题.如图4所示,UPV表示了中间节点的数据结构.它由两部分组成:head和cell.head存储节点的基本信息.其中,ei.Id是ei的唯一标识符;ei.pr代表划分ei的网格分辨率;ei.nm等于ei管理的对象数目;ei.r表示ei的覆盖区域.ei.cell是长为ei.r×ei.r的数组.数组中每个元素对应一个基于α在构建过程中存在着分裂、合并等操作,所以于ei.cell中各元素存储的内容并不相同.给定ei.cell[u]和它对应的单元格cu,如果cu被其他单元格合并,ei.cell[u]指向所有与cu一起参与合并的单元格中下标最小的单元格.在图4中,ei.cell[2]对应于图3(b)中的单元格C.因为它跟A,B等节点一起组成了A2,ei.cell[2]=ei.cell[0].如果cu被分裂,ei.cell[u]指向数组sa.该数组存储cu的子网格.例如,ei.cell[36]对应于J.因为J被分裂成两个节点(J0和J1),ei.cell[36]①给定基于标准网格Page7指向sa.如果cu没被分裂(或合并),ei.cell[u]指向cu对应的单元格.显然,cu,只要它未被分裂,算法就可以利用基于网格的查询算法定位包含于cu中的对象.即使cu被分裂,由于cu中子网格数量往往较少,遍历范围也是可接受的.(2)叶子节点.因为本文根据概率对象的重心统计各节点包含对象的数目,该策略可能导致丢解.如图5(a)所示,U,V,W是3个叶子节点.给定查询q,虽然qr∩o5.r≠,但因为o5的重心包含于U,W并不维护关于o5的信息.因此,o5可能被错误地过滤.为了解决这个问题,本文提出ILV(InvertedListVector)存储叶子节点.如图5(b),ILV为每个叶子节点e分配了倒排列表liste.它存储的内容是所有与e.r存在交集的对象ID.在图5(c)中,iListu,iListv是节点U,V的倒排列表.图6基于批处理的HGD-Tree为了方便管理引BBG-Tree(层索引(α层和β层).与HGD-Tree不同,BBG-Tree的α层索引虽然也是管理概率对象的空间信息,但是它的节点是基于等分构造的①.这种做法的好处是可以利用网格特性实现快速插入.BBG-Tree中的β层索引管理对象的SUM.它的结构和HGD-Tree的β层相同.接下来,本文详细介绍BUA.需要强调的是:因为对象的插入与对象的删除互为逆操作;更新操作可以看成是插入和删除的组合,所以本文仅以对象的插入操作为例介绍更新算法.给定插入对象oins和BHG-Tree的α层索引α,BUA根据oins的重心将oins插入到节点中.假设oins插入节点eb,BUA根据|eb|决定是否分裂eb.具体地,如果|eb|>2r2,算法将eb做r×r4.2.3增量维护算法本文提出一种新的批量更新算法BUA(BatchUpdateAlgorithnm)维护HGD-Treeα层索引.如图6所示,该算法开辟缓冲区当有特定事件发生时,BUA将转移到HGD-Tree中.的分裂.此时,插入操作结束.由于||需要控制在一定范围内,所以BUA会在以4种触发条件下将HGD-Tree.它们是:查询触发;斜触发;溢出触发.(1)查询触发.因为本文使用两个独立的索引管理概率对象,所以查询算法需要在两棵树中分别进行搜索.给定查询q,HGD-Tree中与qr相交的叶子节点集εq,因为qrεq且据查询结果直接定位bqr,所以基于查询触发的数据转移策略可以有效降低插入代价.如图6所示,BUA将q在批量插入HGD-Tree.①对于任意节点ei,它的孩子都是基于特定分辨率划分得到Page8(2)α,因为中对象分布倾斜时,远高于其他子树从而影响查询和插入效率.为了解决上述问题,本文对执行“截断”操作,并将截断的部分转移到HGD-Tree中.回顾前文,当|eb|>2r2时,更新算法对eb做r×r的划分,并将树的高度h加1.如果h+1>σh,BUA将高出的部分“截断”并转移至HGD-Tree.如图6所示,当oins插入f后,因为|f|>2r2,所以BUA需要创建新的网格g.此时,树的高度变为5.因为σh=4<5,BUA需要将f包含的对象转移至HGD-Tree中.给定HGD-Tree的α层索引BUA在转移过程中首先查找子集合εr(通过一次范围查询).然后,BUA根据查询结果进行批量插入.(3)包含的对象数目也会发生变化.给定节点ei∈α,如果|ei|<σmin,ei需要寻找与其合并的节点.由于该操作花费代价较大,本文提出可以及时将降低α中节点的合并频率.具体地,BUA需要为ei寻找合并节点时,BUA发起在象集合果|ei|>σmin,关于ei的合并操作可以避免.否则,ei需要继续合并.(4)溢出触发.由于存机制的更新算法可以在总体上降低更新代价.然而,随着大.因此当||>σ(清空条件为|el|>logBN)并将它们包含的对象以节点为单位插入参数设置.BUA的一个疑问是关于参数σ设置.为了找到恰当的σ行分析.分析中用到的符号如下:||为数目;N为总体数据规模;B为节点的容积;Fq,Fu分别为单位时间内查询和更新次数.除去初始化代价外,总体计算代价由两部分组成:查询代价和更新代价.对于查询代价,因为本文使用了两棵独立的树,所以单次查询代价为O(logB||+logB(N-||)+||),其中||为查询结果的个数.因此,单位时间内总的查询代价为O(Fq(logB||+logB(N-||)+||)).更新代价也是由两部分组成:插入和转移.单个对象的插入代价为O(logB||),单位时间内的插入代价为O(Fu(logB||);单个对象的转移代价为O(1),单位时间内的转移代价为O(Fu).综上所述,由于引入logBN-logB||;总体节省的插入代价为(logBN-logB||)Fu.单次查询额外消耗的代价为logB||;总体额外消耗的代价为(logB||)Fq.为了使得总体节省代价大于消耗代价,不等式(logBN-logB||)Fu>FqlogB||必须成立.因此,本文将σ4.3β层索引算法描述β层索引用来管理对象的SUM.与文献[5-7]一样,本文也是利用划分技术构造对象的SUM.不同的是,本节提出的SUM更能反应对象样本点的分布特征.因此,它具备更强的过滤能力.本节首先提出了MMR的概念和基于MMR的SUM概率边界.其次,本文介绍了基于MMR的SUM构建算法和最优SUM.最后,本节讨论SUM的存储结构.4.3.1基于MMR的SUM概率边界定义1(专属矩形(记作MR)).给定概率对象o,它的样本点xi和包含xi的矩形r,如果r包含且只包含xi,本文称r为xi.的专属矩形.记作:xi.mr.定义2(最大专属矩形(记作MMR)).给定概率对象o,它的样本点xi和它的专属矩形集合xi的MMR为基于MMR的概率上下界.我们首先以文献[5-7]中的算法为背景,讨论基于MMR的SUM能够提供的概率上下界.给定查询q,对象o和它的划分{o1,o2,…,on},如果rr∩oi.r≠,本文可以通过式(3)和(4)分别计算基于MMR的子区域oi能为对象提供的概率上界ub(i)和下界lb(i).式(5)表示能为对象o提供的最大概率边界差.其中,maxRi和minRi分别表示包含于oi的样本点中面积最大和最小的MMR;app(i)表示o出现在oi.r中的概率;si=|qr∩o.r|;w为样本点的权值.maxD(o)=∑i<n比起文献[5-7]中SUM为对象提供的概率边界,基于MMR的SUM显然能为对象提供更紧的Page9概率边界.此外,从式(3)~(4)可知,maxRi-minRI越小,一步指导SUM的构建.4.3.2基于MMR的SUM构建算法本文将基于MMR构建的SUM称为SUMp.它的构造算法与KD-Tree的构建算法相似;其核心思想是将MMR面积接近的区域尽量划分在一起;给定对象o,算法基于KD-Tree的构建算法对or进行划分;用队列sq控制子区域的划分顺序.算法2给出了SUMp的构建流程.算法首先初始化队列sq.此后,算法重复弹出队首并对其执行分裂操作.给定队首节点e和它对应的子区域oi,算法对oi执行等分操作.等分之后,算法根据不等式(6)判断是否对oi继续划分.如果不等式为真,算法停止对oi的划分.否则,算法将划分结果插入队列.算法重复上述操作直到队列为空.最后,算法用KD-TreeT管理这组划分.其中,参数θ是一个阈值.本文将在4.3.4节讨论它的设置.算法2.SUMp构建算法.输入:概率对象o,最大边界阈值θ输出:o的SUMp1.初始化队列Queuesq:sq←or2.While(sq.empty()≠true)3.Nodee←sq.pop();{oi1,oi2}=split(e);4.Foreach(e∈{oi1,oi2})5.IFub(e)-lb(e)>||θ6.7.ENDIF8.ENDFOR9.ENDWHILE10.buildKDTree();11.Return;例1(SUMp的构造).图7(a)给出了对象o样本点的分布.首先,算法将or进行等分操作,结果如图7(b)所示.由于区域A满足不等式(6),算法停止对其划分;由于区域B满足不等式(6),算法将其等分为B和C.由于B中的样本点是均匀分布的,虽然B包含了大量的样本点,算法仍然停止对其划分.接下来,算法继续对C进行划分.在多次划分后,算法将C分成了{C,D},图7(e)显示了最终划分结果.图7(f)表示管理划分结果的KD-Tree①.与文献[5-7]中的SUM构造算法相比,SUMp的构造算法迎合了样本点分布的特性.在大多数情况下,它只需极少次的划分就可以得到概率边界更紧的SUM.接下来,本文对SUMp的剪枝能力和空间代价进行分析.定理1(更紧的概率边界).给定概率对象o和它对应的划分UD-Tree和SUMp管理,SUMp的剪枝能力更强.证明.对于oi∈or,当它被UD-Tree管理时,它提供的概率上下界分别为app(o,i)和0.相反,当它被SUMp管理时,它提供的概率上下界为式(3)和(4).显然,(4)-(3)<app(i)-0.因为ub(o)=∑ub(i),lb(o)=∑lb(i),SUMp会为概率对象提供更紧的概率边界.定理2(更小的空间代价).给定概率对象o和基于UD-Tree得到的划分Ou{ou果maxD(o)=θ,本文可以基于MMR找到一种新的划分等式:(1)maxD(o)θ;(2)|Om||Ou|.其中,|Om|与|Ou|分别表示两个划分中的子区域个数.证明.给定概率对象o和它对应的划分SUMp的构建算法可以基于MMR将域合并且保证合并结果仍满足不等式(6).由于合并操作减少子区域数目,不等式|Om||Ou|成立.证毕.4.3.3MMR构建算法4.3.2节中一个尚未解决的问题是如何为概率对象的样本点构建MMR.本文提出了一种高效算法解决上述问题.给定概率对象o和它的样本点本文首先对样本点各维度的坐标排序并用倒排链表存储.接下来,算法计算各样本点的MMR.具体地,算法任选一列倒排链表进行遍历(本文以选择l1为①为了节省存储空间,KD-TreeT只存储包含样本点的节点.Page10例描述算法).在遍历过程中,给定l1[i]和它对应的样本点su,算法首先找到su在l2中的位置①.其次,算法将su的MMR设置为(l1[i+1]-l1[i-1])×(l2[k+1]-l2[k-1]).特殊地,对于倒排链表首部(或尾部)的元素,算法利用o.mbr计算其MMR.算法总体分为两步:(1)初始化倒排链表;(2)计算样本点的MMR.在初始化倒排列表时,由于算法需要对样本点的每一维坐标进行排序,初始化代价为O(dmlogm).计算MMR的代价是遍历所有样本点,它的代价是O(m).因此,总体的计算代价为O(dmlogm).由于样本点只是原始数据的一个子集,本文可以将m看成常数.4.3.4基于区域热度的SUMp构建模型4.3.2节遗留的另外一个问题是参数θ的设定.本文通过引入区域热度的概念解决这一问题.通常情况下,给定概率对象o,θ越大,构造代价越小,但概率剪枝能力越差.反之,θ越小,构造代价越大,但概率剪枝能力越强.与以往算法相比,因为概率对象只在索引中驻留一段时间,所以SUMp的构造代价是不可忽略的.本文提出基于区域热度的代价模型.它可以为对象找到最优的SUMp构建方式并计算出最优的θ.该模型基于以下动机,给定一组对象,某些区域内的对象经常被访问(热点区域),而另外一些区域内的对象很少被访问(非热点区域).对于具有相同maxD但处于不同区域的对象,它们被验证的频率也是不同的.具体地,处于热点区域的对象访问频率高,被验证的次数频率也高.相反,处于非热点区域内的对象访问频率低,被验证的频率也低.因此,根据区域热度来决定SUMp是十分有意义的.在讨论代价模型之前,本文首先定义一组符号.给定对象o,costV表示o在无法被过滤时消耗的验证代价;costc表示SUMp的构造代价;costp表示SUMp的访问代价;T表示o在其生存周期内被访问的次数.如式(7)所示,给定对象o,它消耗的计算代价包括验证代价、SUMp构建和SUMp访问代价.其中,|T|costp为SUMp的访问代价.显然,这部分代价独立于θ.costc可以拟合成关于θ的函数φ(θ).它的含义是构建maxD(o)=θ的SUMp所需的计算代价.显然,φ(θ)是关于θ的减函数.由于拟合φ(θ)不是本文主要贡献,本文不对其详细叙述.TθcostV是o总共消耗的验证代价.其中Tθ为验证次数的数学期望.从式(7)可以看出,costT是一个非单调函数.本文可以根据它的拐点设置θ.参数T的设置:给定对象o,因为它的SUMp是在其插入时构建的.构建算法只能根据历史访问记录预估T.具体地,给定HGD-Tree的α层索引如果o的重心包含于设置为e的访问次数.4.3.5基于bit串的SUMp存储虽然SUMp可以有效减少划分次数,但是它仍耗费高昂的代价存储各子区域的位置信息和概率概要信息.为了近一步降低存储代价,本文提出了基于bit向量的存储结构.例如,图8中的bit向量存储了图7(f)中KD-Tree.给定对象o、划分O和它对应的KD-TreeT,本文通过描述T中各节点的数据结构介绍SUMp的存储方式.(1)数据结构.T包括两类节点:叶子节点和中间节点.给定叶子节点ef,它用五元组〈type,app,ub,lb,mId〉表示.具体地,type表示节点类型(1bit).app表示对象o出现在ef对应区域的概率.为了降低存储代价,存储算法将概率值(浮点类型)映射成一个rank值(7bit),其值域为[0,127].假设o出现在ef.r内的概率是0.2,它对应的rank值为0.2×128=25.us和ls分别表示ef.r中maxR和minR的面积.与app相同,本文也将面积(浮点类型)映射成rank值(4bit),其值域为[0,15].mID记录了节点的位置信息,本文稍后描述其细节.(2)中间节点的存储结构.给定中间节点ei,它用五元组〈type,app,adr,len,mId〉表示.其中,type,app,mId的含义与上文相同.adr表示其孩子节点在bit串中的相对地址;len表示孩子的个数,它们分别占用的6bit和2bit.(3)基于bMap的mId存储方法.为了介绍mId的存储方法,本文首先提出bMap的概念.给定概率对象o和它的划分基于不同划分得到的单元格,所以它可以用bit向①本文将同一样本点在不同链表上的坐标用指针相连.这样Page11量表示.例如:在图7(e)中,节点B是基于2×2划分下得到的单元格,本文可以用bit向量{10,01}表示它的位置;节点A是基于2×1划分下得到的单元格,本文可以用bit向量{01,1}表示它的位置.然而,节点可能是基于不同网格划分得到的,它们对应的bit串的长度也不相同(例如:图7(e)中的D和C).因此,算法需要为长度不同的bit串提供一个适配器(称为bMap)以便访问.如图9所示,bMap是由多条bit串列组成的静态表.它给出任意长度的bit串到定长bit串的映射关系.bMap中每条记录都是1个三元组〈Id,bit,mbit〉.给定bMap[t],bMap[t].bit表示它在网格(logt×logt)划分下某一行(或列)单元格对应的bit串;bMap[t].mbit表示该行(或列)单元格在(m×m)划分下包含哪些行(或列)子格.例网格如:如图7(d)所示,节点C是基于到的单元格.它对应的bit向量是{0001,1000}.它包含了一组在网格的并集可以表示为{00000011,11000000}.利用bMap,本文可以有效压缩节点位置的存储空间.具体地,本文仅存储各节点对应bit串在bMap中的下标.如图7(e)所示,节点C为基于4×4划分下得到的单元格;其bit向量是{0001,0010};它们分别保存在bMap[2]和bMap[4]中,因此,mId={2,4}.在介绍节点的存储结构之后,本节额外说明以下两点:(1)bMap只需存储少量的元组.因此,在大多数情况下,mId只需2Byte便可存储一个节点的位置信息.此外,bMap可以被所有概率对象共享.因此,基于bMap的存储方式可以大大降低存储代价;(2)与传统的节点存储方式相比,基于bit串的存储策略可以有效压缩空间.例如,一个叶子节点只需要3Byte的存储空间.结合定理2,对象SUMp的存储代价远远小于其他算法中SUM的存储代价.4.4HGD-Tree访问算法本文提出算法SHAB(SearchonHGD-TreeandBHG-Tree)寻找HGD-Tree和BHG-Tree中满足查询条件的概率对象.为了方便描述,本文将α层索引中层次最低的节点称为αleaf.4.4.1α层索引的访问算法SHAB分为两个主要部分.第一部分是通过索引的α层找到所有与查询范围存在交集的概率对象.给定查询q、HGD-Tree的α层索引Tree的α层索引分别访问论述.接下来,本文只强调如下两点:(1)中间节点访问.当访问算法需要对其UPV进行访问.具体地,算法首先根据e.pr和e.r找到和qr相交的网格.其次,SHAB访问e.cell找到与qr的孩子节点.(2)叶子节点访问.当SHAB找到与所有qr相交的αleaf时,SHAB将这些αleaf的倒排链表执行归并操作并剔除重复对象.此后,SHAB遍历归并后的倒排列表并找到所有与qr存在交集的概率对象.4.4.2β层索引访问算法SHAB的第2部分是查找符合概率阈值条件的概率对象.对于包含在查询区域内的对象,SHAB直接将其输出.对于与查询范围相交的对象,SHAB访问它们的SUMp.由上文可知,SUMp可以基于KD-Tree的搜索算法进行访问.因此,本文并不对搜索过程进行详细论述.接下来,本文只强调如下3点:(1)概率边界计算.给定查询q,概率对象o和它的划分域oi与qr的拓扑关系计算o包含在qr中的概率上下界ub(o)和lb(o).具体地:①当oi.rqr时,算法分别将ub(o,q)和lb(o,q)更新为ub(o,q)+oi.app和lb(o,q)+oi.app;②当oi.rqr∧e.type=leaf时,算法分别将ub(o,q)和lb(o,q)更新为ub(o,q)+ub(i)和lb(o,q)+lb(i).其中,ub(i)和lb(i)分别根据式(3)和(4)计算;③当e.rqr∧e.type≠leaf时,算法访问oi的子区域;如图10所示,给定查询q,因为qr∩or≠,SHAB遍历o对应的SHAB将A.app分别加到ub(o,q)和lb(o,q)上.接下来,SHAB访问I对应的子树.同理,SHAB将Page12ub(o,q),lb(o,q)更新为ub(o,q)+C.app+ub(B)和lb(o,q)+C.app+lb(B).(2)决策方法.当SHAB结束对法根据下列不等式决策下一步操作:①lb(o,q)qθ此时,SHAB将o输入到结果集;②ub(o,q)qθSHAB忽略o;③lb(o,q)<qθ<ub(o,q),SHAB执行对o的验证操作.(3)基于位运算的子区域位置比较算法.给定查询q,概率对象o和它的划分为中子区域的位置信息用bMap数组下标表示,所以SHAB需要通过位运算获取各子区域与qr的拓扑关系.SHAB首先根据or和qr的拓扑关系在各维生成一组bit向量qbit.qbit的长度等于bMap中mbit字段的长度(图9中|mbit|=8).qbit的值表示qr在基于网格格存在交集.如图10所示,查询q基于网格的划分生成的qbit为{11111100,11111111}.它表示qr与第2,3,4,5,6,7列(0,1,2,3,4,5,6,7行)网格相交.在生成qbit后,SHAB根据qbit和各子区域的mId判断它们之间的拓扑关系.具体地,oi∈文用布尔表达式(8)判断qr与oi.r的位置关系.其中,oi.mid[u].mbit表示oi第u维对应的mbit.直观地,如果oi.mid[u].mbit∧qBit[u]≠0,oi.r至少在第u维与qr相交.例如:节点C在X维对应的mbit为00001100.因为00001100∧11111100≠0,qr与C在X维相交.进一步讲,如果oi.r在任意一维都和qr相交,oi.r必定和qr相交.如果布尔表达式(8)成立,SHAB近一步判断oi.r是否包含于qr.为此,SHAB更新qbit.新的qbit表示qr在基于网格那些行(列)网格.如图10所示,q基于网格划分下生成的新qbit为{11111000,11111111}.它表示qr与第3,4,5,6,7列(0,1,2,3,4,5,6,7行)网格存在包含关系.更新qbit后,SHAB根据布尔表达式(8)近一步判断qr与oi.r的位置关系.与传统的节点间位置比较算法相比,基于位运算的比较算法有以下两个优点:①由于CPU适合于位操作,因此基于位运算的位置比较算法更能充分CPU的计算优势;②比较次数降低,当使用坐标判断节点的位置关系时,算法需要执行4d次坐标比较(判断相交和包含).相反,本文只需2d次位运算就可以知道查询区域和节点间的位置关系.4.5基于HGD森林的多维数据管理前文介绍了基于二维空间的HGD-Tree.因为HGD-Tree是以网格为基础构建的索引,所以当数据维度d大于2时,索引的空间代价和维护代价会急剧提高.为了折衷查询性能和维护性能,本节提出了HGD森林解决这一问题.给定参数m,本文根据m将对象o的属性{a1,a2,…,ad}分为{a1,a2,…,am},{am+1,am+2,…,a2m},…,{ad/mm+1,ad/mm+2,ad维数据独立的建立HGD-Tree1,BHG-Tree1,法同时维护这些索引.由于维护算法已在上文描述,本节不再重复.需要强调的是,虽然本文构建了多个索引维护多维数据,但是本文并不会为每个索引复制一个关于多维概率数据的副本.相反,在每个索引中,我们只保留它们的ID.概率对象的内容在单独的空间内保存.接下来,本节介绍查询算法.给定查询q,HGD-Tree的α层索引层索引先在α1∪α1,找符合条件的对象.其次,SHAB对查询结果2,…,合1∩2∩…∩d/m.对于o∈1∩2∩…∩d/m,SHAB根据式(9)、(10)计算o出现在qr的概率上下界.ub(o,q)1×ub(o,q)2×…×ub(o,q)d/m(9)lb(o,q)1×lb(o,q)2×…×ub(o,q)d/m(10)我们需要强调的是:由于我们引入了参数m,HGD-Tree可以根据数据的特点和数据维度自适应的选择划分策略.这样以来,HGD-Tree可以避免维度过高而引发的问题.本文将在实验部分讨论适合的参数m.Page135实验分析5.1实验准备本节首先讨论了数据集的获取.接下来,本文讨论参数的设置和实验方法.(1)数据集.实验的第1个真实数据集中国深沪两市约2300支股票近10年内的交易数据.交易记录大约5GB条,占用150GB的磁盘空间.为了降低数据规模,本文以周为单位将这些数据按照股票ID抽象成概率数据.具体地,实验根据各支股票一周内的交易记录随机选取槡N(N为该股票一周内的交易总量)条记录作为样本点.然后,实验将这些条记录中的交易价格和交易数量当做概率数据的两个维度.和文献[1,5-7]中一样,实验的第2个真实数据集是LosAngeles的位置数据.本文根据这些数据生成边长为500的正方形,然后为每条数据根据正态分布生成100个样本点,并将这些数据作为概率数据.第2个合成数据集模拟了正态分布的数据.它分别包含了10TB条2d,3d,4d数据.与第1个合成数据集类似,本文按照110000的方式生成概率数据,且每条概率数据内仍然包含100个样本点.此外,实验生成了两个合成数据集.每个数据集包含10TB条的多维数据.第1个合成数据集是模拟环境监测得到的数据集.该组实验生成1MB个虚拟传感器,它们不间断的上报数据当数据收集到10TB,实验以小时为单位生成概率数据.其中,每条概率数据内包含100个样本点.(2)参数设置.在本实验中,两个重要参数需要测试.它们是查询范围qr和概率阈值qθ.参照文献[1,5-7]中的参数设置方法,本文将查询范围从值域的0.01d扩大到0.1d,默认值为0.05d.概率阈值从0.1增加到0.9,默认值为0.5.此外,本文重点讨论了数据更新频繁时的概率数据管理.在这里,本节需要测试更新速度对索引性能的影响.在默认条件下,实验将单次插入/删除的对象数目设置成10;变化范围是[1,1KB].表2描述了参数设置和默认值.测试参数查询范围概率阈值索引规模更新规模数据集数据维度(3)实验方法.本文首先从文件中读入0.5||条数据初始化HGD-Tree.接下来,实验分成以下两组:第1组实验是在索引不更新的条件下测试HGD-Tree的过滤能力、查询效率和空间代价.查询的默认个数为100;位置随机生成.第2组实验是在数据频繁更新的情况下测试HGD-Tree的更新能力和综合性能.在测试更新能力时,本文重复以下操作:①从文件中读入s条概率数据;②将它们插入到HGD-Tree;③随机删除s条概率数据.当数据集中所有数据被处理后,结束测试.在测试综合性能时,实验方法每更新s条概率数据后提交s条查询.最后,本节介绍实验的对比算法.它们是U-Tree和UD-Tree.(4)数据规模的变化.本文首先测试概率模型对数据规模的影响.表3展示了这3组数据集在引入概率模型后数据规模的变化.如表3所示,在引入概率模型后,数据的规模大幅下降.因此,索引的负担也会大幅减轻.数据集名称真实数据集I真实数据集II合成数据集I合成数据集II5.2实验分析(1)查询范围对索引的影响.这组实验测试查询范围对索引性能的影响.这组实验采用真实数据集I作为测试数据;其他参数均使用默认参数;对比算法是U-Tree和UD-Tree.如图11(a)所示,HGD-Tree的过滤能力强于U-Tree和UD-Tree.特别地,随着搜索范围的扩大,基于这3种索引得到的候选集规模都有不同程度的扩大.然而,相比较于UD-Tree和U-Tree,HGD-Tree候选对象集合的规模扩大的最小.原因是:随着查询范围的扩大,与查询范围相交的概率对象也会随之增多.在这种情况下,概率对象SUM的剪枝能力变得尤为重要.图11(b)对比了基于这3种索引的查询时间.其中,HGD-Tree的运行时间最短.具体原因是:①本文是以网格为基础构建的索引.对于内存索引来说,它的访问速度最快;②SUM的剪枝能力更强,这可以有效的减少验证次数;③基于位运算的SUM访问算法可以近一步降低计算代价从而降低查询时间.(2)概率阈值对索引的影响.这组实验测试的内Page14容是查询概率阈值对索引性能的影响.这组实验采用真实数据集I作为测试数据;其他参数均使用默认参数;对比算法是U-Tree和UD-Tree.如图12(b)所示,概率阈值对于各种SUM的剪枝能力影响不图11查询范围对索引的影响图12概率阈值对索引的影响图13数据规模对索引的影响(3)索引的查询效率.这组实验测试的内容是数据规模对索引性能的影响.这组实验采用真实数据集I作为测试数据;其他参数均使用默认参数;对比算法是U-Tree和UD-Tree.数据规模从0.1扩大到0.9.如图13(a)所示,随着数据规模的扩大,基于这3种索引得到的候选集规模都有不同程度的扩大.然而,相比较于UD-Tree和U-Tree,HGD-Tree候选对象集合扩大的规模最小.原因是:随着数据规模的扩大,与查询范围相交的概率对象也会随之增多.在这种情况下,概率对象SUM对大.与图11(a)中的剪枝能力对比结果相似,HGD-Tree的剪枝能力最强.UD-Tree强于U-Tree.图13(b)对比了3种索引的总体运行时间.与图11(b)中的结果相似,HGD-Tree的查询时间最短.索引的性能产生至关重要的作用.因为基于HGD-Tree的SUM的过滤能力最强,数据规模对索引性能的影响最小.(4)索引的空间效率.这组实验测试的内容是数据规模对索引空间效率的影响.这组实验采用真实数据集I作为测试数据;数据规模从0.1||扩大到0.9||.对比索引是U-Tree和UD-Tree.如图14所示,随着数据规模的扩大,HGD-Tree的空间代价上升幅度最小.其中,最主要的原因是SUMp在大多数情况下只需较少的子区域表示一个划分.其次,Page15本文基于bit向量存储SUMp.这种方法又近一步降低了空间代价.如图15利用合成数据集再一次测试了索引的空间效率.由实验结果可知,HGD-Tree的空间代价最低.(5)不同数据集对索引的影响.这组实验测试的内容是不同数据对索引的性能的影响.实验方法和参数设置同图17中的实验相同.如图15所示,在不同测试数据集中,HGD-Tree的性能最好.这说明了HGD-Tree有着较为广泛的应用范围.(6)更新速度对索引的影响.这组实验测试的内容是索引的更新能力.本文在这组实验里并不考虑查询对索引的影响.这组实验采用真实数据集I作为测试数据;其他参数均使用默认参数.如图16所示,HGD-Tree的动态更新能力最强.这里有两方面原因:①HGD-Tree使用以网格为基础管理概率数据.该结构适用于在数据更新频繁的条件下使用;②本文引入了一种缓冲机制批量的更新数据.(7)索引的综合性能.这组实验采用真实数据集I作为测试数据;其他参数均使用默认参数;本文在这组实验里,查询和更新交替进行.他们之间的比例为11.如图17所示,HGD-Tree的性能最好.这里有两方面原因:①HGD-Tree的更新能力远远强于其他索引;②HGD-Tree的查询效率高于其他索引.因此,HGD-Tree的综合性能最好.(8)最适当的参数m.实验的最后,本文讨论了关于参数m的设置.本节最后讨论关于参数m的设置.本文采用的数据集为合成数据集,它包含了6个属性.为了避免维度过高而引起高昂的空间代价和维护代价,本文将多维数据的属性按照其维度进行划分.图18、图19分别评估了不同划分下索引的过滤能力,计算代价和空间代价.所有参数均为默认参数.图19报告了参数m对算法过滤能力的影响.其中,候选集个数为|1∪2∪…∪d/m|.如图20可知,查询代价也是随着m的增大而降低.但是,我们发现,当m2时,下降速度变得非常缓慢.其原因是:①本文提出的索引具有较强的过滤能力.因此,参与合并的候选对象个数也是有限的;②本文采用位运算加速查询,它会额外降低算法的计算代价.因此,当m减小是,查询性能的下降速度非常缓Page16慢.此外,随着m的增长,算法的空间代价快速增长.其根本原因是,当m增加是,对象summary包含的子区域个数迅速增加.因此索引的整体空间代价会增加.(9)数据维度对索引的影响.这组实验测试的内容是数据维度对索引性能的影响.这组实验采用合成数据集II作为测试数据集;其他参数均使用默认参数.对比算法是U-Tree和UD-Tree.数据维度从2维增加到6维.如图20~图22所示,随着维度的增加U-Tree和UD-Tree的查询代价都快速上升.相反,HGD森林的查询代价上升幅度相对缓慢.这有两方面原因:①SUMp的剪枝能力强于其他索引.当对多个索引的查找结果求交时,因为候选集中包含的对象个数较少,维度对HGD-Tree的影响是有限的;②HGD-Tree是以网格为基础构建的.它在维度小于2时具有很大的优势.所以,HGD森林的性能最好.如图21所示,随着维度的增加,3种索引的更新代价都是呈线性增长的.其中,HGD-Tree增长的最慢.其根本原因是:①HGD-Tree在为对象构建summary速度较快;②4.2.3节中的批处理算法可以使得HGD-Tree快速的更新.如图22所示,随着维度的增加,所有索引的空间代价都是随着维度线性增长.因此,HGD-Tree的空间代价依旧远远好于其他索引.6结论本文研究了支持频繁更新的概率数据范围查询的索引.本文首先提出了一种适用于管理数据更新频繁的索引HGD-Tree.它不仅是一个平衡的结构,而且具有很强的动态更新能力.其次,本文提出了一种批处理算法处理索引的更新.再次,本文提出基于样本点距离的SUM构造算法.该算法可以用较少的空间代价构造出更能反应对象概率密度特征的SUM.最后,通过大量实验验证了本文提出算法的有效性和实用性.
