Page1XML关键字查询处理研究周军锋1),2)孟小峰3)1)(燕山大学信息科学与工程学院河北秦皇岛066004)2)(河北省计算机虚拟技术与系统集成重点实验室河北秦皇岛066004)3)(中国人民大学信息学院北京100872)摘要关键字查询作为一种有效的信息检索手段,一直以来都是XML数据管理领域研究的热点问题,每年均有大量最新研究成果出现在各种顶级会议和期刊上.针对众多国内外研究者在XML关键字查询领域所作出的创新性工作,该文以XML关键字查询处理系统为框架来组织现有工作,重点分析和比较了查询生成、语义定义、排序机制、查询算法及结果展示等5个关键技术点所涉及的代表性工作的特点,并结合最新的应用需求从有效性和高效性的角度归纳出XML关键字查询技术后续研究面临的问题和挑战.关键词可扩展标记语言;关键字查询;查询生成;查询语义;排序机制;结果展示1引言可扩展标记语言XML(eXtensibleMarkupLanguage)的出现,使以网络应用为代表的一大批新型应用得以迅速发展.在当前各种网络应用中,如电子商务、电子政务、金融、出版、科学数据和各种资源的数字化等,XML扮演着极其重要的角色,它已经成为数据交换事实上的标准、SOA架构的基石.高速增长的XML数据管理市场在国际范围内引起了各大厂商的激烈竞争.IBM公司在其新推出的DB29版本中,直接把对XML的支持作为其新Page2产品的最大卖点;Oracle和微软也同时宣称他们的产品可以实现高性能XML数据的存储与查询,使现有应用更好地与XML共存.除此之外,不同行业也都加紧制定本领域特定的标记语言,如用于对数学符号进行编码的MathML、W3C发布的XHTML、化学领域的标记语言CML、W3C推荐的用于描述二维图形的标记语言SVG、金融界的XBRL(可扩展商业报告语言,XML的一个子集)等等,实践中正在源源不断产生XML数据并推动着XML数据管理技术不断向前发展.如何有效地管理和利用快速增长的XML数据,一直以来都是数据库研究领域中的一个热点问题.广义来说,用户可以使用两种查询机制,即结构化查询语言(如XPath和XQuery),或者一组关键字从XML数据中获取所需的信息.使用结构化查询语言可以精确表达用户的查询意图,但其正确使用的前提条件是用户了解所用的查询语言和所查询的XML文档的结构信息.即使对专业用户来说,了解复杂的XQuery语法和XML文档结构都是一件极其困难的事情,更不用说面向的普通用户,这极大限制了XML数据库系统的可用性.此外,数据间关系的对称性和XML文档结构的不对称性之间的矛盾以及XML文档结构随着企业业务的发展不断演变的现象将导致数据以不同的物理形式进行组织,会进一步加重用户了解文档结构和书写结构化查询表达式的负担,削弱数据库系统的可用性.与此对应,关键字查询无需用户学习复杂查询语言和了解复杂文档结构的问题,从而能轻易查询XML数据,可有效增强XML数据库的可用性.尽管关键字查询技术在信息检索领域取得了巨大成功,XML数据区别于普通文本的内在层次结构使得传统的关键字检索技术不再适用于XML数据.针对这一问题,国内外的企业界和学术界都投入了大量人力物力进行技术攻关,相关研究成果最近几年频繁出现在数据库领域各种顶级会议和期刊上,但是基于XML数据的关键字查询问题仍没有得到很好的解决,在查询生成、语义定义、排序机制、查询算法以及结果展示方面依然存在很多问题,这些问题严重制约了XML应用的推广和普及.本文基于这一背景,根据典型XML关键字查询处理系统①所涉及的关键操作及其作用,从查询生成、语义定义、排序机制、查询算法、结果展示及原型系统等六方面系统、深入地分析和比较现有工作的特点,并结合最新的应用归纳出XML关键字查询领域后续研究面临的关键问题和挑战.本文第2节介绍XML关键字查询处理系统的架构,并总结出XML关键字查询处理技术涉及的5个方面的关键问题,以便读者对XML关键字处理技术有一个整体概念;第3节~第7节对各技术点的研究现状进行深入的分析和比较;第8节介绍现有的XML关键字查询原型系统;最后在第9节讨论未来一段时间可能的研究点.2XML关键字查询处理系统2.1查询接口已有关键字查询接口可以分为两大类:(1)纯文本输入.Google、百度等各种搜索引擎均采用这种输入方式.(2)可以指定属性和属性值的查询方式,这类似于很多网站提供的高级搜索功能.在XML关键字查询领域,XSEarch[1]查询的基本形式为Q={t1,t2,…,tm},其中每个ti=〈l:k〉(1im)是一个二元组,l为XML数据中元素的标签名,k是用户指定的关键字,ti可以只由l或者k构成,ti可以通过符号“+”限定为在查询结果中必须出现,否则ti可以不出现在结果中.此外,文献[2]在XQuery中嵌入的关键字查询方式也采用这种形式.2.2系统工作机制图1为典型XML关键字查询系统结构图,如图所示,查询处理器负责查询生成、查询执行和结果图1基于XML数据的关键字查询系统结构图①这里的“典型XML关键字查询系统”指去除不同系统的特Page3展示功能,存储管理器负责数据、索引和模式信息的管理,并基于缓冲区管理模块和文件管理模块调度数据库中存储的数据.用户在进行关键字查询时,系统会涉及到以下的处理步骤:(1)在用户键入关键字的同时,查询生成模块会调用查询清洗功能对输入的关键字进行容错处理,并识别可能的短语和剔除无意义的关键字,同时调用查询提示功能根据历史查询的统计信息为用户实时推荐其它相关的关键字以协助用户构造查询.(2)查询执行引擎根据给定的查询语义和排序机制确定执行算法,然后调用存储管理器的相应模块获取满足条件的Top-K查询结果.(3)结果展示模块将符合查询语义的结果按照其与用户查询的相关程度,依照特定展示策略依次呈现.2.3关键技术问题面的关键问题:基于XML数据的关键字查询技术涉及5个方(1)查询生成,即根据用户输入的关键字构造合适的查询.查询生成的目的是为了向查询引擎提交尽可能准确表达用户自身查询意图的一组关键字.(2)查询语义,即对于给定的关键字查询,定义什么样的结果是有意义结果的问题.有效的查询语义可以为用户返回更多符合其查询意图的结果.图2本文涉及的XML关键字查询处理关键技术内容3查询生成3.1研究动机实际中,用户输入习惯的不同或拼写错误会导致查询中包含不相关或错误的单词.例如,用户想找和AllisonRoss相关的信息,但却错误的输入了“AlisonRose”;再如,用户输入的关键词可能是被找内容的同义词.这些问题的出现在所难免,需要查(3)排序机制.对于得到的结果,排序机制将计算其与用户查询的相关程度,并按照分值进行排序,将最相关的结果最先呈现给用户.(4)高效算法.针对给定的查询,高效算法可以提升系统的响应速度、快速求解符合语义的结果.(5)结果展示,即对于得到的查询结果,以何种方式呈现给用户的问题.有效的结果展示方式有助于用户快速定位所需信息、提高系统的可用性.需要说明的是.图1所示的存储管理器中涉及的技术问题可以借鉴关系数据管理领域的成熟技术和产品进行参考.除了以上5个方面的问题,与XML关键字查询处理相关的研究工作还包括:结构化查询和关键字查询相结合的查询方式,如TeXQuery[3]、FleXPath[4]、GalaTex[5]及文献[2]的结构等;XML数据流上的关键字查询;不确定性XML数据上的关键字查询;数据源的选择等.限于篇幅,本文对这些问题不予讨论.虽然应用领域不同,但其中关键字查询处理部分和本文所述的问题一致.在本文的讨论中,我们将以上5个方面的核心技术问题纳入XML关键字查询系统来进行分类阐述.这些研究点的组织如图2所示,其中关键问题(2)、(3)、(4)都属于查询执行引擎模块,在图中如虚线矩形所示.后续内容将按照图2的分类方式逐一阐述.询生成模块调用其自身的查询清洗功能来协助用户修正输入中存在的问题来改进查询结果的质量.另外,当用户对所查询的内容不熟悉时,为用户自动提示与当前输入关键字相关的信息有助于用户快速构建查询.根据提示信息的类型,可以分为查询提示和结果提示两大类.查询提示通过将用户的实时输入和预先定义的字符串目录(内容来自被查询数据的统计信息和历史查询信息)进行匹配,预测用户未来可能输入的内容,是一种快速编辑文本内容Page4和构建查询的技术.结果提示通过在数据库中快速定位与输入查询匹配的结果,为用户实时反馈与当前输入关键字相关的查询结果.当用户对所查询的内容不熟悉时,这种方式可以改善传统信息检索系统先提交关键字再给出查询结果所造成的重复提交查询的问题.3.2研究现状3.2.1查询清洗文献[6]主要研究计算语言领域的短语识别问题,文献[7-8]关注于信息提取方面的短语识别问题,这些方法基于给定的文本,通过训练一个语言概率模型来推断分隔符的位置.由于针对的不是查询,这些方法识别出来的短语在数据库中可能并不存在.另外,以上方法对短语中的单词是顺序敏感的,而灵活的关键字查询系统应该支持与顺序无关的短语查询.文献[9-10]主要研究基于关系数据的关键字清洗策略,所解决的问题包括识别查询中无意义的关键字、修正错误拼写的关键字、识别有效的短语以及从文本中提取有效的关键字查询.3.2.2查询提示在查询提示方面,已有的很多工具软件,如VisualStudio、Google以及桌面搜索等都提供了该功能.文献[11-17]研究了查询提示问题,其中文献[11]针对有限内存提出了单字符预测的问题并给出了相应的解决方案;文献[13]专门针对文本数据进行查询提示;文献[12]提出了一种短语预测算法来协助图3查询生成技术分类比较4查询语义本文划分语义类型的标准有3个:(1)数据模用户快速构建符合自身语义的查询;文献[14]系统地研究了数据库关键字查询提示的容错处理问题,即当用户由于不了解被查询内容而输入了错误的或者语义近似的单词时,如何为用户实时推荐近似匹配;文献[15]在文献[14]的基础上,将容错处理技术应用到输入URL数据时的实时提示.文献[16]进一步考虑了单词间的语义信息,为用户实时推荐与输入的单词相关的主题词,来协助用户构建面向某个主题的查询;文献[17]也是为用户推荐相关主题信息,和文献[16]相比,区别在于主题的推荐不是实时的,而是对Top-K查询结果进行概括得到的.3.2.3结果提示文献[18-22]研究结果提示问题.其中文献[18-19]分别基于XML数据和关系数据为用户提供与输入同步的实时匹配结果,二者的共同点是关键字的匹配方式都是精确匹配.文献[20-21]研究了在用户输入不准确的前提下,基于相似性匹配技术为用户实时展示近似查询结果的问题.文献[22]在查询表格中键入关键字,实时给出相关查询结果,与其他结果提示方法相比,该方法可以为不同属性指定关键字,通过增加约束条件来提高查询的准确性.图3展示了现有查询生成技术的研究进展情况,结合前面的阐述可以看出:现有技术大多关注文本数据和关系数据;随着研究的深入,尤其是实时结果提示问题,目前可以支持模糊匹配,对用户来说,查询变得更加容易,但对XML数据来说,仅涉及文献[18]的工作.型,即定义语义时是否考虑元素间ID/IDREF及XLink信息,分为树模型和图模型两类.(2)依据对象,即定义语义时依据模式信息进行定义还是直接在数据上进行定义.(3)关键字关系,即关键字之间Page5需要满足AND还是OR关系.如图2所示,现有的XML关键字查询语义可以分为4类,分别是:(1)基于树模型和XML数据的AND语义.(2)基于树模型和XML数据的OR语义.(3)基于图模型和模式信息的AND语义.(4)基于图模型和XML数据的AND语义.4.1基于树模型的XML关键字查询语义在基于树模型的关键字查询语义中,现有工作都是基于数据进行定义的.最低公共祖先(LowestCommonAncestor,LCA)是所有语义的基础.对于给定的查询Q={k1,k2,…,km}而言,以LCA为根的子树是包含这些关键字对应结点的最小语义片段.单纯基于LCA语义的工作主要涉及文献[23-24],这两个工作都着眼于推断用户的查询意图,然后将以LCA为根的子树作为结果返回.文献[23]从查询本身着手,首先基于统计方法判断用户的查询意图,即用户想找什么类型的结点①.文献[24]基于文献[23]的工作,进一步考虑了多个结点之间及多个值之间的关键字和结构信息来推断用户的查询意图.除此以外,其它语义都在LCA的基础上进行了不同程度的限制,下面分别进行阐述.4.1.1基于树模型和XML数据的AND语义目前大多数基于树模型的XML关键字查询语义都属于这一类,共有5种代表性语义,分别是ELCA、SLCA、MLCA、XSEarch及VLCA.其区别可以简单阐述为:ELCA和SLCA仅考虑结果的结构信息,其它3种语义进一步考虑结果中的元素名称.ELCA语义[25-26].其定义可以简单阐述为:如果一个LCA结点v是ELCA结点,则v满足在以v为根的子树中去除所有以其它LCA结点为根的子树后,v仍然包含所有关键字.例如,对于图4所示的文档和查询Q1={k1,k2}来说,满足条件的ELCA结点为r,a1,d3,a5,注意a2之所以不是ELCA的原因在于b3是k1和k2的LCA结点,当移去以b3为根的子树后,以a2为根的子树仅包含关键字k2,因此a2不是k1和k2的ELCA结点.SLCA语义[27].这种语义认为既然以某个结点为根的子树包含所有的关键字,那么它的祖先元素就不应该作为返回结果.例如,对于图4所示的文档和查询Q1={k1,k2}来说,满足条件的SLCA结点为a1,d3,a5.文献[28]基于元素类型提出了一种类似语义MLCA,虽然SLCA不考虑元素类型,但对于图4的D1和Q1来说,SLCA和MLCA语义返回的子树根结点集合是一样的,这里不再单独说明.图4XML文档D1(元素名字中的字母表示其标签,XSEarch[1]和VLCA[29]语义.这两种语义在LCA的基础上,将不同关键字到LCA路径上存在同名结点的结果排除在外.假设T表示给定XML文档中的一个子树,n1和n2是T中的两个元素结点,元素名称指该元素在文档对应的DTD中的标签名(英文称为tag或label),LCA(n1,n2)表示n1和n2的LCA结点,T|n1,n2表示从LCA(n1,n2)到n1和n2的两条路径.定义1(互连关系).如果n1和n2满足以下条件之一,则称n1和n2满足互连关系:(1)T|n1,n2中不存在有相同名称的不同结点.(2)有相同名称的结点只能是n1和n2.基于互连关系,文献[1]提出两种语义,一种是all语义,一种是star语义.对于给定的查询Q={k1,k2,…,km}来说,假设包含这m个关键字的元素结点是n1,n2,…,nm,all语义规定这m个结点中的任意两个之间必须满足互联关系,而star语义需要首先从m个结点中选定一个,其它m-1个结点只需要和被选定的结点具有互联关系即可.本文后续提到XSEarch语义时,均指all语义.从这个意义来说,XSEarch和VLCA语义相同,区别在于文献[29]中基于VLCA语义提出的CVLCA语义.例1.对于图4所示的XML文档D1和关键字查询Q1={k1,k2},假设SX表示满足X语义的结点集合,则根据以上介绍,满足条件的LCA语义的结点集合SLCA={r,a1,a2,b3,d3,a5},满足条件的SLCA和MLCA结点集合SSLCA=SMLCA={a1,d3,a5},满足XSEarch和VLCA条件的结点集合SXSEarch=SVLCA={r,a2,d3,a5},满足ELCA语义的结点集合是SELCA={r,a1,d3,a5}.可以看出,所有语义都返回了d3和a5,但又存在和其它语义不同的①结点类型指在文档中从某个结点到根结点的路径.Page6返回结果,其关系如图5所示.图5基于Q1={k1,k2}和文档D1的查询语义关系示意4.1.2基于树模型和XML数据的OR语义MCT语义[30].对于给定的文档D和查询Q={k1,k2,…,km}来说,MCT(Minimal-CostTree)的定义基于4个概念:①关键字ki(1im)的内容结点(contentnodes)指直接包含ki的元素结点ni.②ki的近似内容结点(quasicontentnodes)指ni的所有祖先结点.③ki和结点n(n是ki的内容结点或近似内容结点)的关键结点(pivotalnode)指在n的后代中,所有ki的内容结点中离n最近的内容结点.④对于ki和n来说,其关键结点ni的关键路径(pivotalpath)指从结点n到ni的路径.最小代价树MCT的定义如下.定义2(最小代价树MCT).对于给定的查询Q={k1,k2,…,km}和文档D中的结点n,Q的关键字和n对应的所有关键结点的关键路径构成了最小代价树MCT.例2.对于图6所示的XML文档D2和关键字查询Q2={k1,k2,k3}来说,k1的内容结点是b1;k2的内容结点是d1和b3;k3的内容结点是d2和b4.k1的近似内容结点是a1;k2的近似内容结点是a1,b2,b3,c1,d1;k3的近似内容结点是a1,b2,b4,c1,d2.对于k1和a1来说,其关键结点是b1;对于k2和a1来说,其关键结点是b3,不是d1;同样,对于k3和a1来说,其关键结点是b4.对于k1和a1来说,其关键路径是a1→b1;对于k2和a1来说,其关键路径是a1→b3;对表1XML关键字查询语义方法XRank[25-26]√XKeyword[32]XSEarch[1]√MLCA[28]√SLCA[27]MSP[2]BLINKS[35]VLCA[29]√EASE[36]Interconnection[33]于k3和a1来说,其关键路径是a1→b4.基于以上结果,对于Q2和a1来说,其MCT如图6中MCT1所示;对于Q2和c1来说,其MCT如图中MCT2所示.4.2基于图模型的XML关键字查询语义在基于图模型的关键字查询中,已有方法的语义主要借鉴了关系数据库中的关键字查询思想[31],即对于给定的一组关键字,返回包含所有关键字的最小连通网络(MinimalTotalNodeNetwork,MTNN).现有方法都要求关键字之间是AND关系.4.2.1基于图模型和模式信息的AND语义文献[32]基于模式图定义数据的最小连通网络.文献[2,33]提出的关键字查询语义也是基于模式图进行定义的,其查询的关键字是由“label:keyword”中的label组成,语义为查询中所有label在模式图中对应的连通网络,因此这两个文献的关键字查询中,每个关键字其实都是模式中的元素.文献[34]针对已有语义存在的问题,通过对元素进行类别标注,提出使用MCN语义来识别有意义的结果.4.2.2基于图模型和XML数据的AND语义文献[35]研究了有向图上的关键字查询问题,并提出了一种双层索引来加速有向图上关键字查询处理的效率.文献[36]提出了一种查询异构文本、XML及关系数据的总体框架,对XML数据来说,其基本语义是半径为r的Steiner图.表1中“结点名称”列表示该语义在定义时是否关键字之间关系ANDOR√√√√√√√√√Page7方法XReal[23]SAIL[30]MCN[34]CLCA[37]√ISO&IRO[38]考虑了结点标签名的影响;“结点类别”列指语义定义时是否考虑了结点所属类别的影响,结点类别包括实体、属性和连接结点.可以看出随着研究的深入,不同工作在定义语义时考虑的角度和因素都有所不同.总体而言早期的语义大多单纯从XML文档结构的角度来定义语义,而最近提出的语义考虑了更多的信息,如结点名称和类别,因而返回结果更加贴近用户的实际需求,更适用于以数据为中心的文档.5排序机制对于得到的结果,排序机制将计算其与查询的相关程度,并给每个结果相应的分值,最后按照分值进行排序,将评分最高的结果最先返回给用户.已有方法所采用的排序机制大致可以分为3类:(1)以结果大小为标准的方法.(2)以PageRank为基础进行扩展的方法.(3)以TFIDF为基础进行扩展的方法,下面进行分类阐述.5.1基于结果大小的排序方法在该类方法中,文献[32]基于模式图,首先根据给定的关键字查询得到包含所有关键字的最小候选网络(MinimalTotalNodeNetwork,MTNN),MTNN类似于XQuery语言对应的结构化查询表达式.这样,每个关键字查询可能对应多个MTNN,每个MTNN的评分是其包含的边的数目.因此,如果一个MTNN对应多个返回结果,则这些结果的评分相同.5.2基于扩展PageRank的排序方法该类方法的典型代表是XRank[25].在计算元素的全局重要性方面,XRank考虑了3种链接信息:(1)元素之间的超链接.(2)祖先结点到后代结点的链接.(3)后代结点到祖先结点的链接.在计算结果和查询间相关性方面,XRank考虑了3种因素:(1)结果专一性(ResultSpecificity),可以简单理解为结果大小.(2)关键字之间的接近性(Keyword关键字之间关系ANDOR√√√Proximity),包含关键字间物理距离的远近和关键字间语义距离的远近.(3)超链接可知性(HyperlinkAwareness).对于满足文献[25]中提出的ELCA语义[26]的结果v来说,v和给定查询Q={k1,k2,…,kn}的相关程度用下面的式(1)来计算.R(v,Q)=∑1in式(1)中等式左边的R(v,Q)表示v和Q的相关度,等式右边由两部分的乘积组成:第1部分表示v与所有关键字的相关度之和,主要考虑了结果的专一性和超链接问题;第2部分的p(v,k1,k2,…,kn)用于衡量关键字之间的接近度.函数p的取值介于0~1之间,文献[25]的方法中,p的取值与v中包含所有关键字的最小文本片段的长度成反比.下面我们重点介绍式(1)中等式右边的和式部分.该和式表示v与所有关键字的相关度之和,对于多次出现ki的情况,文献[25]中取所有r(v,ki)的最大值.文献[25]中r(v,ki)的计算如式(2)所示.式(2)中的decayt-1用于衡量结果的专一性,其中,t表示从v~ki的路径长度;e(v)表示v的全局重要性.其计算方法如式(3)~(5)所示.e(v)=1-d式(3)将XML文档中的元素当成信息检索领域的文档来计算元素v的全局重要性.式(3)中,(u,v)表示XML文档中的一条边;E表示边的集合,由3种边构成:超链接边EH(包括ID/IDREF和XLink)、包含边EC及反向包含边;Ne表示文档中元素的总数;Nc(u)表示u的孩子结点数;Nh(u)表示从u出发的超链接数.式(3)对3种边不加区分,而实际中包含边和超链接边是相互独立的,式(4)考虑了两种边的区别.e(v)=1-d1-d2Ne+d1×∑(u,v)∈EHPage8虽然式(4)对包含边和超链接边进行了区分,但没有对正向包含边和反向包含边进行区分,这在实际中并不合理.例如,对于图7所示的结点n来说,其重要性需要考虑其孩子结点m的重要性.由于n只有一个孩子m,因此m可以向上传递的重要性应该等于其自身重要性,而不应该和式(4)一样,将向上传递的重要性除以Nc(u)+1.修正后的计算方法对正向和反向包含边进行了区分,如式(5)所示.e(v)=1-d1-d2-d3Ne+d1×∑(u,v)∈EH综上,式(1)中的p说明文献[25]的方法考虑了关键字之间的接近度,式(2)中的decay表明该方法考虑了结果专一性,而式(3)~(5)则说明该方法考虑了不同的超链接信息.5.3基于扩展TFIDF的排序方法绝大部分已有的排序方法都是基于TFIDF进行扩展,这里介绍两个代表性工作:(1)结合向量空间模型和TFIDF的排序方法.(2)直接扩展TFIDF的排序方法.下面分别阐述.5.3.1结合向量空间模型和TFIDF的排序方法XSEarch[1]在对结果进行排序时,既考虑了单词的出现频率,也考虑了结果的大小及结构信息.其计算方法如式(6)所示.score(q,N)=sim(Q,N)α式(6)中等号左部表示查询Q与查询结果N的相关度评分,右部的size(N)表示关系树N中的结点个数;AD(N)表示N中具有祖先后代关系的结点对的个数;sim(Q,N)表示基于向量空间模型计算得到的查询Q和N的相似度;β、α及γ表示为3种度量因素设定的权重.从式(6)可以看出,在两个结果sim(Q,N)相同的情况下,结点越多,其评分越小;结果中的祖先后代结点对越多,结果评分越大.对图8中的两个结果N1和N2来说,当sim(Q,N1)=sim(Q,N2),size(N1)=size(N2)且AD(N1)=AD(N2)时,该语义得出的相关性评分score(Q,N1)=score(Q,N2),这种情况不一定和实际情况相符.sim(Q,N)的计算基于向量空间模型,如式(7)所示,其中狋i表示查询Q={t1,t2,…,tm}中的ti①对应的向量,狀j表示结果N中结点nj对应的向量.假设文档D中包含L1个关键字,D对应的DTD中有L2个标签,则向量狋i和狀j的大小是L1×L2,即对于每个关键字和标签构成的二元组(k,l)而言,向量中都有一个数字nbr(k,l)和其对应.对于查询Q中的每个ti而言,其对应的向量狋i中的数字取值分为3种情况:(1)t=“:ki”.(2)t=“li:”.(3)t=“li:ki”.对于第(1)种情况,对于所有包含ki的结点,假设其结点名为l,则相应的nbr(ki,l)等于1,否则为0.对于第(2)种情况,所有(k,l)对中标签等于li的nbr(k,li)取值为1,否则为0.第(3)种情况仅有nbr(ki,li)取值为1,其它为0.对于D中的结点n而言,假设其包含的叶子结点集为Nleaf,则n对应的向量中的每个数字的取值如式(8)所示.nbrn(k,l)=∑nl∈Nleaf式(8)中的w(k,nl)的计算采用TFIDF思想计算,w(k,nl)=tf(k,nl)×ilf(k)②,tf(k,nl)和ilf(k)的计算见式(9)和式(10).公式中occ(k,nl)表示nl中k出现的次数,words(nl)表示nl包含的单词集合,M是XML文档中的结点集合.tf(k,nl)=occ(k,nl)ilf(k)=log1+|M|①②ilf的英文全称是inverseleaffrequency.Page95.3.2直接扩展TFIDF的排序方法SAIL[30]采用基于TFIDF的思想来计算结果和查询的相关性.和XSEarch不同,SAIL考虑了更多的排序因素.例如,XSEarch使用TFIDF计算的是叶子结点和关键字的相关性,而SAIL计算的是任意结点和关键字的相关性,并通过路径长短来区分高度不同的结果的相关性;XSEarch直接用tf(k,nl)×ilf(k)来计算相关性,而SAIL考虑了更多的规范化因子,如对tf和idf取对数,并除以文档长度.简单地说,SAIL通过TFIDF考虑了单词的频率信息,通过路径长度对结果的高度进行区分,通过单词之间的紧凑度对结果的宽度进行区分.文献[37]的排序思想和SAIL类似,通过结构距离和单词的统计信息来对结果和查询的相关性进行计算.XReal[23]和前述工作的区别是语义定义,即通过统计的方法首先确定应该返回什么类型的结果,然后再对该类型的结果进行排序.其结果排序思想同样基于TFIDF,考虑的排序因素包括关键字的频率、关键字出现的顺序、关键字在查询结果中的位置(即结果的紧凑性)及结果的大小(高度)等.文献[24]基于文献[23]的工作,考虑了多个结点之间及多个值之间的关键字和结构信息来推断用户的查询意图.但文献[24]排序的对象不是查询结果,而是返回结果类型.5.4其它方法文献[35]基于图模型数据,提出了一种结合结表2XML关键字结果排序策略(高度表示根结点到叶子的路径长度,宽度表示关键字之间的距离)方法XKeyword[32]XRank[25]XSEarch[1]Fragment[40]RSV[39]SAIL[30]CLCA[37]XReal[23]XBridge[24]EASE[36]ISO&IRO[38]BLINKS[35]6高效算法6.1基于树模型的查询算法基于树模型的查询语义都是基于LCA提出构大小、PageRank以及TFIDF这3种排序思想的混合排序机制.假定查询Q={k1,k2,…,km},结果T=〈r,{n1,…,nm}〉,其中r是根结点,n1到nm是包含关键字的m个结点.则T和Q的相关性评分S(T)的计算方法如式(11)所示.式(11)中等号右边第1部分表示根结点的重要性,用基于PageRank思想的方法计算,第2部分表示每个包含关键字的结点相对于关键字的重要性,用基于TFIDF的方法计算,第3部分用于衡量查询结果的紧凑性,考虑的因素包括从根结点到包含关键字的结点之间的路径长度以及图中结点的出入度等.S(T)=(α珚Sr(T)+β珚Sn(T)+γ珚Sp(T))-1(11)除了以上介绍的代表性工作以外,还有大量工作都是基于TFIDF思想进行排序,如对图数据查询结果进行排序的EASE[36]以及文献[39]提出的可配置参数的排序方法等.总体来看,除了XRank,大多数方法在进行结果排序时,都是改进TFIDF的计算方法,通过综合考虑结果大小、关键字的出现频率等信息,使之更能反映查询和结果的相关性.随着研究的深入,越来越多影响结果排序的因素被考虑在内,如表2所示.从实际应用的角度来看,排序效果的好坏除了受所考虑因素多少的影响之外,不同因素所占权重也在很大程度上影响排序结果的准确性.XReal是最近提出的方法,通过统计获取关键字的分布信息,进而利用这些信息推断用户的查询意图,可以在很大程度上提高系统的推荐准确性.■■△的,如何高效计算两个结点的LCA是其中的核心问题.为此,大多数方法需要使用路径编码.本节我们首先介绍已有方法所使用的编码方案,然后介绍两类典型算法:(1)基于归并连接(Merge-Join)的方法.(2)基于索引连接(Index-Join)的方法.Page106.1.1路径编码Dewey编码[41]方案为每个元素结点设定的编码由该元素的父结点编码和该元素的局部顺序值组成.如图9中每个结点右边第一行所示,对一个元素结点e来说,Dewey编码是由“.”分隔的数字串,其中最后一个数字表示e的局部顺序值,该值表示e在其父结点的所有孩子中自左至右的顺序,最后一个数字之前的数字串表示e的父结点的编码.图9展示了一个XML文档D3及其结点编码,左上角是D3的DTD.图中每个结点右边第1行的编码是通常使用的Dewey编码[41],第2行编码是文献[42]提出的扩展Dewey(ExtendedDewey)编码,第3行带下划线的编码是文献[43]提出的JDewey编码.6.1.2查询处理思路为了处理给定的关键字查询Q={k1,k2,…,km},现有方法需要为每个关键字ki构建包含元素编码的倒排表Li.假设给定查询为Q1={k1,k2},则基于D3的Dewey编码倒排表内容为L1={0.0.1.0,0.2,0.3.0.0},L2={0.0.0,0.0.1.1,0.1,0.3.0.0}.已有方法使用B+树存储倒排表中的编码.查询处理的基本思路可以概括为以下两步:(1)定位每个关键字对应的倒排表Li;(2)在m个倒排表中定位满足语义要求的结果.现有方法在进行第2步处理时,本质上是采用基于连接(join)的方法,通过计算多个Dewey编码的公共前缀来找到包含所有关键字的结点.现有方法通过改编关系数据库中的归并连接(Merge-Join)和索引连接(Index-Join)来处理所有的Dewey编码.归并连接算法以从小到大的顺序扫描m个倒排表中的所有编码,通过使用栈来计算多个编码对应的包含所有关键字的最长公共前缀.和归并连接不同,索引连接算法的提出基于以下观察:假设v是包含某个关键字的结点,w是距离v最近的包含其它关键字的结点,u是v和w的LCA,则任何包含v的ELCA或者SLCA结点都不可能是u的后代结点.因此索引连接算法通过使用v的编码在其它关键字对应的倒排表中查找距离其最近的编码,从而可以避免处理很多无用编码,进而提升算法性能.以下内容中,我们将从这两个方面介绍几种典型算法.6.1.3归并连接算法DIL[25]算法.DIL算法中,关键字ki对应的倒排表中每个元素是一个三元组〈DID,ER,PL〉,其中DID表示直接包含ki的结点ni的Dewey编码,ER表示根据式(5)得到的ni的全局重要性,PL表示ki在ni中的相对位置列表,所有三元组按照DID升序为序,简单起见,后续的例子仅包含DID和ER,不包含PL.除倒排表外,DIL算法还需要维护两个数据结构:栈和堆.栈用于求解满足语义的结果,堆用于保存Top-K结果.DIL的求解过程可以简单描述为:以从小到大的顺序一次性扫描关键字对应的倒排表中的所有元素,每当碰到一个满足条件的结果,将其放入结果堆中,等所有元素处理完毕,输出堆中的结果即为Top-K查询结果.假设给定查询Q1={k1,k2},其倒排表中的内容如图10中L1和L2所示,图10栈中每个元素是(n+2)元组〈N,ER[1],ER[2],ContainsAll〉,这里n为给定查询中关键字的个数,对于Q1来说是四元组,其中N表示Dewey编码的一个分量,所有栈元素中的N自栈底到栈顶表示一个Dewey编码DID,ER[1]表示k1对应的编码评分(ElementRank),ER[2]表示k2对应的编码的评分,Contain-sAll表示该编码对应的结点是否包含所有关键字.DIL首先处理〈0.0.0,85〉,状态如图10(a)所示.接下来处理〈0.0.1.0,32〉,状态如图10(b)所示,注意从(a)~(b)的过程中,首先将图10(a)中的栈顶元素弹出,然后将85根据衰减规则得到77后向下传递给0.0.由于0.0是0.0.1.0的前缀,因此不再继续弹出栈顶元素,然后将0.0.1.0中的1和0对应的元素压入栈顶,得到图10(b)的状态.然后处理〈0.0.1.1,93〉,和上一步类似,首先弹出(b)中的栈顶元素,然后将其衰减值28传递给栈顶元素,最后将0.0.1.1中最后一个1对应的元素压入栈顶,状态如图10(c)所示.接下来处理〈0.2,21〉,当弹出图10(c)中的栈顶元素后,状态如图10(d)所Page11示,表示0.0.1对应的结点b1包含了所有关键字,因此是一个满足条件的结果,随后b1被放入结果堆中.需要注意的是当发现0.0.1满足条件后,其ER[i]中的值不再向下传递.后续的处理类似,这里不再赘述.需要注意的是,该算法虽然在文献[25]中用来求解ELCA结点,但同样可用于求解SLCA结点.文献[26]直接处理最短的倒排表,首先生成一组ELCA候选结果,然后检查候选结果中满足条件的结果,从而可以避免DIL算法扫描倒排表中所有元素的问题.文献[44]进一步通过引入Hash计数的方法降低了算法的时间复杂度.6.1.4索引连接算法IL算法[27].对于求解满足SLCA语义的结果,文献[27]注意到SLCA的个数最多等于包含元素最少的倒排表的长度,例如给定两个关键字k1、k2以及包含k1的结点v,计算包含k1和k2的SLCA结点时,无需扫描k2对应的倒排表L2中的所有元素.相反,只需要从L2中找小于v编码的最大编码和大于v编码的最小编码,然后确定哪个编码能与v得到SLCA结点即可,因此文献[27]将包含结点Dewey编码的倒排表用B+树进行组织,通过索引查找的方式加速算法的执行.显然,该方法只有在至少一个倒排表很短时才比较高效.IMS算法[45].当查询包含多个关键字时,IL算法首先从两个倒排表中取两个结点计算其LCA,然后将该结果与第3个倒排表中的结点进行比较,这种方法即使在结果很少的情况下,也可能在求解的过程中产生大量不必要的中间结果.例如,对于图11所示的文档D4而言,查询{a,b}对应的SLCA集合是{x1,x2,…,x10},由于a对应的倒排表小于b对应的倒排表,已有方法会枚举每个a来计算可能的SLCA集合.很明显,这种方法会造成很多冗余计算.例如,a1~a100之间的所有结点和b1计算得到的SLCA结果都是x1.基于以上观察,文献[45]提出了一种计算SLCA结果的高效算法MS(Multiway-SLCA).MS在计算SLCA集合时,每一步并非计算两个结点的SLCA,而是基于锚点(AnchorNode),每一步从所有关键字倒排表中取一个结点计算该组结点的LCA,然后比较前一步得到的LCA和当前LCA的关系来确定前者是否为SLCA.基于JDewey的算法[43].文献[43]提出了一种JDewey编码,用来高效计算ELCA和SLCA结果.如图9中带下划线的编码所示,每层①结点的JDewey编码在该层的分量具有唯一性,即层数和一个数字可以唯一确定一个结点,而Dewey编码需要所有数字分量组合起来才能唯一确定一个结点.JDewey编码的另一个特性是:对于两个同层结点v1和v2来说,如果v2的该层分量大于v1在该层的分量,则v2的所有孩子结点对应的层分量大于v1的所有孩子对应的层分量.基于JDewey编码,求结点间的LCA时,无需进行最长公共前缀的匹配操作.对于给定的两个结点v1、v2及其JDewey编码l1和l2,l(i)表示编码l中第i层的分量.如果存在一个最大的i值使得l1(i)=l2(i),则可以确定第i层的结点N是v1和v2的LCA.由于JDewey编码通过层数和一个分量可以唯一确定一个结点,因此,可将JDewey编码按照不同层次分别进行存储,这和列存储的概念相同,可以在查询处理时提升系统的性能.6.1.5其它方法针对XSEarch[1]的结果中除了直接包含关键字的结点名字可以相同外,其它结点对不能出现同名的情况,XSEarch使用路径索引来解决该问题.文献[29]针对XSEarch计算互连关系效率低的问题,提出MDC编码来快速推断给定结点的祖先结点名称,针对图9中的文档,其每个结点的MDC编码如结点右侧第2行部分所示.除了得到所有满足条件的结果,实际中,还有很多工作着眼于得到和给定查询最相关的前Top-K个结果.从6.1.3节的介绍可知,DIL算法需要等到①层的概念和树中层的概念相同,根结点是第1层,依此类推.Page12所有元素都处理完毕后才能得到Top-K结果.为了高效处理Top-K查询,文献[25]进一步提出了RDIL算法,该算法和DIL的区别在于:倒排表中元素的排序方式不再是按照编码大小排序,而是按照元素的评分值排序.同时还将每个关键字对应的倒排表用一个独立的B+树进行组织,用来快速定位结点.基于该数据结构,RDIL使用扩展的TA算法来快速求解Top-K结果.虽然RDIL在某些情况下可以快速得到所需的结果,但当所有的倒排表大小相近时,RDIL仍需多次查找倒排表,从而造成较大的CPU和磁盘I/O开销.基于此,文献[25]进一步提出了结合DIL和RDIL的混合式查询算法HDIL,用以最大程度发挥DIL和RDIL的优势,避免其极端情况下的低效问题.对于MLCA语义,文献[28]使用区间编码和栈,通过一遍扫描倒排表中的元素来计算满足MLCA语义的结果.以上讨论的方法都是基于路径编码进行处理,文献[46]通过物化视图的方式高效地计算基于SLCA语义的关键字查询结果.6.2基于图模型的查询算法6.2.1基于模式图的方法XKeyword[32]首先根据模式信息对XML文档进行分割,然后存入关系数据库并构建索引.查询处理时,首先根据给定的关键字从模式图上得到所有的候选网络,即结构化查询表达式,然后基于关系查询引擎得到满足条件的结果.文献[2]也是基于模式图,首先得到给定关键字对应的一组结构化查询表语义算法数据模型表3XML关键字查询算法特点比较ELCASLCA△◆△◆△◆面.编码策略一列中的数字代表的含义为:①Dewey.②MDC.③JDewey.④区间编码,其它参数见6.3节的描述.MLCAMLCAS[28]√VLCAVLCAStack[29]√注:其中k表示结果数量.由于倒排索引一般都用Hash表组织,这里不再单独列出.Hash表一列的值表示对应文献中Hash还用于其它方需要注意的是,这些算法的效率和所用的数据集并无直接的关系,而是和被处理的倒排表中关键字的分布情况相关.为了验证这些方法的特点,我们实现了所有SLCA和ELCA相关算法,并在文献[47]达式,然后分别处理得到最终的结果.文献[34]考虑到文献[32]在求解候选网络时代价高的问题,提出了一种比模式图更紧凑的实体图来得到给定关键字对应的结构化查询,然后基于实体图提出了实体路径索引和部分路径索引来加速查询处理.6.2.2基于数据图的方法文献[35]提出了一种双层索引来加速有向图上关键字查询处理的效率,其索引的对象包括基于关键字的倒排表以及从结点到关键字的最短路径.文献[36]提出的倒排索引和传统的索引不同,该索引的key是关键字对,而被索引的对象是包含该关键字对的最大r半径图(r-radiusgraphs)以及相应的评分.文献[38]维护了两个索引,分别是基于关键字的倒排索引和对象间的链接表,用于存储有逻辑链接关系的对象对.6.3性能比较假设给定文档的最大深度为d,给定的查询为Q={k1,k2,…,km},ki对应的倒排表为Li,文档中的结点数量为n.不失一般性,假定L1最短,Lm最长.现有方法在求解满足条件的结果时,需要两种基本操作:(1)比较两个编码的大小,代价为O(d).(2)在B+树中查找匹配编码,代价为O(dlog|Lm|).如表3所示,由于DIL算法需要扫描所有编码,每次扫描一个编码的代价为O(dm),其时间复杂度为O(md∑m的时间复杂度均为O(md|L1|log|Lm|).对于ELCA语义来说,HC算法通过使用Hash计数器来降低算法的时间复杂度,是一种空间换时间的方法.数据结构的实验部分进行了详细比较,感兴趣的读者可以参阅文献[47]获取详细的比较和分析.这里仅给出不同方法的特点供读者参考.从实现的角度看,DIL的性能和需要处理的编Page13码数量成正比,多数情况下性能较低;IL相对简单,且在多数情况下可以获得较好的性能;IMS在通常情况下可以跳过更多的元素,但当查询结果较多时,其性能反而不如IL高效;JDewey[43]虽然连接操作的代价较低,其最大问题在于当从较低层次发现一个结果后,从高层倒排表中删除祖先结点的代价很高,且层次越高,执行删除操作的代价越高,当查询结果多时,执行删除操作的代价会极大影响系统的整体效率.7结果展示7.1基于树模型的查询结果展示7.1.1基于元组的结果展示方式该方式仅返回和关键字相关的信息.对于给定的关键字查询Q={k1,k2,…,kn}来说,XSEarch[1]的查询结果是一个n元组N=〈v1,v2,…,vn〉,其中ni(1in)是直接包含ki的结点且N中的结点满足all语义①.VLCA[29]和XSEarch[1]的区别在于返回结果中多了一个根结点,即对于查询Q来说,返回结果的形式为(r;l(v1):c1,l(v2):c2,…,l(vn):cn),其中r是v1,v2,…,vn的VLCA结点;ci是vi包含的值结点.7.1.2基于完整子树的结果展示方式该方式展示以某个结点为根的整个子树.如XRank[25]和XKSearch[27]的返回结果分别是ELCA和SLCA结点.在此基础上,XRank还支持用户查看以ELCA为根的子树内容.XReal[23]首先判断哪种类型的结点和用户的查询相符,然后返回以该类型结点为根的子树.7.1.3基于路径子树的结果展示方式该方式返回的是从LCA结点到关键字的路径所构成的子树.和第2种结果展示方式相比,该方式去除了子树中不包含关键字的结点.在此基础上,现有方法根据路径子树中结点所包含的关键字集合的包含关系又进一步分为3种结果展示方式:(1)包含所有路径的子树.(2)满足单调性和一致性的子树.(3)满足单调性和一致性且去除冗余信息的子树.包含所有路径的子树.文献[48-49]将XML文档中的元素分为实体结点、属性结点及连接结点,基于此,提出了推断关键字角色的规则,即相对于XQuery表达式来说,该关键字相当于where子句中的谓词还是return语句中的返回表达式,进而提出了推断用户查询意图的规则,最后基于实体展示结果.例如,对查询Q3={Mike}来说,图12中包含“Mike”的最低实体是编码为0.0的author,文献[48]为用户展示的结果如图13的r1所示.再如对查询Q4={Mike,XML}来说,文献[48]为用户展示的结果如图13的r2所示.注意,两个结果中都有指向未展示内容的链接,如图13中的“+”结点所示,用户可以通过点击链接浏览其内容.图12XML文档D5,带下划线的结点是实体该类工作中,SAIL[30]返回的最小代价树MCT由某个结点n和它所对应的所有关键结点的关键路径构成.文献[37]返回的紧凑连接树CCTree(CompactConnectedTree)由CLCA结点n和从n到和其对应的关键字的路径构成.满足单调性和一致性的子树.文献[50]通过分析基于文本数据的关键字检索的特点,提出XML关键字查询技术应该满足的两个重要属性,即单调性(Monotonicity)和一致性(Consistency).基于单调性和一致性的约束,文献[50]在展示结果时,仅为用户呈现从SLCA结点到各个相关匹配(定义见文献[50])构成的子树,对于查询Q3和Q4来说,返回的结果如图13中的阴影部分所示.①为了简单起见,这里的查询没有使用XSEarch中“label:Page14满足单调性和一致性且去除冗余信息的子树.虽然文献[50]提出的方法满足单调性和一致性的要求,文献[51]通过分析发现,基于文献[50]的方法得到的结果中,仍然存在冗余数据.文献[51]针对文献[50]可能丢失有用结果且在返回的结果中可能包含无用信息的问题,基于有效贡献者(ValidContributor)的概念来判断以LCA为根的子树中哪些是有用结点,并在删除无用结点后返回从LCA结点到各个关键字构成的子树,该方法的返回结果也满足一致性和单调性的要求.7.2基于图模型的查询结果展示基于图模型的结果展示工作中,基本语义是包含所有关键字的互连网络.根据对结果中结点和边的处理方式,可以分为3类工作:(1)基本互连网络.(2)互连实体网络.(3)Steiner图.基本互连网络.XKeyword[32]是该类工作的典型代表,其返回结果中每对结点间最多有一条边相连,展示时,根据结果的结构相似性对同构结果进行聚类,以便用户快速浏览所有可能的结果并定位自身感兴趣的结果集.互连实体网络.文献[34]的返回结果是基于实体语义的连接网络,表现在语义上是实体间的关系,表现在结构上,和文献[32]相比,除了某些实体结点外,其它结点被删除后,该结果不再连通.Steiner图.为了最大限度保留结点间的多种连接方式,文献[36]返回的结果中任意两个结点间保留了其在数据图中的所有边,以便用户理解结果语义.7.3其它结果展示方式文献[52-53]提出了对XML关键字查询结果进行区分的方法,该方法在查询结果过大时,可以对结果进行合理的概括,用以协助用户理解某个查询结果的特点.与此相对应,文献[54]提出了一种对查询结果间的差异性进行量化的机制来减轻用户主观判断结果相关性的负担.文献[55-56]通过使用相关反馈的方式来对查询结果进行过滤.8相关系统研究者通过开发原型系统,对所提出的想法进行验证,极大促进了新技术的发展.下面我们根据已有原型系统的特点进行分类阐述.8.1查询生成相关的系统FRISK[10]基于文献[9]提出的识别查询中无意义的关键字、修正错误拼写的关键字、识别有效的短语以及从文本中提取有效关键字的查询清洗技术,为用户展示高质量的查询清洗结果.文献[15]为用户实时推荐近似的URL,其功能通过Firefox的插件来展示.Yahoo!Finance①支持模糊匹配的功能,根据用户的输入实时推荐相关的单词和短语来协助用户构造查询.Tastier[19-20]和InteractiveSearch[21]②基于关系数据,为用户实时推荐与输入关键字匹配的结果,同时该系统支持模糊匹配的功能.Seaform[22]在查询表格中键入关键字,实时给出精确匹配的查询结果.与Tastier和InteractiveSearch相比,Seaform可以根据不同属性指定关键字,增加了约束条件,提高了实时推荐的准确性,同时Seaform还可以对结果按照特定属性进行聚类展示,以方便用户浏览.INK[18]基于XML数据,可以针对关键字进行准确匹配,实时展示查询结果.8.2查询处理相关的系统8.2.1基于树模型的系统XSEarch[1]主要展示“label:keyword”方式的查询接口和基于TFIDF的思想计算Top-K查询结果.XRank[25]为用户展示基于PageRank思想排序后满足ELCA语义的查询结果.EXTRUCT[57]展示基于文献[58]提出的NTC(NormalizedTotalCorrelation)和NTPC(Normal-izedTermPresenceCorrelation)来提升查询结果的准确率和召回率.XReal[59]主要展示如何推断用户的查询意图.针对用户提交的关键字查询,系统首先推断用户的查询意图并返回相应的结果.用户可以从中选择符合自身查询意图的结果进行反馈,之后XReal根据用户选定结果的特点为用户返回高质量的结果.同时,XReal允许用户配置排序参数.Timber[60]是最早开发的原型系统之一,目前支持嵌入MLCA[28]和MSP语义[2]的XQuery查询.TopX[61]是一个基于文本和半结构化数据的Top-K查询引擎,可以有效地支持基于结构和内容的模糊查询,并提供反馈机制来对查询结果进行过滤.8.2.2基于图模型的系统XKeyword[32]针对图模型数据,基于关系存储,为用户展示聚簇后的查询结果.EASE[62]基于图模型数据,展示了如何以统一的方式查询异构文本、关①②Page15系以及XML数据的问题,其查询语义和排序策略来自于文献[36].8.3结果展示相关的原型系统XSeek[63]通过推断用户的查询意图,基于实体来展示结果.目前,XSeek支持文献[50]提出的结果生成策略.TargetSearch[64]能自动识别查询目标并组合出相应的查询结果,这些查询结果满足文中提出的原子性和完整性(atomicityandintactness)要求.eXtract[65]展示了如何根据文献[52]提出的结果特征抽取策略对查询结果进行概括,以方便用户理解返回结果的意义.XSACT[66]主要基于文献[54]提出的结果比较策略为用户展现不同结果的差异性.8.4其它相关系统虽然和XML关键字查询相关的技术已经得到了深入的研究,并产生了一大批具有代表性的原型系统,但都没有进入实际应用领域.目前工业界广泛使用的数据库系统,如Oracle,DB2及SQLServer等,在对关键字查询的支持方面,都停留在对基于关系数据的关键字查询的处理,均不支持基于XML数据的关键字查询,一种简单的方法是通过支持XQuery的contains函数实现,如“//chapter[con-tains(.,‘XML’)]”,但这种方式本质上是文本检索,没有考虑XML数据的内在结构信息.在基于XML数据的开源数据库方面,Timber和TopX如前所述.其它开源系统,如BaseX①、eXist②及dbXML③等对于XML关键字查询的支持都是通过支持XQuery的contains函数来实现,并非真正意义上的XML关键字查询处理系统.9研究展望通过以上内容的分析可知,自从XML出现以来,针对XML关键字查询技术的研究就一直没有停止过,本文所述工作仅仅是其中的一部分,还有很多未提及的工作,如INEXWorkshop上的工作、各大会议的Workshop等.国内的研究[15-16,18-23,29-30,34,36-38,62,67]也一直没有间断.这些工作为XML数据管理技术的研究与发展做出了重大的贡献,极大地增强了用户查询和利用XML数据的能力,但是就XML关键字查询而言,存在的问题依然很多.从当前技术发展和现实应用的角度来看,有效性和高效性是XML关键字查询处理系统最终追求的目标,两者缺一不可.有效性也指易用性,体现在如下几点:(1)查询输入时,系统应该能够为用户反馈和当前输入信息相关的信息,以便用户轻松构造查询.(2)每个返回结果本身所包含的语义信息可以解释其包含的关键字之间的关系,以便用户能够轻易理解返回结果所传达的信息.(3)系统能够通过用户提交的关键字信息推断用户的查询意图,以便为用户返回满足其查询意图的结果.(4)当返回结果和用户的查询意图存在偏差时,系统应该提供可行的方式对返回结果进行汇总、过滤或者依照不同的标准对结果进行聚类.有效性的缺失意味着系统可能无法协助用户构造查询、返回结果不符合用户的查询意图或不可解释、没有相应的对结果进行归纳和概括的功能,这将直接造成系统用户的流失,影响系统的应用效果.高效性指查询处理的效率.对于XML关键字查询处理系统而言,高效性和有效性同等重要,这一点对基于Web服务环境中的应用而言尤其重要,这时系统需要响应大量用户的查询请求并提供实时反馈.高效性缺失的直接后果是系统无法真正应用于实际中服务用户.下面进行具体阐述.9.1有效性9.1.1有效的查询生成技术问题:如何确定“相关”词汇和短语.文献[68]为用户推荐的关键词仅限于在查询结果中经常出现的高频词.实际应用中,用户需要的可能恰恰是具有代表性的低频词.如何发现具有代表性的词汇,而不单单是用出现频率的高低来衡量相关性是要解决的关键问题,其核心是如何划定相关性计算的范围.如果将没有意义的查询结果中包含的信息也考虑在内,则相关性计算的效果难以保证.同时,XML数据的层次结构特点将为排除不相关信息带来新的挑战.9.1.2有效的查询语义问题1:如何确定“实体”.众所周知,关系数据库中关系的基本组成单位是元组,因此很自然的,基于关系数据库的关键字查询语义是以元组为基本单位的连通网络.一个元组代表一个现实世界中的实体对象,可以表达完整的语义信息,而关系数据库中的元组和XML文档中的元素并非等价的语义单元.已有的各种XML关键字查询语义以元素作为基本语义单元,这导致很多情况下,无法解释基于已有语义的XML关键字查询结果.相反,如果可以有①②③Page16效获取实体信息,并返回基于实体或者实体间关系的结果,则可有效提升现有语义的表达能力.目前为止,还没有一种方法能够在不用人工干预的情况下准确识别实体信息.问题2:如何扩展XML关键字查询的表达能力.目前的XSD支持数据类型的定义,当XML文档的XSD可用时,如果能在关键字查询中选择性的附加谓词信息,可有效提升关键字查询的语义表达能力.例如,从DBLP数据库中“找Mike发表于2002年以后的文章”.同时,当数据库中大部分数据在某个属性上具有相同的属性值,仅有少部分数据具有区别于大多数数据的属性值时,用户需要使用不等于语义.例如,用户可能想了解NBA球员中非美国籍的球员都有谁;或者想了解在某个单位,除了汉族,谁是少数民族等等.如果没有简单谓词的协助,已有的关键字查询语义无法准确表达以上的查询需求.这种附加约束条件的匹配操作依赖于相关属性的类型和语义.9.1.3有效的排序机制已有排序方法在进行结果排序时,考虑了:(1)元素之间的超链接;(2)祖先结点到后代结点的链接;(3)后代结点到祖先结点的链接;(4)单词的统计信息;(5)结果的结构信息.虽然这些工作取得了很大进展,实际的应用效果仍有值得改进的空间.问题1:考虑结点权重的排序机制.基于关系数据的评测表明,结点权重会在很大程度上影响结果的排序质量[69].目前仅有文献[67]讨论了如何对XML数据中的结点名称设定权重.未来的排序机制应能体现权重对于结果排序的影响.问题2:个性化的排序机制.数据是客观存在的,而用户的需求是个性化的.已有工作很少根据用户需求来提高检索结果的质量.虽然信息检索领域有很多成功经验可以借鉴,例如,通过分析查询日志和用户的点击流,系统可以返回个性化的查询结果;迄今为止,在XML关键字查询结果的排序问题上,支持个性化排序机制的工作还没有,其难点在于进行个性化排序操作时,考虑哪些影响排序结果的因素,这些因素的权重如何确定,如何评定结果排序的质量等.问题3:不确定性XML数据的结果排序.大规模使用精确数据的时代已经过去,大多数应用都面临如何有效处理不确定性数据的困扰.数据的不确定性要求能够对结果进行有效的排序,支持Top-K查询是处理这些数据的本质需求.虽然Top-K查询处理机制已经得到了深入的研究,但对于不确定XML数据所增加的额外选项来说,研究还远远不够.9.1.4有效的结果展示功能动态facetsearch指对结果不按事先设定的属性进行聚类,而是将结果根据有代表性的特征动态组合,以便用户快速定位感兴趣的结果.系统在展示结果时,提供动态facetsearch功能可有效协助用户从大量返回结果中定位所需信息,增强系统的易用性.已有的研究主要集中在对查询结果以某种方式进行聚类或者提供facetsearch的能力.这些方法所依赖的聚类或者facetsearch的属性都是预先设定好的.很多时候,用户依然无法有效定位所需信息.以DBLP为例,如果用户想了解和XML关键字查询相关的文章,可在DBLP提供的facetsearch接口(http://dblp.l3s.de/?q=&newQuery=yes&resTableName=query_resultGGjnfG)中输入“XMLkeywordsearch”进行查询,结果显示,只有32个结果(注:查询时间为2010年11月18日),这显然远远少于DBLP中收录的有关XML关键字查询的文章数量.为了得到更多的结果,再次输入“XMLkey-word”,返回结果只有37个;再次放宽查询条件,输入“XML”,发现有1734个结果.显然,要找到所需的文章,用户不得不通过某个属性浏览所有返回结果才能找到和XML关键字查询相关的所有文章.9.2高效性9.2.1可扩展的高效算法高效算法的重要性等同于有效的排序机制,有效的排序机制可以返回用户想要的结果,但高效算法是保证系统可用性的关键,扩展性是系统无法回避的,文献[69]的实验结果表明,面对大规模数据集时,已有基于关系数据的系统在扩展性方面表现不够好,这是至今为止还没有原型系统进入应用领域的重要原因.虽然还没有工作对基于XML数据的关键字查询处理算法的性能进行系统的比较和分析,我们认为,在XML关键字查询处理领域,同样存在类似的问题,尤其是面向Web服务环境中的应用.9.2.2高效的实时结果提示算法为了实时显示和输入关键字相关的结果,研究者已经提出了很多基于磁盘的索引结构和算法[13,70-72].为了获得更好的交互速度,需要在服务器的内存中缓存大量索引和临时查询结果,当数据集增大的时候,内存需求量会急剧增加.和直接返回最终查询结果相比,实时结果提示对算法的高效性提出了更高的要求.目前仅有文献[18]研究了基于Page17ELCA语义的结果提示功能,但提示的是单个ELCA结点,并非具有语义表达能力的数据片段,原因在于已有的数据片段构造方法非常耗时,不能满足在用户输入的同时进行实时结果提示的要求.9.3标准化评测体系信息检索技术的发展已经向我们证明了标准化评价的重要性,这一点可以从TREC①出现以来,查询有效性在6年内提高了一倍②来得到直接证明.INEX③针对基于内容(content-based)的XML检索构建了标准化的评测手段,对基于数据(data-based)的XML检索而言,还没有相应的组织来从事标准化评测体系的构建工作.文献[69]基于相同的数据集和查询对已有的技术进行了测试,结果表明基于相同数据集和查询得到的评测结果比原文章中给出的数据差很多.这可能是因为作者没有在自己的文章中说明测试时的一些调优手段和参数.同样TREC和INEX的评测结果也印证了这一事实,该问题的存在使得读者无法准确比较不同技术的特点.这可能导致在基于数据的XML检索领域,很难取得和信息检索领域以及基于内容的XML检索领域匹配的实用成果.据我们了解,本文提到的原型系统都还没有进入实际应用领域,其中一个潜在的问题是每个系统的评测效果均来自研究者主观认定的评价标准和测试平台.早在2002年,文献[73]就曾提到,针对某类特征的数据设计的检索方法,不应该在其它特征的数据上进行性能比对.正如文献[74]所述,为了评价基于不同结构化数据的关键字查询处理策略的有效性,急需该领域的研究团体一起来构建全面、综合性的标准化评测机制,包括构建标准化的测试数据集和查询.
