Page1主动式三维立体全景视觉传感技术汤一平吴立娟周静恺(浙江工业大学信息工程学院杭州310023)摘要为了使全方位视觉传感器(Omni-DirectionalVisionSensor,ODVS)获取的全景图像上各像素本身具有成像物点的深度信息,文中设计了一种具有单发射中心点(SingleEmissionPoint,SEP)的全景彩色体结构光发生器(PanoramicColorStructuredLightGenerator,PCSLG)以配合具有单视点(SingleViewPoint,SVP)成像特点的ODVS;然后将ODVS和PCSLG垂直配置在同一轴心线上,实现一种主动式立体全景视觉传感器(ActiveStereoOmni-DirectionalVisionSensor,ASODVS);最后根据全景图像上各像素点所带光源的颜色信息,通过颜色识别算法以及ODVS和PCSLG的几何关系推断PCSLG的发射角并估算成像物点的深度值.实验结果表明,该文设计的ASODVS能快速实时进行全景立体图像的特征点实时匹配和空间物点深度的测量,实现了一种以观察者为中心的3D主动立体视觉感知.关键词ODVS;PCSLG;主动立体视觉;颜色识别1引言人类通过视觉感知现实世界,从两眼的视差中感知空间物体的深度.理想的视觉感知装置是要能获得与实际空间物体一一对应的景物深度和色彩对应图的大视野视觉传感器,但是目前的成像技术在获取图像过程中丢失了空间物体的深度信息.而计Page2算机视觉中的立体视觉技术能使机器同人类一样能感知物体的立体信息,因此,立体视觉已成为计算机视觉的一个研究热点,按照是否在场景中投影光源,把立体视觉分为被动式立体视觉技术和主动式立体视觉技术.被动式立体视觉利用人眼双目视差原理,模仿人类利用双目线索感知距离的方法来实现对三维信息的感知.但是被动式立体视觉技术在标定、匹配及重构方面的基础性问题还没有得到很好地解决.为此,许多学者提出了各种主动式立体视觉技术的解决方案[1-11].在主动式立体视觉技术中,通常采用编码后的投影光源来代替被动式立体视觉中的某个摄像机,当目标物体表面被赋予某种光源信息时,通过对投射光源的编码信息的识别,以实现特征点的快速匹配和深度测量.Rioux[1]设计了多种点光源投影的测距仪,实现了对物点的深度信息测量.Oshima和Shirai[2]设计了线结构光测距仪,该测距仪通过向圆柱透镜投射激光来产生线光源,这种线光源在步进电机的匀速转动下能够对物体表面进行扫描,对由这种方式获得的图像进行信息提取并完成深度测量工作.无论是点光源还是线光源,其优点是识别简单,但需要扫描整个场景,实时性不高,不适合大范围的三维测量.Kowarschik等人[3]提出了一种光栅结构光投影法进行三维测量,该方法实现了仅需拍摄一次图像就可以测量较大范围内的深度信息,提高了测量速度;该方法若要提高测量精度,需要增加光栅的密度,但光栅的识别就比较困难.Tajima等人[4]利用彩虹编码结构光,通过识别光源颜色,利用三角测距原理测距,该方法具有能快速获取可见区域深度信息的优点,但其仍是普通视角相机与面结构光的组合,检测场景有限,且需要设计滤波装置.上述几种解决方案主要是针对面成像的立体视觉.在主动式全景立体成像方面,Joung等人[5]提出利用点激光高速旋转形成锥形的激光平面,再通过圆锥形镜面接收全景光源信息,然后通过分析成像平面上的投射光源信息来实现全景三维立体测量.由于激光发散角度小,要形成连续的光源需要高速旋转的机械设备.Orghidan等人[6]提出了一种利用环形激光和圆锥形镜面组合产生“光锥”的方法,该方法能有效的获取全景三维信息,但激光源与镜面之间的组合要求比较苛刻,且由于其传感器设计时采用了抛物面折反射成像,抛物镜面折反射成像虽然有成像算法简单和安装时不要求特殊的几何对应等优点,但是必须采用正交投影镜头的摄像装置(OrthographicCamera),这种摄像装置与一般基于透视的摄像装置有较大的区别,而且正交投影镜头价格昂贵.Yi等人[7]采用线结构光和全方位视觉传感器实现了全景三维测量,由于全方位视觉传感器采用的是抛物镜面折反射成像,仍存在正交投影镜头价格昂贵的问题.接着,Yi等人[8]又提出利用激光和圆柱形透镜来实现全景三维测量,该方法无需利用机械扫描装置就能使大区域内覆盖光源,但圆柱形透镜与激光的组合会大大削弱光能量密度,从而给光源识别带来一定困难.近年来,Kurisu等人[9]采用圆形激光与圆锥形镜组合,并与两个摄像机组合实现了三维地图的构建.Matsui等人[10]利用全方位激光和全景摄像机的组合实现了管道中全景的检测.2012年,Zhang等人[11]提出利用双曲面镜和投影仪的组合设计了一种全方位投影装置,并使之与全方位视觉传感器垂直组合,得到一种全新的3D视觉传感器,可用于行走机器人的导航,但是还属于某一个面上的物点深度检测.综上所述,当前主动全景立体视觉技术最大问题是难以快速直接获取全景空间所有物点的深度信息.既然ODVS是一种体结构式的视觉感知器件,就需要有一种全景彩色体结构光技术与之相对应,这样就能够实时地获得与场景中物体相对应的深度和色彩等信息,本文提出的主动式立体全景视觉感知方式则是围绕着“以观察者为中心”来进行设计的.因此,本文研究的贡献在于能够实时获取与实际物体相对应的深度和色彩全景图像,从视频信号获取源上来解决计算机视觉领域中的准确性、实时性及鲁棒性等方面的问题.主要创新点是:(1)设计了一种单发射点的、具有体结构式的全景彩色结构光发生器(PCSLG),使得被PCSLG照射的三维空间上的所有物点都具备了一种带有特定颜色的空间几何属性;(2)集成单发射点的PCSLG和单视点的ODVS来构建一种ASODVS,通过解析ODVS成像各像素的位置以及颜色特征,根据ASODVS的结构参数等环境条件,使得全景图像中的像素单元均能包含实际景物的深度、方位和色彩信息,最终用一幅全景图像来直接表达三维场景的目标.2ASODVS图1(a)是本文提出的一种ASODVS的成像模型,由ODVS和PCSLG按垂直配置组合而成.其中ODVS是由双曲面镜和CCD摄像头构成,PCSLG由按规则嵌入在圆球外壳上的多组不同发光波长的LED和低速普通旋转电机带动的圆球外壳组合而Page3成.将ODVS的单视点和PCSLG的发光中心配置在同一轴心线上,简化了极线约束.OC即为中央眼(单视点和单发射点连线的中点)到被测物体表面的距离.图1(b)是本文开发ASODVS的原型.式中,R为空间物点C到中央眼O的距离,B为基线距(ODVS的单视点到PCSLG的单发射点之间的距离),α0为空间物点C在ODVS成像平面上的入射角,αp为空间物点C对应在PCSLG上的发射角.根据式(1),要得到空间任一物点的位置信息只需计算出该物点的入射角α0以及对应光源的发射角αp.而任一物点的入射角α0可根据ODVS的全景图上该物点所对应的像素位置以及ODVS的标定结果计算得到;该物点对应光源的发射角αp可根据全景图上物点所带的光源颜色信息计算得到.下面就详细阐述入射角α0和发射角αp的获取方法.2.1ODVS本文采用的ODVS是利用本实验室开发的一种视场范围为120°×360°的ODVS[12].ODVS中的折反射镜面采用双曲镜面,利用双曲镜面单视点的折反射特性[13]来设计单视点的ODVS.关于折反射镜面的设计方法请见文献[14].在设计全方位视觉传感器ODVS的垂直视场范围(VFOV)时,需要与体结构光的发射范围相结合来确定.一般来讲,VFOV的数值越大,得到的全景立体视觉范围也就越大.若要获取全景空间物点的深度等位置信息,首先需要计算物点的入射角α0,这里需对摄像机进行标定,以建立入射角α0与成像平面上像素点的位置关系.ODVS的标定就是以获得成像设备内部的几何以及光学参数和相机在实际场景中的坐标位置为目的的过程,这个过程需要通过确定参考点和它对应的像素点的关系来完成.详细标定算法可以参考文献[15-16].假设值可以通过标定实验求出,ODVS的标定结果见表1.标定精度是根据计算反投影误差得到的[17],即在标定板上手动选取的角点与利用标定所得参数计算反投影到图像平面上的点的像素误差.表1ODVS的标定结果-6.05E-051本文研究的主要目的是实现全景的三维实时感知和重构,因此全景空间各物点的深度信息快速计算是一个关键问题.从三维重构计算角度考虑,本文标定参数α0α2α4ODVS-90.370.0034-0.0000.999-5.22E-05A采用了以中央眼为坐标原点的高斯坐标系,如图1(a)所示,只要获得空间物点的入射角α0和对应光源的发射角αp信息,根据三角测距原理以及基线距B就能快速方便地求得该物点的深度信息,计算公式如式(1)所示.R=Bcos(αp)槡Page42.2全景彩色体结构光发生器PCSLG2.2.1PCSLG的设计彩色体结构光的设计是实现本文提出的主动式三维立体全景视觉传感器的关键技术之一.虽然有关彩色结构光的研究多种多样,有些学者利用颜色来检测物点的三维信息[18-21],但要与本文提出的体结构式的ODVS匹配,需要设计一个全景彩色体结构光发生器.在这里,彩色体结构光的发光器件可以选用发散角小的LED或者激光半导体等器件,激光半导体发光器件具有发散角小的优点,LED具有色彩覆盖面积大的优点.本文产生彩色体结构光的光源是超高亮度LED,设计目标如下:(1)组成结构光的LED光源的投射光的反向延长线必须交于一个点,本文称这个点为单发射点;(2)为了使得彩色光具有体结构,这里要求相同中心波长的LED灯等距离地分布在相同的纬度方向上而相同经度方向上的光源不仅需要等距离排列,其中心波长还需要满足连续变化的条件.设计原理图如图2所示,理论上只要LED的发散角与在经度上相邻的LED之间夹角相同,随着发射角的变化其投射颜色也呈连续变化的趋势,从而使得PCSLG的发射角αp与发射颜色之间成一一对应关系.为了提高在纬度方向上颜色分布的均匀度,本文通过电机驱动旋转圆球面体的方式使得在某一纬度上的PCSLG的投影颜色是连续和一致的.文中设计的PCSLG采用50KTYZ-AC220V6W同步电机来驱动旋转圆球面体,转速为110转/min,基本满足经度上的投影颜色连续性要求.图2所示的圆球面体基板为内部圆球型中空的球体,在基板上按照经度和纬度以均匀的角度排列着几组不同发光中心波长的超高亮度的LED光源,且满足同一纬度上的LED具有相同发光中心波长以及每个LED的发散角与在经度上相邻的LED之间夹角相同等条件,然后通过电机驱动圆球面体旋转以保证PCSLG的投影颜色都与发射角αp之间成一一对应关系.2.2.2PCSLG的标定在式(1)中已经阐明,计算全景空间任一物点的深度信息还需要求得该物点对应光源的发射角αp,由于上述单发射点的PCSLG设计,发射角αp可根据全景图上物点所带的光源颜色信息解析计算得到.本节主要讨论发射角αp与所带光源颜色之间的对应关系.全景彩色体结构光发生器PCSLG标定就是为了获得实际发射颜色和发射角αp之间的对应关系,标定的方法是将PCSLG安置在一个水平面上,然后将PCSLG的光源投射到离PCSLG中心轴相距1米的白色垂直平面上,在白色垂直平面上标有刻度值,如图3(a)所示.标定的刻度见图3(a),每个黑色小格为10cm×10cm,每隔10cm取一个标记点(图中绿色十字叉),计算得到每个标记点实际的发射角;接着通过摄像装置拍摄白色垂直平面成像的彩色图像,如图3(b)所示.为了简化计算,此处不考虑环境光的影响,故实验环境设置在晚上,关闭所有除结构光以外的光源,从而获取标记点的色度值;最后通过彩Page5色光的颜色识别以及固有的几何关系计算得到经度方向上发射颜色和发射角αp之间的对应关系表达式.标定过程中需关闭白平衡,并调整摄像机的参数.标定的结果如表2所示,αp是物点对应光源的发射角(单位:(°)),H是物点对应的发射颜色的色度值(0~360).αp71.268.766.363.961.659.557.4利用MatLab工具将上表的数据进行最小二乘法拟合,得到如图4所示的两者的对应关系图,标定结果得到的关系如式(2)所示.αp=-1.356e-08×H4+9.146e-06×H3-0.001×H2-0.363×H+1.464e+02(2)图4PCSLG的发射颜色与发射角的标定结果2.2.3PCSLG光源颜色的识别要使全景空间物点对应的发射角αp计算准确,必须保证PCSLG的发射光颜色识别准确,这就需要选择一种恰当的颜色模型.通常有计算颜色模型、视觉颜色模型和工业颜色模型三类颜色模型.计算颜色模型多用于颜色的理论研究.常见的有RGB模型、CIELab模型等.视觉颜色模型是指与人眼对颜色感知的视觉模型相似的模型,它主要用于色彩的理解,常见的有HSI模型、HSV模型、HSL模型.本文在描述空间物点的色彩信息方面采用RGB颜色模型,在对PCSLG标定及对PCSLG的发射光颜色识别方面采用HSI颜色模型,据本文作者的另外一项研究结果表明若想使得空间分色算法具有较高识别率,那么使用HIS模型具有较好的效果.HSI模型描述了3个基本特征:色调H、饱和度S、亮度I.其中,色调和饱和度合称为色度,色度可以表示颜色的类别与深浅.通过应用HIS模型,计算机视觉领域的大量算法能方便地分开、相互独立地处理,可以大大简化图像分析和处理的工作量,用H色调分量来表示PCSLG发射光的颜色,受其他干扰的影响较小.PCSLG发射颜色的识别受到自然光引起的饱和现象、光源自身的饱和现象、物体的固有色及其表面属性等因素的影响.需要通过对ODVS和PCSLG进行色度标定,修正并估计耦合性差异对光源颜色识别的影响;通过对物体表面光谱反射率的估计,修正物体固有色对PCSLG光源颜色的影响;通过分离镜面反射成分和漫反射成分来修正高光对PCSLG光源颜色的影响.目前本文的实验研究只考虑在较黑暗的环境中进行,基本上排除了物体的固有色、环境自然光和镜面反射的干扰.这里利用HSI颜色模型中的色度分量进行颜色识别,因为实验中发现,如果有环境光的影响,亮度和饱和度变化较大,色度变化相对较小,故基于色度的判断能很好地表示颜色的类别.但在实际颜色测量过程中除了受到环境自然光干扰外,还受到物体的固有色和镜面反射的干扰,为了排除这些干扰的影响需要采用基于双色反射模型的投射光颜色修正模型进行修正;颜色修正算法框图如图5所示,由于篇幅限制,关于实现方法和实验结果请参考文献[22].2.3主动式全景立体视觉的具体实现ASODVS的设计在前面章节中已经提到,如图1所示,将ODVS与PCSLG在垂直方向上以适合的距离用连接件进行固定,在装配时保证ODVS与PCSLG的轴心线重叠以得到一个ASODVS.ODVS的VFOV和PCSLG的VFOV共同作用的Page6区域就是ASODVS的立体视觉范围.一般来说,为了得到更大的立体视觉范围和更高的检测精度,设计时需要尽可能有效使用ODVS的VFOV和尽可能增大基线距(ODVS的单视点到PCSLG的单发射点之间的距离),然后根据上述约束条件设计PCSLG的VFOV.ASODVS的立体成像原理如图1所示,ODVS与PCSLG的轴心线重叠结构方式能保证PCSLG某一波长光的发射与在ODVS上的折反射光线处于同一极平面上,这种设计方式使得立体视觉中的极线匹配问题得以简化.本文建立的高斯坐标系的坐标原点是在ODVS的单视点与PCSLG的单发射点连线的中点,我们称该点为中央眼(CentralEye),这样任意空间物点A的空间、色彩、时间等信息都能以中央眼为观察点中心,从而用深度、入射角、方位角、色彩和时间(R,φ,β,r,g,b,t)7个参变量来表示,在基线距B确定的情况下,物点的深度信息可以由三角测量原理计算得到,其公式可以用式(1)表示,空间物点相对于中央眼的入射角φ用式(3)表示为了获得成像点的实际色彩(r,g,b)信息,在设计ASODVS中采用分时控制技术,即通过控制LED光源的供电来控制PCSLG的发光.当结构光ON时,计算获得空间某物点的深度R、空间物点相对于中央眼的入射角度φ和方位角度β信息.当结构光OFF时,获取物点的色彩信息(r,g,b).在各个变量中,时间信息t是由微处理器确定的.通过这种方式,能实现在ASODVS中获得与实际物体一一对应的景物深度和色彩对应图的设计目标.为了验证ASODVS的设计思想,本文分别开发和选择了一种视场范围为240°×360°的具有单视点的ODVS(图6(a)所示)和一种发射范围为240°×360°的具有单发射点的PCSLG(图6(b)所示).ODVS中的成像器件选择了分辨率为640×480像素、USB接口的数字式摄像头;ODVS通过USB接口与PC机进行连接,通过PC机中的软件读取ODVS所拍摄的全景视频数据,并对全景图像数据进行图像处理.ODVS通过4根支撑杆与PCSLG进行垂直固定连接,并保证ODVS的轴心线与PCSLG的轴心线重叠.对于PCSLG的实现,在LED的选取上,基于经度方向上发射颜色连续变化的原则,本文采用功率为3W的红色、绿色、蓝色和橙色4种LED光源,基本可满足1m~5m的三维立体测量.由于不同纬度LED具有色光混合区域以及ODVS的成像特性,采用了如图7所示的LED排列方式.本文设计的彩色体结构光从北纬到南纬依次是红色(2号)、蓝色(3号)、绿色(4号)、橙色(5号),遵循波长单调变化的原则,利于实现物点对应光源的发射角与发射颜色的一一对应,便于后续的深度检测计算.3全景空间物点的深度计算与表达3.1全景图像中的三维立体检测针对全景图像中的三维立体信息的检测,本文设计了一种适应于全景视觉的三维立体检测算法.算法的设计思路是在极坐标中对全部像素点进行遍历,如图8(a)所示,全景图像的中心O为极坐标系的原点,从O点引出一条射线OX,像素点的遍历就是沿着射线OX进行的,各像素点的颜色是通过估算PCSLG的发射角αp实现的;接着根据ODVS的标定结果求得不同半径上的像素对应于空间物点的入射角α0;然后用式(1)计算该像素点上成像物点的深度值R,用式(3)计算该像素点上成像物点的相对于中央眼的入射角φ,用全景图上该像素点上成像物点的方位角来设定方位角度β信息;接着以中心点O为旋转中心从极坐标0°~360°以一定的角度步长值顺时针方向旋转射线OX遍历整个全景图像,求得整个全景图像上所有成像物点的深度值R、Page7对应于空间物点的入射角φ和方位角β.其中在极线方向上的色度值变化趋势是大致单调的,如图8(b)所示.算法具体实现步骤如下:算法1.三维立体检测.1.读取全景图像后,以其中心点O作为极坐标系的原点,从O点引出一条射线OX作为极轴;方位角度β作为极角、外径Ro作为极线长度;极角β初始值为0°;2.遍历是从极线与内径Ri相交处开始的,ρ=Ri;3.根据图8所示的PCSLG标定结果,解析像素点的颜色信息,利用式(8)估算PCSLG的发射角αp,接着根据ODVS的标定结果和像素点的坐标值求得对应于空间物点的入射角α0,用式(1)计算该像素点上成像物点的深度值R,用式(3)计算该像素点上成像物点的相对于中央眼的入射角φ,用极角β作为物点的方位角,保存计算数据;4.沿着OX的方向获得相邻像素点的坐标和颜色,ρ=ρ+Δρ,判断该像素点的位置是否满足ρRo;5.如果上述条件不成立,跳转到步3;否则计算β=β+Δβ,接着判断β360°是否成立,当条件成立时检测就结束;否则就跳转到步2.3.2全景空间物点深度信息的表达ASODVS的三维全景测量结果的形象直观表达有助于观察、模拟和计算等各种应用,本文采用科学可视化中的伪彩色图技术.在生成伪彩色图的过程中,需要注意以下两个方面:(1)研究合适的伪彩色编码,实现更符合人眼感知的伪彩色编码方法,最终达到伪彩色图像的实用感和美感的统一;(2)研究深度信息与颜色编码之间的映射关系.由于人的视觉对不同亮度、色度和饱和度相当敏感.如何实现亮度、色度、饱和度与深度的均匀变化是一项关键技术,正确的映射关系可以达到直观清晰地表现场景深度的分布信息.这里选用了一种色度色标,原理同色相环一样,色调值呈单调变化,色标图如图9所示.色度是色彩的相貌,是区分彩色的重要属性,适合人眼视觉感知特性.本文通过深度信息与色标图中颜色的一一映射关系生成深度信息对应的伪彩色图像.上述算法中Δρ和Δβ分别为极线和极角计算步长,计算步长的选取以全景图像的中径处,即Rm=(Ri+Ro)/2处的一个像素单位.另外,在验证系统实验数据时,还对已知实验场景进行了三维点云的重建.生成室内环境三维点云的关键在于得到空间物点的三维坐标,设空间物点为C(x,y,z),该点的深度值为R(即物点到中央眼的距离为R),φ称为该点的空间方位角,β称为点C在全方位图像上的极角.空间物点三维坐标如图10所示,C点的三维坐标可由以下公式求得上述公式中的极角β可以在全方位图像上由简单几何关系求得;而空间方位角φ可由式(3)求得.得到空间三维坐标后,利用OpenGL进行三维点云的重建,详细实现这里不作赘述.4实验研究为了验证ASODVS全景检测系统的有效性,实验设计如下.平面布局图如图11所示,实验环境概况如图12所示.Page8本文设计的ASODVS基线距为71.6cm.实验前,首先将ASODVS放置在实验环境内约中心位置并离地面高度42cm的平台上,在装置周围,以中央眼为中心,在6个极线方向上分别设置障碍物,离中央眼的垂直距离分别为50cm、100cm、130cm、150cm、180cm、200cm,平面图如图11所示;然后将ASODVS的图像采集的分辨率设置为640×480像素;为了进行有效的实验数据的采集,实验前关闭ASODVS自动白平衡功能.在控制ASODVS的色彩输出方面,我们通过控制PCSLG电源的开关来实现全景彩色体结构光的发射与不发射;PC机分别对在仅ASODVS发射光照射情况下以及仅在日光灯照射情况下所获取的全景图像分别进行图像处理;在仅PCSLG发射光照射情况下,如图13(a),检测系统主要进行预处理、入射角计算、投射角与颜色的相互匹配、物点深度信息的计算等;在日光灯光照射情况下,如图13(b)所示,检测系统主要用于获得全景图像中各物点自身的颜色信息.为了避免物体固有色的影响,实验环境中的各障碍物的颜色均为白色或接近于白色.物体固有色的研究以及环境光的影响是今后研究的重点.检测系统采用JAVA语言开发并运行于WindowsXP操作系统.图13在不同光照条件下ASODVS拍摄的全景图像在对空间物点距离测量的实验验证中,本文在被测场景中选取了6个极线方向,在每个极线方向上分别每隔10cm选取被测物点.以图13中的10×10黑色方块作为标识,每次选取黑色方块的角点作为标识点,如图中绿色十字所示,图中被测物点均设置在ASODVS发射光的有效照射区域内.本文在有效测距范围内,来验证ASODVS的检测精度,实验中选取6个极线方向上的一些测量点做如表3的统计.对表3测量结果进行统计,得到平均误差为2.08%,对上述被测物点的误差统计如图14所示.图14实际深度值与深度估计值的误差关系曲线Page9实际深度/cm色度值H入射角αo/(°)投射角αp/(°)深度估计/cm绝对误差误差率/%表3空间物点的测量结果68.062.056.052.050.049.051.0121.0116.0116.0107.0106.0101.5100.5158.0152.0139.0137.0145.0148.0154.0156.0153.0151.0148.0149.0166.5170.0197.0192.0189.0181.0180.0179.0185.0178.5216.0207.0197.0198.0199.0203.0208.053.9053.4055.1758.8370.4377.3588.2256.2360.4263.9368.0070.8675.5481.2846.0446.5460.2764.1071.0889.2491.6852.3753.2463.6166.3375.5487.8889.9351.0963.1364.2667.0668.9982.1790.2785.5965.2765.7971.5175.7978.1678.4495.69对实验进行分析,误差来源主要有以下几个方面:(1)入射角的计算误差.本文采用的ODVS虽然经过标定,但难免会带入一些的标定误差,而且入射角也存在最小分辨率误差.(2)发射角的计算误差.本文的全景彩色体结构光发生器在使用前也经过标定,但在工艺制作上不能保证同一颜色的LED都在同一纬度上,由于制造原因不同方位角的色调和发射角的对应关系不能保证严格一致.的计算过程中带来结构误差.(3)ODVS和PCSLG的轴心线偏离,使得式(1)针对以上几个误差来源,后续研究可以通过以下方法来提高深度计算的精度:对入射角进行补偿.在软件处理程序算法中.(1)采用低噪声设备,或者是将硬件噪声考虑(2)对全方位视觉传感器标定算法进行改进,(3)改进全景彩色体结构光PCSLG制作工艺,使在经度方向上的颜色与投射角能呈现严格的一一对应关系,从而提高投射角的精度.为了更加直观、形象地表现三维全景测量的深度信息,选取了图9所示的色标卡来映射深度信息,因其颜色较丰富,能很好的反应深度的层次感,图15(a)是在晚间无照明情况下采集的带有结构光的全景图,图15(b)是其对应的Bird-view变换图,Page10图15(c)是图15(a)对应的伪彩色图,图15(d)是图15(c)对应的Bird-view图,能较好的反应系统测量深度的有效性.关于Bird-view图的生成算法不是本文的研究重点,这里不再赘述.图15伪彩色全景图像及Bird-view变换图像此外,为更进一步地验证获取的深度信息准确性,这里利用了3.2节中所述的重建空间三维点云的方法来形象直观地表现深度信息.如图16所示,从中可以看出场景的轮廓信息,图中三维点云图有一定程度的旋转.从图中可以看出,虽然测量深度存在着一些误差,但是结果是与实际三维空间完全吻合的.5讨论与总结实验研究表明,本文研制的ASODVS根据全景图像上各像素的颜色信息,通过颜色识别算法以及ODVS和PCSLG的几何关系推断PCSLG的发射角并估算全景空间物点的深度值,其具有较好的测量精度和检测的实时性.基本上实现了设计的目标,能实时获取与实际物体相对应的深度信息和色彩图像信息,使得在ODVS上成像的各像素本身具有所对应物点的深度和色彩信息.本文的特色与创新之处主要体现在:(1)把PCSLG看成是逆向的ODVS,通过单发射点的PCSLG全景彩色体结构光发生技术和单视点的ODVS成像技术的组合实现了一种全新的全景立体视觉获取方法.Page11(2)以观察者为中心来获取实时全景视频图像,能有效减小被监控物体丢失的概率;大仰角双曲面镜和大发射范围彩色体结构光的应用,解决了大范围空间内移动物体的实时跟踪理论和模型问题,能为移动机器人快速避障提供全景视觉解决方案.(3)将立体测量从繁琐的标定、特征提取等步骤中解放出来,使得全景立体摄像测量更加便利和快捷.(4)“以观察者为中心”的高斯球面坐标和数学几何计算方法的应用使得三维场景重构和空间环境的三维测量更容易实现.在今后研究中还有许多问题需要一一解决.首先,目前实验研究中并没有深入研究在全景视觉情况下物体的固有颜色、环境自然光和镜面反射的情况,今后的实验研究需要解决全景视觉情况下的物体的固有色、条件色和光源颜色的快速区分问题,即通过引入基于双色反射模型的投射光颜色修正模型进行修正,具体实现时需要在三维立体检测算法的步3中增加修正模型算法,进一步提高光源颜色检测的准确性和鲁棒性;其次,虽然通过目前采用的PCSLG能推断出发射角αp与H颜色分量的关系,但是在本文实验中所采用ASODVS中的PCSLG并非理想的、与原设计方案完全一致的.今后将采用本文2.2节中描述的PCSLG设计方案制成的器件,使得PCSLG的发射角αp与H颜色分量成一一对应关系,解决PCSLG光源颜色检测的快速性问题.致谢得到了研究所各位同仁的指导和帮助,在此一并表示感谢!
