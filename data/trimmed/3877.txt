Page1S-RAID5:一种适用于顺序数据访问的节能磁盘阵列李元章1)孙志卓1),2)马忠梅1)郑军1)谭毓安1)1)(北京理工大学计算机学院北京100081)2)(德州学院计算机系山东德州253000)摘要磁盘及其冷却系统是现代存储系统中能耗的主体,已有的节能研究主要面向以随机数据访问为主的存储系统,对于广泛存在的以顺序数据访问为主的存储系统,如视频监控、虚拟磁带库(VTL)、连续数据保护(CDP)等,针对该类系统固有访问模式的节能研究较少.为此,提出了适用于顺序数据访问的节能磁盘阵列S-RAID5,采用局部并行策略:阵列中的存储区被分成若干组,组内采用并行访问模式,分组有利于调度部分磁盘运行而其余磁盘待机,组内并行用以提供性能保证.在S-RAID5磁盘阵列中运行磁盘调度算法,辅以合适的Cache策略来过滤少量的随机访问,S-RAID5可获得显著的节能效果.在32路D1标准的视频监控模拟实验中,在满足性能需求、单盘容错的条件下,24小时功耗测量实验表明:S-RAID5的功耗为节能磁盘阵列Hibernator功耗的59%,eRAID功耗的23%,PARAID、GRAID功耗的21%左右.关键词磁盘阵列;节能;顺序数据访问;数据布局;存储系统1引言随着数字信息的爆炸式增长,存储系统的规模日渐增大,其能耗也随之增大,美国2005年全国数据中心的能源费用达到40亿美元[1],而磁盘驱动器是这些存储系统能耗的主体[2],例如在DellPower-Edge6650系统中,磁盘驱动器的能耗占71%,为系统中处理器能耗的18倍[3],因此对存储系统进行节能设计是极其必要的.在大规模存储系统中,为了提高存储的可靠性和改善I/O性能,通常采用独立磁盘冗余阵列(RedundantArraysofIndependentDisks,RAID).RAID把多个磁盘联合起来,形成统一的逻辑存储设备,常用技术有条带化、磁盘镜像和错误修正[4-5].如RAID4、RAID5、RAID6,把数据条带化后,分散存储到阵列中的不同磁盘上以保证并行性,并采用冗余校验,在保证数据可靠性的同时,可获得大容量和高数据传输率[6-7],但是阵列中全部磁盘并行工作也增加了能耗及磁盘损耗.近年来,视频监控(VideoSurveillance)、连续数据保护(ContinuousDataProtection,CDP)、虚拟磁带库(VirtualTapeLibrary,VTL)等存储系统得到广泛应用,这类存储系统的特点是具有海量存储空间,以顺序访问为主,而对随机I/O性能要求较低[8].这类系统称为顺序数据存储系统.与其它存储系统不同,顺序数据存储系统一般对数据传输带宽要求不苛刻,但对数据可靠性、存储空间要求较高.表1给出了一个典型的32路视频监控系统的存储系统参数,工作时间为24h/d×30d,分别采用D1和高清视频数据标准,磁盘容量为2TB,单盘带宽保守估算为10MB/s(顺序数据存储系统中,以顺序访问为主,平均带宽会超过10MB/s).由表1对比得出,即使考虑视频回放、备份恢复等对带宽的额外需求,采用RAID5磁盘阵列时,也存在着严重的性能浪费,同时伴随着严重的能源浪费和磁盘损耗.传输码率/(MB·s-1)视频数据标准D1221111108高清216884840因此,针对该类存储系统的负载特性和访问模式,提出一种适于顺序数据访问的节能磁盘阵列S-RAID5.S-RAID5具备RAID5的冗余校验和存储容量聚合特性,在满足性能需求的前提下,通过降低RAID5的并行性,以实现节能降耗的目的,S-RAID5的特点主要包括以下方面:(1)采用局部并行策略,即把阵列中的磁盘分成若干组,组内采用并行访问模式,分组有利于调度部分磁盘运行而其余磁盘待机,组内并行用以提供性能保证;(2)采用贪婪编址法,即在顺序访问模式下,保证I/O访问在较长时间内分布在部分确定的磁盘上,其它磁盘可以待机且待机时间充分长;(3)通过磁盘节能调度算法,调度磁盘运行或待机,以实现节能的目的.在32路D1标准的视频监控模拟实验中,在满足性能需求、单盘容错的条件下,24h功耗测量实验表明:S-RAID5的冗余磁盘最少,功耗最低,其功耗为节能磁盘阵列Hibernator功耗的59%,eRAID功耗的23%,PARAID、GRAID功耗的21%左右.2相关工作2.1研究现状存储系统节能研究一直是存储领域内的一个热点问题,并取得了一些重要成果.现代磁盘有待机、运行两种工作模式:待机时盘片完全停止转动;运行时盘片全速转动,运行模式又分为读写操作和空转两种状态,读写操作时盘片全速旋转的同时磁头还要进行寻道.不同工作状态下磁盘的能耗不同,如FujitsuMAP3367磁盘[9],见表2.基本的能量控制算法是当磁盘空转时间达到一定值后,就把磁盘转入到低功耗的待机模式,而当请求到来后,磁盘再转入运行模式,称为TPM(Tradi-tionalPowerManagement)算法[10-11].该算法不适合基本RAID.如RAID5把数据条带化后分散存储到不同磁盘上,阵列中磁盘被频繁读写,而无法转入待机模式.Page3Gurumurthi等人[12]提出一种多转速磁盘模型,该模型能够在盘片转动时动态调整转速,并且能够在低速状态下执行读写操作而无须转入到全速状态.Sony公司的开发人员开发出一种2转速的商业磁盘[13],但要切换到待机模式后才能实现转速调整.Carrera等人[14]提出开发动态多转速磁盘,根据工作负载调整转速:当磁盘的工作负载小于低速吞吐量的80%时,转入低速模式,大于该值时,转入高速模式,称该法为LD(LoadDirected)算法.Gurumurthi等人[12]提出DRPM(DynamicRPM)算法,根据平均响应时间和磁盘请求队列的长度来动态调整磁盘的转速.上述的多转速磁盘,仍停留在理论研究阶段,无法应用在实际系统中.基于闪存(Flash)的固态盘(SolidStateDisk,SSD)作为一种新兴的存储介质,相对磁盘最突出的优点是没有机械装置,因而访问延迟小、抗震性强[15].SSD擅长处理随机和小文件负载类型,而磁盘擅长的顺序负载往往具有大数据量的特点.由于容量和单位价格的限制,SSD在海量数据存储中,将更多地作为一种与磁盘互补的介质共同存在.如EDT[16]在基于SSD、SAS、SATA的多层存储结构中,执行动态数据迁移来降低存储能耗,并提供与SAS系统接近或更高的性能.同理,SSD也可以与S-RAID5组成混合存储系统,以进一步优化节能效率和提高性能,这值得进一步研究.Zhu等人[17]设计一种名为Hibernator的节能存储系统,将存储系统划分为若干个不同转速的RAID,动态调整磁盘在不同RAID之间迁移,以实现系统的最小能耗.该方法存在如下不足:磁盘在不同RAID间迁移时,需要重新布局、生成相关RAID中的所有校验块,将增大管理难度和影响性能;每个RAID都需要一个校验盘,磁盘存储空间的利用率低;多转速磁盘未实际应用.Weddle等人[9]提出的PARAID,把存储空间划分为若干个跨越不同磁盘数的逻辑阵列,动态调度不同的逻辑阵列工作可以提供不同的性能,进而实现节能的目的.该方法的不足是:每个逻辑阵列都包含一份完整的存储数据,尽管逻辑阵列之间共享部分数据,仍然浪费较大的存储空间;进行逻辑阵列切换时需要进行数据同步,对于以写数据为主的存储系统,性能将会受到极大影响.Son等人[18]针对科学计算中固定的数据访问模式,优化RAID5中的配置参数,如磁盘个数、条带深度等;MAID使用少量额外磁盘始终运行,作为Cache盘保存经常访问的数据,以减少对后端阵列的访问.PDC方法[19]根据访问频率周期地迁移文件到各个磁盘中,使闲置文件集中到一些磁盘上.Wang等人[20]提出了eRAID模型,利用RAID的冗余特性来重定向I/O请求,eRAID通过停止旋转部分或整个冗余组的磁盘来降低能耗,同时将系统性能的降低控制在一个可接受的范围内.Li等人[21]提出了EERAID模型,将RAID内部的冗余信息、I/O调度策略、阵列控制器级Cache管理策略结合起来,采用NVRAM作为写回Cache来优化写操作.WriteOff-loading方法[22]在多个RAID组成的存储系统中,将要写到待机磁盘上的部分数据重定向到其它RAID中的活动磁盘上,以延长磁盘待机时间,并降低磁盘的启停频率.Pergamum方法[23]针对归档存储系统,在每个节点添加一定量的NVRAM来存储数据签名、元数据以及其它一些较小规模的数据项,从而使延迟写、元数据请求以及磁盘间的数据验证等操作均可以在磁盘处于待机状态下进行.国内方面,谢长生、冯丹等人承担国家自然科学基金重点项目“大规模数据存储系统能耗优化方法的研究”,提出存储系统的能耗优化方法:在部件、节点和系统3个层面都建立电力消耗的测量反馈系统以及相关的调节系统,解决复杂系统自适应动态调度问题.根据节能机制在系统的不同层次的作用范围、效果和成本之间的差异,提出多级、多约束优化融合的方法.毛波[24]提出了一种绿色磁盘阵列GRAID,为RAID10增加了一个日志磁盘,周期性地更新镜像磁盘上的数据,而将两次更新之间的写入数据存放到日志磁盘上和主磁盘上,从而能够关闭所有的镜像磁盘来降低能耗.2.2存在的问题已有的节能研究主要面向以随机访问为主的存储系统,并试图适应各种工作负载,导致难以取得进一步突破.文献[12-14]中,涉及的多转速磁盘,至今没有广泛应用.文献[17,22]中涉及到多组RAID,即把存储系统划分为若干个RAID,其中每个RAID至少需要一个磁盘的空间存储校验信息,存储空间的利用率不高,不适合那些对容量有较高要求的应用,Page4如视频监控、CDP、VTL等.文献[7]中的PARAID,更是以牺牲存储空间的代价来换取节能效果.文献[10,19]根据数据的访问频率,研究节能策略,但在视频监控等系统中,以写操作为主要访问模式,而且访问数据的逻辑地址,在RAID的逻辑空间中基本服从均匀分布,采用这两种方法很难获得理想的节能效果.文献[20-21,24]对基于镜像RAID的存储系统进行了节能研究,镜像RAID同样存在存储空间利用率不高的问题,且最优节能效果小于50%.2.3S-RAID5的主要依据S-RAID5的核心思想是:在满足性能需求的前提下,通过降低RAID5的并行性,即采用局部并行策略,实现节能降耗的目的,主要依据如下:(1)顺序数据存储系统一般对性能要求不高.顺序数据存储系统,如视频监控、CDP、VTL等,其负载主要是顺序I/O流,数据的逻辑地址基本是顺序的,对I/O的并发性要求很低[8],对存储带宽的要求也不苛刻,但对存储空间要求较高.而数据库、联机事务处理(On-LineTransactionProcessing,OLTP)等应用,则要求较高的随机I/O处理能力.(2)单个磁盘的性能得到了显著提高.随着磁盘技术的进步,单个磁盘的性能得到了显著提高,表3列出了2种Seagate磁盘的相关参数[22],这为实现RAID的局部并行提供了性能保证.RAID中部分磁盘并行工作已经能够提供足够的带宽和IOPS.磁盘类型容量/Cheetah10K3008584277256Cheetah15K1468885384269(3)负载特性使局部并行具有可行性.在顺序数据存储系统中,数据的逻辑地址更好地满足存储空间访问的局部性原理,保证了数据访问能够在足够长的时间内,分布在一个或几个确定的存储区域.S-RAID5使这些区域集中在部分磁盘上,并调度这部分磁盘处于运行模式,而其它磁盘则处于低功耗的待机模式.3S-RAID5的实现S-RAID5的实现主要包括:底层数据布局、顶层节能调度算法、Cache管理策略.3.1数据布局设磁盘阵列S-RAID5由N块盘(物理盘或逻辑盘)组成且N3,构成1行×N列矩阵.将阵列划分为N个条带,每个条带包含N个存储块,其中1个校验块,N-1个数据块.为了方便生成冗余校验信息,每个存储块划分若干个存储子块,可根据要求设置子块的大小,典型值如4KB、8KB、16KB等,子块内数据的逻辑地址是顺序的.校验子块由同条带内偏移位置相同的N-1个数据子块异或运算得出.用X(i,j)表示S-RAID5中的一个存储块数据,其中i表示其所在的条带号,j表示所在的磁盘号,X(i,j)位于磁盘j上,0i,j<N.第i条带内的校验块数据用Parity(i)表示,与存储块数据X(i,j)的关系为Parity(i)=X(i,N-1-i).数据块数据用D(i,v)表示,v表示其在所属条带内的数据块序号(忽略校验块),0i,j<N-1,与存储块数据X(i,j)的关系,用式(1)表示:为了能够提供合适的性能,需要对数据块进行分组,方案如下:将每个条带上的N-1个数据块分成P组,每组包含Q个数据块,其中P2,Q1,且满足P·Q=N-1.在各个组内,采用并行数据编址方法,编址单位为数据子块,编址方法如下:设组大小为SGrp,第p组、第i条带、第q数据块内、偏移地址为off的数据子块的逻辑地址LBAp,i,q,off可表示为LBAp,i,q,off=SGrp·(N·p+i)+off·Q+q(2)其中0p<P,0i<N,0q<Q,0off<SGrp.根据式(2)得S-RAID5的数据布局具有如下特征:(1)各组内偏移地址相同的数据子块的逻辑地(2)逻辑相邻的组优先分布在相同或相近的磁盘上.称式(2)表示的编址方法为贪婪编址法.图1给出了5磁盘2分组的S-RAID5的编址示意图,其中D(0,0)、D(0,1)采用并行数据访问机制,D(0,1)与D(1,0)的逻辑地址相邻,依此类推.采用贪婪编址法,可以保证组内局部并行的同时,又使访问在较长时间内分布在部分确定的磁盘上,有利于调度其它磁盘待机,且待机时间充分长,以便获得更好的节能效果.址相邻;Page5在顺序数据访问中,校验数据的更新操作,会触发其它磁盘的状态转换,进而产生额外能耗,但由于S-RAID5的存储块足够大(存储块大小为磁盘容量的1/N),因此校验数据所在磁盘的切换频率很低,该额外能耗可以忽略.例如上述5磁盘2分组的S-RAID5,设磁盘容量为500GB,根据S-RAID5的数据布局划分,可得D(0,0)、D(0,1)及其对应的检验数据块P(0)均为500GB/5=100GB,其中D(0,0)、D(0,1)、P(0)包含若干个子块,以子块为单位进行异或运算生成校验数据(子块类似于RAID5中的Chunk,大小可设置为32KB、64KB等).这样D(0,0)、D(0,1)并行编址后,便可提供200GB存储容量,顺序数据访问时,只有该200GB空间写满后,才会更换校验磁盘,例如停止P(0)所在的磁盘,然后启动P(1)所在的磁盘.以32路D1分辨率(2MB/s)的视频监控为例,每小时产生的视频数据为28.8GB(2MB/s×32×3600/1000),这样写满200GB的空间需要6.9h,即6.9h切换1次校验数据所在磁盘,切换频率非常低,所以由此带来的额外能耗可以忽略.第4章S-RAID5的24h能耗测量结果,可进一步证明该结论.3.2节能磁盘调度算法一般情况下,S-RAID5只需一组或几组磁盘及其校验数据所在磁盘工作,需要调度其余磁盘进入待机状态,以便获得节能效果.为实现节能,需要根据请求队列的历史信息、I/O访问在逻辑空间的分布区域,感知当前负载流的随机性及其时间空间分布特征,从而进行磁盘节能调度算法设计.用r=(tarrive,tfinish,status,pos,len)记录请求队列rq中的1个I/O请求,其中tarrive、tfinish、status、pos、len分别表示请求r的到来时间、完成时间、请求状态、起始逻辑地址和请求长度.请求状态包括等待、执行、完成等状态,请求长度以扇区为单位,用rx表示请求r的参数x.f(rpos),可以按以下方法求出:p、组内块号q及条带号i:由请求r的逻辑地址pos到磁盘号j的映射(1)由pos利用式(3)求出该请求所在的组号(2)根据组号p、组内块号q、条带号i,求出pos指向的数据块数据D(i,p·Q+q);(3)已知D(i,p·Q+q),根据式(1)得pos所在磁盘j=p·Q+q,当i+p·Q+q<N-1;否则j=p·Q+q+1.对请求队列rq中各个I/O请求,根据其逻辑地址所在的磁盘,划分为N个集合:其中0j<N,称Sj为磁盘j的请求集合,用numj表示集合Sj中元素的个数.TPM算法[10-11]虽然不适合基本RAID,但非常适合S-RAID5,这是由顺序数据存储系统的负载特性和S-RAID5的数据布局决定的.TPM算法在S-RAID5中的实现如下:设定磁盘调度的时间阈值tth,系统当前时间为t,如果请求集合Sj中的请求满足式(4),则可以调度对应的磁盘j到待机状态.下次需要访问该磁盘时,再将其调度到运行状态.3.3Cache管理策略顺序数据存储系统以顺序数据访问为主,但还包含一些随机访问,如文件系统元数据、RAID元数据等,随机访问会影响S-RAID5的节能效果,需采取措施过滤对S-RAID5的随机访问.传统的Cache写策略为写回(Write-back)和写透(Write-through)两种,为了获得更优的节能效果,需要特定的Cache策略来过滤随机访问.文献[25]提出的如下两种Cache写策略,同样适合S-RAID5.主动写回(Write-BackwithEagerUpdates,WBEU)策略.当处于停止状态的磁盘因未命中的Page6读操作而转入运行状态时,主动把当前Cache中缓冲的对应数据写入该磁盘.延迟写透(Write-ThroughwithDeferredUp-date,WTDU)策略.采用缓存日志来减少磁盘的启动次数,日志设备可以是NVRAM或固定磁盘,对于少量的随机写操作,可以暂存到日志设备当中,当目标磁盘转入工作状态后,再把日志设备中缓存的写数据同步到该磁盘中.这里给出一种基于统计磁盘数据流量(DataFlowRate,DFR)的WTDU实现方案,根据S-RAID5中各个磁盘的请求集合,由式(5)求出磁盘j的数据流量DFRj为设DFRth为延迟写透的流量阈值,对任意磁盘j,如果其流量DFRj<DFRth,则把该盘的写操作,重定向到当前活动的磁盘上,或把写数据缓存到NVRAM,减少磁盘因少量随机访问进行状态转换的次数.同时,数据流量也可作为磁盘的调度参数,供调度策略选择.3.4读写操作S-RAID5的读操作与RAID5类似,根据映射f(rpos)把读请求r映射到一个分组,并使组内磁盘并行工作,而不需要条带内所有磁盘并行工作.S-RAID5的写操作一般以“读-改-写”为主,因为通常情况下,S-RAID5只有少量磁盘工作.执行写操作时,需要更新对应的校验数据,生成新校验数据需要获得旧数据及旧校验数据,可利用式(6)生成新校验数据.其中,Dsub(k)、Psub分别为组内偏移位置为off的新数据子块数据、其对应的新校验子块数据;Dsub(k)、Psub为旧数据子块数据及旧校验子块数据;m为偏移位置为off的写入数据子块个数.可采用合适的预读策略,改善“读-改-写”对S-RAID5写性能的影响,如把用于生成新校验数据的旧数据、旧校验数据预读到缓存中,以减少读取的次数.4综合测试在Linux2.6内核中MD(MultipleDevicedriver)模块的基础上,实现了S-RAID5的数据布局,设计了一个监控进程Diskpm对磁盘进行节能调度,采用TPM调度算法,tth=120s.修改了MD中的超级块更新程序,使对待机磁盘的超级块更新延迟至该盘的运行状态.4.1实验环境由于S-RAID5主要面向顺序数据访问,因此,性能和节能测试是基于典型的顺序数据存储系统———视频监控进行的.模拟了一个32路视频监控系统,采用D1视频数据标准(平均码率为2MB/s),需要保存24h/d×30d的视频数据,数据量为20.74TB.在存储设备上,每隔指定时间,建立32个视频文件,分别保存该时间段内的各路视频数据,视频数据以添加(append)方式写入视频文件,实验中设定的时间间隔为10min.当存储空间不够时,删除最早存储的视频数据.选取了目前几种典型的RAID节能方法,与S-RAID5进行比较,包括冗余磁盘、性能和节能效果.典型的RAID节能方法包括:文献[17]中的Hibernator,文献[9]中的PARAID,文献[22]中的Writeoff-loading方法,文献[20]中的eRAID、文献[24]中的GRAID.文献[22]中的Writeoff-loading方法,把存储系统划分为若干个RAID,为了比较,选取以下两种划分方式:(1)每个RAID包括1个数据盘和1块校验盘,整个存储系统共分为12个RAID1,记作WOL1;(2)每个RAID包括2个数据盘和1块校验盘,整个存储系统共分为6个RAID5,记作WOL5.其它划分方式,随着RAID内磁盘的增多,其节能效果均小于以上两种方法,不逐一比较.eRAID包括eRAID1和eRAID5,由于eRAID1的节能效果小于GRAID,取GRAID代表eRAID1.综上,与S-RAID5进行比较的节能RAID包括Hibernator、PARAID、WOL1、WOL5、GRAID、eRAID5.功耗测量系统见图2,包括1台运行Linux2.6.26的存储服务器、磁盘阵列(磁盘数由所测试的具体RAID类型决定)、测控计算机、电流表以及电源等部分.存储服务器配置如下:Intel(R)Core(TM)i3-2100CPU,4GB内存,主板型号为ASUSP8B-C/SAS/4L,通过主板集成的LSI2008SAS存储控制器,在背板上扩展出32个盘位,可连接32个SAS/SATA磁盘,选用2TB的希捷ST32000644NS磁盘组成磁盘阵列.利用电流表测量电流,测控计算Page7机负责设定电流采用频率,并在测量结束后读取测量的电流值,电流表通过LAN线与测控计算机相连.磁盘的功率测量见图3,采用GWPPE-3323高精度稳压电源,为磁盘的提供+5V和+12V电压,利用Agilent34410A数字万用表,分别测量并存储其电流值.测控计算机读取电流值,根据电流、电压求出功率值.为了比较,分别把磁盘阵列配置成S-RAID5、Hibernator、PARAID、WOL1、WOL5、GRAID及eRAID5,来保存采集的视频数据,每种配置的测试时间为24h,电流采样频率为5,ChunkSize为64KB.采用NILFS(NewImplementationofaLog-structuredFileSystem)文件系统,NILFS是一种日志结构文件系统(Log-structuredFileSystem),采用顺序写的方式,减少物理磁盘的寻道,非常适合视频监控、CDP等以顺序写操作为主的应用.为了便于管理,把整个存储空间划分为31个逻辑盘,每个逻辑盘上建立1个NILFS文件系统,保存1天的视频监控数据,当第31天数据写满后,删除第1天的监控数据,依此类推,这样存储空间始终保存30天的监控数据.4.2冗余磁盘由于需要保存的数据量为20.74TB,对于容量为2TB的磁盘,需要11块,考虑到文件系统对存储空间的额外消耗,取12块磁盘保存基本数据.为了实现单盘数据容错,对于S-RAID5,需要1块磁盘的空间存储校验信息,所以共需13块磁盘.Hibernator把所有相同转速的磁盘组成1个RAID,由于磁盘有运行和待机两种转速,需要构成2个RAID,分别处于运行和待机状态,数据盘在2个RAID之间动态迁移,所以需要2个磁盘的校验信息,共需14块磁盘.在PARAID中,跨越磁盘数最少的逻辑RAID的节能效果最好,由于每级逻辑RAID都需要保存1份完整的存储数据,因此在最节能逻辑RAID中,需要保存12块磁盘的数据量,加上1块磁盘的校验信息,共需13块磁盘.对于WOL1,每1个数据盘需要1块校验盘,共需24块磁盘.而WOL5,每2块盘的数据量,需要1块盘的校验信息,共需18块磁盘.GRAID是镜像RAID,12块数据盘需要12块校验盘,共需24块磁盘.eRAID5中,12块盘的数据量,需要1块盘的校验信息,所以共需13块磁盘.配置以上不同类型节能RAID所需的磁盘数,见表4.阵列类型S-RAID5HibernatorPARAIDWOL1WOL5GRAIDeRAID5其中S-RAID5、PARAID、eRAID的冗余磁盘数最少,均为1块,而GRAID、WOL1的冗余磁盘数最多,均为12块.以上各RAID均能够实现1块磁盘的容错.对于海量数据存储,尽管目前磁盘的价格已经很低,但冗余磁盘的购置费用仍不可忽视,尤其是基于镜像的磁盘阵列,如GRAID、WOL1的冗余磁盘比S-RAID5多11块,若2TB的希捷ST32000644NS企业级磁盘,每块按1500元计算,约为16500元.4.3犘=12、犙=1分组方式4.3.1性能测试采取D1视频数据标准时,平均码率为2MB/s,Page832路视频数据所需的写带宽仅为2MB/s×32/8=8MB/s.对于以写操作为主的视频监控,通常情况下,进行视频回放的频率是非常低的(一般在视频取证时回放),即使考虑视频回放,带宽的增加也是有限的.首先尝试采用P=12、Q=1分组方式(磁盘阵列分成12组,每组1个磁盘并行)来满足以上的性能需求.如果性能不够,可采用其它分组方式,4.4节将对不同分组方式的性能、节能进行测试.采用P=12、Q=1分组方式时,S-RAID5的数据布局见图4,其中第0组包括数据块D(0,0),D(1,0),…,D(11,0),D(12,0),第1组包括数据块D(0,1),D(1,1),…,D(10,0),D(11,1),D(12,1),依此类推.在该视频监控中,一般只需1组或几组数据所在磁盘工作,其它组磁盘基本没有读写请求,可调度到待机状态,以节省大量能耗.第0组第1组……第10组第11组D(0,0)D(0,1)……D(0,10)D(0,11)P(0)D(1,0)D(1,1)……D(1,10)P(1)D(1,11)D(2,0)D(2,1)……P(2)D(2,10)D(2,11)D(10,0)D(10,1)P(10)……D(10,10)D(10,11)D(11,0)P(11)D(11,1)……D(11,10)D(11,11)P(12)D(12,0)D(12,1)……D(12,10)D(12,11)Disk0Disk1……Disk10Disk11Disk12…………………图413磁盘、12分组的S-RAID5数据布局首先利用测试工具进行性能测试,选取Iozone测量NILFS文件系统下S-RAID5的写性能,采用缓存I/O(fsync)方式,测试结果见图5(a),其中随机写操作的数据传输率最小约为27MB/s,顺序写操作的最小值约为30MB/s.可得无论随机还是顺序写性能,均远大于8MB/s的写性能需求.随机写与顺序写性能接近,是由于NILFS文件系统把随机写,通过地址变换转化成了顺序写.地址变换给NILFS文件系统下的读性能测试带来不便,因为对NILFS文件系统的顺序读,可转换为对磁盘的随机读;对文件系统的随机读,也可能转换为对磁盘的顺序读.读性能主要由磁盘上数据块的地址映射情况决定,没有已经存在的写数据,难以准确测试读性能.为此选用块级测试工具Iometer测试读性能,测试结果见图5(b):顺序读操作的数据传输率高达100MB/s;对于随机读操作,当平均请求长度大于256KB,数据传输率大于18MB/s.NILFS文件系统的地址变换,对读性能的影响可忽略.实际上,在顺序数据存储中,读性能一般会很高,因为读操作大多重复以前的写操作,表现为对磁盘的顺序读.如视频监控中,回放以前记录的视频时,即重复以前的写操作;利用CDP进行数据恢复时,读操作也在重复以前的写操作;其它如备份、归档等,情况与视频监控、CDP类似.图5P=12、Q=1分组时S-RAID5的性能为了进一步验证该分组方式能否满足性能需求,进行了实际数据读写测试.向S-RAID5写入视频数据,然后检验写入数据的正确性,同时进行视频回放.测试表明,该S-RAID5能够正确写入32路D1标准的视频数据,以及正确回放记录的数据,为了避免直接从内存缓冲区读取回放数据,回放的是1h以前的监控数据.综上,P=12、Q=1分组方式的S-RAID5能够满足该视频监控系统的性能要求,进一步测试表明Hibernator、PARAID、WOL1、WOL5、GRAID以及eRAID5等,均能满足该视频监控系统的性能要求,其中Hibernator、WOL1的性能与S-RAID5接近,而PARAID、GRAID、eRAID5的性能则远优于S-RAID5.由于该视频监控系统对存储性能要求不高,PARAID、GRAID、eRAID5的高性能基本被浪费掉,同时带来了高能耗.4.3.2能耗测试对于S-RAID5、Hibernator、PARAID、WOL1、WOL5、GRAID以及eRAID5,测得的24h功耗如Page9图6所示,其中S-RAID5的节能效果最好,24h功耗仅为0.4999kWh,约为WOL1功耗的79%,WOL5功耗的68%,Hibernator功耗的59%,eRAID5功耗的23%,PARAID、GRAID功耗的21%左右.其中PARAID、GRAID的功耗最高,约为2.34kWh.图632路D1标准的视频监控中,各节能RAID的24h功耗为了进一步验证S-RAID5适用于视频监控等顺序数据存储系统,表5给出了S-RAID5与Hibernator、PARAID、WOL1、WOL5、GRAID、eRAID5相比较,能够节省的磁盘购置费用、运行1年节约的电量(根据24h功耗测量结果计算),容量为2TB的希捷ST32000644NS企业级磁盘,每块按1500元计算.表5各节能RAID相对S-RAID5的额外消耗(值越小越好)阵列类型额外磁盘购置费用/年额外耗电量/kWhS-RAID5Hibernator1500PARAIDWOL1WOL5GRAIDeRAID5由表5得,PARAID、GRAID、eRAID5的能耗最高,与S-RAID5相比,每年多消耗600kWh以上的电量.WOL1与WOL5的功耗略高于S-RAID5,但其冗余磁盘的购置费用远大于S-RAID5,分别超出16500和7500元.Hibernator的能耗与冗余磁盘趋中,但仍高于S-RAID5.综上,S-RAID5与这几种典型节能磁盘阵列相比,在满足性能需求、单盘容错的前提下,其功耗最低,冗余磁盘最少.4.4其它分组方式S-RAID5能够根据存储系统的总体性能需求,采用不同的分组方式,改变组内并行磁盘的数量,以提供合适的性能.下面将分别测试S-RAID5在不同分组方式下的性能和能耗.首先选取Iozone测试NILFS文件系统下不同分组方式的写性能,分组方式包括P=12、Q=1时,磁盘阵列分成12组,每组1个磁盘并行;P=6、Q=2时,磁盘阵列分成6组,每组2个磁盘并行;P=3、Q=4时,磁盘阵列分成3组,每组4个磁盘并行;P=1、Q=12,磁盘阵列分成1组,每组12个磁盘并行,测试结果见图7(a),其中缓冲区大小为16KB.由图7(a)得,随着组内并行磁盘的增加,S-RAID5的写性能显著提高,如Q=2时写性能达到54.94MB/s,而Q=4时的写性能已经超过100MB/s,能够满足一般顺序数据存储系统的性能需求.图7不同分组方式下S-RAID5的写性能与功耗NILFS文件系统下不同分组方式的读性能,主要由磁盘上数据块的地址映射情况决定,没有已经存在的写数据,难以准确测试读性能.一般情况下读性能较高,因为顺序数据存储系统的读操作主要回放写操作,而写操作是顺序的(地址变换后).同时由于读操作不需要额外的I/O(写操作中的读改写、重构写需要额外的I/O),读性能一般要高于写性能.不同分组方式下S-RAID5的24h功耗见图7(b),随着组内并行工作磁盘数的增加,S-RAID5的功耗也随之增加,当Q=12(全局并行),性能最高,功耗也最大,其性能、功耗与PARAID、eRAID5相当,此时失去节能效果.然而,对于一般的顺序数据存储系统,局部并行已经能够提供足够的性能,如Q=2时的随机写性能为54.94MB/s,见图7(a),而Page1024h功耗约为0.667kWh,见图7(b),其功耗仅仅略高于WOL1,见图6,却比WOL1节省11块2TB的冗余磁盘,见表4.4.5NTFS文件系统下的性能与节能测试NILFS文件系统是非常适合于S-RAID5,因为它可以将随机写转为顺序写.对于其它文件系统,由于数据管理方式各不相同,将对S-RAID5的性能、节能效果产生重要影响.本节将研究Linux下的EXT3、Windows下的NTFS文件系统是否适合于S-RAID5.4.5.1NTFS下的数据特征判断文件系统是否适合于S-RAID5,需要获取该文件系统在典型顺序数据访问中的数据特征,设计如下实验:在NTFS文件系统下,采用块级I/O跟踪工具Blktrace,追踪该32路视频监控系统(详见4.1节)的所有I/O请求,然后通过Blkparse分析追踪到的I/O请求,进而获得该文件系统下的数据特征,实验中的存储空间大小为160GB,追踪时间为5h(从文件系统创建到存储空间写满,每小时数据量为28.8GB).NTFS文件系统的数据特征,如图8所示,除部分存储区(逻辑地址0和逻辑地址0.4×108附近)被重复访问外,其余为理想的顺序数据访问.4.5.2NTFS下的读写性能应用NTFS文件系统时,测试负载的连续性,直接影响S-RAID5的性能测试结果.由图8可知,在典型顺序数据访问应用中,NTFS的数据特征基本是连续的(少量离散访问被缓冲、Cache过滤后),因此可用连续负载,测试S-RAID5在NTFS下的性能.非连续负载虽然能够反应S-RAID5的基本性能,但对S-RAID5的应用没有太大参考价值,因为S-RAID5主要面向顺序数据访问应用.关于存储空间写满后,删除旧数据,写入新数据等操作,一般会破坏NTFS以上理想的数据特征,这方面的优化将稍后讨论(见4.5.3小节).对于读操作,在实际顺序数据访问中,基本以回放写操作为主,如视频监控系统的视频回放,CDP系统的数据恢复过程,因此一般表现为连续读操作.选取Iozone测量NTFS文件系统下S-RAID5的读、写性能,采用缓存I/O(fsync)方式,测试结果见图9,其中顺序写操作的最小数据传输率为29.8MB/s,而顺序读操作的最小值为109MB/s.虽然读写性能相差较大,但写性能完全能够满足该视频监控系统的基本性能要求(8MB/s写带宽).4.5.3NTFS下的节能对于NTFS文件系统,当存储空间写满后,删除旧数据,写入新数据等操作,会破坏其理想的数据特征(见图8).因此,可应采用如下措施:把S-RAID5的存储空间划分为31个逻辑分区,并分别创建文件系统;数据依次写入每个分区;全部写满后,在第1个分区上重新创建文件系统(即删除第1逻辑分区的视频数据),依此类推.该方法既可实现保存30天视频数据的存储需求,又可避免由于数据写满而导致NTFS数据特征变坏的情况.采用如上优化措施后,测试该S-RAID5在NTFS下的8h平均功耗约为0.163Wh,与其在NILFS下的8h功耗基本相同.进一步测量其它节能方法,得其在NTFS下的8h平均功耗,与其在NILFS下的功耗也基本相同,主要因为2种文件系统的数据特征基本相同,即少量随机数据访问被过滤后,均表现为顺序写操作.5面向非平稳负载的优化为使S-RAID5能够很好适应顺序数据访问中的非平稳负载,包括波动负载和突发负载,需要对S-RAID5进行特定的优化.Page11由于顺序数据访问以写操作为主,因此可综合采用文献[14,22]的思想优化S-RAID5的性能:监控S-RAID5的工作负载情况,当其负载大于某个阈值时,如其最大数据传输率的80%,则将其写操作重定向到某个日志设备当中,日志设备可采磁盘或低功耗的SSD;而当S-RAID5负载较轻、或该分组所在磁盘待机时,恢复重定向的写数据.采用日志方式管理重定向的写数据,所需的主要数据结构是日志链表[24],日志链表包含若干条日志信息,每条日志信息记录一个重定向的写操作.日志信息的主要内容如下:LBA:写操作在S-RAID5中的起始地址;Log_LBA:写操作在日志设备中的起始地址;Length:写数据长度;Hash_pre与Hash_next:链接日志信息的两个重定向写数据会引起存储数据的一致性问题,指针.因此需要执行特殊的读、写流程,详见文献[16].基于Linux中MD模块下的线性RAID(LinearRAID)子模块,把S-RAID5和日志设备组成一个线性存储空间,并在LinearRAID层上实现以上性能优化方法,其中日志设备为2块Samsung830Series(SATAIII)、64GB的SSD组成的镜像RAID(重定向数据需要冗余保护).写带宽大于20MB/s时,重定向写数据到日志设备,根据图5(a)所示,该值小于S-RAID5写带宽的80%.选用块级测试工具Iometer测试S-RAID5的写性能,实验结果表明,此时S-RAID5的最小写带宽超过110MB/s,为正常负载带宽需求(8MB/s)的13倍以上.此时,写数据全部被写入日志设备,在该实例中,每小时写入的数据量为28.8GB,以上日志设备能够缓存约2.2h(64GB/28.8GB)的非平稳负载.可在负载较轻,或该分组所在磁盘空闲时,恢复日志设备中重定向的写数据.S-RAID5应用于确定的顺序数据访问应用时,需要估算实际应用的基本带宽需求、波动负载的周期、强度、持续时间,以及突发负载的强度、持续时间等参数,并根据估算结果设置S-RAID5的局部并行度、日志设备的容量和带宽.也可采用人工智能的相关知识,通过在线学习获得以上参数,该部分内容值得进一步深入研究.如果非平稳负载过于复杂,也可构建基于S-RAID5的分层存储系统(类似于MAID),如上层采用SSD,下层采用S-RAID5,通过上层的缓冲,可较好地把非平稳负载转换为平稳负载,随着SSD价格的下降,该方案是切实可行的.关于应用S-RAID5构建分层存储系统,这里不过多讨论.6结论与展望针对顺序数据存储系统,如视频监控、CDP、VTL等的数据特征和存储特性,提出了适于该类存储系统的节能磁盘阵列S-RAID5,包括阵列的底层数据布局、磁盘节能调度算法和Cache管理策略等内容.通过32路D1标准的视频监控模拟实验,对S-RAID5与Hibernator、PARAID、WOL1、WOL5、GRAID、eRAID5等典型节能磁盘阵列进行了比较.24h功耗测量实验表明:在满足性能需求、单盘容错的前提下,S-RAID5的功耗最低,冗余磁盘最少,非常适合应用在视频监控、CDP、VTL等存储系统中.S-RAID5的性能提升,可从两方面来实现:(1)调整分组来提高性能,S-RAID5的性能随组内并行磁盘数的增加而显著提高,当然能耗也会相应增加,需要根据性能、能耗做出均衡选择.(2)应用WriteOff-loading方法提高性能.当读、写同一组磁盘时,会对S-RAID5的性能产生较大影响.可监测磁盘的I/O请求,当对磁盘同时进行大量读写操作时,则把写操作暂时重定向到其它存储设备上,如SSD等,并在磁盘空闲时迁回该写数据.WriteOff-loading方法可有效解决S-RAID5中,同时读写一组磁盘的性能瓶颈问题.关于WriteOff-loading方法在S-RAID5中具体实现及测试,将在下一阶段工作中进行.
