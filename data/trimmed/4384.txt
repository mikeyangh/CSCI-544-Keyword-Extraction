Page1基于优势关系粗糙集的自主式学习模型邓维斌1),2)王国胤2)胡峰2)1)(西南交通大学信息科学与技术学院成都610031)2)(重庆邮电大学计算智能重庆市重点实验室重庆400065)摘要为了增强对不一致有序信息系统的处理能力,变精度优势关系粗糙集通过引入变精度阈值增加了对不一致信息的适应性,其分类性能受变精度阈值大小的影响.然而,变精度阈值往往依赖于领域先验知识或通过反复尝试确定,极大地影响了算法的实用性.针对优势关系下如何进行信息系统知识获取这一自主控制难题,在分析了变精度优势关系粗糙集所存在问题的基础上,首先定义了优势关系信息系统中决策表的整体确定性、最大整体确定性、整体不确定性、最小整体不确定性等度量准则,进而提出了对各决策类集的最大确定性进行度量的准则和算法.在此基础上,提出了将各决策类集的最大确定性作为该决策类集的变精度阈值进行知识获取的自主式学习模型.该模型不仅避免了知识获取过程中对先验知识的依赖,也增强了对处理不一致信息系统的适应性.通过与现有算法的仿真实验对比分析,发现该自主式学习方法对处理具有较高不一致性的有序信息系统具有比较突出的优势.关键词优势关系粗糙集;自主式学习;不确定性度量;知识获取;机器学习1引言机器学习是当前人工智能研究中较为重要的领域,机器学习的实质是知识表示形式的转化,在其中起决定性作用的是数据所具有的本质特性[1].由于实际信息系统中不一致性的存在,在传统的机器学习(如概率论、模糊集等)研究中,人们往往都借助于部分领域先验知识.如何在不确定性条件下摆脱学习过程中对先验知识的依赖,进行自主地学习,是人工智能知识获取研究中的一个难题[2].由于粗糙集(RoughSet,RS)能有效处理不精确、不一致及不完备信息,能够较好地摆脱学习过程中对先验知识的依赖,自Pawlak[3]于1982年提出以来,从众多机器学习理论中脱颖而出,近年来在机器学习、医疗诊断、市场决策及信息安全等众多领域得到了广泛应用[4-6],很多学者在属性约简和不完备信息系统处理等方面开展了大量的研究[7-9].针对不一致性的处理,Ziarko[10]提出了变精度粗糙集(VPRS),Yao和Wong提出了三枝决策粗糙集[11-13],而这些模型仍然有部分先验知识的引入.为了实现数据驱动的自主式学习,王国胤等学者对基于粗糙集理论的自主式模型和方法进行了有益的探索,构建了面向领域的数据驱动的数据挖掘(Domain-orientedData-drivenDataMining,3DM)基础理论[2],并通过对基于等价关系决策表局部一致性、整体一致性及其关系进行深入研究,将其成果应用到粗糙集的知识获取[14]、决策树自动预修剪[15]、概念格学习[16]、客户分类[17]等过程中.为了处理具有连续属性和优势关系的信息系统,Greco等人[18-19]提出了优势关系粗糙集(Domi-nance-basedRoughSetApproach,DRSA),用优势关系代替了经典粗糙集的不可分辨关系,很多学者对优势关系下不一致、不完备信息等系统也进行了大量研究[20-22].为了增强对不一致信息的适应性,VC-DRSA[23]、VP-DRSA[21]和ISVP-DRSA[24]等变精度模型先后被提出.在这些变精度模型中,对象是否进入下近似取决于一致性阈值β的大小,因此设置一个合适的β值对模型的分类性能至关重要.虽然Blaszczynski等人[25]、Hu等人[26-27]对优势关系下对象和属性的不一致性进行了研究,但由于在优势关系下对决策表和决策类集的不一致性度量变得更为复杂,目前还没有有效的方法.为了避免不一致信息的影响,Wang等人[28]提出了“规则+例外”的思想,Deng等人[29]提出了将优势关系决策表进行一致性转化,并将阈值β设置为1,虽然简化了对最优阈值的反复尝试,但这种方法可能会导致部分有效信息的丢失,所获取的规则也可能会缺乏对噪声数据的适应性.为了实现优势关系下的自主式学习,充分体现粗糙集理论“让数据自己说话”的突出优点,本文在分析了现有变精度优势关系粗糙集分类性能不足的基础上,通过度量优势关系下决策表和决策类集的确定性,提出了一种新的局部变精度优势关系粗糙集模型,以各决策类集的最大确定性为该决策类集的变精度阈值控制规则获取,实现了一种在不确定条件下,完全由数据自主控制的机器学习方法,建立了一种不确定条件下的自主式知识获取模型.2基本理论2.1优势关系粗糙集一些基本概念.定义1.决策表信息系统[2].一个决策表信息系统简称决策表.S=〈U,R,V,f〉,其中,U是对象的集合,也称为论域;R=C∪D是属性集合,子集C和D分别称为条件属性集和决策属性集,D≠;V=∪r∈RVr是属性值的集合,Vr表示属性r∈R的属性值范围,即属性r的值域;f:U×R→V是一个信息函数,它指定U中每一个对象x的属性值.在优势关系粗糙集中,将有序的属性称为准则.定义2.优势关系[19].令q为论域U上的弱偏序关系.yqz是指在准则q上y至少和z一样为了叙述方便,先介绍优势关系粗糙集理论的Page3好.如果对q∈P都有yqz,则y,z在准则PC上的优势关系表示为yDPz.显然,优势关系具有自反性和传递性.定义3.上并集和下并集[19].假设决策属性d将论域U分成有限的类集χ={Xt,t∈T},T={1,…,n},y∈U属于一个且仅属于一个Xt,且假定这种分类是有序的,即对所有的i,j∈T,如果j>i,则Xj中的任一对象优于(或劣于)Xi中的对象.则上并集和下并集表示为定义4.优势集和劣势集[19].给定PC,y,z∈U,y关于P的优势集和劣势集分别表示为定义5.上近似、下近似和边界域[19].为了简化描述,在不致混淆的情况下,用符号X表示类集i或XXP(y),y∈U,则X关于P的下近似P(X)和集D-上近似P(X)分别表示为则X关于P的边界域表示为定义6.不一致对象.如果y∈Xi-1≠或y∈XX为优势关系信息系统中关于P的不一致对象.定义7.近似分类质量[19].设PC,决策类集χ的近似分类质量定义为其中|X|表示集合X的基.粗糙集求取下近似的目的是为了决策规则的提取,以便对其他样本进行预测.下面对决策规则及相关性质进行简单介绍.定义8.决策规则[19,30].决策规则r的一般表现形式为其中,Φ是规则的条件部分,Ψ是规则的决策部分.条件部分Φ是条件值对的合取.如果决策规则r的决策部分有多个决策属性,那么Ψ将是多个基本决策的析取.本文仅讨论决策集属性个数为1的情况.在优势关系粗糙集中,确定性规则都是从类集X的下近似P(X)中导出.所导出规则的一般表现形式为ifci1(y)ti1∧…∧cip(y)tip∧cip+1(y)=tip+1∧…∧ciz(y)=tiztheny∈Xifci1(y)ti1∧…∧cip(y)tip∧cip+1(y)=tip+1∧…∧ciz(y)=tiztheny∈X其中,ci1,…,cip表示具有优势关系的条件属性,cip+1,…,ciz表示没有优势关系的条件属性,tij表示属性cij的一个值,ij∈{i1,…,iz}{1,…,|C|}.从类集X导出的某条决策规则用ri表示,ri的条件部分和决策部分分别用Φ(ri)和Ψ(ri)表示.此外,用{Φ(ri)}和{Ψ(ri)}分别表示满足条件部分和决策部分的对象集合.定义9.决策规则的最小性[30-31].如果从类集X导出的某条决策规则ri只能覆盖X中的对象,则称ri为区分规则.如果ri去掉其条件部分的任一部分后不再是区分规则,则称ri为最小规则.换言之,如果ri是最小规则,则不存在从类集Y中导出的规则rj,使得{Φ(ri)}{Φ(rj)}且XY.定义10.决策规则集的完备性和非冗余性[30-32].假设从类集X导出的决策规则集是R,如对y∈X都至少能被R中的一条决策规则覆盖,则称从X导出的决策规则集R是完备的.如果去掉R中任一决策规则ri都影响了R的完备性,则称决策规则集R是非冗余的.根据决策规则导出的算法不同,一个决策表可以导出多个不同的具有完备性和非冗余性的决策规则集[30-32].有些学者试图提出一种能提取最少规则数量的每条规则都是最小规则的最小决策规则集提取算法,但这已被证明是一个NP-hard难题[33-34].为了尽量提取规则数较少的决策规则集,一般采用启发式搜索方法.针对经典粗糙集,Grzymala等人[33-35]提出了LEM2算法,针对优势关系粗糙集,Greco等人[30]提出了DomLEM算法.2.2变精度优势关系粗糙集在DRSA中,由于部分噪声数据的存在,会导致其他一致对象变成不一致对象,在实际应用中定义5对下近似的求解过于严格,如果系统中存在少量极端不一致对象,就会导致包含在下近似中的对象非常少.为了增强对噪声数据的适应性,学者们分别提出了VC-DRSA、VP-DRSA和ISVP-DRSA的变精度模型.其核心思想是设置一个变精度阈值β,扩充下近似中所包含的对象,以增强对部分不一致信息的适应性.Page4在所有的变精度DRSA模型中,均需对对象的一致性进行度量,将其表示为ΘX:U→[0,).对象的一致性ΘX既可以是一个gain类型(值越大,对象的一致性越高),也可以是一个cost类型(值越小,对象的一致性越高).定义11.变精度DRSA的下近似[23,25,30].给定XU,y∈U,对象一致性度量准则ΘX和变精度阈值β,类集X的下近似定义为其中,∝在gain类型的一致性度量中表示大于等于(),在cost类型的一致性度量中表示小于等于().通常,变精度阈值β∈[0,1],其作用有两个:一是控制对象是否进入下近似;二是在规则提取中作为控制规则是否生成的标准,在VC-DRSA、VP-DRSA和ISVP-DRSA等几种变精度模型中,人为地对一个决策系统中所有类集的变精度值设置成相等.对基于变精度粗糙集的决策规则提取问题,文献[31]在对DomLEM算法改进的基础上,提出了VC-DomLEM算法,使用迭代方法不断从训练集中提取规则,最终从学习数据集中提取出一个规则数相对较少、完备且非冗余的决策规则集.目前VC-DomLEM算法已被集成到波兰科学院Slowinski院士团队所开发的基于优势关系粗糙集的智能决策分析系统jMAF①中.3基于优势关系粗糙集的自主式学习模型首先,分析一下经典变精度优势关系粗糙集所存在的问题.通过定义11可知,阈值β的设置对变精度DRSA的分类性能影响较大,但设置一个合适的阈值并非易事,目前主要是依赖领域先验知识或不断尝试来取得这个值.在gain类型的一致性度量准则中通常设为0.9,0.95等;在cost类型的一致性度量准则中通常设为0.05,0.025等[23,36].为什么设置这些值,并不能给出一个合理的解释,且对所有有序决策信息系统都这样设置β值是否能达到最佳分类性能也值得商榷.下面通过一个实例来分析变精度阈值β设置对系统分类性能的影响.例1.表1是一个包含17个学生成绩评价的决策表,U={S1,S2,…,S17},C={数学(Math),文学(Lit)},d={综合评价(PS)},V={UtterlyBad,VeryBad,Bad,Medium,Good,VeryGood,Excellent,Yes,No},其中决策值Yes表示学生通过了综合考核,No表示学生未通过综合考核.显然这是一个在优势关系下不一致的决策表,如S3在Math和Lit成绩上均优于S9,但决策属性上却比S9劣.根据定义6,S3,S4,S5,S6,S9,S10,S11,S12,S13,S14,S15,S16等12个对象均是不一致对象,决策表的近似分类质量仅为5/17.可知这是一个具有高度不一致性的决策表.下面通过实验来分析阈值β的设置对分类性能的影响.在实验中先用这17条记录作为学习数据,用jMAF系统进行规则提取,并对原学习数据集进行分类,一致性阈值β从0.05开始,以0.05的步长递增到1.0,一致性阈值β在不同取值下的分类效果如图1所示.U数学S1ExcellentVeryGoodS2ExcellentMediumS3VeryGoodVeryGoodS4VeryGoodS5VeryGoodS6VeryGoodUtterlyBadS7GoodS8MediumS9MediumS10BadS11BadS12VeryBadMediumS13VeryBadVeryBadS14VeryBadUtterlyBadS15UtterlyBadS16UtterlyBadVeryBadS17UtterlyBadUtterlyBad图1用jMAF对表1在不同变精度阈值β下的分类效果从图1可看出,当β0.9时分类效果最差,介于0.75~0.8之间时分类性能最好.通过分析发现,根据VC-DomLEM算法[31],随着β值的增加,具有较高支持度(覆盖度较低)的规则会替换具有较低支持度(覆盖度较高)的规则.①http://idss.cs.put.poznan.pl/site/software.htmlPage5这种通过不断尝试对数据集设置一个分类精度较高的β阈值[36-37]的方法需反复进行多次学习和测试,具有较高的时间复杂度,很难满足对海量数据集或适时性要求较高的智能数据分析要求.如何根据不同数据集自身所隐含的特征确定一个合适的变精度阈值是一个难题,也是自主式学习中需要解决的核心问题.为了实现自主式学习,受文献[2,14]的启发,首先对优势关系下决策表和决策类集的一致性进行度量.3.1优势关系下的一致性度量定义12.相对一致对象.假设y∈U是不一致对象,如果将其他不一致对象从决策系统中删除后,y变成了一致对象,则y称为相对一致对象.定理1.决策信息系统中的不一致对象均是相对一致对象.证明.假设决策信息系统S中包含y1,y2,…,yn等共n个对象,对其中的某个对象yi,如果有其他k个对象与yi相冲突,则将这k个对象删除后,yi变成了一致对象.极端情况下,y1,y2,…,yi-1,yi+1,…,yn等n-1个对象均与yi冲突,则将这n-1个对象均删除后,决策信息系统S中仅剩yi一个对象,由于yi与其自身不冲突,则yi变成了一致对象.定理1说明,任何不一致的信息系统均可在删除不一致信息后转变成一致信息系统,转变成一致信息系统之后的记录集合不为空.此外,根据删除不一致信息的方法不同,转变成的一致信息系统也不同.定义13.决策表的整体确定性和整体不确定性.如果将不一致对象集Ou={y1,y2,…,yk}删除后,决策表S变成了一致性决策表,则决策表S相对于不一致性对象集Ou的整体确定性定义为与此相对应,决策表S相对于不一致性对象集Ou的整体不确定性定义为根据定义12和定理1,将决策表S变成一致性决策表的方法有多种,删除不同的不一致对象集Ou,将得到不同的决策表整体确定性和整体不确定性.这与经典粗糙集对决策表的一致性和不一致性度量具有较大区别.定义14.决策表的最大整体确定性和最小整体不确定性.给定决策表S,在删除任意的不一致对象集Ouk后均可变成一致性的决策表,则决策表的最大整体确定性为称Omin=min{Ouk}为最小不确定性对象集,则决策表的最小整体不确定性为定理2.由决策表S得到的完备且非冗余的决策规则集R,在决策表能充分反映领域样本的情况下,用R对样本数据进行测试的最大可能正确率η等于决策表的最大整体确定性μmc,即η=μmc=|U-Omin||U|.证明.当删除了最小不一致对象集Omin后,决策表S转变成了一致决策表S,由于决策规则集R具有完备性和非冗余性的特点,除不一致对象集Omin中的对象外,其余对象均可被正确分类,则最大识别正确率为|U-Omin|定理2说明,在决策表S中除不一致对象集Ouk中的对象外,其余对象均进入下近似,有利于分类性能的改善.如果不一致对象集Ouk中所包含的对象越少,最大可能分类正确率就越大,当Ouk=Omin时,最大可能分类正确率最高.定义15.决策类集的最大确定性和最小不确定性.给定决策表S和最小不一致对象集Omin,类集Xi的最大确定性表示为其中,Xi=Xi-Omin,OXi表示Omin中所有影响Xi中对象一致性的对象集合.决策类集的最小不确定性表示为决策表S的整体最小不确定性反映了决策表S的最小冲突情况,决策类集Xi的最小不确定性反映了决策类集Xi的最小冲突情况.下面设计一个算法来计算决策类集的最大确定性.算法1.计算决策类集Xi的最大确定性算法.输入:决策类集Xi和最小不一致对象集Omin输出:决策类集Xi的最大确定性κXi1.BEGIN2.Xi··=Xi-Omin;3.OXiPage64.FOREACHy∈OminDO5.{FOREACHx∈XiDO6.y∈D+7.OXi8.κXi9.RETURNκXi10.END定义16.规则可信度[14].对于决策表S=(U,R,V,f),R=C∪D是属性集合,子集C和D分别为条件属性集和决策属性集,决策规则r的可信度定义为cr=|{Φ(r)}∩{Ψ(r)}|/|{Φ(r)}|.定理3.在变精度优势关系粗糙集中,用决策类集Xi的最大确定性κXi作为该决策类集可信度阈值提取的决策规则集R,属于R的规则为r1,r2,…,rn,对应的可信度为cr1,cr2,…,crn,则规则集R的最小可信度min{cr1,cr2,…,crn}κXi.证明.如果将决策类集Xi的最大确定性κXi作为该决策类集的可信度阈值,即令βi=κXi.根据变精度优势关系粗糙集规则提取思想,对拟提取的任意决策规则ri,其对应的可信度均需满足criβ=κXi.则有min{cr1,cr2,…,crn}κXi.证毕.定理3表明用决策类集的最大确定性作为可信度阈值提取决策规则集后,其规则集的可信度反映了该决策类集的最大确定性.为了度量决策表的最大整体确定性、最小整体不确定性和决策类集的最大确定性,均需找到决策表的最小不一致对象集Omin,文献[37]给出了一种优势关系下对象全局不一致性的度量准则α(y)=maxα-(y)=D-并根据迭代思想提出了一种将不一致决策表转变成一致决策表的算法TIPStoC,在算法的每次运行中,总是删除不一致性最大的对象,直到决策表变成一致的.当决策表变成一致后,被删除的所有对象构成了不一致对象集Ou,具体过程如算法2.算法2.TIPStoC算法.输入:决策表S=(U,R,V,f),其中R=C∪D,U是决输出:一致对象集OcU,不一致对象集OuU1.BEGIN其中,函数findInconsistentObjects(U)的功能是查找所有不一致性系数α>0的对象,函数findMax-InconsistentObject(OI,αI)的功能是查找不一致对象集OI中不一致性系数最大的不一致对象.在不一致对象查找过程中,对象全局不一致性度量准则起着至关重要的作用,文献[37]也定义了另外两种度量准则ε(y)和μ(y),但通过大量的对比实验发现,在决策表的一致性转化过程中,α(y)准则所删除的不一致对象最少,则本文用α-TIPStoC所删除的不一致对象构成决策表的最小不一致对象集Omin.通过算法2得到决策表的最小不一致对象集Omin后,就可通过算法1计算每个决策类集的最大确定性,下面通过一个实例来说明算法1的工作过程.例2.对如表1所示的决策表,用α-TIPStoC删除的不一致记录为S3,S14,S16和S10,在迭代过程中所对应的全局不一致系数α为7.0,4.0,3.0和2.0,则有Omin={S3,S14,S16,S10},Yes={S1,S2,S4,S5,S7,S8,S9,S12,S15},XNo={S6,S11,S13,S17},Xη=μmc=U-Omin2.Ou··=;3.[OI,αI]··=findInconsistentObjects(U);4.WHILE(OI≠)5.{ymax··=findMaxInconsistentObject(OI,αI);6.Ou··=Ou∪{ymax};7.[OI,αI]··=findInconsistentObjects(OI\{ymax});}8.RETURN[U\Ou,Ou]9.END由于S3影响了S4、S5的一致性,S10影响了S12、S15的一致性,则κX由于S14影响了S6、S11、S13的一致性,S4影响了S11、S13的一致性,则κX3.2优势关系下的自主式学习算法在经典变精度DRSA中,对象是否进入下近似和规则提取都存在对先验知识的依赖.为了实现知识获取过程中的自主式控制,可以从以下两方面考虑:其一是让尽可能多的对象进入下近似,可让除了最小不一致对象集Omin中的对象外,其余对象均进入下近似,如式(20)所示;其二是根据各决策类集的确定性的不同,分别用各决策类集的最大确定性作为对应的可信度阈值控制规则获取.优势关系下的自主式学习过程如算法3所示.Page7算法3.优势关系下的自主式学习算法(SL-DRSA)输入:决策表S=(U,R,V,f),其中R=C∪D,U是决输出:规则集R1.根据式(19)分别计算各对象的全局不一致性α;2.根据对象的全局不一致性,用算法2将决策表S中的对象分成一致性对象集Oc和不一致对象集Omin,其中Oc∪Omin=U,Oc∩Omin=;3.根据式(20)计算各决策类集Xi的下近似P(Xi);4.根据算法1计算各决策类集Xi的最大确定性κXi;规则r1IfMathUtterlyBad&LitBadthenPSYesS1,S2,S4,S5,S7,S8,S9,S12,S15S1,S2,S3,S4,S5,S7,S8,S9,S10,S12,S150.8180r2S6,S11,S13,S17表2用SL-DRSA算法对表1所提取的规则集支持对象4仿真实验拟通过与文献[31,36]中的ε-VC-DomLEM算法和文献[29,37]中的α-TIPStoC算法的对比实验来验证本文提出的自主式学习算法的效果,共选择了16个数据集进行测试,数据集的具体信息如表3所示.其中ERA,ESL,LEV和SWD来源于文献[38],denbosch来源于文献[39],windsor来源于文献[23],GansuMobile来源于中国联通某分公司的客户消费数据,其余数据集来源于UCI①等公共数据集.整个实验分以下几步进行.第1步.对数据集的预处理.(1)由于cpu,housing和windsor三个数据集的决策属性是连续值,为了与文献[37]等实验结果表3实验数据集特征及相应的γ、λ和μ犿犮值对象数条件属性数分类数γ序号12345678910111213141516Yes)={S1,S2,S4,S5,S7,S8,S9,S12,S15},5.调用VC-DomLEM算法,并用各决策类集Xi的最大确定性κXi分别作为各决策类集的可信度阈值βi控制规则获取,得出规则集R.例3.对如表1所示的决策表,XP(XNo的下近似P(XXYes=0.818和κXκXYes)和P(XP(X所示.用表2所示两条规则对原数据进行分类,除S3,S10,S14和S16外,其余对象均可被正确分类,分类正确率达到最高,为13/17=76.47%.进行对比,采用与其相同的离散化方法,即将决策属性分成4段,每段的频数相等.(2)数据集中如果存在缺失值,直接将具有缺失数据的记录删除.第2步.数据集的一致性度量.一致性越好的数据集,可学习性就越强.为了度量数据集的一致性,分别计算了各个数据集的近似分类质量γ、λ度量准则[40](式(21))和最大整体确定性μmc,具体数值如表3所示.λ(χ)=|X1∩POS(X①http://www.ics.uci.edu/~mlearn/MLRepository.htmlPage83个不同的度量值均与数据集的一致性呈正相关,从表3可以看出blance,cpu和housing等3个数据集是完全一致的,bank-g,Australian,breast-w,car,denbosch和fame等6个数据集具有较高的一致性,SWD,LEV和ERA等3个数据集的不一致性很高.对于完全一致的数据集,近似分类质量γ、λ度量准则和最大整体确定性μmc均为1;对于一致性较高的几个数据集,3个度量值比较接近;而对于具有高度不一致性的数据集,不同度量准则的差距较大.对于3个度量准则,均是值越大,表明数据集越易于学习.第3步.分类性能的交叉验证.为了增加实验结果的客观性,测试采用10重交叉验证5次循环的方法(记为5×10-fcv)[31,36-37],即独立运行10重交叉验证5次.在每次10重交叉过程中,随机将数据平均分成10份,先用其中的9份作学习数据获取规则,对余下的1份数据进行测试,如其中,UT表示测试数据集,共有k个测试对象,f(yi,d)表示对象yi在决策属性d上的实际值,f(yi,d)表示对象yi的分类预测值.MAE越小,分类性能越好.对两个测量准则计算出5×10-fcv的平均值和标准偏差,具体结果如表4所示.表4实验结果———犘犆犆和犕犃犈表序号数据集1balance85.6(2)±0.44185.6(2)±0.44185.6(2)±0.4410.170(2)±0.0060.170(2)±0.0060.170(2)±0.0062cpu91.3(2)±1.07091.3(2)±1.07091.3(2)±1.0700.087(2)±0.0110.087(2)±0.0110.087(2)±0.0113housing69.8(2)±1.59069.8(2)±1.59069.8(2)±1.5900.343(2)±0.0170.343(2)±0.0170.343(2)±0.0174bank-g95.3(1)±0.22695.0(3)±0.35995.2(2)±0.2870.047(2)±0.0020.050(3)±0.0040.046(1)±0.0035Australian75.1(2)±0.50275.3(1)±0.97375.0(3)±0.8910.249(3)±0.0050.247(1)±0.0100.248(2)±0.0406breast-w95.8(3)±0.24996.1(1)±0.21095.9(2)±0.2300.042(3)±0.0020.039(1)±0.0020.041(2)±0.0037car97.2(1)±0.07696.7(3)±0.11397.1(2)±0.1080.033(1)±0.0010.040(3)±0.0010.036(2)±0.0028denbosch86.6(2)±1.59084.5(3)±1.26086.8(1)±1.1900.134(2)±0.0160.155(3)±0.0130.133(1)±0.0059fame67.4(1)±0.40265.8(3)±0.57766.3(2)±0.3840.343(1)±0.0040.359(3)±0.0070.352(2)±0.00810GansuMobile87.7(3)±0.12488.0(2)±0.14288.1(1)±0.1470.126(3)±0.0010.123(1)±0.0020.125(2)±0.00211windsor53.3(2)±0.86251.4(3)±1.40055.6(1)±0.9580.541(2.5)±0.0070.541(2.5)±0.0170.489(1)±0.01212breast-cancer74.9(2)±0.71374.3(3)±0.72075.7(1)±0.7510.251(2)±0.0070.257(3)±0.0070.217(1)±0.00413ESL63.2(3)±0.82468.4(2)±1.15069.6(1)±0.9650.409(3)±0.0080.341(2)±0.0110.340(1)±0.00114SWD56.5(2)±0.32056.1(3)±1.02057.2(1)±0.4420.460(2)±0.0030.465(3)±0.0100.445(1)±0.00915LEV54.7(3)±0.45062.6(1)±0.81362.3(2)±0.9410.503(3)±0.0050.405(2)±0.0070.403(1)±0.00216ERA25.0(3)±0.72326.8(2)±0.92227.8(1)±0.6851.380(3)±0.0161.330(2)±0.0181.320(1)±0.016注:结果表示为a(b)±c形式,其中a表示PCC或MAE的5×10-fcv测试结果的平均值,b表示平均值在3种方法中的排序,c表示多次测发现SL-DRSA与ε-VC-DomLEM,α-TIPStoC在第5步.结果分析.(1)用不同分类方法在所有数据集上测试性能PCC和MAE度量准则上的显著性概率均小于0.05,说明本文提出的方法显著优于其他两种方法.的平均排序来度量整体分类性能的好坏[31,36],平均排序值越小,其分类性能越好.可以看出,不管采用而ε-VC-DomLEM与α-TIPStoC方法在PCC和PCC度量标准还是采用MAE度量标准,SL-DRSAMAE两种度量标准下比较的显著性概率均大于0.7,说明这两种方法在分类性能上无显著性差异.方法都比其他两种方法好.(3)为了检验不同方法在所有数据集上分类性(2)为了检验不同方法在分类性能上是否具有显著性差异,取0.05的显著性水平对3种方法的实能优劣和相当程度,对几种方法的实验结果分别进验结果进行相关样本Wilcoxon非参数检验[24,37],行比较,结果如表5所示.其中w-t-l分别表示当前试结果的标准差.平均排序2.121.63此轮循10遍.对文献[31,36]的ε-VC-DomLEM算法,取不同的变精度参数β运行多次5×10-fcv,取其中最好的分类效果.对文献[29,37]的α-TIPStoC算法和本文所提出的自主式学习算法,由于不需要变精度参数的设置,只需运行1次5×10-fcv.第4步.测试结果.一般分类器的性能通过分类正确率(PCC)来体现,而对于有序分类,还常用对象的实际类别与预测类之间的平均绝对误差(MAE)来测度,公式为ε-VC-DomLEMα-TIPStoCSL-DRSAPage9行所在方法比当前列所在方法性能优、相当和劣的数据集个数,如第1行第1列中的“6-3-7”表示α-TIPStoC分类性能比ε-VC-DomLEM方法优的数据集有6个,性能相当的有3个,性能不足的有7个.从表5也可看出,本文提出的自主式学习方法SL-DRSA分类性能也优于其他两种方法,而其他两种方法之间无明显差异,这与采用Wilcoxon非参数检验的结果是一致的.α-TIPStoC6-3-7SL-DRSA9-3-410-3-311-3-210-3-3(4)结合表3分析,发现在3个完全一致的数据集(blance,cpu和housing)上,由于不存在不一致数据,3种方法分类性能完全一样;在一致性较高的6个数据集(bank-g,Australian,breast-w,car,denbosch和fame)上,3种方法性能差异不明显;而在不一致性较高的几个数据集(windsor,breast-cancer,ESL,SWD,LEV和ERA)上,自主式学习方法的性能表现得比较明显.5结论及展望针对优势关系下不一致信息系统的智能决策问题,提出了一种基于优势关系的自主式学习算法.该方法用每个决策类集的最大确定性作为该类集的可信度阈值进行规则获取,避免了传统方法对变精度阈值选取的随意性和不断尝试所带来的计算复杂性,也避免了不一致信息系统一致性转化方法对不一致信息缺乏容忍度的缺陷.通过大量的实验表明,该方法可实现根据数据集本身特性自主确定各决策类的变精度阈值,且表现出了较好的分类性能,特别是在不一致性较高的数据集中体现得比较明显.为了度量决策表和决策类集的不确定性,需确定决策表的最小不一致对象集.文中采用了优势关系下对象全局不一致性的α度量准则,是否还有更好的度量方法,以及如何对大数据集进行属性约简将是下一步研究的主要内容.
