Page1改进向量投影的支持向量预选取方法杨静1)于旭1)谢志强1),2)1)(哈尔滨工程大学计算机科学与技术学院哈尔滨150001)2)(哈尔滨理工大学计算机科学与技术学院哈尔滨150080)摘要针对基于向量投影的支持向量预选取方法选取投影直线过于简单粗糙,导致需要选取较多的边界向量才能包含原始问题的支持向量的问题,提出了一种新的支持向量预选取方法.该方法通过定义好的投影直线具备的3个必要特征,提出:对于线性可分情况,利用Fisher线性判别算法来获取最佳的投影直线;对于非线性可分情况,利用特征空间中心向量所在直线作为相应的投影直线.由于该方法确定的投影直线可以更好地对样本投影进行分离,因此,与基于向量投影的支持向量预选取方法相比,该方法可用更少的原始样本来构造边界向量集合,可有效降低支持向量机算法的时空复杂度.在两个人工数据集和一个现实数据集上的实验表明,所提方法不仅可以达到以往各种实用的支持向量机算法分类精度,而且更为高效.关键词支持向量机;边界向量集合;Fisher线性判别;中心向量1引言关注.实践证明支持向量机对于许多实际问题有着很好的泛化能力,例如手写字符识别[4]、人脸识别[5-6]、行人检测[7-8]、文本分类[9-10]、入侵检测[11],然近些年,支持向量机[1-3]研究获得了越来越多的而标准的支持向量机算法时间复杂度高,并且需要Page2大量的内存空间,因此支持向量机的应用受到了很大的限制.由于利用支持向量机算法进行决策时,最终的决策函数仅仅由支持向量决定[2],因此如果能够预先确定支持向量,那么就可以极大地降低支持向量机训练算法的时空复杂度.为此,很多较实用的支持向量机算法被相继提出,其中大多数被称之为分解方法.例如,方法Chunking[12]、Decomposing[13]和序列最小最优化(SMO)算法[14].这些方法虽然可以预先确定支持向量,但它们获得支持向量时需要迭代多次.为了快速获得支持向量,李青等提出了一种基于向量投影的支持向量预选取方法[15],由于该方法可在边界向量集合上进行一次支持向量机训练,因此该方法有效地降低了支持向量机训练的计算时间和内存需求.但该方法还存在一些不足需要改进,如:(1)没有对向量投影的原因给出详细的分析,没有对投影直线的性能进行比较,影响了该方法可信性;(2)对于线性可分情况,利用中心向量所在直线作为投影直线,不能充分对原始样本的投影进行最大化的分离,甚至会出现经投影后变为线性不可分,从而影响对边界向量集合的合理确定,导致需要选取较多的原始样本构造边界向量集合;(3)对于非线性可分情况,将原始空间两类样本的中心m1,m2通过核函数ψ(·)映射到特征空间,然后在特征空间中,利用向量ψ(m1)ψ(m2→)所在直线作为投影直线,由于该直线不是一般意义上的特征空间中的中心向量所在直线,将影响特征空间中样本投影的分离,导致需要选取较多的原始样本来构造边界向量集合.针对文献[15]的不足,本文提出了一种新的支持向量预选取方法,对文献[15]中方法主要做了如下改进:(1)深入分析了向量投影的原因,明确了通过向量投影方式可以方便地确定边界向量集合,并给出了好的投影直线应该具备的3个特征;(2)对于线性可分情况,为了有效地对原始样本进行最大化分离,提出利用Fisher线性判别算法获取最佳投影直线,保证了原始空间中的线性可分问题,经投影后仍然线性可分,方便了边界向量选取;(3)对于非线性可分情况,本文首先将原始样本投影到特征空间,然后在特征空间中分别求取两类样本的中心m1ψ和m2ψ,最后利用向量m1ψm2→ψ所在直线作为投影直线.由于所获取的直线可以更好地对特征空间样本投影进行分离,方便了边界向量选取,因此本文提出的方法可以使用更少的原始样本构造边界向量集合,为进一步降低支持向量机训练算法的时空复杂度提供了保障.在此基础上,针对线性可分和非线性可分情况,提出了完整的分类算法,并对算法的时间和空间复杂度进行详细分析;最后将本文所提算法与标准支持向量机算法、SMO算法和文献[15]中所提算法,在两个人工数据集上和一个实际问题数据集上进行对比测试,并给出各种算法的运行时间、分类精度和相应的分析结论.2边界向量集合上的支持向量机训练2.1支持向量预选取思路利用支持向量机解决分类问题时,许多Lagrange乘子等于零,然而最终的决策函数却仅仅由具有非零Lagrange乘子的样本决定,这些样本就是所谓的支持向量.因此如果能够预先确定支持向量,那么支持向量机训练将变得更容易.由于支持向量经常位于每一类样本的边界区域,并且面向另一类样本.因此一个很好的预选取支持向量的方法是寻找边界向量,即位于每一类样本的边界区域,并且面向另一类的样本[15-16].2.2投影原因及投影直线的特征分析为了确定该边界向量集合,有必要确定每一类样本面向另一类样本的边界.由于现实世界中原始样本往往是高维的,很难直接确定边界,而采用将所有的样本投影到某一直线上的方法,有可能在一维空间确定边界向量集合,所以如何确定投影直线就成了确定边界向量集合的重要问题.出合适的投影直线所应该具备的特点如下:由于可投影的直线很多,为了确定投影直线,给(1)对于原始空间中的线性可分问题,合适的投影直线能够使其上样本投影也线性可分,即该直线应该能够使两类样本在其上的投影是两个互不相交的区域.(2)对于原始空间的非线性可分问题,在将原始空间映射到高维空间之后,合适的投影直线能够使特征空间内的向量在其上的投影也线性可分,即该直线应该能够使特征空间中两类样本在其上的投影是两个互不相交的区域.(3)为了便于确定边界向量,合适的投影直线应能使各类样本投影后,在一维的空间的各类样本投影尽可能分得开,同时各类样本的投影内部尽量密集.2.3投影直线确定方法基于上述分析,本文提出如下投影直线确定Page3方法:(1)对于线性可分情况,由于Fisher线性判别算法[17]能够寻找最大化类间离散度,并且最小化类内离散度的投影直线方向,所以该算法可以有效地对原始样本的投影进行最大化分离,因此本文提出基于Fisher线性判别算法确定最佳投影直线的方法.(2)对于非线性可分情况,通过核函数将原始空间映射到高维甚至是无穷维特征空间,可将非线性可分情况转化为线性可分情况.由于此时并不知道非线性映射ψ(·)的具体形式,所以无法通过Fisher线性判别算法求出特征空间中的最佳投影直线.由于原始样本映射到特征空间后,第1类样本中心m1ψ和第2类样本中心m2ψ所在的直线,是特征空间中两类样本间中心向量m1ψm2→ψ所在的直线,该直线能根据特征空间线性可分样本分布的变化有效地改变方向,使该直线能够较稳定地对线性可分样本的投影进行分离;又由于m1ψ与ψ(m1)、m2ψ与ψ(m2)都不同,所以投影向量ψ(m1)ψ(m2→)不是中心向量,不能随着特征空间线性可分样本分布的变化有效地改变方向,因此以投影向量ψ(m1)ψ(m2→)确定的投影直线,不能像中心向量m1ψm2→ψ所确定的投影直线具有稳定的可分性.因此对于非线性可分情况,本文提出利用特征空间中心向量m1ψm2→ψ所在直线作为投影直线.下面给出投影直线确定方法的具体实现过程.2.3.1线性可分问题的投影直线确定方法对于线性可分问题,利用Fisher线性判别算法确定最佳投影直线的方法如下:设χ1={x11,…,x1l1}和χ2={x21,…,x2l2}是来自于两组不同类别的样本,mi=1Fisher线性判别通过求解maxJ(w)确定最佳投影中心距离:两类样本中心之间的距离.考虑到求解距离的方法具有普遍意义,将所提出的几种距离的求法以定理的方式给出.定理1.已知两类模式的训练样本分别为χ1={x11,…,x1l1}和χ2={x21,…,x2l2},经非线性映射ψ(·)作用后,映射到某一特征空间H,则在特征空间中的中心距离为l1l2∑l1i=1∑l2i=1ψ(x1i),m2ψ=1j)-2其中证明.dH(m1ψ,m2ψ)=(m1ψ-m2ψ)·(m1ψ-m2ψl1∑l1K(x1i,x2直线方向狑,其中之所以最大化函数J(狑)可以确定的最佳投影直线方向狑,是由于J(狑)中的SB和SW分别是类间离散度和类内离散度,通过最大化J(狑)确定方向为狑的投影直线一定满足最大化类间离散度和最小化类内离散度.2.3.2非线性可分问题的投影直线确定方法对于非线性可分情况,本文提出利用中心向量m1ψm2→ψ所在直线作为投影直线.虽然非线性映射ψ(·)并未显式给出,使得特征空间中心向量m1ψm2→ψ的值无法确定,然而这并不影响通过中心向量m1ψm2→ψ确定边界向量集合.原因是特征空间中边界向量集合的确定,只需要确定特征空间中样本之间的相关距离即可(详见2.4节).下面详细给出特征空间中的样本之间的几种必要距离的求法,首先给出其中涉及到的几种距离的说明.间的距离.间的距离.互中心距离:某一样本与另一类别中心向量之自中心距离:样本与样本所属类别中心向量之j=1l2∑l2j)+1Page4定理2.已知两类模式的训练样本分别为χ1={x11,…,x1l1}和χ2={x21,…,x2l2},经非线性映射ψ(·)作用后,映射到某一特征空间H,则原始训练样本x∈χ1与x∈χ2在特征空间中的自中心距离分别为dH(x,m1ψ)=槡K(x,x)-2dH(x,m2ψ)=槡K(x,x)-2dH(x,m1ψ)=(ψ(x)-m1ψ)·(ψ(x)-m1ψ)互中心距离分别为dH(x,m2ψ)=槡K(x,x)-2dH(x,m1ψ)=槡K(x,x)-2证明.下面仅对式(7)进行证明,其余式子证明方法与之类似.烄槡烆+∑l1i=1ψ(x1i)烌l烎1l21∑l1i=1∑l1j=1抽取到边界向量集合中的原始样本接近全部.更进一步可以看出,如果λ=1,那么本文所提的支持向量机训练算法将退化为标准的支持向量机算法.文献[15]采用中心向量作为投影直线,不能保证对样本投影进行最大化分离,所以确定边界向量集合时,必须分两种情况讨论.与文献[15]相比,由于本文采用Fisher线性判别分析确定最佳投影直线,能够将原始样本进行最大化分离,避免了对两种情况的讨论,因此可以通过更简便的约束关系(12)和(13)方便地确定边界向量集合.2.4.2非线性可分情况对非线性可分情况,用映射ψ(·)将原始样本空间转变为高维特征空间,问题就变成了在高维特征空间中的线性可分问题.下面给出非线性可分情况时具体确定边界向量集合的过程:2.4边界向量集合确定2.4.1线性可分情况设χ1={x11,…,x1l1}和χ2={x21,…,x2l2}是两组来自于不同类别的样本,将全体训练样本不加区分地记为χ=χ1∪χ2={x1,…,xl}.下面是本文提出的确定边界向量集合方法的具体实现步骤:1.利用Fisher线性判别分析确定最佳投影直线,即根据2.3.1节所示确定最佳投影直线方向w.2.将所有的原始样本投影到由步1确定的直线上.设j(1jl)表示原始训练样本xj(1jl)相应的投影,设x0P1和P2分别代表类χ1和χ2的投影.分别求出P1和P2之间的最小距离d(P1,P2)、来自于不同类别且满足d(x0i,x0d(P1,P2)的相应的投影x0i和x0的类内最大距离d(P1)和d(P2)(即类内最远的投影距离).3.结合Fisher线性判别分析确定最佳投影直线,设计抽取两类样本集合中对应投影点与中点c0之间距离分别满足如下关系式的原始样本,构造边界向量集合.d(P1,P2)d(P1,P2)其中:x0m∈P1,x0n∈P2,λ为控制边界向量集合大小的参数,0λ1.由式(12)和(13)可知,如果λ接近0,被抽取到边界向量集合中的原始样本很少.如果λ接近1,被K(x1i,x11.求出特征空间的中心距离D,建立数轴,并以m1ψ为坐标原点,以原点右方D个单位为m2ψ.2.分别对特征空间中两类样本中的每一个样本ψ(x),求取自中心距离与互中心距离.根据三角形的唯一性,可知自中心距离、互中心距离、与中心距离对应的三边可组成一个三角形.由余弦定理可知,若自中心距离的平方加上中心距离的平方之和大于互中心距离的平方,则该样本点在中心向量m1ψm2→ψ上的投影点,应该位于m1ψ和m2ψ之间.对于投Page5影点位于m1ψ和m2ψ之间的样本点ψ(x),根据相应的几种距离关系,可求出它的投影点到m1ψ的距离d,并在数轴原点右方d处标记该点.3.对第一类中投影点位于m1ψ和m2ψ之间的样本,分别求出它们的投影点到m1ψ的最大距离D1和最小距离D2.为了避免文献[15]中对两类不同的样本,采用同样大小的边界区域取值范围,导致样本选取不均衡的问题,本文设计了按照固定比例λ,确定边界区域,使样本选取更均衡.本中,选出投影点到m1ψ的距离d满足不等式(a)若D1小于D2,则从投影点位于m1ψ和m2ψ之间的样D2-D12D2+D12-dD2-D12+λD1(14)或D2-D12d-D2+D12D2-D12+λ(D-D2)的样本作为边界向量,其中参数λ与2.4.1节中相同.(b)若D1大于D2,则分别从投影点位于m1ψ和m2ψ之间的第1、2类样本中,选出投影点到m1ψ的距离d满足不等式或的样本作为边界向量.0d-D1+D22D1-D22+λ(D-D1)(17)以上边界向量求解过程说明,只需要确定特征空间中样本之间的相关距离即可确定特征空间中边界向量集合.2.5算法2.5.1线性可分问题下的训练算法针对线性可分问题,提出一种新的支持向量机训练算法:基于Fisher线性判别的支持向量机训练算法(SVMstrainingbasedonLinearFisherDis-criminant,SVMLFD).该算法首先利用Fisher线性判别算法确定最佳投影直线的方向,然后将原始样本投影到所确定的直线上,再根据边界向量集合确定方法确定边界向量集合,最后利用标准支持向量机算法进行分类训练.算法实现的伪代码如算法1所示.算法1.SVMLFD.输入:原始训练集T={(xi,yi),i=1,…,l1+l2}=输出:决策函数fw=lfd(T);/w是利用Fisher线性判别算法确T0=extract(T,w);/T0表示从原始训练集T2.5.2非线性可分问题下的训练算法针对非线性可分问题,本文提出一种新的支持向量机训练算法:基于中心向量投影的支持向量机训练算法(SVMstrainingbasedonMeanVectorProjection,SVMMVP).该算法首先利用特征空间中心向量作为投影直线,然后通过求取特征空间样本间的相关距离间接等价的将样本投影到所确定的直线上,然后根据边界向量集合确定方法确定边界向量集合,最后利用标准支持向量机算法进行分类训练.算法实现的伪代码如算法2所示.算法2.SVMMVP.输入:原始训练集T={(xi,yi),i=1,…,l1+l2}=输出:决策函数f犪=mvp(T,K(x,x));/犪是距离向量,记录着与2.6时间空间复杂度分析2.6.1线性可分情况的时空复杂度分析对于线性可分情况,SVMLFD算法的时间复杂度主要取决于边界向量集合的确定和边界向量集合上的标准支持向量机训练,其中边界向量集合确定的时间复杂度主要由2.4.1节步1、2和3的时间复杂度决定.对于步1:设原始训练集大小为n,寻找Fisher判别准则下的最佳投影方向w的计算复杂度主要由计算类内散布矩阵和其逆矩阵的过程所决定,其时间复杂度为O(d2n)[17],其中d是原始训练样本的维数.对于步2:只需要分别求出两类样本在直线上投影的最大值和最小值,就可以方便地求出步2中涉及的数量.设第1类样本个数为l1,第2类样本个数为l2.计算第1类样本投影总共需要做l1次运算,而求取第1类样本投影的最大值和最小值最多只需要进行2l1次比较.计算第2类样本投影总共需要做l2次运算,同样求取第2类样本投影的最大值和最小值最多只需要进行2l2次比较.因此步2的时间复杂度为O(n),其中n=l1+l2,为样本的总数目.对于步3:需要对每个样本判断是否满足2.4.1Page6节中的不等式关系,因此时间复杂度为O(n).又由于标准支持向量机的时间复杂度是O(n3)[2],因此综上所述SVMLFD算法的时间复杂度为O(d2n+k3),其中,k表示边界向量集合的大小且kn.所以相对于标准支持向量机算法O(n3)的时间复杂度和O(n2)的空间复杂度,SVMLFD算法的时间与空间复杂度分别降低为O(d2n+k3)和O(k2).2.6.2非线性可分情况的时空复杂度分析对于非线性情况,空间复杂度仍为O(k2),时间复杂度则主要取决边界向量集合的确定和边界向量集合上的标准支持向量机训练,其中边界向量集合的确定主要包含以下几个内容的计算:(1)特征空间中心距离以及各样本的自中心距离和互中心距离的计算.(2)各样本在中心向量投影方向上的投影与第1类样本中心m1ψ之间的距离;第1类样本投影到m1ψ的最大距离;第2类样本投影到m1ψ的最小距离.(3)根据2.4.2节中不等式约束关系,确定边界向量集合.下面分别对各个内容的计算复杂度进行分析.内容(1).需要计算的距离分别是特征空间中的中心距离、两类样本的自中心距离和两类样本的互中心距离.根据式(4),(7)~(10),可知这5类距离共同包含对∑l1的计算,可以将这两个数量预先求出.因此这5类距离主要需计算l21+l22次.内容(2).在求出上面5类距离的基础上,利用余弦定理可以求出各样本在中心向量方向上的投影与第1类样本中心m1ψ之间的距离,主要需要计算l1+l2次,而求取第1类样本投影到m1ψ的最大距离,第2类样本投影到m1ψ的最小距离,则一共最多需要比较l1+l2次.内容(3).为了判断各样本投影是否满足不等式约束,需要比较l1+l2次.由于n=l1+l2,因此边界向量集合确定的计算复杂度为O(n2).又由于标准支持向量机的时间复杂度是O(n3),所以SVMMVP算法时间复杂度为O(n2+k3),k表示边界向量集合的大小.因此在kn的情况下,SVMMVP算法与标准支持向量机算法相比也具有更低的时间和空间复杂度.3仿真实验本节选用了两个人工数据集和一个实际问题数据集进行算法的测试,以说明本文所提出的新的支持向量机算法在达到较高分类精度的前提下,具有较低的时间复杂度.3.1线性可分问题实例为了与文献[15]对比,本实验数据选取文献[15]中的实例:两类均匀分布的样本,第1类样本服从分布U([0,2]×[0,0.95]),第2类样本服从分布U([0,2]×[1.05,2]).对于每一类,随机生成800个样本,其中随机选取300个作为训练样本,其余的作为测试样本.本实验分别利用标准支持向量机算法、文献[15]中线性可分算法和本文提出的SVM-LFD算法进行.对于上述3种算法,分别选择C-SVC[18]和径向基函数作为基本的分类算法和核函数,其中C是惩罚因子,σ是宽度参数,x与y是原始样本空间中的n维向量.本实验中通过10折交叉验证[19]来确定最优的参数C和σ.根据文献[15]中线性可分算法采取D=0和μ=0.1,可获得较优结果的情况,本次测试对于参数D和μ的取值不变;对于本文提出的SVMLFD算法,为了有效地权衡时空复杂度和分类精度,取λ=0.1.于是,采用3种算法的5次10折交叉验证的平均实验结果如表1所示,其中对于文献[15]中线性可分算法和SVMLFD算法的训练时间包括边界向量确定时间和边界向量集合上的标准支持向量机训练时间.表1标准支持向量机算法、文献[15]中线性可分标准支持向量机算法无文献[15]中线性可分算法55SVMLFD算法由表1可以看出,标准支持向量机算法的训练时间要比文献[15]中线性可分算法和SVMLFD算法长得多,主要原因在于标准支持向量机算法的求解过程是在整个原始训练集上进行的,而后两种算法的求解过程仅仅是在边界向量集合上进行.尽管后两种算法训练时间还包括边界向量确定时间,但是由2.6节的时间复杂度分析可知,在边界向量集合样本数目足够小的情况下,后两种算法的运行时间较标准支持向量机算法少得多.对比文献[15]中线性可分算法和SVMLFD算法,可以发现本文提出的SVMLFD算法的训练时间更短一些,其主要Page7原因是SVMLFD算法利用Fisher线性判别确定投影直线,所确定的直线满足好的投影直线的特征,能够更好地对原始样本的投影进行分离,可以更为方便地确定边界向量集合,从而可以用更少的原始样本来构造边界向量集合.因此尽管利用Fisher线性判别确定投影直线的操作较文献[15]中确定中心向量所在直线的操作耗费时间多,但根据2.6节的时间复杂度分析可知,在所选边界向量集合样本数目足够小的情况下,SVMLFD算法的运行时间仍然会比文献[15]中线性可分算法的运行时间少.表1还表明SVMLFD算法能达到标准支持向量机算法同样的精度,主要原因是SVMLFD算法从原始训练样本集中抽取的边界向量集合,包括了原始训练样本集中所有的支持向量.这可以从图1中清晰的看出来.图1是从本实验中选取的一幅样本分布图片,其中空心点和实心点分别代表两类不同的样本,加圈的点代表选取的边界向量,五星形点代表由标准支持向量机算法确定的支持向量.由图1可以看出,边界向量集合包括了所有的支持向量,并排除了大多数非支持向量.图1线性可分时边界向量与支持向量分布关系3.2非线性可分问题实例中的实例:两类交错的同心圆样本为了与文献[15]对比,本实验数据选取文献[15]其中θ∈U[0,2π],第1类样本的半径服从均匀分布U[0,6],第2类样本的半径服从均匀分布U[5,10].对每一类随机产生800个样本,其中随机选择300个作为训练样本,剩下的作为测试样本.本实验将对标准支持向量机算法、文献[15]中非线性可分算法和SVMMVP算法进行测试,仍然选择C-SVC算法作为基本分类算法,选择式(18)中所定义的径向基函数作为核函数.本实验中通过10折交叉验证来确定最优的参数C和σ.根据文献[15]中线性可分算法采取取D=10和μ=0.1,可获得较优结果的情况,本次测试对于参数D和μ的取值不变;对于本文提出的SVMMVP算法,为了有效地权衡时空复杂度和分类精度,取λ=0.2.3种算法的5次10折交叉验证的平均实验结果如表2所示.表2标准支持向量机算法、文献[15]中非线性文献[15]中非线性可分算法182.059.691.2标准支持向量机算法SVMMVP算法由表2可以看出,SVMMVP算法与文献[15]中非线性可分算法的训练时间要比标准支持向量机算法的训练时间少得多,主要原因在于这两种算法各自所确定的边界向量集合的大小较原始训练集小得多.由表2可以进一步看出,SVMMVP算法可以选取更少的边界向量进行训练,可以进一步降低训练时间,而精度却较文献[15]中非线性可分算法的高,这主要是由于SVMMVP算法利用了特征空间中真正的中心向量所在直线作为投影直线,可以更好地对特征空间中的样本投影进行分离,从而可以更好地确定边界向量集合.表2还显示了SVMMVP算法几乎可以达到标准支持向量机算法的分类精度,主要原因是对于SVMMVP算法,边界向量集合几乎包括了原始样本集中所有的支持向量,这可以很明显地从图2中看出.图2是从本实验中选取的一幅样本分布图片,其中加号和点分别代表两类不同的样本,星号代表选取的边界向量,加圈的点代表由标准支持向量机算法确定的支持向量.由图2可以看出,边界向量集合几乎包括了所有的支持向量.图2非线性可分时边界向量与支持向量分布关系3.3实际问题数据集实例为了测试本文所提算法在大规模数据集上的性能,利用入侵检测数据集进行试验.本实验所采用的Page8入侵检测数据集为kdd-cup_10_per,来自于KDDCUP99,共包含494021条记录.每一条记录包含41个特征属性,其中34个属性为连续属性,其余属性为离散属性.该数据集包含23个类别,其中“Normal”表示正常连接行为,其它22类(如“Back”,“Neptune”,“Smurf”等)是入侵行为.本实验首先将这23类记录映射到5种类型,即Normal、Dos、R2L、U2R和Probing[20].不同类型的数据分布如表3所示.NormalProbing3.3.1实验数据从kdd-cup_10_per数据集中选择11500个样本.为了更好地进行分类测试,需要对每一种类型选取有效数目的样本,具体分布如表4所示.NormalProbing3.3.2字符属性数值化kdd-cup_10_per数据集中的每一条记录包含4表5入侵检测数据集上SMO算法、文献[15]中非线性可分算法和SVMMVP算法的分类比较文献[15]中非线性可分算法476.1DR=85FR=11DR=86FR=8DR=29FR=7DR=33FR=4SVMMVP(λ=0.2)SVMMVP(λ=0.3)由表5可知,对于大规模数据集,本文所提出的SVMMVP算法可以有效地缩短训练时间,而且随着λ值的增大,SVMMVP算法在分类精确度上几乎可以和SMO算法相媲美,而SMO算法是一种极为经典的支持向量机训练算法.从表5还可以看出,SVMMVP算法可以利用更少的训练时间达到甚至超过文献[15]中非线性可分算法的分类性能.4总结本文提出了一种新的支持向量预选取方法,该方法采用投影的方式进行边界向量集合确定,所确个字符属性,由于支持向量机算法只接受数值向量,所以需要对它们进行数值化,具体方法可以参见文献[20].3.3.3数据规范化此需要对数据进行规范化.本实验通过计算由于原始数据中每个属性的取值范围不同,因将连续属性的取值映射到区间[0.0,1.0],其中V为规范化后的属性值,v为原始数据中的属性值,min(fi)和max(fi)分别为属性fi的最小值和最大值.3.3.4实验结果个性能指标:为了对算法性能进行比较,本实验采用如下两其中:DR表示检测率,FR表示误报率,D1表示异常数据的总数,d1表示被检测出的异常数据的总数,D2表示正常数据的总数,d2表示被误分的正常数据的数目.本实验对SMO算法、文献[15]中非线性可分算法(D=5,μ=0.1)和SVMMVP(λ=0.2,λ=0.3)算法进行测试,选择C-SVC算法作为基本分类算法.由于本实验是一个多分类问题,因此选择一对多(1-v-r)分类方案.本实验仍然选择式(18)中所定义的径向基函数作为核函数,最优的参数C和σ仍然通过10折交叉验证来确定.3种算法的5次10折交叉验证的平均实验结果如表5所示.定的投影直线由于满足好的投影直线的特征,可以更好地对样本的投影进行分离,因此本文方法可以用更少的原始样本来构造边界向量集合.针对得到的边界向量集合进行支持向量机训练,可以在保证分类精度的前提下,进一步降低训练时间和内存占用率.因此,本文提出方法,为有效降低支持向量机算法的时空复杂度,提供了一种新的思路,有一定的借鉴作用.
