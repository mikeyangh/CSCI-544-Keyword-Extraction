Page1广义SOM及其在人脸性别识别中的应用於东军1),3)吴小俊2)HANCOCKEdwinR3)杨静宇1)1)(南京理工大学计算机科学与技术学院南京210094)2)(江南大学物联网工程学院江苏无锡214122)3)(约克大学计算机系YorkYO105DD英国)摘要将适用于欧氏空间的经典SOM模型,借助于黎曼指数及对数映射,推广至一般黎曼流形空间中,得到了广义SOM模型(G-SOM),给出了G-SOM模型的序列及批量学习算法.G-SOM能够在输出空间中保持模式在输入空间中的内蕴拓扑邻域特性,因此,当输入空间为非线性流形时,G-SOM的性能理论上将优于SOM.FERET人脸图像库上的性别鉴定实验支持了理论结果.关键词自组织映射;广义自组织映射;黎曼流形;模式识别1引言Kohonen[1]提出的自组织映射(Self-OrganizingMap,SOM),又称为拓扑保持映射,是一种无监督学习模型.SOM的一个重要特性是可以在没有任何分类信息的条件下,自适应地学习模式在输入空间Page2空间中的欧氏拓扑邻域关系,而不能有效发现非欧拓扑邻域信息[5].为了能够在SOM的输出空间中揭示模式在输入空间中的非欧拓扑邻域信息,有学者提出了Kernel-SOM[6-7]:使用核函数将输入空间中的模式变换到一个高维(甚至是无限维)的特征空间中;然后将该特征空间作为SOM的输入空间.然而,这种方法是核函数依赖的,使用不同的核函数,Kernel-SOM在输出空间中保持的输入模式的拓扑邻域信息将是不同的.换句话说,Kernel-SOM在输出空间中保持的依然不是模式在输入空间中内蕴的拓扑邻域结构.因此,当模式所在的输入空间是非线性流形空间时,SOM以及Kernel-SOM模型均不能很好地在输出空间中保持输入模式的内蕴拓扑邻域结构.文献[8]提出了基于测地距离的SOM(GDBSOM),在学习阶段寻找SOM的最佳匹配单元(BMU)时,使用测地距离而不是欧氏距离,以期在输出空间保持输入模式的内蕴邻域信息.然而GDBSOM在进行输出节点的原型向量更新时,并不能保证更新后的原型向量依旧位于输入空间中,从而降低了在输出空间中保持模式内蕴邻域信息的能力.本文借助于黎曼对数及指数映射,将SOM从线性欧氏空间推广到一般的非线性黎曼流形空间,得到广义SOM(G-SOM).G-SOM使用黎曼距离度量模式在输入空间中的相似程度,并在权值更新阶段保证更新后的原型向量依旧位于输入空间中,从而最大程度上在输出空间中保持输入模式的内蕴邻域结构信息.我们在FERET人脸图像库上进行了人脸性别鉴定实验:使用PGASFS[9]技术从2D人脸图像重构3DNeedle-map,重构出的Needle-map位于黎曼流形S2(n)上;使用G-SOM对Needle-map进行学习及分类.实验结果表明,当模式所在的输入空间为非线性流形时,G-SOM的性能优于SOM.2自组织映射SOMSOM由两层构成:第1层为输入层,第2层为输出层.通常,输出神经元在输出层以一维或是二维规则网格结构排列,并且输入神经元和输出神经元是全互联的.SOM能够将输入空间中(欧氏空间)的模式以非线性的方式映射至输出空间,并在输出空间中保持输入模式的拓扑邻域特性.设SOM有d个输入神经元,K个输出神经元,称输出神经元i(1iK)的权向量狑i∈Rd为原型向量.SOM模型可以使用序列学习算法或是批量学习算法进行学习[1].2.1序列学习算法给定训练数据集{狓i|狓i∈Rd}N习算法的第t次学习步骤如下[1]:(1)从训练数据集中随机选择一个样本作为当前学习样本狓(t).(2)从输出神经元中找到输入为狓(t)时的最佳匹配单元(BMU),记为c(狓(t)):即在所有输出神经元中,BMU的原型向量与当前学习样本最为接近.(3)更新BMU及其邻域内输出神经元的原型向量:狑i(t+1)=狑i(t)+α(t)·hc(狓(t)),i(t)·(狓(t)-狑i(t))其中α(t)为学习效率,邻域函数hc(狓(t)),i(t)可以使用高斯型:式(3)中的狉i和狉c(狓(t))分别是输出神经元i和c(狓(t))在输出层的坐标位置.2.2批量学习算法序列学习算法中,每一步学习只将训练集中的一个样本输入SOM,然后更新BMU及其邻域中输出神经元的原型向量;而批量学习算法每次学习将训练集中所有样本一次性输入SOM,然后对所有输出神经元的原型向量更新.一轮批量学习的基本步骤简要描述如下[1]:(1)划分训练数据集.依据输出神经元的原型向量集{狑j}K狓i(1iN)的BMU为输出神经元j,则将狓i划分到Voronoi区域Vj.(2)计算每个Vj中样本的均值.用nj表示Voronoi区域Vj中学习样本的个数,样本的均值记为(3)更新输出神经元的原型向量.SOM由于结构简单及有效性,已经在众多领域得到广泛应用.当数据分布在欧氏空间中时,SOM可以较好地学习得到模式的拓扑邻域结构信息;然Page3而,当数据分布在一般的黎曼流形上时,直接应用SOM就不再适合.3广义SOM:G-SOM3.1黎曼指数映射及黎曼对数映射设M是一个黎曼流形,犐是黎曼流形M上的一点,T犐M表示在该点处的切平面,狏是该切平面上的一个向量(狏∈T犐M,狏≠0),γ狏方向的测地曲线.那么,狏在点犐(基点)处的黎曼指数映射[10]Exp犐(狏)是指:将向量狏以犐为基点沿着测地线γ狏的黎曼距离d(犐,犐)为‖狏‖,亦即黎曼对数映射[10]是黎曼指数映射的逆映射:以二维单位球面流形犛2为例:欧氏空间中的单位向量犐∈犚3可以看作是位于二维单位球面流形上的点,亦即犐∈犛2.流形犛2上以犐为基点的黎曼指数映射及黎曼对数映射可以用图1表示.图1二维单位球面流形上黎曼指数及对数映射给定M上的N个点{狓1,狓2,…,狓N},其内蕴均值定义为内蕴均值可以使用基于梯度下降的迭代法进行求解[11]:其中,τ为迭代步长.若wi是狓i的权重,带权内蕴均值:狓-=WIntrinsicMeanw1,狓1;w2,狓2;…;wN,狓=argmin狓∈M∑N可以使用下面的迭代式(11)加以求解:狓-t+1=Exp狓-t3.2G-SOM3.2.1序列学习算法当数据分布于弯曲的黎曼流形犕上时,SOM不能正确学习得到输入模式的内蕴拓扑邻域结构信息.以流形犕=犛2为例,若使用SOM序列学习算法,那么迭代式(2)的学习结果是将原型向量狑i(t)对应的点沿着方向狓(t)-狑i(t)移动距离‖Δ‖到达狑i(t+1)所对应的点.这样存在的问题是:学习后的原型向量狑i(t+1)所对应的点不能够保证仍然位于流形犛2上,从而导致不能准确学习得到输入模式的内蕴拓扑邻域结构信息.在这种情形下,最佳的方法是将原型向量狑i(t)对应的点沿着狓(t)与狑i(t)之间的测地线移动距离‖Δ‖到达狑i(t+1)所对应的点.这一目标可以用以下3步来实现(如图2所示):上:狏=Log狑i(t)(狓(t)).Log狑i(t)(狓(t)).流形M上.(a)使用黎曼对数映射将点狓(t)映射到切平面T狑i(t)M(b)计算在切平面上的调整量:Δ=α(t)·hc(狓(t)),i(t)·(c)再以狑i(t)为基点,使用黎曼指数映射将Δ映射回上述3个步骤可以使用下面的迭代学习公式来统一描述:狑i(t+1)=Exp狑i(t需要注意,在确定狓(t)所对应的BMU时,需要使用黎曼距离而不是欧氏距离,即使用G-SOM的迭代学习公式(12),一方面可Page4以达到将原型向量向当前学习样本移动的目的(SOM的学习目标);另一方面,亦可以保证学习得到的原型向量仍然位于输入流形上.3.2.2批量学习算法当数据分布于弯曲黎曼流形上时,SOM的批量学习算法步骤中的(4)和(5)同样不能保证学习得到的原型向量所对应的点仍然能够位于流形上.为此,G-SOM的批量学习算法在SOM的批量学习算法基础上改进如下:用式(14)来代替式(4)计算每个Voronoi区域Vj中所有样本的内蕴均值狓-式(5)计算狓-狑i(t+1)=其中,wj为狓-WIntrinsicMean(w1,狓-实际上,G-SOM是SOM的推广;而SOM是G-SOM的一种特殊情形.以序列学习算法为例,当M为线性流形时,我们有由此,式(12)的右端为Exp狑i(t)(Δ)=狑i(t)+Δ图3=狑i(t)+α(t)·hc(狓(t)),i(t)·Log狑i(t)(狓(t))=狑i(t)+α(t)·hc(狓(t)),i(t)·狓(t)-狑i(t(亦即狑i(t+1)=狑i(t)+α(t)·hc(狓(t)),i(t)·(狓(t)-狑i(t))式(20)完全等同于式(2),亦即,流形M退化为线性流形时,G-SOM的序列学习算法就等价于SOM的序列学习算法.批量学习算法亦有类似的结论,不再赘述.4实验及分析4.1数据集及预处理FERET[12]数据库在人脸识别领域已经成为标准的数据库.FERET数据库中包含有大量的人脸图像分属于不同的人;每个人均有多幅包含不同姿态、视角、表情、照明的人脸图像.此外性别及种族类别信息在该数据库中也得到很好地表达.在下面的实验中,使用FERET的一个子集,该子集包含200个人的200幅图像(103个男性,97个女性,每人一副图像).数据集中的每幅图像均进行预处理:使用剪切、旋转、缩放、对准等几何运算最终得到解析度为142×124的图像,并对图像进行直方图均衡化.图3(a)给出了数据集中的5幅典型的经过预Page5处理后的人脸图像.图3(b)是使用PGASFS[9]人脸形状恢复技术得到的对应于图(a)中第一幅和最后一幅人脸图像的Needle-map.4.2犛2(狀)上的黎曼指数及对数映射我们已经知道,给定2D人脸图像{狓i|1iN},那么使用PGASFS[9]技术,可以得到一个对应的3DNeedle-map集{狀i|1iN},其中狓i∈Rn×1为图像向量,其对应的Needle-map为狀i∈Rn×3,并且狀i的第p行(1pn,n是人脸图像像素的个i∈R1×3是单位向量,其含义是:图像狓i中第p数)狀p个像素在人脸表面上对应点处的单位法向量.向量狀p点,亦即狀p上的点,即狀i∈犛2(n),其中犛2(n)=∏n对于流形犛2,当基点犐=(0,0,1)时,那么切平面T犐犛2上的一个向量可以记为狏=(v1,v2,0).因此黎曼指数映射为[11]Exp犐(狏)=v1·sin‖狏‖对于犛2上的一点犐=(x,y,z),当基点为犐=(0,0,1)时,黎曼对数映射为其中θ=arccos(z).若给定的基点犐=(x,y,z)≠(0,0,1),必定可以通过连续的两步旋转(先绕x轴,再绕y轴,反之亦可)运算将犐的坐标变换为(0,0,1),然后再利用上述两式得到黎曼指数和黎曼对数映射.流形犛2(n)上的黎曼指数映射等价于n个犛2流形上黎曼指数映射的直积,黎曼对数映射类似[9].4.3训练及识别基于减少SOM输入维数及使用人脸局部特征的优势的目的[3],在学习阶段,将每个Needle-map分割为L=hw分别是图像的高度和宽度,h和w分别是子块的高度和宽度.每个子块是分布在流形犛2(m)上的一个点,m=h·w.需要注意的是,在训练阶段,是将每个子块作为输入模式,共有N·L个输入模式.模型学习完毕后,可以得到N个用于训练的Needle-map的BMU矩阵:其中bij表示将第i个训练Needle-map的第j个子块作为输入时SOM模型的BMU.在识别阶段,对于一个待识别的Needle-map,首先将它划分为L个子块;依次将这些子块输入SOM模型,可得到一个BMU向量:其中ti是第i个子块作为输入时SOM模型的BMU.基于犅和犅,使用Soft-KNN机制[3],可以得到一个信度矩阵,用于度量待识别的Needle-map与所有训练样本在各个子块上的相似程度:其中cij是表示待识别的Needle-map与第i训练样本在第j个子块上相似的信度值.用M表示训练样本中男性的集合,F表示女性的集合,那么测试样本属于男性或是女性的信度可以用下面两式分别求得:依据ScoreM和ScoreF值的大小,可以完成测试样本的性别判定.4.4结果及分析为了便于比较,在实验中,G-SOM及SOM的输出层神经元统一配置为30×20的正六边形网格,且均使用批量学习算法.对于每种不同的子块配置(h×w),实验进行10次;每次实验中,随机选择50%的样本作为学习样本(为降低学习过程的偏向性,在随机选择学习样本时,同时需兼顾男女性样本数的平衡),识别正确率取10次实验结果的平均值.表1中给出了G-SOM与SOM在不同子块配置下识别结果的比较.图4则给出了G-SOM在子图4G-SOM在子块配置为4×4时10次实验的Page6块配置为4×4时10次实验的错误识别样本个数分布情况.子块大小h×w4×49790.316283.88×812487.617382.716×1615384.721278.832×3217582.526873.2注:表中错误识别个数是指10次实验中累计识别错误的样本个数;识别正确率是指10次实验的平均识别正确率.从表1可以看出,在子块配置为4×4时,G-SOM及SOM的识别正确率均为最高,此时,G-SOM的识别正确率为90.3%,比SOM的识别正确率高6.5个百分点.同时,可以发现:随着子块规模逐步变大,G-SOM和SOM的识别率都呈下降趋势,但是在相同子块配置下,G-SOM的识别率总是高于SOM的识别率.图4则给出了G-SOM在子块配置为4×4时10次实验的错误识别样本个数分布.观察图4可以发现,10次实验中,每次识别错误的样本个数差异不是很大,表明G-SOM的学习结果是比较稳定的.在实验中,模式分布的输入空间是弯曲的黎曼流形.G-SOM能够在输出空间中保持模式在输入空间中的内蕴拓扑分布特性;而SOM总是假设输入空间是线性的欧氏空间,性能劣于G-SOM在理论上是可以预见的,而实验结果完全支持我们之前的理论分析.我们还在同样的数据集(恢复得到的200幅Needle-map)上实现了PCA+LDA[13]及PGA+LDA[14]的性别识别方法.实验同样进行10次,每次实验中,随机选择50%的样本作为学习样本,识别正确率取10次实验结果的平均值.表2给出了对比结果.SOMPCA+LDAG-SOMPGA+LDA文献[14]提出的PGA+LDA方法是基于人脸形状信息的性别识别的最新研究成果,G-SOM的识别正确率(90.3%)非常接近PGA+LDA方法的正确率(92.4%),并且明显地优于通常的PCA+LDA方法.这表明,将G-SOM用于人脸性别识别是一种有效且可行的方法.5结论本文将经典的适用于线性输入空间的SOM算法推广到一般黎曼流形输入空间得到G-SOM,给出了G-SOM序列学习算法及批量学习算法.理论分析表明:G-SOM是SOM的推广;SOM是G-SOM的特殊情形.G-SOM能够依据模式的实际输入空间特性,在输出空间中保持输入模式的内蕴拓扑分布特性;SOM则总是假设模式的输入空间是线性流形.因此,当输入模式位于非线性流形上时,SOM势必要劣于G-SOM.在基于人脸形状的性别识别上的实验结果支持了上述结论.需要指出的是,对于G-SOM的序列学习算法及批量学习算法而言,重要的一个步骤是需要知道输入模式所在流形之上的黎曼指数映射及黎曼对数映射.如果能够准确知道输入模式位于何种流形之上(如文中的Needle-map必定位于流形犛2(n)上),应用G-SOM是自然的.但是,在很多应用中,往往只能知道输入模式位于某个特定的流形上,却并不能准确知道是何种流形;也就是说,我们不能显式给出黎曼指数映射及黎曼对数映射.这时,应用G-SOM就会存在困难.如何根据训练模式集找到或是逼近数据所在流形的黎曼指数映射及黎曼对数映射,这是我们需要进一步研究的工作.
