Page1片上网络延时差异对存储系统公平性的影响及对策刘胜陈书明尹亚明陈胜刚谷会涛陈小文王耀华(国防科学技术大学计算机学院长沙410073)摘要研究了在基于片上网络(NetworkonChip,NoC)结构的单芯片多处理器(ChipMultipleProcessors,CMPs)中,访存请求的NoC延时差异对存储系统的公平性带来的影响.针对该问题进行了理论分析、抽象,并构建试验模型,从网络规模、报文比例等4个方面对造成访存请求的NoC延时差异的原因进行了讨论.最后提出了一种基于片上网络延时的存储器访问调度方法(SchedulingBasedonNoCLatency,SBNL),与传统的方法相比,能够将NoC延时差异对访存请求公平性的影响降低20%左右,并带来15.7%的执行效率提升.关键词片上网络;延时差异;存储;公平性;调度1引言CMPs是一种公认的能够有效利用单片集成超过10亿个晶体管能力的体系结构.目前的CMPs已逐渐从多核(multi-core,4~16cores)向众核(many-core,16~256cores)发展,如Intel公司的8核的Xeon处理器[1]、STI联盟的9核Cell[2]、SUN公司的8核UltraSPARCT2[3]、Tilera公司64核的TILEPro64和100核的TILEGM-100[4-5]、Intel公司的80核Teraflop[6]等.当处理器中核的数目到达一定规模时,传统的共享总线模式在带宽、功耗、延时及全局同步等问题上均遇到了难以逾越的障碍.NoC技术以成本低廉的点对点分组互连取代传统Page2的总线模式,能够较好地解决上述问题[7].“存储墙”是伴随着现代处理器的出现就一直存在的问题[8].在CMPs中,这一问题依然存在甚至更加突出.CMPs系统中的PE一般通过NoC进行信息交换并共享存储资源.在所有共享的存储资源中,片外存储资源将对系统的性能产生重要影响[9].由于受到芯片管脚的约束和制造工艺的限制,片外存储器控制器的数目、位置和带宽均为受限的,CMPs相对于传统的多处理机系统其存储资源更加珍贵,因而需要更加公平合理地在线程之间进行分配.片外存储资源不公平分配会导致以下问题[10-12]:(1)由于某些线程被不公平地赋予较高的优先级,会使另外某些线程的访存请求等待过长,从而影响系统的整体性能;(2)会使系统软件级程序(如操作系统或虚拟机)中的基于线程优先级调度的策略失效;(3)减少了应用程序的性能可预测性.存储系统的公平性从本质上讲是提高访存请求的服务质量(QualityofService,QoS)从而提高系统整体性能的问题.随着NoC规模的扩大,访存请求的NoC延时差异已逐渐成为影响访存公平性的一个重要因素,如在64结点的CMPs中不同PE访存请求的NoC延时差异已达180个时钟周期(详情见第4节),而一般情况下外部存储器的访问延时只有几十到几百拍.已有的存储器调度算法[10-12],只考虑到了不同线程的访存请求在存储器控制器内部的相互影响,在高效利用存储带宽的前提下通过策略保证不同线程的访存公平性,但是忽略了CMPs中NoC延时差异对访存公平性的影响.本文将对这一因素进行深入分析,并提出解决方案.本文的主要贡献如下:(1)首次提出NoC延时差异将成为影响外部存储器访问公平性的重要因素;(2)对NoC延时差异影响访存公平性的现象进行了分析建模并构建了模拟平台,分析了影响外部存储系统公平性的4个因素;(3)提出了SBNL(SchedulingBasedonNetworkLatency)的存储器访问调度方法,该方法与传统的调度方法相比能够有效地减少NoC延时差异对访存请求公平性的影响,并带来一定的系统效率提升.2相关研究工作已有很多人员对外部存储系统的公平性及QoS进行了研究.关于在存储器控制器(MemoryController,MC)上采取策略调节不同线程的访存公平性的观点最早出现在Nesbit等人[10]的文章,作者基于网络公平队列的概念提出了NFQ(NetworkFairQueuing)调度算法,其QoS目标为:一个线程i如果被分配了系统存储带宽的φi部分,那么其运行速度不应比一个相同的线程单独运行在一个频率是原有存储系统频率φi的存储系统中慢.Mutlu等人[11-12]认为NFQ算法在某些情况下并不能确保公平,并且不同的线程同时运行时,获取存储带宽并不意味着一定能取得相对应的性能.因此提出了一种新的STFM(Stall-TimeFairMemory)调度算法,该方法的QoS定义为:如果CMPs中运行的线程具有相同的优先级,那么其存储器相关的减速(在MC中由于其它线程的影响)应该相同.已有的存储器调度算法,均是在采用FR-FCFS(First-ReadyFirst-Come-First-Service)调度方法的基础上增加了QoS方面的考虑.这些方法仅考虑到了不同线程的访存请求在存储器控制器内部的相互影响,在高效利用存储带宽的前提下通过策略保证不同线程的访存公平性,但是忽略了CMPs中NoC延时差异对访存公平性的影响.将存储器系统的特点和NoC控制结合起来研究的工作在最近得到了较多的关注.Dutt提出了面向存储器的NoC设计方法学[13],认为随着芯片集成规模的扩大,片上资源主要被存储资源占据,同时许多存储敏感的应用被映射到芯片上,因而必须在NoC设计的早期就考虑存储器相关的事宜(如划分层次和访问结构等).Jang等人[14]设计了一种考虑SDRAM特性的NoC路由器,该路由器赋予报文不同的优先级以减少SDRAM的Bank冲突和数据总线竞争问题,从而提高了SDRAM系统的总体性能.Yuan等人[15]观察到在GP-GPU(GeneralPur-pose-GraphicProcessorUnit)体系结构中,每一个核发出的请求本身具有较高的SDRAM行访问局部性,但是经过片上网络传输之后行访问局部性遭到了破坏.作者通过在NoC设计中实现的“HoldGrant”和“Row-MatchingHoldGrant”两种仲裁策略保证了这种行访问局部性,从而采用简单的FCFS调度策略就可以得到与FR-FCFS相近的效果.关于CMPs片上存储系统特别是片上Cache系统的访问公平性问题的研究已经相当广泛.Fedorova提出了Cache公平的线程调度算法[16],可以有效地解决共享L2中的线程冲突问题.Chang[17]提出了协同Cache(CooperativeCache)机制,通过在私有L2基础上引入Cache间干净数据的搬Page3移,可以在不增加存储延时的基础上隔离线程冲突.此外,Abts等人[18]提出了在大量的PE、少量的MC的NoC中如何放置MC的问题,给出了能够使最大通道负载(MaximumChannelLoad)最小的MC放置方法:菱形放置法.同时在提出了CDR(Class-basedDeterministicRouting)路由算法,能够对处理器-存储器型冲突(Processor-MemoryTraffic)进行负载平衡.该文献和本文讨论的出发点不同,但其研究内容却很有参考价值.据我们所知,目前还没有关于片上网络延时的差异对外部系统的访存公平性的影响这方面的研究成果发表,因而迫切需要对这一问题在理论和试验方面进行分析建模并提出较好的解决方案.3片上网络延时差异的现象、原因及参数化建模在基于NoC结构的CMPs中,外部存储器的请求起始于最后一级Cache(LastLevelCache,LLC)的缺失请求.如果是读请求,则在缺失状态处理寄存器组(MissStatusHandlingRegister,MSHR)记录之后,通过NoC传输至目标MC,在MC经过仲裁选择并向SDRAM发送访存命令,从SDRAM返回的数据再次进入NoC中并最终返回给LLC,同时完成MSHR的状态更新.写请求的处理与上述过程类似,只不过前者从SDRAM向LLC返回的是请求的数据,后者返回的是写确认信息.因而我们能够得到式(1),任何一个访问外部存储器的请求延时可以分为三部分:访存请求发向目标SDRAM在NoC中的延时Treq、访存请求在目标SDRAM中的处理延时Tmem和从目标SDRAM得到的数据或写确认信息返回给请求源结点在NoC中的延时Treturn.在这里我们忽略了访存请求从网络报文解析为请求信号和返回数打包为网络报文所花费的时间,这样能够简化下述分析过程,并且对问题实质影响不大.式(1)中的Treq和Treturn均可视为NoC中的报文延时,在采用虫孔路由的NoC中,报文的无冲突延时包含两部分:报文头传输延时和后续微片(flit)连续传输延时.如式(2)所示[19],Γ1p是一个报文在NoC中传输所花费的时间;hi,j是结点i到结点j之间的跳步数;tc为无拥塞时一个微片通过一个开关和一条链路所需要的时间;L为报文的长度;b为链路带宽.在考虑网络冲突的NoC中,引入tw这一参数,tw表示存在拥塞时报文头在开关节点处平均等待时间,式(2)将变为式(3):而式(1)中的Tmem由文献[20]可知,主要由存储器带宽受限导致的停顿Tm_bw和存储器本身的延时Tm_latency两方面的因素构成,如式(4)所示.将式(4)和式(3)代入到式(1)中,得到在基于NoC结构的CMPs中,外部存储器的访问延时,如式(5)所示.在确定的NoC参数及报文协议下,式(5)中的参数tc、Lreq、Lreturn和b为固定常数,并且由SDRAM的特性可知[21],Tm_latency的变化范围相对较小(如在采用开页策略的SDRAM中行命中与行冲突的延时一般相差十几拍左右).因此不同访存请求的访存延时的差异主要体现在hi,j、tw和Tm_bw这3个参数,其中hi,j主要由请求结点与MC的相对位置、网络规模、MC在NoC中的位置等因数决定,tw主要由应用程序的通信、访存特性(如通信流量模型、报文注入率、访存报文所占比重等)决定,Tm_bw主要由存储器带宽、存储器调度策略等决定.显然在基于NoC结构的CMPs中,外部存储器的访问延时由多种因素共同决定,具有动态特征,因而不能够精确预测.本文第4节构建模拟平台,对上述构成Ttotal差异的原因进行综合分析.由式(3)可知,片上网络延时由hi,j和tw决定,前者具有确定性,后者具有随机性.我们考虑图1所示的情况:在8×8的2维mesh结构下,采用X-Y维序路由,MC放置在芯片的上下两端,结点a和结点b分别访问同一外存空间(MC1控制的一段外存空间),由于结点a和MC1的距离比结点b和MC1的距离大(hi,j_a=15,hi,j_b=1),则结点a的访存请求在NoC中的延时要远远大于结点b的访存请求在NoC中的延时.即对应式(1)中Treq_aTreq_b且Treturn_aTreturn_b,现有的存储器调度策略一般采用FCFS或修改的FR-FCFS调度方法,这些方法保证了不同线程的Tm_bw相差不大,即Tmem_a≈Tmem_b.由Page4式(1)易知Ttotal_aTtotal_b,即不同的结点对同一外存空间的访问延时差异较大(这种差异根据第4节的模拟在256结点下可达400拍以上).同样的道理我们可以推出同一节点对不同外部存储空间的访问延时也具有很大的差异.由式(5)可以看出在NoC规模、MC数目及位置固定的情况下,不同结点访存的hi,j必然存在较大差异,可供我们调节的主要参数是Tm_bw,我们可以采用一定的策略使距离MC较远的结点在竞争访存通道时具有较高的优先级,即当某个请求的hi,j值较大时,使其Tm_bw值较小,从而避免或减弱NoC的延时差异对访存公平性的影响,这也是本文第5节提出的SBNL调度方法的由来.图1不同结点对同一外存空间访问的NoC差异性示意图4片上网络延时差异对存储系统的公平性的影响因素分析4.1模拟平台的搭建本文构建了一个节拍精确的NoC+MC模拟平台,并采用合成的流量模型对影响存储系统公平性的各种因素进行分析.该模拟平台主要由一个NoC模拟器和多个SDRAM的MC模型组合而成.能够全面模拟不同PE对不同存储空间的访存请求在NoC上同时存在,并经过仲裁进而访问MC,然后返回数据的过程.NoC的主要参数如表1所示.在模拟时我们采用了开环模拟的方法,通过Bernoulli过程向每个结点注入报文[19],在模拟器经过预热之后统计每个访存请求花费的节拍数,然后再进一步处理.路由器之间的线延时参数名称拓扑结构PE的数目MC的数目路由延时交换策略通道缓冲数目虚通道数目路由算法报文大小NoC+MC模拟平台中的MC的主要参数如表2所示,每个MC固定连接4个PE,拥有一个存储器通道,控制8个SDRAMBanks和256MB的空间.SDRAM的时序参数模型如表3所示,该模型从Micron公司的SDRAM参数手册抽象而来,能够精确地模拟存储器主要的时序约束,如存储器命令的延时、不同存储器命令之间的最小间隔、刷新周期等.参数名称参数值参数名称参数值tRCDtCAStBLtRAS18cyclestRFC51cyclestRP4.2评价函数对CMPs片外存储系统的公平性进行评测并不是一件容易的事情,已有的研究工作从不同的角度定义了存储系统的QoS目标[10-11],这些QoS目标也可以当成CMPs片外存储系统的公平性的评价函数.然而已存在的QoS目标都是从系统的角度出发,其本身受许多其它因素的影响(如Cache抖动等),并且不利于数学建模.因此本文直接从式(1)定义的Ttotal出发,通过对Ttotal的不同组成部分进行数学统计,进而对CMPs片外存储系统的公平性进行评测.将一段时间内访存请求的总延时、访存请求在MC和存储器中的延时和访存请求在NoC中的延时分别定义为集合A、B和C,且假设一共记录了NPage5个访存请求,即A={Ttotal_i|i=1,2,…,N},B={Tmem_i|i=1,2,…,N},C={TNoC_i|i=1,2,…,N}.本文采用式(6)~(8)3个函数即平均访存延时Taverage、延时均方差LSD(LatencyStandardDevia-tion)和NoC延时非均匀性比例UFRNoC来进行分析.其中Taverage表示所有访存请求的平均延时;LSD衡量了集合A中的所有访存延时与平均延时的偏离程度,即访存请求的公平性;UFRNoC表示了NoC延时的差异占访存请求非公平性的比例,UFRNoC的范围在0与1之间,其值越接近于1说明NoC延时的差异对外部存储器的公平性影响越严重.UFRNoC=StandardDeviation(C)+StandardDeviation(B)4.3影响访存请求公平性的因素分析本节分析了网络规模、MC的位置、报文注入率、报文比例这4种因素对外部存储系统公平性的影响.由于前三者概念明确,这里主要讨论报文比例这一因素的由来.将应用程序中不同线程之间的片图2不同网络规模下的访存公平性分析如图2(a)所示,在相同的报文注入率下,网络规模越大,每个访存请求的访存延时也越大.在相同规模的网络中,每个访存请求的延时随着报文注入率的变高而变大.如图2(b)所示,在相同的报文注入率下,访存请求的均方差随着网络规模的增加而变大,即访存请求延时随着网络规模的扩大而变得越来越分散.同时,在注入率比较低时,访存请求的均方差和变化范围都较小,而在中等注入率和高注入率下,访存请求的均方差比较大.如图2(c)所示,上报文(包片上远程共享Cache的访问、Cache协议的维护等)定义为普通报文,将访问外部存储器的报文(包括外存数据请求和数据返回等)定义为访存报文,普通报文与访存报文的比值称为报文比例.报文比例的范围,在目前的文献中尚没有明确的结论.我们可以进行如下定性分析,决定普通报文与访存报文的比例的最重要因素是片上LLC(假设为二级Cache,且不考虑片上存储器为便签式存储器的情况)的共享情况.如果L2完全私有,则NoC中的报文将全部是访问外部存储器的报文;如果L2是分布式共享的,那么普通报文与访存报文的比例取决于远程L2和片外存储器的访问比率(和应用程序本身的特征相关)以及所采用的Cache一致性方案.根据文献[17],在分布式共享L2中,远程L2和片外存储器的访问比例主要在11到431范围之间.因而下文论述中我们分析报文比例从全部是访存报文到501这一范围对访存请求公平性的影响,并且以301作为一个经验值进行讨论.我们分别模拟了2×2、4×4、8×8和16×16的2DMesh结构在不同注入率下,结点直接发送报文的情况(普通报文与访存报文的比例为301,MC采用FCFS方法调度).在模拟平台预热(经过10万次报文传输)后每个结点向不同的MC发送1万次报文,记录所有的访存请求的延时并进行处理,得到图2所示结果.尽管NoC延时差异在访存请求非公平性中的比例存在波动(在中等注入率时存在下降),但还是占据一定的分量,特别是64、256结点时都超过了50%.因而能够得出,随着网络规模的扩大,网络负载的增加,NoC延时差异已逐渐成为影响访存公平性的一个重要因素,必须予以考虑.在已经商品化的基于NoC的众核CMPs中[5-6],MC均放置在芯片的上下两端(如图1所示).文献[15,18]提出了MC的菱形放置方法(如Page6图3所示黑色的PE或router拥有外部存储器控制器),本文用NoC+MC模拟平台对MC上下端放置和MC菱形放置分别进行模拟(NoC规模为8×8,MC采用FCFS调度策略,普通报文与访存报文的比例为301),得到图4所示的结果.由图4可知MC菱形放置法比上下端放置法拥有更高的报文吞吐率,这与文献[20]分析结果一致,此外MC菱形放置法能够在一定程度上减少访存请求的延时,提高访存请求延时的公平性,因此如果忽略这种放置方法对NoC均匀性和可扩展性带来的问题,MC菱形放置法是一种不错的选择.图4MC上下端放置与MC菱形放置分析结果对比报文比例和应用程序相关,是影响访存请求公平性的一个重要因素.在64结点的NoC平台下(MC上下端放置,FCFS调度),分别在重负载(注入率0.26)、中等负载(注入率0.18)、轻负载(注入率0.06)采用不同的报文比例进行模拟,得出如图5所示结果.可知,报文负载越重,访存请求的Taverage、图5不同报文比例下的访存公平性分析5SBNL访存调度方法通过第3节的定性分析和第4节的定量模拟,我们发现在MC采用上下端放置的芯片布局方法中,NoC延时差异这一因素对外存访问公平性影响较大,并且随着网络规模、报文注入率的提高而变得LSD和UNRNoC均越大.在相同的报文负载下,报文比例越小(即访存报文越多),访存请求的平均延时越大,在报文比例大于某一区间之后,访存请求平均延时变小,访存请求的均方差也变小.NoC延时差异在访存请求非公平性中的比例随着报文比例的变化存在最小值,这个最小值与网络负载相关.日趋严重,因而迫切需要研究人员提出较好的解决方案.本节我们提出SBNL访存调度方法,这种调度方法从不同的线程访问外部存储器的优先级入手,通过在每个MC中增加NoC延时预估表,赋予距离MC较远的请求较高的访存优先级,同时兼顾访存效率,能够对访存公平性和系统性能进行有效的改Page7善,并且对现有的软硬件结构改动较小.5.1主要方法(1)当访存请求进入MC时,由请求源节点坐标查找对应的NoC预估延时,作为初始的优先级;当存储器通道处理一个访存请求时,通道中的其它请求的优先级加t(根据通道中的请求是行命中、行关闭还是行冲突,t进行相应的变化);(2)设Pmax为当前通道队列中的请求的最高优先级,将Pmax与参考优先级Pref进行比较,若Pmax<Pref则采用FR-FCFS调度方法;若PmaxPref则跳入(3);(3)具有Pmax优先级的请求优先处理.SBNL调度方法是一种充分考虑NoC延时差异的存储器调度方法,通过在MC的入口处设立NoC延时预估表,按照访存请求的源节点在NoC延时预估表获取相应的延时预估值.这样在存储器调度时若发现某个线程的请求到达MC之前已经花费了过多的时间,则调高该请求的优先级.NoC延时预估表和Pref可由操作系统或程序员根据网络规模、应用程序的特性等提前配置,具有较强的灵活性.5.2参数设置依据在5.1节阐述的SBNL调度方法中,每个PE_i在MC_j中的NoC预估值由平均网络跳步数、网络负载权重、线程公平因子三方面因素决定,其中平均网络跳步数在一定NoC规模和确定性路由策略下是固定的;网络负载权重和应用程序的报文负载相关,操作系统或程序员可以根据不同的应用设置不同的网络负载权重;在之前的论述中我们只考虑应用中不同的线程具有相同的访存优先级的情况,这里增加了线程公平因子这一因素,操作系统或程序员可以通过改变某个PE的NoC预估值来调整其对应线程的访存优先级.t的值主要受限于两方面的因素:(1)外部存储器的本身参数.不同的存储模型具有不同的行命中、行关闭、行冲突的访问节拍数(如在我们选取的DRAM模型[21]中上述节拍分别为9、14、18);(2)MC与外部存储器的频率比值.Pref的值取决于操作系统或程序员对线程的访存请求延时超出平均访存延时的容忍程度,Pref越小表示应用程序对外存系统的访问公平性要求越严格,当Pref无限大时,SBNL调度方法就转换成了传统的FR-FCFS调度方法.5.3实现开销由上述方法可知,SBNL方法主要的硬件实现开销包括NoC延时预估表、参考优先级Pref寄存器、加法器、比较器等.假设网络规模为N×N,NoC延时预估表的每一项有16bit,MC为M个,每个MC中包含一个同时容纳16个访存请求的通道,则主要的硬件开销包括2M×N2个字节的存储空间、16×M个16位的加法器和15×M个16位的比较器,硬件开销不大.5.4性能分析我们将采用以下两种方法分析所提出的SBNL调度方法相比于传统的FR-FCFS方法在公平性和效率方面的提升.我们选取ΔLSD%=LSDFR-FCFS-LSDSBNLLSDFR-FCFSSBNL调度方法相比传统的方法在提高系统访问外存公平性的评价参数.分别在NoC+MC模拟平台为2×2、4×4、8×8、16×16网络规模下,MC上下端放置、中等报文注入率(在NoC为2×2、4×4、8×8、16×16规模下,其值分别为采用0.35、0.25、0.18和0.06)和报文比例为301的情况下,使每个结点向其它结点均匀发送报文.其中SBNL调度方法中的NoC延时预估表设置为8×hi,j,假定MC与外部存储器的频率为41(即根据行命中、行关闭还是行冲突,t分别设置为36、56和72),假定操作系统或程序员对线程的访存请求延时超出平均访存延时的容忍程度为访存平均延时的6倍(则由图2(a)得:在2×2、4×4、8×8、16×16规模下,Pref的值分别为720、1000、2100和2520).我们统计了不同的网络规模下的LSDFR-FCFS、LSDSBNL及ΔLSD%的值如表4所示.由表4可知,SBNL调度方法相比传统的方法,在不同的网络规模下均能显著地降低访问外存请求的延时均方差,提高了访问外存请求的公平性,同时随着网络规模的扩大,SBNL调度方法对访存公平性的提升效果愈明显.网络规模LSDFR-FCFSLSDSBNLΔLSD/%2×24×48×816×1686.7同时我们给出在网络规模为8×8下,不同的报文注入率和报文比例下ΔLSD%的详细值(SBNL调度方法的延时预估表值随报文注入率增加而加大,其余参数不变),如表5所示.从表5中可以得出Page8如下结论:在网络规模为8×8时,SBNL调度方法均能够有效地降低访存请求的均方差(平均在20%左右,最大达到36.5%),提高系统访存的公平性.随着报文注入率的增加,SBNL方法对访存公平性的提升愈明显,这是因为报文注入率的增加将会引起更多的网络拥塞,使NoC延时的不均匀性更加显著,SBNL方法能够发挥较大的作用.当报文中包含的访存报文较少时,SBNL方法对访存公平性的提升较小,这是因为同一时刻MC通道中包含的访存请求个数有限,SBNL方法发挥的余地有限.表564结点下SBNL与FR-FCFS方法的Δ犔犛犇%值报文比例全部36.529.814.128.85136.228.320.319.710125.822.118.615.015122.523.513.411.520124.320.012.711.325115.214.111.910.230110.18.86.53.43519.78.56.55.74017.36.26.34.9此外,为了评估SBNL方法对系统全局性能的提升,本文在网络规模为8×8的NoC+MC平台上进行固定负载情况下线程运行情况的试验.在平台预热之后,为每个PE安排了5000个访存请求(同一个PE的访存请求拥有不同的行局部性,在数据返回之前,每个PE允许最多发送4个访存请求),在系统运行时,若某个PE共接受的访存数据的数目达到5000,则认为该PE的工作完成,不再发送新的请求.在报文比例为301,中等负载情况下,分别运行SBNL调度方法和FR-FCFS方法,统计了在不同的时间段(以500个时钟周期为采样单位)运行结束的PE的数目.如图6所示,采用SBNL调度方法时,在系统运行到17000节拍时,有6个PE完成了5000个访存图664结点下固定工作负载PE完成的节拍分布图请求的既定任务,而在21500节拍时,64个PE均完成了既定的访存任务;而采用FR-FCFS调度方法,在系统运行到19500节拍时,第一个PE才完成了既定的访存任务,在26000节拍时,全部PE才完成了既定的访存任务.可见,相比FR-FCFS方法,SBNL方法能够显著地减少定额工作负载的平均完成时间和最后完成时间(分别为12.8%和15.7%).5.5与已有的NFQ和STFM方法比较NFQ方法[10]和STFM方法[11]均没有考虑NoC延时的差异.如NFQ方法以线程访存请求到达MC的时间作为访存请求虚拟运行时间的开始,这显然是不准确的,在基于NoC的系统中,这种方法将会完全忽略访存请求的NoC延时;STFM调度方法中的Tshare直接由PE计算并立即传递到MC中,这在基于NoC的CMPs结构中是不可能实现的.本文提出的方法充分考虑NoC延时的差异,并且能够与NFS和STFM方法相结合,因而具有比较明显的优势.6总结及进一步的研究NoC延时差异逐渐成为影响CMPs中不同线程访问外部存储器公平性的一个重要因素,本文对这一问题进行了建模并构建了模拟平台,从4个方面分析了对外部存储系统公平性的影响,提出了SBNL的存储器访问调度方法.该方法与传统的调度方法相比,能够有效地减少NoC延时差异对访存请求公平性的影响.下一步的工作是在系统级模拟平台中寻求SBNL方法的优化及改进措施.
