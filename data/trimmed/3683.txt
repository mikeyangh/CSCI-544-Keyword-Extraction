Page1基于数据源依赖关系的信息评价方法研究张志强1)刘丽霞1),2)谢晓芹1)潘海为1)方一向1)1)(哈尔滨工程大学计算机科学与技术学院哈尔滨150001)2)(闽南理工学院信息管理系福建石狮362700)摘要当前很多的数据管理应用都需要从多个数据源集成数据,每个数据源都会提供一组值,并且不同的数据源常常提供相互冲突的数据值.为了提供给用户高质量的数据值,关键是数据集成系统能够解决数据冲突问题,提取出正确的数据值.文中对已有的真值发现算法进行了分析与总结,通过考虑处理同一个值的不同表现形式和改进的选票算法,作者对现有方法给出了改进,改进后的方法可以更有效地在众多冲突数据中找出正确的数据值.关键词数据源;数据值;数据集成系统;真值;选票算法1引言随着互联网的快速发展,Web上的数据越来越多,已经成为一个巨大的数据库,里面的信息随着时间的推移不断在变化,这种变化主要体现在两个维度,一个是指客观世界对象信息的增删变化,例如亚马逊网站上增加了某本新书的信息;另外一个维度Page2确定哪个数据源提供的信息更准确,质量更高.影响数据值质量的原因有很多.首先,数据值随着时间的变化在不断地更新变化,错误的信息可能会潜入到数据中,一些数据可能会过时.这对于决定哪些值曾经是正确的,并且在哪个阶段是正确的是一个难题.其次,数据源通常有不同的质量,一个自然的想法是当我们判断真值的时候将数据源的因素考虑进去.影响数据低质量的原因有很多,一些数据源在它们初始提供数据的时候就造成了一些错误,一些数据源虽然提供了正确的数据,但是没能及时进行信息的更新.第三,一个数据源会从其它的数据源那里复制一些数据,通常不会知道所复制的这些数据是否正确或是否是过时的.此外,数据源之间的复制依赖关系也会随着时间的变化而不断地变化.本文的主要工作就是研究如何解决数据冲突问题,查找准确的数据值.数据冲突问题早期在数据处理领域中就已经被提了出来[1].后续的一些数据集成系统也相继提出了一些解决策略[2-4],文献[5]对数据集成系统中的冲突处理策略进行了总结.Cho等人[6]提出了一种自动维护本地数据库拷贝与初始数据源真值一致性的方法.由于这些工作的背景,在解决数据冲突问题时,往往假设数据源都是独立的,相互之间没有关联.但是在Web的环境下,同一个对象的信息往往会分布在多个数据源中,而这些数据源的数据具有较强的关联,文献[7]注意到了Web数据的这个特点,考虑了Web数据源之间的复制关系,给出了刻画数据源复制依赖关系的方法,并且引入链接分析的方法[8]来对数据源的可信度进行评判.Berti-Equille等人[9]也注意到了数据源依赖这个问题,并给出了问题的详细定义和描述.文献[10-11]等进一步考虑了数据源的准确性因素,并将其与数据源的依赖关系结合起来,获得了较好的效果.Dong等人[12]对集成问题中的冲突解决研究工作给出了详细的总结和分析.文献[13]采用一种不同的概率投票方法,将数据源的可靠性和描述的准确性之间的关系运用在投票的思想中,同时考虑不同描述之间的影响,另外还考虑了投票数据源的权威性.本文则在分析总结上述工作的基础上,进一步考虑了同一对象数据值具有不同表达形式这个因素以及结合了数据源投票值与数据源准确率不一致的情况,提出了一种改进的方法,实验结果表明,本文的方法提升了结果的准确率.本文第2节将对信息评价问题的主要相关工作进行总结与分析;第3节将介绍本文提出的基于数据源依赖的信息评价方法;第4节介绍了本文采用的实验方案,通过实验对提出的新方法进行评估,并对实验结果进行分析;第5节对全文进行总结并给出今后的研究方向.2主要相关工作介绍本节将主要介绍该领域中的几个经典工作.由于本文工作是在文献[7,10]的基础上进行的改进,并且选取与这两个文献相同的数据集进行测试.因此为了能够获得更客观的对比结果,本文选择这两个文献的工作作为对比对象.下面将主要介绍这两个文献的主要方法.2.1基于数据源和信息可信度的数据评价方法这类方法的基本思想是每一个数据源都有一个信任度,直观上来说,在给出的信息中我们更相信那些信任度比较高的数据源所提供的信息,所以数据源的信任度对数据信息准确性的影响是存在的,而数据源的信任度又是根据它所提供的数据值的可信度决定的,所以数据源的信任度与数据值的可信度是相互影响的,利用迭代算法的思想去计算数据源的信任度和数据值的可信度.这类方法的典型代表是Yin等人[7]提出的ACCUNOD算法,该方法的思路是每个数据源的信任度是由该数据源提供的所有数据值的可信度期望值得到的,由式(1)计算每个数据源的信任度就是求该数据源w所提供的所有数据值可信度的平均值:式中,F(w)是数据源w提供的数据值的集合,s(f)是数据值的可信度.相比之下,估计一个数据值的可信度是很困难的事,对于每一个对象都可能会有很多的数据值,这些数据值之间是相互冲突的.假设f1是对象o的数据值,数据源w1和w2都提供f1这个值,假定数据源w1和w2是相互独立的,这样f1是错误的概率是(1-t(w1))(1-t(w2)),f1不是错误的概率是1-(1-t(w1))(1-t(w2)).如果f是对象o的唯一的数据值,那么f的可信度是s(f)=1-∏w∈W(f)t(w)),W(f)是提供f值的数据源集合,经过变换Page3后,上式改成τ(w)=-ln(1-t(w)),那么数据值的可信度可以表示成σ(f)=-ln(1-s(f)).对于每一个对象实体总会有很多的数据值,这些数据值之间是有一定关联的,如存在两个数据值f1和f2,f1是由很多信任度很高的数据源提供的数据值,而f1和f2具有很强的关联,那么有理由认为f2也得到了这些信任度高的数据源的支持,所以要增加f2的可信度值,即σ(f2)=σ(f2)+ρ·∑o(f1)=o(f2)σ(f1)·imp(f1→f2)式中,ρ是0到1的一个变量,它控制着数据值之间的相关关系;imp(f1→f2)表示f1与f2的相关性;o(f)表示数据值f对应的对象.该模型考虑到了数据源的准确性对数据值的准确性也有影响.通过计算数据源的准确性来计算数据的可信度.而数据的可信度又是由数据源的准确性决定的.不同质量的数据源提供的数据的准确性是不同的,我们当然会更相信那些准确性比较高的数据源,但是本算法没有考虑数据源之间复制关系对数据值的影响.2.2基于数据源依赖关系的数据评价方法Dong等人[10]考虑了数据源之间的复制依赖关系,提出了BENE算法、MAL算法和ACCU算法.2.2.1BENE算法善意模型是假设提供数据信息的数据源都是好的,它们会尽量提供正确的信息,检测到错误的数据并将其改正,正确的数据要比错误的数据更加稳定.具体的思想是在某一时刻对某一对象的数据信息进行监测,根据概率公式计算数据源之间的依赖关系.依据提供该数据值的数据源依赖关系图对数据值进行选票,比如对于一个数据值v,总共有5个数据源提供这个值,那么v获得的选票数就是5,然而这样却忽略了数据源之间可能存在的复制依赖关系.假设有3个数据源是相互复制的,那么它们相当于重复地进行了投票,所以调整后的选票数就是x(x<5),当然这里面考虑了数据源的复制概率影响.选票数越多说明该数据值越准确,因为提供该值的独立数据源比较多.具体的思路是先计算数据源之间的依赖关系,这里认为所有数据源的初衷都是善意的,所以只要求出数据源之间的依赖关系就可以了,然后根据这个依赖关系计算数据值的选票,利用贪心迭代算法得到稳定的结果.数据值的选票算法是这样的,首先考虑一个特v值的数据源集合,假设在集合珚S0(v)中的一对数据源,如果我们知道其中的一个数据源复制了另一个数据源,并且还知道哪个是复制者,那么我们就可以画出一个依赖关系图,每一个数据源就是一个结点,对于每对数据源,如果有S1复制S2的数据值,那么就存在一条边,从S1指向S2,如(S1→S2).对于每一个属于珚S0(v)的数据源S,我们定义d(S,G)为图G中数据源S的出度,表示数据源从多少个数据源复制了数据.如果d(S,G)=0,说明数据源S是独立的,它的选票值为1,否则,数据源S复制数据源S的数据值.数据源S独立于数据源S提供一个数据值的概率是1-c,c是数据源S复制数据源S的概率.那么有数据源S独立于其它数据源提供v值的概率是(1-c)d(S,G),式(3)表示了关于图G,数据值v的总选票数:该方法虽然可以知道依赖关系,但是不能确定依赖关系的方向,所以必须要计算所有图的选票数,这样计算起来很麻烦,所以引入了估计选票数的算法,并将其应用在ACCU算法中.2.2.2MAL算法恶意模型考虑到了提供信息的数据源不全都是好的事实,因为有一些数据源会刻意隐藏自己的复制行为,为了不让其它数据源发现它是复制源,它会将复制过来的数据进行一些修改,我们称这类数据源为恶意数据源.为了查找出恶意的数据源,我们必须要知道数据源之间依赖关系的方向,所以该算法解决了找出数据源复制方向的问题.数据源的依赖关系方向不同,它们共同提供正确的值和错误的值的概率也不同.该算法是在BENE算法的基础上考虑了数据源之间的复制方向.数据源集合S里面有善意的独立源和恶意的复制源.假设每个对象共有n个错误的数据值(n>1),当一个恶意的复制源独立地提供一个数据值时,选择其中一个错误数据值的概率是1/n.考虑两个数据源S1和S2,直观来讲,恶意的复制源比善意的复制源更有可能将正确的值改成错误的值,如果S2提供的正确值是S1提供的值的子集,那么很可能数据源S2复制了数据源S1,但是如果数据源S2提供的值和数据源S1提供的值很少或没有相同的,那么S1和S2就可能有一个是恶意的复制源.珚Ot为数据源S1和数据源S2提供相同的正确值Page4不相同的错误值的对象实体集合.珚Od为数据源S1和数据源S2提供不同值的对象实体集合,可以将其划分成3个集合:珚Od1代表的是数据源S1提供正确数据值的对象实体集,数据源S2提供错误的数据值;珚Od2代表的是数据源S2提供正确数据值的对象实体集,数据源S1提供错误的数据值;珚Od0代表的是S1和S2提供了不同错误数据值的对象实体集.此外,定义S1复制S2表示成S1→S2,相反S2复制S1表示成S2→S1.若S1与S2具有依赖关系,计算Φ的概率(某一时刻对数据集进行观测可能会出现的所有情况的空间[9],用Φ来表示,例如数据源S1和S2同时为对象o提供数据值,可能会是同一正确的值,也可能会是同一错误的值,还有可能是不同的错误值.这3种可能构成了一个观测空间).如果S1与S2是相互独立的,由条件概率公式得出其中,ε是S1或S2提供错误数据值的概率,ε2是S1和S2都提供错误数据值的概率,(n-1)/n是S2提供一个不同于S1的错误数据值的概率.如果S2复制S1的数据值,由条件概率公式得出P(o∈珚Ot|S2→S1)=(1-ε)·c(9)P(o∈珚Of|S2→S1)=ε·cP(o∈珚Od1|S2→S1)=(1-ε)·(1-c)(11)P(o∈珚Od2|S2→S1)=ε·(1-c)·1P(o∈珚Od0|S2→S1)=ε·(1-c)·n-1式(9)和(10)考虑的情况是S2复制S1的数据值,这个数据值是正确值的概率是1-ε,错误值的概率是ε.式(11)~(13)考虑的情况是S2独立的提供v值(其概率为1-c,c为复制其它数据源的概率),如果S1提供一个正确的数据值,那么S2提供一个正确的值的概率是1/n.提供一个不同的错误的值的概率是(n-1)/n.当S1复制S2的数据值时,由条件概率公式得出P(o∈珚Ot|S1→S2)=(1-ε)·c(14)P(o∈珚Of|S1→S2)=ε·cP(o∈珚Od1|S1→S2)=ε·(1-c)·1P(o∈珚Od2|S1→S2)=(1-ε)·(1-c)(17)P(o∈珚Od0|S2→S1)=ε·(1-c)·n-1这样具有不同的依赖关系方向,就会得出不同的概率值.下面是利用数据源之间的依赖关系来计算数据值的选票数.每一个数据值对应一些依赖关系图,如图1所示3个数据源S1、S2和S3具有4个依赖关系图,所有依赖关系图的选票数之和就是这个数据值的选票数(每一个依赖关系图边的权重为数据源之间的依赖关系概率值).存在的一个问题就是当数据源的个数增加时,依赖关系图的数量也会成指数的增加.在这里Dong等人设计了一个简单的计算数据值选票数的算法,该算法大大降低了时间复杂度和空间复杂度.其基本思路是先计算提供v值的数据源的选票数,再将这些数据源的选票数求和,就是数据值v的选票数,具体过程在文献[2]中有详细描述.两种模型相互比较,它们都会从原始的数据源那里共享错误的信息,BENE算法模型能够判断出这些错误的信息,但是BENE算法模型计算得到的恶意复制依赖关系概率要比MAL算法模型的低,并且也不能够判断出复制依赖关系的方向,甚至当它发现该复制是恶意复制时,它还要假定为善意复制,并进行投票计算.换句话说,恶意模型适合于恶意数据源的查找,但是却忽略了一些将错误数据值改成正确数据值的善意数据源.即使它发现了善意的复制源,也会将它所提供的所有值忽略掉,尽管有一些值确实是独立的.2.2.3ACCU算法ACCU算法是在BENE算法和MAL算法的基础上提出的,该方法既考虑了数据源的依赖关系,也考虑了数据源的可信度,主要的思想是通过利用式(19)计算数据源的可信度:式中,P(v)表示数据值v是正确的概率;珚V(S)表示数据源S提供的所有数据值的集合;m表示数据源Page5计算P(v)是通过式(20)和(21)的概率公式和贝叶斯公式完成的:P(ψ(o)|vtrue)=∏S∈S-式中,ψ(o)表示对象o的数据值空间;珚So表示给对象o提供数据值的所有数据源集合,珚So(v)表示给对象o提供数据值v的数据源集合;v值是对象o的某一特定的数据值.利用式(22)计算每个数据值的可信度C(v).式中,I(S)表示的是数据源的选票数,该算法虽然考虑了数据源的可信度和数据源的复制依赖关系,但是没有对数据值进行很好的处理,例如实际中一个对象的同一数据值在不同的数据源中往往具有不同的表现形式,导致不同表示形式的数据值会得到不同的可信度值,同时也降低了真实数据值在结果集中的影响程度,有可能正确数据值的可信度分值低于错误数据值的可信度分值.3本文方法根据对现有几种方法的总结与分析,我们发现现有方法虽然考虑了数据源可信度、数据值可信度、数据源的依赖关系以及三者之间的关联关系等因素,而且可以较好地刻画数据源之间的复制依赖关系,但是仍然存在以下两点不足:(1)没有考虑对象的同一数据值具有不同表现形式的实际情况,而这种现象在实际中十分普遍,且对真值的确定有直接影响.(2)实际中一个数据值的选票值与其正确性概率两者并非总是一致的,有时可能会相差较大,而一个数据值的可信度与两者都有关联.目前的方法只考虑了数据源的可信度和选票值,没有考虑数据值正确性概率的因素.为此,本文对ACCU算法进行了改进,增加了对同一对象数据值不同表示形式的判断,并增强了数据值可信度的计算,算法的基本流程如图2所示.图2中(1)~(4)步骤,数据源依赖关系和数据值选票数的计算与ACCU算法完全一致,由于篇幅原因这里不再详述.下面将分别介绍数据源可信度和数据值的正确概率以及数据值可信度的计算方法,并且对数据值之间的相似性判断给予详细介绍.3.1数据源的可信度计算数据源的可信度影响着数据值的准确程度,通常我们会更加相信那些可信度比较高的数据源,就好像我们向别人打听消息一样,有的人爱说实话,他的话可信度就会很高,而有些人,却很喜欢毫无根据地乱说,他的话可信度就会很低,所以我们不会去听第二类人的话,而比较相信第一类人的话.对于数据源也一样,可信度越高的数据源它所提供的数据值的可信度也就越高.依据这一理论,考虑数据源可信度对数据值的正确性影响是必不可少的.我们采用以下计算数据源的可信度公式:式中,m是数据源S提供的值的个数;V(S)是数据源S提供的数据值的集合;T(S)为数据源S的准确性;Vote(v)是数据值v的选票数.该公式不同于ACCU算法中求数据源准确性的方法,该公式的优点是在于数据值的选票分值是表示每个数据值准确程度的.式(19)是ACCU算法中计算数据源准确度的公式,它只是利用数据值的正确概率,然后计算数据源的可信度,而式(23)更能够体现出数据源的可信度,因为每个数据源所提供的数据值的可信程度是不同的,为了更好地体现出数据源的可信度,利用数据值的选票数来计算每个数据源的可信度要比式(19)的方法好,而且通过实验验证了该方法的准确度要高于ACCU算法的准确度.Page6又因为准确率应该是一个0到1之间的数,而上面等式的结果可能是一个大于1的数,所以需要进行指数变换,将其值限制在0到1之间,上式改为我们利用得到的数据源可信度计算得到数据值3.2数据值的正确概率和可信度计算v的正确概率P(v),由条件概率贝叶斯公式得P(ψ(o)|vtrue)=∏S∈S-P(ψ(o))=∑v∈ν(O)P(v)=P(vtrue|ψ(o))=式中,n是对象o具有的数据值总数;ψ(o)表示所有提供给对象o的数据值空间.通过以上公式重新调整数据值v的可信度,如式(28)所示:经过改进确定数据值的可信度利用式(28)来计算,该公式涉及到求数据值的选票数和数据值的正确概率,然后求它们的平均值.因为每个数据值的选票数和正确性概率的值差距可能很大,可以综合两者的值,通过不同的角度来考虑数据值的准确度,能够更接近数据值v的准确率,P(v)是通过条件概率的理论基础和数据源的准确度来计算的,Vote(v)是通过计算数据源之间的依赖关系概率,利用贝叶斯网络概率的原理计算的,通过两种方法的结合让数据值的准确性判断更加接近于真实世界的描述,提高查找正确数据值的概率.上述方法在数据源可信度和数据值正确率以及数据值可信度等方面对原ACCU算法进行了改进.下面我们将介绍本文的另一个主要改进:数据值之间的相似性计算.3.3数据值之间的相似性同一个数据值的表示形式也会有很多种,例如,“Jia-weiHan”、“HanJiawei”,或“J.W.Han”等均指同一个人的名字;又如日期2012年8月20日,可以表示成“08/20/2012”,或者是“2012-08-20”等形式.这种情况在实际中十分常见,幸运的是实际当中很多的值往往是有规律的,我们可以利用这些规律进行相似性的判断.本文采用的方法很简单,首先将所有的值都转换为字符串,然后再根据不同的特点将这个串分解成单元的集合,最后根据分解得到的单元集合进行相似性处理.本文考虑了3种主要的数据值表示方式,第1种用英文表示,第2种用中文表示,第3种用数据值型数据表示.下面分别介绍一下这3种相似度处理方法.3.3.1英文字符串型的数据值例如两个英文字符串“O’Leary,TimothyJ,andO’Leary,LinaI”和“O’Leary,TimothyJ./O’Leary,LindaI.”,在不考虑字符串的相似度时,之前的方法将它们看作是两个不同的串,因为这两个串不能完全匹配.但我们知道这两个串表示的是同一个值,为此本文采用了如下的分词方法对字符串进行处理.字符串是由一组不同含义的单词所组成,将单词集作为二元变量表中的属性集合,设定为集合Z,假设字符串String1和字符串String2的单词包含于集合Z中,设q是字符串1和字符串2中共有的单词总数,s是字符串1中存在,字符串2中不存在的单词总数,r是字符串2中存在,字符串1中不存在的单词总数,那么采用传统的相似度计算方法中的非恒定相似度评价系数方法(Jaccard系数)来处理,即两个字符串间的相似度公式如下:3.3.2汉字形式的数据值所谓义原词[14]是指用来描述对象某一特征最小意义的词.数据值是一个词组或一段文字描述的,那么对于一个数据值A来说,可以将其分解成一组义原词集合,这样计算一对数据值的相似度就是对这两个数据值所对应的义原词词组进行相似度计算,其计算公式如下:Sim(A,B)=∑m式中,A、B表示两个数据值,数据值A分解成{a1,a2,…,am},其中ai代表数据值A分解的第i个义原词,数据值B分解成{b1,b2,…,bn},其中bj代表数据值B分解的第j个义原词,例如:A=“我爱中国”和B=“我爱母亲”,那么A的义原词集Page7合为{我,爱,中国},B的义原词集合为{我,爱,母亲},利用式(30)计算数据值A和B的相似度就应该是0.5.3.3.3数值型的数据值由于数值型的数据以数字的形式表示,如果是简单的数据值,我们可以将其看作是义原词,但是对于有些数据,如日期的表现形式,我们还需要进一步划分.如20110609、06/09/2011和2011-06-09,它们具有不同的表现形式但是却表示相同的意义,利用数值型数据的特点我们采用树形结构模型将数据值拆分,分解成最小的义原词然后进行对比.3.4数据值的可信度修正基于以上理论,依据数据值之间的相似性求解sim(v,v),我们有式(31):C(v)=C(v)+ρ·∑v≠v由上面公式可知计算数据值的可信度C(v),需要先求解数据值的可信度C(v)和数据值之间的相似度sim(v,v),具体算法如下.算法1.数据值相似性算法.输入:Eo,Fo输出:珚Simo(vj)//Eo集合:对象o的数据值集合//Fo集合:对象o的每一个数据值的可信度C(v)集合//珚Simo(vj):数据值vj与其它数据值的相似度列表1.当集合Eo不为空时2.j=k=1;3.当变量j小于等于Eo中数据值的最大数量时4.变量k小于等于Eo中数据值的最大数量时5.通过式(29)或(30)计算sim(vj,vk);6.如果C(vk)属于集合Fo7.计算C(vk)sim(vj,vk),并将该值加入到对象编号表1ACCU和NEWACCU的部分实验结果对照表9780073-516677“O’Leary,LindaI.J.”9780072-999389“Yacht,Carol/Crosson,Susan”“Yacht,Carol/Crosson,Susan”“yacht,carol;crosson,susan”9780072-843996“Haag,Stephen/Perry,JamesT./9780072-232172“DennisSuhanovs,”9780072-230611“Scambray,Joel”155860-9350“Courage,Catherine”155860-8893“Goldman,Ron”155860-846X“Almeroth,KevinC.”131872-893“Dann,WandaP.”131463-055“Geary,David”“Dann,WandaP.”“DennisSuhanovs”从表1中很容易就能看出NEWACCU算法的结果准确率要高于ACCU算法的准确率.当数据集8.变量k自加返回到4处,直到k大于Eo中数据值9.变量j自加返回到3处,直到j大于Eo中数据值10.程序结束,返回集合珚Simo(vj).通过对比每个数据值的可信度值来最终断定哪些值才是查询对象的正确数据值.4实验与结果分析4.1实验数据本实验所用的数据集来自于DongXinLuna和YinXiaoxin两位博士.下面介绍一下本文的数据集.第1个数据集是Books_Authors,该数据集是网上书店提供的有关书的信息,需要查询书的作者信息.第2个数据集是MovieRunTime,该数据集提供了电影的播放时长信息,需要查询电影的准确播放时间长度.运用本文提出的改进算法对两个数据集进行处理,实验结果表明本文提出的算法无论在数据源数量的变化,还是数据对象数量的变化等方面,得到的准确率都是最好的.我们定义本文的算法为NEWACCU算法.4.2Books_Authors数据集上的实验本实验是针对在网上书店上查找书的作者信息的应用背景,对于同一本书不同网站提供的该书作者信息可能是不同的,我们将考察不同算法在冲突的数据值中查找正确作者信息的能力.我们随机选取了10个书的对象,分别执行需要进行对比的各种算法.表1给出了ACCU算法和NEWACCU算法的部分对比结果.数据增加时,我们发现每种算法的准确率会随着数据值的数量增加而改变,并呈现递增的趋势,也就是Page8说,数据值的数量越多,真值查找的准确率就越高.当数据值的数量增加到110个的时候,NEWACCU算法、ACCU算法、BENE算法和MAL算法的准确率变得很接近,都达到了最大值,并接近于1,如图3所示.图4给出了数据集中数据源数量的变化对数据值准确率的影响情况.数据量增加时各算法模型的准确率都呈现递增的变化趋势.BENE算法是将所有数据源都认为是善意的,即不承认恶意数据源的存在.这样,当数据集中恶意的数据源如果很多的话,就会影响到BENE算法判断正确数据值的准确率.由于NEWACCU算法中加入并增强了计算数据源的可信度环节,大大降低了BENE算法中出现的问题.同样在MAL算法中由于过多地考虑恶意数据源对数据值的影响,而错把那些善意的数据源认为是恶意的数据源,即使这些数据源是将错误的数据值更正为正确的数据值.因此这也影响到了MAL算法的运行结果,使得在计算数据值准确率时不能有很高的准确率.ACCUNOD算法中只考虑了数据源的可靠性,假设数据源是独立存在的,没有考虑数据源之间还存在复制的关系,但是实际中这种理想的独立关系是不存在的,所以大量的数据源进行复制时就严重影响了真值判断的准确率.ACCU算法虽然也考虑了数据源的依赖关系和可靠性,但是在性能上不如NEWACCU算法,因为NEWACCU算法不但利用数据值的选票值来计算数据源的可信度,而且还在数据值的可信度计算上将数据值的选票值和正确概率进行均值计算,目的就是使得结果更加符合真实情况,实验证明我们的假设是成立的.我们知道影响某一数据值v准确率的因素有两个,一个是数据源的可信度,另一个是独立数据源的个数.在选票计算中如果一个数据值被多个独立数据源所提供的话,那么它的选票值就会相对较高,在计算数据值的可信度时,如果提供该值的数据源的可信度很高,那么这个数据值的可信度也会相对较高.通过实验我们观察到当数据源为100个的时候各种方法的准确率如表2所示.本文提出的NEWACCU算法的实验结果准确率比ACCU算法提高了4%多,当数据源数量增大时,准确率还会更高一些.4.3MovieRunTime数据集上的实验这个数据集记录了500部电影,由于本数据集的查询内容是数值型数据,所以在数据处理中要比第1个数据集容易一些.利用BENE算法、MAL算法、ACCUNOD算法、ACCU算法和NEWACCU算法分别进行实验,查找电影的播放时长.表3描述了实验结果.12angrymen2001:aspaceodyssey10514814824hourpartypeople11511542ndstreetabeautifulmind136134134achristmasstory9797aclockworkorange137137137afistfulofdollars101101101afistfulofdynamite13813813812angrymen2001:aspaceodyssey10510510524hourpartypeople11511711742ndstreetabeautifulmindachristmasstoryaclockworkorange137137137afistfulofdollars101101101afistfulofdynamite138138138Page9通过上面的实验结果可以看出,本文提出的NEWACCU算法的准确率要高于其它算法的准确率.随着数据源数量的增加,错误值的变化趋势如图5所示.从图中可以看出当数据源的数量增加时,ACCU算法和NEWACCU算法的错误值数量都在减少,说明当数据源的数量增加时,数据源之间的依赖关系体现得更加明显,准确刻画数据源依赖关系是提高数据值可信度计算的必要前提.当数据源的数量增加时,ACCUNOD算法的错误率反而增多,因为ACCUNOD算法没有考虑数据源的依赖关系,重复投票的比例变大,所以导致当数据源数量增加时,使得ACCUNOD算法计算出的结果错误率增加.从图5中还可以很容易的看出来,NEWACCU算法的错误值数量总是要小于ACCU算法和ACCUNOD算法,因为NEWACCU算法中计算数据源的可信度时是利用数据值的选票值进行计算的,这样在数据源的可信度计算中考虑了数据源之间的复制依赖关系,更能够体现出每个数据源的可信度,从而提高了结果集的准确率.由于ACCU算法的性能要比BENE算法、MAL算法的好,所以这里只利用了ACCU算法、ACCUNOD算法和NEWACCU算法的实验结果进行了比较.随着数据对象数量的增加,错误值的变化趋势如图6所示.从图中可以看到ACCUNOD算法的错误值的数量一直都很高,原因是当数据对象的数量增加时,数据源之间的复制依赖关系也会越明显,由于数据源复制行为并不是一直都存在的,复制源在某一时刻也可以作为独立数据源存在,提供自己的数据信息,或者更改错误的数据值.在这种情况下理想的独立数据源空间是不存在的,ACCUNOD算法是没有办法准确地判断出正确信息的.所以还要考虑到数据源之间的复制关系,ACCU算法就能够较好地解决这一问题.ACCU算法是BENE算法和MAL算法的改进,它是基于数据源依赖关系求解数据值的可信度,通过计算数据源的可信度来重新调整数据值的可信度.NEWACCU算法在处理数据值可信度时要优于ACCU算法,不仅在计算数据源可信度时提高了性能,而且还考虑到了数据值的相似度问题,这也是NEWACCU算法在运行结果中准确率高于其它算法的原因.表4是当数据对象为100个的时候各种算法的准确率对照表.NEWACCU算法的实验结果准确率比ACCU算法提高了2%多,当数据量增大的时候,准确率还会更高一些.4.4小结本节介绍了实验环境并深入地分析了实验结果,通过几种算法结果的对比,我们分析了问题出现的原因,进而提出更有效的解决办法来提高算法的性能.其中,用两个数据集分别进行实验,在第1个数据集实验中,我们通过调节数据源和某一个数据对象所对应的数据值的数量,观察了各个算法模型的实验结果变化,从中我们发现所有算法的实验结果准确率都会随着数据值或者数据源的数量增加而增加;在第2个数据集实验中,我们也得到了相类似的结论,即随着数据源或数据对象数量的增加,所有算法的准确率都增加了.通过实验我们了解到当数据集的数据量增大时,数据源之间的依赖关系体现得越明显,BENE算法、MAL算法、ACCU算法和NEWACCU算法的计算结果就越准确.由于NEWACCU算法中考虑了数据值之间的相似性判定问题,而且在计算数据源的可信度时与ACCU算法有所不同,在计算数据源的可信度时利用了每个数据值的选票值进行计算,通过这两点的改进使得Page10我们的算法NEWACCU的准确率高于ACCU的准确率.5结论本文的主要工作是改进了ACCU算法,加入了数据值之间的相似度问题处理,并且改进了数据源的可信度计算.在计算数据源的可信度时利用数据值的选票值来计算,数据值的选票值是基于数据源的依赖关系计算的,所以利用数据值的选票值计算数据源的可信度更能体现数据源的特征.实验结果表明改进后的算法确实提高了结果的精度,在众多冲突数据中可以更好地找到正确的数据值.后续工作将继续扩展数据集的类型以及建立一个更全面的真值发现方法评价框架,进一步深化相关的研究工作.致谢本实验所用的数据集由DongXinLuna和YinXiaoxin两位博士提供,在此感谢她们的指导和答疑解惑!
