Page1BDSim:面向大数据应用的组件化高可配并行模拟框架1)(中国科学院计算技术研究所计算机体系结构国家重点实验室北京100190)2)(中国科学院大学北京100049)3)(华为技术有限公司中央研究院北京100085)4)(高效能服务器和存储技术国家重点实验室北京100085)5)(数学工程与先进计算国家重点实验室江苏无锡214125)摘要大规模并行模拟是研究大数据体系结构的重要方法,对大数据应用及众核体系结构的发展有着不可替代的推动作用.然而,目前的模拟技术不能满足大数据体系结构研究的需求,主要体现在模拟速度慢、配置过程复杂以及可扩展性差等方面.为了解决此问题,评估面向大数据应用的高通量众核体系结构的性能与功耗,该文提出了面向大数据应用的并行模拟框架———BDSim.该框架基于组件化思想,将功能组件与框架服务单元组成并行功能单元,并可根据负载情况,自由配置组件与框架服务单元之间的映射关系.为了提高组件之间的通信和同步效率,该文提出了一种非阻塞无锁通信优化方法,和一种CMB保守同步算法的优化算法———NMTRT-CMB同步算法.模拟不同并发规模的基于2D-Mesh网络的众核系统的实验结果表明,与基于锁的并行通信方法相比,框架采用的非阻塞无锁通信优化方法可以提高并行模拟速度约10%,该算法与CMB同步算法相比,NMTRT-CMB同步算法可以减少空消息数量达90%以上.关键词组件化并行模拟框架;并行离散事件模拟;非阻塞无锁通信;CMB算法;高可配;大数据1引言随着网络购物、物联网、舆情监测等应用的迅速发展,数据中心需要处理的数据量呈爆炸式增长.面对快速增长的数据规模,面向传统应用的处理器体系结构在处理速度、功耗以及数据带宽等方面都表现出了不足与缺陷.大数据处理不同于用于科学计算的超级计算机,不是追求尽量缩短单个任务的计算时间,而是在允许的时间范围内处理尽可能多的任务(数据或线程)[1-2].因此,现有的众核结构已不能满足实际需要,体系结构需要重大变革[3].近年来,为了满足大数据应用的实际需求,众核体系结构的研究在学术界和工业界都得到了一定的发展.针对众核处理器性能、功耗、温度等方面的改善也成为当前的研究热点[4-10].然而,目前的模拟技术,显然已不能满足针对大数据处理的大规模众核处理器的模拟要求,限制了众核体系结构的进一步发展,主要体现在模拟速度慢、配置过程复杂、可扩展性差等方面.通常,一款模拟器的开发需要权衡以下4个方面:精度、速度、可扩展性以及可配置性.随着众核体系结构各功能部件数量与实现复杂度的增加,传统串行模拟器因为速度的原因已经严重不适于大规模众核处理器的模拟,成为限制模拟器发展的主要因素.例如,目前常用的串行模拟器GEM5[11]、MARSS[12],模拟速度大约在200KIPS左右.基于此速度,模拟一个真实物理核的一秒钟大约需要几个小时,模拟一千个核的一秒钟,几乎需要一年的时间.而与串行模拟器相对的并行模拟器能并发模拟功能部件执行状态,显著提高模拟速度,被广泛用于众核体系结构的模拟.然而,大规模并行模拟器的开发面临诸多挑战.首先,被模拟结构复杂.随着体系结构不断发展,不仅模拟系统内模块的数量逐渐增加,模块的功能也更加复杂,导致模拟器开发任务量大、周期长.其次,模拟器并行困难.由于模拟器系统是紧耦合设计,导致并行过程中任务难以划分、并行单元难以管理、同步控制难以实现,此外并行模拟过程中的消息通信也成为制约性能提升的重要因素.最后,系统构造过程复杂.不同的配置形成的不同的体系结构(包括:网络拓扑、存储层次、一致性协议等)导致目标系统性能迥异,因而大规模模拟带来了配置上的沉重负担.所以,灵活的配置功能对体系结构研究是至关重要的.在对大规模并行模拟系统的强烈需求下,学术界与工业界涌现出大量的并行模拟器.比较有代表性的研究工作有Simics[13]、Graphite[14]、SimFlex[15]、SST①、Hornet[16]、SlackSim[17]、ZSim[18]等等.但是这些模拟器研发初期便以不同的侧重点为目标,导致其并不能完全满足高通量众核处理器的模拟需①RodriguesAF.Thestructuralsimulationtoolkit,http://Page3求,例如Simics拥有极其丰富的模拟组件用于搭建系统模型,在学术和工业界都得到了广泛的应用,但对基于共享访存的多核模拟系统并没有得到很好的支持;SST采用模块化搭建方法,具有较好的可配置和扩展性,但是Barrie同步方法导致其速度不尽人意;ZSim则采用不同的加速方法来提高模拟速度,但专用性太强,灵活性和可扩展性较差.由此可见,现存的并行模拟器在模拟速度、灵活性、可扩展性及对大规模并发模拟等方面的支持上均不能满足其要求.针对目前的现状,为了找到高效的解决方案,本文提出了支持大规模并行系统模拟的并行模拟框架———BDSim.该模拟框架基于组件化思想,将功能模块抽象成功能组件,以动态链接库的形式存在和加载,增强了模拟的灵活性和模块的复用性.模拟框架采用高效的通信方式和同步算法,提高了执行效率.同时支持高可配设计模式,提供文件和图形化两种配置方法,降低了配置的复杂性,提高了框架的易用性.实验分析和应用举例表明,BDSim并行模拟框架能够很好地支持大规模并发系统的模拟,适用于大数据处理的众核处理器体系结构的研究.本文的主要贡献如下:(1)基于组件化思想.所有功能模块以组件库的方式加载至模拟框架中,已开发的组件以资源库的形式存在.提出了FS(FrameworkService)概念,作为组件运行的代理,是并行的最小单位.(2)实现高效的非阻塞无锁通信方法.加快消息的处理速度,提高整体框架的执行效率.(3)实现高效的NMTRT-CMB(基于空消息时间戳请求标志位)同步算法,同时支持粒度可调的松散同步算法.BDSim提供两种同步算法,一种是基于CMB(Chandy-Misra-Bryant)同步算法[19]的改进算法:NMTRT-CMB同步算法.另一种是粒度可调的松散同步.(4)支持高可配设计模式.BDSim提供两种配置方式:一种是通过配置文件,另一种是通过图形化操作界面.本文第2节描述相关工作及研究动机;BDSim模拟框架的实现细节及各种算法应用将在第3节讨论,包括基础框架、端口、组件和FS等模块的实现及非阻塞无锁通信方法和NMTRT-CMB同步算法;实验和结果分析将会在第4节给出;第5节通过应用举例,描述如何使用BDSim搭建高效的大数据模拟评估模型;最后对论文进行总结及阐述未来的研究方向.2相关工作和研究动机随着众核体系结构规模日益庞大,大规模并行体系结构的模拟变成巨大的挑战.目前,大多数模拟器都是串行执行.串行模拟器用一个主机线程来模拟整个目标系统,当目标系统的核数增加时,分配给单个核的模拟性能就会下降.目前已经有许多方法被用来加速模拟,包括并行模拟、直接执行[20]、FPGA加速[21]等等.下面简要介绍几款支持大规模体系结构模拟的模拟器及其关键技术.ZSim[18],是MIT和斯坦福大学推出的一款千核级并行模拟器,目标是解决众核并行模拟的速度问题.ZSim通过使用基于指令驱动的时序模拟配合二进制翻译机制实现单核模拟组件加速.在并行加速方面,提出了Bound-Weave执行算法,将模拟分成Bound和Weave两个阶段.Bound阶段首先进行一定时间的功能模拟,同时记录必要的访存序.Weave阶段根据之前记录的访存序驱动并行模拟,输出时序统计信息,极大地加快了模拟速度.虽然对于众核模拟能够达到很高的速度,但是对于其他功能模块的模拟,例如网络、存储等模块,并不是其研究重点.同时不支持组件化,不能够灵活配置并行度,限制了其使用范围.MARSS[12],是一款结合了QEMU和PTLsim的支持多核模拟的全系统模拟平台.MARSS具有QMEU的全系统支持功能及二进制翻译加速功能,也具有PTLsim精确的乱序核模拟功能.同时也提供详细的性能统计分析功能和配置功能.不足之处是MARSS模拟平台是基于X86指令集的全系统模拟,且可扩展性比较差,严重影响了二次开发,且对于大数据众核模拟并不能提供很好的支持.Asim[22],是Intel研发的一款针对复杂计算机系统的模块化模拟框架.Asim通过模块化和重用性解决模拟的复杂性.通过模块化的实现方法,可以将复杂的性能模拟分解成离散的单模块,简化了实现的复杂性.模块的可重用性可以将已经验证的模块重新用于新环境中,既保证了模块的可靠性,也加速了模拟模型的实现过程,提高了开发效率.然而,Asim的最大缺陷在于其模拟的非并行化,这对于大数据的模拟需求来说是难以回避的问题.SST是一款开源、模块化且支持并行执行的模拟框架.模块主要包括处理器、储存器及一些网络模型.SST已经广泛应用于HPC系统的模拟.它采用Page4了模块化的搭建方法,允许目标系统使用已经存在的组件来组装实现.在并行模拟方面,使用Barrie的方法进行同步操作.然而,此种同步方法会降低模拟的速度.Manifold①,是一项开源软件工程,旨在为多核体系架构提供建模和模拟的可扩展性基础框架.方法是通过使用成熟的并行离散事件模拟(PDES)算法及并行时间步进技术实现粗粒度的并行模拟以获取模拟的可扩展性.Manifold对于并行模拟具有很好的支持,但是并不支持松散同步机制,影响模拟的速度.SIMFLEX[15],是一款基于组件设计思想的模拟框架,具备精确的采样统计功能,支持复杂模型开发,能够确保在快速模拟过程中获取到具有代表性的统计数据.SIMFLEX的创新之处在于它将独特的编译时方法应用于组件链接过程,能够运行不经修改的商业负载,且能获取到精确的模拟数据.但缺点是SIMFLEX不支持并行模拟机制.Simics[13],是一款商用模拟框架,拥有丰富的模拟组件,在学术和工业界都得到了广泛的使用.处理器、存储器、系统控制器、各种总线和网络结构等目标系统都可以模拟实现.同时提供方便的软件测试和调试环境,也支持回滚调试和执行.为了提高模拟速度,Simics推出了SimicsAccelerator加速器[24].它能充分地利用多核宿主机来提高目标系统的模拟速度.然而,大规模并发系统及共享访存式多核系统并没有得到很好的支持.除此之外,还有众多针对大规模体系结构的模拟模型,例如BGLsim[25]、BigSim[26]、Hornet[16]、Parti-tionSim[23]、SlackSim[17]、SimHPC[27]、WWT[28]等并行模拟器.在众多模拟加速技术中,并行模拟因为能够利用目标结构天然的并行特征,能在低成本CMP计算机上实现,成为一种常用的有效加速技术.但是,针对大数据处理的众核模拟系统需达到千核万线程量级.以上各模拟器在模拟规模一旦达到千核万线程量级时,在速度、灵活性、易用性、可扩展性等方面会暴露出各种缺点,并不能很好地满足需求.另一方面,传统的体系结构已经不能满足大数据高通量的需求.Ferdman等人[3]在当前流行的处理器硬件上针对规模化大数据应用做了大量的实验.结果表明,在传统的处理器架构中表现出色的核内乱序、指令级并行、层级Cache、访存预取等结构设计在大数据应用下表现平平,甚至成为影响性能的瓶颈问题.因此,亟需一款灵活、易用、高可配、高效率的并行模拟器,以解决大数据处理结构研究和制造的模拟需求.考虑到以上各模拟器的优势和缺点以及针对大数据应用的模拟特点,本文提出了一种基于组件化的面向大数据应用模拟的并行模拟框架BDSim.BDSim采用离散并行事件模拟机制,首次提出了FS(FrameworkService)概念,支持灵活的并行粒度调节.使用优化的非阻塞无锁通信方式,提高了模拟速度.并支持NMTRT-CMB同步算法和松散粒度同步算法.在配置方面,BDSim提供了方便灵活的配置方法,相对于其他模拟器,在高通量众核系统建模过程中,极大地减少了使用的复杂度,减轻了研究人员的负担.3BDSim结构与特点本节从组件化、通信、同步及配置等方面对BDSim实现结构及特点进行详细描述.3.1组件化框架3.1.1相关概念PDES(ParallelDiscreteEventSimulation).并行离散事件模拟.PDES根据事件和时间戳驱动模拟执行,相对于传统的系统时间驱动方法,PDES具有较高的执行效率[29].图1展示了SDES(串行离散事件模拟)和PDES之间的关系.可以看出,SDES可以由一个或多个逻辑功能单元构成,而多个SDES按照时间轴同时运行构成PDES.(1)组件逻辑功能单元.使用者在BDSim提供的接口协议之下定义的为实现特定功能的模块单元,以动态连接库的形式存在,可根据配置,动态加载至BDSim模拟框架上.(2)端口组件属性之一,消息通信处理单元.端口的数量是由与其相联的其他组件的个数决定.当目标模型①ManifoldProject.http://manifold.gatech.edu.2011Page5拓扑结构确定后,端口会得到一个全局编址.端口地址会插入到消息中,用于路由和寻址.(3)FS(FrameworkService)框架服务单元,并行执行的基本单元.所有功能组件必须挂载到FS之上.FS相当于组件代理,处理拓扑、通信、同步等关键问题.通过使用FS,一方面可以将用户从繁杂的并行同步和通信处理中解脱出来,交由FS处理,用户只关注于组件的功能实现;另一方面,FS的使用使得模拟框架高度模块化,这使得大规模数据处理并行模拟成为现实.3.1.2框架架构BDSim框架结构如图2所示.最底层是多核宿主机.之上的模拟服务层是框架的主体部分,由FS组成,实现整个模拟框架的同步和通信等功能,为上层的各种组件运行提供支持.模拟层即按照模拟需求实现的各功能组件,所有组件的功能之和构成了整个目标系统的模拟功能.最上层是应用层,具体实现目标二进制程序的加载和用户控制的响应.BDSim将框架拆分成离散的FS单元,与功能组件绑定在一起.每个FS和与其绑定在一起的组件运行在一个线程之上.通过这种方式,一方面可以方便地实现并行粒度调节;另一方面为组件开发提供了良好的模块化基础.图4通信结构示意3.2BDSim通信在BDSim模拟框架中,拓扑关系由组件端口的互连确定,消息的收发由FS处理.类似TCP/IP协议,组件间的通信划分成3层结构,层与层之间消息的传递是透明的,每一层负责完成自己所在层的任务,消息依次按照层次之间的协议分别进行处理.通信协议栈如图3所示,组件间同步和通信功能在BDSim层中实现,用于维护各并行单元之间的同步关系及消息传递和处理.组件之间进行通信时,发送方将消息打包,利用模拟框架提供的通信接口将消息送往发送方组件所在的FS.FS收到消息之后,根据源端口通过查找拓扑表找出目的端口,由目的端口号获得目的端口所在组件的全局编号,根据组件的全局编号,进而可以得到组件所在FS的全局编号,将消息和目的端口号打包之后,发往通信层;通信层根据FS的编号将消息发往目的FS.最后,目的FS根据目的端口号判断出消息的目的组件,将消息发往目的组件端口.在BDSim中,每个FS拥有一个输入队列,一个输出队列.FS提供Port_out接口给组件,组件可以使用此接口将发出消息传至FS的输出队列.组件需要提供Port_in接口给FS,FS可以通过此接口将消息发给相应的目的组件,如图4.通过这种消息处理方式,可以实现不同组件之间的消息传递.Page6在并行环境中,消息是线程/进程间数据和控制信号传递的基本方式.消息的传递和处理会占用很多资源,执行过程中大量的消息传递会严重影响模拟速度.在BDSim中,组件间的通信是靠消息的传递来完成,通信开销有时会占到系统运行时资源占用的一半左右,所以通信效率的高低对于模拟框架的性能有着非常大的影响.例如,一个Core组件和Memory组件通过三级总线互连,两者之间的通信消息包需要经过4跳才能到达目标组件.理想情况下,4跳至少需要4个Cycle的延迟.通常情况下,由于路由阻塞等原因,一个消息包所消耗的时间往往大于4跳.而消息传递的长延迟会严重影响模拟器的性能,所以,优化通信和降低消息数量对模拟框架的性能也具有重要的意义.3.2.1非阻塞无锁消息通信消息传递方式分为两类:阻塞和非阻塞.阻塞算法允许缓慢或延迟的处理单元阻止更快的处理单元完成操作,从而无限期地共享数据结构.对于非阻塞算法,如果有一个或者多个处理单元将要操作共享数据结构,可以保证操作在有限的时间或者步骤内完成.在同步的多处理器系统中,当处理单元被阻塞在不合适的地方,将会严重影响系统性能.因此,BDSim采用非阻塞消息传递方式.另一方面,BDSim采用共享存储通信方式,消息以先进先出队列的形式被存储和访问.对共享队列进行并行访问时,需加锁以保证访问的正确性.对于共享先进先出队列的锁避免算法已经有了非常多的研究.Hwang和Briggs[30]提出了一种基于Compare_and_swap指令的锁避免算法.在这些算法中通常忽略了空队列的处理、队列中只有一个元素时的情况,以及当插入队列与删除队列同时发生时的情况.Lamport[31]指出利用单读单写队列可以实现无锁算法.3.2.2BDSim通信算法BDSim模拟框架中组件间的通信主要是由FS代理完成,FS内部串行执行,FS之间并行执行.BDSim模拟框架中FS的个数相对较少,所以可以在每一个FS中,为每对通信的FS建立一个缓冲队列,FS之间的通信对于共享缓冲队列的操作则转变为单读单写队列.根据Lamport理论[31],可以实现非阻塞无锁的操作.由于与每个FS相连的其他FS的个数不确定,为了减少通信中发送端查找通信队列的开销,根据FS的个数为每一个FS建立对应数目的通信队列,发送端在发送消息时,只需根据自身FS的编号,将消息插入到与此编号对应的通信队列的末尾即可.但是,模拟框架针对的是大规模众核系统的模拟,当模拟目标规模达到一定的程度,FS及FS之间的通信连接数量急剧增加,会造成空间的浪费.为了减少冗余队列的开销,提高通信队列的空间利用率,FS中的通信队列采用动态生成机制,即FSi与FSj首次通信时动态建立两者之间的通信队列Qij.因为不同负载和拓扑结构下,通信数量会有变化,所以,当前BDSim对通信队列长度不做限制.且消息的传递只是事件消息内容指针和路由信息的传递,并不传输真正的内容,这在一定程度上减轻了存储空间的开销.通信队列内存开销实验及分析结果见第5节性能评估举例.当插入一个节点时,按节点携带时间戳大小搜索队列,选择插入点并执行插入操作,tail指针更新指向队尾节点.当删除一个节点时,将head指针所指的下一个节点返回,然后head指针后移即可.将head和tail指针指向空节点,且tail指针并不设置为最后一个节点,这种方法可以将对head和tail指针的修改分别限制在Dequeue和Enqueue操作中.具体的队列数据结构及算法操作步骤如算法1.算法1.单读单写消息队列插入/删除算法.队列插入操作:输入:待插入消息节点输出:插入成功队列步骤:(1)搜索FS中与此连接端口相对应的消息队列;(2)创建节点,将待插入消息内容赋值给新节点;(3)按时间戳大小,搜索队列中待插入点,将节点队列删除操作:输入:待删除队列输出:删除成功队列步骤:(1)若队头指针不等于队尾指针,返回队头指针指(2)否则,返回NULL;对于将消息节点插入队列的操作,为队列遍历操作,算法时间复杂度为O(n).对于删除队列消息节点的操作,为一次判断及指针赋值操作,算法时间复杂度为O(1).3.2.3BDSim通信扩展(1)直接通信BDSim在提供消息通信的同时,也提供了直接通信方式———Callback函数(回调函数).组件可以Page7直接调用其他组件在框架中注册的回调函数来实现信息传递.直接通信方式可以对并不关心的功能模块实现加速,提高模拟效率,也为紧耦合的组件实现提供了灵活的外部调用接口,方便使用.同时也可以作为辅助调试接口,加速模拟器的调试.(2)进程通信并行模拟是利用多核平台提高模拟器速度的有效手段,随着模拟的处理器核数的增加,利用多进程、多机模拟是提高模拟速度的有效方法.BDSim在向多进程、多机方向扩展时,主要解决的问题是保证组件间的消息能够正确传递至目的地址.为了实现多进程、多机之间的消息传递,在BDSim模拟框架中增加单独的消息处理单元———CP(CommunicationProcess),专门处理进程间消息收发.扩展通信结构如图5所示.处于同一进程中的FS利用共享内存的方式进行通信,不同进程间的FS利用消息传递的方式进行通信.CP作为逻辑处理单元与其他模拟模块一样参与调度,执行到CP模块时,将本进程需要发送的消息统一发送出去,同时将发往本进程的消息统一接收回来.对于本进程内部线程间的通信,只是完成消息指针的传递,不同进程间的通信才需要消息的拷贝.3.3BDSim同步在并行模拟中,同步策略是模拟速度的主要制约因素.不同的同步策略会带来模拟性能上的巨大差异.同步问题的本质是在不同逻辑单元之间高效地维护实体间的因果关系,根据是否严格按时间戳顺序来处理事件可以把PDES同步分为两种:保守同步和乐观同步.由于乐观同步允许事件乱序执行,通过回滚来达到正确性,系统需要提供保存和恢复机制,这带来整个系统的计算资源和网络资源的巨大开销.因此,BDSim采用保守同步算法,并在此基础上提出了NMTRT-CMB(基于CMB的空消息时间戳请求标志位)同步算法.此算法通过减少同步过程中空消息的数量,提高同步速度,进而提高模拟框架的整体执行效率.3.3.1传统保守同步算法的不足传统保守算法基本思想为逻辑处理(LP)单元之间的消息按非递减的顺序发送,消息接收者为每一个连接维护一个队列来保存收到的消息.每个队列都有一个时间戳,为队列中时间戳最小的消息的时间戳,通过最小时间戳的不断增长,整个系统得以向前推进.但是传统同步算法在大规模并行模拟系统中存在着同步开销大的缺点.例如,CMB算法是经典的保守同步算法,在CMB算法中,当3个LP之间有消息同步时,可能会因互相等待对方消息而发生死锁现象.在死锁处理方面,CMB算法是通过发送空消息的方法解决.当LPi向LPj发送消息时,需要同时向其他相连LP发送同样时间戳的空消息.空消息不携带有用信息,只包含时间戳.时间戳给出了本LP以后发出的消息的时间戳的最小值,在收到一个空消息之后,接收端可以将与连接上的时间戳更新至这个时刻,从而使得该LP可以重新选择时间戳最小的队列,避免死锁的发生.CMB算法是通过空消息来达到时间推进的目的,但是当系统中存在众多组件的时候,每一个组件中的所有端口通道都维护一个接收队列,那么接收队列将会非常多,相应的空消息数量会变的非常巨大,这会消耗大量的系统资源,严重影响模拟的速度.3.3.2NMTRT-CMB同步算法在BDSim模拟框架中,对于处在同一个FS中的组件,可以近似认为它们的局部时钟一致,组件时钟以FS时钟为准.将FS及FS上的组件作为一个整体看作一个逻辑处理单元,只需为与其相连的FS维护队列保存接收到的消息即可.基于此,本文提出了NMTRT-CMB同步算法.在BDSim模拟框架中,处于同一个FS中的组件由于处理消息的能力不同,所产生的延迟也会不同.因此,在NMTRT-CMB算法中,为了实现消息按非递减的顺序发送,FS中需维护一个发送队列,消息按发送时间在发送队列中有序排列.FS在发送消息时,如果消息的时间戳小于等于FS的局部时钟则将此消息发送出去,如图6所示.FS从维护的通信队列中选取时间戳最小的队列,如果队列为空,则向与此相连的所有FS发送空消息且将时钟请求标志位置位.对于收到的空消息,如果时钟请求标志位被置位,则向与此相连的所有其他FS发送空消息;如果时钟请求标志位没有被置位,则FS只是更Page8新对应的接收队列时钟,释放空消息.NMTRT-CMB算法步骤为:(1)找出所有队列中时钟值最小的队列;(2)如果该队列中有消息,如果是普通消息则取出处理转步(1),如果是空消息且时钟请求标志位置位,则向与此相连的FS发送空消息,如果时钟请求标志位没有置位,那么只更新队列时间戳,转步(1);(3)如果该队列中没有消息,则阻塞等待直到这个连接上有一个新的消息来临,同时向与此队列连接的FS发送时钟请求消息;(4)新的消息将该队列的时间戳更新,转步(1).对于算法复杂度,假设某个FS上存在n个通信队列,每个通信队列平均有m个消息节点.在NMTRT-CMB算法中,存在一次队列遍历,时间复杂度为O(n);对于时间戳最小队列,存在一次判断操作,时间复杂度为O(1).所以NMTRT-CMB算法的时间复杂度为O(n).相比CMB算法,NMTRT-CMB算法中空消息数量明显下降,性能得到了明显的提高.后续实验表明,优化后带来的模拟精度损耗非常小,可忽略.3.4高可配BDSim模拟框架是基于组件思想开发的,这使得高可配成为可能.然而,虽然高可配能够带来模拟模型构建的灵活性,但是也带来了沉重的配置负担.使用者需要按照拓扑结构实现所有模块的通信连接.当模拟组件达到上千规模时,配置操作变成了几乎不可完成的任务.为了减轻使用者的配置负担,BDSim提供了两种不同的配置方法:文件配置和图形化配置.3.4.1文件配置文件配置意味着用文件的方式描述拓扑结构,配置内容包括:目标模型有几种组件,每种组件的个数,每个组件端口和其他端口互连信息等.以Router组件为例,首先声明Router组件对象,定义初始化函数,定义Callback函数等.然后描述组件的端口属性,支持2D-Mesh结构的路由器需要5个端口:4个方向端口和1个与Core组件连接的端口.之后是调试命令注册,将组件支持的用户命令注册至框架中,运行时通过框架来识别和执行.最后是初始化一些参数,如路由的坐标信息等,配置格式如图7.在实现单个组件配置后是对整个拓扑结构的配置.图8(a)、(b)分别是相关两个配置文件:Topology和Parameter.Topology文件描述了整个模拟目标系统的拓扑结构,以端口之间的连接方式描述.Parameter文件记录着组件的初始化参数,示例中主要描述每个Router的坐标.Page93.4.2图形化配置文件配置需要使用文件描述语言编写配置文件,繁琐且容易出错.为此,BDSim提供给使用者更为便捷的配置方式———图形化配置.组件库中已有的组件和新添加的组件会以图标的方式展示给用户,同时提供组件的各个属性信息供使用者查看.使用者只需要将需要的组件拖拽至工作区,然后将需要互连的端口通过引线连通即可完成模拟系统的配置,方便快捷.3.4.3配置流程BDSim配置流程如图9所示.首次配置时,在拓扑结构和组件种类及数量确定之后,通过图形化操作界面或编写文件描述符的方法生成目标系统的配置文件.框架对配置文件进行解析,生成二进制配置数据库.在之后的运行中,可以直接使用此配置数据库,无需再次解析生成.如若修改已生成二进制配置文件,则选择启动后重新配置.整个配置数据库以树形结构存储,如图10所示,先根据配置形成相应数量的FS,FS是并行的最小单元.然后将每个功能组件挂载到相应FS之上,一个FS可以挂载多个功能组件,同一个FS之上的功能组件之间串行执行.最后是端口配置.配置完成后,相当于完成了拓扑结构的初始化.使用树形结构,可以快速定位模块的位置,实现不同组件之间的通信.通过这种配置方式,使用者可以按照自己的需求,任意配置并行模拟的粒度,方便快捷地构建目标模型.4实验及分析本部分首先介绍实验环境及实验模型,之后对BDSim框架中的非阻塞无锁通信和NMTRT-CMB同步算法进行测试和分析,最后测试和分析BDSim框架的并行模拟性能.4.1实验环境实验基于Intel多核处理器平台,实验环境及参数配置如表1所示.操作系统编译器CPUL1CacheL2CacheLLC4.2实验模型本实验选择基于4×4的Mesh片上网络结构的众核结构作为模拟模型,配置VCore、Memory、Router三种组件.通过并发模拟VCore、Memory之间的数据传输,控制网络消息流量大小,可以达到充分测试的目的.VCore为虚拟核组件,使用Trace生成访存消息.Router为片上路由组件,根据X-Y静态路由算法向相邻的4个方向传递消息.考虑到Router可能会有消息发往自己(连接VCore的情况),所以为Router保留了发往自己的端口.每个Router组件有10个端口,端口的编号顺序为上、下、右、左,最后是连接VCore的端口.图11为由16个Router组件组成的4×42D-Mesh网络拓扑结构图.Page10Router的拓扑位置以坐标的形式标记,坐标轴以左上角为原点,横坐标方向水平向右递增,纵坐标方向垂直向下递增.消息由VCore根据Trace生成并发送至Mesh网络中,通过控制Cycle内注入消息数量来控制网络流量.测试程序如表2所示.12packets/cycle和110packets/cycle是根据测试程序发送包的总数以及测试程序运行后的总Cycle数计算得到,分别代表不同程度的流量大小.测试程序Router_SmallRouter_Big4.3实验结果及分析4.3.1非阻塞无锁通信性能测试非阻塞无锁队列与阻塞有锁队列相比,对于共享队列的访问不需要加锁.因而,共享队列的访问竞争越激烈,非阻塞无锁队列的优势会越明显.利用通信量比较小的测试用例Router_Small分别测试阻塞有锁和非阻塞无锁两种情况下所用时间,测试结果如表3所示.当线程数比较少且通信量较小时,对共享队列的访问竞争程度相对较小,非阻塞无锁与阻塞有锁两种实现方式所用的时间相差不大.当线程数比较多时,对于同一个FS中的共享队列的访问竞争程度变大,在阻塞有锁的情况下,线程阻塞等待的时间将会变大.非阻塞无锁通信相对于阻塞有锁通信效率提高的比例如图12所示.当线程数为16时,效率的提高约为7.5%.利用通信量比较大的测试用例Router_big分别测试阻塞有锁和非阻塞无锁两种情况下测试用例所用时间,结果如表4所示.线程数越多共享队列的竞争越大,所以,随着线程数的增加,非阻塞无锁相对于阻塞有锁的效率的提高会越来越明显.图13展示了在Router_Big测试用例下,非阻塞无锁通信相对于阻塞有锁通信的效率的提高比.当线程数为16时,效率提高10%左右.图12Router_Small测试程序下非阻塞无锁队列图13Router_Big测试程序下非阻塞无锁队列线程数目阻塞有锁124816线程数目阻塞有锁124816Page114.3.2NMTRT-CMB算法性能测试实验以4线程为例,测试在NMTRT-CMB算法下,空消息的发送量的减少比以及性能损耗.如表5所示,随着每个FS绑定组件数的增加,在优化前需要同步的逻辑处理单元的数目随之增加,因而用于同步的空消息的数量也不断增加.优化后,随着组件数的增加,空消息的发送量明显地减少,变化趋势如图14所示.表5CMB与NMTRT-CMB算法空消息数量对比组件数124衡量并行效果的另一个重要标准是精度损耗.NMTRT-CMB算法将处在同一个FS中的组件近似认为它们的局部时钟一致,势必会对精度产生一定的影响.本实验对精度损耗也做了充分地评估,分别利用通信量比较小和通信量比较大时的测试用例测试优化后相对于传统CMB算法的精度损耗.实验表明,在两种测试用例情况下精度的损耗都是非常小的.结果如表6和图15所示.即便是损耗比较大的Router_Small测试用例,精度的损耗最大也只有0.7%左右.线程数较少时,逻辑处理单元的时钟推进可以依靠收到的普通消息,此时最后程序运行的cycle数跟逻辑处理单元的延迟有一定的关系.而线程数较多时逻辑处理单元时钟的推进会依靠收到的空消息,测试程序运行的cycle数跟同步用到的Lookhead和逻辑处理单元的延迟都有一定的关系,在Router测试用例中Lookhead比逻辑处理单元的延迟要小,所以线程数多时精度损耗反而较小.表6不同线程下NMTRT-CMB算法精度损耗线程数164.4模拟性能测试和分析模拟器的减速比是评价模拟性能的重要指标,它是同一工作负载在模拟器中执行时间与真实系统中执行时间的比值,能够较好地反映模拟行为的开销,该值越小说明模拟器性能越高.实验搭建了基于32×32Mesh片上网络结构的1024核的众核模型目标系统.该模拟系统包括4种时钟精确模拟组件:Core、Memory、Router及Cache.Core组件是基于ARMv6指令集的ARM11①处理器为原型,支持8级流水、乱序执行、分支预测等功能.Memory组件支持程序加载,多种宽度数据读取,虚实地址转换等功能.Cache组件支持多级cache配置,支持映射方式、替换算法、行大小等参数配置.Router组件采用虚通道和虫洞路由交换技术,支持关键数据包大小、延迟、链路宽度可配及性能统计输出等功能.功耗、时延、面积等工艺参数采用基于Godson-T众核处理器[32]的配置.实验选取了搜索引擎(pin_search560)、字符统计(wholeWC)、大数据排序(wholeTS)三个典型的大数据应用程序作为基准测试程序.模拟目标系统在单线程配置下的测试结果如表7所示.测试程序pin_search560搜索引擎程序wholeWCwholeTS由表7可计算出,BDSim模拟框架在单线程下平均模拟速度为722.82KIPS.ARM11系列处理器频率在350MHz到1GHz之间,本文取800MHz为计算标准.流水线采用单发射,因此IPC理论最大①http://www.arm.com/zh/products/processors/classic/Page12值为1.计算可得,BDSim模拟减速比低于1107.目前常用的模拟器GEM5[11]、MARSS[12]时钟精确级模拟速度在200KIPS左右(X86指令集),且X86处理器①频率通常在2GHz左右,所以模拟减速比远大于1107.并行模拟器Graphite[14]在千核单线程配置下的模拟减速比为1751(X86指令集,SPLASH测试程序),也远大于BDSim模拟减速比.本实验中,千核模拟目标系统包括1024个Core,1024个Cache,1024个Router构成的32×32Mesh片上网络以及4个Memory.整个系统规模非常庞大,其在多线程下的模拟加速比如图16所示,当千核系统运行在8线程时有超过2倍的加速比.图17所示为各模块在整个运行过程中所占运行时间百分比.从图中可以看出Memory组件和Mesh组件所占时间之和超过了整体运行时间的一半,这是因为Router组件之间以及Router和Memory之间高度耦合,它们需要对千核发出的访存和通信事件进行处理,降低了模拟系统的可并行度.框架(Framework)只占整个系统10%左右的开销.这说明,通过优化Memory和Mesh组件,提高组件的并行性,整个模拟系统会取得更明显的加速比.图17千核模拟系统各组件运行时间比(8线程)5大数据性能评估举例随着大数据的兴起,“存储墙”的问题越来越严重,对于如何提高访存带宽,实时处理高通量的数据成为学术界和工业界研究的热点.本实验目的是评估访存请求收集表(MemoryAccessCollectingTable,MACT)在大数据应用体系结构中对访存的性能影响,举例说明BDSim模拟框架如何在大数据处理模拟方面发挥作用.MACT通过结合消息式内存机制,收集离散的访存请求并进行批量处理.提高了访存带宽的有效利用率,同时也提高了执行效率.并通过时间窗口机制,确保访存请求在最晚期限之前发送出去,保证任务的实时性.如图18所示,MACT结构内置两个表Rmact和Wmact,分别用于读/写记录.表是一个队列,由一个数组和头尾指针构成.队列每一项包含标志读/写记录的Bitmap、需要结算的时间Deadline以及该项的基址Baseaddr.其中Bitmap中共有1024位,每一位代表了一个字节地址的读/写情况.当接收到一条访存请求时,MACT行为如下:(1)读数据.清除Rmact中相关表项,并将表中Bitmap为1的地址的数据发送给总线;(2)写数据.直接返回ACK;(3)读/写地址.将该地址插入到Rmact/Wmact中,如果现有表项中存在该地址的基址记录,则在此表项的Bitmap中将对应Bit位置1并记录消息内容,如有重复置1的情况则同样需要记录多个消息内容,最后返回ACK.如表项中不存在该地址的基址记录,且表已满,则向总线发送NACK消息,若不满则增加一项基址与该地址基址一致的一项,用当前周期加上固定延时(实验中设置为16cycles)作为此新项的Deadline,并发送ACK消息.①http://ark.intel.com/Page135.1组件模拟模型包括:XBAR、VCore、MCU三类组件,如图19.XBAR即为Crossbar总线,本例中使用XBAR组件搭建三级总线.VCore代表虚拟核,因本实验主要研究访存性能,所以无需模拟完整的核图19多级总线拓扑结构5.2拓扑结构本例中,以128核的众核结构作为实验对象,目标模型如图19所示.每8个核连接到一个三级总线,形成CoreGroup.每个二级总线挂载4个三级总线,4个二级总线连接到一级总线,形成128核的多级总线互连结构.4个MCU分别挂载到4个二内结构,可以降低模拟的复杂度.VCore组件需要实例化两类:带MACT结构的和不带MACT结构的.MCU为存储控制单元.实验Benchmarks为大数据测试程序的访存Trace,虚拟核解析Trace并在一定的时序控制下发出相应的访存事件.级总线之上.5.3测试环境及结果分析具体测试环境如表1所示.实验从整体执行时间、单消息平均延迟、访存带宽比、访存请求个数4个维度比较了大数据应用程序在传统结构和包含MACT结构的模拟目标系统上的执行效率.本次实Page14验以搜索引擎程序(pin_search560)、字符统计程序(wholeWC)及大数据排序程序(wholeTS)3个大数据应用生成的访存Trace作为基准测试程序.Trace大小分别为280MB、1.3GB以及1.9GB.实验统计数据如表8~表10及图20所示.pin_search5601916290816.589992660.3456968546624557wholeWC7087732318.645202550.41129548629151523wholeTS50296552117.252168390.07740316138931121pin_search560834359529.049421880.4915484274101281wholeWC3013482051.273534510.62042895918696515wholeTS49410478568.154647030.06060114629943316pin_search560wholeWCwholeTSaverage图20MACT结构相对于传统结构性能对比统计实验结果表明:通过MACT对访存请求的收集和批量处理,访存数量减少约49%,访存带宽提高约24%,平均执行速度提高约89%.详细分析如下:(1)应用程序整体执行时间下降.增加MACT硬件机制后,pin_search560、wholeWC、wholeTS三个应用程序分别获得了2.30、2.35、1.02倍的加速比.加速比的来源主要有两个方面:①传统内存控制器带宽利用率较低,通过MACT对访存请求的收集可以有效提高带宽的利用率,提高执行效率;②通过收集和批量处理,减少了发往网络中的访存消息包数量,降低了网络拥塞度.其中,wholeTS应用程序的加速效果不明显,加速比只有1.02左右.主要原因是其访存操作不够密集,吞吐量较低,导致MACT对访存请求的收集效果不明显,从而对执行时间的影响也非常有限;(2)消息从访存部件到内存控制器的平均延迟上升.由于核发出的访存消息统一在MACT中收集并等待一定Cycles才被发送至片上网络,所以延迟会相应增大.但是由于处理器在发出访存请求时设置访存裕度值,并且MACT中采用时间窗口机制,所以仍能保证访存请求质量;(3)访存带宽比提高.对于pin_search560和WordCount应用来说,有效带宽都有不同程度的提高,分别为1.42和1.51倍.但对于wholeTS应用程序来说,虽然执行时间和访存请求消息包数目都有所降低,但是它们之间的比值,即访存带宽比(个/Cycle)反而降低了22%.这主要是因为wholeTS应用程序访存密度低,访存压力小所造成;(4)访存请求数量降低.使用MACT硬件机制后,pin_search560、wholeWC、wholeTS三个应用程序分别获得了1.62、1.56、1.30倍的访存数量减少比.这是因为很大一部分的离散访存请求被收集和批量处理,所以在数据通路上看到的效果是访存请求消息包数量有了明显的降低.可见,MACT结构可以通过对访存事件的收集和批量处理,有效减少网络拥塞,增加带宽利用率,缩短执行时间,相对于传统结构具有更强的性能.关于运行过程中存储空间的消耗,图21展示了运行时消息队列长度统计结果.可知,最大队列长度不会超过360,单消息大小为固定32B.在图19的配置下,128核与三级XBAR互连,共128对队列.二三级XBAR互连共16对队列,一二级XBAR互连共4对队列.MCU与XBAR互连共4对队列.整个配置共需2×(128+16+4+4)=304个队列.最大所需内存304×32B×360≈3.34MB大小.可知,即使千核量级配置下,当前通用处理器也完全可以承受.Page15综上所述,实验以评估MACT结构在大数据处理体系结构中的作用为例,验证了BDSim框架的有效性.通过实验过程和结论可以看出,BDSim适用于构建大规模众核体系结构模拟平台,能够在大数据处理研究过程中发挥重要的评估作用.6结论大规模并行模拟已经成为大数据体系结构研究的主要方法.但目前的模拟技术却不能满足大数据体系结构研究的需求,主要体现在模拟速度慢、配置过程复杂、可扩展性差等方面.针对此,本文提出了BDSim并行模拟框架,支持大规模并发模拟.该并行模拟框架具有以下优势:首先,模拟框架基于离散组件化开发模式,功能模块以组件形式加载到模拟框架中运行,提高了模型开发的自由性及组件的复用性.其次,使用高效的非阻塞无锁消息通信机制,加快了消息处理速度,16线程配置下,执行效率提高约10%左右.再次,提出基于CMB的NMTRT-CMB同步算法,4线程16组件配置下,减少控制消息数量90%以上.实验表明,模拟框架模拟减速比小于1107,远低于常用众核模拟器.在3076个模拟组件规模下,8线程运行具有2.3倍的加速比.同时,为了满足不同的同步需求,模拟框架也支持粗粒度同步方法,使用者可以随意配置同步粒度以满足对模拟速度的需求.最后,模拟框架提供了灵活方便的配置方法,文件或图形化配置方法,提高了框架的易用性.实验分析和评估举例表明,BDSim并行模拟框架以其灵活方便的搭建方式和快速精确的执行过程,符合大规模并行系统的模拟需求,适用于大数据处理体系结构的评估和研发.7未来工作为了提高模拟框架的速度、精确度和易用性,未来研究工作主要集中在3个方面.首先,提高模拟框架的模拟速度.模拟速度一直是困扰软件模拟发展的难题.针对大规模数据处理体系结构的模拟,更需要速度的保证.围绕此问题,加速工作主要从两个方面展开:从框架角度,通过进一步优化通信和同步算法,提高框架的执行效率;从组件角度,通过使用动态二进制翻译机制、指令TraceCache以及采样等技术加速组件的执行速度.其次,提高模拟框架的精确度.模拟精确度越高就会使模拟行为和结果更接近于真实硬件,能够更加准确地指导体系结构的研究.目前,BDSim的功耗、时延、面积等工艺参数采用基于Godson-T众核处理器[32]的配置.并且,以BDSim模拟框架为基础,千核级处理器的RTL(RegisterTransferLevel,寄存器传输级)仿真模型的搭建工作正在开展.之后,框架中的功耗、时延、面积等工艺参数信息会与RTL模型进行对比调试,逐步调优BDSim模拟框架的精确度.最后,开发完善的组件库.组件库使已存在的组件被无限次重复使用成为可能.因此,需要继续开发不同功能的组件或是整合现有的功能准确、使用度广的组件添加至组件库,降低并行模拟器开发的复杂性,形成一个功能丰富的模拟开发平台,方便研发人员快速搭建目标模型.
