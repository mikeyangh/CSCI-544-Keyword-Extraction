Page1基于FREAK和P3CA的鲁棒目标跟踪王宇霞赵清杰赵留军(北京理工大学计算机学院智能信息技术北京市重点实验室北京100081)摘要在粒子滤波框架下,提出了基于快速视网膜特征点(FastRetinaKeypoint,FREAK)和主成分-典型相关分析(PrincipalComponent-CanonicalCorrelationAnalysis,P3CA)的目标跟踪算法.该文提出的基于FREAK的多模态运动模型提高了目标位置预测准确性,缩小了目标搜索空间.基于P3CA的外观模型利用图像子区域间的典型相关性衡量候选目标的优劣,解决了基于全局信息外观模型对遮挡敏感的问题;利用主成分分析在数据降维方面的优势,解决了典型相关分析用于跟踪存在的小样本问题,降低了计算开销.同时,P3CA在线更新算法使跟踪器可以更好地应对跟踪过程中目标外观变化.通过在多个具有挑战性的视频上与多种优秀算法对比实验表明,该文的方法可以很好地应对光照变化、遮挡、旋转以及复杂背景等问题.关键词目标跟踪;快速视网膜特征;主成分-典型相关分析;主成分分析;典型相关分析1引言目标跟踪是计算机视觉领域的一个重要分支,Page2及遮挡等问题,实现鲁棒的目标跟踪仍是一个巨大的挑战.针对上述问题,应该寻找更加优秀的运动模型、外观模型以及搜索策略,详细叙述请参见经典的目标跟踪综述[5-8].本文提出的基于FREAK(FastRetinaKeypoint)和P3CA(PrincipalComponent-CanonicalCorrelationAnalysis)的目标跟踪算法对运动模型和外观模型进行了研究.运动模型表示目标状态随时间的变化规律,合适的运动模型可以有效地缩小寻找最优目标位置的搜索空间,降低计算复杂度.为了使问题简化,大多数跟踪算法采用先验转移概率作为目标的运动模型.经典的Condensation算法[9]利用自回归模型对先验转移概率进行建模.通常自回归模型包含确定性漂移和随机扩散两部分,两部分对应的系数可以通过先验设定或者学习得到.早期跟踪算法采用的匀速和匀加速运动模型可以看做是一阶自回归模型的一个特例,通过先验设定确定性漂移部分的系数,忽略随机扩散部分的影响来对目标运动建模.虽然匀速和匀加速运动模型计算简单、易于实现,但是假设目标在整个视频序列中的运动符合固定、简单的运动规律,忽略了目标运动的随机性,限制了这两种运动模型的应用范围.作为自回归模型的另一个特例,随机游走模型[10-11]充分考虑了目标运动的随机性,该模型只对自回归模型的随机扩散部分进行建模,忽略了确定性漂移部分,将先验转移概率建模成一个布朗运动模型.利用随机游走模型跟踪快速运动的目标,需要采用较大的随机噪声,以使采样点分散在较大的范围内,然而当目标运动忽然变慢时,由于采样点过于分散,导致很多采样粒子权重过小,使跟踪性能下降.相反,如果选取的随机噪声过小,采样点集中于一个较小的区域,当目标出现较大幅度的运动时,可能会导致跟踪器丢失跟踪目标.并且要利用随机游走模型实现准确的目标位置预测,需要在采样范围内密集采样,当采样范围变大时,计算量也随之增大.因此,对于目标存在复杂运动的视频序列而言,随机游走模型也不能实现很好的预测效果.为了准确地预测目标在相邻帧间的运动,文献[12]提出了一种通过SIFT(Scale-InvariantFeatureTransform)匹配获取运动模型的方法.该方法通过相邻帧的SIFT匹配获取相邻帧存在的仿射运动,以此作为运动模型的确定性漂移部分;利用随机游走模型作为运动模型的随机扩散部分.该运动模型同时包含了确定性漂移部分和随机扩散部分,并且确定性漂移部分通过相邻帧的SIFT匹配得到,使得跟踪器可以在更接近真实目标位置的较小范围内使用较少的采样实现较好的跟踪.但由于SIFT特征提取速度较慢,限制了其在目标跟踪中的应用.本文通过对比目前较优秀的局部特征描述子,提出了基于FREAK的多模态运动模型,该模型可以快速高效地对目标位置进行预测,缩小了目标的搜索空间,并且运动模型的多模态可以有效避免由匹配不可信带来的预测误差.外观模型用来评估候选目标在特定位置的似然性,它在目标跟踪中起着至关重要的作用.优秀的外观模型可以有效地应对跟踪过程中由光照变化、尺度变化、遮挡、旋转等引起的目标外观变化.通常外观模型可以分为全局外观模型和局部外观模型.最简单、直观的外观表示方法为基于原始像素值的全局外观模型,该模型在IVT[10]、L1[11]、Kanade-Lucas-Tomasi[13]、TOD[14]以及ITS[15]等算法中被广泛采用.基于全局颜色直方图的外观模型由于其计算简单高效并且可以很好地应对目标形变问题从而被很多跟踪算法采用,如Mean-Shift跟踪算法[16]以及基于粒子的跟踪算法[17].虽然全局外观模型计算简单、易于实现,但对于遮挡以及运动模糊比较敏感,因此近年来局部外观模型成为了研究的热点.EnsembleT[18]和FragT[19]中采用局部颜色直方图作为目标外观模型,与基于全局颜色直方图的外观模型相比,该模型能够更好地应对遮挡以及局部外观变化.文献[20]提出了一种基于结构化局部稀疏表示的外观模型,该模型利用稀疏表示对目标外观进行建模,并且充分考虑了目标外观的局部信息和空间结构信息.与文献[20]类似,文献[21]同样利用稀疏表示的方法来对目标外观进行建模,但与文献[20]不同的是,该算法将全局外观模型与局部外观模型有机地结合到一起,使得算法在应对各种目标外观变化时更加鲁棒.与上述方法不同,学者Kim[22]提出了基于相关性的外观模型,该模型通过典型相关分析CCA(CanonicalCorrelationAnalysis)在局部外观模型的基础上引入了各局部之间的典型相关关系,能够很好地应对光照变化以及遮挡.然而CCA算法用于高维样本情况时,其类内协方差矩阵为奇异矩阵,虽然采用广义逆矩阵或者是扰动后的矩阵可以解决奇异问题,但在一定程度上损失精度.在文献[23]中我们提出了一种新的基于相关性的外观模型,即P3CA在线外观模型,该模型将PCAPage3(PrincipalComponentAnalysis)算法[24-26]引入CCA子空间计算过程中,在不损失有效信息的同时解决了高维小样本问题,降低了计算复杂度.同时,我们提出的P3CA在线增量学习算法可以很好地应对跟踪过程中由于光照变化、遮挡、旋转、复杂背景等问题引起的目标外观的变化.鉴于P3CA在线增量外观模型的鲁棒性,本文我们使用该模型作为跟踪器的外观模型.2系统概述本文在粒子滤波的框架下,提出了基于FREAK与P3CA的在线目标跟踪算法.粒子滤波[27-28]是利用一系列的粒子及它们的权重来逼近目标状态后验概率的贝叶斯序列估计方法,该方法可以在实际分布未知的情况下对状态变量的后验概率密度进行估计.本文使用向量犛t表示t时刻的目标状态,犛t=(dx,dy,sc,θ,sr,δ),其中dx、dy、sc、θ、sr、δ分别表示横向平移、纵向平移、尺度、旋转角度、纵横比例以及斜切角度.根据粒子滤波理论,t时刻的状态向量犛t预测如下:p(犛t|犣t)∝p(犣t|犛t)∫p(犛t|犛t-1)p(犛t-1|犣t-1)(1)其中:犣t为t时刻的观测数据;p(犣t|犛t)为观测模型,用于估计由状态犛t产生观测犣t的似然;p(犛t|犛t-1)为运动模型,用于相邻帧间目标状态的转移.本文提出的跟踪系统如图1所示.运动模型采用本文提出的基于FREAK的多模态运动模型.使用FREAK多模态运动模型进行粒子传播:首先,通过相邻帧间感兴趣区域的FREAK特征匹配找到所有匹配点对;然后,使用RANSAC(RandomSampleConsensus)算法[29]计算相邻帧的预测矩阵;最后,根据匹配置信度,选择不同模态的运动模型进行粒子传播.观测模型采用P3CA在线观测模型,该模型利用图像子区域间的典型相关性解决了全局外观模型对遮挡敏感的问题,利用主成分分析在数据降维方面的优势解决了样本协方差矩阵的奇异问题,提高了典型相关分析的计算精度,降低了计算复杂度.P3CA子空间在线更新算法采用PCA与CCA联合同步更新策略,每5帧更新一次.在低维空间中更新P3CA子空间降低了时空复杂度,并且更新频率的选择既避免了由更新频率过高引起的漂移现象,又能够及时反映外观变化.3基于FREAK的多模态运动模型运动模型用来预测目标位置随时间的变化规律,高效的运动模型可以以较低的计算复杂度达到较高的预测精度.鉴于匀速、匀加速运动模型以及随机游走模型预测精度较低,而基于SIFT匹配的运动模型计算复杂度较高,我们提出了基于FREAK的多模态运动模型.3.1局部特征描述子对比局部特征匹配方法已经在图像配准、图像标注、图像检索、图像拼接等领域广泛应用.在目标跟踪中,基于局部特征匹配的跟踪算法也不断涌现.早期基于局部特征的跟踪算法主要集中研究基于局部特征的外观模型[30-31],与这些工作不同的是,本文主要关注基于局部特征匹配的运动模型.由于跟踪过程中存在复杂的环境变化以及目标外观变化,我们需要选择一种对环境以及目标外观变化鲁棒的特征,以保证目标位置预测的准确性.我们对目前流行的6种局部特征描述子进行了测试和对比:BRISK[32](BinaryRobustInvariantScalableKeypoints)、BRIEF[33](BinaryRobustIndependentElementaryFeature)、ORB[34](OrientedFastandRotatedBRIEF)、FREAK[35](FastRetinaKeypoint)、SIFT[36](Scale-InvariantFeatureTransform)、SURF[37](SpeedUpRobustFeatures).图2(a)为测试局部特征描述子的通用图像,大小为640×512像素.Page4图26种局部特征描述子在应对光照变化、高斯模糊、旋转以及尺度变化的表现图2中的4幅曲线图分别显示了6种描述子在应对光照变化、高斯模糊、旋转以及尺度变化的表现.从图2我们可以看出,从平均角度来看,SIFT和FREAK在4种外观变化测试中取得了较好的结果.通过实验统计,进行SIFT特征匹配平均耗时为748.286ms,FREAK平均耗时为47.609ms,FREAK特征匹配的速度是SIFT的15倍以上.综合考虑特征描述子的鲁棒性以及计算效率,FREAK性能优于其它5种局部特征描述子.上述结果与Alexandre[35]得到的结果基本保持一致.3.2基于FREAK的多模态运动模型FREAK描述子用二进制向量描述关键点,采样以及点对的选取都利用了人类视觉特点.新的点采样模式以及二进制特征描述方式使FREAK描述子在稳定性和计算效率上表现都很优秀.目标跟踪中感兴趣区域(目标)通常为整幅图像中一个较小的区域,因此,FREAK特征匹配仅在感兴趣区域内进行.t-1时刻跟踪结果的覆盖区域为第t-1帧特征点检测区域,第t帧的特征点检测区域比第t-1帧的检测范围分别在长和宽上扩大了30个像素.连续两帧图像的匹配结果如图3所示.由于特征点匹配置信度直接影响目标位置的预测,为保证目标位置预测的准确性,我们定义两条准则对特征匹配的置信度进行度量.准则1.匹配率.匹配率r不应低于阈值Tr,匹配率的计算公式如下所示,本文选择Tr=0.7.其中:Nt-1为第t-1帧感兴趣区域内检测得到的特征点总数;Nmatch为匹配点数.准则2.匹配点对描述符间平均距离.匹配点对描述符间平均距离犱不应高于阈值犜犱.其中,犱定义为一个4维向量,犱=(d1,d2,d3,d4),计算如式(3)Page5所示;阈值犜犱也定义为一个向量,本文选择犜犱=(0.4,0.3,0.2,0.1);我们采用逐个分量比较的方式比较匹配点对描述符间平均距离犱和阈值犜犱的大小,当犱中每个分量都不大于犜犱中相应分量时,我们认为犱<犜犱.dn=其中h(Di_n符第n组的Di_n的Dj_nt之间归一化的海明距离.为准确预测目标位置,我们根据特征匹配的置信度不同定义不同的预测矩阵.当匹配完全可信时,即满足上述两条准则并且存在足够多的匹配点,我们定义帧间预测矩阵为仿射矩阵;当满足上述两条准则,但匹配点较少时,我们定义帧间预测矩阵为平移矩阵;其他情况,我们对帧间运动不做预测,即帧间预测矩阵为单位矩阵.多模态预测矩阵犎p定义如下:烄犎p=烅犐,烆其中:犃,狊可由RANSAC算法求出,犐为单位矩阵,Ta,Tl为匹配点对个数阈值,我们选择Ta=6,Tl=3.利用多模态预测矩阵,我们定义粒子滤波框架下的运动方程为其中:犎n由一系列对应目标状态分量的高斯噪声组成;犛t,犛t-1分别表示t和t-1时刻的目标状态.3.2.1预测矩阵计算中的阈值确定准则1中匹配率为相邻帧感兴趣区域间匹配点对的个数与前一帧跟踪结果区域内检测到的特征点总数的比值.当相邻帧间目标外观无任何变化时,理论上匹配率应该为1,而当相邻帧间目标外观完全不一致时,理论上匹配率应该为0,但由于局部特征检测算子和描述算子自身局限以及背景区域的干扰,匹配率并不能达到理论值,因此匹配率取0~1之间的值.当相邻帧间目标外观缓慢变化时,由于目标外观存在变化但变化较小,对于鲁棒的局部特征算子,正常情况下可以在相邻帧感兴趣区域之间得到较多的匹配点对(即匹配率较高),所以匹配率阈值应该设置一个较高的值;但由于目标外观的缓慢变化、局部特征自身的局限以及背景的干扰,此阈值也不应设置过高.实验中,当阈值设置过低时(<0.5时),相邻帧感兴趣区域间计算得到的匹配率多数高于阈值,导致出现过多误匹配;当阈值设置过高时(>0.9时),即使相邻帧间目标外观变化不大,计算得到的匹配率也多数低于阈值,导致我们基于局部特征匹配的运动模型不能发挥作用;经多次实验,当匹配率阈值Tr=0.7时,在大多数视频上预测效果较好.由于FREAK受到人类视觉机制启发,在特征点匹配的过程中采用从粗到精的匹配方式,每个512维的特征描述符被分为4组,每组128维,前128维是相关性最小,可以代表粗的信息,后面的越来越精,即越靠近关键点中心区域的描述符距离应该越小.准则2中,我们分别计算所有匹配点对在每组特征描述符上的归一化的平均海明距离,并为每组距离设置一个阈值.由于4组特征描述符分别代表由粗到精的信息,因此,计算得到的归一化的平均海明距离也应该是由大到小的.阈值中的第1维旨在以较高的置信度滤除匹配过程中相似度很低的特征点对:如果该阈值设置过小不能够有效滤除无效匹配、减少计算量;如果设置过大又会导致很多有效特征点对被滤除.经过多次实验,设置该阈值为0.4时可以保障在大多数视频上不丢失有效匹配的同时有效减少后续匹配的计算量.根据FREAK由粗到精的匹配方式,我们设置后边三维阈值依次增大分别设置为0.3、0.2、0.1,这样可以逐层滤除置信度低的特征点对,保障了最终得到的匹配点对的可靠性.在阈值与平均距离比较过程中,我们首先比较第1组距离和阈值,如果距离小于阈值,则进行第2组比较,依此类推.由于我们使用RANSAC算法计算多模态预测矩阵犎p,所以两帧之间必须存在足够多的匹配特征点对.我们定义Ta、Tl为匹配点对个数阈值,当预测矩阵为仿射变换矩阵时,存在6个待估计参数,为了保证计算出的仿射变换矩阵的可信性,我们选择至少使用6对匹配点对;当只存在3~6对匹配点对时可以使用RANSAC计算两帧之间存在的转换矩阵,但是不能得到可信的仿射变换矩阵,此时我们认为帧间的转换矩阵为平移矩阵,即只估计两个平移参数,此时用3~6对匹配点对估计两个参数基本可以保证参数的可靠性.因此我们选择Ta=6,Tl=3.Page64基于P3CA的在线外观模型CCA是一种用于分析两组随机变量相关关系的统计分析方法,即将两组随机变量之间的相关关系转化成为少数几对互不相关变量之间的相关关系[38].具体来说,对于两组零均值的随机向量狓∈dx,狔∈y使得投影狓d这种相关称为典型相关.由文献[39]可知,通过式(6)的前q个特征值以及对应的特征向量,即可得到CCA子空间的典型相关系数矩阵犘以及投影矩阵犝x、犝y.其中Σ代表协方差矩阵,λ代表特征值.ΣxyΣ-1yyΣyx狌x=λxΣxx狌x,ΣyxΣ-1虽然CCA是一种有效分析两组随机变量相关关系的方法,但当两组随机矢量所在样本空间的协方差矩阵奇异(即出现高维小样本问题)时CCA表现效果不佳.为解决CCA用于目标跟踪时的高维小样本问题,我们在文献[23]提出了P3CA外观模型.该模型利用PCA在数据降维方面的优势,在不丢失有效信息的前提下,有效解决了CCA用于目标跟踪时的高维小样本问题,降低了计算量.P3CA外观模型利用图像两个子区域在低维空间中的典型相关性衡量粒子权重.本文我们采用垂直分区的图像分区方式,即将样本图像垂直分为左右两个相等的子区域.在时刻t对粒子i的权重估计如下:其中,狓-i在低维空间的观测数据.Γ=其中:Σxx,Σyy为P3CA子空间的类内协方差矩阵;犘,犝x,犝y为P3CA子空间的典型相关系数矩阵以及投影矩阵.上述矩阵可以通过P3CA子空间的初始化得到:首先将所有样本数据都垂直分为左、右相等的两个子区域,并利用PCA将分区后的观测数据降维;然后利用CCA在得到的低维观测数据上求解P3CA初始空间(犝x,犝y,犘).得到P3CA初始子空间后,最后一个问题就是如何对P3CA子空间进行更新以适应目标外观不断变化的问题.这里我们简要介绍P3CA在线更新的步骤,详细内容请参见文献[23].假设当前的观测数据犣0(分区后)对应的均值以及协方差矩阵为犿x,犿y,Σxy,Σxx,Σ-1(犝pcax,Σpcax),(犝pcay,Σpcay).m帧新增观测数据犣1到达后,P3CA空间的更新步骤如下.1.利用SKL[40]算法更新PCA空间,记为(犝pcax,Σpcax)和(犝pcay,Σpcay);2.计算更新前与更新后的PCA子空间的转换矩阵犙x、犙y,利用转换矩阵对更新前的均值以及协方差矩阵进行转换:3.计算新增数据犣1在更新后的PCA子空间的投影犣1及其对应均值矩阵及协方差矩阵犿x,犿y,Σxy,Σxx,Σyy;4.利用步2以及步3得到的均值及协方差矩阵计算当前时刻协方差矩阵:(Σ-1其中α=1+犪T犪~,犪=槡mtβ=1+犫T珘犫,犫=槡mt5.利用以上得到的协方差矩阵由式(6)即可更新P3CA子空间(犝x,犝y,犘).5基于FREAK与P3CA的目标跟踪算法1.基于FREAK和P3CA的在线目标跟踪.输入:图像序列,目标初始状态犛0输出:目标在t时刻的状态犛tFORt从1到最后一帧粒子传播阶段:1.检测第t-1帧跟踪结果区域内的关键点,计算2.检测第t帧感兴趣区域内的关键点,计算FREAK特Page73.利用RANSAC算法计算第t帧和第t-1帧的匹配4.根据匹配置信度计算预测矩阵犎p,并计算FREAK5.根据FREAK多模态运动模型对粒子进行传播,获粒子衡量阶段:6.FORi从1到最后一个粒子1)将每个粒子区域按照垂直分区方式分为左右两部分;2)将左右子区域投影到当前的PCA子空间,得到低维3)利用P3CA观测模型在低维的观测数据上计算每个END7.对粒子权重归一化,选取权重最大的粒子作为跟踪8.IF保存的跟踪结果个数=更新阈值THEN利用P3CA在线更新算法和新增观测数据更新ENDIFEND6实验结果与分析为验证本文提出算法的有效性,本部分展示了本文算法在10个具有挑战性的数据集上的跟踪结果,并与近年提出的6种经典算法进行了对比.为了进一步说明本文提出的基于FREAK的多模态运动模型的有效性,我们还将FREAK_P3CA算法与仅使用P3CA算法的跟踪结果进行了对比.10个数据集都是公开获得,其中car4、car11、davidin300、sylv来自IVT算法[10],faceocc2、dollar、girl来自MIL算法[41],occlusion1来自文献[42],stone来自文献[20],animal来自文献[43].10个数据集采集环境包括室内环境和室外环境,并存在不同程度的光照、姿态、尺度变化、遮挡以及复杂背景等情况.6种对比算法分别为SC算法[21]、SLS算法[20]、FragT算法[19]、IVT算法[10]、MIL算法[41]和L1算法[11].为了保证对比实验的公平性,所有对比算法我们都使用作者提供的源程序以及默认的参数设置.对于涉及随机变量的算法,我们都选取5次试验的平均结果作为最终结果.6.1算法定性分析6.1.1car4和car11的实验结果分析car4序列在室外环境下获取,存在运动模糊、尺度变化以及严重的光照变化.car11序列是在非常黑暗的街道上通过一个运动的摄像机获取的,该序列背景光照复杂,前景与背景对比度非常低,存在严重的模糊以及光照变化.跟踪结果如图4(a)、图4(b)所示,FragT算法、L1算法在出现光照变化时出现了较大程度的漂移,随着漂移误差的累积最终丢失目标;MIL算法虽然未丢失目标,但也产生了较大程度的漂移;而SC算法、SLS算法、IVT算法、FREAK_P3CA算法以及仅使用P3CA模型的跟踪算法在强烈光照变化的场景中,都取得了较好的跟踪结果,其中SC算法和IVT算法分别在car4、car11序列中取得了最优的跟踪结果,我们的FREAK_P3CA算法在两个视频序列中取得了次优的跟踪结果,并且与SC算法和IVT算法性能相差不大.以上两个视频的跟踪结果证明本文算法在应对光照变化、复杂背景、运动模糊等方面具有一定的鲁棒性.6.1.2occlusion1和faceocc2的实验结果分析occlusion1以及faceocc2序列都是在室内环境下获取并且都存在被不相似目标遮挡的情况.在occlusion1序列中,当跟踪目标被频繁遮挡时,IVT算法、MIL算法以及FragT算法最终都丢失了目标;L1算法出现了较大程度的漂移和短暂的目标丢失;而SC算法、SLS算法、P3CA算法和FREAK_P3CA算法能实现较为准确的跟踪,跟踪结果如图4(c)所示.faceocc2序列中不仅存在频繁的遮挡,还存在目标旋转、平移、光照变化等现象.由于FragT算法、MIL算法和L1算法都不具备应对旋转变化的能力,所以当目标出现旋转时,3种算法在不同程度上出现了跟踪不准确的现象;另外,当跟踪目标发生旋转后又被严重遮挡时,IVT算法和SLS算法产生了严重漂移;当跟踪目标出现外观变化(带上帽子)时,L1算法也出现了较严重的漂移,并且无法恢复正确跟踪;SLS算法和SC算法在目标同时被帽子和书遮挡的情况下丢失了目标;P3CA算法和FREAK_P3CA算法在频繁遮挡的影响下实现了鲁棒的跟踪,跟踪结果如图4(d)所示.通过以上两个视频证明本文算法能够很好地应对遮挡问题,在视频序列较复杂(同时存在目标旋转、目标平移、光照变化、外观变化、遮挡等问题)时表现尤为突出.6.1.3dollar和girl的实验结果分析dollar和girl序列也是在室内环境下采集,但Page8图48种算法在10个视频序列上的跟踪结果Page9与6.1.2节中的视频不同的是,dollar与girl的遮挡干扰都来自同类事物.dollar序列中原始目标被自身遮挡后又出现了一个与原始目标外观完全一致的伪目标,该序列的跟踪结果如图4(f)所示.IVT算法、MIL算法、FragT算法以及L1算法在原始目标被自身遮挡时,都出现了一定程度的漂移,随着漂移误差的积累,L1算法最终丢失了目标;P3CA算法也出现了一定程度的跟踪不准确的现象;SLS算法、SC算法和FREAK_P3CA算法取得了较好的跟踪结果.girl序列的跟踪结果如图4(e)所示,当相似目标遮挡跟踪目标时,MIL算法、IVT算法、L1算法、SLS算法都出现了严重的跟踪漂移,并且MIL算法和SLS算法最终丢失跟踪目标;SC算法、FragT算法、P3CA算法和FREAK_P3CA算法在整个图像序列上实现了较好的跟踪.dollar和girl两个序列上的实验表明本文算法可以很好地应对相似目标相互遮挡以及伪目标干扰的问题.6.1.4davidin300和sylv的实验结果分析davidin300视频中存在复杂的光照变化、平面外旋转、尺度变化、表情变化等问题.在该序列中,由于光照变化,FragT算法出现多次跟丢目标的情况;L1算法、SLS算法在目标出现平面外旋转时跟丢目标;在整个跟踪过程中MIL算法虽然未丢失目标,但也存在较大程度的漂移现象;IVT算法、P3CA算法、SC算法和我们的FREAK_P3CA算法取得了鲁棒的跟踪效果,如图4(g)所示.sylv视频中不仅存在光照变化并且存在频繁的、大幅度的平面外旋转,跟踪结果如图4(h)所示,L1算法、IVT算法、SLS算法,分别在经历了第1次和第2次大幅度的平面外旋转后丢失目标并且无法恢复跟踪;MIL算法、FragT算法和SC算法在经历频繁的平面外旋转时也出现了多次跟丢目标的情况;P3CA算法在经历了严重的平面外旋转之后跟踪框出现了缩小和扩散现象,FREAK_P3CA算法取得了准确的跟踪结果.通过davidin300、sylv的实验证明本文算法能够较好地应对平面外旋转、光照、尺度、表情等外观变化.6.1.5stone和animal的实验结果分析stone,animal视频背景复杂,存在多个与跟踪目标相似的物体,跟踪结果如图4(i)、图4(j)所示.由于stone视频序列复杂背景中其它目标的干扰,MIL算法和FragT算法跟踪误差不断积累最终丢失跟踪目标;IVT算法、L1算法和SC算法在跟踪目标被相似物体遮挡时跟丢目标,但L1算法和SC算法在短暂的波动后可以恢复跟踪;SLS算法、P3CA算法和FREAK_P3CA算法在整个跟踪过程中取得了较准确的跟踪结果.在animal视频中IVT算法、MIL算法、FragT算法和L1算法都丢失了跟踪目标;SC算法、SLS算法、P3CA算法和FREAK_P3CA算法可以在该视频上实现鲁棒跟踪.通过stone、animal的实验证明本文算法能够较好地应对复杂背景问题.6.2算法定量分析6.2.1算法鲁棒性与准确性分析为了对8种算法进行公平对比,我们手工标注了10个视频序列的目标真实中心位置和真实目标的覆盖区域,并采用中心误差和重叠率对算法优劣进行衡量.中心误差用来衡量跟踪算法的准确性,定义为跟踪得到的目标中心位置与标注的真实目标中心位置的欧式距离.重叠率用来衡量跟踪算法的稳定性,定义为跟踪得到的跟踪框与真实目标跟踪框重叠的比例.假设第t帧的跟踪结果为Rt,真实目标覆盖区域为Rg,根据PASCALVOC①定义重叠率的计算公式如下:图5、图6分别展示了8种算法在10个视频上的中心点误差和覆盖率.FREAK_P3CA算法、P3CA算法和SC算法几乎在所有视频序列上都具有很好的鲁棒性.SLS算法可以应对光照变化和复杂背景问题,尤其在stone和animal序列中表现突出,如图5(i)和图5(g)所示;但当跟踪目标被严重遮挡或者出现频繁的平面外旋转时SLS算法表现不佳,如图5(d)和图5(h)所示.IVT算法可以很好地应对光照变化以及姿态变化,在car11以及davidin300中都取得了较小的跟踪误差,如图5(b)、图6(b)和图5(g)、图6(g)所示.但由于IVT算法采用全局外观模型,对遮挡较敏感,在occlusion1以及dollar序列中跟踪效果较差,如图5(c)、图6(c)和图5(f)、图6(f)所示.IVT算法在跟踪目标出现频繁平面外旋转或者背景复杂的情况下容易丢失跟踪目标,如图5(h)、图5(i)、图5(j)和图6(h)、图6(i)、图6(j)所示.FragT算法是为应对遮挡问题提出的,在场景简单且仅存在不相似目标遮挡时该算法可以实现很准确的跟踪.但当场景复杂,不仅存在不相似目标遮①EveringhamM,VanGoolL,WilliamsCKI,etal.ThePage10挡,还存在光照变化、旋转或相似目标遮挡的情况,FragT算法跟踪效果较差,如图5(c)、图5(f)、图5(g)和图6(c)、图6(f)、图6(g)所示.L1算法是一种基于模板的方法,该算法采用稀疏表示的方法,对遮挡以及光照变化引起的目标外观变化具有一定的鲁棒性.然而由图5和图6的曲线图可知,当场景复杂图58种算法在10个视频序列上的中心误差曲线时,L1算法跟踪效果较差.MIL算法利用在线多示例学习的方法进行跟踪,可以应对光照变化、遮挡、平面外旋转以及相似目标干扰等引起的目标外观变化.由图5和图6可以看出当跟踪目标不存在平面内旋转和尺度变化时,MIL算法跟踪误差都比较小,然而当目标发生旋转以及尺度变化时跟踪误差会增大.Page11图68种算法在10个视频序列上的覆盖率曲线图我们提出的FREAK_P3CA算法采用P3CA外观模型,该模型使用仿射变换的6个参数表示目标状态,可以有效地应对目标平面内、平面外的旋转以及尺度变化;并且采用相关关系模型作为粒子滤波的观测模型,避免了全局模型对遮挡敏感的问题;P3CA模型的在线更新算法使得该外观模型在应对光照变化、表情变化等引起的外观变化时具有很好的鲁棒性.FREAK_P3CA算法采用本文提出的FREAK多模态运动模型,有效地提高了算法的准确性.从表1和表2所示的8种算法在10个视频序列上的跟踪中心误差和覆盖率可以看出,FREAK_P3CA算法在大多数视频上取得了较小的中心误差和较大的覆盖Page12率,该实验结果表明FREAK_P3CA算法性能稳定,可以鲁棒地应对光照、旋转、遮挡、复杂背景等情况.表110个视频上8种算法的跟踪中心误差图像序列FragTMILL1IVTSLSSCP3CAcar4327.2677.26202.165.576.965.166.775.37car1132.677.4826.941.872.622.412.252.05occlusion130.6526.8211.5140.432.481.433.532.99faceocc214.1310.7522.4910.0218.597.677.675.78girldollar39.4921.9975.7814.484.043.627.242.65davidin30037.6112.7477.323.8224.303.046.384.58sylv14.4812.8758.1457.4251.858.3612.823.91stone81.9773.911.6626.671.243.291.431.67animal80.67107.49170.63165.825.5010.2810.1210.16总体66.1937.9865.1043.3418.234.796.114.20图像序列FragTMILL1IVTSLSSCP3CAcar40.220.310.240.920.900.910.870.90car110.110.590.450.820.770.770.810.84occlusion10.550.370.680.380.900.920.830.85faceocc20.680.720.600.770.600.790.830.87girl0.820.440.840.620.410.890.870.87dollar0.380.570.190.670.860.870.760.90davidin3000.280.430.220.680.360.790.620.72sylv0.560.550.240.360.360.670.560.78stone0.150.150.690.480.710.650.740.73animal0.180.090.040.110.810.700.700.70总体0.390.420.420.580.670.800.750.826.2.2算法计算效率分析为考察本文算法的计算效率,本节我们对8种算法的运行时间进行了分析.公平起见,所有使用粒子滤波框架的算法(FREAK_P3CA算法、P3CA算法、SLS算法、SC算法、L1算法、IVT算法)在每个视频序列的跟踪过程中都采用600个粒子,其他未使用粒子滤波框架的算法使用作者默认参数设置.所有算法在同样的机器配置上运行,机器配置如下:Dell,Intel?core(TM)i7-2600,3.40GHzCPU,4GB内存.8种算法在10个视频序列上的计算效率如表3所示,图像序列FragTMILL1IVTSLSSCP3CAcar41.1111.760.1924.753.590.2811.705.96car113.8213.110.1725.715.320.4311.997.29occlusion13.7310.960.1824.275.160.4012.576.62faceocc23.7813.530.1724.515.040.4013.516.96girl3.6114.010.2124.875.460.4611.766.93dollar3.7613.620.2024.395.030.3713.026.47davidin3003.9517.120.1825.515.170.3817.047.45sylv3.9312.370.2124.374.920.3110.096.39stone3.7314.640.1725.525.280.4513.967.04animal1.2211.260.2024.253.250.3911.926.38总体3.2613.240.1924.824.820.3912.766.75IVT算法运行效率最高,MIL算法和P3CA算法取得了次优的运行效率;由于FREAK多模态运动模型的引入,导致我们的FREAK_P3CA算法运行效率比单独使用P3CA算法的运行效率低,但明显比SC算法、L1算法、SLS算法和FragT算法运行效率高.7结论本文提出了基于FREAK和P3CA的目标跟踪算法.基于FREAK的多模态运动模型,有效缩小了目标搜索空间,提高了跟踪器的准确性.P3CA外观模型,使用图像子区域间的典型相关性模型克服了全局外观模型对遮挡、运动模糊敏感的缺点,同时利用PCA很好地解决了CCA用于目标跟踪时的高维小样本问题,提高了计算典型相关性的精度,降低了计算复杂度.P3CA模型的在线更新算法在降低时空复杂度的同时,使算法可以有效地应对跟踪过程中目标外观变化.通过在10个视频上与6种经典算法的对比实验表明,本文提出的算法能够很好地应对光照变化、尺度变化、旋转、遮挡以及复杂背景等问题,当出现目标遮挡的情况时,本文的算法表现尤为突出.致谢衷心感谢提供修改意见的审稿专家和编辑!
