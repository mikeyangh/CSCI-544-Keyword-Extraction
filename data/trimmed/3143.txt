Page1TKEP:海量数据上一种有效的Top-犓查询处理算法韩希先1)杨东华2)李建中1)1)(哈尔滨工业大学计算机科学与技术学院哈尔滨150001)2)(哈尔滨工业大学基础与交叉科学研究院高性能计算中心哈尔滨150001)摘要在许多应用领域中,top-k查询是一种十分重要的操作,它根据给定的评分函数在潜在的巨大的数据空间中返回k个最重要的对象.不同于传统的TA算法,NRA算法只需要顺序读就可以处理top-k查询,从而适合于随机读受限或不可能的场合.文中详细地分析了NRA算法的执行行为,确定了增长阶段和收缩阶段中每个文件需要扫描的元组个数.文中发现在海量数据环境中,NRA在增长阶段需要维护大量的候选元组,严重影响了算法的执行效率.所以,文中提出一种新的海量数据上的top-k查询算法TKEP,该算法在查询的增长阶段就执行早剪切,从而大大减少增长阶段需要维护的候选元组.文中给出了早剪切操作的数学分析,确定了早剪切操作的理论和实际剪切效果.据作者所知,该文是第一篇提出在top-k查询的增长阶段执行早剪切的文章.实验结果表明,和传统的NRA相比,TKEP在增长阶段维护的元组数量减少3个数量级,需要的内存量减少1个数量级,TKEP算法获得1个数量级的加速比.关键词海量数据;top-k;早剪切;TKEP1引言在许多应用领域中,例如Web搜索、信息检索、多媒体数据库和数据挖掘等,top-k查询是一种十分重要的操作,它根据给定的评分函数在潜在的数据空间中返回k个最重要的结果.处理top-k查询时,系统通常根据用户的要求对涉及到的每个对象的属性计算一个数值来反映该属性的特点,然后利用一个单调评分函数聚集多个属性的数值作为该对象的权重,top-k查询返回k个权重最高的对象作为查询的结果.处理top-k查询的一种方式是利用多维索引,可是当查询涉及的属性超过6时,多维索引的查询性能急剧下降(curseofdimensionality)[1].相对于多维索引,另一种更具有扩展性的方法是把数据表列存储化并且按属性值降序排列存储.Fagin等[2]提出TA算法在多个有序文件上执行top-k查询.top-k查询处理涉及到两种数据读方式来获得对象x在指定列文件的数值:顺序读和随机读.顺序读意味着处理完该文件中分数比x大的元组后可以获得x的分数,而随机读则直接获得该文件中x对应的属性值.在某些情况下,例如数据流和海量数据环境,随机读操作是受限的或过于昂贵的,人们利用NRA算法[3-6]来处理只支持顺序读的top-k查询.NRA的执行可以分为两个阶段:增长阶段(不断累积top-k候选元组直到找到top-k结果的阈值)和收缩阶段(不断剪切候选元组直到获得最终top-k结果).由于属性文件的降序排列和评分函数的单调性,NRA算法通常不需要处理完属性文件所有数据就可以结束查询并返回结果.随着涉及的属性数量、元组数量和返回的结果数量的增大,NRA的增长阶段需要维护的候选元组也越来越多,其维护费用也越来越大.尤其是增长阶段维护的数据超过给定的内存容量时,NRA算法将不得不把内存中的数据反复输出到磁盘,这必然会引起较高的费用,从而影响top-k查询的执行效率.本文详细地分析了NRA算法的执行行为,确定了增长阶段和收缩阶段中每个文件需要扫描的元组数,同时还分析了NRA算法在增长阶段需要维护的候选元组的数量.分析表明,在海量数据上,NRA在增长阶段需要维护大量的候选元组,严重影响了算法的执行效率.基于对NRA行为的分析,本文提出一种新的海量数据上的top-k查询处理算法TKEP(Top-KwithEarlyPruning).该算法和现有NRA算法的最大不同在于,该算法可以在查询的增长阶段就执行早剪切,从而减少增长阶段需要维护的元组数量.本文给出早剪切操作的数学分析,确定了早剪切的理论和实际剪切效果.指数间距bloomfilter表(EGBFT)是TKEP算法执行剪切时用到的数据结构,EGBFT的第j个元组是构建在对应文件的第1到第2j元组上的bloomfilter.本文提供了较全面的实验来评价TKEP的性能,实验结果表明,和传统的NRA相比,TKEP在增长阶段维护的元组数量减少3个数量级,需要的内存量减少1个数量级,TKEP算法获得1个数量级的加速比.本文的主要贡献在于:(1)本文提出了一种新的海量数据上的top-k算法TKEP.不同于传统的NRA算法,TKEP算法在增长阶段就开始执行早剪切操作,从而大大减少了需要维护的候选元组.据我们所知,本文是第一篇提出在top-k查询中执行早剪切的文章.(2)本文给出了NRA算法的行为分析,确定了增长阶段和收缩阶段需要扫描的元组数以及增长阶段需要维护的候选元组数量.(3)本文提出了早剪切操作的数学分析,并且确定了早剪切操作的理论和实际剪切效果.(4)本文利用较全面的实验比较了TKEP和NRA算法的性能.实验表明,不管在执行时间还是内存消耗方面,TKEP比NRA算法都具有较大的优势.本文第2节给出本文的背景和问题定义;第3节给出NRA的行为分析;TKEP算法在第4节中介绍;实验和性能分析在第5节中给出;第6节和第7节分别是相关工作和本文的结论.2背景和问题定义给定具有N个元组的表T,每个元组具有M个属性A1,A2,…,AM.表T存储为列文件集合LS={L1,L2,…,LM},每个列文件Li的模式为Li(RID,Ai),其中RID表示元组的标识符,Ai表示元组在属性Ai上的值.t∈T,如果t.RID=ridi,t.Ai=ai,则(ridi,ai)∈Li.Li根据Ai的值降序排列.F是定义在m个属性上的评分函数,不失一般性,假设F定义在A1,A2,…,Am,F(t)=∑mt.Ai),wi是评分函数F定义在属性Ai上的权重.通常,F是单调函数,即t1,t2∈T,如果对所有1im,t1.Ait2.Ai,那么F(t1)F(t2).Page3Top-犽查询.给定表T和涉及到m个属性的评分函数F,top-k查询返回表T的k子集R(k<N),ti∈R,tj∈(T-R),F(ti)F(tj).通常,m10[7].经典的ThresholdAlgorithm(TA)算法要求同时支持顺序读和随机读.TA以round-robin方式读取m个列文件的元组,如果元组t第一次出现,则利用随机读从其它(m-1)个列文件中获得t的其它属性值,得到t的分数F(t).TA利用优先队列PQ维护分数最大的k个元组,令PQ.min表示PQ中最小的分数.假设所有列文件最后读取的元组为(rid1,a1),…,(ridm,am),则TA算法的阈值threshold定义为τ=F(a1,…,am).随着列文件的扫描,TA算法不断更新PQ和τ.当PQ.minτ时,PQ维护的就是top-k的结果,TA算法结束.当m个列文件可以放入内存时,TA算法可以处理top-k查询.但是,在海量数据环境中,内存甚至无法完全容纳单个列文件.此时,top-k查询的列文件都存储在磁盘,每次随机读需要完全扫描其他(m-1)个列文件,费用极高.NRA算法只需要顺序读就可以完成top-k查询.NRA以round-robin方式依次读取m个列文件的元组,并且维护见到的每个元组t的上界Fubt.Aiu),在NRA的处理过程中,如果t.Ai已经出现,则t.Aiu=t.Ai,否则t.Aiu=MAX(Ai),其中MAX(Ai)表示属性Ai的最大值;Flbt.Ail),在NRA的处理过程中,如果t.Ai已经出现,则t.Ail=t.Ai,否则t.Ail=MIN(Ai),其中MIN(Ai)表示属性Ai的最小值.NRA利用优先队列PQ维护t最大的k个元组.NRA算法阈值τ的定义和TAFlb算法的类似.NRA的执行分为两个阶段:增长阶段和收缩阶段.增长阶段利用Hash表维护见到的候选元组集合C直到PQ.minτ,此时我们可以肯定top-k结果包括在C中;在收缩阶段,NRA逐渐剪切候选元组并且更新PQ,当PQ.minFubt∈(C-PQ))时,PQ维护的就是top-k的结果,NRA算法结束.虽然NRA只需要顺序读来处理top-k查询,但是它也存在着如下问题:NRA在增长阶段累积候选元组,直到满足给定阈值条件,根据下节的分析,这使得增长阶段将维护大量的数据,甚至超过内存容量.此时,NRA算法将不得不把内存中的数据反复输出到磁盘,这会引起较高的费用.TKEP算法采用早剪切的方法在增长阶段就执行剪切操作,从而减少了增长阶段需要的内存量,加快了top-k查询的执行.3NRA行为分析我们先给出本节需要用到的定义.定义1(位置索引).给定表T,元组t∈T的位置索引PI(PositionalIndex)是i,如果t是T的第i个元组.我们用T(i)来表示表T中位置索引为i的元组.令T1和T2分别表示增长阶段和收缩阶段每个列文件需要扫描到的位置索引值.3.1节介绍如何确定T1和T2,3.2节分析NRA在增长阶段需要维护的候选元组数.由于本文重点在于讨论早剪切操作,为更清晰地分析问题,假设评分函数F的权重都为1,属性在值域[0,1]内均匀分布并且属性间独立分布.3.1确定犜1和犜2保守地估计,当有k个元组前m个属性A1,…,Am都在增长阶段出现时,增长阶段结束,因为此时肯定满足条件PQ.minF(L1(T1).A1,…,Lm(T1).Am).令T1表示T1的估计值,T1的值对应着需要扫描m个列文件的元组个数使得有k个元组的对应m个属性都出现.t∈T,P(t.AiLi(T1).Ai)=T1/N,t.A1,…,t.Am同时分别出现在L1,…,Lm的前T1个元组的概率p=(T1/N)m.如果把任意元组t的前m个属性出现在列文件L1,…,Lm的前T1个元组的结果看作一次成功的事件S,则成功的次数满足二项式分布BD(N,p),该二项式分布的期望是Np.要获得T1的值,一种简单的方法是令Np=k,可以得出T1=N×(k/N)1是分布BD的方差是Np(1-p),该方法无法保证能够获得至少k个满足条件的元组.根据棣莫弗-拉普拉斯定理,当n较大时,参数为(n,p)的二项分布可以很好地近似为均值为np、方差为np(1-p)的正态分布.由于海量数据中,N很大,p=(T1/N)m很小,所以分布BD可以用正态分布ND(μ,σ2)来代替,其中μ=Np,σ2=Np(1-p).定理1.T1=N×[(-b+b2-4槡ac)/(2a)]1以99.9968%的概率保证事件S成功的次数不少于k,其中,a=N2+16N,b=-(2Nk+16N),c=k2.证明.正态分布ND(μ,σ2)如图1所示.已知Page4如果k=μ-4σ,那么以99.9968%的概率可以保证正态分布ND(μ,σ2)的x轴的值不小于k,即事件S成功的次数不少于k.(k=μ-4σ)(k=[Np-4Np(1-p槡)])(N2+16N)p2-(2Nk+16N)p+k2=0.解上述一元二次方程得样保守地获得T2的估计值T2.其中,a=N2+16N,b=-(2Nk+16N),c=k2.由p=(T1/N)m,得T1=N×[(-b+b2-4槡ac)/(2a)]1m(解方程时我们丢弃了另一个不合理的解).增长阶段结束后,NRA进入收缩阶段.我们同定理2.T2=mT1时,NRA算法结束.证明.已知,当增长阶段结束时,PQ.minF(L1(T1).A1,…,Lm(T1).Am).在收缩阶段,PQ.min的值单调递增.令C表示增长阶段维护的候选元组集合,当PQ.minFubNRA算法结束.令Pm表示出现m个属性的元组集合.可以肯定,如果F(L1(T1).A1,…,Lm(T1).Am)t(t,t∈(C-Pm)),PQPm,则NRA算法结束.Fub图2增长阶段维护的元组个数因为,t∈Pm-PQ,必然有PQ.minF(t).t∈(C-Pm),要排除t,需要扫描m个列文件的最大元组数Tmax对应着如下情况:t的(m-1)个属性取最大值1,剩余一个属性值较小,即F(L1(T1).A1,…,Lm(T1).Am)=(1-T1/N)×mFt=1×(m-1)+(1-Tmax/N),解此不等式,我们得到TmaxN+N×(m-1)-m×(N-T1)=mT1,则当T2=mT1时,NRA算法结束.证毕.定理1和定理2证明T1和T2以极高的概率(99.9968%,根据后文早剪切的操作方法,实际的概率还要远高于该值)保证T1T1,T2T2,所以本文的剩余部分认为T1和T1可以互换,T2和T2可以互换.3.2NRA在增长阶段需要维护的数据量NRA算法在增长阶段不对元组进行剪切[4-5],由定理1知,T1=N×p1/m,p=(-b+b2-4槡ac)/(2a)<1,则T1的值随着m的增大而指数级增长,随着N和k的增大而多项式级增长.接下来,我们分析在增长阶段NRA需要维护的元组数,从而更清楚地理解NRA在增长阶段所需要的内存量.t∈T,P(t.AiLi(T1).Ai)=T1/N(1im),令NUM(t,T1)表示t满足条件t.AiLi(T1).Ai的属性个数,则NUM(t,T1)满足二项式分布BD2(m,T1/N),P(NUM(t,T1)=m)=mNRA在增长阶段维护的元组数量m()×T1/()Nm×(1-T1/N)(m-m),所以NUMtuple=∑m图2(a)说明了当N=12×108,k=20时,随着m的变化,增长阶段需要维护的元组数量.可以看到,随着m的增长,维护的元组数量呈指数级增长,Page5其增长趋势和T1的增长趋势一致.图2(b)说明了当m=4时,N和k的变化对维护元组数量的影响.固定k=20,随着N从4×108增长到20×108,元组数量基本呈线性增长;固定N=12×108,随着k从5增长到25,元组数量也呈线性增长,但是其增长速度较慢.总的来看,由于传统的NRA算法在增长阶段不执行剪切操作,在海量数据上执行top-k查询时,增长阶段维护大量的候选元组,从而严重影响查询的执行效率.接下来介绍TKEP算法如何在增长阶段执行早剪切操作.4TKEP算法本节主要介绍Top-KwithEarlyPruning(TKEP)算法.4.1节给出了早剪切的数学分析,4.2节介绍了指数间距bloomfilter表的构造,4.3节描述如何实现TKEP算法.4.1早剪切的数学分析早剪切在top-k的增长阶段就开始对每个候选元组执行剪切操作,从而尽可能地减少top-k处理需要维护的候选元组,同时加快top-k的执行速度.早剪切基本规则.由定理2,t∈C,如果i(1im),t.Ai<Li(T2).Ai,t肯定不是top-k的结果.如果t的属性在增长阶段出现了i次,t无法被早剪切的概率是Pi的计算公式解释如下:假设元组t有i个属性出现在对应列文件的前T1个元组,要使得t不会被早剪切,则t的其余m-i个属性必须全部在对应的列文件的第T1和第T2元组之间出现.给定t.AiLi(T1).Ai,P(Li(T2).Ait.AiLi(T1).Ai)=(T2-T1)/(N-T1),从而得到Pi的计算公式.令NUMremain表示候选元组集合C中无法被早剪切的元组数量,计算如下:利用NUMtuple和NUMremain,早剪切操作在理论上可以剪切的元组个数NUMpru=NUMtuple-NUMremain,即令fp表示早剪切操作可以剪切的元组占增长阶段见到的所有元组的比例,fp=NUMpruNUMtuple=∑m所以早剪切的理论效果取决于Pi的取值.利用定理1和定理2的结果,Pi=T2-T1N-T()1[=(m-1)×[(-b+b2-4槡ac)/(2a)]1/m其中,a、b和c的取值如定理1所示.可以看出,Pi的值较小,因为Pi≈[(m-1)×(2k/N)1/m](m-i).当N=12×108,m=4,k=20时,Pi=0.043(4-i).给定m,随着i的减小,Pi指数级地减小,这也符合直观的感觉,即如果元组t在增长阶段出现的属性越少,则元组t越不可能是top-k的结果.观察NUMi的计算公式,我们发现在增长阶段,绝大多数的元组的属性只出现1次或者2次,即NUM1和NUM2的值比NUMi(3im)要大很多,例如N=12×108,k=20,m=4时,NUM1/NUMtuple=97.87%,NUM2/NUMtuple=2.1%.再加上Pi的值很小,尤其在i较小时,1-Pi的值就接近于1,所以fp的值接近于1.这就意味着早剪切算法在理论上可以剪切绝大多数的无用元组.图3(a)给出了N=12×108,k=20,m变化时的剪切效果.可以看到,剪切比例都在99%以上,虽然从m=3开始,剪切比例开始降低,但是即使m=6时,剪切比例仍维持在99.59%.这是由于随着m的增大,T1随着m的增长而指数级增加,给定N=12×108不变,增长阶段有更多的元组找到了更多的属性,从而降低了剪切比例.从m=2到m=3,剪切比例有所增加,这是因为m=2时,早剪切操作只能剪切属性在增长阶段只出现过1次的元组,而m=3时,早剪切操作还可以剪切属性在增长阶段出现2次的元组,所以剪切比例增加.可是,当m3时,T1的增加对剪切比例的影响超过了属性增加对剪切比例的影响,所以此时剪切比例开始下降.Page6图3早剪切的理论剪切效果图3(b)给出了m=4,k=20,N变化时的剪切效果.我们看到随着N的增大,剪切比例越来越大,这是由于更大的N使得属性值在列文件中的分布越分散,从而早剪切可以剪切的元组也越来越多.通过分析,早剪切操作理论上可以剪切绝大多数的候选元组,从而大大减少了top-k处理需要的内存量,也加快了top-k的执行速度.4.2指数间距bloomfilter表(EGBFT)Bloomfilter[8]是一种简洁的概率数据结构,用来判断给定元素是否是集合的成员.用于集合S={x1,x2,…,xn}成员查询的bloomfilter实现为一个a位的比特向量,初始时每个位都是0.bloomfilter用b个值域为[1,…,a]的独立Hash函数h1,h2,…,hb来构建和探测bloomfilter.x∈S,bloomfilter的第hi(x)(1ib)位设为1.要判断给定元素y是否属于集合S,bloomfilter判断是否所有的第hi(y)(1ib)位都是1.如果有任何一位为0,则y肯定不是S的元素.否则,bloomfilter认为y属于S.当然,即使y不属于S,bloomfilter也可能返回y属于S的结论(falsepositive).但是,bloomfilter对于属于S的元素肯定返回正确的结论.令fpr表示bloomfilter固有的falsepositiverate,即不属于集合S的元素被bloomfilter误认为是集合元素的概率.给定b=(a×ln2)/n时,falsepositiverate最小,fpr=(1/2)b.下面给出TKEP用到的指数间距bloomfilter表的定义.定义2(指数间距bloomfilter表).给定包括N个元组的列文件Li,EGBFTi是Li上的指数间距bloomfilter表,如果EGBFTi满足条件:(1)|EGBFTi|=log2N,(2)EGBFTi(j)是构建在Li(1)到Li(2j)的RID属性上的bloomfilter.EGBFT的构造如图4所示.给定任意列文件Li,EGBFTi占据的磁盘空间与元组数量N和fpr有关.EGBFTi(j)是定义在2j个元素上的a位并且具有b个Hash函数的bloomfilter,如果b=(a×ln2)/2j,fpr(falsepositiverate)最小,fpr=(1/2)b.给定fpr和元组数量2j,我们得到最优的bloomfilter长度已知,|EGBFTi|=log2N,令SIZEEGBFTi表示EGBFTi占据的磁盘空间,则根据SIZEEGBFTi的计算公式,EGBFT表占据的磁盘空间和元组数量呈线性关系.由于本文中TKEP采用的fpr=0.01,EGBFTi占据的磁盘空间不超过列文件大小的30%.TKEP在每个列文件L1,L2,…,LM上预先构建各自的EGBFT表.4.3算法实现4.1节给出了令人欣喜的早剪切的理论效果,可是在实际中,理论效果是很难实现的,因为它要求Page7快速返回任意位置索引范围的RID集合的成员检测结果.Bloomfilter是一种简洁的成员检测数据结构,考虑到早剪切涉及的位置索引范围的不固定,所以TKEP利用EGBFT表来执行早剪切操作.利用定理2给出T2的值,TKEP首先把EGBFTi(j)(1im)读入内存,其中j=log2T2,然后利用内存中维护的bloomfilter对增长阶段碰到的元组执行早剪切操作.早剪切的代码如算法1所示.算法1的实际效果不如早剪切的理论效果,其主要原因有两个:(1)EGBFTi(j)涉及的元素数量要大于T2;(2)bloomfilter固有的falsepositive问题.算法1.EarlyPruning(RIDrid).//functiontestInBF(bf,rid)isusedtodetermine//whetherridiscontainedinSonwhichbloomfilter//bfisconstructed,trueisin,falseisnot1.intindex=log2T22.fori=1tom3.booleaninflag=testInBF(EGBFTi(index),rid)4.if(!inflag)5.returntrue;6.enfif7.endfor图5早剪切的实际剪切效果如图5(b)所示,在N=12×108时,实际剪切比例要低于其它点的剪切比例,这是由于N=12×108时,T2=67738932刚好超过EGBFT(26),TKEP载入EGBFT(27)执行早剪切操作,EGBFT(27)是构建在第1和第134217728元组的RID属性上的bloomfilter,该范围几乎是T2的两倍,所以N=12×108时的剪切比例较低,而N取其它数值时并没有出现类似的最差情况.令SIZEadded表示需要读入内存的EGBFT元组大小,则8.returnfalse;接下来,我们分析算法1的实际剪切效果.t∈C,假设t的属性在增长阶段出现了i次,t无法被算法1剪切的概率是Pi解释如下:假设元组t有i个属性A1,…,Ai出现在列文件L1,…,Li的前T1个元组,要使得t不会被算法1剪切,那么给定(i+1)dm,存在如下两种情况:(1)Ld(2j).Adt.AdLd(T1).Ad,(2)t.Ad<Ld(2j).Ad,但是以概率fpr,EGBFTd(j)认为Ld(2j).Adt.AdLd(T1).Ad.令fp表示算法1的实际剪切比例,计算公式如下:由于i,Pi>Pi,所以fp<fp,但是算法1仍然可以较好地完成剪切工作.如图5(a)所示,即使m=6时,算法1仍然可以获得98.4%的剪切比例,而在图5(b)中,算法1最低可以获得99.85%的剪切比例.令SIZEpruned表示早剪切操作剪切掉的元组大小,Ltuple表示每个元组在Hash表中占据的空间,则SIZEpruned=Ltuple×∑m通过本文的实验可知,读入内存的EGBFT元组的空间比剪切掉的元组占用的空间要小1个数量级,而且,内存中的EGBFT元组不需要参与任何更新操Page8作,绝大多数候选元组的剪切不但节省了大量的内存空间,还减少了数据维护和更新的费用,这使得在内存中维护EGBFT的代价远小于早剪切带来的收益.TKEP的执行代码如算法2所示.算法1可以较好地执行单次剪切操作.可是,在增长阶段,如果同一元组的多个不同属性在不同列文件出现,算法1需要被调用多次,而其中只有一次剪切是必要的.一种解决方法是记录已经剪切的元组,如果已剪切的元组的其他属性再次出现,则不需要再执行剪切.可是,这样会增加内存的消耗,违背早剪切操作的初衷.TKEP采用的方法是:即使增长阶段出现单个元组的多个属性,TKEP也仍然执行多次剪切操作.这样做的原因是,在增长阶段,绝大多数的元组其属性只出现过1次或者2次,当N=12×108,k=20,m=4时,增长阶段属性数量只出现1次的元组占所有元组的97.87%,属性数量值出现2次的占2.1%,需要的剪切判断次数只比最优情况多2.14%,而且,bloomfilter的检测操作可以在内存中快速执行,从而TKEP可以较小的代价获得较大的收益.算法2.TKEP(L1,…,Lm,F)//PQ:priorityqueuetomaintainkhighestlowerbound//C:tuplesetinhashtable1.booleanbeGrowing=true;2.hashtableht;3.loopfrom4~29;4.readnextobjectxinround-robinwayandupdate5.if(beGrowing)6.if(earlyPruning(x.rid))7.continue;8.else9.Hashtable_Valuevalue=update_hashtable(ht,10.if(value.partialScorePQ.min)11.update(PQ,value)12.endif13.if(PQ.minthreshold)14.beGrowing=false;15.endif16.endif17.else18.Hashtable_valuevalue=ht.get(x.rid)19.if(value==null)20.continue;21.else22.Hashtable_Valuevalue=23.if(value.partialScorePQ.min)24.Update(PQ,value)25.endif26.if(PQ.minFub27.returnPQ28.endif29.endif30.endifTKEP算法对增长阶段见到的每个元组执行早剪切操作,从而减少了需要维护的候选元组数量.在处理过程中,TKEP不断更新threshold和PQ,当PQ.minthreshold时,TKEP离开增长阶段进入收缩阶段.由于此时TKEP维护的元组数量很少,所以收缩阶段可以较快地执行.在收缩阶段,TKEP采用类似于LARA[4-5]的方式维护候选元组的上界,同时忽略不在候选元组集合中的元组,因为它们不可能是最终的top-k结果.当PQ.minFubPQ)时,TKEP执行结束,PQ维护的k个元组就是top-k的最终结果.5性能评价和分析5.1实验设置本节通过实验评价TKEP的性能,我们利用Java语言实现TKEP和NRA算法,jdk版本为jdk-6u17-windows-x64,实验在HPxw8600工作站(8×2.8GHzXeonCPU+32GB内存+1.4TB硬盘+64bitwindows)上执行.实验从3个方面来比较算法的性能:元组数量N、返回结果数量k和涉及到的属性数量m.实现的NRA算法结合了传统的NRA[3]、LARA[4-5]和TBB[6]算法.根据m的数值,我们生成m个属性的表,每个属性的值在[0,1]上均匀分布,该表的每个属性单独存储为列文件,同时实例化每个属性所在元组的标识符,列文件根据属性值降序排列后存储.实验用到的评分函数F=∑m参数默认值N12×108k20m元组数量N分别取值4×108、8×108、12×108(默认值)、16×108和20×108,返回结果数量k分别取值5、10、15、20(默认值)和25,属性数量m分别Page9取值2、3、4(默认值)、5和6.在实验中,我们设置内存Hash表维护的最大元组数量是4×107,此时系统占用的内存空间大约是6G.当需要维护的元组数量超过该数量时,我们采用类似于LARA的处理方法,把Hash表的元组输出到磁盘,并且和指定缓存文件(初始为空)合并,同时更新PQ,然后清空Hash表,继续执行接下来的操作.该种方法可以处理维护的元组数量超过内存最大容量的情况,可是该方法延长了top-k的增长阶段的执行时间,因为在两次文件合并之间,当前Hash表维护的不是增长阶段已经看到的所有元组信息,而只是上次Hash表清空后看到的部分元组信息,只有当下一次文件合并操作时,我们才可以更新已经看到的所有元组信息.5.2实验1:犖的效果固定k=20和m=4,实验1评价N变化时图6元组数量的影响图6(c)说明了TKEP和NRA的执行所需要的内存量,平均来看,NRA需要的内存量是TKEP的15.29倍,其中TKEP所需要的大部分内存用来维护对应的EGBFT元组,因为绝大多数的候选元组都被剪切了.从图6(c)可以看到,在N大于8×108时,NRA所需要的内存量基本不变,这是由于我们限制了内存的Hash表最多维护4×107个元组,而TKEP算法的性能.如图6(a)所示,和NRA算法相比,TKEP获得的平均加速比是16.08.在图6(a)中,我们注意到当N=12、16和20(×108)时,NRA的执行时间增长的幅度不大,其原因在于此时需要维护的所有元组数量超过最大限制,只有当前Hash表的部分元组信息和磁盘上的缓存文件合并时,我们才可以获得已经看到的所有元组信息和更新PQ的信息,这就把检查增长阶段是否结束的检测推迟到了下次文件合并操作,这可以在图6(b)中得到证实,当N=12、16和20(×108)时,NRA在增长阶段维护的基本相等的元组数量.由于采取早剪切操作,TKEP可以剪切掉在增长阶段见到的绝大多数元组,TKEP维护的元组数量比NRA维护的平均少1448.85倍,并且本文对早剪切的理论分析结果和实际运行结果相符.N=12、16和20(×108)时,NRA需要维护的元组数量都超过内存的最大限制,当N=8×108,NRA需要维护的元组数量(35913291)虽然没有超过可是也很接近最大限制.当N=12、16和20(×108)时,TKEP所需要的内存量也基本相等,这是由于在TKEP的执行过程中,绝大多数的内存是用来维护EGBFT元组的,当N=12、16和20(×108)时,Page10TKEP需要维护同样的EGBFTi(27)(1im)元组,所以需要的内存量基本相等.图6(d)比较了估计的T2和实际的T2,我们发现T2>T2,从而验证了本文对NRA的行为分析.5.3实验2:犽的效果固定N=12×108和m=4,实验2评价返回结果数量k变化时TKEP的性能.如图7(a)所示,TKEP的执行时间平均比NRA的执行时间快20.07倍,这是由于TKEP的早剪切操作及时地剪切了绝大多数的候选元组,如图7(b),TKEP在增长阶段需要维护的元组数量比NRA需要维护的平均少3194.66倍.我们注意到,在k=10、15、20和25时,NRA的执行时间基本不变,其原因和5.2节的讨论类似,此时NRA需要维护的元组数量超过内存的最大限制,内存溢出处理把增长阶段结束的结论检查推迟到下次文件合并操图7返回结果数量的影响5.4实验3:犿的效果固定N=12×108和k=20,实验3评价涉及到的属性数量m变化时TKEP的性能.如图8(a)所示,TKEP的执行时间比NRA快了9.07倍,而且基本上从m=3开始,TKEP对NRA的加速比在逐渐减小.这是由于随着m的增大,T1随着m的增长而指数级增加,给定N=12×作,使得NRA在k=10、15、20和25时维护基本相等数量的元组.更少的元组数量使得TKEP需要更少的内存,如图7(c)所示,TKEP需要的内存量比NRA少16.57倍,TKEP需要的绝大多数内存是用来维护EGBFT元组,而在k=5、10和15时,TKEP需要同样EGBFTi(26)(1im),所以其消耗的内存量基本不变,k=20和25时,TKEP需要同样的EGBFTi(27),所以其内存量也相等.在k=10、15、20和25时,NRA消耗的内存量达到内存的最大限制,所以内存量基本维持不变.当k=5时,NRA需要维护的元组数(38181274)虽然没有超过但是也很接近内存最大限制,所以NRA在这组实验中对内存量的消耗基本不变.图7(d)比较了估计的T2和实际的T2,我们发现T2>T2,从而验证了本文对NRA的行为分析.108不变,增长阶段有更多的元组找到了更多的属性,从而降低了剪切比例,如图8(b),这使得TKEP需要维护更多的元组,但是TKEP维护的元组数量仍然比NRA少了320.56倍.如图8(c),TKEP需要的内存量比NRA少9.56倍.我们发现,在m=5和6时,NRA需要的内存量超过了预定的最大限制,这是因为在m=5时,NRA需要清空Hash表5Page11次,而m=6时,NRA需要清空Hash表9次,而Java采用的自动内存回收机制,这就使得在多次反复清空、插入Hash表操作时,有一部分内存没有被Java及时回收,从而造成NRA运行期间内存超过图8属性数量的影响6相关工作作为多个领域中一种重要的数据操作,top-k查询得到了研究人员的广泛关注[9].Bruno等[10]把top-k查询转换为数据库上的范围查询,从而可以利用现有数据库技术来直接回答top-k查询.Fagin等[2]提出ThresholdAlgorithm(TA)算法处理有序链表上的top-k查询.TA算法要求系统同时支持顺序读和随机读操作.相对于TA算法的round-robin读取方式,Guntzer等[11]提出Quick-Combine算法优先读取使算法阈值下降最快的链表,从而加快了TA算法的执行.Bast等[12]把top-k优化问题转化为顺序读和随机读的调度问题,从而获得最优的调度和性能.Akbarinia等[13]提出BestPosition算法来改进传统的TA算法,BestPosition算法利用随机读过程中获得的辅助信息来加快top-k处理.TA算法要求系统支持随机读操作,可是在有最大限制.这从另一个方面也说明了早剪切操作的必要性.图8(d)给出了估计的T2和实际的T2的比较,与之前的分析类似,我们发现T2>T2,从而验证了本文对NRA的行为分析.些情况中,例如数据流和海量数据环境,随机读操作是受限制的或者不可能的.Fagin等[3]提出NRA算法(NoRandomAccess)来处理只支持顺序读环境下的top-k查询.Guntzer等[14]提出的Stream-Combine算法改进NRA算法,优先读取使得算法阈值下降最快的链表.Mamoulis等[4-5]通过对NRA算法的分析,把NRA的执行过程分为增长和收缩两个阶段,并且提出LARA算法减少了top-k处理的计算费用和内存需求.Bruno等[15]和Marian等[16]提出Upper和Pick算法处理Web-accessible数据库的top-k查询.Hwang等[17]提出MinimalProbing算法来最小化top-k查询中的谓词评价费用.Pang等[6]提出TBB算法把NRA的round-robin数据读取过程转换为链表的顺序扫描,从而提高了磁盘效率.另一种处理top-k的方法是利用索引和视图.Chang等[18]提出OnionIndices来处理top-k查询,该方法把元组看作多维空间的点,利用预计算的数据点的闭包来回答top-k查询.Xin等[19]提出了Page12robust索引的概念来加快top-k处理,该方法把元组划分为多个连续的层次,任何top-k查询可以最多利用k层元组来回答.Zou[20]等通过构建支配图结构来改进top-k查询效率,预计算得到的支配图表示元组间的支配关系,top-k查询转换为图的遍历问题.Hristidis等[21]和Das等[22]提出利用实例化视图来加快top-k处理.7结论本文详细地分析了NRA算法的执行行为,确定了增长阶段和收缩阶段中每个文件需要扫描的元组个数.为解决NRA在增长阶段维护元组过多的问题,本文提出一种新的海量数据上的top-k查询算法TKEP,该算法在查询的增长阶段就执行早剪切,从而大大减少增长阶段需要维护的候选元组.本文给出了早剪切操作的数学分析,证明了早剪切操作的理论和实际剪切效果.实验表明,不管在执行时间还是内存消耗方面,TKEP比NRA算法都具有较大的优势.本文给出的TKEP算法假设涉及到的属性在其值域内均匀分布并且属性间独立分布,在后续工作中,我们将继续考虑把TKEP扩展到属性不均匀分布和属性相关的环境.
