Page1基于回归模型的高端容错计算机TPC-C性能估算研究刘迪翟季冬陈文光(清华大学计算机科学与技术系北京100084)摘要高端容错计算机的TPC-C性能测试由于成本高昂且时间漫长,导致市场上只有少部分产品进行了该项测试,无法满足生产商和购买者的需求,高端容错计算机领域需要一种简便快捷、低成本的TPC-C性能估算方法.文中分析了影响TPC-C性能的各种因素,以近5年来发布了TPC-C测试结果的服务器为样本,利用数理统计的方法,在服务器TPC-C性能与硬件指标之间建立了线性回归模型.优化后的模型估算精度达到95%以上,在一定程度上解释了服务器的硬件指标与TPC-C性能之间的因果关系,具备了方便准确地估算TPC-C性能的现实意义.文中所提出的将数理统计的方法用于TPC-C性能估算的思路以及搜集的大量相关数据,对今后该项研究具有重要意义.关键词TPC-C;性能估算;多元线性回归;硬件指标1引言高端容错计算机对国家安全和经济发展具有重要意义.然而,我国的银行、电信、统计等重要部门采用的高端容错机主要被IBM、HP等公司的产品垄断.使用这些服务器不仅价格昂贵,而且存在安全隐患.为此,“十一五”期间,我国开始研制国产高端容Page2错计算机.目前主要由华为和浪潮两家公司负责研制国产高端容错计算机.TPC-C是国际上评测高端容错计算机在线事务处理能力事实上的标准.然而,按照该标准,为了完成TPC-C评测,需要搭建相应测试环境,包括模拟用户端、数据库客户端和存储设备等.整套测试环境成本非常昂贵,而且测试周期长.例如,在TPC-C官方网站发布的数据中,一台达到200万TPMC值(TPC-C评测指标)的高端容错计算机,测试环境的开销高达一千六百万美元①.而且,TPC-C的测试和优化周期需要半年以上的时间.对高端容错计算机的设计人员,他们需要根据不同客户的需求设计不同型号的系统,提供合适的配置,包括处理器个数、内存大小、内存带宽等.系统设计人员往往需要在系统设计阶段就能够预测系统的在线事务处理能力,即TPC-C性能,尽量避免设计出的系统不符合客户需求.如何能够以较低成本、快速准确地预测不同设计方案和配置的系统将来的TPC-C性能,这对厂商加快系统研制周期,降低系统研制成本都具有重要意义.对高端容错计算机的用户来说,一个较为精确的性能模型也非常重要.例如,某单位想购置一套高端容错计算机,要求系统能够满足每分钟千万级的事务处理能力.然而由于TPC-C测试成本高且测试周期长,大厂商如IBM和HP也只是对其主流产品系列中的个别机型进行了完整测试,小厂商更是无力支付高昂的测试开销.新产品的测试结果往往要滞后半年以上才能公布,大大降低了对用户的指导意义.对用户来说,如有一种方法能够判断何种配置的系统恰好满足其需求,对于用户高效准确地选择机型也具有重要意义.针对上述问题,本文从TPC官网收集了近5年来大部分的TPC-C测试数据近40组,服务器的TPMC性能值分布在2万到600万之间,并分析了影响TPC-C性能的因素,收集相关的性能指标,通过将数理统计与TPC-C负载特征分析相结合的方法,在服务器的TPC-C性能与硬件配置参数之间建立了回归模型,通过参数诊断,确定了影响系统TPC-C性能的主要因素,给出最后预测模型.实验结果表明,该模型对于实验中验证样本的预测精度达到95%以上.本文第2节从TPC-C负载特征及测试环境角度,剖析影响TPC-C性能的硬件因素;第3节确定应用在回归模型中的硬件指标并收集相关数据;第4节利用最小二乘法求解回归参数,并对得到的回归模型做相关诊断及调整,最后用实例检验模型的准确度;第5节给出本文相关工作.2TPC-C性能分析2.1TPC-C负载特征及测试环境TPC-C(TransactionProcessingPerformanceCouncilBenchmark-C)是为联机事务处理系统制定的测试标准,该测试由一系列基本操作组成,这些操作代表了复杂的OLTP(在线事物处理On-LineTransactionProcess)的应用,考验了系统在这类环境下展现的性能.TPC-C测试过程模拟了一个真实应用环境———描述一个仓库供应商的货物管理行为,所以测试者可以直观地理解测试基准程序的组成[1].货物管理行为包含了5类请求:新订单事务是一个重量级的读写事务,并且为满足在线用户的操作体验而有严格的响应时间要求;支付事务是一个轻量级的读写事务,执行频率高并要求严格时间响应来满足在线客户的需求;订单状态查询事务是一个重量级只读数据库事务,执行频率低而时间要求严格来满足在线用户的需求;发货事务是一个执行度低时间要求低但必须要完成的事物;库存状态查询事务是一个重量级只读数据库事务,执行频率低,时间要求和一致性要求都低.TPC-C测试系统包括以下4个部分:模拟用户端、数据库客户端、服务器系统和存储系统,这几个部分通过以太网交换机或者光线交换机进行连接.如图1所示.①FujitsuLtd.TPCBenchmarkCFullDisclosureReport-Page3在TPC-C测试中,系统级的优化主要包括内存模拟用户端,用于模拟操作员在终端上的操作行为,向数据库客户端发出各类事务请求,并最终在此统计TPC-C测试结果.数据库客户端,接收操作员或模拟用户端的请求,生成事务的请求内容,向数据库服务器端发送请求,然后接收数据库服务器端的返回结果,将处理结果输出给操作员或模拟用户端.服务器系统端用于接收数据库客户端的请求,完成业务判断和业务处理,并将处理结果返回给数据库客户端,供客户端展示.存储系统端用于存储数据库的所有表项及数据库的系统级应用数据,接受数据库服务器端的统一管理与调度,能高效地完成各种IO请求及处理.系统优化、存储系统优化和I/O调度优化等.2.2影响TPC-C性能的硬件因素经过上述阐述,我们已经能够在理论上对TPC-C有了比较全面的了解,该测试所模拟的在线事务处理应用具备了如下特点:并发处理、多个网上终端会话同时存在、大量的硬盘读写操作、数据之间存在较多的访问与更新的竞争等等.TPC-C衡量的主要是服务器系统在处理数量庞大而单个规模较小的任务的吞吐率,即固定时间处理事务的数量.下面结合TPC-C负载特征,分析有哪些硬件因素影响TPC-C测试的结果.2.2.1CPU性能在程序运行过程中,最重要的CPU性能评价指标是CPU执行时间.关于程序CPU执行时间,有一个简单的公式[2]:CPU执行时间=在实际运行时,程序先由编译器编译成机器指令,然后计算机通过执行这些指令来运行程序.不同的指令完成的功能不同,所花费的时钟周期数就不同,CPI(每条指令的平均时钟周期数)是用来描述所有指令花费的时钟周期数的平均值.于是,执行某个程序的CPU时钟周期数便有了下面的公式:消耗CPU时钟周期数=指令数×每条指令的平均时钟周期数.于是我们就得到了影响机器性能的3个重要因素,其中,指令数取决于指令集系统结构,CPI的两个影响因素是指令集和内存系统性能,内存系统性能将在下一小节介绍,时钟频率由CPU的型号得到.高速缓存Cache利用了空间局部性和时间局部性的原理,大大提高了系统的性能.缓存的存取时间一般情况下是内存存取时间的五分之一,所以较高的命中率会使得访问数据的平均时间大大缩短,甚至接近缓存的存取时间.在影响命中率的诸多因素中,与硬件相关的是缓存相对于内存的容量.大多数芯片除了一级缓存(一般为64KB)外,还有二级缓存甚至三级缓存,我们只考虑离内存最近一级的缓存容量.相对于单个处理器,配置了多个处理器的系统性能得到了扩展,不同的处理器可以同时处理不同的任务,虽然处理单个任务的执行时间没有缩短,但提高了吞吐率.处理器的个数也是影响TPC-C性能的重要因素.2.2.2内存性能数据库系统非常依赖内存对数据进行缓存,因此如果系统内存不足,数据库系统一些可能的优化就无法进行,不能得到期望的性能.单个任务的执行时间也称响应时间,是指完成一个任务所需要的时间总和,包括磁盘存取时间、内存存取时间、输入输出(I/O)操作所需时间,以及操作系统为运行这个程序而必不可少的时间开销等.因此除了内存容量以外,内存带宽也是影响测试结果的重要因素.存储带宽通常考虑的是传输率(带宽),它表示单位时间存取数据量的大小,单位为KB/s或MB/s.2.2.3I/O性能待测系统与存储系统之间需要存储区域网络连接.显然TPC-C中的I/O操作所读写的数据都需要经过存储网络传输,当存储带宽超出单块HBA卡的带宽时,需要待测系统上安装多块HBA卡,HBA卡的带宽决定了待测系统到存储系统之间的I/O带宽上限.TPC-C测试的负载一般是较小操作的事务处理,I/O访问非常频繁,而且每个I/O操作所读写的数据量都不大,因此存储设备的IOPS性能是系统重要的配置指标.IOPS(Input/OutputOperationPerSecond),即每秒进行读写操作的次数,用来衡量硬盘(包括HDD和SSD)存取访问的性能指标.存储设备的IOPS主要由两个因素决定,一个是单个磁盘的设备类型,另一个是磁盘数量.经过上述分析,我们确定了影响TPC-C性能的硬件因素如下:CPU主频、CPU核的总量、线程数量、缓存容量、内存容量、内存带宽、磁盘IOPS值、磁盘数、HBA带宽.Page43解释变量指标的确定和数据收集多元线性回归将所研究的数据指标分为一个被影响变量(也称被解释变量,即为因变量,本文中为TPC-C性能)和一组影响变量(也称解释变量,本文中为影响TPC-C性能的因素),本节将确定解释变量,并收集数据.3.1解释变量指标的确定TPC-C性能与各个硬件指标之间的关系如果完全是线性关系,则代表每个硬件指标对TPC-C性能的作用互相独立,且各个作用可以互相叠加,这在实际情况中是不可能的[3].但我们可以在一定程度上将非线性关系转化为线性关系,尽量客观地描述各个硬件指标的影响.图2TPC-C值与主频、核数、线程数的线性关系图CPU的主频只能表达单个核的运算性能,影响单个任务的执行时间,而影响吞吐率的另一个重要因素是并行度.从硬件角度上来说,影响并行度的是同时工作的核的数量以及线程数.从收集到的数据也可以看出,主频低但核数多线程数多的系统可能拥有更好的TPC-C性能,相反,主频高但核数少线程数少的系统,TPC-C性能并不良好.散点图可以帮助我们更清晰地看到CPU各个指标对TPC-C性能的影响,散点图是数据点在平面直角坐标系上的分布图,可以表示因变量随某一个自变量变化的大致趋势.我们从已发布的TPC-C测试结果中选取了39份作为样本(样本数据见附录中附表1,关于该表中数据的详细说明在随后文中一一阐述),绘制了TPC-C值分别与主频、核数、线程数、主频×核数、主频×线程数的散点图,见图2.其中,TPCC表示Page5TPC-C测试结果值,单位为tpmC;主频单位为MHz;核数表示服务器拥有的核的总数,即“服务器系统所有的CPU个数×每个CPU上核数”,单位为个;线程数表示服务器运行的线程总数,即“服务器核的总数×每个核运行的线程数”,单位为个;主频×核数表示“主频×核的总数”,单位为MHz·个;主频×线程数表示“主频×线程总数”,单位为MHz·个.由图2可以直观地看出,“主频×线程数”与TPC-C性能的线性关系最为明显,我们初步设定,第1个影响因素x1=主频×线性数.散点图对于变量间关系的直观表达可以作为我们考察自变量时的参考,但不能成为判定该自变量是否合适的依据.后面可以看到,散点图上与因变量的线性关系不明显的自变量依然是影响因变量的重要因素.在上面5个散点图上,由于“主频×线程数”包含了主频、核数的信息,故舍弃其余4项.高速缓存由于大大提高了CPU对数据的存取速率而对系统的性能有显著影响,CPU访问缓存的命中率=命中次数/访问次数.而影响命中率的因素除了算法、数据特点外,与硬件指标相关的便是缓存容量相对于内存容量的大小,从理论上说,只要高速缓存的容量与内存容量保持适当比例,高速缓存的命中率是相当高的.基于此,关于高速缓存我们确定两个影响因素:x2=cache-T,表示服务器系统缓存容量的总和,它实际是“每个CPU的缓存容量×CPU个数”;x3=cachePmem,表示高速缓存(cache)的容量总和与内存(memory)容量总和的比值.类似地,关于内存容量我们确定两个影响因素:x4=memory,表示服务器系统内存容量总和;x5=memPcpu,表示能分摊给每个CPU芯片的内存大小,是内存容量与芯片个数的比值.x6=memPcore,表示能分摊给每个核的内存大小,是内存容量与核数量的比值.内存带宽显然是服务器系统的重要指标,业界有很多基准程序(Benchmark)用来测试系统的内存带宽,比如Stream、Lmbench.可惜的是,由于大多数发布了TPC-C值的服务器,并没有统一的内存带宽测试结果,我们这里采用理论上最大的内存带宽值.实际内存带宽与理论最大内存带宽存在差异,但为了数据的统一,我们容忍这方面的差异.内存带宽的理论最大值计算公式如下[2]:带宽=内存时钟频率×内存总线位数×本文研究过程中涉及的服务器采用的均为DDR、DDR2、DDR3类型的内存,内存总线位数总为64bit,倍增系数总为2,本文只考虑内存通道全部插满内存条的情况,则内存通道数由芯片的型号决定,内存时钟频率由内存型号决定.公式中的常数系数可以忽略不计,它们会在模型的回归系数中体现出来,所以可以用“内存时钟频率×内存通道数”来代表内存带宽,这就是第7个影响因素,x7=membw.x8=HBA,表示服务器与存储子系统之间主机总线适配卡的带宽总和.与磁盘的指标相对应,应该选取HBA可以支持的最大IOPS数来做解释变量,但在收集数据过程中发现,很多HBA的IOPS并没有发布,收集难度很大.为了数据的统一性,本文采用HBA的带宽指标做代替,但由于各个服务器的架构各异,部分服务器的磁盘子系统内集成了HBA卡的功能,而这部分功能在相关资料中只是描述性的,没有提供具体数据,导致这一项解释变量的数据质量较差.x9=IOPS,是对磁盘的最大访问频次的描述,值得注意的是,这里的IOPS值并不是所有磁盘IOPS值的总和,由于大多数服务器所配置的磁盘的规格和类型都不是单一的,每一种磁盘的IOPS值也不同,尤其对于HDD和SSD两种磁盘类型,IOPS值相差非常大.本文用作自变量的IOPS值是将不同磁盘的IOPS值对其容量大小做加权平均的结果.指令集是CPU操作所执行的指令的集合,包含的要点非常复杂,例如操作指令表、数据类型、指令格式、寄存器、寻址等,很难用一个量化的数据来描述指令集,故将指令集的类型作为定性的数据参与线性回归.由于指令集与CPU的设计关系紧密,对于指令集的定性描述也在一定程度上表达了不同类型CPU之间的差异.在本文所收集的样本中,AMD的CPU全部为Opteron系列,与Intel的Xeon系列CPU同属于x86-64架构,采用的指令集同为复杂指令集运算CISC(ComplexInstructionSetComputing)系列,但为了对不同厂商的CPU有所区分,我们将其视为两个变量;与Xeon系列有所不同,同为Intel厂商的Itanium系列CPU采用的指令集为显示并行指令集运算EPIC(ExplicitlyParallelInstructionComputing);IBM厂商的power系列CPU采用的指令集为自己研发的基于精简指令集RISC(ReducedInstructionSetComputing)架构的指令集体系,称为POWERISA.在线性回归中,要先将定性变量做数据化处理[4],方法是按性质的种类设置虚拟变量,将虚拟变量的取值设定为只能取0或1两个值,满足性质的Page6取1,不满足的取0.具体地,我们将上述已经按指令集类型和CPU类型划分好的4种性质设置成3个虚拟变量,分别为x10=Xeon,x11=AMD和x12=POWER.对于Intel的Xeon系列CPU,x10=1,x11=0,x12=0;对于AMD的Opteron系列CPU,x10=0,x11=1,x12=0;对于IBM的POWER系列CPU,x10=0,x11=0,x12=1;对于Intel的Itanium系列CPU,则全取0,x10=0,x11=0,x12=0.3.2数据收集利用统计分析的方法建模,是以大量数据为基础的,数据的质量直接影响模型的可靠性、准确性、可用性.在计算机领域,数据的收集要注意两个关键点:(1)数据的来源要客观、权威.每时每刻,都有大量关于计算机领域的数据在网上发布,有的来源于生产厂商、盈利组织,有的来源于学术机构、科研院所,还有很多来自对相关问题有兴趣的个人和团体.不同的来源有各自不同的意图和研究角度,对同一问题也会有不同的理解程度和表达方式,很多数据不仅不具备权威性,而且有自相矛盾的情况,不能够作为继续研究的基础.(2)数据的标准要统一.计算机的体系结构非常复杂,性能表现与底层硬件之间的联系千丝万缕,这种联系是否仅仅由理论研究便能明确尚未可知.本文的研究工作是基于对数据进行统计分析,而计算机复杂的体系结构决定了描述计算机各方面指标的参数也复杂且多种多样.有的以响应时间为基准,有的以吞吐率为基准,有的是测试值,有的是理论值.由于在统计和建模中,所有的数据都体现为数字,不带单位和描述等任何条件限制,数据的统一性就至关重要.参数的数据值具备了统一性,才能保证这个参数参与建模是有意义的.基于以上两点,本次建模所选数据全部来源于TPC官网发布的TPC-C完整性能报告、硬件生产厂商发布的DataSheet.这些数据全部有权威部门负责,可以作为研究的基础.在解决了非线性变量转化成线性变量、定性变量转化成定量变量等问题,并确定了上述12个影响表1验证样本数据(a)tpmC主频×线程数cache-TcachePmem471883HPProLiantDL585G5IBMPower550HPProLiantDL385G7AMDOpteron6176SE705652PRIMEQUEST540IBMFlexSystemx240PRIMEQUEST580AIntelItanium290501238579102400IntelItanium9150M2382032212480因素之后,本文收集并整理了完整的数据,见附录中附表1.4计算结果与回归诊断根据上述分析,我们得到的理论模型为其中,y=TPCC(tpmC),x1=主频×线程数(MHz·个),x2=cache-T(MB),x3=cachePmem(MB/GB),x4=memory(GB),x5=memPcpu(GB/个),x6=memPcore(GB/个),x7=membw(Hz·个),x8=HBA(GB/s),x9=IOPS(次/s),x10=Xeon,x11=AMD,x12=POWER.4.1异常值检验对于由单个自变量与因变量构成的一元线性方程,每个样本可以在二维的平面图中表达成一个点,可以直观地看出比较明显的异常值.但对于多元线性方程,无法用空间中的点来表达样本数据,对于异常值就需要用统计的方法进行检验.统计中常使用删除学生化残差来检验异常值.第i个样本的删除学生化残差为SRE(i)=SREin-p-1式(2)的具体推导过程参见文献[5],|SRE(i)|>3的即可认为是异常值.我们对附录中的39份样本做了删除学生化残差的运算,得到结果见附表1的最后一列SRE,所有样本的删除学生化残差的绝对值均小于3,说明样本中没有异常值.在后面的实验过程中,样本数量和自变量数量发生变化时,都要进行异常值的检验,如果没有异常值出现,则本文不再解释这一过程.在进行了异常值的检验之后,本文从全部样本中抽选6份留作最后对回归模型的验证,用其余33份样本建立模型.抽选验证样本的原则是随机但尽量有所差异.差异体现在两方面,一是CPU以及服务器来自不同的生产厂商,二是TPC-C测试值的大小尽量分布在不同的区间.验证样本见表1.Page7memorymemPcpumemPcoremembwHBAIOPSXeonAMDPOWER(b)256256256102476820484.2回归方程的显著性检验下面对33份样本进行最小二乘估计的运算.由于数据量较大,数据精度较高,本文的计算过程均由计算机完成,部分操作由SPSS软件①完成.计算结果见表2.变量号0123456789101112多元线性回归方程的显著性检验就是看自变量x1,x2,…,xp从整体上对随机变量y是否有明显的影响.F检验是根据平方和分解式,直接从回归效果检验回归方程的显著性[6].平方和分解式:其中,SST=∑nSSE=∑nSST称为总平方和,反映因变量y的波动程度或不确定性.SSR称为回归平方和,它是由回归方程决定的,也就是由自变量的波动引起的.SSE称为残差平方和,反映的是不能由自变量解释的波动,是由自变量以外未加控制的因素引起的.总平方和SST中,由自变量解释的部分是SSR,不能由自变量解释的部分是SSE,SSR越大,说明回归效果越好,F统计量为由给定的显著性水平α②,查F分布表,得临界值Fα(p,n-p-1),将计算给定数据得到的F与Fα1081170280832950700244539423080407500038192684911607297400进行比较,在正态假设下,当F<Fα时,说明F统计量遵从自由度为(p,n-p-1)的F分布,认为回归方程不显著;当F>Fα时,认为在显著性水平α下,y对自变量总体有显著地线性关系,回归方程是显著的,也即自变量全体对因变量产生线性影响的概率大于95%.利用SPSS软件计算F值的结果如表3.方差来源平方和回归SSR6.304E+135.253E+12566.2981.4E-22残差SSE1.855E+119.277E+09总计SST6.323E+13表中F=566.298,远远大于Fα(p,n-p-1)=F0.05(12,20)=2.28,表明回归方程是显著的.表中的Sig值表示“F<Fα”的概率,由Sig值同样可以做回归方程显著性的检验,当Sig值<α时,回归方程显著,当Sig值>α时,回归方程不显著.我们设定的α=0.05,表3中,Sig值接近于0,表示自变量全体对因变量产生显著线性影响.4.3回归系数显著性检验[7]回归模型通过了F检验,证明回归方程是显著的,即因变量对自变量整体的线性回归效果是显著的,但不能保证每个回归系数都是显著的.部分自变量的系数不显著,回归方程也可能显著,所以我们还要对每个回归系数做检验.SSE构造t统计量:与F检验类似,回归模型中依然用SSR与t统计量遵从自由度为n-p-1的t分布,对于给定的显著性水平α=0.05的自由度,查出双侧检验的临界值tα/2,当tjtα/2时,表示自变量xj对因变量y的线性效果显著,当tj<tα/2时,表示xj对y的①②Page8线性效果不显著.利用SPSS软件,我们计算回归方程式(1)的t检验量如表4.变量号变量名称系数tSig0(常量)51751.181.267.7921主频×线程数7.2799.348.0002cache-T297.7261.530.1423cachePmem-543.357.281.7824memory151.9141.677.1095memPcpu829.7921.808.0866memPcore5033.935.862.3997membw-32.4631.368.1878HBA-123.3391.109.2819IOPS.2184.199.00010Xeon18429.415.136.89311AMD128713.994.683.50312POWER-146473.8591.125.274与F检验类似,我们同样可以通过比较Sig值与α=0.05的大小来判定回归系数的显著性,当Sig值>0.05时,表示该回归系数没有通过t检验,其与因变量的线性关系不显著.通过观察表4可知,不是所有的回归系数都通过了显著性检验,对不显著的自变量应予以剔除.但不能一次性剔除所有不显著的自变量,这是由于自变量之间存在交互作用,剔除掉一个自变量就会使得其它自变量的显著性发生变化,原则上先剔除t值最小的,或者说Sig值最大的一个自变量,然后再用y对其它自变量做线性回归,进行检验后再剔除t值最小的自变量,直到所有自变量对y的线性影响都显著为止.这种由多到少逐个剔除自变量的方法叫“后退法”.在用“后退法”进行自变量筛选的过程中,最先剔除了x10=Xeon,说明Xeon系列芯片的芯片类型和指令集对TPC-C性能影响不显著.其次剔除了x3=cachePmem,分析x3不显著的原因,是这个变量代表的实际意义对模型来说是不重要的,高速缓存容量大小与内存容量大小的比值固然是影响缓存命中率的重要因素,但这对单个CPU适用的理论对于多CPU并不一定适用,这是因为每一个缓存只能由它所在的CPU使用,而内存却是所有CPU共用,用这两个容量大小的比值来代表命中率,实际是限制了一个条件,即内存平均分摊在每个CPU上使用,每个CPU只能使用分摊后固定的那一块内存,这严重违背了实际情况,导致这个自变量不能够反映出CPU存取数据的性能.然后剔除了x8=HBA,造成x8不显著的原因可能是数据质量不好,这在第3节收集数据时已经阐述.然后剔除了x7=membw,该自变量不显著的原因应该同样是数据质量较差,由于服务器系统的内存带宽的实际测量值无法得到统一的、权威的、可靠的数据,收集数据时用理论最大内存带宽来代替,而理论最大内存带宽能在多大程度上反映实际测量带宽的信息,对于不同型号的服务器来说是有差异的,这导致了内存带宽数据的不准确.再然后剔除了x6=memPcore,注意到它与x5=memPcpu在自变量的实际含义上存在重合,都是表达内存容量大小与系统规模的比值,即使CPU与核的数量不同,但它们包含的信息量是有很多重合部分的,这有违自变量的选择原则.最后剔除了x11=AMD,说明该自变量对TPC-C性能影响不显著.用y与其余6个自变量做回归,计算结果见表5.此时,所有自变量均通过了回归系数显著性的检验,说明自变量x1=主频×线程数,x2=cache-T,x4=memory,x5=memPcpu,x9=IOPS,x12=POWER对因变量y=TPCC的线性影响是显著的.其中,x12=POWER的系数是负数,究其原因,POWER系列芯片的主频通常在4~5GHz,远远高于Intel和AMD芯片2~3GHz,而其芯片的整体性能优势实际上达不到与主频优势相当的程度,这使得自变量x1=主频×线程数在POWER系列服务器中被过高地使用了,需要一个负值来做整体上的平衡.这也是Intel和AMD被剔除掉而POWER依然保存的原因.变量号变量名称系数tSig0(常量)38077.0611.339.1921主频×线程数6.92614.777.0002cache-T271.5602.531.0184memory242.0604.237.0005memPcpu940.6644.412.0009IOPS.1754.611.00012POWER-90520.3982.749.042自变量整体对因变量线性显著性的F检验结果见表6.方差来源平方和回归SSR6.300E+131.050E+131226.2941.4E-22残差SSE2.226E+118.563E+09总计SST6.323E+13查得在此时的自由度下,Fα(p,n-p-1)=2.47,表6中的F=1226.294>2.47,Sig值接近于0,说明回归方程非常显著.Page94.4拟合优度[7]拟合优度是描述回归方程对样本观测值的拟合程度的指标.在介绍F检验与t检验时,我们了解到,在总的离差平方和SST中,回归平方和SSR所占比重越大,则线性回归效果越好,回归值与样本观测值拟合优度越好;相反,残差平方和所占比重越大,则回归效果不好,回归值与样本观测值拟合优度不理想.于是定义了样本决定系数为样本决定系数R2的取值在[0,1]区间内,R2越接近1,表示回归拟合的效果越好;R2越接近0,表示回归拟合的效果越差.经过计算,在最后一次回归中,因变量y与x1,x2,x4,x5,x9,x12组成的自变量全体的样本决定系数R2=0.996,表明回归拟合效果非常好.经过一系列的检验与调整之后,最终的回归模型为y=38077.061+6.926x1+271.560x2+242.060x4+940.664x5+0.175x9-90520.398x12(6)4.5标准化回归系数式(6)中自变量的系数的绝对值大小并不能代表各项系数对因变量的影响程度,这是因为各个自变量取值的单位并不统一.然而,若某种系数能够代表影响因子,那么对于认识TPC-C性能本身是很有意义的.为此,本文对所有样本的y,x1,x2,x4,x5,x9,x127项数据进行了标准化,以消除量纲和数量级的差异所带来的影响.标准化公式为表8回归值与残差CiscoUCSC250M2Extended-MemoryHPProLiantBladeBL685cG7IBMPower780ServerModel9179-MHBPOWER74.14GHzIBMPower595ServerModel9119-FHAIBMPOWER65.0GHz60851666134795.0-49628.60其中,Ljj=∑n系数为标准化回归系数,如表7.对标准化后的数据进行最小二乘运算,得到的变量号变量名称非标准化系数标准化系数0(常量)1主频×线程数2cache-T4memory5memPcpu9IOPS12POWER-90520.39757-.023从结果来看,对TPC-C性能影响最大的自变量得到的回归值与残差见表8.残差值的变化范是x1=主频×线程数.4.6应用检验围是(-140000,170000).将从全部样本数据中抽选的6组样本数据代入到回归模型式(6)中检验回归模型的实际效果,得到结果见表9及图3.其中,偏差度的计算方法是实测值与估算值的对比如图3所示.Page10HPProLiantDL585G5HPProLiantDL385G7PRIMEQUEST540IBMFlexSystemx240PRIMEQUEST580A表9样本数据检验结果实测值4718836291597056521238579150354423820325相关工作目前针对高端容错计算机TPC-C性能预测的研究工作比较少.其中,微软研究者Barham等人[8]的提出的Magpie研究框架,通过对微软的SQLServer2000关键模块代码进行代码插装,分别建立性能模型,预测系统的TPC-C的性能,取得了很好的预测精度.但是,该工作的主要限制是:(1)为了建模,Magpie需要数据库系统的源码插装,这对使用Oracle等商业数据库系统的用户是一个很难解决的问题;(2)针对特定系统建立的模型不通用,很难直接应用于其它服务器.本文提出基于回归模型的预测方法,不需要提供数据库和操作系统的源码,而且模型比较通用,可以直接应用于大部分系统.此外,IBM公司对其每一款POWER系列的Unix服务器都发布了相对性能值rPerf①(RelativePerformance).rPerf是由解析模型得出的服务器的商业处理性能的估值,该模型综合了IBM网络工作负载、TPC、SPEC等基准测试程序的特点,模拟了部分系统操作如CPU、高速缓存和内存,但没有模拟硬盘和网络I/O操作.IBMeServerp640为其基准,rPerf值为1.0.尽管IBM公司在对rPerf值的解释当中声明,rPerf不能代替任何基准测试的结果,但在很多场合,rPerf值被用来推导TPC-C性能值.rPerf值有两个局限:(1)rPerf值与TPC-C测试结果之间的近似线性关系存在异常点,若不慎将异常点作为已知的样本去推测未知的tpmC值,会造成不可估量的误差.(2)rPerf值仅针对IBM的POWER系列Unix服务器,对POWER系列以外的服务器机型以及其他厂商的服务器不具备参考价值.在计算机领域,每时每刻都产生大量的数据,如何让已有数据产生价值是一个重要的课题.多元线①IBMCorporation.TherelativeperformancemetricforPowerPage11性回归模型是统计学中经典的建模方法,广泛用于社会生活的各个领域[9-12].据我们调研结果,本文是第一次将统计模型的方法用于TPC-C性能预测,解决了非线性转化成线性、实测值与理论值选取、定性变量转化为定量变量等问题,并且收集了大量具备权威性、统一性、可用性的数据,为今后相关工作的研究提供了资料;利用回归模型诊断,确定了影响TPC-C性能的关键硬件因素,对认识和分析TPC-C性能具有重要意义.6总结本文提出了一种基于线性回归模型的TPC-C性能预测方法,可以快速、准确地预测高端容错计算机的TPC-C性能.通过对39组样本数据进行回归分析,实验结果表明所建模型平均预测精度达到95%以上.本文的研究成果可以帮助高端容错计算机的研制人员在系统设计阶段预测性能,也帮助购买系统用户分析所购系统的性能.
