Page1一种面向社区型问句检索的主题翻译模型张伟男张宇刘挺(哈尔滨工业大学计算机科学与技术学院社会计算与信息检索研究中心哈尔滨150001)摘要基于统计机器翻译模型的问句检索模型,其相关性排序机制主要依赖于词项间的翻译概率,然而已有的模型没有很好地控制翻译模型的噪声,使得当前的问句检索模型存在不完善之处.文中提出一种基于主题翻译模型的问句检索模型,从理论上说明,该模型利用主题信息对翻译进行合理的约束,达到控制翻译模型噪声的效果,从而提高问句检索的结果.实验结果表明,文中提出的模型在MAP(MeanAveragePrecision)、MRR(MeanReciprocalRank)以及p@1(precisionatpositionone)等指标上显著优于当前最先进的问句检索模型.关键词社区型问答;问句检索;主题模型;翻译模型;LDA(LatentDirichletAllocation);社会计算;社交网络1引言社区型问答(CommunityQuestionAnswering,CQA)服务逐渐成为人们在互联网上获取信息以及知识的重要途径.典型的社区型问答服务包括百度知道(http://zhidao.baidu.com/)、知乎(http://www.zhihu.com/)、Yahoo!Answers(http://answers.yahoo.com/)以及Quora(https://www.quora.com/)等.随着用户对于CQA服务的广泛使用,大量的用户生成Page2内容(UserGeneratedContent,UGC)以问句和答案的形式被积累下来,形成了优质的数据资源.与传统的搜索引擎检索不同,CQA检索不是返回与用户查询相关的文档列表,而是返回用户查询的答案,从而能够直接满足用户的查询需求.但是,CQA查询中,检索的文档是用户生成的问句和答案,其长度远小于传统意义的文档[1].其中大多数的查询词项在用户的问答对中仅出现一次,因此使得基于词频和文档频率统计的检索模型不再适用于问句检索任务.基于Unigram语言模型的问句检索模型[2-3]假设查询中的词项之间是相互独立的,在检索的过程中其相似性排序主要依赖于字符串的严格匹配.尽管语言模型能够利用参数和大数据集(Collection)进行相应的平滑处理,但是其无法解决问句检索中的词不匹配问题.即语言模型无法建立用户对于同一种语义的不同表述形式之间的联系.基于统计机器翻译模型的问句检索模型[4-7]是当前用于问句检索中的最先进的模型,能够在一定程度上克服上述不足.其利用单语言相似的句子或者双语言互为翻译的句子作为对齐句对,输入到统计机器翻译模型中,获取单语言词项间的翻译概率,并将其作为词项间的相似性度量,或者根据词项的翻译之间的相似性来度量当前词项间的相似性.然而,由于目前用于问句检索的统计翻译模型仅仅利用统计共现信息作为依据来度量词项间的相似性,因此导致语义相关和无关的词项之间的翻译概率无法区分.图1所示为IBMModel1在两个语义相似问句之间的词项翻译关系.图1IBMModel1在语义相似问句之间的词项翻译关系由图1我们可以看出,除了“weight”和“fat”之外,其他的词项之间在语义上是不相似的,但是由于IBMModel1无法识别词项间的这种潜在语义相似关系,使得已有的基于统计翻译模型的问句检索模型在其所依赖的词项互译信息上存在较大的噪声,从而影响语义上相似问句的检索结果.因此传统的基于统计机器翻译模型的问句检索模型很难召回图1中所示的相似问句.针对上述问题,我们提出了一种面向社区型问句检索的主题翻译模型,通过在传统的基于统计机器翻译模型的检索模型中,引入词项间在潜在主题下的语义相似性,从而能够解决传统翻译模型中词项翻译准确性较差的问题.具体地,我们通过利用潜在主题对互为翻译的词项进行约束,从而更加合理地度量检索模型中词项之间的相似度,并取得更好的问句检索结果.2相关工作基于语言模型的信息检索模型首次由Ponte和Croft[8]提出,并被广泛应用到信息检索的各个相关领域[3-4,9-13,23].Jeon等人[2]率先将语言模型应用到问句检索中,他们采用Unigram模型对社区型问答服务中的问答对进行建模,从而将其应用于相似问句的发现工作中.最近,Zhang等人[14]利用依存句法分析技术对用户提出的自然语言问句中词项间的关联性进行度量,从而将重新分配后的权重融入到已有的问句检索模型中,得到更好的问句检索结果.但是由于上述方法没有考虑用户在相同语义上的不同表述形式的信息,从而使得语义上相似但字符串表面不相似的问句无法被召回.2.1基于统计机器翻译模型的问句检索模型针对已有的基于字符匹配的检索模型在匹配用户表述多样性上面的不足,研究人员将基于统计机器翻译模型引入到信息检索模型中,用以获取用户查询中的词项和候选文档中的词项之间的语义相似性.基于统计机器翻译模型的信息检索模型最初由Berger和Lafferty[15]提出,他们将IBMModel1以及其简化版本(他们称其为Model0)应用于信息检索系统中并在TREC数据上验证其有效性.随后,Murdock和Croft[1]验证了IBMModel1在句子级信息检索上的表现优于传统的QL(QueryLikeli-hood)检索模型.Xue等人[4]将语言模型中的平滑机制融入到统计机器翻译模型中,从而提出了一种基于翻译模型的语言模型,并将其应用到问句检索中.然而其采用问句和自身的答案作为平行语料训练翻译模型,包含了很大的噪声.鉴于此,Bernhard和Gurevych[5]通过融合多个优质的单语言平行语料,从而使得基于翻译模型的检索模型效果得到了显著的提升.其采用的资源包括WikiAnswer①中的问答对,用户标注的相似问句对以及同一单词在不同词①http://wiki.answers.com/Page3典中的解释等.Zhou等人[6]利用短语级的统计机器翻译模型计算查询与待检索文档之间的相似性,并将其应用于问句检索中,取得优于词级别的翻译模型的问句检索结果.尽管基于短语级翻译模型的检索模型能够为词项引入上下文的信息,从而在一定程度上解决翻译歧义的问题,但是其仍然没有合理的机制来控制统计机器翻译模型在翻译过程中产生的噪声.本文利用主题信息作为一种隐含语义约束,借此来调整翻译模型用于问句检索时词项间的相似度,从而合理地实现对翻译噪声的控制.进而更好地解决问句检索中的词不匹配问题.2.2基于主题模型的问句检索模型主题模型作为一种文档表征模型,近年来被广泛应用于信息检索和文本挖掘的相关任务中[17].其中代表性的主题模型主要有PLSA[16](ProbabilisticLatentSemanticAnalysis)和LDA[17](LatentDirichletAllocation).Steyvers等人[18]通过将作者和主题之间建立起潜在的语义对应关系,从而提出一种新的作者主题模型.并将此模型用于在论文数据库中发现研究主题的趋势演变以及为特定的作者生成摘要及相关论文推荐等.Wei和Croft[19]利用LDA模型对文档和查询之间的关系进行建模,通过线性结合的方式将LDA模型融合到最终的检索模型中,在TREC数据集上取得较好的检索结果.类似地,Cai等人[7]利用LDA检索模型融入到翻译模型中,并将其应用于问句检索任务.Ji等人[20]通过对问句和答案分别进行主题建模,并假设问句和答案之间不仅属于同一个主题而且还应该共享一些词汇信息.即利用答案作为一种查询扩展应用于原始查询中,并用其提高问句检索结果.尽管上述工作验证了主题信息对于问句检索的作用,但是据我们所知,通过原理性的分析并从已有的检索模型中合理地推导并融入主题模型信息的工作仍然罕有涉及.本文从理论上验证了我们所提出的方法能够将主题模型合理地融入到当前最先进的问句检索模型中,从而提出一种新的基于主题翻译模型的问句检索模型.2.3基于主题模型的机器翻译模型近年来,基于主题模型的机器翻译模型受到了广泛的关注[25-29],其主要思想是通过主题模型解决翻译模型的适应性问题.其中Zhao和Xing[25]提出一种双语主题混合模型,并将其用于统计机器翻译的词对齐任务中.在词和句子级别上,作者提出了三种模型来获取双语文档中的主题信息,并最终将三种模型进行融合用以提高词对齐的效果,进而提高机器翻译的效果.Tam等人[26]提出了一种基于双语LSA的跨语言的语言模型以及翻译词典自适应的方法.他们首先通过主题模型对源文本进行主题分布推断,然后将得到的主题分布用于目标语言的n-gram语言模型,以此来提高翻译模型的自适应性.Gong等人[27]指出现有统计机器翻译只考虑句子级别的信息是不合理的,并由此引入文档主题信息用以提高机器翻译的效果.具体地,他们利用LDA主题模型对文档片段进行建模,并在翻译过程中加入主题分布概率信息.Eidelman等人[28]将主题模型信息作为特征融入翻译模型,用以提高翻译模型的自适应能力.Xiao等人[29]提出一种基于规则的主题相似度计算模型,并将其应用在层次化短语结构的统计机器翻译模型中,提升翻译模型的性能.考虑到翻译模型在问句检索上的良好表现,本文将主题模型引入到翻译模型中,通过主题的信息提高翻译模型的性能,进而提高问句检索的效果.3基于主题翻译模型的问句检索模型3.1LDA背景简介LDA模型是由Blei等人[17]提出的一种新式的语义一致的主题模型.它的提出迅速得到了统计机器翻译,自然语言处理以及信息检索相关研究者的关注.同时,LDA是一种概率图模型,其表示形式如图2所示.其中Nm为第m篇文档的长度,n为单篇文档中词项的索引号,K为主题数,M为文档集的规模,即文档数.布)选择一个多项式分布z;布)选择一个多项式分布θm;选择一个主题z(z∈{1,…,K});LDA模型生成文本内容的过程如下所示:(1)为每个主题z(以参数β服从Dirichlet分(2)为每个文档wm(以参数α服从Dirichlet分(3)为每个文档wm中的词项wm,n(n∈[1,Nm])(4)从多项式分布z中选择词项wm,n.相应地,对于单篇文档w→Page4容的可能性(likelihood)如下所示:p(w→m|α→,β→)=p(→这里,在社区型问答服务中,一个问答对被看作是一篇文档,因此在本文中所用到的主题模型建模对象图3基于主题翻译模型的问句检索模型接下来,我们从最先进的问句检索模型入手,推导出融合主题信息的新的问句检索排序模型.目前最先进的基于统计机器翻译模型的问句检索模型[4],其排序机制如下所示:PTLM(w|(q,a))=λ1pml(w|q)+其中,w表示查询中的特定词项,q表示待检索的问句,t为q中的词项,a为q相对应的答案.TLM代表Xue等人[4]提出的基于翻译模型的语言模型,ml表示极大似然估计方法.且存在关系λ1+λ2+λ3=1.这里,p(w|t)为从查询中的词项w到待检索问句中的词项t之间的翻译概率,我们在此基础之上,考虑引入主题信息,从而通过主题空间上的相似性来提高翻译模型的准确性,具体推导如下所示:p^(w|t)=∑K∝γp(w|t)+(1-γ)∑K=γp(w|t)+(1-γ)∑K为问答对数据集合.3.2基于主题翻译的问句检索模型本节将介绍我们提出的基于主题翻译的问句检索模型.图3所示为该模型的系统框图.该模型以用户的自然语言问句查询为输入,通过利用主题模型对翻译模型的质量进行提高,从而实现问句检索结果的优化.∝γp(w|t)+(1-γ)∑K这里,γ=γ衡翻译模型和主题模型之间的权重.式(3)第1步到第2步的推导,是为了对p(w|t,zi)进行估计时便于计算所采用的一种近似处理,这里,我们采用了一种经常用于联合条件概率估计的线性插值法[19],具体地,我们使用p(w|t)和p(w|zi)对p(w|t,zi)进行估计.p(w|t)利用GIZA++[21]获得,p(w|zi)和p(t|zi)由LDA模型通过Gibbs采样方法估计得出.这样我们可以得到最终的问句检索排序模型如下所示:PT2LM(w|(q,a))=μ1pml(w|q)+μ2∑t∈q(pml(t|q)∑Kμ3∑t∈qPage5其中,T2LM表示我们提出的基于主题翻译模型的问句检索模型.且存在μ1+μ2+μ3+μ4=1.从直观上看,我们可以得出结论,当p(w|zi)和p(t|zi)的值越接近时,则式(4)中第3项的值越高,即查询中的词项w以及待检索问句中的词项t属于同一主题的可能性越大,则其相似性值越高,从而实现利用主题信息对词项间相似性的度量机制的更新.4实验结果及分析4.1实验数据集我们利用API①从Yahoo!Answers中获取了共1123134个完整问答对,其中包括问句的title、content以及answers.该数据集覆盖了较为广泛的主题,例如Health、Internet等.我们从中随机的选择了200个问句作为我们的查询集合,在去除停用词之后,我们手工地过滤掉长度小于2个词的查询,最终得到了168个问句查询,我们在其中随机选择了140个问句作为测试查询,剩余的28个作为开发集用于参数调整.另外,由于我们需要的是在大规模数据上对主题进行建模,因此本文主题模型建模的对象是整个问答对数据集.为了获取查询相关性问句集合,对于查询测试集中的每个查询,我们汇集多个搜索模型(如向量空间模型、BM25模型、语言模型以及翻译模型等)的前20个检索结果,并聘请两位以英语为母语,且不熟悉当前实验方法设计的学生进行手工标注检索结果为相关(数字1)或不相关(数字0),当标注出现冲突时,由第3位标注人员对标注结果进行判定.我们采用p@1(precisionatpositionone)、MAP(MeanAveragePrecision)和MRR(MeanReciprocalRank)[24]作为评价指标.4.2实验对比系统最先进模型作为对比系统,具体设置如下:我们选取了在问句检索方面的经典模型及当前(1)语言模型(LM).Jeon等人[2]提出的基于语言模型的问句检索模型.(2)翻译模型(TRM).Murdock和Croft[1]提出的基于统计机器翻译模型的句子检索模型.(3)基于翻译模型的语言模型(TLM).Xue等人[4]提出的基于翻译模型的语言模型.(4)基于词项赋权的TLM(drTLM).Zhang等人[14]提出的利用依存句法分析图进行问句词项重新赋权的TLM.(5)主题模型(TM).Wei和Croft[19]提出的基于LDA的信息检索模型.此外,还有很多在问句检索方面的杰出工作,如Cao等人[12]、Cai等人[7]和Zhou等人[6]等,前两项工作依赖于问句所在的类别信息,后一项工作基于短语级翻译模型.然而,一方面,我们所提出方法的目标是构建一个通用的问句检索模型,使其可以不受应用场景的影响.因此,我们并没有利用Yahoo!Answers的类别信息作为辅助信息来指导问句检索模型.另一方面,考虑到短语识别本身存在一定的错误,以及短语级别的问句检索存在数据稀疏问题,都会影响问句检索的效果,因此我们采用词作为基础单元进行问句检索的相关研究.文献[20]利用主题模型度量问题与答案词项之间主题分布的相似性,指导问句检索模型,而本文的方法更加注重于度量问句与问句词项之间的主题分布的相似性,以此对问句检索模型进行改进,由于本文与文献[20]在任务的基本假设上存在差异,以及文献[20]与文献[19]在主题建模形式上相似,又同时应用于检索任务中,因此,我们对比了本文方法和文献[19]的实验结果,而没有与文献[20]进行直接的比较.我们在开发集中,利用WEKA[22]提供的GridSearch工具将上述对比系统以及我们系统的参数分别调至最优,其中μ1=0.3,μ2=0.1,μ3=0.4,μ4=0.2,主题数K=80.表1所示为实验结果对比.本文所有的结果都是在p<0.05的条件下进行t-test统计显著性检验的结果.在统计显著性检验中,p值表示当假设成立时,获得一个测试统计至少被观测到一次的概率.p值通常与接受假设检验结果成立的置信度相对应,即p<0.05意味着我们可以以高于0.95的置信度接受假设检验的结果.本实验中,我们以步长为10,变化范围为10~50,对GibbsMAP0.26350.26780.28890.30430.41700.4375%ofMAPimprovementsoverLMTRMTLMTMdrTLMp@1MRR注:粗体为我们所提出的方法及相应的结果,其中T2LM在p<0.05的情况下,在统计上显著优于LM、TRM、TLM和TM.①http://developer.yahoo.com/answers/Page6采样的样本量进行了测试,测试结果表明,采样样本量的变化在实验结果上的差异性可以忽略不计,本文采用的采样样本量为40.由表1我们可以得出以下的分析:(1)TM和T2LM在问句检索上的效果要优于LM、TRM和TLM.这是因为前两个模型引入了主题信息辅助的问句检索模型.主题信息对于TM而言其作用相当于一种查询扩展,而对于T2LM来说,由于其引入了词项间的翻译信息,因此主题信息既可以看作是基于翻译模型的扩展,同时通过主题的限定也能够帮助控制翻译模型在词项互译过程中产生的噪声,因此主题模型在应用于基于翻译模型的问句检索模型上更有优势.(2)对比TLM和TM的结果我们可以看出,虽然这两个模型都是部分地基于语言模型的问句检索模型,但是基于主题模型的语言模型(TM)的实验结果要优于基于翻译模型的语言模型(TLM).从而说明对于问句查询扩展而言,主题模型的效果要优于翻译模型.这是因为主题模型的工作原理更类似于词项聚类,即将语义上相似的词项聚类成若干个主题类别.但翻译模型则是基于词项间的统计共现性的,而共现频度高的词项未必是同一类别的,因此在问句检索的查询扩展方面主题模型更有优势.(3)对比T2LM和TLM的结果我们可以看出,融入主题信息的T2LM模型在MAP上面高出TLM模型51.44%.说明其对基于翻译模型的问句检索模型有较大的帮助.同时我们注意到,在T2LM中μ3的值最大,这说明了其在问句检索上面性能的提升主要来自于主题模型部分.此外,由于直接对词项翻译结果进行评价需要大量的人力,因此本实验中没有讨论在加入主题信息之后的词项翻译结果和原始的词项翻译结果的比较.由于TLM方法的原始文献中,没有发布实验数据集,因此我们无法在其原始数据集上重现实验结果.另外,TLM在我们的数据集上的表现低于其原始文献中的结果,这是因为我们实验中所采用的数据集是来自Yahoo!Answers,而TLM原始文献中的数据集来自于Wondir①,这是数据集上的差异.此外,TLM原始文献中的测试集是来自于TRECQA的50个问题,TRECQA与表2问句检索结果比较示例Rank1IstheAppleStoreonlineagoodstoretobuyfrom?2IsthereanyonlineshopforApplefruittreetobesendto3Isbigapplepetsupplyreliableforliveanimalshipments?IsitcheapertobuyaniPodontheonlineapplestoreorinaYahoo!Answers的数据差异很大,TRECQA的数据是人工构造的问题,而我们采用的测试数据是完全由用户生成的数据.因此导致了TLM在本文上的表现以及与T2LM之间结果的差异.(4)值得注意的是,我们对比了目前最先进的基于词项重要性赋权的问句检索模型drTLM.通过比较发现,T2LM的结果要优于drTLM,这主要因为T2LM一方面是通过改变查询中词项的权重从而提升问句检索的效果,更重要的是另一方面其能够从翻译模型中获得词项扩展增益.由于在使用LDA的过程中,主题数需要在实验前给定,因此我们考虑了主题数对于实验结果的影响,图4所示为在开发集上MAP随着主题数的变化曲线.图4T2LM模型的主题数与MAP的变化曲线由图4可以看出,在主题数小于80的时候MAP的值随着主题数增长而增长,在80之后则趋于平稳.通过观察主题分析后的输出数据我们可以看出,当设定的主题数超过80之后,主题区分度的模糊性便显现出来,以100个主题为例,我们通过输出每个主题的高频词列表中观察到,有20个主题的高频词都能够在其他80个主题中找到,而在这20个主题中,除去其高频词之外的其他主题词则多数为噪声词,因此,我们可以推断这20个主题能够被包含在其余的80个主题中.对其他主题数的观察结果与上述结果相似.因此在我们的实验中,主题数选取为80.表2所示为TLM和T2LM在“IstheAppleStoreonlineagoodstore?”查询上前3位检索结果的对比,其中粗体为相关检索结果.由表2我们可以IstheAppleStoreonlineagoodstoretobuyfrom?ShouldIgetmyipodnanoattheAppleStoreoronline?regularstore/shop?①http://www.wondir.com/Page7直观地看出T2LM检索结果明显优于TLM,这是因为在T2LM中,其问句检索结果被限定在3个主题中,在本实验中为第27,32和58,如图3中所示,可见这3个主题都与AppleStore有关,且都是电子产品类别,因此T2LM能够召回更多相关的检索结果且排序靠前.5实现和应用时的关键技术点本文所提出的基于主题翻译模型的问句检索模型在实现和应用时,主要依赖的是主题分布信息和词的互译概率信息.前者是通过LDA主题模型训练得到的词的主题分布信息,后者是通过Giza++词对齐后得到的词与词的互译信息.此外,为了保证实际效果的准确性,计算主题分布信息时,需要根据特定的数据集调整主题的数量,同时,需要在相应的数据集上获取单语平行语料作为翻译模型输入.最后,在应用时,需要根据特定的应用来调整整个问句检索模型的各个参数,以达到最优的问句检索效果.6结论及未来工作本文提出了一种基于主题翻译模型的问句检索模型,通过在基于统计机器翻译模型的问句检索模型中引入主题信息,从而解决了由于翻译模型产生的噪声而影响问句检索结果的问题.同时我们在理论上说明我们所提出的主题模型可以合理地融合到已有的最先进的检索模型中,实验结果证实了其有效性.尽管主题模型能够作为一种潜在语义扩展增强问句检索的效果,但是我们也应当发现,目前的技术没有很好地解决主题间的歧义关系问题,因此在后续工作中,我们会进一步深入探讨如何解决主题的歧义性问题,以期获得更好的问句检索效果.致谢编辑及审稿老师给了宝贵意见,在此表示感谢!
