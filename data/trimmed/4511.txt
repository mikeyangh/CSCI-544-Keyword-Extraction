Page1一种基于时间衰减模型的数据流闭合模式挖掘方法王志海1)1)(北京交通大学计算机与信息工程学院北京100044)2)(北方民族大学计算机科学与工程学院银川750021)摘要数据流是随着时间顺序快速变化的和连续的,对其进行频繁模式挖掘时会出现概念漂移现象.在一些数据流应用中,通常认为最新的数据具有最大的价值.数据流挖掘会产生大量无用的模式,为了减少无用模式且保证无损压缩,需要挖掘闭合模式.因此,提出了一种基于时间衰减模型和闭合算子的数据流闭合模式挖掘方式TDMCS(Time-Decay-Model-basedClosedfrequentpatternminingondataStream).该算法采用时间衰减模型来区分滑动窗口内的历史和新近事务权重,使用闭合算子提高闭合模式挖掘的效率,设计使用最小支持度-最大误差率-衰减因子的三层架构避免概念漂移,设计一种均值衰减因子平衡算法的高查全率和高查准率.实验分析表明该算法适用于挖掘高密度、长模式的数据流;且具有较高的效率,在不同大小的滑动窗口条件下性能表现是稳态的,同时也优于其他同类算法.关键词事务数据流;数据流挖掘;频繁模式挖掘;闭合模式挖掘;时间衰减模型;概念漂移1引言数据流(DataStreams)作为一种新型数据模型广泛出现在多种应用领域.与传统的数据集不同,数据流是按时间顺序的、快速变化的、海量的和潜在无限的.频繁模式的挖掘是数据挖掘的热点问题,在传统数据库中挖掘频繁模式这个问题已经被广泛地研究和应用.然而,在流数据的环境下挖掘频繁模式给研究者带来更大的机遇和挑战.近年来,针对数据流的频繁模式挖掘算法被陆续提出.算法StickySampling和FDPM[2]挖掘数据流中满足误差界和最小支持度的频繁模式,这是一种近似结果.这类算法没有区分新旧数据,没有考虑最新数据的重要性.MSW[3]和SWP-Tree[4]等算法采用了时间衰减模型设置新旧事务的权重,强调新事务的重要性,可以得到更加合理的结果集.但是这些算法用于挖掘完整的模式结果集,会产生大量的无用的模式.为了减少模式的数量,需要挖掘精简模式,包括最大模式、闭合模式和top-k模式等.为了进行无损压缩,通常的方式是挖掘闭合模式.如算法Moment[5]、CloStream[6]、Stream_FCI[7]、TMoment[8]、IncMine[9]和CloStream[10]等采用滑动窗口挖掘数据流的闭合频繁模式.这类算法的不足在于:(1)采用最小支持度阈值进行频繁模式挖掘,未处理概念漂移问题;(2)虽然采用了滑动窗口,但是窗口内的数据赋予相同的重要性.为了解决概念漂移,强调新旧事务不同的重要性,更加高效的发现压缩频繁模式,本文设计一种基于时间衰减模型的数据流闭合模式挖掘方法.主要的工作与创新点在于:(1)已有设置衰减因子f的方法包括:仅考虑100%查全率(Recall)或100%查准率(Precision)[2-4]时得到的上下边界值或在f的取值范围(0,1)内设置随机值[11-16].前者会使得对应算法的查准率或查全率较低,而随机值则使得算法的性能不稳定.本文设计一种平均衰减因子取值方式,目的是使设计的算法可以在高查全率和高查准率之间得到平衡,且得到的算法性能是稳定的;(2)算法中采用最小支持度-最大误差率-衰减因子的框架,可以解决概念漂移,避免丢失可能的频繁模式;(3)使用闭合算子[6,10]提高算法执行的效率;(4)设计了基于时间衰减模型的闭合频繁模式挖掘方法,可以得到压缩的无损的模式集合.使用时间衰减模型[3-4,11-12,17-26]增加了最新事物的权重,同时降低了历史事务的重要性.通过对数据流处理得到的查准率进行比较得出,与已有方式相比能得到更准确的结果集.本文第2节介绍数据流闭合模式挖掘的预备知识,包括闭合算子和时间衰减模型的介绍;第3节详细介绍基于时间衰减模型的闭合模式挖掘算法;第4节通过实验验证衰减因子选择的合理性,并且给出本文提出算法的实验性能分析;第5节进行总结.2预备知识本节主要介绍数据流闭合模式挖掘的相关知识,包括闭合算子和闭合频繁模式的定义,时间衰减模型介绍,并提出概念漂移问题的解决方式.数据流DS=〈T1,T2,…,Tn,…〉是一个有时间顺序的、连续的、无限的事务(Transaction)序列,其中Tn(n=1,2,…)是第n个产生的事务,如表1所示.由于数据流是无限的和不断流动的,模式P的支持数定义为已出现的N个事务中包含模式P的事务数据个数,记为freq(P,N)[3].频繁模式、临界频繁模式和非频繁模式的定义如定义1、定义2所示.定义1.频繁模式[3].令N为数据流中已有的事务项的个数,θ(θ∈(0,1])为最小支持度阈值.如果项集P满足freq(P,N)θ×N,则P为频繁模式.定义2.临界频繁模式,非频繁模式[3].令N为数据流中已有的事务项的个数,θ(θ∈(0,1])为最小支持度阈值,ε为最大允许误差阈值(ε∈(0,θ)).如果项集P满足θ×Nfreq(P,N)ε×N,则P为临界频繁模式.如果freq(P,N)<ε×N,则P为非频繁模式.概念漂移是指由于数据流实时变化,之前的非频繁模式随着时间的推移可能变为频繁模式.为了减少丢失可能的模式个数.挖掘过程中不仅要维持频繁模式,还需要维持临界频繁模式.此外,为了减少维护模式的代价,需要丢失非频繁模式.丢失这些模式的可能误差不大于εPage3θ-ε框架可以解决概念漂移问题.频繁模式挖掘的过程中存在的最大问题在于出现大量的无用的模式,为了减少模式的数量,通常挖掘压缩模式.闭合模式是一种常用的模式无损压缩方式,它包含完整结果集的所有信息.为了提高发现闭合模式的速度,本文采用了闭合算子[6,10].采用闭合算子发现闭合模式的效率优于CFI-Stream[27]、NewMoment[28]和Moment[5]等经典数据流闭合模式挖掘方式[10].闭合算子以及采用闭合算子的闭合模式概念为定义3~5所示.定义3.闭合算子[6,10].设T是事务集合D的子集,TD.Y是D中出现的所有项集合I的子集,YI.定义函数h和g:其中函数h的输入参数是事务集合T,输出是T中所有事务都包含的一个项集.函数g的输入是项集Y,输出是包含Y的事务集.函数C=hg=h(g)称为闭合算子.定义4.闭合项集[10].如果项集P满足式(3),则P是闭合项集;否则为非闭合模式.其中C(P)称为P的闭合.定义5.闭合频繁模式.如果项集P满足P=C(P)且其支持度不小于最小支持度,则P为闭合频繁模式.如果P满足P=C(P)且其支持度不小于最大误差支持度,则P为临界闭合频繁模式;否则P为非闭合频繁模式.由于数据流的连续无限性,其中包含的知识会随着时间的推移而发生改变.通常情况下,最近产生的事务的价值比历史事务要高的多.因此,需要增加最近事务的权重.时间衰减模型TDM(TimeDecayModel)是一种随着时间的推移而逐步衰减历史事务模式支持数权重的方法[3-4].设模式支持数在单位时间内的衰减比例为衰减因子f(f∈(0,1)),记事务Tn到达时模式P的衰减支持数为freqd(P,Tn).则第m个事务Tm到达时,模式P的衰减支持数满足式(4)和(5).即随着新事务的到达,每次模式的支持数都进行衰减.其中如果新事务Tm中包含模式P,则r的值为1;否则为0.freqd(P,Tm)=3TDMCS算法描述本节首先介绍配合闭合算子使用的数据结构,其次介绍了衰减因子的确定方法,最后详细讨论基于θ-ε-f三层框架的闭合频繁模式挖掘算法TDMCS(TDM-basedClosedfrequentpatternminingondataStream).TDMCS算法采用滑动窗口模型与时间衰减模型在数据流中挖掘闭合频繁模式,主要包括处理新事物和旧事物的两个方法:TDMCSADD(Tnew)和TDMCSREMOVE(Told).TDMCS使用了与算法CloStream[6,10]相似的3个数据结构,包括Closed-Table[6]、CidList[6]和NewTransactionTable.其中ClosedTable用于存储闭合模式相关的信息,包括3个字段:Cid、CP和SCP.Cid用于唯一的标识每一个闭合模式CP,SCP是闭合模式CP对应的支持数.CidList用于维护数据流中出现的每个项item和其对应的cid集合.NewTransactionTable包含与新事务Tnew相关的信息,包括两个字段:Temp-Item和Cid.其中TempItem存储满足条件{Ti∩NewTransaction,Ti∈ClosdeTable}的项集信息.假设衰减因子f=0.8,最小支持度阈值θ=0.1,以表1中事务数据为例介绍TDMCS算法处理新事务的工作过程.当新事务T4={2,3,4,5}到达时,ClosedTable、CidList和NewTransactionTable中的信息如表2~表4所示.处理事务T1,T2和T3后,ClosedTable中有4个闭合模式,如表2左侧所示.当处理事务T4后,ClosedTable中包含6个闭合模式如表2右侧所示.新的频繁项集如果满足最小支持度阈值和最大允许误差阈值,则需要的工作包括:(1)添加频繁项为新的模式,加入ClosedTable.同步更新CidList.(2)更新已有模式.①如果依然是闭合模式,则更新其支持数.②新事务的到来使之成为非闭合模式,则删除.同步更新CidList.具体的过程是,事务T4到达时,将T4存入NewTransactionTable,然后比较CidList和T4中的每个项item,更新NewTransactionTable如表4所示.然后参照NewTransactionTable,在Closed-Table中添加新的模式或者更新已有的模式.同时更新CidList.如此反复,随着数据的到达不断的更新.Page4Cid01234上述示例中设置最小支持度阈值θ=0.1,挖掘过程中发现的所有模式都被保留了下来.这样可能会产生大量无用的模式.如果设置最小支持度阈值θ=0.3,当事务T4到达时需要满足的最小支持数为4×0.3=1.2.产生的ClosedTable如表5所示.通过对比表2和表5可以发现满足最小支持数的频繁模式{34}丢失.Cid012从示例中可以分析出,使用了衰减因子后模式的衰减支持数远小于非衰减时的支持数.如当f=0.8时,采用式(6)可以得到模式的支持数小于:1/(1-f)=1/(1-0.8)=5.因此,按照常规的最小支持数进行挖掘会丢失可能的频繁模式.为了解决这个问题,使得采用时间衰减模型后正确率等于常规模式挖掘,需要设置最大允许误差阈值ε.即挖掘过程中保存频繁模式和临界频繁模式,而不仅仅保存频繁模式.freqd(P,Tm)=freqd(P,Tm-1)×f+r给定最小支持阈值和最大允许误差阈值之后,如何确定衰减因子f的值?已有的方式采用假定100%的查全率和100%的查准率来估计[3-4].即设定Recall为100%时,f应满足式(7),称为下界值.设定Precision=100%时,f满足式(8),称为上界值.现有的f估计方式是采用满足式(7)和(8)的上下边界值之一.这种方式的最大不足是仅考虑了查全率或查准率,而忽略了对应的查准率或查全率.由于Recall和Precision不可能同时为100%,所以选择f是应考虑对二者的平衡.为此本文提出了均值衰减因子设置方式,即设置f为上下边界的平均值,标记为faverage.(2N-θN-1)f(θ-ε)N-1f<例如,假设N=10K,设定θ,ε如表6所示.其中frecall为假定Recall=100%时得到的下界值.fprecision为假定Precision=100%时得到的上界值.在得到frecall和fprecision后,如何选择f的值?可以有3个策略,如式(9)所示.以θ=0.025,ε=0.05×θ为例,可以选定f=f1=frecall=0.999995,f=f2=fprecision=0.995789或f=f3=faverage=(0.999995+0.995789)/2θ0.050.05×θ0.9999950.050.1×θ0.9999890.050.5×θ0.9999290.0250.05×θ0.9999950.0250.1×θ0.9999890.0250.5×θ0.99993通过实验验证(第4节中)选择设置f为faverage不仅可以得到更加合理的模式结果集的个数,且得到结果集的查全率与查准率更平衡.因此本算法中设计衰减因子f的值为frecall和fprecision的平均值faverage是合理的.从滑动窗口中移除旧事务的核心问题在于如何对已有的数据结构进行剪枝处理,已有的方式常采用滑动一步剪枝一步,这样消耗较大.为了增加算法Page5处理的效率,采用移动步长STEPM进行处理.即处理旧事务时先设置删除标记removeTAG,当窗口滑动M条事务后再进行实际的剪枝操作.为了区分历史事务与新事务的权重,从而提高模式发现的准确性,并且为了避免丢失可能的频繁模式,本文提出了基于θ-ε-f框架的闭合模式挖掘算法TDMCS.该算法采用ClosedTable,CidList和NewTransactionTable/OldTransactionTable存储数据信息,使用时间衰减模型估计模式的支持数,挖掘出满足θ-ε的闭合频繁和临界闭合频繁模式.算法的描述如算法1所示.算法1.TDMCS().输入:数据流S,滑动窗口大小N,剪枝步长STEPM,输出:频繁闭合模式AlgorithmTDMCS(S,N,STEPM,f,θ,ε)FORTnewINSDOCALLTDMCSADD(Tnew)IFSLIDINGTHENCALLTDMCSREMOVE(Told)ENDFORIFNEEDEDTHENOUTPUTPATTERNSENDIFENDTDMCS过程1.处理新事务TDMCSADD()输入:新事务Tnew,闭合项集表ClosedTable,滑动窗口输出:闭合项集表ClosedTableAlgorithmTDMCSADD(Tnew)1.ADDTnewTONewTransactionTablesetcid(Tnew)={∪CidSet(itemi),itemi∈Tnew}2.FORcidINsetcid(Tnew)DOENDFOR3.FOR〈TempItem,cid〉INNewTransactionTableDO4.IFitem∈TnewANDitemISNOTINCidListENDTDMCSADD过程2.处理历史事务TDMCSREMOVE().输入:历史事务Told,闭合项集表ClosedTable,滑动窗输出:闭合项集表ClosedTableAlgorithmTDMCSREMOVE(Told)1.ADDToldTOOldTransactionTablesetcid(Told)={∪CidSet(itemi),itemi∈Told}2.FORcidINsetcid(Told)DO3.IFWINDOWMOVESTEPMENDTDMCSREMOVE4实验分析实验运行环境的CPU为2.1GHz,内存为2GB,操作系统是Win7,所有的实验采用Java实现.实验中采用两类数据,一是真实数据流msnbc来自UCI①,此数据描述的是1999年9月28日访问msnbc.com网站的用户信息.用户访问的页面按照URL分类,并按照时间顺序记录.包括989818个事务序列,平均事务长度5.7,数据重复项多,为高密度数据流.二是采用IBM模拟数据生成器产生不同平均①FrankA,AsuncionA.UCIMachineLearningRepositoryPage6事务长度和不同平均模式长度的数据.模拟数据流包括T5I5D1000K、T10I4D1000K、T10I5D1000K、T10I10D1000K、T20I5D1000K和T20I20D1000K.这些数据流用于分析不同事务长度和不同模式长度时算法的性能.其中T10I5D1000K表示数据的平均事务长度为10,平均模式长度为5,数据事务个数为1000K.TDMCS算法中设置最大误差率ε=0.1×θ,衰减因子f为faverage.实验中设置滑动窗口N的大小为0.1M,0.2M,0.3M,0.4M,0.5M,0.7M和0.8M,设置最小支持度θ的范围为[0.06,0.1],衰减因子f的取值如表7中所示.fidf1f2f3f4f5f6f7首先分析设置f为平均衰减因子的合理性.实验从两个角度进行比较:一是比较得到结果集的模式个数;二是比较设置不同衰减因子得到的算法查全率和查准率.表8中是对数据流msnbc进行处理得到的闭合模式的个数.选择最小支持度θ为0.025和0.05,最大误差率ε=0.05×θ.表中第2列是衰减因子f,排列顺序是frecall、fprecision和faverage.以θ=0.025为例,可以得到当θ=0.05时也可以得到相同的结论.因此从得到的模式数据量角度而言,算法中选择faverage作为衰减因子相比上下边界值而言更加合理.0.0250.0250.0250.050.050.05从算法的查全率与查准率角度进行分析.以数据流msnbc为例,比较f设置为frecall,fprecision和faverage算法性能的优劣.比较不同窗口大小时算法的平均性能,表现如图1所示.从算法的查全率可以看出设置f=frecall可以得到几乎100%的Recall,而f=fprecision得到的Recall值最低,f=faverage得到的Recall值介于二者之间.接着比较算法的查准率.设置f=fprecision和f=faverage时得到的查准率几乎相同,而f=frecall得到的值最低.因此,可以得出设置衰减因子为faverage可以得到比fprecision和frecall更优的算法性能:即得到的算法的查全率和查准率更加的平衡.图1设置衰减因子为frecall,fprecision,faverage得到的算法性能比较(其中纵向坐标为算法得到的Recall与Precision百分比)接着比较设置f为faverage与随机值的优劣.为了使设置的随机衰减因子更加合理,取其范围为(0.9,1),标记为frandom,采用Java中Math.random()函数生成.随机生成5个衰减因子值.设置f为faverage与frandom得到的算法性能如图2所示.从中可以看出,设置f为faverage与frandom得到的查准率差别不大.而采用frandom得到的算法查全率差别较大,即得到的结果集的性能不稳定.设置f为faverage的表现明显优于设置为frandom,且其得到的结果集是稳定的.图2设置衰减因子为faverage和随机值得到的算法性能比较(其中纵向坐标为算法得到的Recall与Precision的百分比)对模拟数据进行处理时也可以得到相似的结论.因此,本文中提出的算法使用时间衰减模型时设置平均衰减因子是合理的.其次,分析窗口大小对TDMCS算法的影响.图3和图4所示是窗口大小N为0.1M、0.2M和Page70.3M时,算法TDMCS在真实数据流msnbc与模拟数据流上的执行时间和占用最大内存空间的比较.实验设置衰减因子f的值如表7中f1~f3所示.设置剪枝步长为0.1M[3-4],即数据流每滑动0.1M条事务时进行实际剪枝操作.图3在不同窗口大小下算法TDMCS在msnbc上的图4在不同窗口大小下算法TDMCS在不同模拟数据流上的比较(其中横向坐标为不同特征的模拟数据流)图3是采用TDMCS算法对数据流msnbc处理1M,1.5M,2M和2.5M条事务进行分析.图3(a)显示的是TDMCS算法在数据流msnbc上的执行时间.可以看出处理事务数量较少时,窗口大小的增大会导致执行时间小幅度增加.但是随着处理事务数量的增加,采用大的滑动窗口时间消耗反而更小.如当处理1M条事务时,随着N的增加,时间消耗增加.而当处理2M或2.5M条事务时,随着N的增加,时间消耗反而减少.从图3(a)中可以看出,采用大的滑动窗口处理数据时,随着数据量的增加时间消耗增加的幅度比小的滑动窗口少.如当N=0.3M时,处理2.5M事务与处理1M事务相比,处理的数据量增加了150%,而时间消耗增加了约99.9%.而当N=0.1M时,相同条件下,时间消耗增加了586.5%.因此,采用不同的滑动窗口大小对数据流进行处理时,时间消耗差别较大.图3(b)为算法执行使用的空间大小.可以看出,不同的窗口大小对使用的内存空间影响很小;随着处理事务数量的增加,内存消耗增加幅度较小.综合时间和内存消耗可以得出结论:对数据流msnbc进行处理时,相同的事务数量下,TDMCS算法使用的执行时间会随着N的不同而不同,而使用的存储空间受窗口大小N的影响不大.因此,从空间复杂度角度而言,该算法适用于挖掘任意大小滑动窗口内的频繁模式.图4比较不同滑动窗口大小N时,TDMCS在不同事务长度和不同模式长度的数据流上的性能.从图4中可以看出随着N的增大,算法执行时间成倍增加,内存消耗有较小幅度的增加.首先分析事务长度对算法性能的影响.通过比较两组数据流:T5I5,T10I5和T20I5,T10I10和T20I10可以看出随着平均事务长度的增加,算法的执行时间增加幅度较大,使用内存幅度增加相对较小.接着分析模式长度对算法性能的影响.通过比较两组数据流:T10I5和T10I10,T20I5和T20I10可以看出随着平均模式长度的增加,算法执行时间和内存消耗增加,但增加的幅度不大.如当N=0.3时,在数据流T10I10上的执行时间甚至比在T10I5上略微减少,而内存消耗几乎不变.可以得出结论,TDMCS算法处理不同的数据流时,受到事务长度的影响较大,而受到模式长度的影响较小.这表明该算法适用于挖掘长模式的数据流.第三,分析剪枝步长对TDMCS算法性能的影Page8响.设定滑动窗口大小N为0.5M,0.7M和0.8M,剪枝步长SETPM为0.1M~0.5M(SETPMN),设定衰减因子f的取值为表7中f5~f7.图5(a)为不同滑动窗口条件下采用不同的剪枝步长时算法执行的时间.从图中可以看到,当N=0.5M时,剪枝步长对算法的处理时间影响不大.当N=0.7M时,设定SETPM为0.2M时算法执行过程运行时间最少,而SETPM=0.5M时运行时间最多,后者比前者运行时间增加了57%.当N=0.8M时,SETPM=0.3M时算法执行时间最少,SETPM=0.4M时运行时间最多,后者比前者运行时间增加了70.4%.从执行时间的实验结果可以得到结论:(1)最优剪枝步长与滑动窗口大小N相关;(2)随着N的增大,不同的SETPM带来的执行时间差增大.图5(b)为采用不同剪枝步长和不同滑动窗口大小时算法执行需要的最大存储空间.从图中可以看出最大存储空间消耗受剪枝步长大小的影响不大.从图5中可以得出结论,当设定滑动窗口较小时,剪枝步长的大小对算法的执行时间和使用内存影响不大.而当滑动窗口较大时,对执行时间的影响较大,对内存使用影响甚微.因此当设定参数N=0.1M时,设定SETPM=0.1M是比较合理的.同样的,通过对图5(b)的分析,进一步证明了TDMCS算法适用于挖掘任意大小的滑动窗口内的频繁模式.图5在不同窗口大小下采用不同剪枝步长时,算法TDMCS在数据流msnbc上的比较(其中横向坐标为剪枝步长)最后,分析不同窗口大小时,TDMCS算法与经典算法CloStream,MSW和SWP的性能比较.设定衰减因子f的取值为表7中f1~f5所示.为了更合理的比较查全率和查准率,对算法MSW和SWP稍作修改,使其挖掘闭合模式.算法在数据流msnbc的性能表现如图6所示.其中图6(a)为不同的算法在数据流msnbc上的时间消耗.从图中可以看出采用TDMCS算法消耗的平均时间与其他三者相比用时最少.图6(b)为不同算法在数据流msnbc上执行的最大内存消耗.从中可以看出TDMCS算法的平均内存消耗大约比CloStream减少了65%.并且随着N的增加,两种方法占用的内存消耗的差距增加.与MSW和SWP相比也有一定程度的减少.图6(c)是算法之间的查全率比较.从中可以看出CloStream得到的查全率是最高的,这是由于这个算法没有进行衰减处理.其次是MSW和SWP得到的查全率较高,因为二者采用的是下界衰减值,即设置条件是假定100%的查全率.相比较而言,TDMCS得到的查全率较低,比CloStream减少了5%,比MSW和SWP减少了约2%,这是由于它的衰减程度是最高的.图6(d)是对数据流msnbc进行处理时得到的查准率比较.可以看出采用TDMCS进行数据流处理时得到的算法的Precision明显高于其他三者.与MSW和SWP相比提高了约7%,与CloStream相比提高了约11%.从图(c)和(d)的比较可以得出,采用均值衰减因子设置方式可以得到较为平衡的查全率和查准率.算法在模拟数据流上的比较如图7所示,是对不同窗口下的算法性能取平均得到的.使用事务长度和模式长度不等的4组数据:T10I4,T10I5,T10I10和T20I5.图7(a)是算法执行时间的比较,整体而言,TDMCS和其他3个算法相比,时间使用较短.CloStream由于不进行衰减处理操作,时间消耗也较短.二者的时间消耗低于MSW和SWP.图7(b)比较算法的内存消耗,总体而言,TDMCS的内存消耗是最低的,但整体之间的差距不是太大.图7(c)和图7(d)比较的是算法的查全率和查准率.由于算法MSW和SWP使用的是相同衰减因子设置方式,因此仅与SWP做性能比较.CloStream算法不做衰减处理,其得到的查全率是最高的,但得到的查准率是最差的.SWP设置衰减因子为边界值,得到的查全率和查准率居中.TDMCS得到的查全Page9图6算法在msnbc上的性能比较(其中横向坐标为滑动窗口大小)图7算法在模拟数据流上的平均性能比较(其中横向坐标为不同特征的模拟数据流)率与其余二者相比减少的不足1%.但得到的查准率与CloStream相比增加了约10%,与算法SWP相比增加了约4%.因此,从平衡算法的查全率和查准率角度而言,TDMCS算法的表现更好.从图7的分析可以看出,在不同模式长度的数据流上进行比较,如T10I4,T10I5和T10I10,TDMCS使用的时间和内存消耗随着模式长度的增加,与其余3个算法相比减少较明显,且得到的查准率的优势也很明显.比较不同事务长度的数据流,如T10I5和I20I5可以分析出,TDMCS得到的查准率优势同样较明显.因此,TDMCS算法相比而言更适用于长模式和长序列的数据流处理.Page105总结数据流不同于常规的数据库,它具有流动性、连续性和无限性.数据流包含的知识会随着时间的发展而发生改变.所以挖掘数据流频繁模式时需要考虑到概念漂移问题.通常情况下,新近的事务比历史事务包含更重要的信息.为此,本文提出了一种基于时间衰减模型的闭合模式挖掘算法TDMCS.该算法采用了闭合算子提高闭合模式挖掘的效率;通过设置平均衰减因子得到更加平衡的算法查全率和查准率;采用了最大误差阈值配合衰减模型使用,可以有效避免概念漂移,用于挖掘更加合理的闭合模式结果集.大量实验验证得出TDMCS算法具有较高的效率,适用于挖掘高密度,长序列和长模式的数据流,适用于不同大小的滑动窗口,且该算法优于其他同类算法.
