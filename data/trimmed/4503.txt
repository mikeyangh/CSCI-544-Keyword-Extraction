Page1在部分观测环境下学习规划领域的派生谓词规则1)(广东工业大学计算机学院广州510090)2)(暨南大学信息科学与技术学院计算机科学系广州510632)3)(中山大学信息科学与技术学院软件研究所广东510275)摘要文中提出了一种在部分观测环境下学习规划领域的派生谓词规则的方法.在规划领域描述语言(PDDL)中,派生谓词用来描述动作的非直接效果,是规划领域模型和搜索控制知识的重要组成部分.然而,对于大多数规划领域而言,从无到有地构造派生谓词规则是不容易的.因此,研究自动获取派生谓词的推导规则是有意义的.已有研究工作提出通过修订一个初始的不完备的领域理论来获取推导规则的方法,但是它们的主要缺点在于待学习谓词的训练例的数量非常少,这是因为训练例按照非常有限的方式来生成.而更本质的原因在于它们假设环境是不可观测的.其实,在现实生活中很多动作的非直接效果是可以观测的,或者通过简单的目测或者通过专门的工具.因此文中提出增加观测来反映动作的非直接效果,以便增加待学习谓词的训练例数目从而改善学习的精准度.此外,为了补充一些在归纳学习过程中学习不到的谓词,文中还提出了一个后处理方法来使得学习到的规则在语义上更完整.通过在派生谓词基准领域上的实验表明,文中所提出的方法是可行有效的.更深远的意义在于,文中的研究工作有利于规划领域的自动建模或者控制知识的自动获取的研究与实现.关键词人工智能;自动规划;派生谓词;规则学习;部分观测1引言在智能规划(automatedplanning)[1]研究领域中,派生谓词(derivedpredicates)有两个主要的用途:(1)用于领域建模[2];(2)用于描述控制知识[3-4].作为领域建模的一部分,派生谓词用来描述动作的非直接效果(indirecteffects),这样动作模型就变得简洁从而加速动作的搜索过程.而作为控制知识的一部分,派生谓词用来描述有利于目标求解的情境,从而引导求解过程按照期望的方向进行.不管是上述哪一种用途,派生谓词的获取要么由人类专家提供[5-6],要么由程序从规划解中自动提取[4,7-8].前一种方式耗时且易出错,而后一种方式目前还有很大的局限性,例如训练例少[7]或依赖于固定的规则模式[4,8]等.为了同时弥补以上两种获取方式的不足,与其他领域知识的获取[9-10]一样,派生谓词的推导规则可以先通过自动获取来获得一个初始模型,然后再进行人工的调整和完善.许多领域知识的提取都是从规划解中进行的,通过应用动作来产生一系列中间状态作为学习的知识基础,派生谓词规则的提取也不例外.然而,与其他领域知识的学习不同,派生谓词关注的是同一个状态下哪些命题参与推导,而非相邻状态中哪些命题发生变化.进一步地,从一个包含众多命题的状态中找出那些与推导相关的命题,可借助归纳学习程序或者数据挖掘工具来提取规则,例如使用FOIL[11]、ACE①和aleph②等工具.但是这些自动学习的结果在很大程度上是拟合训练数据的形式,而不能体现训练数据的语义内容.比如,不随状态变化的非fluent谓词是不可能出现在学习到的规则中,因为它们不带来更大的信息增益,尽管它们有时候作为规则的条件在语义上是必要的.除了在学习结果上存在着固有的局限性,派生谓词的学习还必须解决另一个重要的问题:如何产生待学习谓词的训练例?如果一个规划领域的描述中包含派生谓词,那么规划问题的状态应该由基本谓词和派生谓词组成.但是,当派生谓词的推导规则未知时,由于派生谓词不出现在动作效果中,因此应用动作所产生的一系列中间状态则成为只包含基本谓词的信念状态(beliefstates).信念状态的信息是不完备的,那么如何确定哪些派生谓词实例在哪些信念状态中是成立的?已有研究[7]提出了一些确立准则:在成功的规划解中,如果派生谓词出现在动作的前提中,那么它在动作应用之前的状态应该是成立的;如果派生谓词是作为目标出现的,那么它在目标状态中应该是成立的.但是,这些准则能够确定的谓词实例的成立关系非常少,因此使得待学习谓词的训练例也非常少.并且对于不出现在动作前提或者目标中的派生谓词,是无法通过上述准则来获得训练例的.解决的办法只能是增加更多的方式来产生训练例.如前所述,在领域建模时派生谓词用来描述动作的非直接效果.其实,在现实生活中,很多动作的非直接效果是可以观测得到的.例如,打开开关时灯泡不亮,闭合开关时灯泡亮了,灯泡亮是操纵开关的非直接效果.这样的观测可以通过简单的目测或是测量仪器来进行.用观测来反映动作的非直接效果,可以确定更多的派生谓词实例在信念状态中的成立情况,从而产生更多学习的训练例.另外,在现实生活中,完全观测比部分观测更耗时间成本和费用成本,因此更一般的情况是学习在部分观测的环境下进行,更何况完全观测是部分观测的特例.综上所述,根据以上种种动机,本文提出了在部分观测的环①②Page3境下学习规划领域的派生谓词的方法,其中主要贡献在于用观测反映动作的非直接效果以增加待学习谓词的训练例,并且引入通用规划(generalizedplans)[12]中的角色(roles)概念来增加非fluent谓词在规则中出现的机会,从而使得学习的结果在语义上更完善.本文所学习的派生谓词既可用于领域建模,又可用于描述控制知识,并且有利于二者自动获取的实现.本文第2节介绍本文的研究背景,包括派生谓词简介以及部分观测下规划和学习的研究现状;第3节陈述本文的学习问题;第4节介绍学习方法,包括训练例的产生、规则的学习和语义的调整;第5节是实验和分析部分;最后是结束语和对未来工作的展望.2研究背景早期的规划是关于动作的推理,后来发展成状态空间搜索、规划空间搜索和转化为其他问题(例如SAT等)进行求解[1].近十年来,规划的研究逐渐地考虑更多的现实因素的影响,例如不确定动作效果、部分观测环境、外存规划、外部事件和连续时间等等.经过四五十年的发展,智能规划俨然成为人工智能领域中重要的研究分支,在每年的人工智能盛会(如IJCAI或AAAI)上都占有一席之地.结合本文的学习问题,本节主要介绍派生谓词以及部分观测下的规划和学习的研究现状.2.1派生谓词简介在智能规划研究领域,派生谓词用来描述事物间的因果联系,也称为领域公理(domainaxioms).派生谓词由规划领域描述语言PDDL2.2(PlanningDomainDescriptionLanguage2.2)[2]正式引入.它们的真值不受动作模型的影响,而是以规则的形式来进行推导.这样的规则独立于动作模型,从而使得整个领域描述清晰而简洁.已有研究[5]证明派生谓词是规划领域描述语言必不可少的组成部分,缺少它们,容易使得领域描述和规划解长度超过多项式级别.如前所述,派生谓词可以作为领域建模的一部分,也可以作为控制知识的一部分.下面两个例子分别说明其主要用途.例1.在Blockworld领域中,above(?x,?y)是派生谓词,定义其的规则如下:above(?x,?y)≡on(?x,?y)∨z(on(?x,?z)∧该规则表明一个木块位于另一木块的上方的充要条件.该规则属于领域建模的一部分,有了它可以定义包含above谓词的目标.例2.同样地,在Blockworld领域中,good-tower(?x)是派生谓词,定义其的规则如下:goodtower(?x)≡clear(?x)∧GOAL(holding(?x))∧该规则表明一个木块处于“好塔”位置,当且仅当它位于塔顶,并且在目标状态不要求robot举着它,以及它下面的所有木块没有破坏任何目标条件.该规则属于控制知识的一部分,它要求后继的动作应避免去移动处于“好塔”位置的木块.派生谓词的处理方法分成两种:间接方法和直接方法.间接方法将派生谓词转化为其他语言要素.例如,早期处理派生谓词的方法是将其转化成已有动作的条件效果或者新动作[13-14],但是这样的方法效率低,只适合求解小规模问题.直接方法基于逻辑推理机制.自从2004年的国际规划大赛(InternationalPlanningCompetition2004,简称IPC-4)正式引入派生谓词的基准领域以后,不少规划系统提出了能够直接处理中等规模的包含派生谓词的规划问题的方法,其中代表性的有LPG-td[15]、SGPlan[16]、FastDownward[17]和Marvin[18]等.FastDownward和Marvin采用相同的方法:每应用一个领域动作后,先删除所有原来成立的派生谓词实例,然后再由规则重新推导出新实例直至到达状态的不动点.LPG-td在规则图上推导派生谓词实例的激活集,用来代替其在动作图上的出现以进行规划空间搜索.SGPlan调用LPG-td作为底层规划器来处理包含派生谓词的子问题.但是以上方法都难以处理大规模问题,这是因为当问题对象增多时,规则的实例化空间急剧膨胀而使得推理的复杂性大大增强.为了降低复杂性,还有研究[19]改进了激活集的定义并在一定程度上简化其计算.2.2学习派生谓词尽管关于派生谓词的处理方面研究得已比较成熟,但是有关派生谓词的自动提取方面的研究并不多见.原因主要来自于两方面:(1)认为派生谓词规则的提取与其他一阶规则的提取没什么不同,都是基于逻辑程序的归纳学习过程;(2)难以摆脱归纳学习本身的局限性,即只能拟合训练例的形式而无法挖掘其含义,学出来的规则往往缺乏语义上的合理解释.于是,一个令人尴尬的结果产生了:一方面认为派生谓词的学习是一件容易的事情,而另一方Page4面学出来的效果又总是不理想.其实,如前所述,学习派生谓词的关键问题不在于一阶规则的归纳学习过程,而在于待学习谓词的训练例产生过程以及对学习结果在语义上的调整.对于训练例的产生方式,已有研究或者通过谓词的预先定义[4,8],或者通过规则语义[7]来解决.而对于学习结果的语义调整,至今没有研究能够给出形式化的方法.关于派生谓词学习的研究现状如下:首先,在2005年,Zettlemoyer等人[8]在有噪音的随机环境下学习动作的效果模型时,通过预先定义的操作应用到文字上来产生新的谓词,将它们作为动作的衍生效果加入到动作模型中.实质上,他们将动作的所有效果都收集到动作模型中并没有形成独立的描述动作非直接效果的规则.接着,在2010年,饶东宁等人[7]根据训练数据来修订一个初始的不完备的领域理论(即派生谓词规则集合).他们的工作结合了分析学习和归纳学习,其中初始理论用于派生谓词实例的激活集来扩充规则的候选式.尽管学习效果大大依赖于初始理论的准确程度,但是他们提出了如引言所说的一些确立准则来产生待学习谓词的训练例.最后,在2012年,Rosa等人[4]提出了采用柱状搜索和归纳学习来获取控制知识中的派生谓词.所学习的派生谓词是为了增强控制知识的表达力,而非领域建模的一部分.学到的谓词由固定的规则模式来定义,分为三类:组合、抽象和递归.因此,他们的工作不是学习领域模型中的派生谓词,而是根据已有的规则模式来产生派生谓词,从而改善控制知识的描述.2.3部分观测下的规划和学习在部分观测环境下,状态信息是不完备的,每个状态变成了信念状态.因此,在部分观测下的规划问题可以形式化成在信念空间的非确定搜索问题.这样的问题比经典规划问题更难[20-21],因为追踪信念状态比追踪状态更难,并且要得到的是一个动作策略而不是动作序列.根据信念状态的形式,部分观测规划问题分为两类:随机规划和POMDP规划.在随机规划中,信念状态是一个状态的集合,求解方法主要是处理信念空间的搜索.代表性的研究工作有:Hoffmann等人[21]给出了信念空间的与或图搜索算法;Bryce等人[22]提出了如何评估信息状态之间的距离;Cimatti等人[23]用符号模式检测的方法来求解随机规划问题等.而在POMDP规划中,信念状态由在状态集合上的概率分布来表示,求解方法主要依赖于MDP方法中的值迭代和策略迭代过程.代表性的研究工作有:Kaelbling等人[24]提出方法来估算新状态的概率分布;Bonet等人[20]将部分观测问题转化为完全观测问题并用经典规划器来求解等等.然而,不管是随机规划还是POMDP规划,在一个变得更复杂的搜索空间中如何能够快速求解是它们共有的核心问题.在部分观测下的学习,也是在信念空间中进行[25-26].目前研究得较多的是在部分观测的环境下学习确定性的动作模型.训练数据仍然由规划解产生,但此时的规划解已经从动作序列变成了动作-观测序列.观测可以表示成一种像领域动作一样的动作[26],也可以表示成一个由fluent命题组成的逻辑公式[21].给定用于学习的动作-观测序列,需要程序能够自动获取导致这些序列的动作模型或者转换关系.一些有代表性的研究工作包括Schmill等人[25]使用决策树归纳来学习动作模型,观测信息从agent与环境的交互中获取;Amir等人[26]提出了SLAF(SimultaneousLearningandFiltering)机制,即使用领域动作来扩展信念空间和使用观测动作来过滤信念状态;Zhuo等人[10]在不完备的信息状态下学习包含量词和蕴含关系的复杂动作模型等.不难想象,不管是在部分观测下的规划还是学习,其结果的准确性与真实模型还是有差距的.由于只能根据初始信息或者是观测到的信息来提取模型,因此结果的准确性不仅与求解过程或者是学习方法有关,还受到观测信息数量和质量的影响.若没有观测到重要的信息或者观测数据不够多,则可能使得产生的模型不够准确或者不够完备.不过,对于部分观测的两个极端———不可观测和完全观测,其学习的效果就主要由学习方法来决定了.3问题陈述规划问题的描述基于一阶谓词逻辑,其中谓词分成两类:基本谓词(basicpredicates)和派生谓词(derivedpredicates)[2].二者的差别是,基本谓词可以出现在动作模型的效果中,而派生谓词则不能.这样,动作模型只需要描述动作的最直接效果,而各种衍生效果和因果联系可以通过派生谓词规则来表示.下面给出包含派生谓词的规划领域、规划问题和规划解以及观测的形式化描述.一个经典规划领域由谓词集合、状态集合、动作Page5集合和转换关系等部分组成[1].包含派生谓词的规划领域是在经典规划领域的基础上定义的.与经典领域不同的是,派生谓词规划领域将谓词分为基本的和派生的,并且定义派生谓词规则,在每次应用动作后产生的新状态要进行规则集下的扩充.引用文献[27],派生谓词规划领域、规划问题和规划解的定义如下.定义1.派生谓词规划领域[29].设L={p1,…,pn}是有限的谓词符号集合,派生谓词规划领域Σ是一个六元组〈S,A,X,B,D,R〉:(1)S是状态集合,S2L;(2)A是动作集合,A={a|a=〈pre(a),add(a),del(a)〉}.其中pre(a),add(a),del(a)∈2L分别表示动作a的前提集合、增加效果集合和删除效果集合;(3)X是转换函数,X(s,a)=add(a))-R(s)),当动作a在s中是可应用的;(4)B是基本谓词符号集合;(5)D是派生谓词符号集合,且B∩D=;(6)R是派生谓词规则集合,且R={r|r=(:derived(d?狓)(f?狓))}.在定义1中,动作a在状态s中是可应用的,当且仅当pre(a)则集R下的扩充状态,即R(s)表示在状态s下应用规则集R推导至不动点所得到出的派生谓词实例集合.在规则集R中,一条派生谓词规则r由形如(:derived(d?狓)(f?狓))的前缀表达式来表示,其中(d?狓)是单个派生谓词,(f?狓)是由基本谓词和派生谓词组成的逻辑公式,狓是规则中的变量矢量.规则r的含义为,如果(f?狓)在状态s下为真,则(d?狓)在s中也为真.对于一个派生谓词实例而言,如果推导它的某个规则实例的条件在状态中是成立的,那么该谓词实例在状态中也是成立的;然而,如果推导它的所有规则实例的条件在状态中都不成立,那么该谓词实例在状态中也不成立.因此,在应用动作之后(即(s-del(a))∪add(a)),有可能动作删除了原有某个派生谓词实例成立的所有条件,因而要在后继状态中先减去原有的所有派生谓词实例,然后在规则集下进行重新推导,使得新状态能够准确地持有应该成立的谓词实例.定义1中状态的扩充方法与FastDownward[17]和Marvin[18]处理派生谓词的方法是一致的.定义2.派生谓词规划问题[27].一个派生谓词规划问题Π定义为三元组〈Σ,I,G〉,其中Σ是派生谓词规划领域描述,I是初始状态,G是目标条件.定义3.规划解[27].派生谓词规划问题Π=〈Σ,I,G〉的解π是一个原子动作序列〈a1,a2,…,an〉,其中n是动作的个数.该动作序列产生一个状态变换序列〈s0,s1,s2,…,sn〉,使得(1)s0=(2)pre(ai)(3)Gsn.一个派生谓词规划问题是派生谓词规划领域的实例.遵循经典规划的假设,初始状态是唯一的,动作效果是确定的,定义3描述了派生谓词规划问题的解.此外,对于一个派生谓词实例p,如果它出现在某个动作实例的前提中,即p∈pre(a),则称p为派生谓词前提.类似地,如果p出现在目标条件G中,即p∈G,则称p为派生谓词目标.接下来,我们定义观测.首先,状态所包含的命题分为两类[1]:fluent命题和非fluent命题.fluent命题的真值随着状态的变化可能发生变化,例如on(A,B)在当前状态下为真,在应用了动作pickup(A,B)之后,在下一个状态下为假.而非fluent命题的真值不随状态的变化而变化,例如block(A)在任何状态下都为真.因此,需要观测的是fluent命题,一个观测变量就是一个fluent命题.然后,如前所述,一个观测可以定义成动作[26],也可以定义成一个观测变量组成的逻辑公式[21]或者映射函数.当定义成动作时,观测o是一个序对〈pre(o),obs(o)〉,其中pre(o)和obs(o)都是命题集合,该定义表明当pre(o)s成立时,可以观测到obs(o)中命题的真值.这样定义的好处是把观测动作当成领域动作一样来处理.而当定义成逻辑公式或者映射函数时,观测o是观测变量集合O的一个部分映射函数fo:O×S→{true,false},它表明某个fluent命题p∈O在当前状态s∈S下的真值fo(p,s)或者为真或者为假①.这样定义的好处是便于往状态中添加经过观测而确立的命题.为了方便算法描述,本文采用观测的第2种定义.定义4.观测.观测o是一个部分映射函数fo:O×S→{true,false},其中是O观测变量集合,S是状态集合,即存在着PO,对于任意p∈P,fo(p,s)①逻辑公式是映射函数中取值为真的命题组成的公式.Page6都存在.并且如果fo(p,s)=true,则表明观测变量p在状态s中的真值为真,反之,如果有fo(p,s)=false,则表明观测变量p在状态s中的真值为假.最后,我们定义本文的学习问题.为了描述方便,本文以下内容均使用ao来表示由动作-观测组成的序列.具体地说,ao=〈〈a1,o1〉,…,〈an,on〉〉,其中ai(1in)为领域动作,oi(1in)为观测,n称为序列长度.在本文问题中,动作模型是已知的,动作效果是确定的,因此观测用来反映动作的非直接效果,即观测变量全部由fluent形式的派生谓词实例组成.因此,在本文余下部分,除特别说明外,观测变量均指fluent形式的派生谓词实例,并且所有的观测都假设为准确的.定义5.在部分观测下的派生谓词学习.若在一个规划领域描述Σ=〈S,A,X,B,D,R〉中,只有R是未知的,当给定该领域的若干规划问题Π及其解πΠ=ao(ao为动作-观测组成的序列)时,能够通过学习方法得到R的过程,称为在部分观测下的派生谓词学习问题.参照相关研究工作[4,7,10]的习惯,本文中派生谓词学习问题的精准度定义为学习结果在验证集上正确解释训练例的比例,而不是与一个理想模型对比的相似程度.首先,这是因为表示相同语义的规则形式可能不是唯一的,因此当一个学习到的模型与一个理想模型在形式上有差异的时候,并不代表学习到的模型是不正确的.其次,一阶规则的提取基于归纳学习,而学习的结果是得出拟合训练例的假设,因此当验证集合能充分代表实例空间时,在验证集上的精准度可以完全代表在实例空间上的精准度.另外,正确解释训练例的含义指的是给定一个派生谓词的正例,经过学习到的规则能够推导出该实例,或者给定一个派生谓词的反例,经过学习到的规则不能推导出该实例.定义6.学习精度.在部分观测下的派生谓词学习问题中,给定验证集T,学习到的规则集R在T上的精准度定义为AT=ncorrect/ntotal,其中ntotal是T中训练例总数,ncorrect是R在T上正确解释的训练例总数.4学习方法本节介绍在部分观测环境下学习派生谓词规则的具体方法,包括产生训练例、规则学习和语义调整三部分.在产生训练例部分,首先定义什么是派生谓词学习的训练例,然后介绍如何从动作-观测序列中产生待学习谓词的训练例.在规则学习部分,主要介绍常用的序列覆盖学习算法和柱状搜索学习算法.在语义调整部分,首先介绍什么是角色以及角色特征,其次介绍如何将角色特征引入到学习到的规则中以加强语义完整性.4.1产生训练例派生谓词的训练例采用〈状态,谓词实例,正例/反例标识〉的三元组形式.因为动作序列会产生一系列中间状态,而派生谓词实例往往是fluent命题,即随着状态的变化其真值也发生变化,因此训练例的形式中应加入状态信息,以标识谓词实例在什么状态下其真值如何.此外,对于基本谓词实例而言,如果也是fluent命题的,其训练例中也应加入状态信息.因此,为了统一处理,在本文的规则学习中,所有谓词的训练例中都应该加入状态信息.定义7.训练例.在部分观测下的派生谓词学习问题中,谓词p(狓)的一个正例t+〈s,p(犮),+〉,其中s表示状态,p(犮)是用常矢量犮来替换狓所得到的谓词实例.t+下真值为真.类似地,谓词p(狓)的一个反例t+为三元组〈s,p(犮),-〉,其语义为p(犮)在s下真值为假.下面给出从给定的问题描述和动作-观测序列中提取待学习谓词的训练例的算法.算法1.产生训练例.输入:派生谓词规划问题Π=〈Σ,I,G〉及其解ao=输出:正例集T+、反例集T-1.s0=I//producethestatesequence2.FORi=1TOnDO3.si=(si-1-del(a))∪add(a)//handlederivedpredicatepreconditions4.FORi=1TOnDO5.FORallderivedfactdDO6.IFd∈pre(ai)THEN7.8.ELSEIF(notd)∈pre(ai)THEN9.//handlederivedpredicategoals10.FORallderivedfactdDO11.IFd∈GTHENPage712.Add〈sn,d,+〉toT+13.ELSEIF(notd)∈GTHEN14.Add〈sn,d,-〉toT-//handleobservations15.FORi=1tonDO16.FORallderivedfactdDO17.IFfo18.Add〈si,d,+〉toT+19.ELSEIFfo20.21.RETURNT+,T-算法1通过3种方式来产生待学习谓词的训练例:(1)如果一个派生谓词实例d(derivedfacts)出现在动作ai的前提中,那么它应该在执行ai之前的状态中si-1成立,并且肯定出现产生正例,否定出现产生反例(步4~9);(2)如果一个派生谓词实例d出现在目标描述G中,那么它必然在最终状态sn中成立,同样地,肯定出现产生正例,否定出现产生反例(步10~14);(3)如果一个派生谓词实例d出现在观测oi中,由于观测oi是在执行完动作ai之后的状态si中进行的,因此根据观测函数foi的映射来判断d在si中成立与否(步15~20).定理1.算法1的时间复杂性为O(nmk+nm2),其中n是动作-观测序列的长度,m是规划问题的派生谓词实例集合的大小,k是规划问题的基本谓词实例集合的大小.证明.首先,由于动作效果不包含派生谓词,因此应用动作-观测序列所产生的状态全部由基本谓词实例组成.在步2~3中,动作a的增加效果和删除效果个数均不超过k,因此所花的时间为O(nk).其次,步4~9包括一个两重循环,内循环总共执行nm次,每次执行内循环需检测一个派生谓词实例是否包含在动作前提中,由于动作前提可以包含派生谓词实例和基本谓词实例,因此所花时间为O(k+m),从而整个步4~9所花的时间为O(nm(k+m)),即O(nmk+nm2).接着,步10~14只包含一个循环,所花的时间为O(km).最后,步15~20包含包括一个两重循环,内循环总共执行nm次,每次执行内循环需检测一个派生谓词实例是否存在着观测函数的映射值,所花时间为O(m),因此整个步15~20所花的时间为O(nm2).综上,算法1所花时间为(nmk+nm2).另外,在产生了待学习谓词的训练例之后,还必须从规划解所产生的状态序列〈s0,s1,s2,…,sn〉中转化出基本谓词实例的训练例,作为规则学习的知识基.具体地说,如果一个基本谓词实例b∈s,则产生一个正例〈s,b,+〉;反之,如果bs,则产生一个反例〈s,b,-〉.这些训练例同样加入到T+和T-中,作为规则学习算法的输入.4.2规则学习派生谓词的学习可以采用序列覆盖算法[11]或柱状搜索算法[4].序列覆盖算法采用信息增益来评估候选式,每次选取最佳候选式来构造规则的条件,直至其覆盖(即解释)部分正例而避开所有反例为止.在学习到一个规则后,序列覆盖算法继续在剩余的正例集合中学习其他规则.柱状搜索算法的规则扩展过程与序列覆盖算法的是类似的,二者的主要区别在于柱状搜索算法进行多点扩展,每次选取精度排在前面的k个规则,而序列覆盖算法进行的是单点扩展,始终围绕同一条规则来进行扩展.下面给出两个算法详细的实现过程.算法2.序列覆盖算法.输入:训练例集合T+和T-、谓词集合L、要学习的派输出:规则集合R1.R←;Pos←thepositiveexamplesetofdpinT+2.WHILEPosisnotempty3.r≡→dp4.Neg←thenegativeexamplesetofdpinT-5.WHILENegisnotempty6.ProducethecandidatesetCofrbasedonL7.BestC←arg_max8.AddBestCtotheantecedentofr9.Neg←trainingexamplesthatsatisfythe10.AddrtoR11.Removethepositiveexampleswhicharecovered12.RETURNR算法2的关键在于步6~7.在步6中,候选文字集合C的产生取决于变量的关联关系.具体地说,由谓词集所产生的候选文字至少应包含一个已在原规则中存在的变量,即候选文字与原规则是有关联的.步7采用信息增益函数Gain来评估候选文字的优劣,用BestC来记录使得Gain函数值达到最大的候选文字.设原规则为r,增加了候选文字c的规则为r,则Gain函数表示为编码r的所有正例约束的分类,加入c所减少的编码位数.具体定义Page8如下:Gain(c,r)=tlog2其中,p0和n0分别表示规则r的正例约束数目和反例约束数目,p1和n1分别表示规则r的正例约束数目和反例约束数目,t是r和r共同约束的正例数目.定理2.算法2的时间复杂性为O(n3l),其中n=max{n+,n-},n+和n-分别是正例集合T+和反例集合T-的大小,l是谓词集合L的大小.证明.算法2包含一个双重循环.在最坏情况下,外层循环(步2~11)执行n+次,内层循环(步5~9)执行n-次.在执行内层循环时,候选式集合C的大小不会超过l的常数倍,即步6所花的时间为O(l).步7在训练例集合T+和T-上评估候选式,所花的时间为O(l(n++n-)).同样地,规则前件的数目不会超过l的常数倍,因此步8所花的时间为O(l).步9所花的时间为O(n-).综上,内层循环所花的时间为O(n-l(n++n-)),外层循环所花时间为O(n+n-l(n++n-)).如果记n=max{n+,n-},则算法2的时间复杂性为O(n3l).柱状搜索算法比序列覆盖算法多了柱状宽度k.此外,在构造规则时,柱状搜索算法没有像序列覆盖算法一样严格要求避开所有反例.算法3.柱状搜索算法.输入:训练例集合T、谓词集合L、要学习的派生谓词输出:规则集合R1.R←;beam←{→dp}2.irrelavent←3.REPEAT4.best_fn=facc(first(beam))5.successors←6.FORallrinbeamDO7.ProducethecandidatesetCofrbasedonL8.FORallc∈CDO9.10.11.12.FORallrinsuccessorsDO13.Evaluatefacc(r,T)14.IFfacc(r,T)<best_fnTHEN15.Addrtoirrelavent16.beam←firstkrsinsorted(successors,facc)17.UNTILfacc(first(beam))best_fn18.RETURNfirst(beam)算法3每次选取精度排在前k位的规则来进行构造.facc是规则在训练集上的精准度函数,first(beam)表示beam中精度排在首位的规则.加入新的候选式的规则存放在successors中(步6~11),其中精度过低的规则被抛弃,并且为了避免重复计算精度,将它们存放于irrelavent中(步12~15).sorted函数表示将规则按照精度从高到低进行排序,排在前k位的规则存放于beam中作为下一轮的待扩展规则(步16).最后,当不再出现精度更高的规则时,算法结束,返回精度最高的规则.定理3.算法3的时间复杂性为O(k2l2+kln),其中n是训练例集合T的大小,l是谓词集合L的大小,k是柱状宽度.证明.算法3中repeat-until循环的执行次数是不固定的.在该循环中,步4在训练集上评估规则精度,所花的时间为O(n).步6~11包含一个双重循环,由于柱状宽度为k,因此外层循环执行的次数为k.在外层循环内部,步7所花的时间为O(l),内层循环(步8~11)所花的时间为O(lkl).这是因为beam中至多包含k个规则,每个规则的候选式集合C不超过O(l),因此successors中的规则数不超过O(kl).而irrelavent中的规则均来自于successors,所以步10~11所花的时间为O(kl).综上,步6~11所花的时间为O(klkl),即O(k2l2).同样地,步12~15所示的循环执行O(kl)次,每次执行评估规则精度所花的时间为O(n),则总共花的时间为O(kln).步16需按精度进行排序,所花时间为O(kl(logkl)).综上,算法3的时间复杂性为O(k2l2+kln+kl(logkl)),即O(k2l2+kln).4.3语义调整语义调整是一个后处理阶段,目前主要是在规则条件部分增加归纳学习过程学习不到的非fluent命题.如前所述,这些非fluent命题的真值在状态中是保持不变的,即只要它们在初始状态中出现,就可以一直保持到终止状态.当它们作为一阶规则学习的谓词候选式时,新规则所覆盖的正例数和反例数与原规则是一样的,即没有信息增益的增加,这些非fluent命题很难作为最佳候选式加入到规则中.所以,基于信息增益的规则学习过程是学习不到非fluent命题的.这些命题之所以出现在问题描述或者规则定义中,是因为它们刻画了对象的属性或类别以及对象之间的语义联系.因此尽管在学习过程中学不到这些命题,但是在后处理阶段应尽可能地Page9补充它们,以增加学习结果在语义上的完整性.例3.PSR(PowerSupplyRestoration)领域是在IPC-4上引入的派生谓词基准领域之一,该领域描述了电源给线路供电的电路问题.在PSR领域中,派生谓词(affected?x)表示电源?x受到故障线路的影响,其定义规则(使用PDDL2.2语法规范)如下:(:derived(affected?x-DEVICE)(and(breaker?x)(exists(?sx-SIDE)(unsafe?x?sx))))其中,breaker(?x)是一个非fluent谓词,表示?x是一个电源,其所有实例均为非fluent命题.使用FOIL,在规则条件部分只能学习到unsafe(?x,?sx),而不能学习到breaker(?x).对于一阶规则,为了在条件部分增加非fluent谓词,可以参考通用规划[12,28]的研究,引入角色(roles)的概念.角色表示对象所属的类别,与非fluent谓词的作用非常相似.角色可用抽象谓词(abstractpredicates)集合来描述.对于一个规划领域而言,抽象谓词指的是领域描述中的单目谓词(即谓词只有一个参数)[12],或者是只包含一个变量而其他变量均为领域常量的多目谓词(即谓词可有多个参数)[28].在本文中,为了讨论方便,抽象谓词只局限于单目谓词,并且是非fluent谓词.这样,在应用规则时,如果能够识别同一参数对应的所有对象都属于一种角色,就可以引入角色的抽象谓词到规则条件中,从而实现对非fluent谓词的补充学习.定义8.抽象谓词[12].对一个规划领域Σ而言,抽象谓词指的是其谓词集合L中所包含的单目谓词.在本文中,抽象谓词还必须是非fluent谓词.定义9.角色[12].对一个规划领域Σ而言,角色指的是对象所满足的抽象谓词集合.对于一个规划问题而言,角色将其所包含的对象进行了划分.已有研究工作[28]证明,当一个对象属于多个角色时,总可以创建新的角色使得这个对象唯一的属于该新角色.因此,角色和对象是一对多的关系,每个对象唯一的属于一个角色.对象也称为角色成员.例4.在PSR领域中,谓词集合L={ext(?l,?x,?s),breaker(?x),closed(?x),faulty(?l),con(?x,?sx,?y,?sy),upstream(?x,?sx,?y,?sy),unsafe(?x,?sx),affected(?x),fed(?l)},其中非fluent谓词包括ext(?l,?x,?s),breaker(?x),faulty(?l),con(?x,?sx,?y,?sy).可创建两个角色:定义10.角色参数.设规划领域Σ的角色集合为ROLE,r=(:derived(d?狓)(f?狓))是派生谓词规则且p(x1,…,xn)∈f(狓).对于规划问题〈Σ,I,G〉,r存在着实例规则(即规则中所有变量均用对象常量来替换)集合Ground(r),如果p的某一参数xi(1in)在Ground(r)中对应的所有对象均属于ROLE中的同一角色role,则称xi为role的角色参数,标记为xi∈parameter(role).本文定义角色参数的意义在于,在归纳学习方法学习到规则以后,如果能够识别出规则中谓词的角色参数,则可将角色的特征谓词增加到规则中,即补充非fluent谓词从而进行语义上的完善.具体算法如下.算法4.识别角色参数.输入:规则集R、角色集合ROLE、规划问题Π=〈Σ,I,G〉输出:规则集R1.FORallr∈RDO2.non-fluent←3.X←thesetofvariablesthatappearintheantecedent4.InstantiaterwithobjectsthatarecontainedinΠto5.FORallx∈XDO6.IFrole∈ROLEsuchthatx∈parameter(role)7.FORallq∈abstractpredicatesofroleDO8.Addq(x)tonon-fluent9.Addnon-fluenttotheantecedentofr10.RETURNR定理4.算法4的时间复杂性为O(nkpl),其中n为规则集R的大小,l为谓词集合L的大小,p为L中谓词参数个数最大值,k为规划问题所含的对象数.证明.首先,步1的循环次数为n.其次,在该循环内部,步3收集规则前件中所有出现的变量,由于所产生的集合X的大小不超过O(pl),因此所花时间为O(pl).步4中,根据规划问题所包含的对象来实例化规则,由于规则中变量个数不超过O(pl),因此实例化规则的数目不超过O(kpl).步5~9包含一个双重循环,设m为角色集合ROLE的大小,其中每个角色的特征谓词集合不超过O(l),因此步5~9所花的时间为O(plml),即O(pml2).最后,步1~9的循环所花时间为O(n(kpl+pml2)),Page10即O(nkpl+npml2).一般地,kplpml2,因此算法4的时间复杂性为O(nkpl).5实验基于以上算法,本文开发了两个学习工具:POLDRFOIL(PartialObservableLearningDerivedRulesbasedonFOIL)和POLDRICL(PartialObserv-ableLearningDerivedRulesbasedonICL).其中,POLDRFOIL实现了算法1、2和4,在实现算法2时调用了FOIL(FirstOrderInductiveLearning),是基于序列覆盖的归纳学习过程;POLDRICL实现了算法1、3和4,在实现算法3时调用了ICL(InductiveClassificationLogic),是基于柱状搜索的归纳学习过程.两个工具的组成结构图见图1.图1POLDRFOIL和POLDRICL的组成结构图从图1可见,POLDRFOIL和POLDRICL分别由4个部分组成,其中产生训练例和调整语义是共有的两个部分.由于FOIL和ICL采用不同形式的训练例,因此在调用它们之前,必须先转化为其所接受的训练例形式.FOIL的训练例采用关系元组的形式,关系即谓词,元组即参数列表.将算法1所产生的训练例〈s,d(x1,…,xn),+/-〉转换为关系元组的做法如下:先将状态s编号,比如i;然后将谓词d(x1,…,xn)转换为关系元组d(i,x1,…,xn).此外,FOIL采用分号来分隔正例和反例.ICL的训练例采用模式的形式,每个模式代表一个状态,因此不需要对状态进行编号并增加为额外的参数.ICL实质是一个分类器,待学习谓词的正例归为正例类,反例归为反例类.除了训练例的形式不同,二者的输入文件个数也不同.FOIL的输入只有一个训练例文件.d,而ICL的输入有4个文件:.kb、.bg、.l、.s,其中,.kb存放训练例;.bg存放背景知识,比如领域规则;.l存放语言偏置,比如构成前件和后件的可用谓词集合以及数量范围;.s是设置文件.图2给出了同一个PSR规则学习问题分别在FOILPage11和ICL中的输入示例.POLDRFOIL和POLDRICL的各部分(除FOIL和ICL之外)用C++语言来实现,实验环境为WindowsServer2008+2.4GHzCeleronCPU+2GBmemory+EclipseHeliosServiceRelease2.另外,FOIL的运行环境为UbuntuServer10.04.3LTS+gcc4.3.0+FOIL6.4①,ICL的运行环境为WindowsServer2008+ACE-1.2.15②.实验数据采用IPC-4公布的PSR规划领域的基准问题,选择PSR-Middle-ADLDerived版本下的规划问题以及参赛规划器LPG-td公布的规划解来分别产生训练例③.由于公布的规划解不包含观测,因此为了产生部分观测的环境,对于每个规划问题Π,可以先将其所包含的派生谓词实例化以得到实例集合DΠ,然后设置一个观测率λ在DΠ上产生观测函数.例如,假设|DΠ|=100,当λ=0.2时,则在每次观测时随机选取20个派生谓词实例来进行观测.另外,为了避免某些派生谓词的实例特别多而造成观测集中,这些观测名额可以平均分配到每个派生谓词上.观测加入到规划解中,构成动作-观测序列.考虑到问题实例的代表性以及观测的随机性,选择3个规划问题P01.PDDL、P03.PDDL和P05.PDDL来分别产生训练例集合,即3个训练例集合.对于每个训练例集合,学习过程采用3-交叉验证方法,即2/3用来学习,1/3用来评估,此学习-验证过程交叉进行3次.综上,在同一观测率下,每个派生谓词学习3×3=9次,记录其在所有过程中出现的最高精度作为规则学习的最后精度.实验结果由图3和图4给出.图3给出观测率与学习精度之间的关系,图4给出相应的运行时间.从图3可见,对于两个学习系统而言,学习精度总体来说是随着观测率λ的增加而增加.首先,注意到λ的两个极值为0和1.当λ=0时,即完全没有观测,派生谓词的训练例只能从动作前提和目标产生,由于unsafe和upstream不出现在这些部分,因此POLDRFOIL和POLDRICL都无法学到它们的规则.当λ=1时,即完全可观测,在每个状态下所有派生谓词实例的真值是可知的,这时学习到的规则精度完全由FOIL和ICL的性能来决定.其次,当λ分别取值0.2、0.5和0.8时,在大多数情况下两个学习系统的学习精度会增高,少数情况会降低.这表明当待学习谓词的训练例数目增多时,学习精度不一定会持续增长,此时会受到多方面因素的影响,例如观测的随机性和有用性以及观测名额的分配比例等.从图3中总体来看,POLDRFOIL的学习精度曲线的走势与POLDRICL的大致相同.不过,在运行时间方面,POLDRICL多数情况下比POLDRFOIL更费时(见图4),这主要是由于ICL的运行时间高于FOIL所导致的.在这里还要补充说明的是,本文的工作没有与研究工作[7]进行直接的比较,其原因在于两点:①②③Page12(1)研究工作[7]需要给定一个初始的大部分完备的领域理论,其学习的效果在很大程度上取决于初始理论的完备程度,而本文不需要初始理论,是纯归纳的学习;(2)当研究工作[7]没有初始领域理论引导时,就变成了本文在观测率λ=0时的情形,即在不可观测的环境下学习,二者的结果是一样的.另外,为了测试算法4的效果,这里借用规则学习的另一精确度定义[29]:设一个理想的标准规则为r,学习到的规则为r,如果p在r中出现而不在r出现,则称出现了一个错误.鉴于此,学习到的规则r的精确度定义为:(r的前件数-错误数)/r的前件数.另外,要说明的是,由于FOIL和ICL均学不到规则中的存在量词,因此这里在计算精确度时存在量词是被忽略的.例5说明了POLDRFOIL在学习谓词affected(?x)的规则时调整语义的效果.表1给出了当λ=0.2时两个学习系统语义调整前后的精确度比较.尽管两个系统学习到的具体规则会有些差异,但是与标准规则比较时,它们的学习精确度的变化基本一致(见例5和例6).经过语义调整之后,一半的谓词规则的精准度有所提高,即更贴近于标准规则.不过,要注意的是,图3和表1中规则精准度的定义是不相同的,前者是通过验证集来得到的,后者是与标准模型比较来得到的.表1当λ=0.2时两个学习系统语义调整前后的POLDRFOILPOLDRICLPOLDRFOILPOLDRICL例5.在λ=0.2时POLDRFOIL学习到的关于affected(?x)的规则r如下:affected(A,B):-unsafe(A,B,C)!0.500000,其中,A是状态参数,0.500000是在训练例集上的精度.经过算法4识别出B是角色参数,所属的角色为BREAKER,因此引入角色抽象谓词后的规则r为affected(A,B):-breaker(A,B),unsafe(A,B,C).已知affected(?x)的标准规则r如下:(:derived(affected?x-DEVICE)(and(breaker?x)(exists(?sx-SIDE)(unsafe?x?sx))))则当与标准规则r比较时,r的精度为0.5,r的精度为1.0.例6.在λ=0.2时POLDRICL学习到的关于affected(?x)的规则r如下:rule((upstream(A,B,C,D),unsafe(E,F)),[type(dnf),cpu(93.0),heur(0.5),local(1,0,0,3),total(1,0,0,3)]).该规则其本质是个分类规则,学习到了多余的文字upstream,且不包含状态参数.经过算法4,识别出E是角色参数,所属的角色为BREAKER,因此引入角色抽象谓词后的规则r为rule(upstream(A,B,C,D),unsafe(E,F),breaker(E)).与上述标准规则r相比,r的精度为0.5,r的精度为1.0.可见,语义调整阶段对于两个学习工具所学到的结果是都是有效的.6结束语本文提出了在部分观测环境下学习派生谓词规则的方法,这有利于规划领域的自动建模或者控制知识的自动获取的研究与实现.学习过程由三部分组成:产生训练例、调用基本工具和语义调整.其中,训练例的产生来自于动作前提、目标和观测中出现的派生谓词实例,用于学习规则的基本工具为FOIL和ICL,语义的调整基于角色参数的引入.用观测来反映动作的非直接效果,从而增加待学习谓词的训练例数目以及学习的精准度,是本文创新性的主要体现.此外,对学习到的规则的语义后处理,是本文对学习技术局限性的一种改进.在派生谓词基准领域的实验表明,本文所提出的学习方法是可行有效的.进一步的研究工作包括以下3个方面:(1)在本文中观测被假定为准确无误的,然而在很多现实环境中观测是会出错的,因此可进一步研究在有噪音的观测环境下如何正确地获取派生谓词规则;(2)基于信息增益的归纳学习方法学习不到在规则前件中应出现的非fluent命题,本文通过引入角色的抽象谓词解决了非fluent命题是单目谓词的情况,但是并没有解决多目谓词的情况,因此在语义调整阶段,可参考相关工作[28]研究如何处理多目谓词之间的语义关联;(3)FOIL和ICL的候选式中不包括存在量词,因此学习到的规则没有存在量词,可参考相关工作[10]在候选式中增加包含存在量词的模Page13式,使得可以学习到包含量词的复杂规则.
