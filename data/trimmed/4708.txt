Page1基于OpenCL的Viola-Jones人脸检测算法性能优化研究贾海鹏张云泉袁良李士刚(中国科学院计算技术研究所计算机体系结构国家重点实验室北京100190)摘要Viola-Jones人脸检测算法是最为成功的可实用的人脸检测算法之一.然而,随着该算法所在领域数据处理规模的不断扩大,现有算法的性能已经越来越无法满足日益增长的交互性与实时性要求.使用GPU计算平台提升该算法性能,以满足日益增长的实时性要求已经成为研究热点.然而,该算法在对GPU的实现和优化中,存在线程间负载不均衡的非规则特性,如果仅使用传统的优化方法,则难以在GPU计算平台上达到较高性能.针对此种情况,该文构建了针对此类算法的并行优化框架,通过Uberkernel、粗粒度并行、PersistentThread、线程与数据的动态映射、全局及本地队列等优化方法的应用,突破了负载不均衡非规则特性导致的性能瓶颈,大幅提高了人脸检测算法在GPU计算平台上的性能.同时,该文通过对不同GPU计算平台关键性能参数的定义、抽取和传递,实现了该算法在不同GPU计算平台间的性能移植.实验结果表明,与OpenCV2.4中经过高度优化的CPU版本在IntelXeonX5550CPU上的性能相比,优化后的算法在AMDHD7970和NVIDIAGTX680两个不同GPU计算平台上分别达到了11.24~20.27和9.24~17.62倍的加速比,不仅实现了高性能,而且实现了在不同GPU计算平台间的性能移植.关键词OpenCL;负载不均衡;任务队列;线程与任务动态映射;性能移植1引言Viola-Jones人脸检测算法由Viola和Jones[1]于2001年提出,是最为成功且在一定程度上满足实时要求的可实用人脸检测算法,并在执法监控、安防系统和娱乐等领域有着广泛应用.然而,随着该算法所在领域需要同时处理的数据规模的不断扩大以及图片分辨率的不断提高,现有算法的性能已经越来越无法满足其日益增长的交互性与实时性要求,提高该算法性能的需求日益迫切.与此同时,随着GPU通用计算的发展,特别是GPU计算能力与可编程性的不断增强,GPU受到了越来越多应用开发人员的青睐,利用GPU计算平台实现对应用程序的加速已成为提高程序性能的主要模式.使用GPU计算平台提升人脸检测算法的性能,以满足日益增长的实时性要求已经成为研究热点.本文将对Viola-Jones人脸检测算法在GPU计算平台上实现和优化的关键技术和方法进行深入研究.同时,针对当前GPU架构日益多样化以及人脸检测算法应用场景不确定的特点,本文进行该算法在不同GPU计算平台间的性能移植研究.GPU计算平台具有大规模细粒度并行的硬件架构特征,这对于Viola-Jones人脸检测算法来说是一把双刃剑:一方面,Viola-Jones人脸检测算法具有良好的并行性,非常适合GPU大规模并行的架构特点;另一方面,在Viola-Jones人脸检测算法的GPU实现中,线程间会产生严重的负载不均衡现象,它将导致算法性能的急剧降低,这无疑是GPU这种细粒度并行处理器的梦魇.不幸的是,传统GPU编程一般采用静态编程模式,即在GPUkernel启动之前,线程和数据的映射就已经确定,线程被GPU硬件静态顺序调度执行.这种编程模式虽然对任务规则的数据级并行算法具有良好的适用性,但是对于像Viola-Jones人脸检测算法这样具有线程间负载不均衡非规则特性的算法,该编程模式会产生严重的性能瓶颈,严重制约算法性能.因此,要提高Viola-Jones人脸检测算法在GPU计算平台上的性能,必须研究新的优化方法和策略,突破由于线程间负载不均衡导致的性能瓶颈,实现算法到硬件架构的良好映射,从而有效地提高算法在GPU计算平台上的性能.对此,本文提出了一个面向GPU计算平台,针对具有负载不均衡特性算法的性能优化框架.通过Uberkernel、粗粒度并行、PersistentThread、线程与数据的动态映射、全局及本地队列等优化方法的应用,突破Viola-Jones人脸检测算法在GPU计算平台的实现中由于负载不均衡导致的性能瓶颈,从而完成了该算法在GPU计算平台上的实现和优化.本文提出的并行优化框架不仅大大提高了人脸检测算法的性能,而且也能够在一定程度上指导类似算法在GPU上的移植和优化,具有一定的普适性.同时,本文还针对当前GPU架构日益多样化以及人脸检测算法应用场景不确定的特点,总结不同GPU平台架构的异同,通过关键性能参数的定义、抽取和传递,实现了人脸检测算法在不同GPU计算平台间的性能移植.实验结果表明:优化后的算法相对于OpenCV①库中高度优化的CPU版本在IntelXeonX5550上的性能,在AMDHD7970和NVIDIAGTX680两个GPU计算平台上,分别达到了11.24~20.27和9.24~17.62倍的加速比.它不仅实现了高性能,而且实现了不同GPU计算平台间的性能移植.值得注意的是,本文工作是在已有工作[2]的基础上进行的改进和提升.相对于之前工作,本文主要工作体现在整体优化框架的提出、Uberkernel调度、本地队列分层次优化、新的线程与任务动态映射机制4个方面.与前期工作相比,最终获得了22.3%~51.6%的性能提升.本文的主要贡献如下:(1)研究和实现了Viola-Jones人脸检测算法在GPU计算平台上的关键优化技术和方法.①OpenCV:http://www.opencv.org.cnPage3(2)提出了一个面向GPU计算平台,针对具有负载不均衡特征算法的并行优化框架.(3)实现了人脸检测算法在NVIDIAGTX680和AMDHD7970两个不同GPU计算平台上的高性能与性能移植.本文第2节为相关工作介绍,详细讨论Viola-Jones人脸检测算法在GPU计算平台上实现和优化的相关工作;在第3节简要介绍GPU架构以及Viola-Jones人脸检测算法之后;第4节详细讨论该算法在GPU计算平台上实现和优化的关键技术和方法;并在第5节给出性能评估结果;最后,第6节进行总结.2相关工作近年来,关于Viola-Jones人脸检测算法的GPU移植和优化已有许多工作,代表性的工作主要有:David等人[3]通过优化图像积分图算法在GPU上的性能来提高人脸检测算法的整体性能,但是对人脸检测部分在GPU上的实现和优化工作较少,更没有指出如何解决算法中由于负载不平衡问题而导致的性能瓶颈.Kong等人[4]通过使用share-memory存储待检测窗口,通过数据本地化减小对访存带宽的依赖,但其主要工作集中在检测窗口的并行处理上,并没有对算法并行性进行充分挖掘,更没有解决算法中由于负载不平衡问题而导致的性能瓶颈.Sharma等人[5]将Viola-Jones人脸检测算法移植到GPU,通过建立图像金字塔机制实现对不同大小的缩放图像的统一处理,从而在一定程度上缓解了图像间负载不均衡的问题,但对于Thread级和work-group级的负载不均衡现象没有进行进一步研究.Ghorayeb等人[6]充分分析了人脸检测算法的并行性,提出该算法具有三级并行性:特征值计算并行、检测窗口并行和缩放图像并行,并通过对这三级并行的性能优化,使人脸检测算法的性能达到了在FPGA上的性能,但在负载不均衡的处理上,仅仅通过在工作量大的一级分类器中,将负责每个探测窗口的线程数目提高两倍的方法来解决.这种方法不仅简单粗暴而且非常低效,只能在较低的程度上缓解负载不均衡问题,但不能有效解决.Jia等人[2]认为层次式队列机制是解决负载不均衡的优先选择,并构建了本地和全局两级队列解决人脸检测算法Thread级和work-group级负载不均衡问题.然而该工作的全局队列实现较为简单,没有实现线程和数据的动态映射机制,导致全局队列的任务调度实现方式不够高效,同时也没有解决全局队列的高效访问的问题.总之,虽然上述工作在对Viola-Jones人脸检测算法的GPU移植方面取得了很大的进展,但在并行性发掘以及负载不均衡导致的性能瓶颈的处理上,这些工作的研究依然不够深入,更没有给出一个统一、有效的解决方案.与此同时,近年来也有许多工作通过其他算法的GPU移植,提出了克服GPU计算平台上线程间负载不均衡的方法和策略.如Tzeng等人[7]通过光纤追踪算法在GPU上的移植和优化,构建了非规则算法在GPU实现中的作业管理机制,并提出有效的内存管理和动态调度是负载不均衡应用在GPU上达到高性能的关键因素.Merrill等人[8]和Aila等人[9]根据以上方法,分别完成了光线追踪和广度优先图遍历算法在GPU上的实现和优化,并取得了很好的加速比.Nasre等人[10]通过图算法在众核计算平台上的实现和优化,根据其算法特性,得出在众核编程环境下,Topology-driven比Data-driven更能降低负载不均衡,从而会大幅提升程序性能的结论.Cederman等人[11]和Chatterjee等人[12]通过将改进的任务窃取算法应用到全局队列中,以动态任务调度的方式大大缓解了work-group间的负载不均衡现象,从而获得了较高的性能加速,但该方法实现过于复杂.Yan等人[13]通过引进邻接同步的定义和算法,通过消除全局同步以及降低线程间的任务依赖达到解决负载不均衡的目的,从而提高了程序性能.Burtscher等人[14]提出了针对具有条件分支和访存不规则特征的算法在GPU上实现和优化的方法和策略.Nasre等人[15]针对非规则算法在GPU计算平台上实现和优化中,原子操作可能会导致的性能瓶颈,提出了atom-free编程方法,有效地解决了原子操作导致的性能瓶颈.虽然,这些工作针对负载不均衡算法在GPU上的实现和优化都提出了不同的编程和优化方法,也都取得了很好的加速效果,但是这些方法都没有在Viola-Jones人脸检测算法上验证其有效性.然而,这些工作提出的方法和思想,对于Viola-Jones人脸检测算法的GPU移植具有很好的借鉴意义.本文将从上述的已有研究工作出发,结合已经提出的优化策略方法,根据Viola-Jones人脸检测算法的算法特点和GPU硬件架构特征,实现该算法在GPU计算平台上的高性能移植.同时,通过抽象影响性能的关键参数,本文实现了该算法在不同GPU计算平台上的性能移植.Page43背景介绍本节将详细描述GPU硬件架构特征和Viola-Jones人脸检测的算法特点.3.1GPU架构随着GPU通用计算应用的推广及其应用领域的不断扩大,GPU架构的发展非常迅速.主流芯片厂商根据实际计算需求,不断发展自己的GPU架构来满足日益增长的市场需求和性能需求.NVIDIA已经发布了如Fermi[16]、Kepler[17]和Maxwell[18]架构的GPU,AMD也发布了Cypress、Cayman、GCN架构[19]的GPU.这些GPU都具有不同的架构特点,对应的优化策略也有差异.这种GPU架构的日益多样性,对算法移植特别是性能移植提出了新的挑战.幸运的是,虽然不同的GPU架构在优化方法选择以及优化细节上会有不同,但是从整体上看,GPU架构又具有很好的统一性,即都是大规模细粒度并行处理器,且具有层次式的架构特点,这主要体现在4个方面:(1)在计算单元的组织上,GPU由多个计算单元(ComputeUnit,CU)组成,每个CU又由多个处理部件(ProcessingUnit,PE)组成;(2)从内存组织上,从只能被一个线程访问的私有内存,到能够被work-group内所有线程共享的本地内存,再到可被所有线程访问的全局内存;(3)在线程调度上,GPU一般都采用静态顺序调度模式,线程和数据映射在GPUkernel启动之前就已经确定,线程以work-group为单位被硬件顺序调度;(4)在编程方式上,都采用了Host+Device的编程模式,即GPU程序依然由CPU端控制,CPU设定开启线程的数目后,将计算任务发送到GPU端执行,线程组织也都采用了Grid-Block-Thread的层次式组织方式.GPU这种统一的架构特点和线程组织调度方式,使性能移植成为可能.Jia等人[20]给出了在不同GPU计算平台上优化策略的选择及应用.本文将以Viola-Jones人脸检测算法为例,研究该算法在不同GPU计算平台间性能移植的方法.3.2Viola-Jones人脸检测算法Viola-Jones人脸检测算法由剑桥大学的Viola和Jones[1]于2001年最早提出,是最为成功且满足实时要求的可实用人脸检测算法.Viola-Jones人脸检测算法使用Haar特征值进行目标检测:通过Adaboost算法生成级联分类器,直接对图像的一小块区域进行特征匹配,从而判断该区域内是否有人脸存在.该算法包括训练和检测两部分:训练部分使用Adaboost算法从预先收集的正负样本中提取特征值进行计算,最终生成一个级联分类器;检测部分使用级联分类器,通过检测窗口的移动和缩放,对图像上的人脸进行检测.由于训练部分可脱机执行,对实时要求并不高.因此,本文只讨论算法的检测部分在GPU上的实现和优化.如图1所示,Viola-Jones人脸检测算法使用Haar特征值计算特征.Haar特征值共使用了3种类型4种形式的特征模板,每种特征模板内包含黑色和白色两种矩形,该模板的特征值定义为白色矩形像素和减去黑色矩形像素和的差值.图1所示的特征模板称为“特征原型”,“特征原型”在图像窗口中平移伸缩而得到的特征称为“矩形特征”,“矩形特征”的值称为“特征值”.在检测过程中,特征模板可以以任意尺寸放置在图像窗口上的任意位置.从而形成各种形态,每一种形态称为一个特征.这样,通过改变特征模板的大小和在图像中的位置,可在图像窗口中穷举出海量特征.图2显示了人脸检测中的Haar特征值在样本窗口中的位置.对于一个24×24的图像样本而言,矩阵特征的数目可达160000,这是非常庞大的计算量.而且随着图像尺寸的不断增大,特征数目也会快速增长,这就对计算能力提出了严峻挑战.同时,如果每次Haar特征值的计算,都要统计矩形中所有像素的和,那么庞大的计算量无疑会降低检测的速Page5度.为此,Viola与Jones引入了积分图作为输入图像的一种中间表达形式.在完成图像的积分图运算后,通过图像积分图来完成Haar特征值的计算.因此,积分图生成算法的性能对于人脸检测算法的性能也至关重要.然而,这超出了本文的讨论范围,关于积分图生成算法的GPU移植,已有大量的研究工作,并且已经非常成熟.感兴趣的读者可以参考文献[3].图3显示了Viola-Jones人脸检测算法的主要流程,Viola-Jones人脸检测算法通过定义检测窗口遍历整幅图像,使用Adaboost方法构建的级联分类器检测检测窗口中的人脸.值得注意的是,通过使图3Viola-Jones人脸检测算法4人脸检测算法的GPU实现与优化4.1并行性分析通过3.2节的算法介绍,我们可以分析得出Viola-Jones人脸检测算法具有良好的并行性,具体来说,该算法包含3级并行性:(1)特征值级并行:每个特征值的计算是相互独立的,可以并行执行;(2)窗口级并行:每个检测窗口的检测是相互独立的,可以并行检测;(3)图像级并行:为了检测大小不同的人脸,需要将图像进行放缩,对每一幅缩放图像的检测也是相互独立的,可以并行执行.由此可见,一方面Viola-Jones人脸检测算法的计算量非常大,但另一方面,该算法又具备良好的并行性.这种算法特性非常适合GPU计算平台大规模并行的架构特点.针对以上分析,本文实现了Viola-Jones人脸检测算法在GPU计算平台上的nave版本.4.2nave实现与负载不均衡Viola-Jones人脸检测算法在GPU计算平台上的nave版本采用最基本、最简单的并行化策略,即用级联分类器可明显加快检测速度.检测流程具体如下:首先,为了检测出图像中包含的不同大小的所有人脸,需要按照一定大小的缩放因子缩放图像;其次,使用级联分类器对检测窗口进行检测.级联分类器将检测窗口交给第一级分类器,如果检测窗口检测为未包含人脸,则分类器将此检测窗口丢弃并停止检测,如果当前探测窗口被判为疑似包含人脸,则进入下一级分类器继续检测.最后,只有通过所有分类器检测的窗口才被判定为包含人脸.在级联分类器中,分类器的复杂度是逐层增加的,层数越深,检测要求越高,与之相对应的计算量也越大.仅并行化检测窗口的检测,具体过程为:(1)每次只处理一幅缩放图像,在CPU端循环启动OpenCLkernel以处理所有的缩放图像;(2)对于每幅缩放图像,每个线程负责一个检测窗口,多个检测窗口可进行并行检测;(3)使用LDS完成数据本地化,实现work-group内线程的数据共享,减少对访存带宽的依赖;(4)在线程组织上,采取有多少检测窗口,就开启多少线程的策略,每个work-group大小为256,并采取二维组织形式:16×16.然而,与CPU版本的性能相比,nave版本的性能并没有提升,反而有所下降.这主要有两方面的原因:一是没有充分发掘并行性,nave版本仅仅开发了三级并行性中的一级,即检测窗口并行;二是在nave实现版本中,线程间存在严重的负载不均衡现象,这是GPU这种大规模细粒度并行处理器的梦魇.这使得GPU计算资源远未得到充分利用,从而导致性能的严重降低.其中第2个原因是最主要、最关键的因素.Viola-Jones人脸检测算法的串行实现中,级联分类器之所以能够提高检测速度,是因为在一般的输入图像中,大部分区域都不包含人脸.通过前面的几级简单分类器就可以直接滤去这些区域,只对少Page6量的极可能包含人脸的区域使用更为复杂的分类器进行检测.在这个检测过程中,随着弱分类器数量的增加,通过Adaboost构建的强分类器的检测表现也会不断提高.但这种方法也导致了该算法在GPU的实现和优化中,会导致严重的负载不均衡现象,大大限制了其在GPU上的性能.图4说明了这种负载不均衡现象的产生过程.如图4所示,假设有9个检测窗口,共开启9个线程,每个线程负责一个窗口的检测.当使用级联分类器进行检测时:窗口(0,0)首先被Stage0分类器检测为肯定不是人脸而被丢弃,在此后的检测过程图4线程间负载不均衡现象由此可见,级联分类器方法虽然在串行算法中可大大减少工作量,提高检测速度,但在GPU实现中却会导致严重的线程间负载不均衡现象,成为性能瓶颈,严重制约算法性能.特别是在大多数图像中,人脸区域可能只占很少一部分.如果对该算法的GPU实现不进行改进,也就意味着在实际GPU程序中,只有一小部分线程会一直处于工作状态,直到检测结束.而绝大部分线程可能很快就退出并在CPU端等待全局同步了.这显然是我们不愿意看到的结果.此外,为了检测图像中大小不同的人脸,需要将中,线程(0,0)将一直处于空闲状态,其他线程继续工作;接着在下一级检测中,窗口(1,1)被Stage1分类器也检测为不是人脸,因此线程(1,1)在随后的检测中,也将处于空闲状态;更为不幸的是,随着检测的进行,越来越多的窗口被检测为不是人脸而被丢弃,也就是说越来越多的线程处于空闲状态;直到最后一个阶段,只有线程(1,2)处于忙碌状态,而其他线程都处于空闲状态.更为严重的是,根据级联分类器的定义,检测越靠后,分类器级数越高,相对应的计算量就越大.因此,实际的负载不均衡现象远比图4描述的严重得多.图像按照一定的缩放因子进行放缩.nave实现在CPU端循环处理这些缩放图像.这样处理不仅增加了GPUkernel的启动和同步开销,而且当缩放图像过小(如只有几个甚至一个检测窗口时)而不能充分利用GPU的计算资源时,就不能充分利用GPU强大的计算能力,从而造成资源浪费.因此,在实际图片的人脸检测中,Viola-Jones人脸检测算法存在三级负载不均衡:(1)Thread级.线程负责的检测窗口中的图像越接近于人脸,该线程的工作量越大;否则,工作量越小.Page7(2)Work-group级.当一个work-group处理的图像区域包含人脸时,工作量巨大;否则,工作量可能会很小.(3)图像级.当图像不断放缩而不能充分利用GPU计算资源时,就会导致图像级的负载不均衡.本文下面的内容将着重讨论如何解决这些负载不均衡的问题.幸运的是在解决负载不均衡问题的同时,并行性没有充分发掘的问题也一并得到了解决.4.3GPU优化如上节分析,Viola-Jones人脸检测算法虽然具有很好的并行性,但在GPU移植中存在负载不均衡的非规则特性.这种非规则特性是GPU计算平台的梦魇:一方面,GPU具有大规模细粒度并行的架构特点,负载不均衡会导致GPU计算资源利用率的降低;另一方面,现代GPU的线程调度采用静态调度策略,如不进行针对性优化,无法自动处理负载不均衡问题.更为严重的是,传统的GPU编程和优化方法并没有涉及对负载不均衡现象的处理和优化.因此,负载不均衡现象将会成为人脸检测算法在GPU计算平台上的性能瓶颈,仅仅使用传统GPU编程和优化方法(即计算、访存和数据本地化优化)无法克服该瓶颈,将严重制约算法的性能.对此,本文针对Viola-Jones人脸检测算法的特性,结合GPU的架构特征,提出了一种并行优化框架,以突破由于负载不均衡导致的性能瓶颈.图5显示了该优化框架的整体架构.并行优化框架主要由6个部分组成:粗粒度并行、PersistentThread、Uberkernel、线程与数据的动态映射、全局及本地队列.这6个组成部分相互协同,共同解决由于负载不均衡导致的性能瓶颈问题:(1)Uberkernel.将执行人脸检测算法主要计算部分的多个kernel合并为一个Uberkernel,统一负责人脸检测.这样一方面可以减少kernel的启动和全局同步开销,另一方面也可解决图像级负载不均衡问题.(2)PersistentThread与粗粒度并行.PersistentThread和粗粒度并行共同定义了Uberkernel的线程组织和运行方式,作为解决线程间负载不均衡问题的基础.粗粒度并行通过重新定义线程组织方式,提升GPU并行粒度:由thread变为warp(wavefront,AMDGPU),在一定程度上缓和了负载不均衡对性能的影响.PersistentThread重新定义了GPUthread的运行方式,使thread的生命周期和OpenCLkernel的生命周期相同,可循环处理多个任务.(3)动态映射与全局队列.在线程和任务的映射上,本文不采用传统GPU编程中的静态映射方式,而是构建线程与任务的动态映射机制,根据线程的任务负载情况,实现线程和任务的动态映射.同时构建以此为任务调度策略的全局队列,解决work-group间负载不均衡的问题.(4)本地队列.构建位于共享内存(LDS,AMDGPU)的本地队列,work-group内的所有线程协同工作,解决work-group内的负载不均衡问题.本节将对以上关键优化方法和技术进行详细讨论和介绍.4.3.1Uberkernel如3.2节所述,为了检测图像中不同大小的人脸,我们需要按照一定的缩放因子对图像进行缩放,直到缩放图像和检测窗口为同等大小为止,这样就形成了一个缩放图像集.如果一次只处理一幅图像,并通过在CPU端通过多次启动GPUkernel循环处理这些缩放图像,不仅会增加GPUkernel的启动和全局同步开销,而且当缩放图像过小而不能充分利用GPU的计算资源时,会导致GPU计算资源的极大浪费,由此会产生图像级负载不均衡.为此,我们引入了Uberkernel机制,其核心是通过kernel合并,一次处理多幅甚至所有图像.这样仅通过一次或几次OpenCLkernel的启动就全部处理完所有的缩放图像.Uberkernel的具体流程如图6所示.在GPU的GlobalMemory中设立一个统一的地址空间,将所有图片按照缩放比例,顺序放入统一的地址空间中.同时,OpenCLkernel将对这些缩放图片按照统一的方式进行处理.当图片太大,统一的Page8地址空间不能全部容纳所有缩放图片时,则按照统一地址空间最大化利用的原则(尽可能填满统一地址空间)对缩放图片进行分组,然后循环处理每组图片.该机制尽可能的保证每个OpenCLkernel的工作量足以充分利用GPU所有的计算资源,很好地解决了图像级负载不均衡问题.4.3.2粗粒度并行与PersistentThread在Uberkernel的线程组织及运行方式上,本文引入组粒度并行与PersistentThread.传统GPU编程是大规模细粒度并行,即一次开启大量线程,并以单个软件线程(thread)作为并行粒度.这种编程方式无疑是线程间存在负载不均衡特性算法的噩梦.为此,本文在Viola-Jones人脸检测算法的GPU实现中,采用硬件线程(NVIDIAGPU为warp,含32个thread,AMDGPU为wave-front,含64个thread)作为并行粒度.同时,硬件线程内多个thread协同工作,共同处理分配的检测窗口,其协同工作方式在4.3.5节本地队列中会详细讨论.粗粒度并行的实现方式较为简单:一个work-group只包含一个warp或者wavefront,work-group将作为全局队列任务分配的单位.采用粗粒度并行编程方式的优势主要有3个:(1)移除本地同步操作.wavefront/warp是GPU最基本的执行和调度单元.当一个work-group内只包含一个wavefront/warp时,可移除本地同步操作,减少本地同步开销,在一定程度上提高程序性能.(2)一个work-group只包含一个wavefront/warp,我们可以将work-group看成是一个与其他work-group执行相互独立的多指令多数据(MutipleInstructionMultipleData,MIMD)线程.即保证了SIMD执行方式的有效性,又提供了MIMD式的工作粒度.(3)减轻work-group内线程间的负载不均衡.在粗粒度并行模式下,任务的分配以work-group为单位,work-group内的所有线程协同处理所分配的计算任务.这种工作模式结合我们下面即将讨论的本地队列,可大大减小work-group内线程的负载不均衡现象.当然,粗粒度编程方式也存在一个劣势:由于GPU硬件资源的限制,每个CU上同时运行的work-group数目是有限制的.因此,当work-group包含的线程数目较少时,可能会导致CU上同时运行的线程不足,从而不能有效地隐藏访存延迟.幸运的是,由于人脸检测算法有较大的计算密度,这个劣势可以消除.在实际实现中,结合数据本地化,为每个CU部署8~12个work-group即可有效地隐藏访存延迟.在运行方式上,传统GPU线程的生命周期一般为五个过程:启动、获取操作数据、处理数据、写回处理结果、退出,其运行及调度方式都是静态的且由GPU硬件控制.这种运行方式显然对于解决负载不均衡的问题是非常不利的.因此,本文引入了PersistentThread,其生命周期和OpenCLkernel的生命周期相同,并可循环处理多个任务:线程在将一次数据处理的结果写回后,不是立即退出,而是判断是否还有别的任务需要处理,如果有,线程将继续获取任务进行处理,如没有才退出.这样在Viola-Jones人脸检测算法中,可为每个线程分配多个检测窗口,线程将循环处理这些检测窗口,直到将分配给它的窗口全部处理完毕.同时,线程与检测窗口的映射将根据线程的任务负载情况采用动态映射方式,从而最大限度的保证了线程间的负载均衡.这将在4.3.3节线程与任务的动态映射中进行详细讨论.4.3.3线程与任务的动态映射在线程与任务的映射方面,传统GPU编程采用静态编程模式,即在GPUkernel启动之前,线程和任务的映射就已经确定,线程由GPU硬件顺序调度执行,每个线程处理的任务和任务数都是固定的.这种编程模式虽然很好的满足了规则的数据并行应用,但对于具有线程间负载不均衡特征的人脸检测算法,无法解决其存在的负载不均衡问题.本文Page9在PersistentThread的基础上,引入GPU动态编程模式,该模式具有以下3个特征:(1)固定开启线程数目.根据目标GPU计算平台的CU数量,确定开启的线程数目.在人脸检测算法中,共开启8×N(AMDGPU)或者12×N(NVIDIAGPU)个work-group,其中N为CU数目.每个work-group包含64(AMDGPU)或32(NVIDIAGPU)个线程.(2)每个线程分配多个计算任务.结合PersistentThread编程方式,每个线程循环处理多个任务.(3)在线程的任务分配方面,在GPUkernel启动之后,根据线程的实际任务负载情况确定线程与任务的映射关系.(4)该策略将作为全局队列(4.3.4节)的任务调度机制,根据粗粒度并行的定义,以work-group为单位进行任务分配.图7显示了线程与任务动态映射的过程:首先每个work-group的第0号线程作为标记线程,访问位于全局内存上的原子变量G,在获得原子变量访问权后,对原子变量加N(N为work-group每次处理的窗口数目,在AMDGPU上N为64,在NVIDIAGPU上N为32);然后判断G是否小于检测窗口总数Total+N,如果小于,则获取该work-group要处理的检测窗口,否则对应work-group退出;最后将待处理的N个检测窗口返回给对应的work-group.work-group以4.3.5节介绍的本地队列机制处理完这些检测窗口后,再重复以上操作,直到所有检测窗口都处理完毕为止.注意,所有检测窗口以队列形式存储在全局内存上,全局内存的构建组织方式将在4.3.4节详细讨论.图8为线程与任务动态映射的伪代码.G:位于全局内存的原子变量,记录被处理的窗口数N:每个work-group一次处理的窗口数1.2.3.4.5.6.7.8.9.10.11.12.动态编程模式根据线程的实际任务负载情况进行任务分配,即当work-group处理的窗口包含人脸而导致计算量过大时,该work-group处理的窗口数目就会变少;反之,当work-group处理的窗口计算量小时,该work-group就会处理更多的窗口.因此,动态编程模式在一定程度上解决了work-group间负载不均衡的问题.当然,动态编程模式会因原子变量访问导致额外的开销.但一方面,由于work-group的调度执行存在一定的时间间隔,所以这个开销会非常小;另一方面相对于负载不均衡导致的性能瓶颈,这个开销几乎可以忽略不计.因此,动态编程方式会大幅提高人脸检测算法在GPU上的性能.4.3.4全局队列线程与任务的动态映射机制能够很好的解决work-group间负载不均衡问题的前提是:位于全局内存上的待检测窗口必须被很好的组织,能够及时响应访存请求.因此,本文引入了全局队列.全局队列的作用是以队列的形式组织好待检测窗口,在线程与负载动态映射机制下,能方便的建立起线程与数据的动态映射关系.结合前面讨论的Uberkernel和PersistentThread,全局任务队列的工作流程如下:首先将Uberkernel中所有的探测窗口都加入到该队列中;其次以32(NVIDAGPU)或者64(AMDGPU)为单位将探测窗口分成若干任务组,并将其作为任务调度单位;最后,根据线程与任务动态映射机制,以work-group为分配单元,Page10根据线程的实际任务负载情况,完成任务的动态分配.全局队列除了任务与负载动态映射机制外,没有使用更加复杂的任务调度方式.这里有两方面的原因:一方面,全局队列位于全局内存上,其访存和原子操作的开销都非常昂贵.复杂的任务调度方式不仅难以实现,而且可能会产生昂贵的调度开销,在性能的提升上得不偿失.另一方面,线程与数据动态映射机制已经决定了全局任务队列的任务调度方式,且这种任务调度方式足够解决work-group间的负载不均衡现象.4.3.5本地队列线程与任务的动态映射及全局队列机制的引入,较好地解决了work-group间负载不均衡的问题,而work-group内线程间负载不均衡的问题由位于片上本地内存(共享内存,NVIDIAGPU)的本地队列解决.图9详细地显示了本地队列及其任务处理过程.work-group将其负责处理的待检测窗口组织为位于片上本地内存的队列,然后使用级联分类器进图9本地队列由此可见,本地队列基本上解决了work-group内部线程间负载不均衡的问题.4.3.6其他优化方法除以上优化方法外,Viola-Jones人脸检测算法还使用了GPU传统优化方法:(1)开发ILP.开发ILP主要有两种方式:一是循环展开;二是调整代码顺序,使相同指令类型(GPU的指令类型可分为3种:读内存指令、计算指行检测.每级分类器将会检测队列中的所有窗口,通过本级检测的窗口将会重新进入队列,等待下一级分类器的进一步检测;否则,该窗口将会被丢弃.其检测过程分为两个阶段:(1)单独处理阶段.因为0~2级分类器特征数目较少,可以很快完成计算,故令每个线程单独负责处理一个窗口.在这个过程中,当使用1~2级分类器进行检测时,会有线程处于空闲状态,但这个时间太短,不足以引起性能瓶颈,反而能减少协同处理开销.(2)协同处理阶段.随着分类器级数的增大,特征数目和计算量会急剧增长.同时,经过0~2级分类器的检测,队列中的待检测窗口数目也会减少.此时进入协同处理阶段,即一次从队列中取出M(在AMDGPU上M为4,NvidiaGPU上M为2)个检测窗口,由work-group内所有线程协同处理(通过检测的窗口返回队列),直到队列中的所有窗口都通过本级分类器检测为止;然后,进入下一级分类器继续检测;最后,只有经过最后一级分类器检测的检测窗口中才包含人脸.令以及写内存指令.在执行过程中,GPU会将相互独立、相同类型且相邻的指令打包在一起并行执行)的代码打包在一起,编写对编译器友好的代码.(2)指令选择优化.因为人脸检测函数较高的计算密度,选择高吞吐量的指令对性能的提升就变得尤为重要.在该算法的实现中,共采取了两种指令优化:一是使用位运算指令代替乘法和除法指令;二是用mad24、MUl24指令代替乘加指令.Page11(3)减少动态指令.主要方法是减少条件分支.因为人脸检测算法中存在着大量的条件判断语句,因此使用?:语句代替if…else…语句是减少动态指令的主要方式.4.3.7性能移植优化如前文所所述,虽然GPU架构日益多样化,但是统一的层次式架构模式为性能移植提供了可能.只要完成了关键性能参数的抽取,并建立完善的性能参数传递机制,就可实现不同GPU硬件平台间的性能移植.两个GPU计算平台的关键性能参数抽取如表1所示.在性能参数传递机制构建方面,利用OpenCL程序运行时编译的特点是通过宏定义将性能参数在编译时传入OpenCLkernel,根据目标平台,传入相应的性能参数.根据以上方法,本文在不修改代码的前提下,最终实现了Viola-Jones人脸检测算法在AMDRadeonHD7970和NVIDIAGTX680两个不同GPU计算平台上的性能移植.表2GPU计算平台性能参数AMDRadeonHD7970NVIDIAGTX680Viola-Jones人脸检测算法的CPU版本来自OpenCV2.4,该版本已深度优化,在CPU平台上具有较高的性能.因此,选择该版本,可提高性能对比的可信性.值得注意的是CPU版本在编译时,添加“-o3”选项,以充分利用CPU的计算资源,提高CPU串行版本的性能.检测图片来源于CMU人脸检测项目所用的数据库[21],该数据库是CMU人脸检测项目的专用数据库,提供了用于大量评估算法准确性的人脸正面图片,非常具有代表性.在实际测试中,我们选择了50张图像共包含427个人脸来评估我们实现的人脸检测算法GPU版本的正确性和性能.图10列举了其中3幅不同大小、不同背景、不同人脸数目的图片.其中图片1的大小为256×337,包含人脸数目为1;图片2大小为696×510,包含人脸数目为12;图片3大小为1280×1024,包含人脸数目为56.5.2正确性验证本文选取OpenCV2.4库中实现的Viola-Jones人脸检测算法作为进行GPU移植和优化的基准CPU程序,OpenCL程序的各方面参数与该基准程序保持一致.同时,检测模型也直接使用OpenCV2.4work-group大小work-group数目全局队列任务发送单元本地队列协同处理单元处理每个检测窗口的线程数目循环展开次数5性能评估5.1测试平台搭建本文选取AMDHD7970和NVIDIAGTX680两个不同架构的GPU作为性能测试平台,选取Intel(R)Xeon(R)X5550QuadCoreCPU(2.66GHz8MBL3Cache)作为CPU计算平台.选取两个不同计算平台的目的是验证性能可移植性.两个GPU计算平台的主要性能参数如表2所示.3.06.0自带的检测模型.因此,本文的正确性验证只和该CPU串行代码的运行结果进行比较.值得注意的是,通过改进算法及检测模型来提高检测的准确率并不是本文关注的内容,本文主要关注的是相同算法实现在GPU计算平台上的性能提升.Page12图10显示了本文实现的OpenCL版本对3幅不同图像的检测结果.从中我们可以看出:并不是所有的人脸都被检测出来.这主要是因为这些未检测出的人脸并不是标准正面像.同时也可以发现许多没有人脸的区域也被检测为人脸,如图像3.这是因为这些区域在一定程度上与人脸相似.从以上分析可以看出:OpenCL版本并没有达到100%的人脸检测精确度.但通过和OpenCV库中的CPU串行版本的运行结果相比较,我们发现人脸检测精度没有实现100%与串行算法实现及检测模型有关,而与OpenCL实现无关.表3CPU版本与OpenCL版本人脸检测数目(单位:个)图片编号123表3显示了CPU串行版本和本文实现的OpenCL版本针对不同图片的人脸检测数目.从中可以看出,本文实现的OpenCL版本在人脸检测数目上与CPU串行版本完全一致,这就证明了人脸检测算法OpenCL版本实现的正确性.而人脸检测的准确率可通过改进算法实现或者使用更精确的检测模型来提高,但这并不是本文关注的内容.5.3性能分析5.3.1整体性能分析图11和图12分别显示了优化后的Viola-Jones人脸检测算法在AMDHD7970和NVIDIAGTX680两个不同GPU计算平台上的性能及相对于CPU版本的性能提升.值得注意的是,OpenCL版本的性能测定包含了OpenCL程序运行的所有时间,包括OpenCL初始化时间、CPU和GPU间的数据传输时间以及kernel的运行时间.从中我们可以看出,与人脸检测的CPU版本的性能相比,本文实现的OpenCL版本在两个GPU计算平台上处理不同的图片都达到了可观的加速比:在AMDHD7970GPU计算平台上,实现了11.24~20.27的性能加速;在NVIDIAGTX680计算平台上,实现了9.24~17.62的性能加速.由此可以看到,NVIDIAGTX680GPU与AMDHD7970GPU相比,在性能提升方面略有差距.这主要是因为前者在峰值计算性能和峰值访存带宽这两个主要的性能参数方面要弱于后者.图11和图12不仅说明了我们优化框架的有效性,有效地解决了算法负载不均衡的问题;而且说明了虽然两个GPU计算平台的架构不同,计算单元的组织也不相同,但是二者都采用了层次式架构,优化技术和方法也大致相同,只要对性能参数进行精心抽取和定义(如4.3.7节中的每个work-group一次处理的窗口数N以及work-group内线程处理一次协同处理的窗口数M等),是完全可以实现不同GPU计算平台间性能移植的.同时,我们可以看到,对于不同图像,GPU的加速效果也是不同的.主要有两方面的原因:第一,GPU是大规模并行处理器,理论上,图片规模越大,计算量越大,越能充分利用GPU计算平台强大的计算能力,加速效果也就越好.第二,图像的背景和人脸数目不同,算法的总体计算量也不同.同时,算法在处理不同图片时的负载不均衡的程度也不尽相同,从而进一步影响了GPU计算平台对性能的提升效果.5.3.2不同优化方法对性能的影响图13显示了以Nave版本为基准,采用不同优化方法后,在两个GPU计算平台上所带来的性能提升.从图13中,我们可以看出如下6点:(1)在两个GPU计算平台上,不同优化方法带Page13来的性能提升虽有差异,但趋势大致相同.这不仅说明了两个GPU计算平台在整体架构设计上的统一性,而且说明了在两个GPU计算平台上,线程间负载不均衡都是最严重的性能瓶颈,这些都是导致性能降低的主要因素.图13不同优化方法在两个GPU计算平台上的性能提升(2)线程与任务的动态映射带来的性能提升最大,注意这里的线程与任务动态映射实际指的是动态映射+全局队列,因为两者是一个统一整体,没有必要分开说明.从性能图中可以看出,采用传统GPU静态编程模式,work-group间的负载不均衡会导致性能的极大降低,这是因为图片中绝大部分区域没有人脸,大量的线程可能运行很短的时间就会退出等待,只有少量线程仍在运行.而线程和任务的动态映射很好地解决了这个问题,因为线程和任务动态映射的核心是根据线程的实际任务负载情况,动态进行任务的分配.这样就可以让执行大任务的线程,执行的任务数量少一些;执行小任务量的线程,执行的任务数量多一些.这就从根本上解决了work-group间负载不均衡的问题.(3)本地队列也有效地提升了算法性能.这说明了3点:第一,work-group内同样存在着线程间负载不均衡问题,同样会影响程序性能;第二,work-group内线程间负载不均衡对性能的影响没有work-group间的负载不均衡对性能的影响大,这是因为一个work-group处理的图像区域毕竟有限,线程间的计算量差距并不会太大;第三,本地队列很好地解决了work-group内线程间的负载不均衡问题.(4)传统优化方法带来的性能提升并不明显.这就说明了负载不均衡是人脸检测算法在GPU计算平台上的性能瓶颈,传统意义上引起性能下降的因素在该算法上体现得并不明显.但同时也说明了,只要解决负载不均衡问题,传统优化方法依然后改善GPU计算资源的利用率,同样可以带来性能提升.(5)虽然PersistentThread和kernel合并对性能的提升有限,但是两者是整个优化框架的基础.对性能影响最大的线程与任务的动态映射机制构建的基础就是PersistentThread和kernel合并.粗粒度并行虽然无法测试对性能的具体影响,但同样作为优化框架的基础,同本地队列一起,克服work-group内线程间的负载不均衡问题,从而在一定程度上提升了算法性能.(6)通过该算法的优化,说明了只要经过精心优化,具有负载不均衡特征的非规则算法在GPU计算平台上也能够取得非常好的加速比.因此,GPU不仅对规则的数据级并行能够取得很好的加速效果,对于不规则的任务级并行,只要优化方法得当,也会取得相当可观的性能加速效果.这无疑会大大扩展GPU计算平台的应用场景.5.3.3与以往工作的比较虽然有很多关于Viola-Jones人脸检测算法的GPU移植工作,但很少有发布出来的代码或者库.而针对不同图片,人脸检测算法的性能又具有很大的差异性.因此,在与以往工作的对比上,本文只选取了OpenCV2.4库中该算法的OpenCL实现版本.但考虑到OpenCV在计算机视觉领域应用的广泛性,这个对比也在一定程度上体现了我们工作的有效性.图14显示了本文实现与OpenCV2.4中人脸检测算法的OpenCL版本的性能对比.从图中可以看出,相对于OpenCV库的实现,本文实现在两个GPU计算平台上,针对不同图片都取得了较大的性能提升.具体为:在AMDHD7970计算平台上,取得了27.1%~37.9%的性能提升;在NVIDIAGTX680计算平台上取得了20.6%~31.7%的性能提升.本文实现性能提升的主要原因是work-group间负载不均衡问题的解决:OpenCV库的OpenCLPage14实现版本中,全局队列依旧采用静态调度的方式,没有很好地解决全局队列的任务调度问题,work-group间的负载不均衡问题依然没有得到改善.而本文实现了线程与任务的动态映射机制,全局队列可以根据线程的实际任务负载情况进行任务分配,很好地解决了work-group间的负载不均衡问题.总之,本文提出的优化框架很好的解决了Viola-Jones人脸检测算法在GPU的实现和优化中,由于负载不均衡导致的性能瓶颈,取得了可观的性能加速比.该框架的6个组成部分,既各司其职,又相互协作,共同提升了人脸检测算法在GPU计算平台上的性能.同时,该框架不仅适用于人脸检测算法,而且对于其他具有类似特征的算法,也具有很好的指导意义和参考价值.6结束语本文详细地讨论了Viola-Jones人脸检测算法在GPU计算平台上实现和优化的关键方法和技术.由于人脸检测算法的GPU实现存在线程间负载不均衡的非规则特性,导致仅使用传统优化方法无法有效地提升性能.本文构建了一个针对此类算法的并行优化框架通过Uberkernel、粗粒度并行、PersistentThread、线程与任务动态映射、本地/全局队列等优化方法的使用突破了由于线程间负载不均衡导致的性能瓶颈.实验结果表明,与OpenCV2.4中经过高度优化的CPU版本在IntelXeonX5550CPU上的性能相比,优化后的算法在AMDHD7970和NVIDIAGTX680两个不同GPU计算平台上分别达到了11.24~20.27和9.24~17.62倍的加速比,不仅实现了高性能,而且实现了在不同GPU计算平台间的性能移植.本文采用的优化方法,对其他具有线程间负载不均衡特性的算法在GPU计算平台上的实现和优化也具有很好的指导意义和参考价值.致谢感谢王伟俨对本文前期工作的支持;感谢AMD公司对本文工作的支持;感谢课题组内其他成员的帮助和支持!
