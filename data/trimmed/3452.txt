Page1可扩展路由器FIB表分解存储模型陈文龙1),2)徐明伟3)杨扬2)韩冬4)1)(首都师范大学信息工程学院北京100048)2)(北京科技大学计算机与通信工程学院北京100083)3)(清华大学计算机科学与技术系北京100084)4)(北京大学软件与微电子学院北京100080)摘要FIB表急剧增长是互联网高速发展面临的重要问题之一,FIB表分解存储能有效解决该问题.现有的SPAL技术将FIB表较均匀地分解存储在不同线卡,但仍然存在较多的表项冗余存储现象,并且实现复杂.对此设计了一种新型的转发表分解存储模型(DecomposedStorageofFIB,DSF),它依据IP前缀的前若干bit位实现线卡对转发表的分解存储,并只带来极少的冗余存储.DSF的改进方案———EDSF,更可使各线卡非常均衡地完成分解存储.提出的分解存储模型缓解了FIB表项急剧增长问题的解决压力,同时大大节省了硬件资源.对于线卡数量更多的可扩展路由器尤为适合.通过对当前运营的路由表的分解存储实验研究及与其它方案的比较,验证了文中模型良好的存储性能.关键词路由器;路由;转发表;分解存储;IP前缀1引言互联网快速发展带来的一个重大问题就是核心路由器FIB表的急剧增长[1].我们需要在路由器中部署更大容量的路由查找及存储芯片.而且,商用路由器普遍采用全冗余备份方法存储FIB表项,该方法使得每块线卡(LineCard,LC)都要大量扩充硬件资源.随之带来的芯片供电和散热处理还会消耗更多的电力资源.随着路由器体系向可扩展结构的发展[2],该问题显得更为突出.FIB表分解存储是解决上述问题的重要手段.现有FIB表研究[3-4]主要集中于通过并行处理提高查询速度,只有文献[5]提出的SPAL技术是一个完备的FIB表分解存储方案,但它仍存在大量转发项在多块线卡的冗余存储.本文设计了转发表分解存储方法(DecomposedStorageofFIB,DSF).它依据IP前缀的前若干bit位进行转发表分解存储,实现线卡对FIB表的部分存储.每线卡只需存储系统转发表的一个子表,且每线卡平均存储转发项数量随着线卡数增加而减少.模型只需为每块线卡增加存储极少虚拟路由,与真实转发项共存于一个转发表中.线卡转发引擎通过最长前缀匹配(LongestPrefixMatching,LPM),既可实现转发下一跳查询,又可实现报文到转发子表的对应.针对真实网络中路由前缀分布不均衡特征,DSF模型的改进方案EDSF,能使各线卡存储的转发项数非常均衡.DSF/EDSF模型可实施于所有进行最长前缀匹配的分布式转发体系.而且,针对该模型设计的线卡功能结构与现有商业路由器线卡设计兼容,易实施.理论分析及对实际运营路由器FIB表的分解结果都表明它能极大地减少整个系统及每线卡存储的FIB表项.本文提出的分解存储模型较之SPAL技术,能实现更为平均的分解存储以及更少的冗余存储.其主要特点包括:(1)各线卡分解存储非常均衡,使得线卡所需的最大存储容量变小;(2)只需增加存储极少的虚拟路由即可实现;(3)方案适用范围广:所有遵循LPM的分布式路由转发体系;(4)与现有商用路由器兼容,我们只需对现有商用路由器线卡功能做极小的改动,便可完成DSF模型的实施,易推动其产业化进程.本文第2节介绍相关研究工作;第3节介绍DSF模型;第4节介绍DSF模型实施算法及线卡功能结构;第5节介绍优化的DSF模型———EDSF;第6节为实验及结果分析;第7节总结全文.2相关研究文中“核心路由表”是指系统对各路由协议所学路由计算后的最佳路由,“转发表(FIB)”是指存储在线卡上指导报文转发的信息.传统模型中,每块线卡的转发表都是核心路由表的映像.然而,该描述在本文提出的新型模型中并不成立.另外,“真实路由”或“路由”也表示核心路由,它对应DSF模型中的“虚拟路由”描述.近年来学者们研究了如何通过并行路由查询,提高转发引擎查询速度.文献[3]针对Trie树路由存储提出了一种基于SRAM的多管道并行IP查询体系,通过缓存常用路由来均衡各管道流量.文献[4]设计了一种基于分块路由并行查询的报文转发体系:IFPLUT.它根据转发出接口将转发表分成若干子部分.下一跳查询时,所有子部分并行进行路由查询,所有结果中IP前缀长度最大的路由即为报文转发的依据.文献[3-4]的主要贡献是提高了FIB表查询效率,虽没有实现FIB表分解存储,但确为分解存储提供了有价值的参考.文献[5]为解决FIB表扩张问题设计的SPAL技术是真正的FIB表分解存储方案.SPAL根据目的IP前缀中任意n位的值将转发表分解成若干子集,分别存储在不同线卡.线卡分析报文目的地址该n位值,确定其转发项所在线卡,并向该线卡进行转发查询获得结果.虽然SPAL缓存查询结果,但新到流量转发项查询时涉及两次线卡间消息传递,增加了转发时延.而且,缓存维护(新项插入、删除等维护)行为带来很大开销.最重要的,该方法基于SRAM实现且硬件逻辑实现复杂,与现有商业核心路由器实现不兼容.另外,该方案中仍会出现较多的转发项冗余存储.路由器已向可扩展体系结构发展[2].可扩展路由器是由若干个子路由器级连而成的一个统一的路由系统.它在功能、性能、接口规模等方面,具有极大的可扩展性.其主要优点有:保护前期运营投资,提高系统性能,增强可靠性,简化网络拓扑等.主要的路由器厂商已开发出相应产品[6-7].可扩展路由器的一个重要特征是线卡数量急剧增多,所以FIB表容量增大导致的消耗更多硬件资源及电能的问题在可扩展路由器中显得更为突出.3DSF模型商用核心路由器通常为分布式体系结构,普遍Page3采用的转发表存储方法是每块线卡存储所有核心路由表项[6-8],称为完全备份存储模型(FullBackupStorage,FBS).假设可扩展路由器系统的核心路由表项数量为m,线卡总数为n,满足n>1(本文不考虑系统仅有一块线卡的情况).传统FBS模型中,系统存储的转发项总数为m×n.随着路由器路由数量逐渐增大,设备存储代价及查找开销都难以承受.而且,因为IPv6路由占用更多存储空间,IPv6网络的部署将加剧这一矛盾.本文的DSF模型正是为解决这一矛盾而设计的.3.1分解存储定义1.对于两个给定IP前缀PFX1:Address1/Masklen1;PFX2:Address2/Masklen2,若满足Masklen2Masklen1,且前缀地址Address1和Address2的二进制前Masklen1位完全相同,则称作PFX2归属PFX1,或PFX1包含PFX2,记作:PFX2PFX1.如有192.0.0.0/2128.0.0.0/1、10.0.0.0/810.0.0.0/8.定义2(单元前缀PFXunit).单元前缀是分解存储中依据某种策略指定的一些IP前缀.单元前缀具有下述特性:目的IP前缀归属同一单元前缀的若干路由项,存储在同一线卡,一块线卡可拥有多个单元前缀.定义3(聚集前缀PFXaggr).包含多个不同单元前缀的IP前缀被称作聚集前缀.令所有可能的单元前缀集合为Sunit,所有可能的聚集前缀集合为Saggr.DSF模型中,单元前缀和聚集前缀的指定方法分别通过规则1和规则2完成.规则1.对于给定整数k(0<k<32),所有掩码长度等于k的IP前缀被指定为单元前缀.k被称作分解位,有|Sunit|=2k,并令PFXunit(i)为前k位二进制数等于i的单元前缀.规则2.对于给定整数k(0<k<32),掩码长度小于k的IP前缀被指定为聚集前缀.以k=2为例进一步说明.此时单元前缀个数为4,包括PFXunit(0)=“0.0.0.0/2”,PFXunit(1)=图1n=4和n=6时单元前缀分配示例“64.0.0.0/2”,PFXunit(2)=“128.0.0.0/2”,PFXunit(3)=“192.0.0.0/2”;而“128.0.0.0/1”就是一个聚集前缀.所有前缀长度大于等于2的IP前缀,总归属于4个单元前缀中的某一个.我们将任一IP地址视为掩码长度为32的IP前缀,则任一IP地址总是属于且只属于某一单元前缀.DSF模型根据线卡数n来确定分解位k的取值,满足DSF模型的单元前缀和聚集前缀都是根据满足式(1)的k值指定而得.以4块线卡为例,n等于4则k等于2,即根据IP前缀的前两位进行路由表的分解存储.那么,共有4个单元前缀,每块线卡分得一个单元前缀.IP前缀归属“0.0.0.0/2”的路由项存储在LC0中,IP前缀归属“64.0.0.0/2”的路由项存储在LC1中,以此类推.对于目的前缀为聚集前缀(掩码长度小于2)的路由项,会在所有线卡存储.当然,路由系统中的线卡数可以为任意值,系统总是以满足式(1)的k,进行单元前缀的指定.所以,单元前缀的个数为进一步可得烅烄n<|Sunit|<2n,当n不等于2烆根据均分原则分配单元前缀.由式(3)可得每块线卡拥有PFXunit数为1或2,线卡会存储IP前缀归属其任一单元前缀的路由项.定义4.路由系统中,若第i个单元前缀PFXunit(i)被分配给第j块线卡LCj,记作PFXunit(i)LCj.为了描述方便,假设线卡标号为0、1、2依次递增,则DSF方案中线卡与单元前缀的分配关系为式(4).图1所示分解树以线卡数等于4和6为例说明了单元前缀的分配方法.Page4单元前缀分配后,就可实施对FIB表的分解存储.一条路由的IP前缀,要么归属某个单元前缀,要么本身就是一个聚集前缀.对于系统任一条核心路由项,其存储方法遵循规则3.规则3.令核心路由项的目的IP前缀为PFXdst,若PFXdst为聚集前缀,则通告该路由项给所有线卡存储;否则,该IP前缀必归属某个单元前缀,则只通告给某块线卡LCj存储,满足PFXdstPFXunit(i)和PFXunit(i)LCj.分解存储过程总结如下.首先,根据系统线卡数n及式(1)计算得分解位k.接着,根据k值及规则1得到所有单元前缀.最后,依据规则3对核心路由表进行分解存储.3.2虚拟路由及数据转发FIB表在各线卡分解存储后,DSF模型实施的另一关键则是数据层基于此存储规则的报文转发机制.DSF模型对处理报文的线卡进行角色定义.针对系统转发的某个IP报文,目的地址归属的单元前缀所在线卡,被称作该报文的宿主线卡,记作LCattach.以4块线卡为例,单元前缀“64.0.0.0/2”属于LC1,则LC1是目的地址为64.0.0.1、65.10.0.1、100.0.0.1等报文的宿主线卡.另外,定义LCin为接收该报文的线卡,LCout为发送该报文的线卡.DSF模型中报文转发思想是:对于待转发IP报文,总是在其宿主线卡进行LPM查找时才能获得最终转发信息,包括查找失败也在宿主线卡中决策.当报文的接收线卡不是其宿主线卡时,通过增加虚拟路由并按LPM查询机制将报文发向宿主线卡.也就是说,线卡接收报文后只需进行LPM处理,若接收线卡就是报文的宿主线卡则可直接获得最终转发信息进行转发处理,否则发送报文到它的宿主线卡再次进行LPM查找.DSF方案用简化、统一的硬件LPM查询,集成了报文处理的两个重要功能:获取最终转发信息及获取宿主线卡信息.一条转发项的描述包括以下主要字段:〈目的网段,出线卡号,出接口号,下一跳地址〉.对任一单元前缀PFXunit(i),若其分配给LCj,系统会构造一条目的网段为该单元前缀的虚拟路由:〈PFXunit(i),j,Inv,Inv〉(Inv表示一个无效值),并通告该路由给除LCj外的所有线卡存储.这样做的目的是,当除LCj外的其它线卡收到目的地址属于PFXunit(i)的报文,LPM查找后必定会匹配该条虚拟路由,从而转发报文到LCj.仍以4块线卡为例,单元前缀“64.0.0.0/2”属于LC1,则归属“64.0.0.0/2”的路由全部存储在LC1中.并且,系统会在0、2、3号线卡增加一条虚拟路由:〈“64.0.0.0/2”,1,Inv,Inv〉.若LC0或LC2或LC3收到目的地址为64.0.0.1的报文,LPM查找必匹配该虚拟路由,从而转发报文到LC1.每个单元前缀对应着一条虚拟路由,而每条虚拟路由会存储到(n-1)块线卡上,由式(2)可得路由器系统总共增加存储的虚拟路由数为总结每块线卡存储的FIB表包括:(1)所有聚集前缀路由项;(2)IP前缀归属本线卡所拥有单元前缀的路由项;(3)其它线卡的单元前缀对应的虚拟路由.其中,前2类路由都是系统真实存在的核心路由项.真实路由及虚拟路由全部存储进FIB表后,各线卡就可通过对报文进行LPM处理实现快速转发.根据接收报文的角色不同,可以分为两种情况:(1)非宿主线卡接收.LCin经过LPM查找后必定匹配某条虚拟路由,查找结果中出线卡就是该报文的LCattach,且得到的出接口号和下一跳都是无效值.报文通过内部交换网络到达LCattach后,LCattach发现边带信息中出接口和下一跳是无效值,于是再次进行LPM查找,若查询失败则丢弃报文.否则,必匹配某条真实路由,并得到全部转发信息.若最终出线卡就是LCattach,即LCattach与LCout角色重合,则直接发送;否则,通过交换网络发往最终的LCout,LCout发现边带信息已包含所有有效转发信息,则发送报文.(2)宿主线卡接收.此时报文的LCin与LCattach角色重合,报文所需的转发项只可能存储在接收线卡.LCin进行LPM查找,若查询失败则丢弃报文;否则,必匹配某条真实路由,并得到全部有效转发信息.若最终出线卡就是LCin,即LCin、LCattach与LCout三种线卡角色重合,则直接发送;否则,通过交换网络发往最终的LCout,LCout发现边带信息已包含所有有效转发信息,发送报文.DSF模型的报文转发过程中,板间转发次数由两个条件决定,条件1:LCin=LCattach;条件2:LCattach=LCout,而LCin与LCout的关系并不影响板间转发次数.条件1表示线卡从外部接收的报文的目的地址所需路由在入线卡;条件2表示转发时报文出线卡恰好存储了报文转发所需真实路由.DSF模型中,上述两个条件都成立则需0次板间转发,任一条件成立则需1次板间转发,都不成立则需2次板间转发.3.3无效地址考虑互联网单播路由中,有些IP前缀是不可能出现Page5的,如私有地址和组播地址.DSF模型中,如果一个单元前缀覆盖范围完全是这些地址,就无需分配.例如针对组播地址,它是二进制1110(十进制14)开始的地址范围.当单元前缀划分位数为4时,组播地址恰好归属于单元前缀:PFXunit(14).当单元前缀的划分位数为5时,组播地址恰好归属2个单元前缀:PFXunit(28)和PFXunit(29).以此类推,当单元前缀的划分位数k大于等于4时,有2(k-4)个单元前缀属于组播地址空间,分别是PFXunit(14×2(k-4)),PFXunit(14×2(k-4)+1),…,PFXunit(14×2(k-4)+(2(k-4)-1)).考虑无效地址的分解存储算法实现时,在本文算法基础上略作修改即可.4设计及算法4.1线卡设计图2是基于普遍施用的TCAM结构,设计的DSF模型线卡硬件功能结构.关键模块包括:Module_1,外部接口报文收发模块;Module_2,FIB表查询及转发处理模块;Module_3,板间报文分析处理模块.其中,Module_2是整个转发引擎的核心,图2支持DSF模型的线卡功能结构无论DSF模型还是下文介绍的EDSF模型,都有一部分报文需要多一次LPM查找或多一次板间转发,这就带来两个问题:报文转发时延增加、消耗更多的内部交换带宽.不过,由于核心路由器普遍采用TCAM芯片完成LPM查找,TCAM查找速度可达到纳秒级,但这对端到端至少毫秒级的传输时延来说影响很小,不影响设备提供的网络服务质量.而对于交换带宽,由于目前的分步式核心路由器处理速度瓶颈在线卡本身而不在交换网络上,我们只需通过设置提高交换结构的加速比就可解决内部交换带宽增加的问题.另外,我们还可在线卡增加存储常用路由(PopularRoutes),使得两次LPM查找或两次板间转发的情况发生概率大大减小.限于篇幅,本文不对该问题深入探讨.通过TCAM芯片存储转发项的IP前缀并实现LPM处理.静态随机存储器(SRAM)在路由器查找系统中配合TCAM查找,用于存储匹配表项信息,即LPM查找结果:出线卡、出接口、下一跳等信息.其中,Module_1和Module_2是当前商用高端路由器普遍具备的功能[9],目前的线卡设计中没有标识①所指流程,收到交换网络发来的报文就直接走标识②所指流程,利用边带信息发出.Module_3是专门为DSF模型设计的.报文从其它线卡经交换网络发到本线卡,由板间报文分析处理模块对报文的边带信息(报文内容以外的相关处理信息,如入接口、出接口、下一跳地址等)进行分析处理,有两种可能:(1)报文已获得出接口及下一跳信息则直接发送(即图2中标识②),对于该报文来说本线卡的角色是LCout,该类报文在本线卡会直接通过外部接口发送.(2)报文未获得有效的出接口及下一跳信息(即图2中标识①),到本线卡进行最终LPM查询及转发处理.对于该报文来说本线卡的角色是LCattach,该类报文会在本线卡进行最终LPM查询及转发处理.4.2实施步骤及算法DSF模型实施时包括以下步骤(它们全在主控板中完成,各线卡只需对主控发来的转发项进行存储即可):3.虚拟路由存储.路由引擎为每个单元前缀构造一条虚拟路由,通告除该单元前缀所属线卡之外的所有线卡.见算法2.1.参数初始化.主控在向线卡分发转发项之前设置参数.设置系统核心路由数为m;设置线卡数为n;根据式(1)计算单元前缀分解位k,即单元前缀掩码长度;计算单元前缀数量s=2k,也等于虚拟路由数.2.真实路由分解存储.路由引擎对真实路由IP前缀分析,若为聚集前缀,对应路由项分发给所有线卡存储;否则,只通告所属单元前缀所在的线卡存储.见算法1.Page6算法1.Distribute-Actual-RT.1.for(i=1;i<=m;i++)2.getmasklenofPFXdstofRTi:3.if(masklen<k)4.sendRTitoallLC;5.else6.getPFXdstofRTi;7.for(j=1;j<=|PFXunit|;j++)8.ifPFXdstPFXunit[j]9.sendRTitoLCPFXunit[j]belongsto;10.break;11.return;算法2.Distribute-Virtual-RT.1.for(i=0;i<s;i++)2.if(i<n)3.constructvirtual_rt:4.sendvirtual_rttoallLCexceptLCi;5.else6.constructvirtual_rt:7.sendvirtual_rttoallLCexceptLC(i-n+1);8.return;算法假设系统中线卡编号从0开始依次增加,实际环境中并不一定如此.此时,算法略作改进,只需给每块线卡额外分配一个依次加的序号,并记载序号与线卡号的对应关系,算法主体思想不变.4.3存储分析通过式(5),我们可以分析虚拟路由总数、每线卡平均虚拟路由数随线卡数的变化关系,见图3.图中虚拟路由总数随线卡数增多有一定的增加,但数量较小,16线卡时也不到250条虚拟路由.相对核心路由器多达几十万的路由数来说,影响不大.另一方面,每线卡平均存储的虚拟路由数量也随线卡数增加而略有增加,但数值一直较少,16线卡时每线卡增加存储15条虚拟路由.所以,DSF方案在真实FIB表分解存储过程中所增加的虚拟路由数极少,额外存储开销很小.接着,我们分析路由器总共存储的转发项数及每线卡平均存储的转发项数.FBS方案系统存储的转发项总量为m×n.DSF模型中,路由存储分为三块:聚集前缀真实路由、非聚集前缀真实路由和虚拟路由.令聚集前缀路由数为m,它们会在每块线卡存储,共为n×m.非聚集前缀路由只会在某一块线卡存储,共存储m-m.而对于虚拟路由数量,依据式(5)计算可得.所以,DSF方案中系统的转发项总量为(m-m)+n×m+(2log2n×(n-1)),即m+(m+2log2n)×(n-1).由于聚集前缀路由数m总是较小,所以相对FBS方案中m×n的转发项数量,DSF方案在系统转发项总数和每线卡平均转发项数有很大的减少,大大节省了硬件存储资源.5优化模型互联网中,地址分配零乱且不延续,导致路由表IP前缀分布极不均衡.DSF模型虽然能将系统路由分解到各线卡,但各线卡存储转发项数量差别极大.DSF模型对两个真实路由表的实施结果都说明了该问题的存在,见表2和表3.所以,我们设计了优化模型:EDSF(EnhancedDSF),希望能将FIB表项尽量均匀地分解到各线卡.优化方案的转发引擎,仍然通过虚拟路由完成报文到宿主线卡LCattach的传送,线卡功能结构与图2一致.EDSF模型区别于DSF模型的主要特征是:不同的单元前缀指定策略.DSF模型的单元前缀掩码长度总时相等,EDSF模型却无此约束.优化方案主要思想是从第1个bit位开始,每次根据路由IP前缀一个bit位的值对核心路由表进行分解.针对每次分解,令该bit位值为0的一份为SEG0,值为1的一份为SEG1.只要分得部分的路由数大于基准值m/2n,即平均每线卡路由数的1/2,就根据下一bit位的值继续分解.分解完成后,根据树根节点到每一叶子节点的bit位值,生成一个单元前缀PFXunit,单元前缀个数就是该分解树的叶子节点数.每一PFXunit只分配到某一线卡,一块线卡可分得1个或多个PFXunit.分配依据是归属到每一线卡的多个PFXunit所辖真实路由数尽量接近.后续处理,如根据单元前缀生成虚拟路由,以及真实路由存储过程与标准DSF一致.需要说明,上述基准值的指定与方案所需分解均衡粒度相关,基准值越小分解得越平均,但会带来更多的虚拟路由.下面我们举例说明分解树产生过程.假设某系Page7统核心路由表共有100条路由,4块线卡,则基准值m/2n为12.5.根据前述规则,只要分解后的节点对应的路由数大于12.5,就根据下一bit位继续分解.图4(a)是该系统对应的分解树,其中树节点圈内数值表示归属该节点前缀的路由数,外数表示该节点对应前若干bit位的值.如第一次分解,根据IP前缀第1bit位分解.SEG0有76项,对应节点0,SEG1有24项,对应节点1.由于节点对应路由数都大于12.5,需要根据下一bit位继续分解,直至所有图4基于EDSF的分解树示例叶节点每节点LC00000010000107001825LC1000015000111101100925LC21010011011101110324LC301111121109111526所有单元前缀都是分解树的叶子节点,则任意两个单元前缀的覆盖范围交集为空.所以对于任一路由前缀PFXdst,最多只可能归属于一个PFXunit.由于分解树覆盖了IP前缀的全集,而且是从树根开始,依次根据1个bit位进行分解的.所以,如果一个PFXdst不归属任一PFXunit,则必有对应的非叶子节点.以其为根的子树中,叶子节点代表的单元前缀全部归属该PFXdst.如图4中,前缀128.0.0.0/1不归属分解树任一PFXunit,其对应非叶子节点1.以节点1为根的子树所有单元前缀:128.0.0.0/2(节点10),192.0.0.0/3(节点110)和224.0.0.0/3(节点111)都归属128.0.0.0/1.EDSF模型在指定单元前缀并分属到各线卡后,对于系统的任一核心路由项,其分解存储方法遵循规则4.规则4.令一条核心路由目的IP前缀为PFXdst,若PFXdst归属某单元前缀PFXunit(i),即叶子节点对应的路由数都不大于12.5.图4(a)中,虚框内节点01分解后,所有路由都被节点011继承,此次分解没有意义.所以,可对图4(a)中虚框内结点压缩为一个节点,压缩后的分解树如图4(b)所示.分解树生成后,根据路由均分原则将单元前缀归属到各线卡.如表1,各线卡分得路由数分别为25,25,24,26.表中每个叶子节点对应一个单元前缀,如节点00000对应PFXunit:0.0.0.0/5,节点10对应PFXunit:128.0.0.0/2.PFXdstPFXunit(i),则对应转发项存储在PFXunit(i)所属的线卡;若PFXdst不归属任何PFXunit,则对应转发项存储在PFXdst对应子树的单元前缀所属线卡.以图4及表1进行说明.若一条路由前缀为33.0.0.0/8,它归属节点001对应的单元前缀32.0.0.0/3,该单元前缀分配给了LC0,所以将该路由存储在LC0.若一条路由前缀为128.0.0.0/1,不归属任一单元前缀,而对应非叶子节点1.以节点1为根的子树有3个叶子结点,其单元前缀分别属于LC2和LC3.所以,前缀为128.0.0.0/1的路由项存储在LC2和LC3.现实互联网中,没有前缀长度小于8的路由.所以,只有当分解树的深度达到9以上时,真实路由的IP前缀才可能出现在分解树的非叶子节点上,此时出现真实路由的冗余存储.而一般情况,EDSF分解树的深度很难达到9以上.所以,EDSF模型出现真实路由在多块线卡存储的概率很小.真实路由分解存储后,如3.2节描述思想,系统根据单元前缀产生虚拟路由并存储.对任一单元前缀PFXunit(i),若其被分配给第j块线卡,系统增加一条IP前缀为单元前缀的虚拟路由:〈PFXunit(i),j,Inv,Inv〉(Inv表示一个无效值)并通告该路由给Page8除LCj外的所有线卡存储.下面给出EDSF模型相关算法.算法3用于EDSF模型分解树生成,是一个递归算法.参数SETrt表示本次待分解的路由集合,参数i表示依据第i个bit位进行分解.首次调用中,参数SETrt是所有路由项的集合,i等于1.只要分得的SEG0容量大于m/2n,就对SEG0进行分解,之后再回朔分解SEG1,分解过程是深度优先进行.另外,可以对单脉相传的节点进行压缩.即一次分解后所有的路由项都由某一子节点继承,则该次分解无需进行,并根据下一bit位进行分解.算法4描述了系统真实路由项的存储方法.若目的IP前缀PFXdst归属某单元前缀PFXunit(i),则该路由项只存储在一块线卡:PFXunit(i)所属的线卡,算法会跳出内层循环.否则,该路由存储在PFXdst对应子树所有叶子节点的单元前缀所属线卡.算法会遍历所有单元前缀,只要满足PFXunitPFXdst,就把路由存储到该单元前缀所属线卡.算法5实现虚拟路由存储.依次对每一PFXunit,以其为目的IP前缀生成虚拟路由,虚拟路由的出线卡是该单元前缀所属线卡,出接口和下一跳为无效值.该虚路由存储在PFXunit所属线卡之外的其它线卡.算法3.Distribute-Tree(SETrt,i).1.SEG0issubsetofSETrt,satisfiedwith2.SEG1issubsetofSETrt,satisfiedwith3.if(|SEG0|>m/2n)Distribute-Tree(SEG0,i+1);4.if(|SEG1|>m/2n)Distribute-Tree(SEG1,i+1);5.return;算法4.Hand-Actual-RT.1.for(i=1;i<=m;i++)2.getPFXdstofRTi;3.for(j=1;j<=|PFXunit|;i++)4.ifPFXdstPFXunit[j]5.gettheLCPFXunit[j]belongsto;6.RTiisstoredinthisLC;7.break;8.ifPFXunit[j]PFXdst9.gettheLCPFXunit[j]belongsto;10.RTiisstoredinthisLC;11.return;算法5.Hand-Virtual-RT.1.for(i=1;i<=|PFXunit|;i++)2.LCjistheLCPFXunit[i]belongsto;3.constructvirtual_rt:〈“PFXunit(i),LCj,Inv,Inv”〉;4.sendvirtual_rttoallLCexceptLCj;5.return;算法实施在主控板完成,各线卡只需对主控引擎发来的转发项进行存储即可.EDSF模型完成转发项分解存储后,报文转发过程与DSF模型相同.所以,EDSF模型的线卡功能设计与DSF模型完全一样,图2所示.EDSF模型中,每一单元前缀生成一条虚拟路由,而每条虚拟存储在(n-1)块线卡.所以,系统总共存储虚拟路由数为(n-1)×|Sunit|.虚拟路由数与线卡数量或单元前缀数成正比关系.而对于单元前缀个数,在线卡数一定的情况下,与真实路由数量及路由IP前缀分布是否均匀相关.路由IP前缀分布得越均匀,需要的单元前缀越少;而真实路由越多,则需要的单元前缀越多.EDSF模型虚拟路由数比DSF模型略有增加,但基本维持一个数量级,参见表2、表3实际路由表分析.6实验分析实验系统利用5台安装Linux操作系统的PC机完成.交换机模拟路由器内部交换网络,PC0-3模拟4块线卡,PC4模拟主控.主控主要负责管理路由表及向线卡分发路由.这样,1块主控及4块线卡构成一台可扩展分布式路由系统.PC0-3都安装两块以太网卡,Eth0用于联接内部网络,Eth1用于路由器系统的外部通信.各线卡利用CLICK[10]模块仿真路由器转发引擎.CLICK现有功能可支持传统FBS模型,而按图2功能整改又可支持DSF模型和EDSF模型.线卡可支持几种模型的功能切换.我们获取了真实路由表对各种存储模型进行分析.Data1①和Data2②分别是CERNET和AS65000真实运营中的路由表.在主控上分别注入Data1和Data2路由表,再查看各线卡转发表存储情况.实验分别基于4种转发存储模型进行,实验结果如图5、图6所示.其中,SPAL模型面向Data1最优选择第10及第13位进行分解,面向Data2最优选择第14及第15位进行分解.我们对数据的进一步整理分析为表2和表3.可以看出,相对传统的FBS模型,无论线卡数量多少或者不同的路由表,DSF模型和EDSF模型都能①②Page9大量减少系统转发项数量.DSF模型中,虽然实现转发项分解存储,但各线卡存储的转发项数量差异非常大.同时,EDSF模型却能实现将路由非常平均地分解存储在各块线卡.DSF模型和EDSF模型增加的虚拟路由数量都很小,EDSF较之DSF,虚拟路由增加略多.相对SPAL,EDSF模型分解更为平均,带来的额外存储也更少,即最后存储的路由总数更少.表2基于Data1(CERNET路由表)的不同模型存储分析每线卡最多FBS530185301815905400212072DSF2973844850122525353030EDSF133471309304525453063SPAL136541293366072153084表3基于Data2(AS65000路由表)的不同模型存储分析每线卡最多FBS22443522443567330500897740DSF1103702417801286192224447EDSF57105554480391657224474SPAL5769955709265101990227086上述DSF/EDSF分解过程中,没有出现某条路由目的前缀是聚集前缀的情况,所以不存在真实路由的冗余存储.整个分解存储过程中,DSF/EDSF模型只增加了少量的虚拟路由,并且不存在一条真实路由的冗余存储,具有很好的存储性能.从线卡路由数最大差值和路由存储总数两方面分析,显然EDSF模型具有最好的存储性能.最后,我们将仿真路由器的外部接口与普通PC相连,验证DSF/EDSF模型能根据灌入路由进行正常报文转发.7总结本文设计的转发表分解存储模型以IP前缀的前若干bit位进行分解存储,实现线卡对FIB表的分解存储.该模型在各线卡增加少量虚拟路由与真实路由项共存于一个转发表.线卡转发引擎的LPM查询集成了对虚拟路由和真实路由项的查找,既可实现转发下一跳查询,又可实现报文到转发子表的对应.DSF模型大大降低了系统总共存储转发条目及各线卡存储转发条目,节省了硬件资源及电能开销.而且,本文还针对真实网络中路由IP前缀分布不均衡特征,设计了改进方案EDSF,它使各线卡存储的转发项数非常均衡.与现有SPAL技术比较,在路由存储的均衡度及冗余率方面都有了进一步的改进及提高.根据对当前正在运营的两个路由器路由表数据进行分析,证明了本文分解存储方法的优越性.而且,无论DSF模型或EDSF模型,都有较强兼容性,只需在现有商业路由器上做极小的改动即可实现.所以,该方法可快速进入产业化进程,具有很好的现实意义.对于线卡数量更多的可扩展路由器,本文的分解存储方法尤为适合.致谢本论文工作在清华大学完成,感谢清华大学网络研究所的支持!
