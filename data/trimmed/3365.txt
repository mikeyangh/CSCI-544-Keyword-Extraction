Page1求解组合优化问题伊藤算法的收敛性和期望收敛速度分析董文永1),2)张文生2)于瑞国3)1)(武汉大学计算机学院武汉430079)2)(中国科学院自动化研究所北京100086)3)(天津大学计算机学院天津210000)摘要文中作者主要针对一类组合优化问题,分析了伊藤算法的收敛性理论和达到最优解的期望运行时间.首先将研究的组合优化问题转化为图模型,在图模型的基础上研究了伊藤算法的各种算子设计方法,阐明了伊藤算法的漂移算子、波动算子的寻优过程,给出了几种算子转移所服从的概率分布;然后在转移概率的基础上,利用离散鞅的极限分布给出了伊藤算法几乎必然收敛行为分析;最后研究了1个粒子的情况下,伊藤算法达到最优解的期望运行时间的上界,其取决于粒子半径的设置,并结合具体的参数设置,分析了伊藤算法参数选择的重要性.关键词伊藤算法;收敛性分析;运行时分析;波动算子;漂移算子1引言近些年来,一些基于迭代过程的仿生优化算法相继出现[1],如遗传算法、蚁群算法、微粒群算法、人工免疫算法、人工鱼群算法、混合蛙跳算法等,为组合优化问题提供了切实可行的解决方案.由于这些方法在实践的过程中是一种通用的优化器,普遍存在通用与效率的矛盾、探索与开发的矛盾、效率与精度的矛盾等.为了解决这些矛盾,许多学者提出了各种各样的改进版本[1-4],这些改进主要包括:各种元启发式算法的结合;参数的动态自适应;融合统计理论提出新的算法;算法的算子的改进等[5-7].其中最常用的是前两种改进方法,参数自适应的方法的基本思路是在算法搜索的过程中不断根据获取的新的信息来修正算法中的参数,这类算法主要包括OGA/Q、MMAS、ASrank、ASe等[8-16];混合算法的基本思路是将不同的算法结合在一起,构成新的自适应算法GLS-FLS-2opt、stGA、Tabu-SA、HybridACS、HybridSA等[17-20],由于这种结合方式属于不同算法的简单组合,因此作者称其为松散耦合方式.从大量的文献可以看出,不同算法的融合以及参数自适应是当前元启发式算法的研究趋势,急需一种新型的计算模型和理论作为支撑,基于此,Dong和Li首创提出了一类新的演化算法,称为伊藤算法(ItoAlgorithm,ITO).ITO算法已在求解组合优化、函数优化、系统辨识、时间序列建模等问题时取得了很好的效果[1-4].伊藤算法主要是基于随机过程中的伊藤过程,模仿粒子系统中粒子相互碰撞与作用的动力学规律进行算法设计和问题求解.是从微观的角度来分析粒子的运动规律,然后通过抽象及模拟的方法提出的新算法.伊藤算法一方面体现了仿生演化算法群体搜索的特征,解的表示(编码)被看成是一个粒子,大量的粒子组成粒子系统,是伊藤算法处理的对象;另一方面又运用了伊藤过程的理论来分析算法,利用伊藤随机积分的方法建立算法的动力学方程,并根据爱因斯坦、朗之万等人提出的大分子运动规律来设计伊藤算法的两个关键算子:漂移率和波动率,结合粒子热运动规律,使之具有模拟退火的一些特征,伊藤算法也因此而得名.元启发式算法的理论分析主要涉及到收敛性理论和收敛速度估计两个方面,收敛性理论的分析比较成熟,但收敛性速度的分析相关文献较少.关于伊藤算法的收敛性和平均达到最优解的期望时间分析尚未在文献中见到,因此本文主要研究求解一类组合优化问题时伊藤算法在这两方面的行为.目前,对于收敛性分析方面主要有以下几种方法:一种是将算法的迭代过程映射为Markov链,然后采用Markov链来分析算法的极限行为[21];一种是将算法迭代过程中产生的最优解所形成的序列映射为离散鞅,采用离散鞅来分析算法的行为[21-22];还有的是结合算法的特点来进行分析,比如遗传算法有模式定理、Vose-Leipins模型分析、整体随机搜索模型分析等[21-22];蚁群算法有基于图的蚁群系统收敛性分析等[23-25].运行时方面的文献比较少,目前主要有针对(1+1)EAs[24]、1-ANT[23,25]、(1+1)MMAS[26-27]等算法的运行时分析.这些文献[23-29]中的运行时分析主要针对One-Max、Needle-in-a-Haystack、Leading-Ones、特殊TSP问题等进行分析.受这些文献的启发,本文的主要工作就是研究伊藤算法在这两方面的行为,许多结论均借鉴这些文献.本文第2节主要介绍一类组合优化问题及其向图模型转换的方法,解空间划分的方法;第3节我们主要讨论求解该类组合优化问题的伊藤算法的设计,包括按照概率构造解、漂移和波动的实现、粒子半径的设计等;为了验证算法的性能,我们将在第4节中针对TSP问题利用ITO算法进行求解;第5节利用离散鞅的相关极限行为分析伊藤算法的收敛性;第6节是主要分析第2节中提出的组合优化问题的图模型来分析单个粒子达到最优解的期望运行时间;最后是论文的结论和将来要研究的工作.2一类组合优化问题及其向图模型的转换组合优化问题的种类非常多,其中许多属于NP完全问题,下面我们主要考虑如下一类组合优化问题的模型,并研究这些问题向图模型的转换方法,以便能够在统一的框架内讨论伊藤算法的相关理论.考虑一个最大化问题(S,f,Ω),其中S为候选解的集合,f为目标函数,对于任意一个候选解s∈S都对应着一个目标函数值f(s,t),Ω(t)为约束条件的集合.参数t表示目标函数和问题的约束都与时间有关.问题的目标就是要找到一个全局最优的可行解s,使得f(s)最大.论文中我们主要研究下面描述的静态无约束组合优化问题:(1)解空间中的所有解可以采用固定长度的编码,即每一个解可以表示为狓={x1,x2,…,xn},其Page3中n<+是编码的长度.(2)状态空间可以表示为C=C1×C2×…×Cn,其中C1,C2,…,Cn中的元素个数为n1,n2,…,nn.上述的组合优化问题可以通过如下的方法来构造其相应的2n+1段有向图模型:第1段有一个初始的结点c(0)2,c(2)结点,分别表示C1中的点,我们用c(1)来表示这些点,第3段包含一个结点,我们用c(0)表示;第4段包括n1个结点,分别表示C2中的点,我们用c(1)个结点,我们用c(0)含ni个结点,分别表示Ci中的点,我们用c(1)i来表示这些点,第2i+1段包含一个结点,我们c(ni)i来表示.每一段中的结点到后一段的所有结用c(0)点均有一条有向边.这样的有向图从起点c(0)点c(0)上述组合优化问题的一个可行解{c(i1)n},该路径的函数值就是可行解{c(i1)c(in)n}所对应的函数值.按照上述构造有向图的方c(in)法,n=4的伪逻辑函数(Pseudo-BooleanFunctions)的图模型如图1所示[23].n的每一条路径c(0)对于上述的组合优化问题,我们引入划分的概念,见定义1.定义1.对于任意的组合优化问题,假设解空间的函数值按照从小到大的顺序排列f1<f2<…<fM,把解空间C划分成M个不相交集Ω1,Ω2,…,ΩM,其中任意集合Ωi≡{x|f(x)=fi,x∈C},则称Ω1,Ω2,…,ΩM是解空间C的一个划分.从这一种划分上可以看出,最优解必然位于集合ΩM,且最优值为fM[23].对于上述的图模型,我们采用如下所述的路径构造方法来生成一个可行解:对于图上所有形如{〈c(0)n-1,k=1,2,…,ni+1}的边,我们为这样的边上附上选择概率Pc(0)算法的波动算子和漂移算子来确定,详细内容参见论文的第3节,其中需要保证∑ni+1形如{〈c(k)ni+1}的边,我们为这样的边上附上选择概率1,然后按照该概率值采用轮盘赌的方法为路径选择下一个结点.具体地,路径的初始结点σ(0)=c(0)结点σ(2n+1)=c(0)进行选择.3求解TSP问题的伊藤算法3.1算法思想及流程介绍维纳过程是对粒子系统无规则运动的描述,伊藤过程是带趋势项的维纳过程,如果粒子系统所在的空间映射为优化问题的搜索空间,每个粒子按照伊藤公式定义的运动规律来运动,自然就会得到一个新的优化算法.把伊藤随机过程映射为优化算法,我们需要解决两个关键问题:一个是如何设计波动过程,使得每个粒子能在局部的空间内进行搜索;另一个是如何设计伊藤过程的宏观趋势项,使得算法在宏观上朝着最优解的方向前进.根据伊藤积分公式,我们可以将飘移过程理解为公式第一项,即所有的解都应该朝着当前吸引元移动,以期提高自己的评估值.伊藤方程中的漂移就可以映射到粒子的向优性上.这样一种运动是具有确定性的,即有确定的方向和速率.而粒子除了朝当前最优解移动之外,还应该随机地在自己的周围进行波动,从而达到两个目的:精细化搜索和跳出局部最优解.伊藤方程的波动就可以映射到粒子的随机性上,伊藤算法就是受此启发而被提出的.伊藤算法主要是针对优化问题提出来的一种全新的基于种群的算法,和其它的智能启发式算法一样,我们需要详细设计有关算子.伊藤算法的算子有两个:飘移和波动,其中波动类似于遗传算法的变异,飘移类似于遗传算法的杂交,但两个算子和遗传算法的两个算子有很大的不同.由于伊藤算法是受到粒子的热运动的启发而提出来的,我们有必要考虑粒子热运动所具有的规律,从而设计出高效、自适应的算子.伊藤算法的提出首先是从粒子的布朗运动得到启发的,即算法的求解过程与粒子的运动是相似的.在物理学中,粒子布朗运动的剧烈程度是跟粒子半径和温度相关的,即布朗运动的剧烈程度与半径反相关,与温度正相关.可以将这个物理原理映射到本算法的求解当中,搜索解空间的每一个粒子都会有一个半径属性,但是这个半径属性不像物理世界中的半径是恒定的,算法中粒子的半径是会根据粒子的当前状态动态地变化,从而Page4影响了粒子漂移和波动的剧烈程度,这就是本算法自适应的特点所在.根据爱因斯坦和朗之万的大分子巨系统的公式,当粒子距离中心越近,漂移就越缓慢,当粒子距离中心较远的时候,漂移就较迅速.伊藤算法的框架如下:Initialize:采用某种策略初始化N个粒子的种群,并设While(terminationconditionnotmet)do1.寻找种群中的最好粒子和最差粒子;2.为每一个粒子选择飘移算子的吸引点(或者叫吸引3.计算退火温度,每个粒子的半径、漂移率和波动率;4.每个粒子按照设定飘移算子进行移动,如果新的位5.每个粒子按照设定波动算子运动到新的位置,如果END.每一个粒子在飘移时,都需要飘移算子有一个吸引的中心,如何选取飘移中心取决于问题的类型,对于最大化问题,一般会选取当前种群中若干个目标函数值比较大的粒子作为吸引的中心;对于最小化问题,一般会选取目标函数值比较小的几个粒子作为吸引的中心;同时为了防止所有粒子集中到一起,可以引入小生境技术、对每一个吸引的中心加上拥挤因子从而保持种群的多样性,这种策略被称为全局漂移策略(globalexcursionstrategy).吸引子同样可以是每一个粒子在移动的过程中形成的抽样路径上的最优解,这样的处理基本上可以保持种群的多样性,这种策略被称为局部飘移策略(localexcursionstrategy).飘移算子和波动算子均依赖于粒子的半径和当前所处环境的温度,这一点和液面上花粉的运动规律一致.因此如何设计与函数值相关的粒子半径,如何设置温度的退火表,将影响到算法的性能.如果种群中只有一个粒子存在,则伊藤算法的飘移算子只能够采用局部飘移策略,这一点伊藤算法从一定意义上而言变成了局部爬山法.对于组合优化问题,我们将漂移和波动两种运动分开来,这样更便于算法的设计.漂移和波动算子的设计一般取决于具体的问题,下面针对上述的图模型,详细讨论算法中的几个关键点,包括粒子半径定义、粒子波动算子和粒子飘移算子.3.2粒子半径设计将半径的设计与布朗运动中运动规律结合起来,按照爱因斯坦和朗之万的公式,我们可以看出半径越大的粒子运动能力越小,半径越小的粒子运动越剧烈.因此,映射到算法当中就是要遵从以下原则:种群中的每一个粒子对应于约束空间中的一个可行解,对于极小化问题,函数值较差的粒子半径小,这样它就会大范围的运动,以达到快速搜索的目的.适应值较好的粒子半径大,这样它的运动幅度就不会特别大,于是它就会小范围地搜索更精确的解.反之,对于极大化问题,函数值越大的粒子其半径越大,函数值越小的粒子其半径越小.为了便于算法的处理,一般我们假设粒子的半径在[rmin,rmax]之间,rmin,rmax∈R且rmin<rmax.因此粒子的半径可以用如下函数表示:其中f(x)为可行解的函数值,g:R→[rmin,rmax],对于极大化问题,g为单调递增函数,对于极小化问题,g为单调递减函数.目前,有很多函数都可以用来设计粒子的半径,例如线性变换函数和指数函数等,具体设计方案参见文献[2],这里我们主要介绍基于排序的粒子半径计算方法.其计算步骤如下:{n1,n2,…,nn};对种群中的n个粒子按照目标函数值进行排序按照如下公式计算每个粒子的半径:基于排序的方法生成的粒子半径平均分布在[rmin,rmax]之间,而不考虑各个粒子的目标函数值,这种方法使得算法在后期也有很强的搜索能力,从而更加适合目标函数比较复杂的情形.为了简化飘移算子和波动算子的设计,我们通常取rmin=0,rmax=1,此时的粒子半径可以简化为由于算法中每一代的粒子的半径可能不一样,因此我们用r(t)3.3波动算子设计波动算子主要完成粒子在自己的领域内局部扰动,由两部分构成:一个是漂移强度,也即飘移的系数γ;一个是飘移的过程,即如何按照波动强度完成在领域内的波动.波动系数γ与粒子自身的半径、当前的环境温度等因素有关.为了简化起见,我们假设函数γ=f(r,T)是可分离变量的,即波动的速率是由粒子的当前半径r函数和当前温度T的函数共同决定的:f(r,T)=γmin+f1(r)·f2(T)·(γmax-γmin),其中γmax,γmin分别表示粒子的最大波动强度和最小波动强度,一般取γmax=1-γmin;f1为粒子半径决Page5定的漂移强度,一种可行的实现方案为f1(r)=(e-λr-e-λrmax)/(e-λrmin-e-λrmax).函数f2(T)表示粒子受环境温度的影响而表现出的活动强度,一种可能设计是类似于模拟退火算法中Metropolis准则所采用的函数,其结构如下:其中,T是当前的环境温度.波动过程可以描述如下:有了波动强度,粒子按照该波动强度进行波动,假设粒子代表的路径为σ,从上述的图模型可以看出,路径上所有的,然后按照如下的概率按照第2节中的方法构造出一条新的路径:其中,α是设定参数,τ(c(0)τ(c(0)在这个概率选择规则下,当α=1时,∑ji+1)]α=1,则Pc(0)c(j)3.4漂移算子设计飘移算子主要实现粒子朝着吸引元的方向前进,由两部分构成:一个是漂移强度,也即飘移的系数μ;一个是飘移的过程,即如何按照漂移强度完成在领域内的漂移.飘移系数μ同样与粒子自身的半径、当前的环境温度等因素有关.为了简化起见,漂移强度的计算方法和波动强度一样.漂移过程主要是按照概率来构造路径,〈c(0)法如下:假设当前粒子的路径为σ,为其选择的吸引元的路径为σ.在漂移算子生成新的路径的时候,有以下两种情况:σ∧〈c(0)τ(c(0)(1)如果存在城市〈c(0)i,c(k)i,c(k)(2)如果k1∈Ni∧k2∈Ni∧k1≠k2,使得i+1〉∈σ∧〈c(0)〈c(0)i,c(k1)假设在迭代到某一代最优解σ已经出现,第i个粒子σi所对应的漂移强度是μi,采用漂移算子的生成路径的规则,则第i个粒子生成最优解的概率为生成自身的概率为其中h(σi,σ)表示路径σi和σ形如〈c(0)边的个数.按照漂移算子,p(σ→σ)=1,这一点说明漂移算子具有保持最优解的能力,但是漂移算子不是全局收敛性算子,每一个粒子的漂移都是在该粒子和吸引元构成的局部区域内进行,因此具有局部爬山的能力.4求解TSP问题的实验性研究伊藤算法作为元启发式算法中的一元,为了得到算法的实验性能,我们主要对比如下一些求解TSP问题的元启发式算法:MMAS、ACS、AS、DPX-GA和PSO算法.AS是第一个用于求解TSP问题的ACO(AntColonyOptimization)算法;MMAS是对AS算法的改进,通过限制每一条边信息素的最大值和最小值从而使得AS算法具有全局收敛性;ACS同样也是AS算法的改进版本,在ACS算法中只有最优解对应的路径增加信息素;DPX-GA是采用DPX杂交策略的GA算法,并被应用于TSP问题的求解;PSO主要是解决连续系统优化问题的算法,随后被扩展到组合优化问题中.这些算法中MMAS、ACS、AS实验的结果数据来自文献[30],DPX-GA的实验数据来自文献[31],PSO算法和本文的算法由我们编程实现,其中这两类算法的参数设置如下:PSO算法的参数:种群规模和实例规模一致;局部学习率c1=0.8,全局学习率c2=0.6,将连续变量利用log函数转换到[0,1]之间,然后按照概率进行基因位的反转;停机条件为连续20代算法没有改进就停机.ITO算法的参数:粒子的个数和问题实例的大小一致,停机条件为连续20代算法没有改进就停机,计算粒子半径的方法为线性变换法,pmin=0.005,pmax=0.8.表1为不同算法的对比实验,每种算法均采用多次运行结果的平均值作为算法对比的依据,其中PSO和ITOges算法是我们编程实现,两个算法的每一个计算实例均独立运行30次.黑体字对应的计算结果是几种算法的最好解.从表1中可以看出,ITO算法针对4个不同规模的TSP问题的计算均胜出.Page6DPX-GA算法是除ITO算法之外的优秀算法,但和ITO相比,针对实例Eil51和Lin318的计算效果要差于ITO算法.从表中我们还可以看出,PSO算法的求解性能最差,其次是ACS和AS.作为一种通用的算法,ITO算法的计算性能具有一定的竞争性,算法性能的改进值得进一步的研究.MMAS427.621320.315972.542029.0ACS428.121420.016054.0AS437.322471.416702.1DPX-GA428.52128515839.542605.3PSO498.221993.516049.749385.1ITO426.92128515839.542029.05收敛性分析从算法的描述上来看,伊藤算法的每一个粒子都按照自身的运动规律进行运动,为了分析算法的收敛性,我们可以独立分析每一个粒子的运动规律,从而组合成整个算法的性能.首先我们引入一些证明过程中用到的符号.CN=(x1,x2,…,xN),i,xi∈C表示种群中的第t次迭代时种群最大适应值为粒子,N表示种群规模.第t次迭代时种群平均适应值为G={xy∈C,f(y)f(x)}.伊藤算法的每一个粒子的运动规律基本一致,主要区别是每一步的转移概率不一样,整个算法的行为特征可以通过分析单个粒子的运动规律得到,下面我们首先定义伊藤算法的几种常见的收敛性定义.定义2.伊藤算法{X(t),t=1,2,3,…}被称为依概率弱收敛到全局最优解,如果limx→P(犡(t)∩G≠)=1,简记为犡(t)w.p.→1G.定义3.伊藤算法{X(t),t=1,2,3,…}被称为依概率强收敛到全局最优解,如果limx→P(犡(t)G)=1,简记为犡(t)s.p.→1G.定义4.伊藤算法{X(t),t=1,2,3,…}被称为几乎必然弱收敛到全局最优解,如果P(limt→犡(t)∩G≠)=1,简记为犡(t)w.a.→sG.定义5.伊藤算法{X(t),t=1,2,3,…}被称为几乎必然强收敛到全局最优解,如果P(limx→犡(t)G)=1,简记为犡(t)s.a.→sG.根据上述4种收敛性的定义,可以看出几乎必然收敛强于依概率收敛,本文将证明伊藤算法的几乎必然强收敛性.从伊藤算法的流程上来看,伊藤算法的第t代种群只取决于第t-1代种群,而与过去时刻的其它种群没有关系,并且每一代种群的转换概率互不相同,因此伊藤算法的行为是一个非齐时Markov链{Xt,t=1,2,…},确切的讲,这样的非齐时Markov链从Xt向Xt+1的转换过程中经历了5个步骤:下面我们针对这5步来解释每一种算子的转移概率.(1)第2步是漂移算子,漂移算子是从C2到C的随机算子,从算子的定义来看,给定任意一种状态,该算子并不见得可达,主要取决于该状态是否在粒子和其相应吸引元张成的空间上.针对第二部分定义的图模型,有如下的转移概率:M(i×j,k)=P(t)我们用Ωi×j表示利用漂移算子所能够生成的新的解空间,则有Ωi×jC,同时P(t)M(i×j,C-Ωi×j)=0.P(t)种群的漂移概率为M(犢(t)=狔犝(t)=狌)=P(t)漂移算子的主要作用是加快粒子的改进,根据文献[2]的分析,如果求解的问题具有良好的领域结构,则漂移算子生成改进粒子的概率就比较大.但该算子不具有全局可达性,对算法收敛性的意义不大,仅仅是加速改进算子.(2)第3步和第5步的选择算子所起的作用是一样的,即只有新的粒子改进了,才会被选择,而且选择的方法与迭代的过程无关,因此有如下概率:种群第3步的转移概率为Page7PS(犣(t)=狕犢(t)=狔)=∏k种群第5步的转移概率为PS(犡(t+1)=狓犠(t)=狑)=∏k(3)第4步是波动算子,波动算子从C到C的随机算子,从算子的定义来看,如果漂移的强度不为零,则给定任意一种状态,该算子均可达.W(i,j)=P(t)(1-γi)h(i,j)·∏k,〈c(0)其中h(i,j)表示i和j两条路径中所有形如{〈c(0)i+1〉,i=0,1,2,…,n-1,k=1,2,…,ni+1}的边相c(k)同的个数.我们可以推出波动算子的最小转移概率:整个种群的转移概率为W(犠(t)=狑犣(t)=狕)=∏kP(t)(4)第1步是选取吸引元算子,吸引元是对粒子具有吸引力的粒子,如果采取种群中的最优解作为吸引元,则该算子可以描述为P(t)种群中的选择吸引元的概率可以描述为A(犝(t)=狌犡(t)=狓)=∏kP(t)基于上述分析,非齐时Markov链{Xt,t=1,2,…}的转移概率为P(犡(t+1)=狓犡(t)=狓)=∑(狌我们引入以下向量犉(狓)≡(f(狓(1)),f(狓(2)),…,f(狓(N)))T,则有如果犉(狓)犉(狓),则否则,P(犡(t+1)=狓犡(t)=狓)=0.对于单个粒子而言,我们有狓∈C,有E(f(犡(t+1))犡(t)=狓)=同时由于每一个粒子均具有这样的特征,因此,我们有如下结论:同时,由于伊藤算法迭代过程中具有马氏性,因此有E(f-(犡(t+1))犡(1),犡(2),…,犡(t))=综合上面的分析,我们可以得到如下结论.引理1.伊藤过程迭代过程中形成的随机过程{f-(犡(t)),t=1,2,…}为非负有界下鞅,且有极限π存在.引理2.针对上述的图模型,种群中的每一个粒子具有下述结论,x∈Ωk,k<M,证明.根据伊藤算法粒子的转移概率,由于x∈Ωk,所以一旦转移出去,必然朝着Ωj,j>k的方向转移,并且再也不会返回到Ωk.因此有P(犡(t)∈Ωk犡(0)=狓)=∏t由于γmax<1,所以有同时limt→P(犡(t)Ωk犡(0)=狓)=1也成立.引理3.伊藤过程迭代过程中形成的随机过程{f-(犡(t)),t=1,2,…}的极限π有π=fM(a.s).证明.由于limt→P(f-(犡(t)))=π,所以对于任意一个粒子而言均有limt→P(f(犡(t)))=π,下面我们主要分析一个粒子的极限.如果π≠fM,说明x∈Ωπ,limt→P(犡(t)∈Ωπ犡(0)=x)=1,与定理2的结论矛盾,因此必然有π=fM(a.s).6运行时分析6.1运行时的一般性引理针对上述的图模型,伊藤算法群体的行为可以Page8通过单个粒子的行为分析来得到,这里我们将种群规模设置为1,得到的结论同样适合于任意规模的情况.在这种情况下,由于选取的吸引元就是自己,波动算子产生的个体是自己的概率为1,因此算法迭代的过程其实仅仅取决于波动算子.算法的转移过程可以简化为一步转移概率可以简写为P(犡(t+1)=狓犡(t)=狓)=∑狑根据波动算子的定义,只有目标函数值优于自己的个体才能够取代自己,否则转移后的个体仍然是自己.下面我们研究如下概率:P(犡(t+1)∈Ωk犡(t)=狓∈Ωk)=P(犡(t+1)=狓犡(t)=狓)同样有t=1P(犡(t+1)Ωk犡(t)=狓∈Ωk)=1-(1-rmax)n.下面给出运行时的一般性定义.定义6.给定一种初始状态x∈Ωk,k=1,2,…,M,我们定义从状态x∈Ωk出发,算法首次到达最优解ΩM的期望时间为x→ΩM)=E(TΩk∑t·P(Xt∈ΩM,XsΩM,1s<t/X0=x),可见该变量是个随机变量,那么运行时则定义任意状态下到达最优解的期望时间,即E(TM)=∑2,…,M,单个粒子的伊藤算法均有E(TΩkE(TΩk引理4.任意给定两个状态xi,xj∈Ωk,k=1,xj→Ω-证明.给定任意状态x∈Ωk,根据伊藤算法的转移矩阵,有E(TΩkx→Ω-=(1-(1-γmax)n)+2(1-(1-γmax)n)·(1-γmax)n+3(1-(1-γmax)n)·((1-γmax)n)2…=(1-(1-γmax)n)·∑=1/(1-(1-γmax)n).由于x的任意性,所以上述结论成立.证毕.引理5.给定一初始状态x∈Ωk,k<M,则E(TΩkx→ΩM)E(TΩkx→Ω-该引理的证明类似于文献[23,25]附录1中的证明方法,差别在于文献[23,25]中的每一种划分Ωk中的元素个数是可数无限个,我们定义的划分是有限个元素.引理6.给定一初始状态x∈Ωk,1k<M,则引理7.单个粒子的伊藤算法在求解图模型时有如下结论:E(TM)∑M-1引理6和引理7的证明参见附录1.6.2OneMax问题的上界分析OneMax问题的描述如下:f(x)=∑n该问题的最优解是xi=1(i=1,2,…,n),按照上述的适应值空间的划分有Ωi={x∈{0,1}n|f(x)=j-1},j=1,2,…,n+1.这种情况下,有M=n+1.根据引理7,我们可以得到如果γmax取值(0,1)之间的常量,则可以看出(1-(1-γmax)n)~1(n→),此时E(TM)=O(n);如果γmax=11/e(n→),此时有E(TM)=O(n).7结论本论文中我们研究了伊藤算法的收敛性和平均达到最优解的期望时间等问题.收敛性方面,我们证明了伊藤算法具有几乎处处强收敛的特点;运行时方面,我们针对图模型得到了伊藤算法期望运行时间的上界,并分析了参数设置对算法性能的影响.论文中我们还可以看出,来自EA和GA等算法分析中的相关理论可以映射到伊藤算法,从而丰富伊藤算法的收敛性理论.以后的研究工作主要包括:(1)如何进一步提高选择吸引元的效率,从而提高伊藤算法的总体性Page9能;(2)分析基于种群的ITO算法达到最优解的期望运行时间;(3)针对ITO算法如何构造欺骗性问题,从而研究哪些问题对伊藤算法而言是难解问题,哪些问题是易解问题.伊藤算法的理论分析是一门艺术,论文中研究的问题是针对图模型而言的,所得到的结论有一定的局限性,我们需要进一步比较伊藤算法和其它元启发式算法之间的联系,从而形成一整套具有说服力的理论体系.
