Page1基于关系矩阵融合的多媒体数据聚类张鸿1)吴飞2)张晓龙1)1)(武汉科技大学计算机科学与技术学院武汉430081)2)(浙江大学计算机科学与技术学院杭州310027)摘要针对目前多媒体聚类研究中如何挖掘和利用不同数据集之间统计关系的问题,提出一种基于关系矩阵融合的聚类方法,首先,对图像和音频数据集中提取的特征矩阵进行相关性分析和子空间映射,进而在全局范围内对图像相似度、音频相似度以及图像和音频的相关度进行融合与优化,最后,采用基于相似度的循环迭代算法进行图像和音频聚类.对比实验从多个角度验证了文中方法的有效性,并能较好地应用于多媒体交叉检索.关键词视听觉特征;关系矩阵;多媒体数据聚类;相关性融合;交叉检索1引言随着多媒体技术和信息技术的高速发展,Web页面上各种类型的多媒体数据(如图像、音频、视频)正迅速膨胀,同时,由于多媒体数据本身具有底层视听觉特征异构、高层语义丰富的特点[1],使得对Web多媒体数据的有效管理和智能利用十分困难.大量研究工作从数据存储、信息检索、知识挖掘等不同角度关注上述问题,其中,多媒体聚类研究通过机器学习、统计分析等方法,帮助理解多媒体数据集的潜在语义[2],该项研究主要以底层内容特征来表达Page2多媒体样本,学习样本向量在特征空间中的几何结构,从而分析潜在的语义关系,实现多媒体数据集的聚类.传统的多媒体聚类研究大多是针对单一类型的多媒体数据,如图像聚类[3-4]、音频聚类[5]等.近年来,随着Web多媒体数据类型的不断丰富,越来越多的研究者开始关注包括图像、音频等的多媒体数据综合处理和聚类问题;本文的前期工作和相关研究已证明:由于图像、音频等不同类型的多媒体数据可以从视觉、听觉的不同侧面表达相似的语义,视听觉信息彼此具有互补性,这种互补性可用于提高多媒体语义理解的准确率[6-10].本文在前期工作[6]的基础上,以Web页面上获取的图像和音频为训练数据,在特征降维过程中分析了两者间的统计相关性;并在特征子空间中利用图像和图像、图像和音频以及音频和音频之间的多重数据关系进行相关性融合,挖掘潜在的相似语义,并修正相似度矩阵;最后通过基于相似度的循环迭代算法实现图像和音频聚类.对比实验从多方面验证了本文方法的有效性,实验还表明本文方法可成功应用于多媒体检索,实现图像和音频之间的交叉检索.2基于核矩阵的子空间映射特征降维是对多媒体数据向量化表示的重要步骤,也是多媒体内容分析和聚类的前提.传统的方法通常是针对训练样本集提取出的高维特征矩阵进行矩阵分解,并通过线性变换实现维数约减.图像对应非时序性的视觉特征,音频对应时序性的听觉特征,虽然针对两种特征目前都已提出了不同的降维方法[11-12],但很少有研究关注如何对视觉特征矩阵和听觉特征矩阵统一分析和降维,并计算视听觉特征间的潜在相关性.视觉特征从颜色、纹理、形状等层面描述了图像的视觉属性;音频特征从频域、压缩域等方面描述音频数据的听觉属性.因此,给定n幅图像和n段音频组成的图像-音频数据库,设视觉特征包括j个属性值,即构成j维向量,听觉特征构成k维向量,则特征提取后得到n×j维的视觉特征矩阵犃和n×k维的听觉特征矩阵犅.在前期研究中提出的基于CCA(CanonicalCorrelationAnalysis)的相关性保持映射基础上[6],引入核矩阵方法,提出基于KCCA(KernelCanonicalCorrelationAnalysis)的同构子空间映射.首先,通过非线性映射Φ(犃),Ψ(犅)将视觉特征向量和听觉特征向量映射到核空间,并在此空间中采用传统的CCA方法计算相关性保持映射的投影向量犠犃=∑αiΦ(ai)=Φ(犃)α,W犅=∑βiΨ(bi)=Ψ(犅)β,其中α=[α1,…,αn]T,β=[β1,…,βn]T表示组合系数;其次,与CCA方法类似,得出目标函数max[αTΦ(犃)TΦ(犃)Ψ(犅)TΨ(犅)β],其最优解即为能最大程度保持相关性的投影子空间;引入核矩阵犓a,犓b∈Rn×n,其中(犓a)ij=Φ(ai)TΦ(aj),且(犓b)ij=Ψ(bi)TΨ(bj),则可以将目标函数简化为在约束条件αT犓a犓aα=1,βT犓b犓bβ=1下求解maxαT犓a犓bβ;最后,通过拉格朗日乘子法求解上述目标函数,得到组合系数αi,βi的值,从而,训练集中任意一个图像样本a在低维子空间S中的坐标为犠T犃Φ(a)=∑αiΦ(ai)TΦ(a)=∑αi犓a(ai,a),音频样本的坐标可以采用类似的方法计算得到.通过上述变换,将矩阵犃和矩阵犅转换为n×m(m<j,m<k)维的矩阵犃和犅.设向量狕i=(zi1,…,zim)表示S中的图像或音频样本点,用dij表示任意两个样本点狕i和狕j在S中的距离,进而得到所有样本点之间的距离矩阵犇2n×2n=[dij],归一化后表示为犇2n×2n=[dij](dij∈(0,1]),矩阵犇2n×2n体现了图像和音频在子空间S中的几何拓扑关系.3基于矩阵融合的相似度优化由于语义鸿沟的存在[13],矩阵犇2n×2n并不能真实地反映样本点在语义上的相似度,即:若样本狕i和狕j在矩阵犇2n×2n中对应的元素值较小,并不能说明两者在语义上是强相关的,反之亦然.针对上述问题,本节提出基于矩阵融合的优化算法,从全局意义上对图像和音频的相似度进行求精.图像和音频样本共同分布于子空间S中,这些样本点之间存在的相关性数据关系主要可分为4种,如图1所示.其中,实线表示子空间中两个样本之间距离较近,为强相关,虚线表示两个样本之间距离较远,为弱相关.这4种数据关系在子空间S中并不是孤立存在的,同时,不同类型的数据关系之间具有互补性和可传递性[6-7,9].对距离矩阵犇2n×2n=[dij]求取倒数,得到关系Page3图1子空间中图像和音频样本间的相互关系矩阵犕,定义如下:犕=犕II犕IA其中σ为常参数,子矩阵犕II,犕AA分别是图像相似度矩阵和音频相似度矩阵,子矩阵犕IA和犕AI是对称矩阵,表示图像和音频之间的相关程度.则任意两幅图像xi和xj之间的相似度对应子矩阵犕II中的元素值犕II(xi,xj),采用式(2)对犕II(xi,xj)进行优化:犕II(xi,xj)=λ犕II(xi,xj)+(1-λ)·式(2)的约束条件为犕IA(xi,yk)>ε1,犕IA(xj,yt)>ε2,犕AA(yk,yt)>ε3,且α,ε1,ε2,ε3∈(0,1)(3)式(2)中实参λ是权重参数,实参ε1,ε2,ε3用于控制音频样本yk和yt的选择,yk和yt是用于传递相似度的媒介,故参数ε1,ε2,ε3称为传递因子;犕IA(xi,yk)>ε1和犕IA(xj,yt)>ε2表示图像xi和音频yk以及图像xj和音频yt之间具有强相关性,如图1(b)~(d)所示;犕AA(yk,yt)>ε3要求音频样本yk和yt是强相关的,如图1(b)、(d)所示(其中图1(b)表示y1和y2是同一样本的特殊情况);符号∑表示对所有符合约束条件的音频yk和yt计算犕IA(xi,yk)犕IA(xj,yt)犕AA(yk,yt),对结果进行累加.实验中传递因子ε1的取值为ε1=12其中n为音频样本数量.传递因子ε2的计算与ε1类似;参数ε3依照式(4)从子矩阵犕AA计算得出.同理,式(2)可用于修正音频和音频样本之间的相似度犕AA,修正后的相似度矩阵记为犕II,犕AA.式(2)的计算结果更接近图像xi和xj在语义上的相似程度,这是因为:式(2)从多重数据关系的角度,综合分析了子空间中多媒体样本点间的相似度,将图像和音频以及音频和音频之间的相关性,融入到图像相似度的计算和优化.另外,从矩阵优化的角度而言,子矩阵犕II,犕AA,犕IA(犕AI)分别表示子空间中3种单一类型的多媒体数据关系,具有稀疏性,同时,这3种数据关系之间具有互补性和可传递性,式(2)将子矩阵犕AA,犕IA中潜在的互补信息融入到子矩阵犕II中,提高了矩阵犕II的密集度,也是对矩阵犕II所表达数据关系的优化.4聚类算法由于在矩阵融合过程中图像和音频在子空间S中的坐标未变,不能以坐标值为多媒体聚类的输入条件.并且,一些传统的聚类方法,如Kmeans聚类[3],在初始状态下需要指定聚类中心,而聚类中心的选择将会对结果造成较大影响.本文受到AP(AffinityPropagation)聚类算法[4]的启发,采用基于相似度的循环迭代方法进行聚类.AP算法利用数据点之间的相似度,通过循环迭代自动计算聚类质心和及其隶属数据点,最初被用于文本数据分析、人脸识别等领域.设图像数据集X分布于无向加权图G中,且xi,xj∈X之间的权重对应于图像相似度矩阵中的元素值犕II(xi,xj),节点xi,xj之间存在一条无向加权边当且仅当犕II(xi,xj)<ξ,其中ξ为常参数.图像聚类质心的计算如下,节点node(i)向其相邻节点node(j)发送实数值的消息r(i,j),表示节点node(i)选择节点node(j)作为质心的概率,计算如下:r(i,j)=犕II(i,j)-maxj≠j{a(i,j)+犕II(i,j)}其中a(i,j)是节点node(j)向node(i)发送实数值消息,表示node(j)能够成为node(i)的质心的概率,a(i,j)的值初始化为零,a(i,j)的计算如下所示:a(i,j)=min0,r(j,j)+∑max{0,r(i,j式(5)、(6)在整个数据集内迭代进行,直到达到收敛状态,即r(i,j)和a(i,j)的变化小于规定的阈值.图像聚类质心的计算过程反映了整个数据集范围内的累积关系,即r(i,j)的值,同时a(i,j)的不断更新也反映了某个图像数据点能够成为一个合适的聚类质心的累积概率.因此,对于图像数据点node(i),Page4若node(j)能够使a(i,j)+r(i,j)取得最大值,则node(j)为node(i)的聚类质心.音频的聚类采用与图像类似的方法得到.5实验结果与分析5.1数据集和特征选择为验证上述算法的有效性,在WindowsXP下用VC6.0实现了一个原型系统,实验从Web页面上采集了20个语义类别的图像和音频作为训练数据集,例如:爆炸、鸟类、汽车、老虎、狗、海豚、闪电等类别,其中每个类别中包括100幅图像和60段音频例子.实验数据主要来源于网站http://www.ani-malbehaviorarchive.org、http://encarta.msn.com和http://image.baidu.com/,部分图像来自于Corel图像数据集.实验提取的图像特征包括256-dHSV颜色直方图、64-dLAB颜色聚合向量以及32-dTamura方向度;音频特征包括4个Mpeg压缩域特征:质心(Centroid)、衰减截至平率(Rolloff)、频谱流量(SpectralFlux)和均方根(RMS).音频是时序性数据,对持续时间不同的音频样本提取得到的特征向量维数也不同,文本收集的音频例子持续时间均不超过7秒钟,并使用前期工作中的模糊聚类方法[6],对初始音频特征提取相同数目的聚类质心作为音频索引.此外,基于相关性分析视听觉特征降维和坐标计算用Matlab7.0完成,计算复杂度将随着特征维数的降低而减小.5.2性能评价公式实验从训练数据集中选取k(2k20)个语义类别的图像和k(2k20)个语义类别音频数据进行聚类,并设定输出的图像聚类个数和音频聚类个数均等于选定的k值.设某个图像样本x和音频样本y均是从语义类别为gi的数据集中选取,x的聚类结果是被划分到类别ri中,y被划分到类别si中,则图像聚类准确率IAccuracy和音频聚类准确率AAccuracy计算如下:其中n,m分别表示本次聚类实验中图像样本总数和音频样本总数,map(x)是将语义类别标签映射到聚类结果上的最优映射函数,本文用文献[14]中的Kuhn-Munkres方法获取最优映射.5.3参数选取相关性融合算法中传递因子ε1,ε2,ε3的取值根据式(4)计算得出,ε3=0.72,ε1,ε2没有固定取值,而是随图像样本集的变化而变化(参见第3节);此外,权重参数λ直接影响了相似度修正结果犕II,犕AA.为优化λ取值,实验从值域(0,1)范围内选取不同数值进行测试,如图2所示.并且对于λ的每个取值,按照5.2节中的方法,从训练数据集中选取k个语义类别的图像和k个语义类别音频数据进行聚类,计算相应的IAccuracy和AAccuracy,图2的结果是k=3,4,5,6的情况下得到的性能均值.可见,当权重参数λ=0.7时,图像聚类性能IAccuracy和音频聚类性能AAccuracy均达到最优.5.4对比实验和分析在确定参数取值之后,为验证本文方法的有效性和优越性,实验分别采用下列4种方法,对5.2节中选取的k个语义类别的图像和k个语义类别的音频数据集进行聚类:(1)本文方法.用本文的方法对实验数据进行视听觉特征统一降维和子空间映射、矩阵融合和基于相似度的数据聚类;(2)KCCA+AP.为了验证本文方法在子空间中进行矩阵融合的有效性,首先采用KCCA方法进行子空间映射,然后直接采用AP算法[4]分别对图像和音频聚类;(3)PCA+Kmeans.PCA(PrincipalComponentAnalysis)[15]是一种经典的多媒体特征分析方法,首先对5.1节中提取的视觉特征和音频特征分别用PCA方法进行主成分提取和去噪,然后用传统的Kmeans[3]聚类方法分别进行图像和音频聚类;(4)Kmeans.直接使用Kmeans聚类方法分别进行图像聚类和音频聚类.Page5上述实验中参数k的取值为[2,10]范围内的所有整数,并对k的每个取值,随机选择5次数据集进行聚类实验,最后计算性能均值.其中80%的数据用作训练数据,其余20%作为测试数据(Kmeans方法除外,无训练过程).图3显示了上述4种方法所得聚类结果的IAccuracy,AAccuracy性能平均值.从图3可以看到,本文的方法在图像聚类准确率IAccuracy和音频聚类准确率AAccuracy方面均优于其它3种方法.几类方法中,PCA+Kmeans方法的IAccuracy性能虽然相对较低,但仍优于Kmeans方法,这是因为PCA方法的使用去除了视觉特征中的噪声;PCA+Kmeans方法和Kmeans方法的AAccuracy性能较为接近,这是因为在5.1节中已采用文献[3]中的模糊聚类方法,对初始的时序性听觉特征进行索引.此外,本文方法明显优于KCCA+AP方法,这是因为聚类性能的高低很大程度上取决于输入条件,即:相似度矩阵,也正说明了本文提出的特征子空间中相关性融合算法能够优化图像和音频数据集的相似度矩阵,使之更加符合高层语义关系.图4是当k=5时,聚类结果的一个示例图,其中每一列是一个聚类类别中的图像示例,并按照与聚类中心的相似度进行排序,包括前5个正确结果以及一个错误结果.实验结果说明了,关系矩阵融合方法挖掘了图像和音频数据集在特征子空间中的潜在关系,可有效用于语义理解和聚类.5.5图像-音频交叉检索结果为进一步验证本文方法的适用性,在上述实验的基础上,还设计了图像-音频交叉检索实验,步骤如下:(1)求解相似音频.用户提交一个图像样本r作为查询例子,检索系统从音频聚类结果中找到类别标签与r相一致的音频类Ω={y1,…,yi,…,yp}(yi表示音频样本);(2)排序.从相关性矩阵犕IA(参见第3节)中找到r与yi的关系值,以降序输出数据集Ω中的音频,作为检索结果.表1显示了当参数k∈[5,6,7,8,9]时,对检索结果进行两轮相关反馈(采用文献[16]中的反馈策略)后得到的平均结果,其中每一行列出了返回结果个数分别为n=5,10,15,20,25,30,35时,正确结果的个数.可见,本文的方法应用于图像-音频之间的交叉检索,可以取得较好的结果,当样本类别数k=5,返回结果个数为n=15时,正确结果的个数为13.12.表1以图像为查询例子检索音频的平均结果kn=5n=10n=15n=20n=25n=30n=3554.418.6913.1216.8219.5422.8723.4564.318.2112.6515.2718.1119.8721.1374.127.1310.9314.1517.2118.4119.3583.956.8410.2412.7414.1315.1416.0593.256.259.2611.6712.4513.7414.23Page66结论不同于传统的多媒体聚类研究,本文提出的方法可以同时用于图像和音频两种不同量纲的多媒体数据,创新之处在于:将图像和音频数据同时映射为特征子空间中的样本点,综合利用子空间中不同数据集之间的多重相关性,优化多媒体语义的学习结果,并通过基于相似度的循环迭代算法实现了图像和音频的聚类.本文方法考虑了目前Web多媒体数据中图像和音频共存的现实情况,突破了传统聚类方法对不同类型数据集之间相关性融合分析上的局限性.实验从多方面验证了本文方法的有效性,并给出了应用于多媒体检索领域的实例和性能分析结果.局限性在于,当数据集达到海量时,本文方法缺少有效索引机制,难以快速处理Web上的海量多媒体信息.因此,进一步研究工作包括:大规模数据集的多层索引和响应时间优化等问题.
