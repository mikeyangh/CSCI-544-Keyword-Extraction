Page1模型指导的多维GPU软件低功耗优化方法王桂彬(国防科学技术大学计算机学院并行与分布处理国家重点实验室长沙410073)摘要作为众核体系结构的典型代表,GPU(GraphicsProcessingUnits)芯片集成了大量并行处理核心,其功耗开销也在随之增大,逐渐成为计算机系统中功耗开销最大的组成部分之一,而软件低功耗优化技术是降低芯片功耗的有效方法.文中提出了一种模型指导的多维低功耗优化技术,通过结合动态电压/频率调节和动态核心关闭技术,在不影响性能的情况下降低GPU功耗.首先,针对GPU多线程执行模型的特点,建立了访存受限程序的功耗优化模型;然后,基于该模型,分别分析了动态电压/频率调节和动态核心关闭技术对程序执行时间和能量消耗的影响,进而将功耗优化问题归纳为一般整数规划问题;最后,通过对9个典型GPU程序的评测以及与已有方法的对比分析,验证了该文提出的低功耗优化技术可以在不影响性能的情况下有效降低芯片功耗.关键词低功耗优化;GPU;动态核心关闭;动态电压/频率调节1引言作为众核体系结构的典型代表,图形处理器(GraphicsProcessingUnit,GPU)具有相对简单的控制逻辑,集成有大量并行处理核心,具有较高的峰值效能(单位功耗的计算性能).随着芯片集成度不断提高,GPU功耗开销逐渐增大.当前主流高性能GPU的功耗普遍超过200Watts,成为计算机系统中功耗开销最大的组成部分之一;与此同时,GPU的运行温度也在不断攀升,降低了芯片的可靠性,增加了系统维护成本.因此,面向GPU的低功耗优化技术研究具有重要的实际意义.程序执行时间取决于关键路径上功能单元的执行速度;而降低非关键路径上功能单元的运行频率或关闭部分功能单元可以在较小的性能损失下有效降低功耗,相应实现技术可以分为动态电压/频率调节(DynamicVoltageandFrequencyScaling,DVFS)和动态核心关闭技术(DynamicConcurrency-Throttling,DCT).随着GPU核心数量的不断增加,平均每个核心分得的访存带宽在逐渐减少,导致计算性能与访存性能的差距逐渐增大,因此存储系统逐渐成为GPU性能的主要瓶颈[1].本文的功耗优化研究主要针对访存受限程序.针对传统多核体系结构,文献[2-3]提出了结合DCT与DVFS的多维低功耗优化方法,包括基于启发式搜索方法[2]和基于采样预测方法[3].其中搜索方法是在给定程序执行时间约束下搜索不同活跃核心数和运行频率的组合(称为配置),通过采样实际能耗开销求得能耗最优的配置;而预测方法通过采样部分配置下的程序执行性能以及硬件事件计数器信息,预测其余配置下的执行情况,在达到性能最优的同时降低能耗.不难分析,上述方法存在以下不足:(1)已有方法均以程序执行时间而不是能耗开销作为搜索或预测的目标函数,无法充分发掘功耗优化的潜能;(2)已有方法需要对配置空间进行采样,其方法引入的额外开销以及方法的有效性与配置空间的大小密切相关,而GPU体系结构集成有大量并行处理核心,这将大大增加方法本身引入的额外开销.基于此,本文提出了模型指导的多维低功耗优化方法,通过结合GPU多线程执行模型特点,建立了访存受限程序的功耗优化模型,在该模型的指导下求解能耗最优的活跃核心数及其运行频率.本文的主要创新包括:(1)针对GPU多线程执行模型的特点,建立了访存受限程序的功耗优化模型.(2)面向访存受限的GPU程序,提出了结合DCT与DVFS的多维低功耗优化方法,并将该优化问题归纳为一般整数规划问题.(3)实验结果表明本文提出的多维低功耗优化方法可以有效降低GPU功耗,在性能损失不超过0.6%的情况下节省能耗17.5%;与已有的搜索算法相比,本文提出的方法可以进一步节省能耗9%.本文第2节提出本文研究问题,并给出访存受限程序的功耗优化问题描述;第3节介绍结合DCT与DVFS的多维低功耗优化方法;第4节介绍相关实验平台与测试用例;第5节对本文提出的功耗优化方法进行详细评测与分析;第6节介绍低功耗优化问题的最新研究进展;最后,我们在第7节总结全文.2GPU执行模型与问题提出2.1节首先简要介绍CUDA编程模型及其多线程执行机制;2.2节给出了面向访存受限程序进行功耗优化的约束条件以及该优化问题的一般性描述.2.1CUDA编程模型与多线程执行机制在CUDA模型中,GPU上执行的程序称为Kernel程序[4],CPU对GPU的调用过程通过一系列的Kernel调用实现,因此本文以Kernel的一次调用作为功耗优化操作的基本单位.Kernel程序由多个线程块(ThreadBlock)组成,每个线程块由许多线程组成.在Kernel执行过程中,GPU上的线程调度器以线程块为粒度,动态地将计算任务分配给空闲流多处理器(StreamMultiProcessor,SM),如图1(a)所示.由于不同SM独立完成计算任务,本文将SM看作处理器核心.线程块中的线程以Warp为单位组织并调度到SM上执行,并行执行的多个Warp通过时间重用的方式占用SM.记Warp的大小为Swarp,处理器核心内的SIMD宽度(即标量核心数)为Ssimd,则Warp发射一条指令的延迟为SwarpSsimd2.2面向访存受限程序的功耗优化2.2.1问题提出文献[5]对GPU体系结构建立了详细的性能模型,本文的功耗优化研究以该模型为基础展开.根据该性能模型,程序执行时间由运算操作延迟和访存操作延迟组成,其中访存操作延迟又细分为由存储器带宽不足而引发的延迟和由绝对访存时间而引,如图1(b)所示.Page3图1Kernel调度与执行图发的延迟,其中绝对访存时间是一次访存操作的最短时间.记一个Warp的平均运算操作延迟为Tcomp,访存带宽延迟为Tbw,绝对访存延迟为Tlat,则平均每次访存操作间的运算操作延迟为Tcomp/Nmem,访存带宽延迟为Tbw/Nmem,其中Nmem为Warp的平均访存次数.图2给出了并行Warp执行中运算操作与访存操作的关系图,其中C表示运算操作,M表示访存操作.图中灰色框表示访存带宽引发的延迟,虚线表示绝对访存延迟.需要注意的是,不同访存操作的访存带宽延迟不能相互隐藏.通过分析可以发现,平均一次访存带宽延迟可以被一次运算操作所隐藏;因此如果满足TcompTbw,则处理器核心不是制约程图2计算操作与访存操作关系图序性能的关键路径,降低核心运行频率或关闭部分核心都可以在不影响性能的情况下降低功耗.对比图2(a)和(b)可以看出,在一定范围内增大运算时间不会增加Kernel总执行时间(与原执行过程相比,图2(b)中只增加了一次启动开销,因此该影响可以忽略).从图2(b)中可以看出,此时优化后的运算时间(记为Tcomp)不等于访存带宽延迟,即Tcomp≠Tbw.其原因是,在考虑访存操作延迟时不仅需要考虑访存带宽不足引发的延迟也应注意绝对访存时间的影响.对比图2(c)可以看出,如果进一步增大计算时间Tcomp,由于绝对访存延迟的影响,访存带宽无法被充分利用,增大了程序总执行时间.需要注意的Page4是,图中未被重叠的空闲部分在每次访存操作中都会存在,因此该影响无法忽略.综上所述,对于访存受限程序,在功耗优化过程中不仅需要考虑访存带宽的影响,也应该考虑绝对访存时间的影响.通过对图2(b)的执行过程分析可知,优化后的计算时间Tcomp应同时满足以下条件,即可在不影响性能的情况下降低功耗:TcompTbw∧Tlat+TcompNmemWLPeffTbwNmem其中WLPeff表示一个SM上并发执行的Warp数,图2中示例程序的WLPeff为3.2.2.2问题描述不失一般性,访存受限程序的功耗优化问题定义为:在不影响程序性能的情况下,确定活跃处理器个数N和运行频率F,使GPU完成Kernel执行的总能耗E最小.文中活跃处理器核心指实际参与计算的处理器核心.根据文献[6]对同构多核处理器的分析结论可知,将计算任务平均分配给所有处理器核心,且处理器以相同的运行速度完成任务时总能耗达到最优.我们假设Kernel中的计算任务可以均匀分配到所有核心,因此在分析模型中认为所有处理器核心的频率相同;作为特例我们在3.2节中也讨论了负载不平衡的情况.按照物理学定律,能耗E是芯片功耗P与执行时间T的乘积.下面首先讨论芯片功耗的影响因素.CMOS电路的总功耗由动态功耗Pd和静态功耗Ps组成,即总功耗P=Pd+Ps.动态电压/频率调节技术是降低动态功耗Pd的有效方法.在工艺尺度大于90nm时,动态功耗在总功耗中占较大比重;随着工艺尺度不断缩小,静态功耗的比重不断增大,在45nm尺度下两者比重已经相当[7].动态处理器核心关闭技术是针对静态功耗Ps的主要优化方法.下面分别介绍影响动态功耗和静态功耗的因素.根据CMOS电路的功耗公式,处理器动态功耗与电压和频率的关系为其中A是切换因子,C是切换电容,V是核心电压,F是运行频率.处理器核心电压与该电压下的最高运行频率有如下关系:其中VT为阈值电压,K和γ是与工艺相关的参数.一般VT很小,因此上式简化为在本文中,我们假设处理器工作在核心电压允许的最高频率,因此在后文中省略下标max.为便于描述,记Kd=ACK,则Pd=KdVγ+1.根据文献[8]建立的静态功耗模型,处理器静态功耗Ps为其中n是晶体管个数,Kdesign是与设计相关的参数,I^leak是与工艺温度相关的参数.本文假定GPU在执行Kernel程序的过程中温度恒定,即I^leak为定值.为便于描述,记Ks=nKdesignI^leak,则Ps=KsV.记Kernel中包含的线程块数为NTB,每个线程块中包含Warp数为NWarp,则平均每个处理器核心执行NWarpNTBN个Warp.根据2.2.1节的分析,对于访存受限程序Kernel总执行时间取决于访存操作时间,即需要注意的是,动态功耗只发生在处理器核心的运算过程中,而静态功耗在Kernel执行过程中始终存在,则Kernel执行的总能耗为E=NKdVγ+1×NWarpNTB=NWarpNTBKdVγ+1Tcomp+KsVT综合式(1)和式(3),访存受限程序的功耗优化(问题可以描述为minE=NWarpNTB(KdVγ+1Tcomp+KsVTbw)烄s.t.TcompTbw烅烆其中,Vlow和Vhigh分别为处理器核心电压的最低值和最高值;与之相应的Flow和Fhigh分别为处理器核心频率的最低值和最高值;Nmax为GPU包含的核心总数.3模型指导的多维GPU功耗优化方法由式(4)可知,降低运行频率F可以有效降低能耗E,同时在不影响程序性能的约束下,活跃处理器数量N对处理器运行频率F有着直接的影响,因此问题的关键是确定活跃核心数量与运行频率对程序执行时间和能耗的影响.3.1节首先分析核心间Page5负载平衡情况下的功耗优化问题;作为特例,3.2节中分析了负载不平衡的情况.为便于推导,在本节中所有与时间有关的变量都以核心单元周期数为单位.3.1负载平衡下模型参数求解通常,CUDA程序中线程块数远远大于处理器核心数量,即NTBNmax,因此本节假设核心间负载平衡.根据文献[5]建立的GPU性能模型,Warp中每条指令的平均延迟为LcompSWarp程中指令的平均延迟,故一个Warp的指令延迟Ccomp=Ninst要注意的是,访存指令同样需要发射周期,故令访存指令延迟为1.进一步,考虑由访存带宽引起的延迟Cbw.记一个Warp访问片外存储器的字节数为Nbytes,GPU片外存储器带宽为Membw.由于片外存储器带宽由所有处理器核心共享,因此每个核心分得的带宽为MembwN,则Warp平均访存带宽延迟Cbw=NbytesFMembw/N=NbytesNF对于访存受限程序,Warp的执行时间取决于访存延迟Cbw.由式(4)可知,Kernel程序的能耗E为E=NWarpNTBKdVγ+1Ccomp由式(4)可知,功耗优化过程需满足不等式TcompTbw和NmemTlat+TcompWLPeffTbw,将Ccomp和Cbw的表达式代入上述不等式,可得综合式(5)~(7),在式(4)的基础上访存受限程序的功耗优化问题可以进一步描述为minE=NWarpNTBKdKV2Ccomp+KsKV2-γC烄s.t.NVγ-1CcompMembw烅NmemTlatKVγ-1+CcompWLPeffNbytes1NNmax,VlowVVhigh,N∈N烆3.2负载不平衡下模型参数求解3.1节中假设NTBNmax,即有足够多的并行任务占满所有处理器核心.此时,式(8)中核心数量N的取值范围是1NNmax,且WLPeff=WLPmax,WLPmax表示硬件资源允许的最大并发执行的Warp数量,由处理器核心的硬件资源和Kernel程序对硬件资源的使用量决定.但是在部分应用中,由于问题规模或应用并发度等因素的影响,实际运行的线程数可能少于处理器核心可以允许的最大值.如果NTB<Nmax,则必有Nmax-NTB个处理器核心处于空闲状态,显然关闭空闲处理器核心可以降低静态功耗开销.因此当NTB<Nmax时式(8)中N的取值范围应修正为1NNTB,而参数WLPeff与N的取值有关,不难分析得到WLPeff=minWLPmax,NwarpNTB4实验方法由于目前商用GPU芯片尚不支持动态核心关闭技术,因此我们基于一款时钟精确的GPU模拟器扩展了功耗模拟模块,以此验证本文提出的功耗优化方法.4.1节和4.2节将分别介绍测试平台和相关测试用例.4.1测试平台介绍实验平台的配置参数.4.1.1功耗模型扩展本节依次介绍GPU功耗模型的扩展方法以及为了验证本文提出的低功耗优化方法,我们基于一个开源GPU模拟器GPGPU-sim扩展了Wattch[9]和Orion[10]功耗模型.GPGPU-sim是一款时钟精确的统一框架GPU模拟器[11],该模拟器支持CU-DAPTX(ParallelThreadExecution)指令集,可以运行CUDA和OpenCL程序.Wattch是目前模拟平台中使用较为广泛的处理器动态功耗模型,它基于CMOS电路动态功耗公式,通过参数化方法评估动态功耗值.Wattch功耗模型将所有硬件结构分为四类:Array结构(Array)、全相连内容寻址存储器(CAM)、组合逻辑与线路(CLW)和时钟(Clocking).我们参考了SimpleScalar中功耗模型的扩展方法实现GPGPU-sim的功耗模型,表1给出了GPGPU-sim中功能部件与Wattch功耗模型中定义的硬件结构的对应关系.Page6类别ArrayCAMInstructionwindowCLWALUandInstructionselectionunitClockingGlobalclockWattch中不包含互联网络的功耗模型,而随着核心数量的不断增加,互联网络的功耗日益增大,因此我们扩充了Orion[10]网络功耗模型.Orion功耗模型对网络中时钟、链路、仲裁器等部件都有较为准确的建模.表1中各主要硬件结构的工艺尺度参考了Orion2.0版本中关于65nm工艺下的参数定义.对于静态功耗的模拟,我们采用文献[2]中的方法,按照动态功耗值的一定比例估计静态功耗值.记最高频率下静态功耗与动态功耗的比值为λ=Ps/Pd,则可计算Ks=λKdVγ+1我们通过调整不同的数值反应不同温度下功耗优化的情况.4.1.2测试平台配置GPGPU-sim提供了灵活的体系结构级配置方法,如核心数量、核心频率、访存带宽等重要结构参数.实验中的参数配置参考了NVIDIAQuadroFX5800GPU的硬件参数.FX5800GPU是目前主流高端GPU,其单精度峰值性能达到624GFlops,访存带宽102GB/s.表2给出了硬件配置参数,其中对核心频率和电压的设置参考了当前GPU芯片参表3测试程序描述应用类别SpeckleReducingAnisotropicDiffusion5实验结果与分析5.1访存操作对程序性能的影响分析图3给出了所有Kernel程序中存储器处于忙状态的时间占Kernel总执行时间的百分比,该值体现了Kernel程序对存储器的使用密集性.从图中可数.由于真实处理器只支持离散的频率调节,因此我们以100MHz为跨步,定义了9个离散频率值.硬件#ShaderCore#SIMDPipelineWidth#registerpercore#sharedmemory#memorychipBandwidthpermemorychipMemorycontrollerCore/Interconnection/MemoryFrequencyInterconnectionShaderCoreFrequency0.5~1.3GHz,step=100MHzShaderCoreVoltage4.2测试用例介绍我们选取了9个科学计算应用作为测试用例,其中2个应用选自SPECOMP2001测试集,5个应用选自Rodinia测试集[1],另外一个应用出自CUDASDK2.3.Rodinia测试集是由弗吉尼亚大学开发的一套面向异构系统性能评估的基准测试程序集,目前提供OpenMP和CUDA两种实现版本.我们选择了其中的5个程序,并尽可能覆盖更多的应用类型,如表3所示.此外,我们选取了SPECOMP2001测试集中的312.SWIM和314.MGRID两个应用,并通过CUDA语言映射在GPU平台[12].表3中给出了所有应用的简要描述,包括每个应用中所有Kernel的并发线程块数等,其中ki表示应用中的第i个Kernel程序.StructureGridSWIMk15;k27;k36UnstructuredGridBPStructuredGridStructuredGridSRAD以看出,除HS、SRAD和NW以外,其它Kernel程序都对存储器有很高的使用率.其中HS和SRAD是计算受限的应用程序;而NW中访存部件的利用率低的原因是该程序对GPU的占用率较低,而且其对不同存储体的访问存在不平衡,导致整体利用率不高.与之相反的是,MG和SWIM中所有Kernel程序的存储器利用率都很高,访存带宽成为程序的性Page7能瓶颈;而BP中存在一个Kernel程序对存储器的使用率较高.通过对比存储器利用率均值和最大值的差距,可以发现部分Kernel程序对存储体的使用率存在不平衡性(如BP、SC),这必然加剧对存储系统的压力.同时,图3也给出了平均每个周期完成的图3DRAMBank忙状态时间比例与处理器核心实际IPC5.2模型指导的功耗优化推演过程示例本节以一个具体的程序为案例,详细介绍本文提出的基于模型的功耗优化推演过程.由式(8)可知,模型求解的关键参数可分为系统参数和程序参数.系统参数主要包括SM的SIMD宽度、Warp大小以及流水线深度等.如表2所示,模拟GPU的SIMD宽度Ssimd=8,Warp大小SWarp=32;因此Warp发射一条指令的延迟为4个周期.根据文献[11],模拟GPU的流水线深度为24,因此当一个SM上执行的Warp数大于6(24/4=6)时,可以有效隐藏线程内由于指令间真依赖关系引发的流水线延迟[11](这里不考虑长访存延迟,访存延迟通过Cbw描述).在程序参数方面,主要包括运算延迟Ccomp和访存量Nbytes.下面以SWIM应用中的k3程序为例,介绍程序参数的计算方法.如图4所示,该程序中每个线程需要从9个数组中各读入1个数据元素,在完成相关计算后,将结果写入其中6个数组(图中只给出了代码片段).CUDA编程语言提供了一种与平台无关的中间代码PTX指令,模拟器的执行是通过PTX指令驱动的,因此我们以PTX指令分析程序参数.通过分析,该程序中每个线程执行的指令数Ninst=37,其中包含15条访存指令.根据硬件资源约束,该程序在一个SM上的并发Warp数为24(大于6),此时可完全隐藏线程内由于指令间真依赖关系引发的流水线延迟,因此平均每条运算指令的延迟Lcomp=1.如果并发Warp数不足以隐藏流水线延迟,则需在此基础上增加未被隐藏的延迟开销;根据指令数(InstructionPerCycle,IPC).模拟GPU的峰值IPC可以达到240,但是由于受限于访存带宽,大量Kernel程序的实际IPC都远低于理论峰值,因此对于大量GPU程序,面向处理器核心的功耗优化具有较大潜能.文献[5]建立的GPU性能分析模型,可以分析得出任意Kernel程序的平均运算指令延迟,因此本文不再赘述.__global__voidk3(floatgUNEW,floatgUOLD,floatgU,…){…unew=gUNEW[idx];//idxisthearrayindexuold=gUOLD[idx];u=gU[idx];gUOLD[idx]=u+alpha(unew-u-u+uold);gU[idx]=unew;…}根据Lcomp可知每个Warp的运算指令延迟Ccomp=Ninst作对象为单精度浮点数据,因此每个Warp的访存量Nbytes=15×4×Swarp=1920.将Ccomp和Nbytes代入式(8),可知该程序为访存受限程序;同时,在以上参数的基础上,通过式(8)即可求得最优活跃核心数量及其运行频率.5.3优化效果评估与分析根据2.2.1节中对访存受限程序边界条件的分析,我们区分出测试用例中的访存受限程序.为了体现芯片温度对静态功耗的影响,我们调节参数λ的大小以反应不同静态功耗下的功耗优化效果.图5和图6给出了优化前后的执行时间和能耗对比图,分别对应静态功耗与动态功耗比λ为0.2和0.5两种情况.图中尖括号中数值依次表示活跃处理器核Page8心数量和运行级别(取值范围是0~8,数字越小频率越低).当λ为0.2时,本文提出的方法可以在性能损失平均不超过0.6%的情况下节省能耗17.5%.其中MG中的k1程序和FWT中的k2程序在频率图5功耗优化效果图(λ=0.2)图6功耗优化效果图(λ=0.5)当静态功耗与动态功耗比λ为0.5时,静态功耗在总功耗中的比例增大.由2.2.2节的分析可知,当静态功耗增大时,与降低运行频率相比,关闭处理器核心可以获得更大的能耗节省.对比图5和图6中分析方法给出的最优配置,我们可以发现,图6中Kernel程序的运行级别提高,但是活跃核心数量相应减少;可以看出本文提出的方法可以有效适应不同的硬件特征或运行环境.当λ为0.5时,本文提出的方法平均可以在不影响性能的情况下节省能耗22.7%.因此,对于以GPU为代表的众核体系结图7与单独使用DVFS或DCT的优化效果对比(λ=0.2)降低的情况下,性能反而提高.通过对模拟器输出结果的分析发现,在运行频率较低的情况下,处理器核心对网络的竞争明显降低,减少网络拥塞带来的额外开销,提高了系统吞吐率.构,处理器核心动态关闭技术将是降低功耗的重要手段.图7给出了结合DVFS和DCT的多维低功耗优化方法与单独使用任一方法下的优化效果对比.除BP程序外,其余所有测试程序中多维优化方法都优于单一优化方法.伴随处理器芯片工艺的发展,处理器静态功耗比例不断增大,处理器运行电压的不断降低,单纯依靠DVFS方法已经难以获得有效的能耗节省.与此同时,DCT方法将随着核心数量的增加变得尤为重要.本文提出的DVFS与DCTPage9多维优化方法可以有效结合两种优化方法的优势,综合考虑静态功耗与动态功耗的影响以选择最优配置.5.4与搜索算法的比较为了检验本文提出的功耗优化方法,我们实现了文献[2]中的启发式搜索方法.该方法以最高配置(所有核心参与计算且运行在最高频率)为起点,通过二分法在处理器核心数量一维进行搜索,按照顺序方法由高至低在频率一维进行搜索.如果遇到某图8与搜索算法的优化效果对比(λ=0.2)6相关工作(1)多核通用处理器功耗优化研究面向多核处理器的功耗优化技术研究已久.Li等人[2]首次提出多核处理器DVFS与DCT两维空间优化方法.作者提出一种基于经验结果的启发式策略以缩小优化空间,该策略并未定量分析动态功耗与静态功耗的关系,而且该方法的执行时间随着处理器核心数量与核心调频级数的增大而增大,难以应用于众核体系结构.Curtis-Maury等人提出了基于采样的优化方法[3],该方法需要采样部分配置下的执行时间与功耗开销,因此同样引入无法忽略的运行开销,影响执行性能.文献[6]为同构系统的功耗优化方法建立了基础理论模型,并基于该模型评估了不同任务调度方法对系统功耗的影响,文章指出在同构多核处理器中,所有核心以相同的频率完成等量的计算任务可以使总能耗达到最优,该结论对指导多核处理器功耗优化具有重要意义.(2)GPU功耗评估与优化研究随着GPU进入通用计算领域,乃至高性能计算领域,面向GPU的功耗优化技术逐渐被各大厂商和相关研究者关注.在产业领域,NVIDIA公司提出了PowerMizer[13]功耗管理方法,PowerMizer可以根据显卡的负载情况动态调整运行频率,但是只配置采样性能低于第一个采样结果,则在更高的配置空间继续搜索.需要注意的是,搜索次数不仅受限于配置空间大小而且受限于程序迭代次数.如图8所示,由于GPU体系结构搜索空间巨大,而且大量真实程序的迭代次数较少,不足以抵消搜索过程本身带来的时间和能耗开销;搜索算法的优化效果明显低于本文提出的分析方法.随着单芯片核心数量和运行级别数的不断增加,搜索算法的效率将随之降低,基于模型的分析方法优势将更为突出.支持相对简单的管理策略,难以根据应用的需求进行有针对性的调频操作.AMD公司的类似功耗管理方法称为PowerPlay.在学术领域,一些面向GPU的功耗统计研究也逐渐出现.文献[14]以一个典型的生物计算应用为案例,详细对比了CPU和GPU的执行性能和能量消耗,同时指出GPU高效能的发挥与程序特征和优化策略有密切关系.文献[15]评测了GPU在一些典型应用中的功耗开销,详细分析多处理器和存储层次等关键部分对功耗的影响.与本文思路接近的最新研究[16]针对访存带宽受限的程序提出了关闭冗余处理器核心的GPU功耗优化方法;而本文提出的方法综合考虑了动态电压/频率调节和关闭技术,而且详细区分了访存带宽和绝对访存时间对功耗优化的影响.目前,在已有的GPU功耗优化方法中,尚未出现基于DVFS的编译级功耗优化方法.(3)GPU性能模型研究与传统通用处理器结构相比,GPU体系结构更为简单,不包含分支预测、乱序执行等复杂控制逻辑,因此一些研究者建立了简单高效的性能模型[5,17].在文献[17]中,作者提出了一个简化的GPU性能分析模型.作者认为访存操作是性能模型的关键,因此模型主要描述了访存操作的并行度,而访存操作的并行度主要取决于并行执行的线程数和访存带宽.通过对访存并行度的分析得出访存操作的平Page10均开销,进而得以预测程序的执行时间;但是该模型忽略了流水线延迟、分支操作等因素,因此影响了模型的准确性.文献[5]建立了更为准确的性能模型,通过建立程序工作流图(WorkFlowGraph),描述了运算操作、访存操作和同步操作的依赖关系和执行延迟.该模型中充分考虑了线程组间、线程组内和线程内指令级三级并行性对执行时间的影响;同时考虑了流水线延迟、分支操作等文章[17]中未涉及的因素.因此,本文中对GPU性能的分析参考了该文献[5],并进而讨论了处理器核心频率调节和关闭对性能和功耗的影响.7结论随着GPU集成度的不断提高,其功耗开销日益增大,因此面向GPU体系结构的功耗优化研究将成为该领域的研究热点.本文提出了模型指导的动态电压/频率调节与并发度控制多维功耗优化方法.通过对9个典型应用的评测表明,本文提出的方法在性能损失不超过0.6%的情况下节省能耗17.5%;与已有的搜索算法相比,该方法可以进一步节省能耗9%.
