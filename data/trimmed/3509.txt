Page1基于经验感知的自适应用户界面模型樊银亭1),2)滕东兴1)杨海燕1)马翠霞1)戴国忠1)王宏安1)1)(中国科学院软件研究所人机交互技术与智能信息处理实验室北京100190)2)(中国科学院研究生院北京100049)摘要针对传统自适应界面缺乏自主学习用户交互历史、难以根据用户经验有效预测用户意图的现状,基于认知心理学相关理论,该文提出了基于经验感知的自适应用户界面模型,从界面静态组成元素、动态交互行为和自适应策略三个方面建立了该模型的统一描述,然后研究了自适应界面模型的实现架构、关键技术和建模方法.最后开发了一个个性化的虚拟家居定制原型系统,并进行了实验评估.实验结果表明,该模型能够根据用户交互历史和上下文环境,准确预测用户意图,实时调整界面布局和交互行为以主动地适应用户.关键词用户经验;自适应用户界面;上下文感知;界面模型;人机交互1引言用户界面从最初的手工作业阶段,经过作业控Page2的固定的输入输出模式,交互式系统日益多样和复杂.传统的界面由于缺乏主动满足多种用户需求的能力成为软件可用性提高的瓶颈.由于用户需求因个体特征、设备特征和环境状况的不同而千差万别,因此研究一种能处理多种上下文环境满足用户个体需要的自适应用户界面(AdaptiveUserInterface,AUI)[1]显得尤为重要.现有面向不同领域的自适应用户界面应用[2-3]对不具备专业计算机知识、也没有兴趣学习这些专业知识的最终用户[4]来说,降低了对界面的认知差距和学习负担,使得人与机器之间的交互更加自然高效.自适应界面的研究目标是使用户更加方便灵活地使用软件,通过采用智能化的技术,使用户在使用软件时,让计算机通过学习或其他方式得到特定用户的认知方式、行为习惯、偏好等,使得用户界面适应用户的个性化特征.自适应用户界面是简化人机交互的好方法,它的目的是根据用户的个性化需求和应用环境主动裁减定制系统的显示和交互行为[5].自适应用户界面是面向最终用户的界面的重要组成部分和具体体现,因此也是今后用户界面的发展方向和发展趋势.从面向最终用户的角度来说,目前自适应界面的研究和应用在特定领域中的静态自适应方面(如界面定制)取得了较大进展[6],但是对于界面动态自适应最终用户的研究仍显不足.具体表现在:(1)缺乏对用户的认知活动进行深入研究,难以从有利于最终用户交互的角度设计自适应界面;(2)当前界面自适应研究主要体现在界面静态元素的个性化呈现方面,缺乏对用户动态交互行为自适应的探索;(3)没有充分利用人们已经习成的交互方式和交互行为(经验),造成现有系统在学习用户经验方面缺乏主动性和智能性,从而影响了交互任务的高效执行;(4)缺少基于上下文环境感知的预测方法,正确感知、预测用户意图的准确率不高[7],反而“干扰”用户任务的有序执行,降低了用户的执行效率.基于经验感知的自适应界面的提出,为上述问题提供了一种可行的解决方案.它将成为未来最终用户界面的主要发展方向.借助用户的交互历史,它能主动学习用户已经取得的经验,结合上下文环境预测用户意图,为用户提供个性化的信息服务.针对上述问题,本文提出一个基于用户经验感知的自适应用户界面模型(AdaptiveUserInterfaceModelBasedonExperienceAwareness,AUIM-BEA).首先根据用户的个性特征、用户角色、使用经验,建立用户模型;然后在此基础上从静态界面组成、动态交互行为和自适应策略三方面对自适应界面模型进行统一描述,最后提出自适应界面的体系架构、关键技术和建模方法,并给出一个应用实例.实例表明,基于经验感知的自适应界面能根据用户交互历史和上下文环境,准确预测用户意图,实时调整界面布局和交互行为以主动适应用户.本文第2节介绍自适应界面相关研究,并分析当前研究的不足之处,提出研究基于经验感知的自适应界面模型的必要性;第3节从认知心理学方面研究自适应用户界面的关键模型-用户模型,并做了详细描述和定义;第4节研究自适应界面模型主要组成部分,从静态组成元素、动态交互行为和自适应策略三方面对该模型进行统一描述;第5节描述了实现该模型的软件体系架构;第6节讨论了实现自适应机制的关键技术:交互动作序列模式构建和交互动作预测;第7节是提供该模型的建模过程;第8、9节给出一个自适应虚拟家居定制系统实例并进行了评价、分析;最后一节是对本文的总结和展望.2相关研究自适应界面已经成为人机交互领域研究的热点,ACMCHI、UIST、IUI等相关国际会议都将自适应用户界面作为重要研究内容,AAAI早在2000年春季专门召开了题为“AdpativeUserInterfaces”的研讨会.研究集中在特定领域的个性化界面定制和推荐等方面,如超媒体学习系统中的教师与学生之间的自动反馈[8]、医疗领域中的针对不同用户(护士、医生)提供不同的界面和导航[9]、残障人的辅助上网[10]、市场中的个性化的客户关系[11]等.此外,也有一些特定领域自适应界面应用评估方法[12]的研究.从上述研究可以看出,自适应用户界面因其智能性、主动性的需求,使其相对于传统图形用户界面,更侧重在理解用户意图和预测未来行为方面.此外,自适应用户界面是普适计算环境中的重要界面形式,交互设备及应用场景的多样化给自适应用户界面的研究带来新的挑战.利用统一的模型框架解决自适应用户界面面临的上述问题成为研究的关键.TakeoIgarashi开发了一个专门绘制3D图形的智能用户界面,系统根据用户显式提供的线索和意图,预测当前用户的目标任务并提供方案供用户选择[13].Pu提供了一种“向前看”的原则和一组推荐策略,能够帮助用户做出更准确的方案选择[14].香港浸会大学提出的自适应用户界面通过跟踪、识Page3别和记录用户在交互过程中的行为序列来识别用户的意图,属于面向用户的自适应用户界面[15].Yoo等人[16]提出一个推荐系统,该系统将用户划分成不同组,并在每组成员解决实际问题时进行协调过滤.与传统推荐系统相比,南京大学孙正兴教授针对笔交互环境下的在线草图识别,研究了基于SVM的用户适应性解决方法[17],解决了在线草图识别和用户适应性问题.Duarte等人[18]提出了用以指导开发多通道自适应用户界面的概念框架,并用行为矩阵来表示多通道用户界面的自适应规则.徐礼爽等人[19]提出了一个自适应笔式用户界面开发的概念框架,用来指导自适应笔式用户界面开发中的具体应用.另外,也出现一些有关自适应的个性化系统,例如Thompson等人[20]于2003年开发的个性化会话建议系统,戴姆勒-克莱斯勒研究与技术中心开发的自适应路线导航系统和自适应定位系统[21]等.除上述几类研究外,还有一些面向可视化的自适应用户界面研究[22-23].这些研究着眼于在绘制上增强信息呈现效果,如鱼眼技术等,但缺乏对交互的有力支持.当前,自适应用户界面研究主要还存在两方面不足:一方面,没有充分利用人们已有的与系统交互的历史经验,缺乏主动学习用户经验以动态适应用户,系统在界面自适应上呈现静态行为;另一方面,目前自适应用户界面的研究多集中在特定领域的应用,对自适应界面模型和实现框架研究不足,对于交互过程中自适应用户界面的作用机制和模型表达缺乏全面系统的理论研究,因而不能很好地指导自适应用户界面的设计与开发,限制了自适应用户界面图1基于认知心理学的人机交互环境为了完成特定的交互任务,用户需要在计算机中执行一系列交互动作,这些交互过程会增加用户的认知和记忆负担,而且随着用户使用系统经验的增长,这些重复执行的交互步骤也会降低用户的体验.因此,人机交互过程中,最佳的方式是尽可能发挥计算机的计算能力,使系统智能地适应用户.计算在更多领域的应用推广.3用户模型3.1模型描述人机交互的过程是人与计算机互相适应的过程,它包括两个层面的含义:(1)通过人工智能方法,使机器、环境适合于人;(2)通过最佳训练方法,使人适应于机器和环境.后者往往会给用户造成认知和学习负担.认知心理学家从信息加工角度把人看作信息加工系统,这种加工依赖于控制系统的当前目标.人为了达到既定目标,通常会根据所处环境、个体认知和个性倾向性(即需要、动机和价值观)的不同,采取不同的行动.在人、计算机、环境以及目标与行动之间形成一个人机交互空间.从用户的角度来说,如果用户界面呈现的刺激/信息能适应用户的认知心理和个性特征,就有助于用户快速完成任务,达成目标.从计算机系统角度来看,如果系统能不断根据来自用户的刺激/信息,为用户提供反馈,则能提高完成目标的效率.这种交互过程在自适应用户界面系统中体现为探测-适应的过程.首先,如果系统能够从用户的交互行为探测中获得足够的信息,就能感知用户的行为意图;其次,因为用户在与计算机交互过程中也不断学习,用户则不断提高使用系统的能力.因此,结合这两个条件,计算机系统就可能为用户提供适应用户个性化需要的信息.如图1所示.机的主要任务是对根据用户的认知特征、个性偏好和使用经验等建立用户界面模型、记录用户的交互方式和交互行为,结合上下文环境分析预测用户的意图,主动为用户提供合适的界面布局和信息呈现方式,智能地为用户提供自然的交互方式.根据心理学相关研究成果,人们在感知事件时Page4习惯于将连续事件依据各类特征分割为若干有意义的活动.事件边界即为相邻活动之间的间隔,它能够辅助用户更好地理解、记忆事件活动.利用上下文信息为交互提供辅助支持,包括三类上下文信息:用户上下文、任务上下文和交互环境上下文.用户上下文主要用于描述、记录用户的个性特征、所处角色、用户经验等;任务上下文包括交互任务的目标、活动以及一系列用户的交互过程;环境上下文则涉及交互任务的设备、工作方式及位置等.借助各类上下文,将传统交互中的以人为认知主体的交互策略扩展到个体与交互环境的相互作用.3.2模型定义认知特征、个性偏好等个体差异使得不同用户对用户界面有不同的要求,影响用户正确理解界面的可视表达方式.而且,对同一个系统而言,专业人员和初学者为完成同一任务所采取的行为是不同的,同一用户随着对系统的不断熟悉其行为特征也是不同的.另外,计算机也有适应个体或群体用户的需求.在自适应系统中,用户模型描述了用户的个性特征、工作环境中所处的角色以及用户使用系统的经验.用户模型(UserModel,UM)是一个四元组,UM=〈UserID,Personality,Role,Experience〉,UserID代表用户唯一标识符,Personality表示用户个性特征,Role表示用户角色,Experience表示用户经验.3.2.1用户的个体特征即使有相同的角色、相同的工作经历,不同用户也会因个体差异有不同的需求.例如习惯使用左手的用户,对界面布局和呈现方式与习惯于右手的用户有所区别.个体特征包括两个方面:一是个体所具有的客观属性,如性别、年龄、学历、认知能力等等;另一方面主要是用户的情感偏爱等主观属性.催化和激发用户的感知刺激主要由用户的个体特征所决定.Personality=〈Sex,Age,Education,Cognitive,Preference…〉.偏好(Preference)是人们根据环境、知识、感知和认知的结果而对动作做出的有倾向性的选择,是对系统中已有属性的选择.为定义偏好,我们引入供给(Affordance)这一概念.定义为系统为用户提供的可选属性集合,例如屏幕分辨率、字体、颜色、交互方式等.偏好(Preference)可描述为Preference={Aff(i)|Aff(i)∈AffSet,1in}.Aff(i)是系统供给集合AffSet的元素,n表示用户偏好的总数.3.2.2用户角色用户角色表示群体用户可以执行的共同行为,角色(Role)是一个三元组,Role=〈RoleID,RoleName,{Action}〉.RoleID表示角色标识符,RoleName代表角色名,Action是同一角色下的许可的交互动作.角色和动作是多对多关系,即一个角色可以拥有多个交互动作,一个交互动作也可以隶属于多个角色.同理,用户和角色也是多对多的映射关系.3.2.3用户经验用户在完成任务过程中,需要执行一系列的交互动作来达到目标,这些执行序列作为用户使用经验保存在系统中.随着用户使用系统时间的增多,用户经验的不断增加,用户则能更快地完成任务.反过来,如果系统能不断学习用户经验并结合上下文环境分析预测用户的交互意图,则能提供更好的自适应用户界面.这些经验决定系统自适应用户的智能程度,影响着用户使用系统的效率和体验.本文中,用户经验是为了达成目标而执行的一系列交互动作,每个动作表示原子的、作用在界面对象上并有作用效果的交互任务,比如对界面对象的平移、旋转和缩放等.我们将系统中的交互动作Action统一定义为一个六元组:Action=〈actionID,actionName,objectId,其中,actionID为该动作的标识,actionName为动作名称,objectId为动作的作用对象标识,position为动作发生位置,time为动作发生的时间,ResParam为动作效果特性参数,需根据特定动作的效果特性个性化定义.例如,平移动作的动作效果特性参数ResParam=〈fromPos,toPos〉,fromPos和toPos分别为平移对象的起始和结束位置.因此,用户经验Experience定义为Experience=〈Action(t)|t=t1,t2,…,tn,andt1<t2<…<tn〉.4自适应用户界面模型Puerta提出了一种通用的界面模型,基本组成元素包括用户模型、领域模型、任务模型、表示模型和交互模型,各个组成模型从不同侧面对界面进行描述[24].用户模型(UserModel)侧重描述特定平台下不同类型的用户角色、用户特征等.领域模型(DomainModel)侧重描述用户通过界面能够浏览、访问、操作的应用领域信息.任务模型(TaskModel)侧重描述用户通过界面所能完成的任务.表示模型(PresentationModel)侧重描述界面上的可视组件.交互模型(DialogModel)侧重描述用户与界面对象Page5交互的过程.用户模型、领域模型和任务模型属于抽象模型,表示模型和交互模型属于具体模型.本文以上述通用界面模型的各个组成元素为基础,结合自适应界面的特点和一定的界面自适应策略,构建自适应用户界面模型.其中,用户模型、领域模型、任务模型和表示模型属于界面的静态组成部分,交互模型属于界面的动态交互行为.自适应用户界面模型是一个六元组,可描述为AUI=〈UM,DM,TM,PM,IM,APM.〉,其中,UM为用户模型,DM为领域模型,TM为任务模型,PM为表示模型,IM,为交互模型,APM为自适应策略模型.由于本文中自适应策略模型是从具体模型中直接生成,我们把自适应策略模型划归为具体模型.4.1界面静态组成元素定义1.用户模型UM的定义见第3.2节.定义2.领域模型DM定义为DM=〈{Entity},{RL}〉,其中,Entity={Attribute1,Attribute2,…,Attributen},Entity表示含有若干属性的业务对象;RL表示实体之间的属性引用.定义3.任务模型TM定义为TM=〈{action}〉,其中,action为交互任务.定义4.表示模型PM定义为PM=〈{VCP}〉,其中,VCP为可视化组件,VCP=〈DCP,GCP,ICP〉,DCP为数据属性,GCP为组件可视属性,ICP为交互属性.4.2界面动态交互行为4.2.1交互上下文交互上下文是决定或影响人机交互过程和对话方式的各种相关信息资源,可以来自用户、设备与系统以及外部环境等实体.结合前面的分析,影响界面自适应的主要因素是当前交互的用户上下文、任务上下文和环境上下文.定义5.自适应用户界面交互上下文:Context=〈UC,TC,EC〉,其中UC为用户上下文,TC为任务上下文,EC为环境上下文.定义6.用户上下文UC定义为UC=〈User〉,图2交互模型user∈UserSet其中,User为当前用户,UserSet表示为系统的所有用户集合.定义7.任务上下文TC定义为TC=〈System,type,name,des,time〉,其中,System为当前执行任务的系统状态,type为动作类型,name为动作名称,des为动作描述,time为动作发生的时间.定义8.环境上下文EM定义为EM=〈device,worktype,location〉,其中,device为设备,worktype为工作方式,location为用户所处位置.4.2.2基于上下文感知的交互模型交互是用户通过物理设备完成一系列操作,界面将操作序列转化为可执行指令并执行的过程.建立交互模型的目的是定义符合用户认知特征的交互技术,为界面设计提供指导原则.由于人的认知能力受交互过程中可得到资源的影响[25],超过一定数量的资源会给用户带来较大的认知负担.此外,硬件设备成本、物理输入设备资源数量以及其所支持的操作原语类型的限制也会增加用户的交互负担,因此需要借助扩展逻辑空间的逻辑工具辅助交互过程,以解决复杂的交互任务问题.以笔交互为例,笔只有简单的点击、勾画、旋转等几个基本操作(交互原语),而交互任务种类繁多,仅对图形的任务操作就有平移、缩放、旋转、删除、裁剪等若干种,有的任务还相对复杂,单纯依靠笔的基本操作很难实现自然流畅的交互.因此,需要将笔输入设备根据用户意图映射成符合人们认知习惯的虚拟逻辑工具.据此,提出了基于上下文感知的交互模型.定义9.交互模型IM定义为IM=〈OptSet,LGTSet,Context,MapAlogrithm,FuseAlogrithm〉.用户完成复杂任务可能需要多个辅助工具.因此,某一时刻物理设备与虚拟逻辑工具并不是一一对应的映射关系,当交互动作发生时,物理设备可能被映射为多个逻辑工具.交互任务决定映射结果,用户的个性偏好和交互上下文对映射结果具有一定的影响.即相同任务在不同上下文环境中完成,逻辑工具映射结果可能不同.映射过程表示为Map,如图2所示.Page6定义11.融合过程Fuse定义为Fuse({LGT1,定义10.映射过程Map定义为Map(Device,Context)→{LGT1,LGT2,…,LGTn}.由于受物理输入设备的限制,传统交互方式在同一时刻只能有一个辅助工具处于激活状态,用户需要在多个逻辑工具之间来回切换,影响了交互的流畅性.在该交互模型中,系统将映射的逻辑工具集融合为一个整体,相互配合,从而有效地减少交互中断.融合过程表示为Fuse,如图2所示.LGT2,…,LGTn})→Set〈LGT〉.4.3自适应策略4.3.1基于动作的自适应策略自适应策略分为3类:(1)基于动作的自适应策略;(2)基于上下文的自适应策略;(3)基于策略的自适应策略[26].本文所提出的自适应用户界面中的自适应策略是基于动作的,但也结合用户所在的上下文环境进行预测.本文中所有的动作都是在一定的交互上下文环境中执行的,只有在相同交互上下文中的相同类型动作才视为相同动作重现.基于动作的自适应策略就是系统通过不断记录用户的个性化信息、系统当时的状态参数和所处的环境参数等上下文信息,从而形成用户的交互历史,结合当前上下文,从以往的用户交互经历中提取用户的交互意图和兴趣,从而对用户未来要执行的动作进行预测.用户动作的粒度可以是低层次的原子操作事件,也可以是经过封装的高层次的交互动作.低粒度的操作事件,如鼠标的单击、双击、键盘的按键事件等,能最大程度地记录下用户在系统中的操作行为.用户动作的粒度对交互历史的构建和用户的语义理解都有重要影响.交互历史采集动作的粒度太小或太大,都可能导致驱动系统状态转换的动作缺少完整语义,不易被用户理解.本文所研究的自适应动作是以用户为中心的交互任务模型中的交互动作,如对图形操作的平移、缩放、旋转等动作,对表单操作的添加、删除、保存等等.4.3.2自适应策略模型用户与系统交互的过程采用时序的方式保存,形成操作的偏序集合-用户经验.我们可以根据执行操作的时间密度将用户经验聚类,从而产生用户经验Experience的一个划分Experience={E1,E2,…,Em},每一个分块Ei(1im)代表在相应时间内完成的操作序列,这些序列中蕴含着用户与系统的交互模式[8].我们在子分块基础上挖掘出交互历史中的用户交互规律,从而发现用户与系统交互的一有限集合;为的观察值的有限集合;些个性偏好,智能地为用户提供自适应界面.为了提高自适应计算效率,我们进一步分析整合用户交互历史,建立自适应策略模型.组APM=〈ΩS,ΩP,ΩO,A,B〉,其中,限集合;定义12.自适应策略模型APM为一个五元ΩS={s1,s2,…,si,…,sn}为一组系统状态的有ΩP={p1,p2,…,pi,…,pm}为一组原子操作的ΩO={a1,a2,…,ai,…,at}为一组用户操作行A={aij}={L(Ot=ai|Xt=si)}是系统处于状态si下,操作观察值ai的匹配序列的平均长度概率分布;B={bij}={P(Ot=ai|Xt=sj)}是系统处于状态sj下,操作观察值ai的概率分布.自适应交互的实现方法就是匹配从用户交互历史中挖掘出的交互模式与当前即将发生的动作.传统的方法是通过选择两个连续的动作对作为模式,计算在前一个动作发生后,下一个动作发生的条件概率,根据当前的已发生动作,找出对应最大概率的下一个动作.事实上.通过查看用户的交互历史记录可以看出用户交互模式跨越不只两个动作,这对于向前回溯多个动作的预测就显得无能为力.为了解决这个问题,我们需要改变模式匹配长度.匹配模式越长,捕捉当前的状态越好,预测的效果越好.即我们要选择匹配当前动作的模式是最长的交互序列.假设一个小整数k,在时刻t状态s时预测动作a,通过计算Lt(s,a)取得在状态s时,以动作a结束的最大长度为k的序列的长度的平均值.定义13.匹配序列平均长度概率L(a|s)=lt(s,a)lt(s,ai).∑i尽管我们把匹配模式的长度看作主要预测指标,但是特定状况下,一个指定的动作可能并不是长模式的一部分,它的发生可能与另一动作密切相关,为了说明这种可能性,我们在此引入动作频率函数f(s,a)表示在状态s下动作a发生的次数.定义14.动作发生概率P(a|s)=f(s,a)定义15.动作发生评价Rt(s,a)=αL(a|s)+(1-α)P(a|s).其中,用参数α(0α1)作为考量两个预测指标的影响因子.表示在模式长度和动作频率上进行Page7折中,当α=1则只考虑匹配模式长度,当α=0时则只关注动作频率.如图3所示,我们用一个短的交互历史序列为例,当前状态为s3,k=3,匹配即将发生的动作的最长序列集合为{2,1,0},因此Lt(s3,a3)=(0+1+2)/3=1.假定所有动作的总值∑i图3交互动作序列与状态变迁5自适应用户界面体系架构根据相关研究和开发实践,本文提出自适应用户界面的体系架构,如图4所示.该体系结构分为4层:底层为数据层,中间层为模型层和自适应层,上层为界面层.数据层存放应用领域的数据信息.模型层由用户模型、任务模型、环境模型组成,描述自适应所需的信息集合.自适应层由自适应推理模块、自适应决策模块和交互上下文收集器组成,推理引擎通过系统事件消息处理机制捕捉事件,对事件进行分析、合并和整理,形成交互任务原子事件序列,结合上下文识别交互任务,并把识别结果传入用户模式识别模块中,进而结合知识库和规则库识别用户图4自适应用户界面体系架构6关键技术基于用户经验(交互历史)的动作预测方法通过对经验动作序列进行挖掘,利用交互历史机制所记a3在界面状态s3时发生的次数为30次,s3状态时总共有100次的动作发生历史,α=0.8.则动作a3在t时刻界面状态s3时的动作发生评价为的交互模式,通过意图预测模块预测用户最可能的交互行为候选;自适应决策模块基于传入的交互行为候选,结合交互历史中的系统自适应反馈评价进行自适应交互行为的决策;自适应层是实现用户界面自适应功能的算法和调度部分.界面层呈现自适应层推荐的结果.层与层之间以通信相互关联:来自系统底层的消息通过消息事件引擎形成交互历史,并为自适应引擎提供了交互上下文.自适应模块由信息收集和自适应规则来确定,它通过连续不断地收集和分析上下文信息和交互历史信息,采取一定的自适应策略,结合领域知识库和推理规则,为界面层提供自适应的功能.总体上,自适应层通过与上层的界面层和底层的模型层以动态在线迭代的方式通信,从而实现了用户界面的自适应功能.录的用户动作序列构建用户动作模式,进而对用户将要执行的动作进行预测,为用户提供自适应界面支持,如推荐相应的动作和系统状态等,以减少用户操作负担和提高用户交互体验.基于用户经验的动作预测方法包括两部分:交互动作序列模式构建和Page8交互动作预测.6.1交互动作序列模式构建人们在交互过程中会自觉或不自觉地遵循一定的交互方式,自适应用户界面关注的重点就是通过对历史交互动作序列的研究,发现人们交互中存在的模式,从而对用户未来的行为进行预测.为了预测用户下一步要执行的动作,系统会选取当前长度为n的动作序列S1,然后到用户模式中搜索,找出长度为n+1的动作序列S2,其前n长度的动作子序列与S1完全一致,则S2的第n+1个动作为用户可能执行的动作.构建交互动作序列模式主要算法思想:偶尔出现一次的交互动作序列为预交互模式,反复出现的交互动作序列作为交互模式加入模式库中,在最大模式长度限制下,匹配模式的序列尽可能长.假定存在一个正在执行的交互动作a,交互动作集合为C,新动作集合为E.如果a∈E,则产生一个以a作为结束项的交互动作序列模式,作为预交互模式;否则,若a不属于C,取以a为结束项,连续的若干动作与预交互模式比较,将其中相同的序列段作为以a为结束项的交互模式加入到模式库中,并把a加入到集合C中.如果a属于C,则到模式库查找与它局部匹配的序列.如果存在,则加入到模式库中;如果不存在,则预示着这段序列可能蕴含一个新交互模式.具体算法如算法1.算法1.交互动作序列构建算法.输入:用户当前的交互历史序列和交互模式库输出:用户交互动作序列模式算法过程:1.如果a=NULL,算法结束.否则,若a∈E,则转向步2;否则,若a∈C,转向步6;否则转向步3.2.设交互模式库中的最大交互模式长度为N,在交互上下文历史记录集合中,取以当前动作为结束项、长度为N的连续序列,作为预交互模式preS,a从集合E中取出,转向步5.3.取当前以a为结束项、长度为N的连续序列,与预交互模式preS比较,其中相同的序列段为以a为结束的交互模式S.4.把S加入到模式库中,更新S序列模式中各个动作的发生评价Rt.5.继续下一个动作结点,转向步1.6.对于以a为结束项的历史记录序列,如果在交互模式库中没有与它局部匹配的模式,则预示这段记录序列中可能存在一个新模式,转向步2.否则,产生一个新的交互模式S,转向步4.下面对这个算法的时间复杂度和空间复杂度进行分析.首先我们假定一个指定系统交互历史在线跟踪机制所捕获的交互动作的类型数为m,当前交互动作序列的长度为n.算法在每次交互动作发生时,将新的交互动作加入到交互动作序列中,形成交互动作序列模式,假设新交互动作所在序列的总长度为p的话,则p的最大值为交互动作的类型数为m.因此,算法的时间复杂度为O(m).交互动作序列模式采用Tried树数据结构存储,Tried树的最大深度为交互动作序列的总长度n.Tried树每个结点的最多子树数为m,Tried结点最多是每个交互动作子序列在Tried树只出现一次.因此,Tried树中的最大结点数为当前交互动作子序列数.在动作序列模式构建过程中,将长度为n的交互动作序列构建为交互历史模型,最简单的情况是交互动作序列为一个线性序列,此时当前交互动作子序列数为n(n+1)/2.因此,交互动作序列模式构建算法的空间复杂度为O(n2).6.2交互动作预测在构建用户动作模式基础上,对用户下一步要执行的动作进行预测.预测用户下一步动作的方法有多种.例如,可以找出交互上下文下一个最大可能性动作,也可以找出最大长度匹配序列的动作预测等等.本文采用综合计算最大匹配长度和最大发生概率的折中方法.算法思想是:与当前动作序列匹配长度和待发生动作发生概率最大的序列,对应的待发生动作即为预测的动作.在当前交互上下文环境下,已有动作序列从当前动作开始逐步向后递增序列长度,和模式库中的模式匹配,取得所有预测动作候选集合C.每个候选预测动作在每次序列匹配时,动作发生评价Rt取最大时的匹配序列长度.最后从候选集合中取出最大Rt的预测动作为预测结果.为了提高预测效果,减少预测错误,规定一个动作发生评价阈值Rth.若Rt大于Rth,则预测有效,否则不作预测.具体算法见算法2.算法2.交互动作预测算法.输入:当前交互动作序列输出:预测的交互动作算法过程:1.取长度L为1的当前交互动作序列S,使用此序列在交互模式库中查找,计算所有匹配序列中的下一个动作发生评价R,计算得到交互动作初始预测集C={〈Ci,Ri,i〉|i∈[1,L]}.2.假定最大模式长度为N,M=min(L,N),如果L>M,转向步4,否则转向步3.3.当前交互动作序列长度L=L+1,沿着当前交互动作序列反向读取上一个动作,形成新的长度为L的当前交互动作序列.依次取出预测集C中交互动作Ci,置在长度为L的当前交互动作序列后,形成新的长度为L+1的动作序Page9列Si.在模式库中查找,计算所有Ci的动作发生评价Ri.如果i(Ri>Ri∧i∈[1,L]),则更新C集合对应的动作评价和序列长度,转向步2.4.取出C集合中最大Rmax,及对应预测动作Cmax,如果Rmax<Rth,则Cmax=NULL,表示不作预测.列模式库和信息库,算法结束.5.最后的Cmax为最终预测的交互动作,并更新动作序交互动作预测算法采用当前交互动作序列从当前交互动作逐步回溯增长匹配长度,在交互动作序列模式库中查找,并将得到的候选预测动作集合逐步评价后取最佳的预测动作.算法的执行次数与最大模式长度和模式库长度成正比.设定交互动作序列模式最大长度为N,交互动作序列模式数为m,因最大模式长度不变,逐步递增匹配长度计算数量级为O(1),而系统采用每次到序列模式库中查找,则每次模式查找时间复杂度为O(m),因此交互动作预测算法时间复杂度为O(m).7建模方法针对上述自适应用户界面模型,本节重点介绍该模型的构建方法和步骤.自适应界面模型建模方法是从抽象模型到具体模型逐步构建的过程.用户模型是建立一个良好的自适应界面模型的基础.以此模型为出发点,提取领域内的信息,形成领域模型;提取领域内的管理任务,形成任务模型;结合具体交互设备,依据领域模型元素和任务模型中的命令集合,设计平台设备上的可视组件对象,形成表示模型;根据任务模型中的任务功能集合,设计合适的交互原语和命令集合,形成交互模型;自适应策略模型是系统从表示模型和交互模型中自动构建的,如图5所示.具体过程如下:(1)建立良好的用户模型第1步是明确用户的个性特征(Personality),对Personality给出定义并进行描述.即用户习惯左手还是右手操作;用户对色彩、字体等的偏好.用户偏好可以为设计表示模型对象提供帮助,例如对象的布局、颜色、大小等.第2步明确用户角色,对用户所在的应用中所处角色进行分类描述.即用户是管理员,还是超级用户或者其它角色.按照角色不同分配可执行的交互任务、可查看的领域信息和改写的领域信息等.第3步,因用户经验是系统自动记录交互历史,不需要手动建模.(2)从用户模型到领域模型设计人员在建立领域模型时,需要从用户模型出发,列举出待管理的实体对象,分析各实体对象的属性,然后将若干相关属性组织在一起整理化简,定义为实体(Entity),并把一个实体的属性来源于另一个实体的属性定为关系(RL),选择合适的名称进行命名,直到所有的领域信息用实体联系模型描述完成.例如虚拟家居定制系统中的家居管理,家居实体由家居序号、名称、类别、2D示意图、3D示意图、价格和说明等属性组成,家居类别实体是由类别号、类别名称和父类别等属性组成,两个实体之间存在一个关系,即家居实体中的类别来源于家居类别实体中的类别号属性.(4)从用户模型、领域模型到表示模型设计表示模型首先需要明确界面中的可视组件对象,包括交互对象和应用对象,根据用户模型可显示的领域模型元素选择应用对象,根据用户可实现的交互任务选择交互对象.进而明确对象属性,根据用户模型中的用户偏好,设计应用对象、交互对象的(3)从用户模型到任务模型用户模型中的角色已定义了该角色下可执行的任务.在设计任务模型时,每个交互动作对应一个任务,例如界面的切换、可视对象的创建、数据的保存等.在建立任务模型时,根据上下文信息,定义用户需要完成的交互任务,定义功能集.以PC机上用笔装饰衣柜侧面的任务为例.用户模型中对该场景的描述为MS=〈(Goal1,Goal2),(E1,E2)〉,Goal1=〈PC,IC1,Pen〉,其中IC1=〈Tools,OpTime,Decorating〉;Goal2=〈PC,IC2,Pen〉.其中IC2=〈Bureau,OpTime,Decorated〉,(E1,E2)=(Tap,Tap).对应的任务模型中的任务定义为Task=〈AT1,AT2〉,AT1=〈Tap,Tools,R,IC0,Select,IC1〉,IC0=〈Tools,OpTime,Null〉,其中,R=〈Rbureau,Rtexture〉,IC1和IC2定义同上.AT2=〈Tap,Bureau,IC1,Decorate,IC2〉.Select与Decorate是抽象的功能描述.Page10外观属性,例如用户对色彩的选择、字体的要求、界面的布局等.(5)从任务模型和表示模型到交互模型交互模型的构建主要是对交互上下文环境进行描述:包括交互设备、交互原语、命令、应用反馈以及系统反馈.具体来说,就是根据任务模型中每个任务的事件集合,描述在用户界面中的要执行任务的原子操作(如单击、双击等等);结合上下文,描述出对应表示模型中交互对象的命令(如激活、删除);根据任务模型中任务上下文描述应用反馈;根据系统需要描述系统反馈.(6)从表示模型和交互模型到策略模型策略模型是系统自动构建的.系统结合上下文环境,自动将来自交互模型的交互原语信息构建成策略模型中的原子操作事件,执行交互任务后自动记录系统所处的状态等等.8应用实例我们采用VC++开发工具和Direct3D渲染引擎,利用SQLServer2005数据库开发了一个家居设计定制系统Decorator1.0.该系统定位在房地产售楼、室内装修、家居销售等行业,以直观、快速、自然地实现家居装修方案的设计为主要目标,通过笔交互、三维造型、三维真实感图形渲染和实时漫游等技术,使客户能很容易地参与到自己家居的设计过程中.面向虚拟家居设计展示系统主要分为两大模块.第一部分是针对三维可见有形体的操作,这类交互任务在符合客观世界物理规律的虚拟环境中完成.图6为演示实例.第二部分是对各种非有形信息的操作与处理,即对海量的虚拟家居设计方案的数据信息的操作与处理.该部分针对最终需要完成信息洞察、综合分析得出结论等任务的用户,包括可视组件分析界面和交互历史模块两大模块.可视组件分析界面展示了配置好的可视分析组件集,并提供了丰富的可视组件及可视组件之间的交互操作,主要包括图元操作、数值操作、视图操作和内容操作.交互历史模块实现了交互历史在线跟踪机制,监测用户的交互操作,构建用户的交互历史库,并提供给用户交互历史导航界面及历史知识注释界面,同时实现了基于交互历史的自适应布局机制和基于动作预测方法的可视分析状态推荐界面.交互历史在线跟踪机制监测用户的交互动作,添加可视分析状态到交互历史库中,并同步更新交互历史可视化界面.交互历史可视化导航界面允许用户做任意的回溯操作,回溯到任意的先前分析状态,并通过注释操作添加中间的分析结论和分析思路.自适应布局则融合在可视组件分析界面中,设计了聚焦布局工具以便于完成自适应布局.可视分析状态推荐融合在交互历史导航界面中,通过预测状态工具可以弹出可视分析状态推荐界面.图7为经过自适应布局的可视分析界面,图8为用户经验可视化界面.下面以复用三维装饰室内家居方案为例,分析基于用户经验的自适应界面的推荐过程.在家居定制的实践中发现,选用同类家具的用户希望推荐最常用的室内环境装饰风格,也就是说一定类型的家Page11具与一定的室内环境存在一定的关联性.因此,根据所选家具选用多数用户共同喜好风格的装饰方案提供给当前用户,是一项常见的交互活动.为客户推荐常用装饰方案的交互过程往往相同,一般过程如下:选中室内家具,过滤已有方案,点击最常用方案,放大方案效果图,确认推荐方案.如用数字笔为用户Tom提供客厅装饰过程,其动作序列历史描述为{〈1,‘Tom’,Sofa,Select,time1,null〉、〈2,‘Tom’,Sofa,Search,time2,schemeList1〉、〈3,‘Tom’,scheme1,Select,time3,targetGraph1〉、〈4,‘Tom’,targetGraph1,Resize,time4,null〉、〈5,‘Tom’,scheme1,Select,time5,null〉}.后4个交互动作作为序列常常紧随第一个交互动作之后,具有自适应的价值.系统把整个交互动作序列作为潜在模式记录下来.当再次发现该序列模式时,就不断提高该模式的自适应评价指标.经过一段时间后,当评价达到一定的阈值时,再次选中家具后,就直接提供最常用方案的推荐结果,从而大大减少用户的交互工作量.由上面例子分析可知,系统在学习用户的交互历史经验后,能根据所处上下文环境准确预测用户的意图,智能地提供用户自适应界面,从而减少用户的交互步骤,提高用户的交互效率和体验.9实例评估为了验证本文研究结果,本文针对Decorator1.0设计了一组实验,目标在于考察基于经验感知的自适应用户界面的易用性和易学性.在实验过程中,选择了六位设计人员作为被试,其中3名被试具有较高的计算机操作水平(用A、B、C表示),另外3名被试(用D、E、F表示)只具备一般的计算机操作能力,属于非专业用户.实验任务要求每一位被试利用Decorator原型系统在规定时间内先后完成两个简单方案的设计(用T1和T2表示).用工具Design-MyRoom重复做一个相同的方案(用T1表示).在实验开始阶段,首先要求被试人员花费15~20min熟悉Decorator和DesignMyRoom系统与任务描述.在实验过程中,记录被试人员每个子任务的操作完成时间及总任务的完成时间;根据交互动作历史记录,标注所有回溯操作,并统计总任务的回溯总次数;统计用户在实验过程中的操作失误总次数,如表1所示.实验结束,每一个被试者完成问卷调查,问卷包括6个评估维度,评分范围为1分~10分.评估结果如图9所示.TesteeTaskTimespent/minBackTrackingtimesErrortimesABCDEF由表1可以看出,专业人员做第一方案时通常需花费24.7min,在做第二个方案时花费时间可缩短至20.3min;非专业用户在做第一方案时需花费较长的时间,平均都在35min以上,做第二个方案时,花费时间大大减少到29.7min;而且对所有被试者而言做第二个方案时,相比第一个方案,回溯次数由平均7.3次降至4.6次,错误次数由平均6.3次降至3.8次;当重新用DesignMyRoom做一个相同方案时,所有被试者的平均花费时间高达35min,回溯次数平均达10.8次,错误次数平均达9.7次.图9表示除了可靠性外,其它各项指标都比用传统设计较高,且有几个指标都明显高于传统界面设计.由此得出结论:(1)用户在熟悉系统一段时间后,不管是专业用户还是非专业用户,完成任务所需花费的时间有所减少,尤其是非专业用户所花时间减少更显著,表明该系统能够主动学习用户经验,更智能地适应用户,交互过程更加自然流畅;(2)交互历史库的构建对用户交互任务的执行具有有效的辅助作用.基于交互历史分析的自适应虚拟家居定制系统能够减少用户的交互操作,改善家居设计活动的用户体验,并在一定程度上提高了工作效率.另外,系统的可靠性还有待在未来进一步提高.Page1210结论本文研究基于认知理论的用户模型.在此基础上,提出了一个基于经验感知的自适应用户界面模型,从静态组成元素、动态交互行为和界面自适应策略三个方面对自适应界面进行分析和描述.然后提供了该模型的实现架构以及关键实现技术,给出了自适应界面模型的建模方法.最后,以虚拟家居定制为背景,给出一个自适应界面原型及实验评价.原型及评价表明,本文提出的自适应用户界面模型与传统自适应界面模型相比,具有以下优点:(1)关注用户的交互历史经验,为自适应界面自主学习用户经验和智能地适应用户奠定基础;(2)结合用户交互上下文,为用户提供更自然流畅的交互方式和交互次序;(3)基于用户经验的交互动作预测方法能够从用户经历中发掘用户的交互动作模式,有助于提高界面自适应效果,减少用户认知负担和交互行为;(4)注重序列匹配长度和动作发生频率相结合的自适应策略,大大提高自适应界面的智能程度.由于时间所限,依据该模型所构建的自适应系统尚有一些不足,自适应效果有待进一步提高.未来我们将进一步优化动作预测方法,增强动作预测效果,改进界面布局机制和交互方式,使界面自适应用户更加自然流畅.致谢向对本文提出建议的同行和审稿人表示感谢!
