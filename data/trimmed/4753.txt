Page1高阶熵压缩的全文自索引霍红卫陈晓阳陈龙刚于强(西安电子科技大学计算机学院西安710071)摘要大数据集正在以前所未有的速度产生,研制大数据集的实用压缩全文自索引是目前的挑战问题之一.该文提出了一种高阶熵压缩的全文自索引.对于长为n的文本T以及任意kclogσn-1和c<1,该压缩索引占用2nHk(T)+n+o(n)位的空间,其中Hk(T)表示文本T的k阶经验熵,σ为字符表的大小.此外,该压缩索引可在线性时间O(n)内构造.在此基础上,该文还给出了上述压缩索引的一种实用改进.这种改进引入了混合编码方法,额外的空间开销为o(n)位.对于Pizza&ChiliCorpus上的三类典型数据的实验表明:该文的压缩索引较之主流压缩索引在压缩率和查询时间上具有显著的优势.该文所述的压缩索引软件可在GitHub上访问.关键词大数据;压缩索引;自索引;高阶熵;混合编码1引言大数据正以前所未有的速度产生.现实世界的数据源如WWW数据、社交网络、基因组数据、音乐Page2传感网和物联网的蓬勃发展是大数据的又一推动力,各个城市的视频监控每时每刻都在采集巨量的流媒体数据.大数据的不断激增为数据存储、管理、检索和从数据中搜索可用信息提出了新的挑战[2].Gartner提出了大数据的3个主要特征[1]:海量(Volume)、多样性(Variety)及速度(Velocity).海量是指数据量大,使用传统基础设施进行处理的难度变大.多样性是指数据类型、表现形式和语义解释的异质性.过去的数据更多的是结构化的数据.现在越来越多的数据是半结构数据,甚至是完全没有结构的数据.据IBM大数据的报告,2013年世界上的数据量大约是1.6ZB.在这1.6ZB的数据中,约80%的数据是无结构的数据,因而,存在很多数据源是传统技术不能管理或分析的.速度有两层含义:一是数据到达的速率;另一个是必须对数据处理的速率.模式匹配是理论计算机科学最古老的研究领域之一[3-4],是理论领域为许多应用领域提供切实可行解决方案的典范.从KMP算法[3](几乎所有算法教科书中最重要的内容之一)到Boyer-Moore算法[4](所有文本编辑器中搜索命令的核心),由于其在信息检索、Web数据挖掘、计算生物学和图像处理等领域的应用,一直得到广泛关注.模式识别从一开始就是设法解决大型异质数据集的搜索问题.如果是在一个小型的文件中搜索某个特定的单词,是不需要什么特殊算法的.然而,如果要在人类基因组中查找某个基因,而基因组中没有单词分隔界限,而且数据规模和搜索的模式都很大,那么理解如何重用扫描过的数据就变得至关重要.因此,上述的KMP算法[3]和Boyer-Moore算法[4]的重要性就体现出来了.在出现更为复杂的问题时,例如,给定一个大型非文本数据库(如数值数据、音频数据或生物序列),我们能够索引它并能快速回答搜索查询吗?正是因为这个问题,所以发明了后缀树[5-6]和后缀数组[7]这样的数据结构.虽然后缀数组和后缀树均能在最优或几乎最优时间内支持模式匹配查询,但对于输入规模为n的文本T,它们使用O(n)字的空间,即O(nlogn)①位.在空间复杂度方面,这个大小要比文本T自身的大小O(nlogσ)位要大得多,其中σ为字符表的大小,且在实际中这些数据结构所占空间为原文本的5~20倍[2].1.1已有相关研究工作压缩后缀数组[8-13](CompressedSuffixArray,CSA)和FM-Index[14-16]利用了文本的可压缩性和规则性,克服了空间上的局限性,同时能支持后缀数组和后缀树的功能.压缩后缀数组和FM-Index是不需要原始文本的自索引(self-indexing),也就是说,它们既能作为压缩的原始文本,也能作为索引,原始文本可以抛弃.从实际的角度来看,这是首次获得的模式匹配的空间高效的压缩索引方法.此外,这些索引技术在空间和时间上还能与搜索引擎中所使用的著名的倒排索引(invertedindexes)技术[17-18]相媲美.因为倒排索引是一种词索引技术,适合做关键字搜索,不适合短语搜索;如果用倒排索引进行短语搜索效率不高[19],因而这些索引则提供了更为一般的搜索能力.Grossi和Vitter[8-9]首次建立了压缩后缀数组理论(CompressedSuffixArray,CSA),使用O(nlogσ)位的空间,可在o(m/logσn+occlogσn)时间内支持模式匹配查询,其中m为模式P的长度,occ表示P在文本中出现的次数.在Grossi和Vitter[8-9]的CSA中,后缀数组的值间接编码,以Φ函数(又称近邻函数[8-9])存储,其中Φ(i)=SA-1[SA[i]+1].Φ函数可压缩为熵含义下的最优空间,每个SA的值可在O(polylogn)时间使用Φ函数的一小部分值计算出.Sadakane[12-13]给出了将Grossi和Vitter的CSA变为自索引的方法,该索引使用(1/)nH0+O(nloglogσ)+σlogσ位的空间,可在O(mlogn+occlogn)时间内支持模式匹配查询.Ferragina和Manzini[14-15]提出了基于BWT(Burrows-WheelerTransform)变换[20]的FM-Index.其索引至多使用5nHk+o(nlogσ)位的空间,klogσ(n/logn)-ω(1),可在O(m+occlog1+n)时间内检索P在文本T中的出现次数occ,其中0<<1,Hk表示文本T的k阶经验熵,k0.Grossi等人[10]提出了理论上可证明达到渐近空间最优性的第1个自索引,即高阶项前的系数为常数1.该自索引使用nHk+o(n)位的空间,达到了O(mlogσ+polylogn)的查询时间.同样的分析也适用于FM-Index,因而FM-Indx也达到了这样的最优性.Foschini等人[21]给出了压缩后缀数组的一种新的存储结构,空间达到了熵界;他们的方法不仅保持了以往工作理论上的性能,且在实际中显示了良好的结果.Krkkinen和Puglisi[22]提出了一种固定块压缩提升技术,类似于上下文块提升技术,将BWT变换分成固定大小的块,而不是按照字符表①本文中不特别指明情况下,对数都以2为底.Page3的分块.虽然这种划分不是最优的,但他们表明了这种技术不会比最优划分差很多.这种对BWT变换L进行固定块划分的技术,其数据结构较为简洁、快速.Mkinen等人[23]提出了一种针对高度重复序列的压缩自索引,称为RLCSA.他们提出了后缀数组采样的一种新策略.实验结果表明RLCSA对于高度重复DNA序列如酵母序列表现出了良好的性能.Huo等人[24]提出了表示CSA的近邻函数Φ的一种新结构,理论上空间保持了高阶熵,设计了一种查找表支持快速解码.Ferragina等人[25]从实践角度将已有索引进行了实现,并做了对比.Navarro和Mkinen[26]综述了这方面的成果.Gog和Navarro[27]扩展了CSA的模式定位功能.Gog和Petri[28]实现了一个包含GGV-CSA和FM-Index的简明数据结构库.1.2本文的贡献本文提出了一种基于压缩后缀数组(Com-pressedSuffixArray,CSA)的高阶熵压缩的全文自索引.对于长为n的文本T,我们的压缩索引可在线性时间内构造.对于任意kclogσn-1和c<1,我们的压缩索引占用2nHk+n+o(n)位的空间,其中Hk表示文本T的k阶熵,σ为字符表的大小.此外,本文还给出了上述描述的压缩索引的一种实用改进,称之为ACSA(AdaptiveCSA).这种实用改进引入了混合编码方法,额外的空间开销为o(n)位.对于PizzaChiliCorpus上的三类典型数据的实验表明,我们的压缩索引较之主流压缩索引在压缩率和查询时间上具有显著的优势.所开发的压缩索引可在GitHub上访问:https://github.com/chenlonggang/Compressed-Suffix-Array和https://github.com/chenlonggang/Adaptive-CSA.2预备知识2.1问题定义和符号含义文本索引问题:给定大小为n的文本T,其中字符取自大小为σ的字符表Σ.文本索引的目标是构建T的一个索引,使得对于任一查询模式P,能够高效地确定P是否在T中出现.对于具体应用问题,我们可能希望确定模式P在T中的出现次数occ;或者定位模式P在T中出现的所有位置;或者展示文本T的子串T[s,s+len-1],给定子串起始位置s和长度len.在压缩空间,本文索引的目标是构建空间占用逼近文本熵压缩大小的压缩索引,同时支持快速查询性能.表1中给出了本文中使用的符号及含义.符号T文本Tn文本T的长度P模式Pm模式P的长度Σ字符表{α1,…,ασ}σ字符表的大小Σk定义在字符表Σ上长为k的串集SAT的后缀数组(suffixarray)T[i]T中第i个字符T[i..n]T的第i个后缀,1inSA[i]第i个字典序最小后缀在T中的起始位置SA-1[i]后缀T[i..n]的排名.称SA-1为逆后缀数组CSA压缩后缀数组(CompressedSuffixArray)Φ(i)近邻函数,满足Φ(i)=j,ifSA[j]=(SA[i]+1)modnx-list以x开始的所有后缀位置的一个递增序列Hk(T)T的k阶经验熵,简称k阶熵ni字符i在T中出现的次数wsk-contextT中后缀的长为k的前缀C[x]T中所有小于x的字符出现次数的总和occ模式P在T中的出现次数count确定模式P在T中的出现次数locate确定模式P在T中出现的所有位置extract返回T[start..start+len-1],给定start和lenpolylognn的对数多项式2.2后缀数组令T[1..n]为长度为n的文本,其中字符取自大小为σ的字符表Σ.形如T[i..n]的T的子串(i=1,2,…,n)称为T的后缀.后缀数组(suffixarray)SA[1..n]是n个元素的整型数组,SA[i]=j表示第i个字典序最小的后缀在T中的起始位置为j.类似地,我们可以定义逆后缀数组:SA-1[i]=j,表示后缀T[i..n]的排名为j,即T中由i起始的后缀的排名为j.如果模式P出现在文本T中,那么存在整数L和R(LR),满足SA[L],SA[L+1],…,SA[R]存储了P在T中出现的所有位置.2.3压缩后缀数组Grossi&Vitter(GV-CSA)压缩后缀数组[8-10]解决了后缀数组作为索引时空间占用过大的问题,其核心是如何高效地表示近邻函数Φ[8-10],定义如下:Φ(i)=j,ifSA[j]=(SA[i]+1)modn(1)Φ函数将SA中的某个位置i(满足SA[i]=p)映射到另一个位置j(满足SA[j]=p+1),其核心在于把当前位置和下一个位置联系起来,不仅利用了上下文信息,且有利于压缩,又提供了通过Φ函数访问整个文本串的能力,从而提供了检索和数据Page4恢复的能力.Grossi等人[10](GGV-CSA)所提出的达到渐近空间最优性的压缩自索引引入了Σ-list的概念(此后我们称x-list),这些x-list(x∈Σ)可对文本中的所有后缀及其关联的Φ值按照其前缀进行划分.通过对后缀指针按其长度为2k(k=0,1,i01234567891011121314151617181920212223242526272829303132333435TabfgdbfbgdfccbgacefcegcdefgbfcadbgafSA01530345271133272912112216194312391724203562810182521433262138Φ61417232425293031352711182022482126272833091012153234135131619图1后缀数组SA和近邻函数Φ2.4犽阶经验熵令T为长度为n的文本串,其中字符取自大小为σ的字符表Σ.由信息论可得,使用经验熵(empiricalentropy)可以界定存储文本T所需空间的下界.经验熵类似于概率意义上所定义的熵,不同之处在于经验熵是根据所观察到的T中字符频率来定义的,而不是由字符概率来定义的.可用经验熵来度量一个压缩算法的性能,它是文本串结构的一个函数,不对输入做任何假设.文本串T的0阶经验熵定义为[29]其中:ni是字符i在T中出现的次数,∑inH0(T)表示理想压缩器的输出大小,该压缩器使用-logni()n位对字符表Σ中的符号进行编码.这是使用唯一可解码编码所能达到的最大压缩率,其中字符表中的每个字符被赋以一个固定的码字.如果用于每个字符的码字依赖于其在T中的前k个字符,那么还可以达到更好的压缩率.对于长为k的串w∈Σk,令ws是连接w在T中每次出现之后的字符所形成的串.|ws|是该串的长度.T的k阶经验熵定义为[29]值nHk(T)表示如果使用的编码依赖于前k个最近所见的符号,所能达到压缩率的下界.注意,对于任意串和k0,有Hk+1(T)Hk(T)logσ.1阶经验熵如下计算:H0(T)=-(1/4)log(1/4)-(1/4)log(1/4)-例如,对于T=abcdabcdabcd,其0阶经验熵和2,…)的前缀进行划分,可得这些x-list.这些x-list的简单连接恰好为近邻函数值.每个x-list形成关于文本位置的一个递增序列,如图1所示.其中标示出了a-list和c-list.因此,如果对递增序列的间隔长度进行编码,就能实现对文本的压缩.=(1/4)H0(bbb)+(1/4)H0(ccc)+上例T的所有高阶熵均为0.这表明如果我们随机均匀地从T中选择一个字符来猜测,其不确定性为2.如果猜测之前我们知道其前一个字符,那么可以肯定结果答案.在一般情况下,对于给定的文本串T,存在N,满足对于kN,有Hk(T)=0.3压缩后缀数组的存储结构3.1Φ的简明表示为了方便叙述起见,我们根据上下文交替使用Φ()函数和Φ[]数组这两种形式.GGV_CSA[10]是一种多层递归结构,按照k-context[10]对Φ进行划分,达到了文本的高阶熵,且最高项系数为1.我们在这一理论的基础上,考虑实际,对此进行简化,并结合后向查找过程,提出了一种相对简明、易实现的单层CSA结构,同时空间上保持了理论上的高阶熵.我们的结构采用两层模式:一层是超块(superblock,SB),另一层是块(block,B).过程如下:(1)首先把长为n的Φ数组分为长为a=(logn)2(2)其次把每个超块分成a/b个块,每个块包含的超块,故共有n/a个超块.b个整数,b=(logn)2/loglogn.(3)最后对每个块内的整数序列做差分,对差分后的每个差值进行EliasGamma编码[30],连接起来即得到Φ数组的表示,记为S.但我们必须处理一种特殊情形.假设x表示前一个Φ值,y表示当前Φ值,当差值gap=y-x<0时,Gamma编码无法处理,此时令gap=y-x+n,Page5再将该gap值进行Gamma编码.这是由于(x-z)modn=(x+n-z)modn,其中x和z都是正整数.在我们的结构中,需要保存超块的偏移量表SB,块的偏移量表B,Φ的采样表SAM以及最终的Gamma编码序列S,我们用这4个结构表示Φ数组.图2给出了大小n=36的Φ数组及其表示,其中超块长度a=9,块长度b=3,超块中的块数r=3.图2中每个x-list(x∈Σ)内对应的所有后缀都具有相同的首字符,如a-list内对应的所有后缀都具有相同的首字符a.每个x-list内的Φ值呈升序i01234567891011121314151617181920212223242526272829303132333435Φ61417232425293031352711182022482126272833091012153234135131619gap08301101103507201840510530120172022033S00010000111111011001010011101000001001000100001011001010111010000010001010010010011011SBB010120816061401218SAM623293511222128915113图2Φ的表示(n=36,a=9,r=3,b=3)EliasGamma编码[30]是一种前缀无关码,因此解码是唯一的.理论上,对于一个大小为x的整数应用Gamma编码,需要2logx+1位表示这个整数.Gamma编码由两部分组成,前一部分是logx个0,后一部分是x的二进制表示,使用logx+1位.解码时从左到右数出连续0的个数,不妨设为c个,然后解码c+1位即得x.例如:gap=8,log8=3,表示前一部分含有3个0,由于8的二进制表示为1000,即后一部分为1000,因此8的Gamma编码为0001000.解码时,从左到右数出连续0的个数,为3,然后解码c+1=3+1=4位,即得8.SB表示每个超块在编码序列S中的偏移位置,例如,上表中的第2个超块的第2个差值3(因为每块中的第1个Φ值会被采样,不需要保存在S中)的编码在S中的偏移为14,所以SB[1]=14.B中保存的是块中第2个差值(即每个块内之后的那个数)的偏移量,这个偏移量是相对于该块所在超块的相对偏移量,如第5个块是在第2个超块中,且相对偏移量为8,所以B[4]=8.上表中的SAM数组保存的是每个块中的第1个数的值,即Φ的采样值.如果要访问Φ(i),就要进行解码.解码过程是首先查询SB和B结构后确定所属块在S中的位置,然后解码S序列,加上相应的采样值SAM,即可得到Φ值.Φ(i)的表示如下:排列,但不同的x-list之间不存在这种关系.表中的gap数组是各个块内求差分后的值,每个块内的第1个数会被采样,所以没有与之对应的“差值”,表中这些位置标记为0,实际编码的gap序列不包含块中的这些0.需要注意的是第4、6、8个块,因为这些块中的3个整数分属两个x-list,所以出现了差分后为负值的情况,此时gap=Φ[i]-Φ[i-1]+n,对于本例,第4个块的gap=2-35+36=3,所以该gap编码为011,对于第6个块,gap=4-22+36=18,因而对应的编码为000010010.Φ(i)=(SAM[i/b]+decompress(S,SB[i/a]+其中a为超块长度,b为块长度.decompress过程完成在Gamma编码序列S上的解码,解码的起始位置由SB[i/a]+B[i/b]确定,即第i个值所属块的起始位置.imodb为要解码的次数,最后将解码值与第1项SAM[i/b]相加得到Φ(i)值.对于图2示例,如果要求Φ(11),首先求得SAM[11/b]=SAM[11/3]=35,又由于SB[11/a]+B[11/b]=SB[11/9]+B[11/3]=SB[1]+B[3]=14,即解码起始位置为14,且11mod3=2,所以从S表中的第14个位置开始解码,连续解码2次和SAM[3]累加即可,S表中第14个位置解码第1次得到3,第2次解码得5,因此Φ(11)=(35+3+5)mod36=7.如果要求Φ(25),首先求得SAM[25/b]=SAM[25/3]=9,又由于SB[25/a]+B[25/b]=SB[25/9]+B[25/3]=SB[2]+B[8]=58,即解码起始位置为58,且25mod3=1,所以从S表中的第58个位置开始解码,解码1次和SAM[8]累加即可,S表中第58个位置解码1次得到1,因此Φ(25)=(9+1)mod36=10.3.2空间占用令gj为x-list内第j个gap的长度,nx为该表中的元素数.由x-list的定义可知,nx恰好为字符xPage6在文本T中出现的次数.我们使用EliasGamma对gj=Φ(j+1)-Φ(j)进行编码,该编码长度包含2gj+1位.因此,该表内的gap总长度为所需要的总编码位数至多为∑nx-1Φ(j))+1)位,最坏情况下为2nxlog(n/nx)+nx位,其中nx=n-1.对所有表上的gap编码位数求和,可得∑x∈Σ2nxlogn/n()x+n其中n=n-σ,σ为字符表Σ的大小.使用文献[21]中的方法,对表内gap编码进行更为细致的分析,可得更好的一个空间上界.令Φ(i)的k-context表示T[SA[Φ(i)]]长为k的前缀.按照k-context划分,每个x-list可被划分为至多σk个子表,由此可见,∑log(Φ(j+1)-Φ(j))nHk,其中求和取自同一表内及同一k-context内的所有gap.不在同一k-context内的gap数目至多为σk+1.同一k-context内的所有gap的编码总长度为2nHk+n,其他gap的编码总长度为2σk+1logn.值得一提的是,我们的结果对于任何k都成立.然而,我们还需要处理一种情况,那就是有些gap(每块中的第1个)是不需要编码的,因为它们已被采样,这部分的编码大小可以去掉.这些gap所占总空间至多为(n/b)(2loggi+1)=o(n),因为b=(logn)2/loglogn.现在考虑结构SB,B和SAM所占空间.每个超块的起始位置至多为|S|=O((n/b)(lognH)),其中H是编码每符号的平均位数;而每块在其超块内的相对位置至多为O((logn)2).我们还需存储O(n/b)=O(n/((logn)2/loglogn))个Φ值采样,每个值需要logn位.因此,结构SB,B和SAM所占总空间为O((n/a)log|S|+(n/b)log|b|+(n/b)logn)位.将a=(logn)2和b=(logn)2/loglogn代入,可得这3个结构所占总空间为(On(logn)2log()nH+nloglog()n将以上各部分所占空间加起来,可得总空间界为2nHk+n+2σk+1logn+o(n)位.定理1.对于任意kclogσn-1及常数c<1,Φ的简明表示所占空间为2nHk+n+o(n)位,其中Hk表示文本T的k阶经验熵.3.3加速Φ值访问给定编码序列S及解码位置p.对于大小为O(logn)的块,最坏情况下需要O(logn)时间访问Φ.通过维持一个宽度为W=O(logn/2)的表R(如表2所示),可在几乎常量时间内访问Φ.表R由四部分组成,分别记为R1、R2、R3和R4.R1用来快速确定宽度为W的位串中从左端起连续出现的0的个数.R2表示宽度为W的位串中可以完整解码的gap数目.R3表示该宽度为W的位串可以正确解码的位数.R4表示可以正确解码(gap)值的累加和,这与我们用差值保存Φ是对应的,直接保存累加值,省掉了累加的过程.例如,对于表2中的第1行,16位全是0,所以R1列值为16,该16位串一个gap都解码不出来,所以R2列为0,R3、R4列也就都为0.该表中的第6行的位串0010101110100110,可以完整解码的gap数目为5,所以R2=5.这些gap所对应的解码位数之和为15,故R3=15,解码gap值总和R4=14,所剩1位是不可解码的.0000000000000000160000000000000000001150000000000111111110711525500101011101001102515140010110010101110251515101010100111100107131111111111111111110161616可用2WlogW位存储每个Ri(i=1,2,3)表,因为每个Ri表中的元素在[1,W]中取整数值,因而每个元素可用logW位表示.代入W=logn/2,可得这3个表所占总空间为3槡n(loglogn-1)位.类似分析可得R4所占空间为(1/4)槡nlogn位,因为R4至多有2W/2个元素,每个元素至多用logn表示.因此,R表所需总空间为3槡n(loglogn-1)+(1/4)槡nlogn=o(n)位.利用R表,可以加速Φ(i)值的获取.设i表示需要解码的次数,temp表示某次查找表可以解码的Gamma编码数(即可以解码的gap数),num表示已经解码的编码个数,则获取Φ的过程如下:(1)读取SAM、SB和B,得到采样值和偏移量.Page7(2)读取W位,用查找表解码,temp为本次可以解码的Gamma编码数,更新num=num+temp,如果num<i,重复该步,否则,后退一步,抛弃本次解码值,转到步(3).(3)由步(2)的结束位置开始,顺序解码,每解码一次,num自增,直至num=i为止,此时返回解码值的累加和.假设待解码序列为S,当前位置为p,需要连续解码10次,则利用查找表的解码过程如下:获取S序列的前W(W=16)位,不妨说1010101001111001,查表R2,发现该16位串可以解码7个数(gap),即该16位串包含7个完整的Gamma编码,查表R4,得到对应解码(gap)的累加值,即11,查表R3得到正确解码的位数,即这7个完整Gamma编码的解码位数总和为13位,所以本次查表解码7个数,累加值为11,正确解码的位数为13.下一次从p+13位置开始,再解码10-7=3次,继续累加即可,新的16位串为0010101110100110,查表R2,该串可以解码5个数,大于剩余解码次数3,则结合R1表,按照步3,顺序解码3次,分别得到5,3,1,与gap当前累加值累加,得到decompress(S,p,10)=20,则一个完整的decompress操作完成.3.4字符频数统计统计字符频数是为了支持自索引.按照字典序,C[x]表示原文本T中所有小于x的字符出现次数总和,C[x]的实际含义为:第1次以字符x打头的后缀的排名.表3给出了图1中文本T的C值.为了方便,我们在字符频数统计表的最后一个位置增添一项,填入n值.abcdefg04101620233036利用C表和Φ的表示结构,可以恢复SA[i]对应的后缀T[SA[i]..n-1],因此T可以丢弃.对于i=j,Φ[j],Φ[Φ[j]]…,后缀T[SA[i]..n-1]的第1个字符T[SA[i]]在SA中是连续且字符表有序的.因而T[SA[i]]必定为满足C[c]<iC[c+1]的字符.因此我们可以首先对i在C上做二分查找,确定i所属的字符区间,然后利用以下的incode表,就可以恢复出首字符,然后改变i为Φ[i],重复上述过程,即可恢复后缀T[SA[i]..n-1].字符重映射的含义为:假设T中出现了σ个不同的字符,按照其ASCII编码排序这σ个字符,由小到大重映射为0~σ-1,即编码为0~σ-1.在需要时,也需要把0~σ-1之内的数字编码值再映射回原字符.这两个映射可以使用大小分别为256和σ的数组完成.以图1为例,假设code表完成由字符到编码的映射,incode表完成由编码到字符的映射,表4和表5分别给出了这两个映射的实例.字符0…abcdefg…255编码……0123456……编码0123456字符a4索引构造我们可在O(n)的时间内完成压缩后缀数组构造(不包括计算后缀数组的时间),主要由4步组成.步1(预处理).读取原文件T,计算字符频数统计表C,计算SA.步2(构造Φ数组).利用表C、SA、T计算Φ值,删除T.步3(采样SA&SA-1).采样SA和SA-1数组,保存采样值,删除SA.步4(编码Φ).采样、编码Φ数组,即用图1中的S、SB、B和SAM结构保存Φ数组,完成之后,删除Φ数组.4.1构造近邻函数Φ读取源文件,完成统计工作,必要时过滤非法字符,创建字符统计表C、字符映射表code、重映射表incode,计算SA等都可以在这一步完成.算法constructPhi给出了近邻函数Φ的构造过程.算法1.constructPhi.输入:C,SA,T输出:Φ1.temp←C[lastchar]2.FORi←0ton-1DO3.pos←SA[i]4.IFpos=0THEN5.h←i6.ELSE7.c←T[pos-1]8.Φ[C[c]]←i9.C[c]←C[c]+110.Φ[temp]←h11.RETURNΦPage8算法计算公式(1)中定义的Φ值.第1行记录后缀T[n-1](lastchar是T的最后一个字符)的排名,保存在temp中,即SA[temp]=n-1.算法的第4、5行记录SA[i]=0时的i值,保存在h中.根据式(1),Φ[temp]=h,因为SA[h]=(SA[temp]+1)modn=0.对于图1中的示例,SA[0]=0,所以h=0,C[lastchar]=C[f]=23,故temp=23,所以Φ[23]=0.显然,该算法的时间复杂度为O(n).该算法基于以下事实:当扫描整个后缀数组时,假设此时在处理后缀SA[i]=j,如果c=T[j-1],且c是在某个后缀之前第k次出现,则c-list[k]=i,即Φ[C[c]]=i.算法第9行中C[c]每次自增,所以C[c]始终指向c-list表中第1个需要赋值的单元.在算法伪代码的描述中,我们假设数组C[]是一个局部变量.当算法constructPhi执行完时,C表值复位.4.2采样犛犃及犛犃-1被采样的后缀数组SA及逆后缀数组SA-1中的点将作为锚点(anchor)保留下来,用来恢复未采样点的值.采样过程中将产生SAl和SA-1设SA的采样步长为c,SA-1的采样步长为d,采样过程如下.算法2.samplingSA&SA-1.输入:SA,c,d输出:SAl,SA-11.k←(n-1)/c2.FORi←0tok-1DO3.SAl[i]←SA[i·c]4.FORi←0ton-1DO5.IFSA[i]modd=0THEN6.SA-17.RETURNSAlandSA-1l算法的第2~3行计算SAl,每隔c个SA值采样一个值,即保留那些下标为c的倍数的SA[i]值,SAl结构可用来支持getpos过程(第5节中描述),用于返回SA[i]的值.第4~6行计算SA-1是对逆后缀数组SA-1进行采样(利用SA与SA-1互逆的特点,所以采样时不需要SA-1的存在),用来支持extract(start,len)操作,即返回T[start..start+len-1].我们知道,对于某个已知具体排名的后缀可以方便的恢复该后缀,所以如何将位置start转换成排名i成为唯一的难点.我们可以首先确定start/d的排名i,再重复执行startmodd次i←Φ[i]即可.得到排名后,按照3.4节的方法,就可以恢复T[start..start+len-1],当然我们需要处理start+len大于n的情况.4.3编码Φ该过程主要完成S、SB、B和SAM这4个结构的初始化工作.假设超块长度为a,块长度为b,且a是b的倍数,并假设S、SB、B和SAM所需空间已经在该步的预处理阶段分配完成.算法过程如下.算法3.codingPhi.输入:Φ输出:S,SB,B,SAM1.Initializeindex1,index2,index3,len1,len2tobe02.FORi←0ton-1DO3.IFimoda=0THEN4.len2←len15.SB[index3]←len26.index3←index3+17.IFimodb=0THEN8.SAM[index1]←Φ[i]9.index1←index1+110.B[index2]←len1-len211.index2←index2+112.pre←Φ[i]13.ELSE14.gap←Φ[i]-pre15.IFgap<0THEN16.gap←gap+n17.pre←Φ[i]18.len1←len1+2bl(gap)-119.append(gap,S)20.RETURNS,SB,B,andSAM当第3行的IF条件成立时,该点就是超块的采样点,只保留采样点在Gamma编码串中的绝对偏移量,index3是该结构(超块)的下标.第7行的IF条件成立时,该点对应块的一个采样点,需要保留采样点的Φ值.第8~9行完成这一工作,也需要保存该采样点相对于所属超块采样点的偏移量,所以第10行保存len1~len2,显然len2为采样点所属超块的绝对偏移量,len1为当前S序列的长度.第12行和17行更新pre值,表示前一个Φ值.当前两个IF条件都不成立时,执行14~19行,计算差值gap,如果发生gap<0的情况,第16行修正.第18行bl(gap)表示gap的二进制码长,所以2bl(gap)-1就是gap的Gamma编码长度.第19行append操作把gap值按照Gamma编码的方式,追加到S结构上.显然,整个过程的时间复杂度为O(n).因此,索引CSA的构造过程可以在线性时间内完成,最终保存的结构为S、SB、B、SAM、SAl和Page9l结构,S、SB、B和SAM加在一起在逻辑上充SA-1当Φ数组,Φ[i]可由式(4)得到.也可以用3.3节介绍的查找表加速计算.5模式匹配5.1查找查找过程可以分为计数查询和定位查询,分别用count和locate表示.count返回模式P在T中的出现次数.本质上说,count查询确定T中以P为前缀的那些后缀的范围[L,R].一旦完成count查询,我们就能得到[L,R]中每个后缀在T中的起始位置.算法采用后向查找技术,并结合3.4节的C表,可以实现自索引.算法摆脱了基于字符串比较的查询框架,在查询的过程中,不断利用Φ数组,缩小结果范围[L,R],当迭代到模式的首字符时,SA[L,R]内的所有后缀都以P为前缀,算法描述如下.算法4.count.输入:P,Φ输出:L,R1.c←P[m-1]2.L←C[c]3.R←C[c+1]-14.FORi←m-2downto0DO5.c←P[i]6.LL←C[c]7.RR←C[c+1]-18.newL←min{j:j∈[LL,RR]&Φ[j]∈[L,R]}9.newR←max{j:j∈[LL,RR]&Φ[j]∈[L,R]}10.L←newL11.R←newR12.IFL>RTHEN13.RETURN“patterndoesnotexist”14.ELSE15.RETURNLandR其中m表示P的长度,第8~9行的含义为确定新的左右边界,该算法建立在Φ变换的实际含义和特点上.该算法由模式的最后一个字符开始,循环到模式的第1个字符结束.显然,该算法在执行过程中保持下列循环不变式:当算法执行完倒数第k个字符时,[L,R]区间之内的后缀以模式P的后k个字符为前缀,证明如下:初始化.算法执行1~3行,完成初始化,显然此时L对应c-list的第1个元素,R对应c-list的最后一个元素,所以此时区间[L,R]就是c-list区间,该区间内的所有后缀均以字符c开头,得证.保持.假设算法已经执行到了倒数第k个字符c,即此时区间[L,R]内的后缀以模式P最后面的k-1个字符为前缀.算法在第6~7行确定c-list的区间[LL,RR],并且该区间内的Φ值都是升序的.Φ[i]值的实际含义为该后缀“剔除”掉首字符后的后缀的排名,如果T中包含该模式,即会出现pkpk-1pk-2…plen-1,那么区间[LL,RR]中一定有一个连续片段[newL,newR],其中所有的Φ值都在区间[L,R]内,因为[L,R]区间内的后缀都以pk-1pk-2…plen-1为前缀,所以执行完该次循环,以[newL,newR]为新的[L,R],即该区间内的后缀都以模式的最后k个字符为前缀.结束.算法有两个退出位置,第13行或第14行.由第13行退出时,表示模式不存在,当由第14行退出时,区间[L,R]内的所有后缀都以模式P为前缀.因此当该算法结束时,当LR时,模式出现R-L+1次,当由第13行退出时,L>R,表示模式没有出现.以P=“bga”为例,算法执行过程如下:1~3行初始化.确定区间L=C[a]=0,R=C[a+1]-1=C[b]-1=3,即区间[L,R]=[0,3]内的后缀都以字符a打头,对应a-list.第1次循环.此时LL=C[g]=30,RR=C[g+1]-1=35,即区间[30,35]内的后缀都以字符g打头,[30,35]内的Φ值为{1,3,5,13,16,19},其中前两个的Φ值属于区间[L,R],所以[newL,newR]为[30,31],第10、11行将[L,R]更新为[30,31],即该区间内的后缀以“ga”为前缀,可以从图1得到验证.第2次循环.此时[L,R]为[30,31],LL=C[b]=4,RR=C[b+1]-1=C[c]-1=9,[4,9]内的Φ值为{24,25,29,30,31,35},所以[newL,newR]=[7,8],满足RL的条件,更新[L,R]为[7,8],循环结束,返回.所以最终[7,8]区间内的后缀以“bga”为前缀.在具体确定newL和newR时,由于[LL,RR]区间内的Φ值都是升序的且采样点的值是直接存储的,所以先在采样点上执行二分查找,确定newL、newR的目标区间Bi,然后在目标区间Bi上利用查找表顺序解码,确定具体的位置.采样点上二分过程的时间复杂度为O(log(n/b)),b表示块大小.假设H表示Gamma编码的平均长度,则一个B块对应bH位,一次查找表可以解码W位,W表示查找表宽度,所以顺序解码过程的复杂度为O(bH/W).所以算法Page10第8~9行的复杂度为O(log(n/b)+bH/W).对于块大小b=(logn)2/loglogn,计数查询算法的时间复杂度为O(mlogn/loglogn),m为模式P的长度.算法的返回值为L和R,表示区间SA[L,R]内的后缀以模式P作为前缀,故P出现的次数为R-L+1次.如果查询的模式不存在,某次循环第12行的IF条件将成立,跳出循环,直接返回模式不存在.定理2.给定长为m的模式P,借助于查找表R(3.3节描述),计数查询可在O(mlogn/loglogn)时间内完成,空间占用由定理1给出,额外C表开销为σlogn位,其中σ为字符表大小.算法locate以count过程返回的[L,R]作为输入,然后利用getpos(i)操作确定SA[i]的值,i∈[L,R].在T中的起始位置.算法过程如下.算法5.locate.输入:P,L,R输出:ans1.ans[0…R-L]←02.FORi←LtoRDO3.ans[i-L]←getpos(i)4.RETURNansgetpos(i)过程返回SA[i],即第i个最小后缀过程犵犲狋狆狅狊(犻).1.step←02.WHILEimodc≠0DO3.step←step+14.i←Φ[i]5.i←i/c6.RETURN(SAl[i]-step)modngetpos从某点i∈[L,R]出发,沿着i(Φ[i]),i(Φ[i]),…,顺序后移,满足SA[i]+1=SA[i],SA[i]+1=SA[i],…,直至遇到被采样的某点SAl[i].令step表示后移的步数,则结果返回为SAl[i]-step,该结果在算法第6行返回.因为对于b=(logn)2/loglogn,使用宽度为W=O(logn/2)的查找表,访问Φ的时间为O(logn/loglogn).因此,locate算法的时间复杂度为occ·c·O((logn)2/loglogn),其中c为SA的采样步长,occ为模式在T中出现的次数.定理3.给定长为m的模式P及模式出现的范围[L,R],定位查询可在occ·c·O((logn)2/loglogn)时间内完成,其中c为SA的采样步长,occ为模式出现的次数.继续以模式“bga”为例,count过程求出[7,8]区间内的所有后缀具有“bga”前缀,所以locate过程用getpos分别求出SA[7],SA[8]的值.以求SA[8]为例,简单描述getpos过程(c=3).step=0,i=8,WHILE循环开始.8mod3≠0,step=1,更新i=Φ[i]=Φ[8]=31;31mod3≠0,step=2,更新i=Φ[31]=3.3mod3=0,循环结束.第5行i=i/3=3/3=1,算法在第6行返回SAl[i]-2=34-2=32.5.2展示文本串给定子串起始位置start和长度len,extract(start,len)操作可以展示T中起始位置start处长度为len的子串,即T[start..start+len-1].4.2节采样SA-1数组,产生SA-1数组实现extract(start,len)操作,返回这个子串.在3.4节中我们讨论了如何恢复后缀SA[i],即返回后缀T[SA[i]..n],该过程会用到Φ的表示结构和C表(字符统计表).因此我们只需把某个后缀的起始位置start转换成对应的排名i,extract(start,len)操作就能借助3.4节的方法完成.由4.2节可知,对于排名为i的后缀,可以在C表上进行二分查找,确定i所属的区段index,则排名为i的后缀的第1个字符就是incode[index],后续部分用f(i)表示这一过程,即返回排名为i的后缀的首字符.显然,过程f(i)的时间复杂度由C表的二分过程决定,为O(logσ),σ表示C表大小,即字符表的大小.更新i=Φ[i],重复上述过程,可以确定整个后缀.以下描述过程restore(i,len),该过程返回排名为i的后缀T[SA[i]..SA[i]+len-1].过程狉犲狊狋狅狉犲.输入:i,len输出:substr1.FORj←0tolen-1DO2.substr[j]←f(i)3.i←Φ[i]4.RETURNsubstr以下transform将后缀的起始位置start转换过程狋狉犪狀狊犳狅狉犿.输入:start输出:i1.i←SA-12.step←startmodd3.FORj←0tostep-1DO4.i←Φ[i]5.RETURNi成排名i.Page11d表示SA-1数组的采样步长,该过程先查找比start小的最大的SA-1数组采样点start/d,得到该点排名i,然后重复执行startmodd次i=Φ[i],根据Φ[i]的物理含义,此时的i就是start位置开始的后缀的排名i.算法6.extract.输入:start,len输出:substr1.i←transform(start)2.substr←restore(i,len)3.RETURNsubstr算法的时间复杂度由两个过程f(i)和Φ[i]决定.由本节分析可知,f(i)的时间复杂度为O(logσ).Transform最坏情况下执行d次Φ[i]操作,restore执行len次Φ[i]操作,因而extract操作的时间复杂度为O((d+len)(logn/loglogn)+lenlogσ).定理4.给定子串起始位置start和长度len,i01234567891011121314151617181920212223242526272829303132333435TabfgdbfbgdfccbgacefcegcdefgbfcadbgafSA01530345271133272912112216194312391724203562810182521433262138SAl03417111923246181421SA-106293416424935192612117301142027152233131821283252510217831323SA-1l034241911127332152316改进不同数据的分布特点是不同的,体现在Φ的gap序列中1的比例.我们的统计实验表明,像dna这样的数据,其gap值为1的比例大约占到总数的40%~60%左右;像english这样的数据,其gap值为1的比例大约占到总数的50%~70%左右;像influenza这样高度重复的(highly-repetive)序列,其gap值为1的比例可高达80%以上.因此gap序列中势必存在大量连续的1(也称长游程,longruns),单纯一种Gamma编码不能很好的适应这种情况,需要结合run-length编码,而run-length编码可以很高效的处理这种具有长游程的数据.对Φ的gap序列运用run-length编码之后,解码速度也会有所提升,因为一个runs可能会对应好多个gap,不再需要逐个恢复,所以gap中1的比例越高,则倾向于应用run-length编码,块大小也可以适当的取的大些.但并不是所有的gap片段都呈现很好的runs特性,因而我们仍然需要Gamma编码方法作为展示子串查询可在O((d+len)(logn/loglogn)+lenlogσ)时间内完成,其中d为SA-1的采样步长.图3给出了c=d=3时对后缀数组SA和逆后缀数组SA-1的采样结果,分别用SAl和SA-1示.我们将SAl和SA-1位的数组里.结合图3,执行extract(14,4)的过程如下:第1步.确定位置14的排名,图3中SA-1的采样步长为3,不超过14的最大采样点为12,对应SA-1(下标从0开始),得i=11,即位置12开始的后缀的排名为11,14mod3=2,重复执行两次i=Φ[i],最终i=30,即位置14开始的后缀的排名为30,该计算由transform过程完成.第2步.len=4,循环4次.首先,i=30,属于g-list范围,故第1个字符为‘g’.其次,i=Φ[30]=1,属于a-list范围,故第2个字符为‘a’.然后,i=Φ[1]=14,属于c-list范围,故第3个字符为‘c’.最后,i=Φ[14]=20,属于e-list范围,故第4个字符为‘e’.因此T[14..17]=“gace”.l示例第2种编码方法,当run-length编码失效时,使用Gamma编码.最终我们的数据感知的、自适应的编码策略如下:候选编码方法有Gamma编码,run-length编码,块大小根据gap中1的比例决定,块内编码方法在Gamma和run-length编码中择优选取.最终的结果是:我们改进的CSA能根据数据分布的不同,自动的选择合适的编码方法和块大小,具有数据感知和自适应的特点.如何把run-length编码结合进来是个很艺术的问题,区分一个值y(表示待编码的值)是gap还是1的runs,一种简单的策略如下:h()y=2y-3,如果y是一个gap这样解码时通过奇偶判断就能确定编码的是gap还是1的runs值.这里可做进一步优化,将y映射为2y-1时,所有被编码的值都大于1,此时我们可以修改Gamma编码的规则,当y的二进制需要x位时,在y的二进制前面追加x-2个0,而不是原来的x-1个0.此外,高度重复数据的runs值Page12或偶尔出现的非1gap的值都较大,所以EliasDelta编码更合适,按照类似的方式修改Delta编码规则,“剔除”最左端的0.我们的改进版称为ACSA(adaptiveCSA),改进版在结构上比图2多了记录编码方法的methods域,每个块对应一个ceil,每个ceil需要2位,可表示4种编码方法(Gamma,RLG,RLD,All1).其中Gamma表示对y使用Gamma编码,RLG表示对y使用run-lengthGamma编码,RLD表示对y使用run-lengthDelta编码,All1表示整个块为1的runs,这样的块不编码.这个methods域所用空间为2(n/b)=o(n),对于b=(logn)2/loglogn.实现时,超块大小固定为块大小的16倍,块大小自适应,以gap序列中1的比例为依据.如果数据是高度重复的,设为512,如果数据是像english这样的,设为256,否则设为128,令b表示块大小,则在实际中b值取值如下:其中r为gap序列中1的比率.我们的实现中,提供了speedlevel参数,该参数决定3个典型的阈值:speedlevel=0对应阈值(l1,l2)=(0.50,0.60),此时压缩率较好,count查询较慢.speedlevel=1对应阈值(l1,l2)=(0.60,0.75),该阈值是个比较好的权衡值.speedlevel=2对应阈值(l1,l2)=(0.65,0.80),此时压缩率较差,count查询较好.这些阈值和speedlevel的取值都只是经验值,可以根据需求进行权衡.speedlevel值偏小时,侧重于压缩率,speedlevel值偏大时,侧重于查询速度.图4Φ结构大小7实验结果与分析7.1实验环境设置实验中没有运行其他大型程序,任何系统设置保持默认,运行Ubuntu12.04LTS32位系统,g++4.4.1编译,加-O3优化参数.机器情况:HPZ400,CPU:Inter(R)Xeon(R)2@2.53;RAM:4GB,L3:4MB.我们使用源自CanterburyCorpus(http://corpus.canterbury.ac.nz)和Pizza&ChiliCorpus(http://pizzachili.dcc.uchile.cl/indexes.html)的数据测试所提方法的性能.我们的两个版本可在https://github.com/chenlonggang/Adaptive-CSA及https://github.com/chenlonggang/Compressed-Suffix-Array上获取.7.2参数对性能的影响我们的CSA结构是带参数的,参数的选取影响着压缩索引的空间和时间性能.本节简要讨论这些参数对算法性能的影响.假设a表示超块的大小,b表示块的大小,c表示SA的采样步长,d表示SA-1的采样步长,SAM、SB、B按照紧凑方式存储.为了降低空间,我们固定d=16c.本节我们将讨论a和b的最佳倍数关系,在此基础上确定参数b、c对算法实现性能的影响,最终确定一组最佳的参数.图4表示b取不同的值,a=kb时,随着k的变化,Φ结构大小(bps,bitspersymbol)的变化趋势,横轴表示系数k,纵轴表示Φ结构的大小.从图4中可以看到,当n=50M、100M时,当k大于18左右之后,空间不再降低,甚至有变大的趋势,所以选取a=18b是合适的.后续的实验都是建立在a=18b的基础上的.Page13现在讨论参数b、c对性能的影响,实验中以50MB大小xml数据为例.第1组.参数b对性能的影响本组测试参数b对性能(压缩率、查询时间等)的影响,如图5所示.实验中参数c=32,参数b由16开始变化,以16为步幅,增加到160.参数b表示Φ块的大小,即Φ[ib]的点将被采样,直接保存,并且还会保存该点相对于所属超块的偏移量,随着参数b的增大,Φ的辅助结构会越来越小,但随着b的增大,压缩率的降低趋势会放缓,图5(a)表明了这一点.参数b对压缩时间的影响不大,如果假设某个点被采样和被编码的时间代价相当,则不管参数b如何变化,压缩时间都不会有明显的变化,这一点可以从图5(b)中看出.图5(c)和图5(d)清楚的说明了Φ块大小b对计数查询、定位查询时间的影响,因为这两个操作都需要Φ结构的支持,增大b应该会显著的影响计数查找的时间,因为增大b会增大Φ获取过程中的跳跃次数,但是图5(c)表明参数b的变化对计数查找的影响不大,这得益于对查找表的充分利用.图5(d)中参数b由16变化到160时,定位查询图5参数b对性能的影响时间变为原来的2倍左右,图5(a)表明压缩率变为原来的0.6倍左右,观察图5(a),图5(d)的走势,不建议选取大于128的b值,因为b>128后,对压缩率的贡献降低,但定位查找时间显著上升.第2组.参数c对性能的影响本组测试固定参数b=128,参数c由16开始变化,以16为步幅,增加到160.在图6(a)中,参数c由16~160变化时,压缩率逐渐降低,但随着c的增大,降幅逐渐减小,在整个过程中,压缩率由0.49左右降到0.30左右,变为原来的0.6倍左右.压缩时间依然没有显著变化,调整c并不影响计数查找,因为计数查找只需要字符频数统计表C和Φ数组的支持.图6(d)表示定位查找时间,c=16、160时的增幅高达16倍左右,而图5(d)中的增幅只有2倍左右,这个结果是我们实际中将参数b选择较大,而将参数c选择较小的重要依据.综合考虑上述实验,我们选取b=128,a=18b,c=32,d=16c作为我们算法的默认值,该值既可以保证Φ数组的辅助空间较小,同时又保证了查询算法的速度,后续实验都基于该组参数值.对于ACSA,参数b取值分3档,128,256和512,speedlevel可取值0,1和2,对应的阈值分别为Page14图6参数c对性能的影响(0.5,0.6),(0.6,0.75)和(0.65,0.80).此时阈值为Φ的gap序列中1的比例,speedlevel的默认值为1,即当1的比例低于0.6时,b取值128,当1的比例在0.6到0.75之间时,b取值256,大于0.75时,b取值512.这些参数的取值都是在上述实验的基础上综合考虑的结果.7.3结果与分析本节采用Pizza&Chili网站上的数据进行测试,与当前主流方法在压缩率和查询速度方面进行了比较.表6给出了有代表性的数据文件(100M)的统计信息.它们包括像dna这样的数据(符号分布几乎均匀),像influenza这样的高度重复的数据以及介于这两者之间的数据,如像english文本这样的数据.文件dnaproteinsxmlsourceenglish字符集162596227215待比较的方法包含:CSA(本文第3节的方法),ACSA(本文第6节的方法),speedlevel=1,FM-Index[14-15],RLCSA[23],Sad-CSA[12-13],SDSL-CSA[28].除了ACSA的块大小自适应之外,其他被比较的方法,块大小b=128.我们在索引构造时间、压缩率和模式查询时间上与现有主流方法进行了比较.压缩率bps(bitspersymbol)定义为CSA结构大小与源文本文件大小的比值再乘以8,表示文件压缩后每个字符平均所需要的比特数.对于每个文件,我们随机生成一万个长度为20的模式,获取平均的查询时间(单位为us).每个算法查询的10000个模式是一样的.表7~10中的黑体字说明的是这些方法在每一列不同数据上表现最好的前两个结果.表7给出了上述的压缩索引方法在不同特征数据集上的构造时间.在所测试的7组数据中,CSA的构造时间在其中4组数据上显著优于其他压缩索引的构造时间.FM-Index在其余的3组数据上的构造时间表现最佳.但在这3组数据上,CSA的构造时间与FM-Index的构造时间接近.表8显示了对不同的数据采用不同的压缩索引Page15方法得到的压缩率.由表8可见,除了高度重复的数据influenza和kernel以及sources,ACSA的压缩率显著优于所比较的其他压缩索引方法的压缩率.而对于所测试的数据,CSA的压缩率也有一定的优势.而对于高度重复的数据influenza和kernel,RLCSA的压缩率最佳,但我们ACSA的压缩率与之相当.FM-Index的压缩率在所比较的压缩索引上表现最佳,而ACSA的压缩率也能与之相当.随机选取数据文件中的长度为20的模式串,我们测试了不同压缩索引的count和locate查询时间,其结果如表9和表10所示.由表9可知,与其他所比较的压缩索引方法相比.CSA的计数查询时间是最快的,这是由于我们设计了一个快速查找表,加速了Φ值的解码过程.改进后的ACSA,在压缩率表7索引构造时间FM-Index22.1523.3322.9618.3321.1129.7322.65RLCSA46.3536.4052.0639.8440.0143.5142.22Sad-CSA50.3648.4557.3637.4441.5464.2776.63SDSL-CSA33.5936.2632.0426.1927.1930.9727.18MethodACSACSAMethodACSACSAFM-Index4.03RLCSASad-CSA4.81SDSL-CSA5.31MethodACSACSA表8压缩率比较(犫狆狊,犫犻狋狊狆犲狉狊狔犿犫狅犾)表9Count查询时间FM-Index416.003666.703221.192606.052651.240493.020576.641RLCSA73.39958.61061.12561.58539.25667.00163.920Sad-CSA46.69741.04841.57538.89634.52542.39838.534SDSL-CSA95.70661.83296.09970.26549.89381.78073.042表10Locate定位时间MethodACSA1023.569186.42624.44102969.0025831.302985.05191733.00CSAFM-Index3488.0410745.611368.2497021.69115336.059160.00425353.25RLCSA4302.6224595.901304.99198446.0032463.908335.38379402.00Sad-CSA617.539159.41559.5448222.973041.82314.596779.30SDSL-CSA455.081964.81270.4213406.399178.77701.1223723.74上进一步改善的同时,在查询时间上略逊于CSA.但ACSA的查询效率在多数情况下仍然优于其他压缩索引的计数查询时间.由表10可知,在定位查询locate中,CSA在5组测试数据上优于Sad-CSA,在4组测试数据上优于SDSL-CSA.改进后的ACSA增加了解码的复杂度,定位查询效率逊于CSA,优于RLCSA和FM-Index.ACSA和CSA相比,在压缩率上有很好的提升,特别是对于高度重复的序列数据,比如influenza数据,压缩效果提升3.54倍,块的增大并没有显著增大count查询时间,这归功于run-length编码.和RLC-SA相比,CSA和ACSA的count查询时间优势明显,压缩率在dna这样的数据和english这样的数据上优势也很明显,但在高度重复序列上略逊一筹.2.252.902.242.554.144.24Page168结论与进一步工作本文提出了一种高阶熵压缩的全文自索引.对于长为n的文本T,我们的压缩索引可在线性时间内构造.对于任意kclogσn-1和c<1,我们的压缩索引占用2nHk+n+o(n)位的空间,其中Hk表示文本T的k阶熵,σ为字符表的大小.此外,本文还给出了上述描述的压缩索引的一种实用改进.这种实用改进引入了混合编码方法,能根据1在gap序列中的分布选择最佳的编码方法,其额外的空间开销为o(n)位,可以忽略不计.对于Pizza&ChiliCorpus上的三类典型数据的实验表明,我们的压缩索引较之主流压缩索引在压缩率和查询时间上具有显著的优势.虽然我们提出了一种高阶熵压缩的全文自索引,并开发出了相应的软件.但还存在以下问题有待进一步深入研究.首先,第一个问题是,运行时内存过大,严重影响其实用性.这是由于在索引构建过程中,首先要建后缀数组,这就需要比原文本大5倍以上的空间.其二,目前我们的方法只提供在压缩索引上支持精确模式匹配查询,下一步需要研究支持近似模式匹配查询的压缩索引.这两个问题高效地解决后,我们的压缩索引才既能作为文档检索的基础,也能行使倒排索引的功能并可能应用于搜索引擎,且比倒排索引支持更为广泛的查询.致谢各位评阅人给出了诸多建设性的意见,在此致谢!
