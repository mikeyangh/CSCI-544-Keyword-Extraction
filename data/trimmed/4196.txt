Page1电子商务商品归一化方法研究王立1)张蓉1)沙朝锋2)王晓玲3)周傲英1)1)(华东师范大学软件学院上海200062)2)(复旦大学计算科学技术学院上海200433)3)(复旦大学上海市智能信息处理实验室上海200433)摘要电子商务网站中不断增长的商品数量和商品规模对数据管理提出了新的挑战,其中一项重要基本任务是商品归一化,即识别属于同一个客观实体的所有商品.商品归一化的实现有助于提高商品搜索的准确性、改善用户的体验.但由于在电子商务网站中,特别是在C2C(Customer-to-Customer)模式下,商品信息的数据质量很低且缺乏统一的模式定义规范,导致已有的商品归一化方法难以适用.针对这一问题,文中设计了一种将数据集成、数据清理和商品归一化相结合的混合框架.该框架首先基于图的方法进行模式集成,然后利用商品的描述信息进行数据清理,从而得到数据质量更高且模式统一的商品信息数据;在数据集成和数据清理之后,利用逻辑斯蒂回归(Logisticregression)模型训练分类器,从而得到商品之间的相似度矩阵,最后对相似度矩阵聚类实现商品归一化.通过与已有的方法在真实数据上进行对比实验,验证了文中提出的方法的有效性.关键词实体识别;模式集成;数据清理;逻辑斯蒂回归;聚类;电子商务1引言在过去的10年里,电子商务的交易量快速增长.2011年,中国约41%的网民拥有网购经历,全国的网购年交易量达到了7850亿人民币,其中超过60%的交易量在C2C模式下完成.C2C模式电子商务的飞速发展使得C2C网站的商品种类和规模呈爆炸式增长.这种增长虽然给网购用户带来了更大的选择空间,但由于缺乏有效的商品管理机制,对用户的购物体验也产生了负面影响.目前,对电子商务数据管理的一个迫切的任务是实现有效的商品归一化(EntityResolutionforonlineproducts),即判断两个或多个商品是否指向同一个客观实体(是否对应的是同款产品).商品归一化在提高用户购物体验中起到很重要的作用,主要表现在以下3个方面:(1)用户浏览.用户在购物之前通常要进行商品搜索,对于搜索结果的组织目前有两种解决方案:①同类商品合并.这一方案展示的是合并之后的商品分类,它的实现建立在商品归一化的基础之上;②搜索结果多样化(SearchResultDiversification).该技术用于对搜索结果的排序,实现在考虑相似度的基础之上,尽可能多地返回不同的实体,从提高返回结果的信息量.当文本信息具有噪音的时候,基于文本相似度的搜索结果多样化的效果不佳.商品归一化之后会得到更为准确的商品相似度,从而提高表13个同款商品的信息无线路由器便携TP-LINKTL-WR703N包邮无线路由器高速上网99品牌:TP-LinkTP-LINK150M迷你TL-WR703NTP-LINK150M迷你Wi-FiiPadiPhone98商品型号:TL-MR3220最大速率:150MbpsTP-LINKWR703N是一款即插即用的无线路由器…型号:TL-WR703N端口数:4端口最大速率:150Mbps基于以上挑战,本文提出了一种基于监督学习的归一化方法.该方法首先对商品进行模式集成和数据清理.其中模式集成的目的是规范化商品的描多样化技术的效果.(2)产品比较.当用户决定购买某款产品时,需要尽可能多地调查由不同卖家所出售的同款商品,对商品的价格、评价,卖家的信用等诸多方面进行比较.商品归一化可以实现同类商品的正确归类,提高用户体验.(3)广告推荐.在各种电子商务网站中,用户购买历史矩阵常常用作协同过滤推荐的输入.大量的同款商品会加剧矩阵的稀疏性,从而导致生成的模型不准确.商品归一化可以有效地合并同类商品,从而实现矩阵降维、祛噪的目的.由此可见,商品归一化是电子商务网站的一项重要任务.但模式的异构以及商品描述信息的混乱主要给商品归一化任务带来了以下两点挑战.首先,不同商品之间的模式异构.通常情况下每一个商品都有一个属性表,包含有若干个〈属性,值〉对,即〈attribute,value〉,如表1所示.属性表提供了商品的详细描述信息,它对商品归一化起到了至关重要的作用.但是属性表往往缺乏统一的模式规范化要求(比如对于“产品型号”属性,在一些商品中叫“型号”,而在有些商品中则叫“生产型号”),从而造成模式异构的产生,影响商品归一化的效果.其次,商品数据中噪音严重.商品的描述数据(value)是由卖家填写.对于值的填写各个网站通常都缺乏有效的验证机制,导致商品描述数据中存在大量的异构信息、噪音或缺失值(比如漏填了重要的商品属性,或是填写了错误的商品属性值).数据噪音加剧了商品归一化的困难.述属性.基于模式集成的数据清理包含缺失值的填充、错误值的检测和正确值的确认3个步骤,从而保证每一个商品描述的准确性和全面性.在进行模式Page3集成和数据清理之后,在选取的特征上,用逻辑斯蒂回归模型在训练集上训练二值分类器.该分类器用于计算商品间的关联关系矩阵,该矩阵表示商品间相互匹配的估计概率.训练分类器的过程本质上是在为不同的特征训练权重,使得贡献度高的特征被赋予更高的权重.这样的方法可以提高算法的鲁棒性,使得分类效果不会因为选取的个别表现不佳特征而降低性能.最后,利用该矩阵进行聚类,将两个商品之间的实体识别转换为集合之间的实体识别,从而实现商品归一化.本文第2节介绍相关工作;第3节阐述本文的研究动机;第4节整体介绍提出的商品归一化方法框架;第5节描述模式集成和数据清理的过程;第6节介绍商品归一化;第7节通过实验来验证和分析本文的方法;最后在第8节总结全文.2相关工作商品归一化是实体识别(EntityResolution)的一个分支.实体识别最早被文献[1]提出,其目的是识别那些指向同一个现实世界中的实体的实例,是一项重要且充满挑战的任务.传统的实体识别工作,如文献[2-5],主要是通过定义字符串的相似度来实现无监督的实体识别.这类方法不需要有标注数据,且进行实体识别的时候具有很高的处理速度,但其主要弊端是对字符串相似度过于敏感,在大数据集中往往难以定义出表现良好的字符串相似度计算函数.有一些研究使用机器学习方法利用标注数据去训练字符串的相似度[6-8],其主要优势是避免人为设计字符串相似度计算函数的要求,但此类方法的主要局限是没有充分利用除字符串之外的其它信息.文献[9-11]通过使用上下文中的实体引用来提高实体识别的效果.由于利用了额外的信息,因此比起前两类方法在性能上有较大提升.与此类方法相似,本文提出的方法则充分利用了上下文中的信息来进行信息填充和修复.此外,本文还就上下文信息中的缺失信息和错误信息进行了修复.文献[12]中提出了使用概率分类器来进行实体识别的技术.近年来的一些研究工作使用维基百科和WorldNet等外部资源来进行一些独立领域的实体识别[13-15].这些方法都是基于待识别的实体在外部资源中都有相应的文档这一假设,然而这一假设的要求很高,常常不易满足.为了降低对外部资源的要求,文献[16-18]等研究工作在实体识别过程中提取那些能证明两个object不是同一个实体的证据,根据这些证据来增加这些object的距离,从而提高实体识别的准确度,但是这种方法对于反面证据的准确率要求很高,错误的证据会直接导致准确率的下降.本文没有利用外部资源,这使得本文提出的方法具有更好的通用性.需要强调的是,本文的方法可以通过定义新的特征和相似度函数,将外部资源引入到本文的相似度向量中.在电子商务领域,文献[19]提出了对商品进行聚类的方法,这与本文的研究内容较为相似.该方法将商品的属性视为特征,使用SVM来训练每一个属性的权重,然后利用聚类实现最终结果.但是此方法没有考虑到数据噪音问题,因此当数据噪音严重时,属性的权重难以收敛且很不准确,实体识别的效果很差.文献[20]中提出了一种对非结构化的商品信息进行匹配的方法,他们假设已经存在一个存储着每一款商品详细信息的数据库,然后将非结构化的商品信息与数据库中的记录进行匹配.此方法依赖于存储每款商品信息的数据库,适用范围很小,与本文的研究场景不同.3研究动机目前电子商务网站中识别同款商品的方法主要是基于商品标题中的关键词.但由于在购物网站中(特别是C2C模式下)商品信息中标题噪音很严重,导致现有的方法在商品分类上的性能很低.本文旨在设计一种在缺乏统一的商品模式且具有噪音的环境下,能有效地进行商品归一化的方法.商品包含标题、价格、属性表和文本描述等信息,如表1所示.尽管这些信息非常丰富,但利用他们进行实体识别却充满挑战,主要表现在:(1)标题中的挑战.标题是目前进行商品归一化方法的重要信息.但标题中往往充满噪音,主要原因是:①卖家各自填写所出售商品的标题,由于卖家具有不同的行为习惯,因而造成标题信息异构(比如表1中第二款商品的标题中缺少型号“TL-WR703N”);②很多卖家通过在标题中添加一些与商品无关的热门词汇来提高商品的曝光率、增强影响力,从而提高销售额(比如表1中第三款商品标题中的“iPad”和“iPhone”).(2)属性表中的挑战.属性表以结构化方式展示商品相关信息.但由于以下两点原因使得属性表在商品归一化过程中所起到的作用非常有限:①属Page4性名表达不规范(比如表1中第1行“型号”属性有另外两种表述,即第2行中的“商品型号”以及第3行中的“产品型号”);②数据值缺失或者错误(如表1中“品牌”属性值缺失,“商品型号”属性值错误).(3)文本描述中的挑战.使用文本描述来进行商品归一化比较困难,主要是因为以下两点:①传统的文档处理方法在处理短文档时效果不佳;②同一类别的不同型号商品的文本描述很相似.由于上述原因,很难直接用当前的商品信息实现良好的商品归一化效果.但通过对数据的观察,我们发现可以利用数据本身的特性去解决上述问题,这也是本文的出发点,可概括为3个方面:(1)命名上不同但本质相同的属性会存在取值上的交叉(比如“商品型号”和“产品型号”本质上是相同的属性,它们的取值空间会有大量的交集).因此可以利用值的统计信息进行模式的集成,详细方法见5.1节.(2)对于商品属性中的缺失值或错误值,可以利用上下文信息和其它的同类商品信息进行填充和修复(比如表1中的第2个商品中,“产品型号”值是缺失的.从第1个商品信息中可以得知“TL-WR703N”是该属性的一个候选值,并且“TL-WR703N”在第2个商品的描述信息中出现,因此我们可以推断“TL-WR703N”可能就是那个缺失值).寻找证据进行数据值修整的方法见5.2节.(3)商品归一化过程中不同的特征(标题、价格等)具有不同的区分能力(比如当两个商品的“产品型号”属性取值相同时两个商品属于同一款商品的可能性比起“品牌”属性取值相同时的可能性更大).本文定义了一组商品特征,使用训练数据来确定各个特征的区分能力.特征区分能力的判定方法见6.2节.4整体框架由于商品归一化会遇到模式集成和噪音消除等困难,为此我们设计了一个混合的商品归一化框架,如图1所示,它可以分为两个部分.首先,进行数据预处理,它分为3个主要步骤:(1)将异构的模式集成为一个统一的全局模式,后续的数据噪音消除和相似度都是基于全局模式的基础之上.(2)在每个商品寻找缺失的属性,然后利用该商品的其它信息对缺失的信息进行填充.(3)根据商品上下文以及全局模式中的统计信息,找到错误的属性,并进行更正.然后,进行商品归一化,它分为3个主要步骤:(1)除全局模式中的每一个属性都作为一个特征,除此以外,还在商品的若干重要属性上定义特征和相似度.(2)为选取的每一个特征通过训练集训练不同的权重,从而加大重要的特征的作用,降低或去除不重要的属性的作用,并训练处可以预测两个商品是否为同一个实体的分类器.(3)利用上一步的分类器生成商品的相似度矩阵,在此基础上进行聚类,从而实现实体识别.5数据预处理5.1模式集成本文的模式集成的目标是使所有的商品的属性表都处于统一的模式下.模式集成包含两步:(1)全局模式的生成;(2)全局模式的规范化.5.1.1全局模式生成定义1.全局模式.全局模式中存储在所有商品属性表中出现的属性和值以及它们取值范围和相互对应关系.定义2.全局模式图.将全局模式表示为二部图G=〈A,V,E〉,则称G为全局模式图.其中A和V是点集,E是边集.A中的每一个点对应一个属性,V中的每一个点代表一个取值.对于任何a∈A和v∈V,如果〈a,v〉在k个商品的属性表中出现,则在E中存在一条权重为k的边(a,v),其权重记为w(a,v).对所有商品的属性表进行一遍扫描后生成全局模式,并以二部图的形式来表示,见图2(a).G中任意一个属性节点a∈A都和若干值节点邻接,所有和a邻接的值节点所组成的集合就是属性a的值域.Page5在全局模式中,存在许多表述不同但相互等价的属性节点和值节点.例如属性“产品型号”和“商品型号”是相互等价的,“TL-WR703N”和“WR703N”也是相互等价的.全局模式规范化是合并那些相互等价的属性和值,从而有利于在属性表上对商品进行更为精确的比较.在合并本质上相同的属性节点之前,首先合并本质上相同的值节点,这将有利于属性节点的合并.定义3.超级值(属性)节点.将所有值(属性)节点划分为若干个互不相交的子集,使得同一个子集内的所有值(属性)节点是相互等价的.划分中的一个子集称为一个超级值(属性)节点.5.1.2全局模式的规范化算法1.值节点合并.输入:G=〈A,V,E〉,δ输出:G=〈A,Vs,E〉1.V=,E=E2.FOREACHv∈V3.Vs=Vs∪{{v}}4.ENDFOR5.WHILE6.Vs7.Vs8.DeletealledgesadjacenttoVs9.FOREACHv∈A10.IF(a,Vs11.E=E∪{(a,{Vs12.w(a,{Vs13.ENDIF14.ENDIF15.ENDWHILE值节点的合并如算法1所示:首先将G中的任意一个值节点作为一个超级值节点(2~4行).如果两个超级值节点之间的字符串相似度大于某个给定的阈值δ(0<δ<1),则将两个超级值节点合并,并合并对应的边(5~15行).两个超级值节点Vs之间的相似度是分别属于两个超级值节点的所有节点对相似度的平均值:SimStr(Vs本文并不关注字符串相似度的定义,而是使用现有的编辑距离或N-gram相似度,记为SimStr(·).通过合并相互等价的值,G被转换为G=〈A,Vs,E〉,其中Vs是生成的所有超级节点的集合,E是连接超级值节点和属性节点的边集,如图2(b)所示.属性节点a和超级属性节点Vs定义如下:对于任意V中的节点v,在集合Vs中有且只有一个超级值节点Vs节点记为sup(v).对于任何一个超级节点Vs在Vs作为Vsi中选定在全局模式中出现频数最高的值节点合并本质上相同的值节点后,进行本质上相同的属性节点的合并.如果只利用字符串相似度进行属性节点的合并在很多情况下并不有效,例如“RAM”和“RandomAccessMemory”是本质上相同的属性名,但是他们的字符串相似度很低;反之“CoreNumber”(CPU的参数)和“ModelNumber”的字符串相似度很高,但它们在本质上并非同一个属性.经过观察发现本质上相同的属性的值域会有很大的交集,因此本文在合并属性名时不仅利用字符串相似度,还考虑到邻域信息.因此将属性节点之间的相似度定义如下:Satt(ai,aj)=1SNeighbor(ai,aj)=∑v∈V(ai)∩V(aj)Max(w(ai,v),w(aj,v))Satt(·)是字符串相似度和邻域相似度的加权和.对于任意a∈A,V(a)表示与a邻接的所有超级节点的集合.利用Satt(·)和一个给定的阈值θ,使用Page6与合并值节点相同的策略对属性进行合并,合并后G就被转换为G=〈As,VS,E〉,如图2(c)所示.对于集合As中的任何一个超级节点As在数据中出现频率最高的节点作为As的代表节点,记为As.rep.经过上述步骤,已经集成的模式就被存储于G中,其中相互等价的属性(值)被存储在同一个超级属性(值)节点中(例如“商品型号”属性和“产品型号”属性将会在一个超级属性节点中,“WR703N”和“TP-WR703N”将会在同一个超级值节点中).我们利用G按照以下步骤将所有的商品映射为统一的模式:对于每一个商品p的属性表中的每一个〈属性,值〉对〈a,v〉,将〈a,v〉转换为〈Asi.rep〉,其中AsVs性节点和超级值节点.通过G将所有的商品的属性表转换为统一的模式之后,就可以更加精准地使用属性表来计算两两商品之间的相似度.5.1.3参数调优在合并超级值节点和合并超级属性节点的过程中,须指定阈值δ和θ.选择合理的阈值对进行商品模式集成的结果具有重要意义.本文采取的策略是随机挑选一部分商品属性表格中的属性和值进行人工标注(标注两两属性(值)是否相互等价的).利用人工标注的数据训练阈值δ和θ.将已标注的属性和值的集合分别记为Apos和Vpos,对于任意a1,a2∈Apos,I(a1,a2)=1当且仅当a1与a2等价,否者I(a1,a2)=0;对于任意v1,v2∈Apos,I(v1,v2)=1当且仅当v1与v2等价,否者I(v1,v2)=0.δ和θ取值按照如下方法:δ=argmax0<δ<1θ=argmax0<θ<1即采用在标注样本中表现最好的δ和θ的取值作为全局数据进行模式集成的阈值.5.2数据填充和数据清理属性表中的缺失和错误的值严重降低了商品归一化的效果.这一子节介绍修复这些缺失和错误值的方法.对于任意商品p,将其属性表转化为局部二部图g(p)=〈A(p),V(p),E(p)〉,如图3(a)所示,其中A(p)和V(p)是节点集合,A(p)中的每一个节点表示一个属性,V(p)中的每一个节点表示一个值,E(p)是边集,每一个〈属性,值〉对都在E(p)中有一条权重为1的边.图g(p)是全局模式图G的一个子图,A(p)中的每一个顶点都属于G中的某一个超级顶点,且是所属于的超级节点中的代表节点.商品p的标题和文本描述分别用tit(p)和des(p)来表示.5.2.1缺失值的填充(2)模式级缺失.属性表中的缺失值分为两类:(1)值级缺失;定义4.值级缺失.值级缺失是指某个属性的值不存在或者是空值.在图3(a)中,没有边的属性节点就存在值级别的缺失.定义5.模式级缺失.如果一个商品比起同类商品缺少了某些属性,则称为是模式级别的缺失.例如表1中第3个商品与同类商品相比,缺少“商品品牌”这一属性,这属于模式级缺失.模式级缺失蕴含值缺失.算法2.缺失值的填充.输入:G=〈As,VS,E〉,g(p)=〈A(p),V(p),E(p)〉,输出:g(p)=〈A(p),V(p),E(p)〉1.Vmiss=,g(p)=g(p)2.FOREACHAs3.IFAs4.Amiss=Amiss∪As5.ENDIF6.ENDFORPage77.FOREACHai∈AmissDO8.FOREACHv∈∪a∈sup(ai)V(a)DO9.IFvappearsintit(p)ordes(p)THEN10.IF(ai,sup(v).rep)∈E(p)THEN11.w(ai,sup(v).rep)++12.ELSE13.V(p)=V(p)∪{sup(v).rep}14.w(ai,sup(v).rep)=115.ENDIF16.ENDIF17.ENDFOR18.ENDFOR19.RETURNg(p)对于任何商品p,缺失值的填充过程如算法2所示.首先,遍历全局模式中的任何一个超级属性节i,如果As点As失(第10行进行验证);如果As有相应的值,则是值级别缺失.将找到的值级缺失属性和可能的模式级缺失属性储于集合Amiss中.注意有些缺失属性是相互等价的,为了避免冗余,只将代表性节点存储于Amiss中.然后,为缺失属性赋值(7~18行).对于Amiss中每一个属性ai,在tit(P)和des(p)中搜索所有与任意v∈∪a∈sup(ai)V(a)所匹配的子字符串(v∈∪a∈sup(ai)V(a)是属性ai的值域).如果存在任意子字符串与v匹配,则v被视为属性ai的一个候选值,并在g(p)中创建一条权重为1的边(ai,v),如果(ai,v)已经存在,则将其权重加1.执行算法1之后将生成一张新的二部图g(p)=〈A(p),V(p),E(p)〉,与g(p)相比多了一些新增的节点和边,如图3(b)所示.A(p)中新增的节点是潜在的模式级缺失,而V(p)中新增的节点是潜在的值级缺失,新增边的权重是通过tit(p)和des(p)所找到的缺失证据的支持数.定义6.冲突属性.A(p)中与多个值节点邻接的属性节点称为冲突属性.我们需要在冲突属性的多个邻接值节点之间保留一个最可能正确的值节点,这部分内容见5.2.3节.5.2.2错误值检测对于任意商品p,可以根据tit(p)和des(p)检测出属性表中可能错误的属性值(比如,表1中第3个商品的标题和文本描述暗示“产品型号”属性正确的值应该是“TL-WR703N”).算法3.错误值检测.输入:G=〈As,Vs,E〉,g(p)=〈A(p),V(p),E(p)〉,输出:g(p)1.FOREACHai∈A(p)DO2.FOREACHv∈∪a∈sup(ai)V(a)DO3.IFvappearsintit(p)ordes(p)THEN4.IF(ai,sup(v).rep)∈E(p)THEN5.w(ai,sup(v).rep)++6.ELSE7.A(p)=A(p)∪{ai}8.V(p)=V(p)∪{sup(v).rep}9.w(ai,sup(v).rep)=110.ENDIF11.ENDIF12.ENDFOR13.ENDFOR14.RETURNg(p)算法3描述了错误值检测的过程.对于A(p)中每一个属性ai,遍历v∈∪a∈sup(ai)V(a)中的每一个元素v,查看在tit(p)和des(p)中是否存在任何一个子字符串与v相等.如果存在,则在g(p)中添加一条新增边,如果这条边已经存在,则使权重加1.经过上述步骤,对于任何能够表明当前属性的值是错误的证据都存储于g(p)中(以边的形式存储,边的权重对应支持数),如图3(c)所示.经过错误值检测后,图g(p)中会产生新的冲突属性,下一小节将介绍如何为冲突属性选择最可能正确的值.5.2.3正确值确认经过缺失值填充和错误值检测后,图g(p)中会存在冲突属性,例如图3(c)中的a1和a3.对于g(p)中任何一个冲突属性(冲突属性的候选值集合记为V(ai),可以根据以下两个策略之一来为ai选择一个值v:(1)v=argmaxv∈V(ai)w(ai,v);(2)v=第1个策略较为直观,在多个值之间选择支持数最大的值.第2个策略更为保守,只有当最大的支持Page8数占全部支持数的和某一个给定的阈值γ后,才选择支持数最大的值,否则保持原值以防止错误的修改.保守参数γ的取值范围是[0,1].γ越大,在改变值时就越保守.当γ<minw(ai,v)∑v∈V(ai)w(ai,v)时,策略2与策略1等价.当γ=1时,不会进行任何数据修复.经过上述步骤,完成了对商品p的缺失值填充和错误值修复,最终的结果如图3(d)所示.6商品归一化本节介绍在模式已经集成、噪音已经消除的数据上进行商品归一化.本文的商品归一化包含特征选择、分类器训练和商品聚类3个步骤.6.1特征选择6.1.1属性表属性表含有详细和丰富的结构化信息,它在商品归一化中的作用在经过数据预处理之后得到了进一步加强,因此是首选的特征.我们将属性表中的所有属性都作为特征.由于数据已经通过G统一了模式,因此共有|As|个特征.若两个商品在某个属性上的取值分别为v1和v2,则他们在该特征上的相似度定义如下:Simi(v1,v2)=由于已经在数据预处理过程中将相互等价的值进行了统一的转化,因此使用等值判断决定相似度.注意如果v1或v2中有一个是空值,则说明两个商品可能不是同一类商品,这在一定程度上说明两个商品不匹配.对于这种情况,规定相似度取值为np(空值惩罚系数,np取[0,1)).6.1.2标题标题是对属性表中的特征的补充.计算两个标题t1和t2之间相似度最简单的方法是使用编辑距离或者余弦相似度.但是由于卖家常常在标题中添加一些流行但与商品内容相关性很低的关键词,导致同款商品的标题相似度可能较低,不同款商品的标题相似度也可能较高.为克服此问题,本文使用分词工具对t1和t2进行分词,然后利用tf-idf对每一个词进行加权,最后计算带权的Jaccord相似度,从而降低流行词汇的影响.计算公式如下:Simtitle(t1,t2)=TFIDF∑w∈w(t1)∩w∈w(t2)w6.1.3价格价格是进行商品归一化的一个重要特征,尤其是当一个商品是另一个商品的配件时,两者价格上的差异就尤为重要(比如“iPad216G”和“iPad壳”).两个商品之间的价格相似度定义如下:Simprice(price1,price2)=1-|price1-price2|6.1.4用户评论大多数的购物网站支持用户购买某商品后,对该商品提交有关商品质量、服务态度等方面的评论.一个普遍的规律是两个同款商品的评论内容往往涉及许多共同的特征.因此商品的用户评论可以为商品归一化提供重要的特征.从评论中抽取用户所讨论的特征的步骤如下:首先,使用分词和标注工具[20]将评论中的语句转化为带标记的词.例如,“鞋子很漂亮,皮质很柔软!”经过分词和标注后为“鞋子/n很/d漂亮/a,/w皮质/n很/d柔软/a!/w”,其中“/n”、“/d”、“/a”和“/w”分别代表“名词”、“副词”“形容词”和“符号”.我们发现在评论中,名词和形容词往往是有意义的词,其中名词常常是谈论的某一个方面,形容词是对这一方面的评价.本文关注的是评论中所谈论的中心语,而不是用户的评价,因此我们只抽取名词作为特征.然后,进行特征词选取.评论中许多名词对区分商品的贡献不大,例如“秋季”、“正品”和“韩版”等.因此我们需要在提取出的名词中选择对商品归一化贡献大的名词作为特征.所采取的策略是对某商品p的所有评论中的名词按照tf-idf进行打分,然后将名词按照打分的降序排列,选择前m个名词作为特征.将从p中按照打分函数取得的前m个名词所组成的集合记为Asp(p)={w1,w2,…,wm}.对于任意两个商品pi和pj,它们在评论特征上的相似度定义为Simreviews(pi,pj)=|Asp(pi)∩Asp(pj)|6.1.5图片每款商品都具有相应的图片.为了减少计算量,Page9本文只在商品搜索页面中所显示的图片作为特征,而暂不考虑商品页面中的诸多图片.由于商品规模庞大,加之图片相似度仅仅是多个特征中的一个,因此,本文采用代价较低的基于直方图的图片相似度.假设任意两款商品的图片直方图分别为p和和p,则图片相似度定义如下:其中p(i)和p(i)分别为p和p在第i个像素位上的灰度值.需要强调的是,在图片质量较高且缺乏其它有效特征的情况下,可以采用计算更为复杂效果更好的其它图片相似度.6.2分类器训练根据6.1小节的特征选择,每一个商品都有k=|As+4|个特征(|As|个特征来自属性表,剩下的四个特征分别来自标题、价格、评论和图片).同时对于任意两个商品pi和pj,可以根据6.1小节的定义计算它们的相似度向量狊(pi,pj)=〈si,…,sk〉.本文将两个商品pi和pj是否匹配的问题看做二类分类问题,并使用线性逻辑斯蒂回归模型来训练分类器.分类器训练完毕后,就可以利用分类器预测两两商品相互匹配的概率,然后产生商品之间的相似度矩阵,最后对相似度矩阵进行聚类实现商品归一化.本文使用二类分类器,而不使用多类分类器的原因有两点:(1)多类分类器中所需要训练的参数个数远远大于二类分类器,尤其是在C2C网站这种实体数(商品的款式数)巨大的环境下,多类分类器过于复杂.(2)若使用多类分类器,训练数据集就必须覆盖所有的类别.然而在电子商务网站的场景下,商品的实体数目巨大,甚至是未知的.为所有的实体都进行数据标注显然是不现实的.而二类分类器不需要训练集覆盖所有的实体.在二类分类器中,设定C0为匹配,C1为不匹配.C0类的后验概率可以利用一个关于特征向量的带权线性和的sigmoid函数来建模:P(C0|s)=y(狊)=1在P(C0|s)中,狑=[w0,w],其中w0是偏置、狑是特征向量的权重,狊=[1,s].P(C1|s)=1-P(C0|s)的作用是:如果两个商品的特征越相似,它们在所有特征上相似度等于1或者接近1的值就越多,因此特征相似度的带权和(狑T狊)就越大,通过sigmoid函数得到的估计概率就越接近于1,反之亦然.利用训练数据集通过极大似然估计可以对狑以及偏置w0进行训练.训练完毕后狑中的第k个值反映了第k个特征在区分商品时的重要程度:狑k越大,说明第k个特征的重要性越高,则分类器将k特征上不同的商品进行匹配的可能性就越低.6.3商品聚类至此我们已经训练用来预测两两商品之间匹配概率的分类器.然而本文的目标是找到所有指向同一个实体的商品.因此需要将两两匹配的估计概率转换为一个划分,即将所有商品划分为若干个互不相交的子集,使得同一个子集里的所有商品都指向同一个客观实体.或者说,我们需要设计一个算法,将两个商品之间的实体匹配转化为集合之间的实体匹配.最直观的方法是将所有商品建模为一张图,图中的节点为商品,节点之间存在一条无向边当且仅当两个节点所对应的商品指向同一实体的估计概率大于0.5.这样图中的每一个连同分支中的所有商品就被认为是指向同一个实体的商品.然而该方法中分类器的伪真错误会将两个不相关的联通分支错误地连同,因此本方法对分类器的准确率过于敏感.本文的解决方案是用两两商品之间匹配的概率生成商品的相似度矩阵,然后对相似度矩阵聚类来实现划分.使用聚类进行划分时不但考虑两两商品之间的相似度,还会考虑到邻域信息,因此会得到更好的结果.本文使用现有的聚类算法(如k-means或HAC)来对商品进行划分.在聚类过程中所期望的簇的个数是通过纯度(purity)或者直径(diameter)来决定的.当商品个数很大时,相似度矩阵的存储代价和聚类的计算代价都很高.解决方案是使用分类信息(如商品的类别信息)将商品划分为若干个不相交的子集,使得子集中商品的数目远远小于全部商品的数目,然后在各个划分上分别进行相似度矩阵的存储和聚类.7实验与评估7.1数据集本文实验中使用的数据集是中国某个大型C2CPage10网站的真实数据.数据集包含有168个商品类别、140多万个商品和7000多万条评论.我们选择12个具有代表性的商品类别,并从每个类别中随机选择10%的商品作为实验数据.实验数据中商品的类别、商品数和实体数(商品的款式数)见表2.表2实验数据中商品类别、商品数目和实体数笔记本电脑网络设备牛仔裤洗发水运动鞋7.2数据噪音统计7.2.1标题中的噪音本文通过3个方面来测试标题中的噪音含量:(1)标题中与商品内容非相关词的比例;(2)同款商品标题之间的字符串相似度;(3)非同款商品之间的字符串相似度.非相关词是指那些对商品的归一化帮助不大的词.非相关词包括广告词汇和情感词汇(比如“包邮”和“漂亮”),也包括“衣服”和“相机”这种只有助于区分商品类别,但对商品归一化几乎没有帮助的词汇.非相关词是进行归一化的噪音.我们随机选择1000个商品并对其标题中的非相关词进行人工标注,结果见图4(商品按照非相关词的比例降序排列).实验结果表明超过30%的商品标题中含有至少30%的非相关词,至少有80%商品的标题中含有至少15%的非相关词,这说明标题中含有大量的非相关词.为了测试非相关词对商品归一化的影响,分别对比同款商品之间的字符串相似度和非同款商品之间的字符串相似度.我们随机选择5款商品数超过200的产品,为分别对这5款产品随机抽样50个商品,将每款产品的50个抽样商品作为一个组,因此得到5组商品.然后再选取另外5组商品(每组50个商品),使得每组中的商品都来自同一个商品类别但各自属于不同款的商品.本文分别使用编辑距离、Jaccord相似度和N-gram相似度,对上述10组商品分别计算组中两两商品之间的字符串相似度,然后取平均值,结果见图5.统计结果中前5组与后5组的字符串相似度(在3种不同的度量方法下)没有明显差异,这说明标题中噪音很大,仅仅依靠标题难以实现商品归一化.7.2.2属性表中的噪音为了评估属性表中的噪音,本文从所有商品类别中随机抽样出10000个商品,然后人工统计每个商品的属性表中缺失值和错误值的个数,结果见图6(商品分别按照缺失值和错误值所占的比例降序排列).统计结果表明90%的商品属性表的存在明显数据质量问题,有50%的商品属性表的数据质量问题严重.7.2.3数据填充和数据清理算法的评估在已经标注好缺失值和错误值的10000个商品中,利用本文提出的数据填充和数据清理方法对数据进行祛噪,将结果与标注数据进行比较.在实验Page11中,我们分别设定保守参数γ为0,0.2和0.4,实验结果如表3所示(其中最好的结果用粗体表示).实验结果表明本文提出的数据清理算法在进行数据填充时的准确率和召回率都很高(尤其是当γ=0.1时),错误值修复的效果也较好(注意本文的场景下,准确率比召回率更为重要,因为对正确值的错误修改比遗漏修改错误值更为严重).在后续的实验中,我们设定缺失值填充时的γ=0.1,设定错误值修复时的γ=0.2.参数γ=00.850.780.720.75γ=0.10.940.770.810.67γ=0.20.950.750.920.65γ=0.40.980.430.930.257.3商品归一化效果评估在效果上进行对比:我们将本文的商品归一化方法与以下3个方法(1)对比方法1(标题文本相似度).此方法只是用商品的标题来进行商品归一化,如果两个商品的标题之间的字符串相似度大于某个事先给定的阈值η,则认为两者是匹配的.我们发现编辑距离和N-gram的效果不佳,因此我们使用中文分词工具对标题进行分词,然后计算它们的Jaccard相似度.(2)对比方法2(标题的带权文本相似度).此方法与对比方法1基本相同,区别是在计算Jaccord相似度时,对每一个词利用tf-idf值加权.(3)对比方法3(自适应的商品归一化).此方法基于文献[19],使用标题、价格和文本描述作为特征,然后使用感知机来训练每个特征的权重.与文献[19]不同的是,我们在该方法的特征中添加了属性表.(4)对比方法4(自适应的商品归一化).此方法是对对比方法3的扩充,除使用标题、价格和文本描述作为特征外,还添加属性表、评论和图片作为特征,其目的是为了与本文提出的方法进行更公平的对比.我们将实验数据中的每一个商品类别的数据都平均分为5组,并进行5则交叉验证.与传统的交叉验证不同的是,在每组验证中,我们只用1组数据对模型进行训练,用其余4组数据对训练的模型进行测试.这是因为在C2C环境中,商品数目太大,以至于只有很小一部分数据能够被标注,只用一组数据作为训练集是为了尽可能拟合C2C网站的真实环境.在训练集中,我们将所有两两匹配的商品对作为正样本,将所有两两不匹配的商品对作为负样本.若一共有k个实体(k款商品),每个实体分别有N1,…,Nk个商品,则总共有∑k∑Ni-∑kC2往远大于正样本数,这将造成训练的不平衡问题.因此需要根据某一采样率对负样本进行均匀采样,使得正负样本的数目相当.在本文的实验中,正样本与负样本的比例为110,故将采样率设定为0.1.7.3.1实验结果的评测标准结果:我们使用准确率和召回率来评测商品归一化其中|TP|、|FP|和|FN|分别是真阳数、假阳数和伪阴数.如果模型将两个相互匹配商品预测为“相互匹配”,则是真阳的结果,如果预测为“相互不匹配”,则是伪阴的结果.如果模型将两个相互不匹配的商品预测为“相互匹配”,则是假阳的结果.我们使用F-measure来综合评价准确率和召回率:7.3.2实验结果和分析我们在12个商品类别上分别用本文的方法和3个对比方法进行了实验.对比方法1和对比方法2不需要训练模型,可以通过改变阈值η来调整准确率和召回率之间的平衡.η越大,预测为“匹配”的要求就越高,从而提高了准确率,但于此同时牺牲了召回率.同样,降低η可以提高召回率,但却牺牲了准确率.对比方法3和本文的方法中使用了5则交叉验证.需要注意的是,这两种方法的实质是通过训练数据集决定不同特征的权重,因此训练集必须覆盖所有的特征,即保证任意一个特征都必须至少出现在一个训练样本中.这一要求很容易满足,因为在进行模式集成之后,每一个商品类别的属性表中不同的属性数不会超过40.在对比方法和本文的方法中不需要去指定偏置w0,但可以在测试时调整w0来平衡准确率和召回率.本文的方法需要在计算特征相似度时设定空值惩罚系数np.通过实验发现,np在取值为[0.1,0.4]的实验效果最好,且在此范围内Page12np的取值变化对实验结果影响很小,因此本文设定np=0.25.图7展现了4个对比方法和本文的方法在12个商品类别上进行商品归一化的平均准确率和召回率.实验结果表明对比方法1和对比方法2的效果不佳,而且当准确率较高时召回率很低.这是因为当η设为很高的值时,这两个方法只将标题几乎相同的商品预测为“相互匹配”的商品,因此准确率高,但召回率会非常低.于此同时,准确率随着召回率的提高而急剧下降,这是因为标题中含有的不相关词导致“不匹配”的商品标题也会较为相似.对比方法2效果要好于对比方法1,这是因为对比方法2在计算字符串相似度时给词加上了由tf-idf计算的权重,因此那些相对流行但与商品内容无关的词的所起到的噪音作用就被降低了.但对比方法2的效果依然远远不能达到实际需求,这也说明了进行商品归一化不能仅仅用商品的标题作为特征.对比方法3的结果远远优于前两个方法.这得益于此方法使用了价格和文本描述这两个更为丰富的特征并使用了机器学习的方法来训练特征的权重.对比方法4在对比方法3的基础上有所提高,这是因为它是用了评论、属性表格等额外的特征.但对比方法4的提升空间十分有限,这反映出评论、属性表格尽管有用,但由于其噪音太大,直接使用难以获得较大的帮助.本文的方法明显优于前4个比方法,这是因为:(1)本文进行了模式集成,因此那些本质上相同、表述不同的属性可以被作为一个属性对待;(2)本文进行了缺失值填充和错误值修复,使得用来训练模型的特征更为全面和准确.为了验证模式集成和数据清理在本文提出的方法中的作用,在本文的方法基础上定义了3个变种:(1)本文的方法(CA);(2)不进行数据清理(w/oDC);(3)既不进行模式集成也不进行数据清理(w/oDCorDRep).分别按照上述3个方法在12个商品类别上进行实验,实验结果的F-measure如图8所示.实验结果表明,进行数据清理的实验效果在整体上要优于既不进行模式集成也不进行数据清理的实验效果,从而验证了模式集成对商品归一化效果提升的贡献.此外,进行数据清理后,各个商品类别的实验效果都得到了明显提升,从而验证了数据清理对实现商品归一化的重要作用,以及本文提出的数据清理算法的有效性.图8对比3个变种方法与本文方法的实验结果8总结随着电子商务(特别是C2C模式)的发展,日益增长的商品规模使得进行商品归一化这一任务变得越来越迫切.但由于商品数据噪音严重且缺乏统一的模式,进行商品归一化的困难很大.本文提出了一种将数据预处理和商品归一化相结合的架构,通过充分利用已有数据,进行数据的验证以及填充.文章最后在真实数据集上进行了实验,结果验证了本文提出的方法的有效性.本文在进行特征选择的时候,并没有考虑到个属性之间的正交性,这使得本文的方法可能引入冗余的特征,从而造成计算代价的提升和潜在的性能降低风险.如何判断特征之间的正交性及避免引入冗余的特征,将是下一步的研究工作.
