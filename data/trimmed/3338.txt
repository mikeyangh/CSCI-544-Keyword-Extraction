Page1中文深度万维网数据库的现状研究刘玉奎周立柱范举(清华大学计算机科学与技术系北京100084)摘要深度万维网(DeepWeb)已成为万维网上十分重要的资源,是数据库领域的研究热点.目前已有的多数研究主要集中在深度万维网发现、查询接口集成以及查询结果处理等技术层面.然而对于这个超出表面万维网所涵盖信息数百倍的宝贵资源,人们目前还缺乏足够的了解和认识.对于一些基本问题,例如:(1)中文深度万维网的具体规模有多大;(2)中文深度万维网在各个领域上的分布如何等,目前还没有人能给出一个明确的回答.针对这一状况,文中采用数据挖掘中的分类技术,对中文万维网上的深度万维网进行识别,并将其按所在领域的不同进行划分,对以上提到的两个基本问题给出了客观的度量,并对中文深度万维网的现状作了一些相关的统计.文中将主要介绍以100万中文万维网网站首页数据为基础,如何采用分类的技术来解答以上提到的两个问题.实验结果表明,当前中文万维网上,拥有60多万个深度万维网查询接口,其中一半以上属于商业领域,这比较客观地反应了当前我国万维网的使用现状.同时,中文深度万维网中复杂查询接口和简单查询接口约各占一半,而当前的研究主要集中在对复杂查询接口上,对简单查询接口的研究却相对较少,这一结论提醒我们在今后要加强对简单查询接口的相关研究.关键词中文深度万维网;数据库;分类;统计;查询接口1引言中文万维网的飞速发展,使得其在全球万维网中所占的比重越来越大,其内部涵盖的信息也越来越丰富.然而对于其内部所包含的深度万维网,人们目前却缺乏足够的认识.对于一些基本问题,例如:(1)中文深度万维网的具体规模有多大;(2)中文深度万维网在不同领域上的分布如何等,人们还没有明确的概念.为了能够对中文深度万维网的现状进行客观的统计,本文以搜索引擎爬取到的全网数据为基础,通过利用数据挖掘中的分类技术对中文深度万维网进行自动识别,并对其按所在领域的不同进行自动划分.我们的工作主要分两个部分:(1)中文深度万维网的自动识别.通过将其转化为二分类问题,本文以分类算法为基础,通过综合利用中文深度万维网内部的多类不同特征,有效地解决了该问题.(2)中文深度万维网的多分类.通过对中文深度万维网的多类不同特征,按其功能的不同进行分割,本文提出了一种基于层次的分类算法.实验证明,该算法具有较好的性能.据我们所知,这是第一次对大规模的中文深度万维网的分类问题进行研究.通过对中文深度万维网当前总量及其在各个领域上的分布状况进行统计,本文客观地回答了人们对中文深度万维网在总量和分布上存在的困惑.统计结果表明当前中文万维网上存在60多万个深度万维网查询接口.其中一半以上属于商业领域,并且其中所包含的简单查询接口和复杂查询接口约各占一半.但当前的研究主要集中在复杂查询接口上,由于简单查询接口自身的一些特性,使得当前对复杂查询接口的策略无法应用到简单查询接口上,而简单查询内部也蕴藏着海量的数据信息,这需要我们在今后的研究中要加强对简单查询接口的研究.本文将分以下几个部分进行介绍.首先,总结相关工作,然后介绍本文的整体处理流程和对数据集进行的预处理操作、本文提出的深度万维网模型以及对应的特征抽取算法;接着分别对如何实现对中文深度万维网的自动识别和分类进行详细介绍.通过对实验结果进行分析,我们对中文深度万维网的现状做了概括性统计.最后,对我们的工作进行总结和展望.2相关工作深度万维网所包含的数据规模庞大,并且其中大部分都是结构化数据,为了对其进行有效地利用,在工业界和学术界人们都做了许多相关的工作,也取得了一定的成果.按研究内容不同来分,当前对深度万维网的研究,主要集中在对深度万维网的集成[1]和深度万维网的分类[2]上,其中和本文研究相关的主要是深度万维网集成中涉及到的识别问题和深度万维网的分类问题.下面,我们对这两方面前人的相关工作进行概括性总结和介绍.深度万维网的自动识别,是深度万维网研究中的一项基础性工作,只有在获得足够数量的深度万维网后,才能开展相关的深入研究工作.深度万维网一般以表单的形式出现在万维网上,但不是所有的表单都属于深度万维网.文献[3-6]中作者采用文本特征或量化特征来进行深度万维网的自动识别.本文通过对深度万维网的不同类别的特征进行比较,发现在综合利用多类不同特征的情况下,可以达到更好的性能.对于深度万维网的分类问题,在工业界,国外已经存在一些成型的深度万维网目录网站,如Completeplanet、InvisibleWeb和lii等.它们大多通过手工或半自动的方式对深度万维网数据进行标注,成本较高,可扩展性差.有的网站自称使用分类的方法来进行深度万维网的自动处理,但其具体实现算法却未公开,不能为人们所了解和利用.在学术界,人们也提出了许多相应的解决策略.如文献[2,7-9]提出一种基于提交查询的分类算法.通过对深度万维网查询接口进行填写,作者将返回的结果数目作为分类的依据,通过构建混淆矩阵,对深度万维网进行分类.文献[10]作者假设存在一个由有限的属性值构成的模型在指导深度万维网查询接口的构造,通过对不同领域的深度万维网构造不同的模型,作者基于目标函数MD(Model-Differentiation)对查询接口进行聚类.文献[11]通过利用查询接口的属性标签、价格和图像数量等特征,在400多个查询接口上进行试验,作者称可以达到90%的准确率,但其工作只是针对商业领域的深度万维网.文献[12]中作者提出一种基于页面信息和Hub信息进行深度万维网分类的算法.文中首先通过利用深度万维网所在网页包含的一些特征对深度万维网进行初步分类,接着作者通过利用Hub信息,对分类结果进行进一步的优化和调整,达到了很好的效果.以上研究都是以英文深度万维网数据集为基础,对其多分类问题进行研究,而缺少以中文深度万维网数据集为基础的分类问题的研究.总体来讲,对深度万维网分类问题的研究,按其策略的不同可以分为基于查Page3询的分类策略和基于非查询的分类策略.基于查询的策略是指,通过填写深度万维网表单,并提交查询,利用返回的结果,对深度万维网进行分类.而基于非查询的策略,则是不对深度万维网进行查询,而是依据其自身的一些特征,对其进行分类的方法.基于查询的策略,其核心问题是查询词的选择和如何利用返回结果.其面临的另一个问题是,需要频繁访问深度万维网所在的服务器,会造成大量网络带宽的浪费.而对于非查询策略,其优点是比较高效,不需要对深度万维网进行查询,通过结合利用信息抽取技术,抽取其所包含的各类特征,具有更高的可扩展性.由于中文深度万维网数据规模庞大,如通过查询的策略对其进行处理将是相当耗时的工作,因此本文采用基于非查询的策略,对其进行自动识别和多分类处理.3中文深度万维网模型和数据处理本节,首先对本文的整体处理流程和使用的数据源进行介绍,接着介绍中文深度万维网模型,以该模型为基础,我们进行中文深度万维网中各类特征的抽取和标准化处理.通过这一步的处理,我们获得了中文深度万维网中的各类特征,为后面进行相应的识别和多分类工作做好了准备.3.1中文深度万维网处理流程和数据来源为了能够对中文深度万维网的现状进行客观的调查,本文以搜狗获得的全网数据为基础,采用如图1所示的流程对其进行处理.整个过程以中文万维网数据为基础,通过对数据进行预处理,过滤掉冗余的数据,接着对其进行特征抽取,并进行相应的深度万维网的识别和多分类处理,最后通过对结果的分析,实现了对中文深度万维网现状的统计.下面对本文使用的数据源和对其进行的相应预处理工作进行介绍.本文使用的数据来源于搜狗搜索引擎所抓取到的全网数据.由于搜索引擎的核心思想是通过链接地址来抓取尽可能多的网页,并对其进行倒排索引深度万维网进行统计).供用户查找.这使得其内部包含各种各样的数据,如属于不同国家的网站等.因此本文通过采用如下3条规则,来获得全部数据集中可能包含中文深度万维网的页面:(1)网站首页页面(本文以网站为单位,对中文(2)页面字符编码为简体中文.(3)过滤掉不存在表单的页面.(4)空表单.即页面中包含表单标签,但自身不包含任何表单控件.通过采用以上规则对全部数据集进行处理,我们获得100多万网站首页包含表单的站点和77万多的中文深度万维网表单(如表1所示).以该数据为基础,我们进行中文深度万维网的自动识别和多分类工作,力图对中文深度万维网的现状进行客观的调查.中文万维网首页包含表单网站总数中文深度万维网表单总数集合;3.2中文深度万维网模型深度万维网一般以表单的形式出现在万维网上,内部特征多种多样,通过对其各类特征的整理,本文提出一种深度万维网(表单)模型,其具体内容如下.定义1.对于任意给定的深度万维网表单-Γ,可以将其表示为四元组形式Σ=〈I,C,S,R〉:(1)I是深度万维网表单自身特征的集合;(2)C是深度万维网表单所在页的上下文特征(3)S是深度万维网表单所在网站的特征集合;(4)R是深度万维网表单返回结果页面的特征集合.其中,对于I来说,其自身又包含多种不同类型的特征,因此,我们做出如下定义.定义2.对于任意给定的深度万维网表单-Γ,将其对应的I特征表示为三元组形式Σ=〈N,T,L〉:(1)N是深度万维网表单内部可量化特征,主要指各类控件个数,这里的控件主要是指:文本输入框、隐藏按钮、下拉框、单选和多选框等.(2)T是深度万维网表单内部文本特征,主要指其中的标签文本和控件对应的某些属性值.(3)L是深度万维网表单内部的链接特征,主要指其Action属性所对应的链接以及深度万维网表Page4单所在网站的网址.对于任意给定的-Γ,通过上面的定义,可以表示为如下的多元组的形式-Γ=〈〈N,T,L〉,C,S,R〉,如图2所示.其中T类特征指的是表单内的文本,如“到达城市”等;N类特征指的是其中各类控件(如图中所示文本输入框)的数量;L类特征指的是表单指向的链接地址等,如点击“酷讯搜索”后指向的链接地址;对于特征R在图中指的是点击“酷讯搜索”所返回的结果页中包含的特征,在图中未标出.对于深度万维网的各类特征,其功能和权重各有不同,通过将各类特征转化为文本形式,本文采用向量空间模型[11]来对其进行描述,并做出如下定义.定义3.对于任意给定的深度万维网表单-Γ=〈〈N,T,L〉,C,S,R〉,将其对应的每类特征,表示为Feature=〈ω1,ω2,ω3,ω4,ω5,…,ωn〉,其中ωi代表特征向量,对于每个特征向量可以表示为一个二元组,ω=(Term,Weight),其中Term由字符组成(Term=[Char]+)代表特征词,Weight代表该特征词能表征其属于某类深度万维网的权重.对于任意给定的两个深度万维网表单-Γ1和-Γ2来说,其对应的相似度可通过如下的公式进行计算:Sim(-Γ1,-Γ2)=γn·N+γt·T+γl·L+其中γ表示各类特征的权重值,N、T、L、C、S和R分别表示对应类型特征的相似度的计算.以本节构造的中文深度万维网模型为基础,通过对其描述的各类特征进行抽取,并结合数据挖掘中的多种不同的分类算法,本文进行中文深度万维网的自动识别和多分类工作,下面对其中的特征抽取过程进行介绍.3.3特征抽取本节主要介绍对深度万维网模型中各类特征进行抽取的具体实现算法.由于本文采用基于非查询的策略对中文深度万维网进行处理,其中不涉及到对深度万维网模型中返回结果(R)特征的利用,因此,对该类特征的抽取将不在本文的讨论范围之内.为了获得深度万维网表单的各类特征,我们采用分步处理的方式对不同类型的特征采取不同的抽取策略.首先,通过利用NekoHTML①将网页转化成DOM②树结构.接着,利用DOM所提供的API接口,获得其中对应的深度万维网表单结点,并将其从整个DOM树中分离出来,并对深度万维网表单结点和剩余的结点分别进行不同类型特征的抽取.对于表单结点,本文主要抽取其内部包含的量化特征(N)、文本特征(T)和链接特征(L).对于量化特征(N),通过遍历DOM树,并对其中各类控件的数目进行统计来完成.对于文本特征(T),本文主要抽取两种类型的文本,一类是深度万维网表单Form结点中所含有的文本;另一类是深度万维网表单内部各类控件的属性值.本文抽取的控件属性主要包括value、name、alt和title.对于这类特征的抽取,通过结合NekoHTML提供的API,遍历深度万维网表单内部的各个控件,将其中包含对应属性的值抽取出来.对于链接特征(L),在去除其链接头(http://或https://)后,通过按分隔符(主要包括点、下划线、斜线、等于号、问号或中划线等)进行单词的切分.通过对处理结果进行观察,我们发现,许多网站采用了驼峰命名法.因此,本文将链接地址按大写字母进行分割,并过滤掉其中的数字部分,例如:URL:http://www.etpass.com/message.php?action=结果:www,etpass,com,message,php,action,list,cidURL:/tip/Default.aspx?displayType=2&ResourceId结果:tip,Default,aspx,display,Type,Resource,IdURL:http://www.yoee.com/Newguolv/Search_at-结果:www,yoee,com,Newguolv,Search,attach,asp对于页面中其它的结点,本文利用和获得深度万维网表单中文本特征相似的算法,通过对转化后DOM树的遍历,抽取出其中的文本结点,并过滤掉其中非中文和英文字符,将处理结果进行相应的特征规范化,作为最后应用的特征.3.4特征规范化由于网页中经常是中英文混杂,因此,抽取出来的特征中也是中英文混在一起,需要我们进行有效的特list&cid=48tach.asp①②Page5征规范化.对于抽取出来的各类特征,本文通过结合利用IKAnalyzer①和SnowBow②来完成对特征中包含的中文和英文进行规范化处理.首先通过最长英文匹配,将其中的英文和中文分离开,接着利用IKAna-lyzer对中文进行分词,并删除掉其中的常用词(如:的,我们,是等),同时,记录下各个单词出现的频率供后续处理的需要;对于英文,通过将全部转化为小写字母后,去除掉其中重复的单词,接着通过利用SnowBow将其转化为对应的词根,同时,和处理中文单词一样,对每个英文单词出现的频率进行统计和记录.经过这一步的规范化处理过程,实现了将深度万维网所包含的不同类型特征转化为深度万维网模型中对应的多元组形式,其中包含各个特征向量和该向量的频率值,为后面进行深度万维网的自动识别和多分类打下了基础.4中文深度万维网自动识别中文万维网形式多样,数据量庞大,其中包含大量的深度万维网,如何有效地将其识别出来,是进行中文深度万维网研究的一项基本工作.本节将主要介绍如何利用中文万维网表单的多类不同特征来判断其是否属于中文深度万维网.4.1问题描述在万维网上浏览网页的时候,人们经常会遇到各式各样的表单,它们以Form表单的形式出现在网页中,其中有深度万维网表单(也称深度万维网查询接口),也有非深度万维网表单.我们的目标就是找到那些属于深度万维网的表单.由于对于某一给定的表单,其只有是否属于深度万维网表单两种可能,因此,本文将深度万维网识别问题转化为一个二分类问题,通过利用表单所包含的多类不同特征,并结合数据挖掘中的分类算法,对其是否属于深度万维网进行判断.中文万维网上的表单数量庞大,通过人工的方式进行判断,虽然可以达到很高的准确率,但将是一项费时费力的工作.因此,需要采用自动化处理的方式,进行中文深度万维网的识别.同时,该算法需要有较好的扩展性,当有新的中文万维网表单加入的时候,能对其是否属于深度万维网进行自动判断.由于机器学习方法具有自适应和高可扩展性的特征,因此本文采用机器学习的办法,来进行中文深度万维网的自动识别.4.2中文深度万维网自动识别算法中文万维网上表单类型多种多样,展现形式也各不相同.通过对中文万维网上表单进行分析,我们发现其中包含的非深度万维网表单主要包括6大类(其中每类后面对应的编号与图3中相应的范例编号相对应):登陆注册表单(1)、投票表单(2)、邮件表单(3)、提交表单(4)、评论表单(5)、翻页表单(6).从图中可以看出,各种类型的非深度万维网在控件数量和标签内容上各不相同,这都给进行中文深度万维网的识别带来了一定程度的困难.中文深度万维网包含多类特征,而对于万维网表单来说,其是否属于深度万维网是对该表单功能的一个描述.因此其所依赖的特征主要集中在表单自身特征上,与其它类别的特征关系不大.因此,本文主要对中文深度万维网自身所包含的3类不同特征(量化特征、文本特征和链接特征)在解决中文深度万维网自动识别问题上的性能进行比较.实验表明在综合利用文本特征、量化特征和链接特征的情况下,可以达到较好的性能.在综合利用中文深度万维网表单中的3类不同特征的基础上,本文对不同分类算法③进行了比较,期待从中找到性能最好的算法.实验证明基于决策树的J48算法具有最好的性能.4.3实验过程根据中文深度万维网的特征的不同和分类算法的不同,本文进行了两组对比实验.在中文深度万维网特征方面,对比了文本特征、量化特征和将多类特征进行组合后的特征.在分类算法方法,本文对14种不同类型的分类算法进行了比较.对于性能的评价,本文采用文本分类中经常使用的准确率、召回率、F-Measure和正确率[2]对不同的实验结果进行评价.同时,本文采用10折交叉验证法[3]这一被广泛采用的验证方法进行实验验证.10折交叉验证法,即将实验数据分类10份,轮流将①②③Page6其中的9份做训练集,剩余的1份做测试集,最后将10次的结果均值作为最终的验证结果.本节使用的实验数据来源于表1中的数据集,我们通过手工方式,从中选取814个表单进行标注,其中包括图3所示的各类不同的非深度万维网表单和一定数量的深度万维网表单.4.4不同特征的中文深度万维网识别对于不同类型特征,我们对其在5种不同的分图4基于不同类型特征的中文深度万维网识别比较4.5不同分类算法的中文深度万维网识别由于不同的分类算法在不同的场景下具有不同的性能[13],基于多类不同特征的组合,我们对14种不同的分类算法进行了比较.以便从中选择出性能最好的算法,进行全部数据集上的中文深度万维网自动识别,实验结果如图5所示.从实验结果可以看图5基于不同分类算法进行中文深度万维网识别的比较类算法上的性能进行了比较,实验结果如图4所示(其中Numerical-Based代表量化特征;Textual-Based代表文本特征;OurENFF代表组合多类不同的特征).从实验结果可以看出,基于量化的分类算法具有较高的准确率,而基于文本的分类算法具有较高的召回率,而综合多类不同特征的分类算法不仅具有更高的准确率,而且具有较高的召回率.出,在基于多类不同特征组合的情况下,许多算法的性能都比较好,如其中ConjunctiveRule、VFI、LWL的召回率几乎达到98%.从整体性能来看,J48分类算法,在准确率、召回率、F-Measure和正确率上都比较稳定,因此,本文基于中文深度万维网表单中的多类不同特征,对J48算法进行分类模型的训练,并在全部数据集上进行中文深度万维网的自动识别.4.6中文深度万维网数量统计通过实验得知,J48在基于多类不同特征的情况下,拥有比较好的性能.因此,通过对J48构建的分类模型进行训练,本文用其对数据源中的70多万中文万维网表单进行中文深度万维网的自动识别,处理结果如表2所示.Page7统计结果显示,当前中文万维网上共有60多万深度万维网查询接口.与文献[14]2006年初统计的74000个相比,增加了近7倍.与CNNIC在其2010年报告①中提出的从2006年初到2009年中国万维网网站总数增长5倍多相比,中文深度万维网拥有更快的增长速度.这说明,在当前中国万维网迅速增长的过程中,许多网站都开始结合利用数据库技术,为用户提供查询接口,方便用户对站内相关信息的查找.5中文深度万维网多分类在完成总体规模的统计后,以其处理结果为基础,本文进一步对中文深度万维网在各个领域上的分布进行统计.本节首先介绍我们构建的中文深度万维网一级分类目录,以该分类目录为基础,接着进行相关的实验介绍.5.1中文深度万维网分类目录当前万维网上存在较多的是表面万维网的分类目录,但各网站之间在分类目录多少和层次深度上都各不相同,没有统一的标准.对于深度万维网的目录结构,国外已经存在一些相应的目录网站,如BrightPlanet、Completeplanet、InvisibleWeb、lii.org、Profusion、SurfWax和SearchEngineGuide等,但在国内还没有见到类似的网站出现.本文通过参考Yahoo分类目录②,构建了一个如表3所示的中文深度万维网根级分类目录.5.2多分类实验过程以本文构建的中文深度万维网分类目录为基础,通过手工标注的方式,我们选取整体数据集中的一万条数据进行标注.以该数据集为基础我们试图寻找一种有效的中文深度万维网分类的策略.从而能够有效地完成中文深度万维网的多分类,并对其在不同领域的分布进行统计.为了对不同分类算法的性能进行比较,首先通过将中文深度万维网的各类特征简单组合在一起,构建分类器,对其性能进行评价.实验结果表明这种基于简单耦合的方式,无法达到很好的性能.通过对数据集的分析,我们发现其中存在大量的冗余特征,因此通过对数据集的特征进行选择,我们重新进行相应的实验,但实验结果仍无法达到很好的效果.受文献[4]的启发,我们通过将中文深度万维网的特征依据其表征内容的不同进行划分,针对不同特征进行不同分类器的训练,取得了较好的实验效果.下面,我们将对进行的各个实验进行介绍.对于不同算法性能的比较,这里使用基于准确率、召回率和F-Measure的评价标准[2].并采用与中文深度万维网识别相同的10折交叉验证法,对各类算法性能进行验证.5.3基于简单组合的分类为了找到最能有效对中文深度万维网进行分类的算法,本文对4种典型的分类算法进行了比较.通过将中文深度万维网的各类特征简单组合起来,对4种不同类型的分类算法在相同的数据集上进行比较实验.期待能从中找到性能最好的算法,并能通过这种简单组合的方式来解决中文深度万维网的分类问题,实验结果如图6所示.从实验结果可以看出,不同分类算法的准确率都比较低,都不到50%,其中以ZeroR的准确率最低,大概在30%左右.而在召回率上,以J48算法最高,将近60%.图6不同分类算法的中文深度万维网多分类由于分类结果比较差的原因,我们对实验数据进行详细分析.通过分析我们发现,由于分类的目录层次比较高,各个分类目录中都包含大量的子类,这使得各个类别的目录在特征上存在很多的交集,并且存在大量的冗余特征.因此需要采取有效的特征①②Page8选择算法,将最能表征深度万维网所属类别的特征保留下来,而将那些冗余的特征过滤掉.5.4基于特征选择的分类基于上一步的实验结果得知,中文深度万维网中大量冗余特征的存在,造成了分类性能的不理想.因此,通过对数据集利用不同的特征选择算法进行特征选择,我们重新展开实验.特征选择算法多种多样,如互信息(MutualIn-formation)、低损降维法(LowLoseDimensionalityReduction,LLDR)和频率差法(RelativeFrequencyDifference,RFD)等,本文采用目前被广泛使用的3种算法[15](文档频率、信息增益和卡方检验)进行相应的比较实验.在进行特征选择后,各类分类算法的性能都有了一定程度的改善.和上一步基于简单组合的分类实验结果相似,除ZeroR外其它各种分类算法的性能相差不大,其中以J48算法的整体性能最好,如图7所示.其中FS-#1表示文档频率特征选择算法,FS-#2表示信息增益特征选择算法,FS-#3表示卡方检验特征选择算法.从实验结果可以看出,在进行特征选择后,整体的实验性能有所改善,其中以信息增益的效果最好,可以达到接近70%的准确率,但召回率却相对低一些.另一方面,从实验结果可以看出,这种基于简单组合的方式,即使进行相应的特征选择,也无法有效地解决中文深度万维网的多分类问题.图7不同特征选择算法的中文深度万维网多分类5.5基于层次的分类基于简单组合的策略,在对中文深度万维网进行特征选择后,仍无法有效地解决其多分类问题.受文献[4]的启发,本文采用一种基于层次的分类算法,对中文深度万维网的特征,依据其表征内容的不同进行分割,并为分割后的特征进行不同分类器的设计,实验证明这种策略具有较好的性能.对于中文深度万维网特征的分割,我们将其分为页面特征和表单特征两部分.其中页面特征,主要是指深度万维网所在页面所包含的特征,主要包括上下文特征(C)和网站特征(S).而表单特征,则是指深度万维网表单内所包含的各类特征,主要包括文本特征和链接特征,这里我们没有考虑量化特征,因为对于深度万维网来说,其表现形式多种多样,各个表单在表现形式上的不同,使得其在控件个数上相差很大.而这和其所在的领域关联不大,因此本文不考虑中文深度万维网中的量化特征.通过对页面特征和表单特征利用不同的分类算法进行分类器的训练,我们分别构造了页面分类器(PBC)和表单分类器(FBC).对于页面分类器的构造,通过实验,我们选择准确率较高并具有最高召回率的J48算法;而对于表单分类器,我们选择性能较好的SVM算法.对于某一给定的中文万维网表单,首先,我们用页面分类器对其进行分类,如果其置信度高于设定的门槛值(λ),我们认为其是正确的分类结果,并直接返回;而如果其置信度低于设定的门槛值,则将其传给表单分类器,对其重新进行分类,并作为最终分类结果输出.实验证明基于特征分割的层次分类算法具有较好的性能.与基于特征选择后各方面的最好性能相比,具有更好的效果,如图8所示(其中Non-Hier-archicalMethod指基于简单组合的分类;Hierar-chicalMethod指的是基于层次的分类).从实验结果,可以看出这种基于层次的分类算法在准确率、召回率和F-Measure上与基于特征简单组合的分类算法相比,有了很大的提高,取得了较好的效果,拥有70%多的准确率和召回率.6中文深度万维网多分类结果分析通过对中文深度万维网的多分类实验,证明基于层次的分类算法可以获得较好的性能.以该模型为基础,通过利用标注的数据集对其进行训练,我们将训练好的模型应用到中文深度万维网上,对表2Page9中的60多万中文深度万维网进行多分类处理.通过对实验结果进行分析,我们对中文深度万维网的分布和其中包含的简单查询接口和复杂查询接口的比例进行了统计.6.1中文深度万维网分布统计各领域的数量进行统计,结果如表4所示.通过对中文深度万维网进行分类,本文对其在从表中可以看出,比例最多的主要集中在商业与经济和购物两个领域,其中商业占了将近45%,而两者的总和占了将近60%.这与CNNIC在其2010年1月份报告的中国近几年网民应用网络进行商务交易大幅增加的趋势相吻合.越来越多的网民进行网上购物和商务信息的查询,这使得商家更关注于自己在网络上的营销,搭建自己的商务网站,进行相关的宣传和推广活动,从获得的中文深度万维网的数据来看,大部分商业网站内部都包含深度万维网查询接口,方便用户对其相关信息的查找.如果能将这些深度万维网有效地整合起来,将是个无比庞大的信息库,也将对人们更容易了解和获取商业信息产生巨大的帮助作用.6.2简单查询接口和复杂查询接口统计简单查询接口是指查询接口中只有一个输入框,可以利用其针对不同属性进行查询.而复杂查询接口则是指将与后台数据库相对应的多个不同属性显示在查询接口中,供用户进行相应的选择或填写.从功能上来看,简单查询接口方便了人们的使用,并且和传统的搜索引擎的查询接口很相似,可以很容易地将其整合到传统的搜索引擎中.相比较而言,复杂查询接口,需要用户填写更多的信息,其结构也比较复杂,但通过对不同属性进行填写,可以为用户提供更加精准的信息.通过对结果的分析,本文对中文深度万维网中的简单查询接口[16]和复杂查询接口的数量进行统计.结果发现,当前中文深度万维网中,简单查询接口和复杂查询接口所占的比例相当,其中复杂查询接口的数量稍微多一些,约占50.71%,而简单查询接口的数量稍微少一些,约占49.29%,但两者相差不大.而当前的研究大多都集中在对复杂查询接口的研究上,而对简单查询接口的研究却较少.由于简单查询接口的特性,使得现有研究中对复杂查询接口的策略不适用于简单查询接口.例如:(1)在深度万维网接口模式识别问题上不同:识别复杂查询接口模式是要明确其多个输入框各自对应哪个属性的查询;而简单查询接口只有一个输入框,其模式识别是要明确简单查询接口可以查询的属性有哪些.(2)在探测查询策略上的不同:简单查询接口可以接受更为灵活的属性查询,同时用户输入的查询可能对应后台数据库上的多个不同字段.而如何将简单查询接口和复杂查询接口进行综合利用,则有待我们进行更加深入的研究.7结论本文以搜索引擎抓取到的全网数据为基础,通过对其进行相应的数据预处理、中文深度万维网自动识别和多分类完成了中文深度万维网一级分类目录的构建.通过对处理结果的分析,对中文深度万维网的现状进行了概括性统计,客观地回答了人们对当前中文深度万维网存在的两大疑问:(1)中文深度万维网的规模有多大;(2)中文深度万维网在各个领域上的分布如何.通过对实验结果进行统计,我们得知,当前中文深度万维网上有60多万个查询接口,与2006年初人们统计所得的74000个相比,其增长了近7倍.同时,在CNNIC在2010年1月发布的统计报告中称,自2006年初到2009年末,中文网站的总体数目增长了5倍.与其相比深度万维网拥有着更高的增长速度.这说明,当前在中文万维网的发展中,越来越多的网站开始为用户提供查找功能,方便用户对站内相关信息的查找.而在如此快速增长的中文深度万维网后面,隐藏着的是一个海量的数据信息库,如何对其进行有效的利用,值得我们进行深入的思考.对于中文深度万维网在各个领域上的分布,统计结果显示,当前中文深度万维网中占绝大多数的是与商业相关的领域,约占中文全部深度万维网的60%.这与近几年来,网上购物大量涌现的现象相吻合,越来越多的人开始从事网上商业活动,许多企业Page10也开始将自己搬上万维网.另一方面,我们还对中文深度万维网中简单查询接口和复杂查询接口的比例进行了统计.统计结果表明,简单查询接口和复杂查询接口所占的比重相当,各占约50%.这说明在当前中文深度万维网上,人们在追求简单查询的同时也追求准确查询.而当前的许多研究都主要集中在对复杂查询接口的研究上,这需要我们在今后的研究中,注重对简单查询接口的研究,从而能够对简单查询接口背后所蕴含的海量信息进行有效利用.由于本文采用基于分类模型的研究策略,因此对未来不断增长的中文深度万维网具有良好的通用性和扩展性,可以利用该系统对今后中文深度万维网历年状况进行统计,跟踪分析其发展趋势.但另一方面,在多分类算法的准确率上,该系统目前未能达到很好的性能,在今后的工作中,我们将进行相关的研究,对其性能进行相应的改善和提高.
