Page1一种面向非规则引用的Cell多核处理器自适应Cache行策略曹倩胡长军张云星朱于畋(北京科技大学信息工程学院北京100083)摘要非规则问题是大规模并行应用中普遍存在和影响程序效率的关键问题,软件Cache是Cell处理器上解决该问题的一种普遍手段.鉴于通常的软件Cache忽略了非规则引用的内存访问模式,将Cache行设定为一个固定的长度,而加重内存带宽负荷及制约Cache利用率的问题,文中提出了一种自适应的Cache行算法,它根据非规则内存访问的特点,在程序执行过程中不断地调整Cache行的大小,因此减少了传输的数据量.同时,针对不同的Cache行大小,设计了一种相应的软件Cache结构———混合行大小的Cache.它包含多种Tag项数组,每种Tag项数组对应于一种Cache行大小.该Cache设计是一种分级的结构,因为当长Cache行的Tag项数组缺失的时候直接进行缺失处理,而当短Cache行的Tag项数组发生缺失的时候启动缺失处理,同时检查长Cache行的Tag项数组是否命中,若命中,则终止缺失处理.通过对Tag项数组的分级查找,Cache的命中率有了显著的提高.除此之外,文中提出了一种新的行索引对齐的Cache替换策略,它能够在多种不同的Cache行大小并存的情况下实现LRU替换策略.实验表明该文提出的自适应的软件Cache行策略极大地减少了冗余的数据传输,提高了Cache的命中率.同时,与固定的1024B,512B,256B,128B的Cache行的性能相比,自适应的Cache行策略的执行速度分别提高了28.9%,29.7%,32.1%和33.5%.关键词非规则;混合;软件Cache;多核;编译优化1引言Cell处理器是一款异构多核处理器,结构如图1所示.它包含一个基于Power架构的主处理器PPE(PowerPCProcessorElement)和8个协同处理器SPE(SynergisticProcessorElement).PPE是一个通用的双线程的处理器,包含两级硬件Cache结构.每个SPE包含一个软件可控的256KB的本地存储,但不具有硬件Cache.SPE依赖直接内存访问(DirectMemoryAccess,DMA)操作来完成主存和本地存储之间的数据传输.PPE和8个SPE通过互联总线EIB和主存储器以及I/O连接在一起.内存接口控制器MIC提供了EIB和主存之间的接口.非规则问题是指在编译时无法确定内存访问情况,且循环界限和数组引用下标不再是循环控制变量的线性表达式.该类问题在程序中的一个主要体现是对间接数组的访问,如A[B[i]],它的最大特点就是内存访问的非连续性.非规则引用问题在实际应用中普遍存在,如大规模油藏数值模拟生产系统(见图2)、分子动力学(见图3)和流体力学等.非规则问题作为影响大规模科学计算效率的关键因素之一,其优化技术对于充分发挥异构多核系统的计算能力具有重要的理论和现实意义.图2油藏数值模拟程序中的非规则计算程序片段图3分子动力学中计算电子密度的程序片段SPE不能直接访问系统内存,而需要通过显式的DMA操作来完成主存和本地存储之间的数据传输.而每次SPE对系统存储器中变量的访问,如果都简单地通过插入DMA传输指令进行,那么SPE将在等待总线数据时空转,数据总线也将在SPE处理数据时空等,SPE的利用效率将非常低.如果将这些数据分块传输并存放在本地存储中进行重复利用,将有利于提高程序性能.所以,对于非规则的内存访问的情况,运行时系统采用有效的软件Cache技术来模拟硬件Cache,便可以重用本地存储中临时的镜像数据,减少不必要的DMA操作.因此软件实现的Cache成为Cell处理器上解决非规则问题时的通用手段.但现有的软件Cache方案通常忽略了非规则内存访问的特点而将Cache行设定为一固定长度,从而加重了内存带宽负荷,制约了Cache的利用率.本文将提出一种自适应的Cache行策略,它根据非规则引用的特点在程序运行过程中连续地、自适应地调整Cache行的长度.该方案首先收集非规则引用访问到的内存地址,如果有任意两个或多个地址映射到同一条长Cache行的不同短Cache行中,则这样的地址被记作长Cache行地址,其它地址则被记作短Cache行的地址.当地址被划分之后,需要查找Tag项数组(TagEntryArray)以判断命中或缺失.因此,我们设计了一种在Cell多核处理器上实现的软件Cache结构———混合行大小的Cache(HybridLineSizePage3Cache,HLSC).该设计基于传统的四路组相联Cache,它包含了多种Tag项数组(方便起见,本文中给的图仅包含了两种Cache行),每一种Tag项数组对应一种Cache行大小.该Cache设计是分级的,表现为当长Cache行的Tag项数组缺失的时候直接进行缺失处理,而当短Cache行的Tag项数组发生缺失的时候启动缺失处理,同时检查长Cache行的Tag项数组是否命中,若命中,则立即终止缺失处理.经过分级地查找Tag项数组,Cache的命中率有了明显的提高.为了在多种Cache行下解决Cache替换问题,本文对最近最久未使用(LeastRecentlyUnused,LRU)Cache替换策略进行扩展,提出一种新的行索引对齐的LRU策略———IndAlign_LRU策略.它引入一个链表数组,其中的每个链表同时对应于长Cache行的Tag项数组的一个组和短Cache行的Tag项数组的多个组.链表结点的数据域存储了Cache行的索引,通过移动结点来实现多种不同Cache行的LRU替换策略.为了评估自适应的Cache行策略的性能,我们在Cell处理器上实现了HLSC方案,并与传统的固定Cache行方案以及扩展的组索引Cache(Extend-edSet-IndexCache,ESC)策略[1]进行了比较.实验结果表明HLSC策略明显地提高了Cache命中率,极大地减少了传输的字节总数.与扩展的组索引Cache中自适应的Cache行技术相比,加速比可达到1.52.本文第2节介绍相关工作;第3节详细提出自适应的Cache行算法;HLSC的结构在第4节作具体介绍;第5节对HLSC的操作模型进行详细描述;第6节应用多种测试用例评估自适应的Cache行策略的性能;最后为文章的结论及下一步工作.2相关工作及问题分析Cell多核处理器问世之前,关于软件Cache的研究已经有了一些成果[2-7].Miller等人[2]提出了一种软件Cache设计,该方案自动地维护部分或全部的scratchpad内存作为Cache.但其只对指令进行缓存,而本文提到的应用软件Cache来解决非规则问题主要是对数据进行缓存.Moritz等人[3-4]设计的Hotpage/FlexCache需要相当精确的编译器指针分析以标记出可以重用某些页的内存引用,实现起来相当复杂.Udayakumaran等人[5]提出的软件Cache方案通过代码profiling技术以及内存访问的频率进行代码区域分析,根据获得的信息将每个基本块赋予一个时间戳,并在程序的特定位置插入控制代码以实现系统内存与Cache之间进行数据传输.这种方法对静态的内存访问很有效,但是当涉及到基于指针的内存访问时该方案就失效了.文献[6-7]中软件Cache的设计主要是为了在嵌入式系统中减少能耗.Witchel等人[6]提出了DirectAddressedCaches,它依赖硬件记住Cache行的准确位置,因此消除了Tag查找的开销.但是该方案需要定义新的寄存器将load/store操作跟具体的Cache行联系起来,同时还需要提供新的load/store命令才能充分发挥寄存器的作用.Fryman等人[7]提出了软件Cache———SoftCache,它基于对二进位的重写,需要对二进制图进行完整的数据流和控制流分析,因此实现起来很复杂.具体到Cell多核处理器,由于SPE本身没有硬件实现的Cache,软件Cache[8-12]已经成为近几年的一个研究热点.Eichenberger等人[8]提出了一个在Cell处理器上用软件实现的传统的四路组相联的Cache设计.该设计采用LRU的Cache替换策略,以单指令多数据(SIMD)的方式在组内查找是否有匹配.Balart等人[9]设计了一种面向Cell处理器的Cache,它使得用户可以确定一个代码区域,从而避免了Cache冲突,用户还可以在该区域中对多次访问lookup操作以及misshandler操作进行重排,从而有效地将计算与通信重叠起来.该方案对于Cache访问时间局部性很高的特定循环效率很好,但是对一般的循环来讲,由于lookup过程需要对地址执行模操作,从而确定对多个链表中的哪一个进行遍历,因此实现的开销很大.文献[10-12]中提到了在Cell处理器上实现一种混合的Cache结构.该方案首先将内存访问模式划分为两类———高局部性的内存访问和非规则的内存访问,然后提出一种包含两种Cache结构的软件Cache设计,不同的Cache结构采用不同的Cache替换策略.该方案需要精确的内存访问的分类,不但引入了额外的内存开销,实现起来比较复杂.此外,它侧重于区分规则和非规则的内存访问,而忽视了非规则内存访问本身的数据局部性.以上软件Cache实现的共同点是忽略了非规则内存访问自身所表现的数据局部性,而将Cache行Page4设置成一个固定的长度,因此增加了冗余的数据传输,加重了内存访问带宽的负荷,从而影响了非规则应用的整体性能.显然,采用自适应的调节Cache行大小的策略,会极大地提高SPE上本地存储的利用率,减少冗余数据的传输.目前已经有一些基于硬件实现的自适应的Cache行策略[13-15],但由于SPE本身不具备硬件Cache,因此需要研究Cell上的软件管理的自适应Cache行算法.然而这方面的研究成果却很少,典型的工作是Seo等人[1]提出的扩展的组索引Cache(ExtendedSet-IndexCache,ESC)中的自适应的执行算法,它能够在Cell处理器上自适应地调整软件Cache行长度.ESC的自适应调整Cache行的策略作用对象为一个循环,其基本思想是假设该循环在程序运行过程中被多次调用,在前几次调用中分别选用不同的Cache行执行该循环并测得执行时间,从而选出一个最优的Cache行长度.而当该循环被再次调用时,便选择该最优的Cache行进行执行.该自适应的算法存在以下不足:(1)该算法作用的对象为一个循环,而对于循环内的单个迭代区域不起作用.因此,当某个循环其迭代次数很多,并且不同迭代区间表现出不同的内存访问的局部性时,该策略就不够准确.而本文的自适应Cache行策略作用对象为循环内的每个迭代区间,自适应的选择过程更为准确;(2)为了得到某一循环最优的Cache行,ESC的自适应的Cache行算法需要计算该循环被调用的前几次的性能,特别是当候选的Cache行种类比较多时,性能比较可能会引入更大的开销;(3)该算法只对循环在应用中被多次调用的情况起作用,而当某个循环在程序执行过程中只被调用了一次或很少的几次时,该自适应的算法就失效了.而本文提出的自适应Cache行策略对循环被调用的次数没有要求.3自适应的Cache行策略本节给出自适应的Cache行算法,根据非规则引用的特点连续地、自适应地调整Cache行的长度.它首先将非规则引用访问的内存地址收集起来,并存放在一个临时数组ea中.之后将这些地址对齐到长Cache行的边界,并将对齐后的地址存放在另一个数组work_ea中.如果work_ea中有相同的元素,则说明它们的内存地址是能够在长Cache行的边界对齐的,并且如果该内存地址映射到不同的短Cache行地址中,则这样的地址就可以合并为一个长Cache行地址.为了便于描述,本文从NASbenchmarks[16]的CG中提取出了一个循环,将其边界标准化,如图4(a)所示.该自适应的算法针对非规则引用p[colidx[k]]进行最优的Cache行选择,为了便于描述,该算法提供了两种可选的Cache行,其过程如图4(b)所示./第1步:初始化/lb_tmp=0;ub_tmp=0;Longline=256;//长Cache行Shortline=128;//短Cache行do{/第2步:动态地确定迭代区间/ub_tmp=collect_dynamic(lb_tmp,ub_tmp);/第3步:自适应的Cache行选择过程//将收集到的地址存储到数组ea中/for(k=lb_tmp;k<ub_tmp;k++)ea[k]=&p[colidx[k]];/将收集到的地址对齐到256B的边界并存储到数组for(k=lb_tmp;k<ub_tmp;k++)work_ea[k]=ea[k]&(~(Longline-1));/在数组work_ea中查找相同的值,比如,work_ea[i]=search_same_data(work_ea,i,j);if((ea[i]&(~(Shortline-1)))!=i,j被记作长Cache行地址的索引;其它下标被记作短Cache行地址的索引;/第4步:迭代内的计算循环/for(k=lb_tmp;k<ub_tmp;k++)if(k为长Cache行地址的索引)sum+=a[k]长Cache行对应的操作(ea[k]);elsesum+=a[k]短Cache行对应的操作(ea[k]);/返回值ub_tmp作为下次循环的lb_tmp/lb_tmp=ub_tmp;}while(lb_tmp<ub)该过程大致分为以下步:第1步为初始化.简单起见,假设有两种可选的Cache行,128B和256B.第2步为确定迭代区间.迭代区间指连续两次组冲突之间的迭代上下界.本文提出的自适应算法作用的对象是循环内一个个迭代区间,即对每个迭代区间内的非规则访存地址进行长、短Cache行地址划分,因此迭代区间是一个非常重要的因素.一方面,迭代区间不能太小,因为这些迭代要分摊后面地址收集、地址划分及计算的开销.另一方面,迭代区Page5间也不能太大,因为有可能导致物理地址上很临近但访问时间差距很大的两个短Cache行的地址错误地合并为一个长Cache行的地址.因此,该算法提出了一个动态迭代区间,它规定顺序地收集非规则引用访问的内存地址直到发生组冲突的时候停止.为了确定何时发生组冲突,对短Cache行的Tag项数组的每个组设定一个计数器,初始化为0.当一个地址映射到某个组时,该组的计数器加1,并判断该计数器是否到达4(因为是四路组相联),若没有到达,则继续判断下一次迭代的非规则访存的地址映射情况.直到到达第ub_tmp次迭代时,非规则访存地址所映射到的组其计数器达到了4,即发生了第一次组冲突.此时,各个组的计数器均置为0,该次迭代区间的上界为ub_tmp,并将其作为下次迭代区间的下界.为了方便起见,动态确定组冲突的过程在代码中用函数collect_dynamic(lb_tmp,ub_tmp)表示,其返回值为停止收集地址时即发生组冲突时的迭代,该返回值将作为下次地址收集时的lb_tmp,即下次地址收集时的起始迭代.第3步对本次迭代区间内的地址进行长、短Cache行地址的划分.首先,将本次收集到的非规则引用的地址存放在一个临时数组ea中.经过ea[k]&(~(Longline-1))操作,ea中的每个元素即每个地址都对齐到256B的边界上.如果ea中的两个元素ea[i]和ea[j]经过256B边界对齐后的值相等,并且经过128B边界对齐后的值不等,那么这两个地址就可以合并为一个长Cache行对应的地址,下标i,j被记作长Cache行地址的索引.相应地,ea数组中不满足这样条件的地址则被记作短Cache行地址.第4步为本地迭代内的计算.根据第3步确定的下标是否属于长Cache行索引地址,在相应的Cache的Tag项数组中进行查找并进行相应的命中或缺失处理操作,具体的操作见第5节.为了更清楚地说明自适应的Cache行策略,图5给出了一个实例.作如下假设:(1)在某个迭代区间内,有5个有效地址a1到a5位于内存区间[256N,256(N+2))内,其中,N为一正整数;(2)位于内存区间[256N,256(N+1))的数据被记作Li,前128字节的数据表示为Li-1,后128字节的数据表示为Li-2;Li-1和Li-2互为“邻接行”;(3)位于内存区间[256(N+1),256(N+2))的数据被记作Lj,前128字节的数据表示为Lj-1,后128字节的数据表示为Lj-2;Lj-1和Lj-2互为“邻接行”.初始状态下,该迭代区间内所有的地址都记作短Cache行地址,如图5(a).地址a1和a2分别映射到两个邻接行Li-1和Li-2中,在响应其中率先到达的一个内存请求时,如果从系统内存中取到一个短Cache行,则在响应晚到达的内存请求时仍然需要再次访问系统内存取得下一个短的Cache行,即需要两次DMA操作分别从系统内存将Li-1和Li-2取到Cache中.为了降低多次内存访问的开销,本文的自适应Cache行策略将两个短Cache行地址合并为一个长Cache行地址,即将两个短Cache行合并为一个长Cache行,显然响应a1和a2的内存请求时,只需要进行一次DMA操作,将长Cache行Li一次取到Cache中.同理,地址a3也被记作长Cache行地址,见图5(b).地址a4和a5均被映射到Lj-2中,而没有地址映射到其邻接行Lj-1中,所以地址a4和a5均为记作短Cache行地址.总之,该自适应的Cache行策略可以作用于循环内部的迭代区间,对于不同迭代区间中最优Cache行发生变化的循环优势更为明显.同时,与ESC中自适应方案不同,该策略对循环被调用的次数没有要求.4混合行大小的Cache结构设计经过自适应的Cache行算法之后,收集到的非规则引用的地址被划分为长Cache行地址和短Cache行地址.因此,本文设计了一种新型的软件Cache结构,混合行大小的Cache(HybridLineSizeCache,HLSC).它基于传统的四路组相联Cache,但是它引入了多个Tag项数组(简单起见,这里以两个的为例).其具体结构如图6所示.(1)Cache_Storage(Cache存储)用来存储应用数据;(2)Cache_Parameter1用来记录长Cache行相Page6应的参数;项数组;(3)Tag_Entry_Array1为长Cache行的Tag(4)Cache_Parameter2用来记录短Cache行相(5)Tag_Entry_Array2为短Cache行的Tag应的参数;图6混合行大小的Cache的结构Cache_Storage(Cache存储)用来存储应用数据,本文将其设置为64KB.Cache_Parameter1用来记录长Cache行相应的参数,它包含长Cache行的大小以及掩码mask1.本节将长Cache行设置为256B,所以长Cache行的数目为n_L=256(64KB/256B).Tag_Entry_Array1为长Cache行的lookup表,它包含了S1(S1=n_L/4=64)个组,每一个TE映射到一个256B的长Cache行.Cache_Parameter2用来记录短Cache行相应的参数,短Cache行设置为128B,则短Cache行的数目n_S等于512(64KB/128B).Tag_Entry_Array2为短Cache行的lookup表,每一个TE映射到一个128B的短Cache行.Cache_Storage中的每一个基本的Cache行有个索引(index),由于长Cache行的Tag项数组的一个组对应Cache存储中的8个基本的Cache行,所以将Cache存储中的基本的Cache行的索引值依次设为0,1,…,7,0,1,…,7.为了在多种Cache行中实现LRU的Cache替换策略,本文对传统的LRU替换策略进行扩展,提出了行索引对齐的LRU策略———IndAlign_LRU策略.它引入了索引链表数组(Index_Link_Array),图7给出了它的初始信息以及它与Cache行的映射关系.项数组;索引以实现多种Cache行的LRU替换策略;(6)Index_Link_Array用来存储Cache行的(7)V1和V2数组用来记录有效位;(8)D1和D2数组用以记录脏字节.图7初始的索引链表数组及其与Cache行的映射关系Index_Link_Array(索引链表数组)是一个由Cache行的索引组成的链表数组,该数组包含了S1个链表,每个链表同时映射到Tag_Entry_Array1的一个组和Tag_Entry_Array2的两个组.每个链表包含了8个结点,每个结点的数据域存储行索引Page7值.每个链表从头结点到尾结点其数据域依次存储了从最早访问到最新访问的Cache行的索引值,通过将对应链表中的结点移动到链头(head)或者链尾(tail)即可以记录基本Cache行的活跃信息.显然行索引对齐的LRU替换策略既可以在单一的Cache行又可以在多种Cache行下实现LRU替换策略.V1和V2数组用来记录Cache行的数据是否有效.当赋值为1和0时,分别表示有效和无效.D1和D2数组用来记录Cache行中的脏字节,以减少Cache行被剔出去时传输的数据量.该Cache设计是一种分级的结构.为了说明该问题,图8给出了长、短Cache行地址的组掩码(SetMask).因为长、短Cache行的Tag项数组的组数均为2的幂,所以在计算组号(SetID)时可以用简单的位操作代替复杂的模运算.即其中,2N_bit等于相应Cache行的字节数.因为短Cache行的Tag项数组包含了128个组,所以需要7位(图8所示的第7~13位,用灰色表示)来确定组号.同理,长Cache行的Tag项数组需要6位(第图9简单的HLSC的操作流程图5.1犔狅狅犽狌狆_犾狅狀犵和犔狅狅犽狌狆_狊犺狅狉狋当Cache接收到一个有效地址为ea的内存请求时,根据自适应的Cache行算法,查询相应的Tag项数组.对长Cache行和短Cache行的查询过程跟传统的四路组相联的过程相似,分别叫做Lookup_long和Lookup_short.5.2犐狀犱犃犾犻犵狀_犔犚犝_犾狅狀犵和犐狀犱犃犾犻犵狀_犔犚犝_狊犺狅狉狋当长Cache行地址命中时,IndAlign_LRU_long被调用;而当短Cache行地址命中时,IndAlign_LRU_short被调用.假设SPE接收到一个长Cache行地址,经过Lookup_long之后该地址命中,匹配的组和路分别为set_L和hit_index_L,IndAlign_LRU_long操作就是将第set_L个链表中结点数据域的值为(2hit_index_L)和(2hit_index_L+1)的结点8~13位)来确定组号.当Cache接收到一个有效地址,将其与短Cache行的组掩码进行按位与操作,如果在确定的组内发生缺失的话,可以将它与长Cache行的组掩码进行按位与操作,因为确定组号的位少一位,则该地址有可能在长Cache行的Tag项数组中命中.5混合行大小Cache的操作模型该部分介绍HLSC的操作模型,主要包含Lookup_long,Lookup_short,IndAlign_LRU_long,IndAlign_LRU_short,Misshandler_long以及Misshandler_short.图9给出了一个简单的操作流程图,下面来分别对这些操作加以介绍.移到链尾,即标记为最新访问的Cache行.图10(a)给出当匹配的路hit_index_L等于0时的一个实例.假定随后Cache接收到一个短Cache行的地址,经过Lookup_short之后该地址命中,命中的组和路分别为set_S和hit_index_S,当满足set_L2=set_S或者set_L2+1=set_S的时候,就表示Tag_Entry_Array1中的第set_L组和Tag_Entry_Array2中的第set_S组同时映射到第set_L个索引链表.当前者满足的时候,表示短Cache地址命中的是Tag_Entry_Array2中的第偶数个组,根据TE与Cache行的映射关系,第set_L个索引链表中数据域的值为hit_index_S的结点移到链尾,记为最新被访问到的Cache行.图10(b)给出了当hit_index_S等于3的时候该条件被满足时索引链表的操作Page8图10HLSC操作的具体实例情况.当后者满足的时候,表示短Cache地址命中的是Tag_Entry_Array2中的第奇数个组,第set_L个索引链表中数据域的值为(hit_index_S+4)的结点移到链尾,记作最新被访问的Cache行.图10(c)给出了当hit_index_S等于3的时候该条件被满足时索引链表的操作情况.总之,在短Cache行地址命中的情况下,对链表的操作以实现LRU的替换策略都称为IndAlign_LRU_short.5.3犕犻狊狊犺犪狀犱犾犲狉_犾狅狀犵当一个长Cache行地址缺失的时候,调用Misshandler_long.用IndAlign(index_L)表示当链表的链头结点的数据域的值为index_L的时候,最早访问的长Cache行的对齐的行索引值.为了便于描述,简单地定义IndAlign(index_L)如下:IndAlign(index_L)=index_L和(index_L+1)当index_L为偶数的时候,当index_L为奇数的时候,IndAlign(index_L)=(index_L-1)和index_L假定Cache接收到一个长Cache行地址,该地址映射到Tag_Entry_Array1中的第set_L组,并且该地址缺失,则Misshandler_long被调用,该过程包含以下几步:①选择最早访问过的长Cache行作为被换出的行.因为链表索引数组规定了链头结点记录最早访问的Cache行的行索引,所以从第set_L个索引链表中选择链头的数据域的值,记作index_L,根据index_L的奇偶性,选择定义(1)或定义(2),从而确定最早访问的长Cache行的行索引值.同时将该长Cache行包含的两个短Cache行的行索引从小到大依次记作index_low和index_high.图10(d)中index_low和index_high的值分别为2和3.②检查对应的V数组并将脏字节写回主存.如果数组V1的对应元素为1,即整个长Cache行的有效位为1,则作为victim的长Cache行中的脏字节被写回主存.如果整个长Cache行对应的有效位为0,可是长Cache行中的两个短Cache行无论哪个对应的有效位为1,则相应的短Cache行的脏字节写回主存,并将其有效位置为0,同时将长Cache行对应的有效位置为1.③从主存中取得需要的长Cache行的数据,同时将作为victim的长Cache行对应的结点移至第set_L个索引链表的链尾.5.4犕犻狊狊犺犪狀犱犾犲狉_狊犺狅狉狋用IndAlign(index_S)表示当链表的链头结点的数据域的值为index_S的时候,最早访问的短Cache行的行索引值.对于一个映射到Tag_Entry_Array2中第set_S组的短Cache行的地址来说,IndAlign(index_S)定义如下:当set_S是偶数的时候,IndAlign(index_S)=earlist(0,1,2,3)(3)当set_S是奇数的时候,IndAlign(index_S)=earlist(4,5,6,7)(4)这里earlist(para1,para2,para3,para4)中的4个参数表示短Cache行的行索引,earlist(para1,para2,para3,para4)表示括号中4个短Cache行中最早访问的Cache行的索引.假设Cache接收到一个短Cache行的地址,该地址映射到Tag_Entry_Array2中的第set_S组,并且满足set_S/2=set_L,如果该地址在Tag_Entry_Array2中缺失,它跟长Cache行的缺失不一样,在调用缺失处理的同时检查Tag_Entry_Array1.如果在Tag_Entry_Array1中查到一个有效匹配,则立即终止缺失处理,之后的操作类似于短Cache行的命中.如果在Tag_Entry_Array1中仍然缺失,则返回Misshandler_short的值.Page9为了清楚地描述该过程,图11给出了一个局部的HLSC的结构图.假定短Cache行的地址映射到第set_L个链表,该链表对应的短Cache行标记为L[0]到L[7].Misshandler_short的具体实现如下:①选择最早访问的短Cache行作为victim.判断set_S的奇偶性,从而根据定义(3)或定义(4)确定最早访问的短Cache行的索引index_old.图11中假定index_old等于5.②检查对应的V数组并写回脏字节.先检查index_old对应的长Cache行的有效位V1[2]是否有效.如果有效,则L[4]和L[5]组成的长Cache行的脏字节写回主存,同时将V1[2]设置为无效.如果无效,则检查V2[5]是否有效,如果有效,则需将L[5]中的脏字节写回主存.③从主存中取得需要的短Cache行的数据,填写相应的TE,将V2[5]设置为有效.最后将链表中数据域的值为5的结点移到链尾,记作最新访问的Cache行索引.6实验6.1实验环境该实验在一个3.2GHz的Cell处理器上进行.Cell处理器上的PPE包含一个32KB的一级指令Cache,一个32KB的一级数据Cache以及512KB的二级Cache.每个SPE包含一个256KB的本地存储.测试使用的系统为Fedora9(LinuxKernel2.6.25-14),编译程序使用的是CellSDK3.1.为了评估本文提出的方案,我们在Cell处理器上实现了HLSC方案,并与传统的固定Cache行方案以及ESC方案进行了比较.实验中应用稀疏矩阵向量乘(SpMV)以及NASbenchmarks[16]中的FT、IS、CG、MG进行性能评估.稀疏矩阵来源于佛罗里达大学的稀疏矩阵向量集[17],这些矩阵涵盖了实际应用的很多领域,如计算流体力学、电路模拟、分子动力学、线性规划等.实验中自适应的Cache行算法动态地从128B,256B,512B和1024B中选择最优的Cache行.6.2加速比首先将HLSC的自适应策略与固定的Cache行设计作比较.将256B的Cache行设计的执行速度设置为标准的速度,那么各种Cache设计的加速比如图12所示.整体上来讲,HLSC的执行速度要明显优于固定的Cache行设计的执行速度.跟固定的1024B,512B,256B和128B的Cache行设计相比,HLSC的平均执行速度分别提高了28.9%,29.7%,32.1%和33.5%.特别是MG,它的性能随Cache行长度的改变而发生明显的变化,因此当采用自适应的Cache行策略之后,它的性能提升得最多.IS对Cache行大小不敏感,因此跟固定的Cache行设计相比,HLSC的性能改善不太明显.然后,将HLSC的自适应策略跟现有的Cell处理器上实现的ESC的策略作比较.这两种自适应的算法均从128B,256B,512B,1024B4种Cache行大小中自适应地选择最优的Cache行.以ESC中的自适应算法的执行速度作为基准,标准化了的加速比见图13.图13ESC和HLSC的自适应的算法性能比较Page10整体上来讲,HLSC的自适应算法提高了程序的执行速度,特别是对于MG,性能提升最为明显,加速比可达到1.52.主要在于以下两点:(1)HLSC的自适应算法可以作用到循环内部每个迭代区间,可是ESC的自适应算法只对某个循环起作用,而对内部迭代不敏感.MG对循环内的迭代区间Cache行的改变很敏感(如图12所示),因此性能提升较为明显.(2)在某些情况下,ESC的自适应算法选出的Cache行长度可能不是最优的.为了说明问题,作如下假设:①有5种候选的Cache行大小,LS0到LS4,Cache行长度依次增长;②对某个循环来说,这5种Cache行的性能级别分别为1,3,2,4,0(数字越大,表示对应的Cache行的性能越好),则ESC中自适应的选择Cache行的执行过程如下:当循环第一次被调用的时候,选择中间长度的Cache行,即LS2,测得其每次迭代的执行时间TPI(TimePerIteration)记作TPI1;当该循环被再次调用时,选择一个稍短的Cache行(即LS1)执行该循环,此时计算得到每次迭代的执行时间为TPI2.根据假定的性能级别,TPI1肯定会比TPI2大,ESC的自适应算法会认为短的Cache行性能会好一些;所以在下次该循环被调用时,ESC自适应的算法选择一个更短一些的Cache行(即LS0)来执行该循环,并测得此时的TPI为TPI3,根据假定的Cache行的性能级别,TPI3比TPI2大.因此,ESC自适应的算法选择最小的TPI对应的Cache行(即LS1)作为其最优的Cache行.但是,从假设的性能级别可以看到LS3才是针对此循环的最优的Cache行.产生这样的问题主要因为:当TPI1比TPI2大时,ESC的自适应算法会认为短的Cache行性能会好一些,这个推理不一定成立,因为在长度上连续的两种Cache行对某个循环来说,其执行性能不一定连续,即可能出现随着Cache长度依次递变,执行性能却发生跳变的情况.从图12可以看到MG是一个随Cache行长度递变性能会出现跳变的应用,因此MG的性能提升受到了ESC中自适应算法的限制.SpMV中稀疏矩阵向量乘的循环只被调用了一次,为了测试两种不同自适应策略下的性能,本文将选择中间长度的256B和512B中性能较好的256B作为ESC中自适应策略确定的最优Cache行.ESC算法需要多次调用某个循环以确定最优的Cache行,而SpMV中稀疏矩阵向量乘的循环只运行了一次,所以该应用从ESC的自适应策略中获得的性能提升并不明显.而本文提出的HLSC的自适应算法对循环被调用次数没有限制,因此对于SpMV应用来说,HLSC的自适应策略明显优于ESC的自适的算法.IS是一个对Cache行变化不敏感的应用,所以对于固定的Cache行、ESC的自适应算法和HLSC的自适应策略性能变化都不明显.6.3传输的字节数如果将128B的Cache行设计传输的字节数作为基准,则各种Cache行设计传输的字节数如图14所示.很明显,HLSC传输的字节数要少于固定的1024B,512B,256B和128B的Cache行设计所传输的字节数.特别是跟最长的1024B的Cache行设计相比,HLSC设计传输的字节数约占1024B的Cache行设计的31%.主要在于假如计算中只需要一个字节,1024B的Cache行设计需要传输全部的1024B的数据,而HLSC设计可能只需要传输128B的数据.HLSC设计传输的字节数之所以也会少于128B,256B等短的固定的Cache行设计是因为当短的固定的Cache行设计遇到缺失处理时立即传输数据(不管是直接从内存中取数还是组冲突之后先剔出Cache中的数据再从内存中取数据),而HLSC方案有可能在较长的Tag项数组中找到需要的数据,而无需进行冗余的数据传输.6.4命中率图15给出了以128B的Cache行设计的命中率为基准的情况下,各种Cache行设计的命中率.与固定的1024B,512B,256B和128B的Cache行设计相比,HLSC的命中率分别提高了20.5%,21.1%,23.4%,24.7%.主要因为HLSC设计是分级的,当Page11短Cache行的Tag项数组发生缺失时,还要检查较长Cache行的Tag项数组是否命中.在大多数情况下,固定的长Cache行的命中率要高于固定的短Cache行的命中率.因为一次长Cache行的DMA操作取到的数据可能相当于多次短的Cache行的DMA操作取到的数据.以固定的1024B和512B为例,如果Cache接收到两个连续的内存请求,并且请求的数据均未取到Cache中,这两个地址分别映射到1024B的Cache行中的前、后512B,那么采用固定的512B的Cache行的两次请表1除Cache外的额外存储开销CacheLineTable(CLT)LTEN=6NLTEN=2NLTEN=6NTotalSize(TEArray+CLT)14N32S+6N表1给出了除了Cache存储以外各种Cache结构的额外存储开销.其中:“FAC”和“4WC”分别代表全相联Cache(fully-associativecache)和四路组相联Cache(4-wayset-associativecache).HLSC采用的是128B,256B,512B和1024B4种Cache行结构.HLSC的额外存储负荷比FAC和4WC的多一些,但是在一个数量级上差别不明显.ESC结构中的S的值是最接近S的2的幂,所以S的值跟S在同一个数量级上.因此,4种Cache结构的额外存储开销相当.7结论和下一步工作本文提出了一种在Cell异构多核处理器上解决非规则问题的自适应的Cache行策略,它根据非规则访问的特点自适应地调整Cache行大小,极大求一定都是缺失,而采用固定的1024B的Cache行设计的第一次请求的地址缺失,但第二次请求的数据已经被第一次DMA操作取到Cache中,因此命中.从图14和图15中可以看出,HLSC性能提高不仅来源于减少了冗余的数据传输,还在于提高了Cache的命中率.6.5存储开销比较为了形式化表示存储的开销,作如下假定:(1)Cache存储中包含N个128B的Cache行,则四路组相联的Cache中包含S(S=N/4)个组;(2)ESC中的组数表示为S,依据ESC的设计,S是跟S最接近的2的幂;(3)Tag是4个字节的整数,脏位和有效位均为一个字节;(4)每个TE需要一个四字节的行索引(line_index);(5)“LTE”(LineTableEntry)代表行表项,在FAC和ESC结构的行表项中均包含了一个跟TE中一致的Tag项(TagEntry,TE),用以记录全局地址.地减少了冗余的数据传输.同时,设计了一种混合的软件Cache结构———HLSC,它包含了多种Tag项数组,提高了Cache的命中率.除此之外,文中还提出一个面向多种Cache行设计的LRU的替换策略.实验结果证明自适应Cache行技术极大地提高了Cache命中率,跟固定的1024B,512B,256B,128B的Cache行的性能相比,自适应的Cache行技术的执行速度分别提高了28.9%,29.7%,32.1%和33.5%.并且与ESC相比,HLSC不仅具有明显的性能提升而且应用范围更为广泛.下一步工作中,我们将同时考虑规则和非规则两种内存引用的特点[18],把该自适应的Cache行的策略扩展到混合的内存引用中[19-20],从而使该策略更具通用性.同时通过观察发现,预取技术能有效地将通信(DMA操作)与计算重叠起来,因此,设计一种面向非规则引用的自适应软件Cache的预取技术将是我们下一步的研究重点.Page12
