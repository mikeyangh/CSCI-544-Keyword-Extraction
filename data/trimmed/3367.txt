Page1提高堆数据局部性的动态池分配技术王振江1),2),3)武成岗1),2)张兆庆1),2)1)(中国科学院计算机系统结构重点实验室北京100190)2)(中国科学院计算技术研究所北京100190)3)(中国科学院研究生院北京100049)摘要动态内存分配在现代程序中被广泛使用.通用的内存分配器通常关注于降低运行时开销和内存利用率,而在发掘所分配对象之间的特性方面有所欠缺.文中展示了一个低开销的动态优化技术“动态池分配”.它在运行时构造存储形状图,从中发掘动态分配对象之间的亲缘性,把具有亲缘性的对象聚集到一段内存区域(称为内存池)里,改善了它们的数据布局.作者在实际机器上实现了动态池分配原型系统,并在GCC--O3编译的一些大量使用堆数据的SPEC2000和2006程序上进行了测试.原型系统在两台实际机器上获得了13.1%和11.8%的平均加速比,对一些程序的加速高达82.2%.此外,作者还研究了CPU的高速缓存大小对池分配效果的影响.关键词池分配;变长调用链;亲缘性;数据布局;动态优化1引言体系结构的发展,处理器的性能以指数级速度增长[1].而内存性能的提高则相对缓慢,于是二者之间形成了一个巨大的鸿沟,并且这一鸿沟在可预见的在过去的几十年中,由于半导体工艺的进步和将来,还存在继续扩大的趋势.访存速度低已经成为Page2阻碍计算机系统性能发挥的主要瓶颈.现代处理器主要依靠高速缓存来缓解内存与处理器之间的性能差异,因此如何提高应用程序的数据局部性,使之充分利用处理器缓存,就成为提高计算机系统整体性能的关键问题之一.在很多应用程序中,堆中的数据占其数据集的很大一部分,对这些数据局部性的优化具有重要的意义.通用堆内存分配器(如Linux操作系统中广泛使用的dlmalloc)的关注点集中在降低运行时开销、减少内存碎片和提高并行分配能力等,很少考虑所分配对象之间的局部性.另一方面,程序员往往出于方便,根据需求来分配堆上数据,也很少将精力放在维护数据的局部性上.图1(a)展示了一个程序通过调用堆分配函数,交叠地为三个独立的数据结构分配节点空间时,所形成的堆数据布局.堆分配器按照程序对空间的申请序,在连续空间中为每一个节点分配所需的内存.这种策略可以减少碎片,但由于缺少对应用程序的内存分配和访问模式的针对性分析,形成较差的数据布局,如图1(a)中同一个数据结构的对象被分散地摆放.图1使用dlmalloc和池分配器的内存空间布局如果这些对象的位置符合它们的访问模式,如图1(b)所示,数据局部性就可以得到改善.一些编程语言(如Java和C#)通过自动内存管理机制“垃圾收集器”(garbagecollector),可以在运行时改变对象的位置.Huang[2]、Chilimbi[3]和Serrano[4]等通过在线采样技术收集和分析这些对象的各种特征,把关系紧密的对象移动到相邻的位置,提高了它们的局部性.然而,现在有相当多的应用程序在运行时没有垃圾收集器的支持(如大量的C和C++程序),这种环境下移动对象必须显式更新所有对该对象的引用.由于程序里潜在的别名指针,运行时系统很难自动更新所有对该对象的引用,而任何遗漏的旧引用都可能会使程序发生错误.因此,很多工作转而关注于在对象的分配时就把它放置在适当的位置.Lattner[5]在编译时刻分析程序的源代码,识别对象所属的数据结构,把同一数据结构的对象从一段连续的内存空间(称为内存池)里分配,遍历数据结构时可以获得更好的局部性.但是很多情况下,用户并没有条件得到源代码并进行重新编译,因此更需要一种能够直接对二进制程序进行优化的方法.Seidl[6]和Barrett[7]通过事前训练获得对象的访存频率或生命周期等信息,在随后的运行中把相似的对象从同一内存池里分配.这种方法依赖于有代表性的训练集,但对许多实际应用来讲,很难获得一个有代表性的训练集,并且事先的训练也会成为用户的一个大的负担.本文提出了一种对用户透明的、轻量级动态数据分配技术,在用户态直接优化二进制代码.它在运行时识别对象之间的亲缘性,把具有亲缘性的对象从同一内存池里分配.这种方法不需要用户提供源代码,也不需要寻找特定的训练集.在两台实际机器上的测试数据表明,这种技术对SPEC中的部分测试用例的平均加速比为13.1%和11.8%,比现有的动态池分配技术提高3.7%和5.6%,对某些例子可达82.2%.本文的主要贡献包括:(1)根据亲缘性进行池分配的方法.这种方法识别对象之间的亲缘性,把可能邻近访问的对象从同一内存池中分配,提高了数据局部性;(2)在运行时构造存储形状图的方法;(3)研究了影响池分配效果的各种因素,对何种情况下应该使用池分配技术有指导意义.本文第2节介绍相关工作;第3节介绍我们提出的动态池分配技术;第4节介绍动态池分配的原型系统;第5节进行测试和分析;最后一节是结论.2相关工作垃圾收集器能够识别对象的所有引用,因此它有能力安全地在运行时移动一个对象.在这种机制的帮助下,一些工作利用在线采样技术收集和分析这些对象的访问模式[2]、亲缘性[3]或其它运行时特征[4],把一些关系紧密的对象(如热访存序列里的相关对象)移动到相邻的位置,提高它们的局部性.对没有垃圾收集器支持的应用程序,Chilimbi等人[8]设计了半自动工具ccmorph.在运行时对树结构中的节点进行布局重组.这种方法需要程序员指定树的根节点,并且由程序员确保没有从外部指向叶子节点的指针,以保证重组是安全的.他们还设计了另一个工具ccmalloc,能够接受程序员的提示在指定对象的附近分配新对象.这两个工具都需要Page3源代码和程序员提供的标注.Lattner等人[5]设计了一个编译框架,在其中通过指针分析的结果进行数据结构分析.他们识别程序中用到的数据结构,把属于同一个数据结构的对象从同一个内存池里分配.这种方法同样也需要源代码.针对那些没有源代码的应用程序,出现了一些基于剖面分析(profiling)的方法[6-7,9].文献[9]用剖面分析得到热的访存序列,把序列中相邻访问的对象尽量分配在同一个缓存行中,增加缓存行的重用概率.文献[6]收集训练时堆中对象的访问行为和生命周期,结合分配时的栈指针、路径指针和栈内容等信息预测对象在其它运行中的行为.不同类别的对象会从不同的区域分配,但由于划分的粒度较粗,只能减少页缺失(pagefault)的数量.这些基于剖面分析的方法需要提供有代表性的训练集,但是对一些实际程序,找到这样的训练集并不容易.Zhao等人[10]提出了一种纯动态的优化技术.他们给程序中每一个内存分配点(即内存分配函数的调用点)建立一个专用的内存池.当一个内存分配点分配了足够多同样大小的对象后,它随后分配的内存便从对应的内存池中分配.这种方法对一些程序有不错的效果,但是不能解决程序中的一些复杂情况.这些情况在3.2和3.3节中有介绍.3动态池分配程序在访问数据时,一些对象容易被邻近访问到.我们用亲缘性(affinity)来识别数据的这种性质,提出了基于这种亲缘性的动态池分配方案.这一节将首先介绍我们的亲缘性定义,接着给出我们在运行时构造存储形状图,并在图中进行亲缘性识别的方法,最后介绍内存池的组织形式.3.1亲缘性定义很多数据结构(如链表和树)是由大量节点组成的,每个节点的指针保存在前一节点中.程序要访问其中一个特定节点(设为NODEn),必须从NODEn-1中获得NODEn的地址,而访问NODEn-1又需要从NODEn-2中获得地址……以此类推.图2展示了两个这样的数据结构以及它们典型的访问顺序(图中的序号所示),这些节点很容易被邻近访问到.由于这些节点对象直接用指针互相连接,我们把它们之间的这种关系定义为I类亲缘性.定义1.I类亲缘性.两个对象如果具有相同的类型,并且其中一个对象的指针保存在另一个对象中,那么它们具有I类亲缘性.此外,如果两个对象都和第三个对象具有I类亲缘性,那么这两个对象也具有I类亲缘性(传递性).节点对象里一般包含若干个域.在遍历这些数据结构时,各个节点中的同一个域通常具有相似的访存行为,即它们要么都被访问,要么都不访问.如链表的next域一般都会访问到,而data1域可能在一个循环中访问,而data2域在另一个循环中访问.如果一个域是指向另一种对象的指针,那么这些对象也和这个域一样,容易被邻近访问到.图3展示了遍历链表和数组时的典型访问序列.这些从数据结构中延伸出来的对象之间并没有直接被指针连接,因此我们把它们的这种关系定义为II类亲缘性.定义2.II类亲缘性.两个对象如果具有相同的类型,并且它们的指针被保存在具有I类亲缘性的两个对象的同一个域中,或数组里的两个对象的同一个域中,那么这两个对象具有II类亲缘性.和数据的其它性质(如文献[6,9]中使用的性质)相比,这两种亲缘性是从数据之间的存储关系入手(即这些数据的指针的保存方式),能够直接反映出这些对象容易被邻近访问的特点.依据亲缘性把对象分到不同的对象组里,可以更好地适应它们的访存特点,提高数据局部性.然而程序在运行时分配的对象数量可能非常多,为所有的对象一一进行亲缘性分析的代价是无法接受的.因此我们把相似的对象分到一个对象组中,抽象成存储形状图(StorageShapeGraph,SSG)中的一个节点.通过对SSG中这些节点的亲缘性分析指导池分配.3.2存储形状图我们在运行时低开销地构造存储形状图.我们Page4所用的存储形状图源于文献[11-12],它是一个三元组(V,H,E).V是变量节点的集合,代表全局静态变量和栈上变量.H是堆节点的集合,每个堆节点代表一个对象组(具体构造方法将在3.2.1节中介绍).E(V∪H)×H×O是边的集合,每条边代表了一组指针.当指针是结构体对象中的某个域时,O是这个域在结构体内的偏移;否则O的值为0(此时可以把指针变量看成只有一个域的结构体,0正是这个域在结构体里的偏移).图4展示了一段构造链表的代码示例和它对应的SSG.3.2.1构造SSG中的节点在二进制代码中,全局变量以一个直接地址表示,栈变量以帧指针寄存器(如x86程序里的ebp寄存器)和常数偏移量表示.通过这些特征可以识别出全局变量和栈上变量,从而在SSG中构造对应的变量节点.常用的构造SSG中堆节点的方法是基于调用点的[11],即把从同一个调用点分配的对象划分到同一个对象组里,形成SSG中的一个堆节点.这种方法对部分程序有不错的效果,但不能适用那些采用包装函数(wrapper)的应用程序.图5是SPECCPU2000中的测试用例300.twolf里的一个典型的包装函数safe_malloc,这个程序里的所有内存分配都是通过调用safe_malloc来实现的.safe_malloc函数里的malloc调用点会误导基于调用点的策略,使程序中所有的对象都划分到同一个对象组中,从一个内存池里进行空间分配,这和不charsafe_malloc(size)unsignedsize;{}使用池分配相比没有改善数据局部性,失去了池分配的作用.类似的包装函数在很多程序中都有应用,例如在SPECCPU2000测试集的175.vpr、176.gcc、253.perlbmk和300.twolf等.更糟糕的是,有时这些包装函数可以互相包装几层,例如在SPECCPU2006的测试用例483.xalancbmk中,2.3%的动态内存分配是通过一层以上的包装函数实现的.典型的包装函数的特征是:新分配内存的指针由内存分配函数返回包装函数之后,包装函数没有把指针保存到某个全局变量或某个堆中变量里,也没有对新分配的内存进行写操作,而是把这个指针返回该函数的上一层调用点.由于包装函数没有对分配的内存进行有意义的操作,不足以说明它分配的对象是否具有相似性,也就不应该简单地把这些对象划分到一个对象组中.程序在调用内存分配函数时的调用链包含了上下文信息,可以用来解决包装函数的问题.本文所用的调用链第一项是当前所在函数的被调用地址,随后是当前函数的调用者的被调用地址,以此类推,直到main函数中的调用地址为止.在运行时通过“栈回滚”(stackunwinding)[13]可以得到程序当前的调用链,但由于每次分配都需要用完整调用链选择内存池,栈回滚的开销有时会很大,尤其是调用链很长(例如存在递归函数调用)的程序.一些工作使用调用链的前n项以降低开销,n大多采用经验值.但在不同的程序,甚至同一程序的不同的调用点需要的最佳n值都可能不同.例如在483.xalancbmk中,许多调用点的n值只需要1或2,但是有些调用点需要n>4才能完全消除包装函数的影响.我们提出了使用变长调用链来生成堆节点的方法.变长调用链的定义如下.定义3.变长调用链是完整调用链的一个子集,它从完整调用链的第一项开始,到第一个位于非包装函数内或main函数内的调用地址结束(包含这个调用地址).由于变长调用链是完整调用链的一个子集,它的构造方法也类似于完整调用链,只是结束条件不同:它还需要判断所在函数是否为包装函数.不过每个函数仅需要识别一次包装函数并记录,这部分开销可以被多次分配请求平摊.3.2.2构造SSG中的边从产生堆节点hj的调用点开始,我们对hj里的Page5对象的指针进行数据流传播.当一条访存指令把指针的值写入变量var时,SSG中就产生对应的边.依据var的变量类别,产生的边分为两种情况:(1)var是全局静态变量或栈上变量,对应SSG中的变量节点vk:此时SSG中产生从vk到hj的一条边,其O值为0.(2)var是堆对象obj中的一个域,obj对应SSG中的堆节点hk:此时SSG中产生从hk到hj的一条边,其O值是该域在obj里的偏移.全局静态变量或栈上变量的识别相对简单,而识别堆中的对象则需要其它堆节点的信息.访存指令的内存操作数(通常具有基址寄存器+常数偏移量的形式)代表了一个内存变量,我们在访存指令的IR中创建一个belong集合,表示该内存变量可能属于哪一个堆节点.在传播堆节点hj中对象的指针时,如果该内存变量的基址寄存器的值等于该指针,就表示这个内存变量是hj中对象的一个域,域偏移是操作数的常数偏移量,因此我们在该belong集合中增加hj.这样通过检查该内存变量的belong集合,即可得知它所属的堆节点.图6是在x86平台上构造一小段链表的代码示例.指令1产生了新的堆节点h1,它的指针被指令2写入全局静态变量0x8048234中,因此SSG中增加了从节点v1到h1的边,边的O值为0,如图6(b)所示.指令7的内存变量的基址寄存器ebx是堆节点h1的指针,因此在这条指令IR的belong集合中增加h1.图6构造链表节点的代码示例(x86平台)以及对应的SSG当程序通过指令5分配了新对象(对应SSG中的堆节点h2)后,我们把新对象的指针进行传播.当传播到指令7时,发现该访存指令把新对象的指针写入内存,且该指令IR里的belong集合中包含h1,因此在SSG中增加从h1到h2的一条边,边的O值即为该内存变量的常数偏移量4,如图6(c)所示.我们的传播和分析只在过程内进行(intra-procedure),这是因为它的开销比过程间分析要少.在动态优化系统中必须严格控制额外的开销,如果开销超过了优化的收益则会得不偿失.另外通过在源代码中的观察,我们发现程序在分配了一个对象后,通常很快就会把对象指针保存在某个内存位置,类似图6(a)中的程序那样.因此过程内的分析通常就能够发现这些操作并相应地更新SSG.相对于更精确的过程间分析,我们的方法可能会在SSG中少一些边,但这只可能影响池分配的决策,而不会影响程序的正确性.此外我们还通过一个地址表和解释器(interpreter)来进行补充分析,尽量弥补在精度上的损失.地址表中记录了每个堆节点中最先分配的若干个对象的大小和地址,还有创建的内存池的大小和地址.在堆节点中的第一个对象分配后,我们使用解释器模拟执行随后的一段指令,直到对象的指针不再保留在寄存器中,从而得到指针被写入的实际内存地址(可能有多个).通过查询地址表,可以得到写入地址对应哪个堆节点对象里的哪个域,从而相应地更新SSG.3.3存储形状图上的亲缘性分析在SSG中,每个堆节点代表了通过变长调用链生成的对象组.但是程序中一些具有亲缘性的对象是从不同的内存分配调用点分配的.产生这种情况的原因有两个.其一是由程序员产生,例如程序员在程序里的几个片段中都动态分配节点,并把它们插入同一个链表.另一个原因是由编译器优化产生,例如循环展开(loopunrolling)优化会把循环体内的一个内存分配点复制若干次,变为多个内存分配点.编译器在对函数进行内联(inlining)优化时也会产生同样的问题.如果不把这些对象组进行合并,它们的对象会被分散到不同的内存池里,破坏了数据局部性.表现形式是:两个对象组的对象之间的亲缘性在SSG中的(1)当两个对象组的对象之间具有I类亲缘性时,它们的堆节点之间会有一条边.(2)当两个对象组的对象之间具有II类亲缘性时,它们具有从同一个节点出发的两条边,或者从I类亲缘的两个节点出发的两条边;并且两条边的O值(边代表的指针在结构体中的域偏移)是相同的.我们依据上述特征,在SSG中进行堆节点之间的亲缘性识别,把具有亲缘性的堆节点合并.例如根据上面的形式(1),图6(c)中的h1和h2节点具有I类亲缘性,应当被合并.Page6识别对象之间的亲缘性需要比较这些对象的类型,但是在二进制代码中无法得到类型信息.在我们的原型系统中,将判断亲缘性的条件放宽,即将“两个对象具有相同的类型”放宽为“两个对象具有相同的大小”.尽管大小相同的对象不一定是同一类型,但是我们放宽条件的做法在大多数情况下还是有效的.只有在两个对象类型不同但大小相同,而且满足其它亲缘性判定条件的情况下才会出现误判.即使出现误判,它也只会影响堆中的数据布局,而不会影响程序的正确性.通过对本文所用的测试用例的人工检查,只有197.parser中有19%的误判率,而且这些误判最终并没有对程序性能造成负面影响.3.4内存池的组织当内存池中的对象数量较少时,对它们进行池分配并不会太多改善局部性,反而会增加管理开销和空间浪费.另外内存池中的对象大小较大时,相邻对象的数据很可能不在同一个缓存行中,对这种对象进行池分配也没有太大必要.因此我们的原型系统对每个对象组的最早分配的若干个对象,调用系统的分配函数来分配,并统计对象的数量和大小.只有当对象组里的对象数量超过m,且它们的大小都小于n字节时,才开始对该对象组随后的对象进行池分配,否则将一直使用系统的分配函数来分配.经过实际测试,m=100和n=128是较好的阈值.由于无法预测一个内存池需要多大空间,因此固定大小的内存池容易不够用或造成空间浪费.我们使用的内存池并不是一整块内存空间,而是由若干个内存池段组成的.新创建的内存池只有一个内存池段,其中的空间分配完之后再增加新的内存池段;内存池段中的对象如果都被释放,则回收这个内存池段.通过这种组织方式,每个内存池的大小随着需求增长,既不会因为空间不够而无法分配,也不会造成太多的空间浪费(每个内存池里最多可能浪费最新分配的一个内存池段).内存池段的长度需要仔细选择.太大可能造成过多的空间浪费,而太小会产生过多的内存池段,破坏内存池里数据的连续性,并增加内存池段的管理开销.我们选择了从1KB到64KB的几种不同的内存池段长度,在不同的平台上进行了测试.我们发现虽然这些平台的虚拟页大小并不相同,从4KB到16KB不等,但4KB的内存池段长度在各个平台上都能得到最佳或接近最佳的性能.多数内存池(本文测试用例里占78.6%)中的对象具有固定大小,因此我们在内存池段中采用一种轻量级的分配算法.该算法在内存池段中维护空闲列表(freelist)和最远已分配对象的指针p.分配请求优先从空闲列表中满足,当空闲列表为空时,新对象通过移动指针p来分配.相比需要额外对象头(objectheader)的dlmalloc,这种算法产生的布局更为紧凑.例如在183.equake中有超过15万个16字节的小对象.去掉4字节的对象头会使其占用的空间减少33%(对象需要8字节对齐).此外该算法在分配/回收时只需要移动指针或修改空闲链表头,需要的操作较少;而dlmalloc在释放时会查看前后对象并合并相邻碎片,这需要较多的访存和运算操作.因此这种轻量级的算法比dlmalloc的时间开销要小.图7展示的就是使用这种算法的内存池段分配示例.少数内存池里的对象长度不固定,这些对象通常用作数组或字符串.在它们的内存池段中,我们采用类似dlmalloc的基于空闲链表并且合并相邻碎片的算法.这种算法需要一个对象头来保存一些管理信息,以保证能够正确地对各种大小的内存进行回收.4动态池分配系统我们在x86/Linux平台上实现了动态池分配原型系统DigitalBridge-dopt.它不需要修改操作系统或可执行程序,而是通过指定LD_PRELOAD环境变量[14]的方式,在运行时用动态池分配器替换程序原有的内存分配函数.原型系统的框架如图8所示.当应用程序从堆中申请内存时,如果是新堆节点的第一个对象,动态池分配器会进行第3节介绍的各种分析并更新存储形状图,确定堆节点所属的内存池,把堆节点到内存池的映射关系写入Hash表.堆节点中的后续对象可以直接通过Hash表查到该内存池,避免了对同一个堆节点中的对象进行Page7重复分析.为了进一步减少查Hash表的开销,我们通过插桩模块在一些堆节点的变长调用链的最上层调用点提供一个额外的参数,指明它所属的内存池.这些堆节点的对象分配可以直接使用这个参数从内存池里分配,不再需要查询Hash表.5性能测试5.1平台配置和测试用例实验平台有4个单核处理器(IntelNorthwood家族,2.40GHz主频,一级缓存32KB,二级缓存512KB),2GB内存.操作系统采用的是Linux2.6.27,其中2.9版本的libc所用的内存分配函数是dlmalloc的修改版.实验所用的11个C/C++测试用例选自SPECCPU2000和SPECCPU2006测试集,如表1所示.测试用例的选择标准是在内存池中分配的数据超过1MB(2倍二级缓存大小),并且超过堆中总数据量的1%.表1之外的其它例子由于堆数据布局的变化很小,因此它们的运行时间没有明显变化.测试名编程语言175.vpr197.parser253.perlbmkC300.twolf197.art183.equake473.astar483.xalancbmkC++XML处理447.dealII453.povray482.sphinx3需要说明的是,197.parser中使用的是一个定制的内存分配函数,其行为和dlmalloc类似.由于我们无法截取定制的内存分配函数(这需要从语义上判断一个函数是否具有分配内存的功能),为了达到实验的目的,我们把它定制的内存分配函数替换成调用系统默认的dlmalloc分配函数,以便我们截取内存分配请求.所有测试用例是使用GCC4.3.2的--O3优化选项编译生成的,使用reference输入集.本节所展示的运行时间是程序三次运行时间的平均值.5.2动态池分配的效果本文的基于亲缘性的动态池分配技术对测试用例的加速比如图9所示.图中也展示了现有的基于调用点的池分配技术[10]的性能.加速比以没有池分配优化的程序运行时间为基准.本文的方法提高了7个例子的性能,提升幅度大多超过了20%,剩余的例子也没有明显的性能下降.本文的方法对所有例子的平均加速比达到了13.1%.比已有的基于调用点的池分配方法提高3.7%.动态池分配的收益来自3个方面,它们在总收益中所占比例如图10所示:(1)改善了数据布局.例如483.xalancbmk中的几个对象组各有188718个小对象,在使用系统的内存分配器时,这些数据会被分散到200MB范围内,遍历它们时会产生很多缓存缺失.而这些数据在使用池分配后只占据3MB~6MB的空间,局部性得到了很大改善.(2)减少了数据量.在3.4节介绍的内存池段分配算法不需要额外的对象头,因此程序用到的数据排列的更加紧凑,减少了它们所占的空间.例如在183.equake中有超过15万个16字节的小对象.去掉4字节的对象头会使其占用的空间减少33%(需要8字节对齐).(3)内存的分配/回收更快.在3.4节介绍的内存池段分配算法比dlmalloc要快.197.parser进行了大约10亿次内存分配,因而从中得到了较大收益.Page8有些例子(如253.perlbmk和453.povray)产生的缓存缺失较少,说明它们已具有较好的数据局部性,再进行局部性优化的改善性能的空间不大.有些内存池里的对象不是被程序遍历访问,如175.vpr中的内存池里的对象是用来构造Hash表的,把它们聚集在内存池里也无法改善它们的局部性.因此这些例子没有得到性能提高,但也没有降低.表2是动态池分配优化前后的二级缓存(最末测试用例原缓存175.vpr197.parser253.perlbmk139300.twolf197.art183.equake473.astar483.xalancbmk4992447.dealII453.povray482.sphinx31262312840102表3动态池分配前后的TLB缺失数量测试用例原缓存缺失数/M池分配后的缓存缺失数/M比例/%原TLB缺失数/M池分配后的TLB缺失数/M比例/%175.vpr197.parser253.perlbmk300.twolf197.art183.equake473.astar483.xalancbmk1671447.dealII453.povray482.sphinx3可以看到,483.xalancbmk在平台#2上有更高的加速比(82.2%),而300.twolf和179.art则没有加速(它们在#1上有20%左右的提高).池分配技术在不同机器上的性能差异主要由两个原因引起:(1)缓存的大小.假设一个程序重复遍历大量小对象,系统分配函数把它们分布在12MB的空间一级缓存)的缺失数量.从表中可以看到,动态池分配平均能够减少15%的缓存缺失.453.povray的缓存缺失数量有一定增加(因为我们的动态池分配模块本身也会产生缓存缺失),但是其绝对数量相对其它测试用例来说相当小,对性能的影响也可以忽略.对照表2和图9,可以看到凡是缓存缺失有明显减少的测试用例都得到了性能加速.动态池分配技术也可以降低其中一些程序的TLB缺失,但该实验平台缺乏统计TLB缺失的硬件支持.下一小节将会展示另一实验平台的TLB缺失数据作为参考.5.3缓存大小对动态池分配的影响为了研究动态池分配技术在其它平台上,尤其是缓存大小不同的环境下的效果,我们在另一台服务器(称为#2)上测试了动态池分配技术.平台#2采用2个IntelHarpertown系列4核处理器,有6MB二级缓存和16GB内存.动态池分配技术在这个平台上的加速比如图11所示.平台#2上优化前后的缓存和TLB缺失如表3所示.1014310686206250393316920956899中,此时6MB和512KB的缓存都会工作得很差.池分配后这些对象只占据6MB空间,这时6MB的缓存可以基本装下池分配后的数据,因此可以产生更高的性能提升.然而在更大的缓存下(例如15MB,足够装下池分配前的数据),池分配通常不会提高性能.Page9(2)平台#2的CPU更先进,所以存储墙的问题在这个平台上会显得更加突出.因此存储方面的改善会产生更明显的效果.为了研究缓存大小对池分配的影响,我们在平台#2上采用了基于操作系统中页着色(pagecoloring)[15-16]的缓存划分(cachepartitioning)技术.这种缓存划分技术利用页表,把程序的虚拟空间映射到特定的一些物理页中.这些物理页又映射到特定的一些缓存行中,从而控制了程序可用的缓存大小.我们在平台#2上用不同缓存大小测试了6个产生加速的测试用例,图12显示了池分配后的缓存缺失数量占原程序的缓存缺失数量的比例,有一些比例被设置成了1.0,因为它们的缓存缺失数量太少(小于1亿次).图12不同缓存大小的池分配前后缓存缺失基于上面对因素(1)的分析,当缓存大小和数据量大小相差不大时,随着缓存大小的减小,缺失比例(池分配后的缓存缺失数/池分配前的缓存缺失数)应该呈现一个“V”字型,即先下降再上升.300.twolf和179.art很好地表现了这种趋势,因为它们的访存模式比较简单,而且程序的数据量小于最末一级缓存大小(6MB).473.astar有非常大的数据集,所以图中只能表现出这种趋势的上升阶段.有一些程序含有很多内存池,改变缓存大小对这些内存池的影响不同,因此程序的总体(这些内存池影响的累加)并没有表现出明显的趋势.图13展示了这些测试用例使用不同缓存大小时的池分配加速比.可以看到除了197.parser和473.astar-2之外,加速比的趋势和缓存缺失减少的比例趋势大多是一致的.197.parser在使用3MB以上缓存时,缓存缺失没有减少但仍然有超过30%的加速.这是因为它还得益于更快的分配/回收,而且这部分收益是基本稳定的.473.astar-2在使用小缓存时,池分配的效果降低,但程序的加速比上升.我们用一个简单的模型来说明这个问题.假设程序的运行时间包括由缓存缺失引起的Tmiss和其它部分Tother.池分配使缓存缺失数量变为原来的ratio倍(0<ratio<1,数值参考图12),也近似把Tmiss变为原来的ratio倍;Tother在池分配前后没有变化.程序的加速比由下列公式给出:Speedup=TbaseTopt-1=Tother+TmissTother+Tmiss×ratio-1小缓存环境下会产生更多的缓存缺失,因此Tmiss会增大,使得总加速比增大;而ratio的增加(如473.astar-2)会使总加速比减小.所以最终加速比的变化需要综合这两方面的因素,也因此导致473.astar的两个输入集产生不同的加速比变化趋势.5.4动态池分配的开销分析动态池分配技术的空间开销包括:(1)由于内存池段的大小通常不是其中对象大小的整数倍,因此每个内存池段的末尾可能会浪费一段空间.由于我们最大只对128字节的对象进行池分配,在最坏情况下,128字节的空间浪费占4KB内存池段的3%.在我们的测试程序中,这个比例通常较小.(2)各种元信息,包括从变长调用链到对象组的Hash表(最大约8KB)、二进制代码的中间表示(几倍于二进制代码的大小)、存储形状图(约10KB)等.动态池分配系统的运行时开销来自:(1)对每个堆节点进行的各种分析,(2)每次内存分配需要的查Hash表或执行插桩代码.为了测量这些开销,我们修改了原型系统使其仍然进行正常的分析、查表、插桩等工作.在将要从内存池段中分配对象空间时,将分配请求转发给系统的内存分配函数,使数据布局和不使用动态池分配的布局相似.图14展示了这些开销在总运行时间中的比例.从图中可以看出我们的动态池分配技术在大多数测试用例上的开销很小,平均为0.7%.Page106结论很多程序里,堆中的数据占总数据集的很大部分,提高这些数据的局部性非常关键.池分配技术能够把具有亲缘性的对象从内存池里分配,增加它们所在缓存行的重用.本文提出了一种动态池分配技术,直接对应用程序进行透明的优化以提高性能,扩展了优化的应用范围.本文提出了在运行时低开销构造存储形状图,并在存储形状图上进行亲缘性识别的池分配方法.这种方法解决了已有动态池分配方案的两个重要问题:广泛使用的包装函数可能把不相关的对象聚集到一个内存池里;不同的调用点可能把相关的对象分散到不同的内存池里.我们实现了一个动态池分配的原型系统,在两台实际机器上获得了13.1%和11.8%的平均加速比,比现有方法好3.7%和5.6%,对某些测试用例的加速比可达82.2%.我们还研究了池分配在不同机器上的性能差异的内在原因.
