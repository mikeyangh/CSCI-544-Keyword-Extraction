Page1基于LSH的时间子序列查询算法汤春蕾董家麒(复旦大学计算机科学技术学院上海200433)摘要子序列的相似性查询是时间序列数据集中的一种重要操作,包括范围查询和k近邻查询.现有的大多算法是基于欧几里德距离或者DTW距离的,缺点在于查询效率低下.文中提出了一种新的基于LSH的距离度量方法,可以在保证查询结果质量的前提下,极大提高相似性查询的效率;在此基础上,给出一种DS-Index索引结构,利用距离下界进行剪枝,进而还提出了两种优化的OLSH-Range和OLSH-kNN算法.实验是在真实的股票序列集上进行的,数据结果表明算法能快速精确地找出相似性查询结果.关键词相似性查询;时间序列数据库;子序列;LSH;索引1引言时间序列数据是一种重要的数据类型[1-2],在计量经济学的研究中与横截面数据和纵面数据并列为3大数据形态.随着Web技术的迅速发展和金融信息学的兴起,在时间序列中的各种挖掘分析是当前工商业界和学术界共同关注的热点问题.时间序列相似性查询分为全序列匹配和子序列匹配两种.查找与查询序列长度相同且相似的内容,称为全序列匹配;而查找与查询序列长度不同但相似的,称为子序列匹配.时间序列子序列匹配,根据不同查询标准,可分为范围查询和k近邻查询两类.k近邻查询能找出k个与查询序列最相似的子序列;而范围查询则能找出与查询序列的距离不大于允许误差Δ的子序列.近年来在时间序列数据集上的许多子序列匹配算法被提出来,这些算法主要是采用传统欧几里德距离或者动态时间规整(DTW)作为相似性度量的.由于时间序列存在海量性和超高维特性,这两种距Page2离函数都会造成系统运行效率低下,即若时间序列时间长度为l,欧几里德距离的时间复杂度是O(l),而DTW时间复杂度是O(l2).为提高查询效率,目前最常用的技术是“降维-剪枝-验证”的方法.然而这种方法在验证阶段,仍需要使用现有耗时的距离度量,所以算法时间的减少主要取决于剪枝效果,一旦剪枝效果不理想算法开销要比暴力算法更大.因而如何设计一种有效的且不依赖于时间序列长度的相似性度量成为一个迫切需要解决的问题.由此还需要设计符合新相似性度量的基于索引的剪枝技术.基于上述讨论,本文主要贡献如下:(1)给出了一种基于位置敏感Hash(LSH)的时间序列距离度量方法,并且证明了该距离度量的正确性.(2)设计了基于LSH距离的DS-Index索引结构,并给出了DS-Index的建立、插入、删除算法.(3)提出了两种优化的基于DS-Index索引结构的时间序列子序列相似性查询算法OLSH-Range和OLSH-kNN.(4)将基于LSH的时间序列固定长度子序列查询算法扩展成任意长度子序列查询.本文第2节介绍时间序列子序列查询的相关工作;第3节描述基于LSH的时间序列距离度量方法;第4节给出基于LSH距离的DS-Index索引及其建立、插入和删除算法;第5节给出基于索引的OLSH-Range和OLSH-kNN两种优化算法;第6节给出基于LSH的时间序列任意长度子序列查询算法;第7节是在真实股票数据集上的实验结果及其分析;最后一节是本文总结.2相关工作本文相关的工作主要涉及到以下3个方面:(1)时间序列的距离度量距离度量主要有3种:传统的欧几里得距离度量、基于动态时间规整(DTW)[3-4]和基于编辑距离的距离度量.欧几里德距离度量把时间序列的第i个点和另一个时间序列的第i个点比较,相对简单和直观,计算距离的时间复杂度是线性的;DTW允许时间序列的延伸和压缩,查找结果优于欧几里得距离度量,如果两条时间序列的长度分别是m和n,则计算距离的时间复杂度是O(mn),时间复杂度较高,但可以使用下界函数加速查询速度.而基于编辑距离的距离度量需要先将时间序列离散化成字符序列,常用的有LCSS[5],其利用最长公共子序列模型,优点是对噪声点具有鲁棒性,若阈值参数ε已知且它们的距离小于ε,则两条时间序列的两个点是匹配的;EDR[6]是基于编辑距离的另一种相似性度量,其利用了空白长度数据率计算两条时间序列间的差距.ERP[7]结合了DTW和EDR的优点,通过连续变化的参考点来计算两条时间序列的距离.本文所设计的基于LSH的距离度量是基于Lp-norm(p=1,2,…,)准则的,和欧几里德距离较为相似,其特点是计算速度快、便于索引.(2)时间序列相似性查询查询主要分4种:全序列范围查询、全序列k近邻查询、子序列范围查询和子序列k近邻查询.时间序列相似性查询最早是由IBM的Agrawal等人[8]于1993年提出的,该问题被描述为“给定某个时间序列,要求从一个大型时间序列数据库中找出与之最相似的序列”.文献[8]同时解决了全序列范围查询问题.算法共有两个步骤:第1步是进行降维,并使用R树[9]对转换后的点进行保存;第2步是查询,首先将查询点也进行维度归约,然后使用转换的点进行查询,由于映射函数保证了距离下界,因此可以保证召回率.Keogh等人[10]提出了全序列的k近邻查询算法,并提出了一种APCA降维算法.该算法首先找到k近邻上界,然后使用范围查询找到所有的k近邻.Faloutsos等人[11]提出了一种FRM算法,能解决子序列范围查询问题.该算法首先使用滑动窗口对序列进行切分,然后使用降维技术对窗口降维并保存于R树.查询阶段首先将查询序列切分成互不相交几段窗口,将窗口进行降维,并使用转换后的点查找到所有候选集,最后对候选集进行验证找到所有满足条件的子序列.窗口切分算法还有DualMatch[12]和GeneralMatch[13].DualMatch在切分窗口时引入了二元性概念,GeneralMatch则引入了J滑动窗口和J不相交窗口的概念.Han等人[14]开发了排名子序列匹配算法,解决时间序列子序列的k近邻问题.该算法使用了最小距离匹配窗口对(MDMWP),有效地减少了需要匹配的子序列的数量,极大地减少了I/O开销.本文和现有这些算法的区别是,本文提出了一种新的时间序列度量方法,同时分别设计了范围查询和k近邻查询算法,Page3并设计了维度划分索引用于剪枝.(3)时间序列降维算法由于时间序列的超高维特性,目前已经有很多降维的方法,主要包括离散傅里叶变换(DFT)、离散小波变化(DWT)、主成分分析(PCA),或奇异值分解(SVD).本文使用的是位置敏感Hash(LSH),主要用于设计新的距离度量.3基于LSH的时间序列距离度量我们先简单介绍位置敏感Hash(LocalitySensitiveHash,LSH).LSH是一种高维的空间最近邻搜索算法,基本思想是将距离上较近的点大概率地映射到同一个Hash桶内(Hash桶的个数远远地小于输入点数的总和),形式化定义[15]如下.定义1(位置敏感Hash族).对于Hash族H,如果任意两点满足以下条件,则认为H是(R,c,P1,P2)敏感:(1)如果p-qR,则PrH(h(p)=h(q))P1.(2)如果p-qcR,则PrH(h(p)=h(q))P2.条件(1)保证了两个相近的点以高概率被映射到同一个Hash桶,条件(2)则保证了两个相异的点以低概率被映射到同一个Hash桶.值得注意的是,只有当P1>P2时,此Hash族才有实际意义.这里我们采用文献[16]中的Hash函数定义hi(v)=犪i·v+bi推荐使用ω=4),犪i是一个d维向量,其中每一维的值都满足标准正态分布.bi是随机偏离参数,满足[0,ω]均匀分布.定义2(d-Hash函数).将长度为l的序列v进行d次Hash并连接,构成d-Hash签名:H(v)=〈h1(v),h2(v),…,hd(v)〉.定义3(LSH距离).对于两个长度为l的序列x,y,其LSH距离为DLSH(x,y)=PrH(h(x)≠h(y)).注意:这里的距离表示为概率值,因此距离值域是[0,1],0代表距离最近,1代表距离最远.定理1.距离保序性.令查询序列为q,如果时间序列qA和qB满足:‖qA-q‖>‖qB-q‖0,则DLSH(qA-q)>证明.根据定义1,对于时间序列x,y,若设DLSH(qB-q)0.σ=x-y,就有pq(σ)=PrHh(x)=h(y(其中fp()t=∫t可见fp(t)是一个严格递增函数,可知PrH(h(x)=h(y))是一个随着σ递减的函数,又DLSH(x,y)=PrHh(x)≠h(y(因此,DLSH(x,y)随x-y递增.证毕.在此体系结构中,定义3的LSH距离等价为Hash签名的海明距离(HammingDistance)[18],即DHammingH(x),H(y(其中,fHhi(x),hi(y(Hash签名的长度.由于海明距离无法区分微小的距离差距,因此在这里我们使用曼哈顿距离(ManhattanDis-tance)[19],即其中fMhi(x),hi(y(hi(x)-hi(y)/φ,hi(x)-hi(y)<φ烅烄1,烆在这里φ是一个规约参数,实验中设为φ=10.对于两个长度为l的序列x,y,其计算LSH距离的时间分为两个步骤:第1步,转换为d-Hash签名;第2步计算DManhattanH(x),H(y(为d-Hash签名可以预处理,因而计算LSH距离的复杂度是仅仅和d-Hash签名长度有关,为O(d).距离保序性证明了LSH距离的正确性,即两条序列的欧几里德距离越小,其LSH距离也越近.序列在HASH签名空间下和原空间的距离是等价的.所以使用LSH距离进行子序列的相似性度量可以得到正确的相似结果集.4DS-Index索引本节介绍一种全新的基于LSH的序列索引结构,称作DS-Index索引(DimensionSplitIndex).DS-Index是二叉树结构,下文中我们使用NL代表DS-Index非叶结点,用L代表DS-Index叶节点.叶节点L的结构为简单的数据块,保存不超过θ的d-Hash签名数据点.由此下文中的L除了代表Page4叶节点,同时也代表该叶节点的Hash签名点集.4.1相关定义与定理定义4(维度边界).设有d-Hash签名集合A=x|x=〈x1,x2,…,xd{界被定义为bi(A)=〈minx{}i,maxx{}i〉,x∈A,这里上下界分别是该d-Hash签名集合的最小和最大值.使用bilower(A)代表下界,使用biupper(A)代表上界.定义5(索引边界).设L为索引叶节点,Hash签名维数是d,叶节点L的索引边界由d个维度边界组成,定义为B(L)=〈b1(L),b2(L),…,bd(L)〉.定义6(索引距离).Hash签名x到某索引叶节点L的距离定义为D(x,L)=∑dbi(L)).其中DManhattanxi-bi(L())=fMxi,bilower(L(烄0,烅fMxi,biupper(L(烆定理2.索引距离下界定理.Hash签名x到叶节点L的距离满足D(x,L)minDManhattanx,()y|y∈{证明.由于曼哈顿距离是所有维度距离分量的累加,因此我们只需要证明索引距离的每个维度距离分量都是最小的即可.共有3种情况:(1)当xi<bilower(L)时,由于bilower(L)yi|y∈{}L,所以fMxi,bilower(i())fMyi,x()i,y∈L.(2)当bilower(L)xibiupper(L)时,由于索引距离该维分量为0,必然是最小值.(3)当xibiupper(L)时,由于biupper(L)yi|y∈{}L,所以fMxi,biupper(i())fMyi,x()i,y∈L.以上3种情况中,索引距离的每一维距离分量都最小.索引距离下界定理保证了数据点到该索引叶子节点的距离是距离的下界.通过这个性质,我们可以在保证正确性的前提下进行剪枝.4.2索引的建立、插入和删除算法DS-Index索引结构主要利用了维度划分的二分k-means聚类算法.L代表索引叶节点,θ代表叶节点所能容纳的最大数据点数;NL代表索引非叶节点,非叶节点有两个属性,第1个属性表示其子孙在哪个维度进行分裂,用表示;另一个属性表示其子孙在维的哪个值进行分裂,用表示.算法1.索引建立算法(DS-IndexBuiling).输入:Hash签名点集D,叶节点所能包含最大数据点数θ输出:非叶结点NL1.ifD<θthen将D作为叶节点L返回;2.选择维度;3.在维上,执行一次二分k-means聚类,得到D→4.计算=maxx|x∈D{}1+miny|y∈D{}25.生成非叶结点NL=〈,〉;6.Node1=DS-IndexBuilding(D1,θ);7.Node2=DS-IndexBuilding(D2,θ);8.设NL左子孙为Node1、右子孙为Node2;9.返回NL.索引建立算法是一个递归调用的算法,每次将数据点集D一分为二,即D→D1,D{}2,其中D1∩D2=,D1∪D2=D且x∈D1,y∈D2,xy.由于使用了二分k-means,因此该分裂算法与参数无关,由算法自行选择分裂点.当有新数据点x来到时,使用索引插入算法进行更新.索引插入算法主要使用非叶节点的两个属性〈,〉来定位应该插入的叶节点.首先从根节点开始,新数据点如果x,选择根节点的左子树,否则选择根节点右子树,同样的过程反复调用直到找到叶节点.当插入叶节点后,所在叶节点中数据点个数超过了θ,则叶节点需要进行分裂.分裂过程调用DS-IndexBuilding算法,生成两个新的叶节点和非叶结点,然后将原叶节点删除替换成新的非叶结点.算法2.索引插入算法(DS-IndexInserting).输入:索引index,新数据点x输出:x所属叶节点1.node←index,root;2.while(node∈NL)//node不是叶节点3.ifxnode.node.4.thennode=node.left5.elsenode=node.right;6.将数据点x插入node;7.ifnode.size>θ8.thennewnode=DS-IndexBuilding(L,θ);9.替换node为newnode.当有数据点需要删除时,使用索引删除算法来实现.首先使用和插入算法同样的方法找到数据点所在的叶节点,然后将该数据点从叶节点中删除,若发现叶节点为空时,删除其父节点,将其父节点的父节点的子孙指针指向其兄弟节点,并删除空叶节点.Page5算法3.索引删除算法(DS-IndexDeleting).输入:索引index,需要删除的数据点x输出:根节点root1.node←index,root;2.while(node∈NL)//node不是叶节点3.ifxnode.node.4.thennode=node.left5.elsenode=node.right;6.将数据点x从node删除;7.ifnode.size=θ8.thennode.father.father.child=node.brother;9.删除node,node.father.该索引并非一颗平衡树,理想的树高是logD,其中D代表数据集D的大小,而DS-Index最差情况是D/θ.值得注意的是,我们使用索引是为了快速查询k近邻而并非搜索某一个特定的点,因此叶子节点内数据点的相似性成为索引好否的标准.由于高维数据的“维灾”问题,往往使得聚类效果不尽如人意,而基于LSH距离度量能够有效规避“维灾”[20].5基于DS-Index索引的两种优化查询算法由于时间序列的超高维特性使得匹配结果候选集非常大,即序列中任何一个时间点开始的子序列都可能是查询结果,从而使得子序列匹配中消耗过多的时间[5].所以,在本节中我们给出基于索引的OLSH-Range和OLSH-kNN两种优化算法.定理3.k近邻搜索原则.令S为目前访问的所有数据点中距离查询点q最近的k个数据点集合,Sfarthest代表这k个数据点中距离q最远的数据点.对于数据点p,如果DManhattan(p,q)>DManhattanSfarthest,()q,则数据点p必定不是q的k最近邻.需要注意的是,这里的p和q都是经过LSH签名转换后的新数据点,而非原始时间序列.定理4.近邻分区剪枝原则.令S为目前访问的所有数据点中距离查询点q最近的k个数据点集合,Sfarthest代表这k个数据点中距离q最远的数据点.对于叶节点L,如果D(q,L)>DManhattanq,S()farthest,则x∈L,x必定不是q的k最近邻.证明.由于D(q,L)是q到数据点集合L的距离下界,故必有x∈LD(q,L)>DManhattan(Sfarthest,q),根据定理3得证.近邻查询优化算法OLSH-kNN.由此,我们给出基于索引的固定子序列长度k算法4.k近邻优化查询算法(OLSH-kNN).输入:索引index,查询序列q的Hash签名x,k输出:查询序列q的k近邻结果集S1.S←;//S为最大堆,最大容量为k2.遍历index中的叶节点L3.计算D(x,L);4.根据D(x,L)升序排序所有叶节点;5.foreachL6.ifD(x,L)>DManhattanx,S()farthestthenbreak;//剩余的L被剪枝7.计算D(x,y),y∈L,如果D(x,y)DManhattan(x,8.returnS.k近邻算法采用了剪枝的思想体系,将分区从近到远排序,依次检查叶子节点中的每一个数据点的距离,然后将已经计算过的数据点插入优先队列中.当分区的索引距离大于优先队列中数据点最远距离,则表示剩下的点已经不可能成为数据点的实际k近邻,算法可以终止.优先队列中的数据点即实际k近邻.我们使用最大堆S保存k近邻查询结果.该最大堆的容量为k,当堆中已经有k个签名的时候,如果新加进来的签名比Sfarthest小,则从最大堆S中删除Sfarthest并将新的签名插入最大堆.注意到要遍历index中的叶节点L,叶节点的个数n≈D/θ,因此这部分的时间和叶节点的容量θ成反比.排序使用快排或者归并排序,时间为nlogn.第6行的剪枝和叶节点内Hash签名的紧凑程度有关,而θ越大,叶节点数据越分散,剪枝效果越差,因此这部分时间和θ成正比.基于索引的固定子序列长度范围查询优化算法OLSH-Range和OLSH-kNN算法相同,但不需要使用Sfarthest来动态描述更新剪枝的阈值,因此比OLSH-kNN算法简单.由于篇幅关系这里不给出伪代码.6基于LSH的时间序列任意长度子序列查询算法由于位置敏感Hash族H的参数P1和P2都是固定长度的,LSH距离理论上只能对这种固定长度为d的时间序列进行比较.本节我们针对长度不等的时间序列,设计了一种Hash函数构造方法并解Page6决了这个问题.定义7(同位连接向量).设有同一起始点但不同维数i≠()j的两个向量分别为犃=[a1…i]和犅=[b1…j],则存在i+()j维向量犞是这两个向量的连接,则记作犞=[犃;犅].定义8(错位连接向量).设有不同起始点且不同维数i≠()j的两个向量分别为犃=[a1…i]和犅=[b1…j],若j>i且起始点差值为t,则存在j+()t维向量犞′是这两个向量的连接,记作犞′=[犃1…t;(犃(t+1)…i+犅1…[(j-i)+2t]);犅[(j-i)+2t+1]…j],简记为犞=[犃;()犅t].根据以上定义,任意长度子序列查询可分成以下两种情况:(1)对于长度为k·d长度的时间子序列,可以直接使用同位连接向量进行构造.参数anew构造为k个a的同位连接anew=a;a;…,烉烇烋a[](2)对于长度为k·d+t长度的时间序列,需要先使用同位连接向量,再使用错位连接向量进行构造.参数anew构造为k个a的同位连接加上一个错位连接anew=a;a;…,烉烇烋a[]通过这样的构造,我们能够实现长度大于d的任意长度的时间子序列相似性查询,而不需要重新构造不同长度的Hash函数.令时间序列为T,记T的一段从第i个时间点开始的长度为d的子序列为Ti,d.由于任何一段长度为d的子序列的Hash值都计算过,因此对于从第i时间点开始长度为k·d的时间子序列HTi,k·()d=anew·Ti,k·d+bnew∑kHTi+y·d,()d;对于从第i时间点开始长度为y=0k·d+t的时间子序列,同理可得,HTi,k·d+()t=anew·Ti,k·d+t+bnew即任何一段长度大于d的时间子序列Hash值都可以通过已经计算得到的长度为d的时间子序列Hash值得到.7实验结果及其分析在这一节,我们实现了前文表述的多个算法,采用上海与深圳交易所时间跨度自2007年1月1日到2012年4月1日,共有2347只股票、2110544个数据点、1882791条长度为100的时间子序列.所有实验在配置为2.2GHz的CPU和2GBRAM的PC上实现,语言为JAVA.我们选择基于索引的OLSH-kNN优化算法作为主要实验对象.相应对比算法有2个,一个是使用欧几里得距离的原始序列暴力查询算法(BruteForceEuclidean-kNN);另一个是d-Hash签名暴力查询算法(BruteForceLSH-kNN).7.1DS-Index索引开销由于基于索引的OLSH-kNN优化算法使用了DS-Index索引,所以需要对索引的额外开销进行专门实验,以证明索引是否在时间或空间的开销上都较小.(1)时间开销DS-Index索引的时间开销主要是计算Hash签名和建立索引两部分:计算Hash签名,即使用LSH函数将1882791条子序列映射为d-Hash签名,这里取ω=4;建立索引,即在d-Hash签名的基础上,构造相应的DS-Index,需要说明的是LSH-k近邻查询是基于d-Hash签名而非原始时间子序列.图1是不同Hash签名长度的DS-Index索引开销比较.从图1可以看到,计算Hash签名和建立索引的时间都与Hash签名长度参数d成正比.其次,将计算Hash签名和建立索引两部分累加,不同Hash签名长度预处理开销都在200s~300s之间;而据多次实验结果显示,BruteForceEuclidean-kNN算法进行1次传统的欧几里得距离的k近邻查询时间超过13s,在需要执行上万次OLSH-kNN算法的情况下,这部分时间开销可忽略.图1不同Hash签名长度的DS-Index索引时间开销比较另外,由于DS-Index索引的数据结构是二叉树,DS-Index索引的时间开销还与树的深度有关,这是因为树的深度决定了DS-Index索引插入或删Page7减操作的时间开销.理想的树深是log2况是D引实际与理想树深比较.θ.表1是不同叶节点容量θ的DS-Index索表1不同叶节点容量θ的DS-Index索引树深比较叶节点容量θ实际树深从表1可以看到,实际树深接近于理想树深,虽然并没有保证DS-Index是一颗平衡树,但是维度选择机制和基于聚类的分裂点选择使得实际树深接近于理想树深.(2)空间开销由于叶节点内存储的是所有的数据点,叶节点的存储开销等于数据集的大小,因而DS-Index索引的额外空间开销来自于索引非叶节点个数,由于DS-Index索引是二叉树,其非叶结点个数是也节点个数减1.表2是不同叶节点容量θ的所需额外存储开销比较.可以看出,除了叶节点对所有序列保存所必须的开销以外,索引所需要的额外开销非常的小.表2不同叶节点容量θ的预处理空间开销比较叶节点容量θ7.2算法时间效能比较我们知道,Hash签名的长度d是影响时间效能的一个重要因素.d越长,OLSH-kNN优化算法的查询时间也越长,同时Hash签名的曼哈顿距离就越接近于实际概率值PrHh(x)≠h(y(算也越准确.OLSH-kNN算法的时间分布如表3所示,其运行时间大致可分为两个部分:阶段1是计算查询点到所有叶节点的索引距离,并对索引距离进行排序;阶段2是依次搜索索引叶节点,直到剪枝条件达成.阶段2中被搜索的点集称为候选集,候选集中点的数量除以所有点的总数为候选集占比(CandidateRate).Hash签名长度d阶段1时间/ms阶段2时间/ms候选集占比/%57101215从表3可以看到,阶段1的时间随着Hash签名长度参数d增长而线性增长,那是因为阶段1的时间主要来自于索引距离的计算,索引叶节点个数不变的情况下,维度的增加导致了计算时间的增加;而阶段2的时间变化较大,这是因为随着维度的增加,“维灾”效应慢慢体现,索引的剪枝能力渐渐降低,因此运行时间不仅随维度增加而增加,更会随着剪枝能力的降低而增加.总的来说,表3显示OLSH-kNN算法的剪枝能力较好.不同算法运行时间比较如图2所示.从图2中可以看到,随着Hash签名长度参数d的增长,BruteForceLSH-kNN的运算时间呈线性增长,这是由于计算Hash签名曼哈顿距离的时间是呈线性增长的;而OLSH-kNN算法虽然也是增长的,但运行时间仍远小于相同情况下的BruteForceLSH-kNN算法,这是由于OLSH-kNN采用候选集剪枝策略,需要查询的数据点总比BruteForceLSH-kNN来得少.OLSH-kNN优化算法的不同叶节点容量θ的时间效能如图3所示.可以看到,图3说明了叶节点最大容量θ和查询时间的关系:叶节点最大容量越小,叶节点的签名之间距离就越紧凑,所以剪枝效果就越好,但是由于叶节点的增多使得计算索引距离的时间增加,因此总时间反而增加.在实验中,我们还发现使用θ=100能达到最优查询效果.Page8图3OLSH-kNN算法的不同叶节点容量θ的时间效能7.3候选集占比关系比较从前面实验可以知道,算法时间效能与候选集的占比(CandidateRate)情况密不可分.如表3所示,随着候选集占比不断增加,阶段1的时间变化随Hash签名长度参数d的变化不大,而阶段2则随之快速上升.特别地,当d较大时,OLSH-kNN优化算法时间将主要由阶段2决定,即候选集占比关系决定.图4说明了候选集占比和Hash签名长度参数d的关系,横坐标是d以10为底的对数.虽然从表3中发现,随着d的增长,候选集占比出现快速增长.然而从图4的实验中,我们使用最小二乘法线性拟合,发现候选集占比和lg(d)现线性相关,其相关系数是0.9168.这说明了算法在d较大时有良好的可扩展性.图4候选集占比和Hash签名长度参数d的关系图5说明了候选集占比和叶节点容量θ的关系.从图5可以看出,随着叶节点最大容量θ的线性增长,候选集占比以超过线性速度增长.这是因为叶节点容量越小,每个叶节点的索引距离所代表的距离下界越紧、剪枝能力更强,而叶节点容量变大时,剪枝能力迅速降低.另外从图3可以发现,OLSH-kNN优化算法总运行时间并非是θ越小越好的,因为θ越小则代表叶节点越多,导致计算索引距离次数越多,反而增加了运行时间.图6说明了候选集占比和近邻参数k的关系,横坐标是k以10为底的对数.从图6可以看出,lg(k)线性增长时,即k线性增长时,而候选集占比却没有出现快速增长.这是因为候选集占比在一定比例下,对近邻参数k是有范围覆盖作用的,因为候选集实际个数要比k大许多.图6使用最小二乘法进行线性拟合,发现候选集占比和lg(k)呈现线性相关,相关系数0.898.OLSH-kNN优化算法在参数k上的可扩展性得到了证明.8结束语在本文中,我们较好地解决了时间子序列海量匹配的查询问题.设计了一种全新快速的时间序列距离度量,同时设计了基于该距离度量上的索引结构DS-Index,使用剪枝策略进一步加快了范围查询和k近邻查询的搜索过程.一系列的实验表明我们的算法相比传统的基于欧几里德距离的算法快了数百倍,而额外内存开销却很小.Page9
