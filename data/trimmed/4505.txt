Page1具备反向学习和局部学习能力的粒子群算法高柯夫1)1)(武汉大学卫星定位导航技术研究中心武汉430079)2)(华东交通大学软件学院南昌330013)3)(武汉大学计算机学院武汉430079)摘要为解决粒子群优化(ParticleSwarmOptimization,PSO)算法中存在的种群多样性和收敛性之间的矛盾,该文提出了一种具备反向学习和局部学习能力的粒子群优化算法(Reverse-learningandLocal-learningPSO,RLPSO).该算法保留了初始种群中满足排异距离要求的多个较差粒子以及每个粒子的历史最差位置.当检测到算法陷入局部最优时,利用这些较差粒子的位置信息指导部分粒子以较快飞行速度进行反向学习,将其迅速牵引出局部最优区域.反向学习过程可改善粒子种群的多样性,保证了算法的全局探测能力;同时,利用较优粒子间的差分结果指导最优粒子进行局部学习与搜索,该过程可与粒子群的飞行过程并行执行,且局部学习的缩放因子可随进化过程动态调节.局部学习可提高算法的求解精度,保证算法的迅速收敛.实验结果表明,RLPSO算法同其他PSO算法相比,在高维函数优化中具有收敛速度快、求解精度高的特点.关键词粒子群算法;反向学习;局部搜索;多样性保持;高维函数优化1引言粒子群优化算法(ParticleSwarmOptimization,PSO)是由Kennedy和Eberhart[1]提出的一种基于群体智能的随机优化方法.PSO中每一个粒子都代表一个问题的候选解,通过粒子个体的简单行为及群体内的信息交互实现问题求解的智能性.由于PSO操作简单、收敛速度快,因此在函数优化[2]、图像处理[3]、大地测量[4]等众多领域都得到了广泛的应用.同时,由于PSO算法存在早熟收敛、维数灾难、易于陷入局部极值等问题,因此,针对这些问题,产生了很多有效的改进方法,主要可分为以下几类:第1类是通过调整PSO的参数来平衡算法的全局探测和局部开采能力.如Shi和Eberhart[5]对PSO算法的速度项引入了惯性权重,并依据迭代进程及粒子飞行情况对惯性权重进行线性(或非线性)的动态调整,以平衡搜索的全局性和收敛速度.Trelea[6]和Jiang等人[7]先后对标准粒子群算法进行了收敛性分析,并提出了收敛性和稳定性较好的一组参数选择.2009年张玮等人[8]在对标准粒子群算法位置期望及方差进行稳定性分析的基础上,研究了加速因子对位置期望及方差的影响,得出了一组较好的加速因子取值.第2类是致力于设计不同类型的拓扑结构,改变粒子学习模式,从而提高种群的多样性.如Kennedy等人[9-10]提出几种基本的邻域结构,如环形结构和星形结构等,并分析了不同邻域结构对优化结果的影响.文献[11]中,每个粒子学习的对象不是其单个邻居粒子的最优解,而是其全部邻居粒子的最优解的综合信息,在文献[12-13]中,则利用粒子间欧氏距离的大小来选择粒子的学习对象,以改善种群的多样性.谭阳等人[14]将PSO中指导粒子群进化的全局最优解扩展为由多个精英粒子组成的精英子群,精英粒子间采用了排异策略,并采用适应值竞争策略对整个粒子群进行指导,从而保证种群的多样性.而在CLPSO[15]中,每个粒子在变量的不同维上选择不同的粒子进行学习,避免所有维向同一粒子学习时产生的早熟收敛,实验也证明该算法在多峰函数上具有较好的优化效果.这些通过对改进邻域结构来丰富粒子学习模式的方法都从不同程度上克服了标准PSO算法的早熟现象.第3类是将PSO和其他优化算法(或策略)相结合,形成混合PSO算法.如曾毅等人[16]将模式搜索算法嵌入到PSO算法中,实现了模式搜索算法的局部搜索能力与PSO算法的全局寻优能力的优势互补.Angeline[17]和Higashi等人[18]分别将遗传算法中的选择操作和杂交操作引入到PSO算法中,有效提高了算法的收敛性.Xin等人[19]将PSO和差分进化算法(DifferentialEvolution,DE)相结合,通过设定一个学习统计周期对该周期内的两种算法的性能进行分析,并依据统计结果更新PSO和DE算法被选中执行的概率.文献[20]中还提出了以PSO和人工蜂群算法(ArtificialBeeColony,ABC)为基础的混合算法,PSO和ABC共享全局历史最优解,并分别指导2个子种群并行进化.2014年,Xia等人[21]在种群搜索过程中定期对每维决策变量空间进行划分,通过对历史进化信息的统计分析决定重点搜索区域,实现搜索空间的逐步收缩,进而达到提高搜索效率和求解精度的目的,此外,采用的禁忌探测技术也有效提高了算法跳出局部最优的能力.第4类是采用小生境技术.小生境是模拟生态平衡的一种仿生技术,适用于多峰函数和多目标函数的优化问题.例如,在PSO算法中,通过构造小生境拓扑,将种群分成若干个子种群,动态地形成相对独立的搜索空间,实现对多个极值区域的同步搜索,从而可以避免算法在求解多峰函数优化问题时出现早熟收敛现象[22-23].Suganthan[12]在1999年提出一种邻域可变的PSO算法,其基本思想是在算法开始阶段,每个个体的邻域为其自身,随着进化代数的增长其邻域范围也在不断增大直至整个种群.Parsopoulos[22]提出一种基于“分而治之”思想的多种群PSO算法,Page3其核心思想是将高维的目标函数分解成多个低维函数,然后每个低维的子函数由一个子粒子群进行优化,该算法对高维问题的求解提供了一个较好的思路.需要指出的是,很多对PSO算法的改进其实不仅限于其中的某一类,而更多的是不同改进方法的融合.本文提出了一种改进的PSO算法:具有反向学习和局部学习能力的粒子群算法(Reverse-learningandLocal-learningPSO,RLPSO).在粒子群的每轮迭代中,RLPSO借助最优粒子间的差分结果来指导最优粒子进行局部搜索,从而增强算法的局部开采能力,提高求解精度.当算法出现“早熟”收敛时,粒子群将分化为两个部分,一部分粒子负责协同最优粒子强化局部搜索,其他粒子则向其个体历史最差解和初始种群最差解进行反向学习,引导这些粒子逃离局部最优区域.同时,在反向学习时,放松了飞行速度限制,保证粒子能更快地飞离局部最优.反向学习行为与最优粒子的局部学习行为协同工作,有效地兼顾全局探测与局部开采能力.2PSO算法PSO算法是从鸟群觅食模型中得到启示的一种基于群智能的随机搜索算法,已广泛应用于各类优化问题.在使用PSO算法时,每个粒子可视为D维搜索空间中的一个搜索个体,粒子的当前位置即为对应优化问题的一个候选解,粒子的飞行过程即为该个体的搜索过程.粒子的飞行速度可根据粒子历史最优位置和种群历史最优位置进行动态调整.假设D维搜索空间中,有N个粒子组成一个群体,其中第i(i<N)个粒子在第t代时可用两个指标来描述:位置可表示为Xtij,…,xtxt(υti1,υt搜索至第t代时的个体历史最优位置为Pi=(pi1,pi2,…,pij,…,piD),搜索至第t代时的整个粒子群的历史最优位置为Pg=(pg1,pg2,…,pgj,…,pgD),则在第t+1代时,第i个粒子的第j维速度和位置的迭代更新公式如下:i2,…,υt其中,ω为惯性权重,衡量着前一时刻的速度对下次移动的影响,c1和c2为学习因子,r1和r2为[0,1]内的随机数.惯性权重ω作为PSO算法的一个重要参数,对于平衡算法的收敛速度和全局搜索能力有着重要的作用.研究表明,较大的ω有利于全局搜索,并增加种群的多样性,而较小的ω则可以提高算法的局部开采能力,加快收敛速度.因此,在众多改进的PSO算法中,根据搜索进程而动态调节惯性权重ω的值已成为一个被普遍接受的观点,其中,较为常用的是线性递减权重策略,即从算法前期的较大值线性递减至一个较小值,以保证算法较好的前期全局搜索能力和后期局部搜索能力.ω常用的更新方式如下:其中,t为当前迭代次数,T为最大迭代次数,ωmax为初始惯性权重,通常取0.9,ωmin为粒子群最大迭代次数时的惯性权重,通常取0.4.粒子的飞行速度υ表征着粒子遍历解空间的能力,它直接影响着粒子位置更新的步长.最大飞行速度υmax决定着当前位置与最好位置之间区域的分辨率,如果速度太大,尽管收敛速度很快,但可能会飞过最优解;反之,若速度太小,尽管收敛的分辨率很高,但又不易跳出局部极值,不利于搜索到全局最优解.因此,υmax一般取变量可行域的10%~20%.迭代过程中,粒子的飞行速度将被约束在设定的范围内,即如果υt+1-|υmax|时,υt+1c1和c2表征着粒子个体向个体历史最优解和种群历史最优解的学习能力大小.当c2=0,c1≠0时,粒子的学习过程类似于在其个体历史最优解附近的一种变异操作,整个粒子群表现出较好的分布多样性,但群体信息交互能力太弱,因此全局收敛的速度很慢;当c1=0,c2≠0时,粒子仅向群体历史最优解学习,粒子群全局收敛的能力较强,但超级个体的巨大吸引子使得算法很容易陷入局部最优.以往的研究表明,c1、c2的取值一般在1.5~2.0之间时,算法效果较好[8].3具备反向-局部学习的RLPSO算法和其他群智能算法一样,PSO算法在优化过程中,种群的多样性和算法的收敛速度之间始终存在着矛盾.对标准PSO算法的改进,无论是参数的选取、小生境技术的采用或是其他技术与PSO的融合,其目的都是希望在加强算法局部搜索能力的同时,保持种群的多样性,防止算法在快速收敛的同时出现早熟收敛.RLPSO算法也是基于这一思想的,Page4即在加强种群历史最优个体的局部开采能力的同时,依靠其他多个粒子的反向学习能力,保持种群的多样性.具体采用的改进策略如下:(1)种群历史最优位置邻域的局部搜索.粒子群在每代飞行更新位置后,更新种群历史最优位置Pg1和历史次优位置Pg2,并利用Pg1与Pg2之间的差分结果指导Pg1进行局部搜索,增强Pg1邻域内的搜索能力,具体如下:式中,r为[-1,+1]之间均匀分布的随机数,用以控制局部搜索的方向,dt为第t代时的局域缩放因子.一般而言,在进化初期,Pg1距离函数最优解一般较远,这时较大的dt能使其以较大的半径进行局部搜索,加快收敛速度;而到进化末期,Pg1距离函数最优解一般较近,这时则希望通过较小的dt使其开采更高精度的解.因此,这里采用了和惯性权重ω类似的线性递减策略,即dt随着种群迭代次数t的增加而线性递减,具体为对局部搜索的结果Pg1采用贪心保留策略,即式中,fit(狓)为狓的适应值.(2)粒子的反向学习.当检测到种群历史最优位置在一定迭代步数内未更新时,则认为算法已陷入停滞,并启动当前种群中的n个粒子进行s代的反向学习过程,其他的N-n个粒子的学习方式不变.第i个粒子反向学习的对象为该粒子的历史最差位置Wi=(wi1,wi2,…,wij,…,wiD),以及初始化种群时选择的规模为m的初始最差粒子个体的位置集合W={W0W0个粒子反向学习过程时的速度更新公式为k=(w0式中,wt其历史最差位置Wt为随机选择的初始最差粒子个体位置W的值.为了保证m个初始最差粒子能将反向学习的粒子牵引出当前的局部最优区域,并较为广泛地分布到搜索区域中,这m个初始最差粒子间应该具有较大的欧式距离,所以在选择它们时需要保证其两两间的距离大于预设的排异半径R.最差粒子构成子种群的生成算法见算法1.算法1.初始最差粒子子种群的生成算法.输入:初始种群X0={X0输出:初始最差粒子群体W={W0Begin1.依照粒子个体X0{X0W02.FORi=2TON3.IFcountmbreak;4.ELSEIFj(‖W05.count++;W06.ENDIF7.ENDFOR8.WHILEcount<m//初始最差粒子群体W未满9.随机生成新的粒子个体ind;10.IFj(‖ind-W011.count++;W012.ENDIF13.ENDWHILEEnd(3)反向学习期间,粒子的最大飞行速度υmax进行动态调整.粒子进行反向学习的目的是利用种群初始最差位置和个体历史最差位置的牵引作用,迅速逃离局部最优,因此较大的υmax值可以提高其逃逸速度.此外,由于粒子群在开始反向学习之前,算法已陷入停滞,即种群历史最优解Pg1在其邻域内无法找到更优解,因此也需要增大其υmax值,使其能在更大活动范围内进行搜索,提高求解的成功率.当反向学习结束后,υmax将再次设置为正常学习时的取值.RLPSO算法的伪代码见算法2.算法2.RLPSO算法.输入:算法搜索空间维数D,种群规模N,规模为m的输出:种群历史最优解PgBegin1.根据D和N,随机初始化粒子种群X0={X02.计算Xt中粒子的适应值,令Pg1=最优粒子个体,3.根据算法1构造最差粒子子种群W;4.WHILE(不满足停机条件)Page55.按照式(1)、(2)更新Vt和Xt;6.计算Xt中粒子的适应值,并更新Pi、Bi、Pg1和Pg2.7.根据式(4)和(6)对Pg1进行局部搜索;根据式(5)8.IF满足反向学习条件9.临时调整υmax;10.根据式(7)、(2)分别更新Vt11.按照式(1)、(2)分别更新Vt12.ENDIF13.t=t+1;14.ENDWHILEEnd4实验与分析4.1算法及参数设置本文选取7个改进的PSO算法与本文提出的RLPSO算法进行比较.这些算法涵盖了前文介绍的多种改进策略,如SPSO2007、FDR-PSO[13]对参数进行了优化,wFIPS[11]对邻域的拓扑结构进行了优化,RCPSO[14]、CLPSO[15]和CPSO[23]对粒子个体的学习模式进行了优化,DEPSO[19]则属于DE算法和PSO算法的混合.需要指出的是,上述改进的PSO算法其实都涉及到多种改进策略,具体内容可参见相应的文献.在本文的实验中,这些算法的参数设置同原文献相同,具体如表1.RLPSO算法的参数设置为:初始最差粒子群体规模为M=N/4,排异半表2本文选用的10个测试函数AcleyAlpineRastriginSchwefelP1.2(xisin(|xi槡|))GirewankSalomonSphereRosenbrockSchwefelP2.22SumofdifferentpowerF10(X)=∑x2槡i+1径R=∑数变量第i维的取值上限与下限,学习因子c1=1.85、c2=2.0,最大惯性权重为ωmax和最小惯性权重为ωmin,最大飞行速度υmax初始为变量可行域的1/8,当进入反向学习阶段时调整为变量可行域的1/4,反向学习因子c3=0.7、c4=0.3,反向学习代数Ltimes=20,反向学习子种群规模n=0.8×N,扰动系数初始值d0=40,反向学习条件为种群最优解连续20代未发生变化.FDRCPSO2004年ω:[0.4,0.9],c1=c2=1.4945wFIPS2004年χ=0.729,∑ci=4.1CLPSO2006年ω:[0.4,0.9],c1=c2=1.4945SPSODEPSO2010年χ=0.729,∑ci=4.1,DE/rand/1/bin,RCPSO2011年ω=0.5,c1=1.44,c2=2,M=104.2测试函数为了评价算法的收敛速度和全局搜索能力,本文对10个常用的测试函数进行了对比实验.其中,F1~F6为多峰函数,主要用于检验算法的全局搜索能力;F7~F10为单峰函数,主要用于检验算法的收敛速度和求解精度.函数详细信息见表2.D(1D∑i=1Page6本文利用8种算法对F1~F10进行了2组对比实验,第1组实验中,函数变量维数D=30,种群规模N=20,最大评价次数maxFEs=1e5;第2组中,函数变量维数D=100,种群规模N=30,最大评价次数maxFEs=2e5.每组实验重复执行30次.实验表3对比算法对测试函数的优化结果(犇=30,犖=20)测试函数F1F2F3F4F5F6F7F8F9F10测试函数F1F2F3F4F5F6F7F8F9F10CLPSO9.70e-012.89e-014.47e+001.19e+001.05e+028.98e+009.55e+019.80e+018.49e-011.17e-011.27e+001.76e-011.13e+003.42e-015.33e+021.58e+021.71e-013.56e-021.28e-161.45e-16表4对比算法对测试函数的优化结果(犇=100,犖=30)CLPSO6.05e+003.03e-013.14e+013.18e+004.69e+021.95e+013.37e+035.76e+021.06e+011.11e+007.64e+004.88e-011.05e+031.47e+021.46e+053.74e+041.63e+011.20e+006.61e-209.24e-204.3实验结果分析从表3和表4可以看出,在低维(D=30)时,RLPSO在F1、F2、F7和F9上取得了最优的表现,而环境为:Inteli3CPU2.93GHz.RAM4.00GB,Windows7操作系统,MATLAB2009a.实验统计结果包括优化结果均值(Mean)和标准差(Std.Dev),具体结果见表3和表4,其中,加粗数值表示对比算法在相应函数上得到的最优结果.CLPSO、wFIPS和CPSO在其他函数上则分别获得了更好的优化效果.其中,wFIPS在F10以及CPSO在F3上的优势较明显.当函数维数增至D=100时,Page7RLPSO在5个测试函数上具有较明显的优势,且在F10上的成绩也只是略差于CLPSO,而CPSO则对其他3个函数具有更好的效果.因此可以说明RLPSO算法在高维函数优化时性能较为突出.此外,为了验证数据的置信度,本文还进一步对RLPSO在D=100,N=30时与其他PSO算法的优表5RLPSO与对比算法的置信狋-检验(α=0.05,双尾)F1F2F3F4F5F6F7F8F9F101(Better)0(Same)-1(Worse)4.3.1时间复杂度本文实验均采用最大评价次数maxFEs作为停机条件,其原因在于在算法迭代过程中,对粒子个体的评价是整个算法中最耗时的部分.因此,以maxFEs作为停机条件对各个算法更公平.需要指出的是,尽管对粒子个体的评价操作最为耗时,但种群在每次迭代时进行其他操作的耗时也会对整个算法的速度有一些影响.如RCPSO每代操作时都要从当前粒子群中选择较优粒子对精英子种群进行替换,而为了保持精英个体多样性而进行的排异距离计算消耗了较多的计算时间,例如,若精英子种群的规模为M,则每代更新该子种群最少需要进行M×(M-1)/2-1次粒子间的欧式距离计算,此外,RCPSO每代还对排异半径都进行了计算,因此该算法的耗时最多;DEPSO的耗时比SPSO2007略多,一方面是统计和学习要耗时,但更主要的原因在于其中的差分演化算法(DifferentialEvolutionAlgorithm,DEA)本身就比SPSO2007耗时要多;化结果进行了双尾t-检验,置信水平α=0.05.检验结果如表5所示.表中,Better、Same和Worse值分别表示RLPSO比相应的PSO算法在进行函数优化时具有显著更优、相同和显著更劣的函数个数.从检验结果可以看出,RLPSO算法比其他算法具有更好的性能.此外,CPSO算法也表现出了较好的性能.CLPSO109.3410.00027.8860.00086.2030.000-33.9520.00052.1560.00021.3360.00038.9340.00021.2590.00074.9780.000-2.4800.016802FDR-PSO中每次为粒子选择学习对象时均要计算粒子间的欧式距离,这也会耗费一定的运行时间.RLPSO除了基本学习外,还有反向学习和最优粒子的局部搜索过程,即每次迭代时,种群历史最优解Pg1和Pg2会进行局部搜索,以及RLPSO算法要构建用于部分粒子进行反向学习的最差粒子种群.但与RCPSO构建精英子种群不同的是,RLPSO只在种群初始化时构建一次,在种群进化过程中,该子种群是不变的.而反向学习的部分粒子只是改变了学习方式,却并未增加额外的时间消耗.因此,RLPSO比DEPSO、RCPSO和FDR-PSO耗时要少.其他几种算法在每次迭代中所进行的额外操作很少,因此速度都与RLPSO相当.4.3.2收敛速度从前面的耗时统计与分析可以知道,RLPSO算法具有较低的时间复杂性.而收敛速度是另一个衡量算法求解速度的重要指标,它在解决实际应用问题时具有重要的意义.图1给出了不同算法在10个Page8图1不同PSO算法在测试函数上的收敛曲线(D=100,N=30)Page9测试函数优化上的收敛曲线.从图中可以看出,RLPSO和CPSO在大部分函数中均具有更快的收敛性,RLPSO除了在F3上明显劣于CPSO外,在其他函数上均取得了最佳或近似最佳的收敛速度.因此,若在求解实际应用问题时,将算法终止条件改为达到设定精度,则RLPSO具有更好的性能.RLPSO这种快速的收敛性得益于每次迭代时,种群历史最优解Pg1和Pg2都会进行局部学习.这说明RLPSO中局部学习机制有效地增强了算法的收敛速度.4.3.3反向学习机制保持种群多样性一直是在改进群智能算法性能时的一个关键问题,因为种群多样性直接关系到算法能否跳出局部最优,是克服“早熟”收敛的一个关键.RLPSO算法的反向学习过程的目的就是通过最差粒子位置的牵引,使一部分可能已陷入局部最优的粒子飞离出该区域.之所以利用最差粒子位置进行牵引是考虑多峰函数中的峰尖附近总有峰谷存在,而峰谷可视为一个最差位置,若能将粒子牵引至峰谷附近,则该粒子在后续学习过程中寻找到更优图2反向学习过程的粒子分布情况LPSORLPSO从表6及前文分析可以看出,反向学习机制在不增加算法复杂性的基础上不同程度地改善了算法的性能(一般为1~2个数量级).因此可以保守地认为PSO算法在进行多峰函数优化时,该机制是可以帮助种群跳出局部最优的.同时,我们也看出,该学习机制对于算法的改善还是很有限的,其原因在于学习机制过于简单,对较劣粒子所隐含的有益信息的提取和利用还不够,后续将进一步针对该问题展开研究.解的可能性会大大增加.图2演示了F4(D=30)在反向学习过程中粒子的飞行过程.图2中,“+”表示种群粒子,“○”表示初始种群中的较劣粒子,其中“●”表示最劣粒子.可以看出,在初始种群中,尽管这些较劣粒子具有较差的适应值,但其中一些粒子在某些维上的取值比当前种群最优解更接近于真实最优解狓=420.9687D,如图2中最劣粒子以及与其最邻近的劣粒子在横坐标这一维的取值比其他粒子在该维的取值更优.因此可以利用这个有益信息牵引一部分粒子跳出局部最优,改善在该维上的取值.图2(a)~(d)分别表示反向学习开始、反向学习5代、15代及结束时的种群粒子位置分布情况.可以看出,在反向学习过程中,较劣粒子有效地将部分粒子吸引到了其周围.为了进一步从数值上验证这一思想,下面将RLPSO与移除反向学习机制的算法(这里称为LPSO)进行了比较.由于反向学习的主要作用是牵引一部分粒子飞离局部最优,因此这里只选取了部分多峰函数F1~F4进行测试.实验参数设置为:N=30,D=20,独立运行30次.实验结果如表6所示.5结论为了缓解PSO算法的收敛速度与“早熟”问题之间的矛盾,进一步提高其优化性能,本文提出了RLPSO算法.该算法保留了种群历史最优解和历史次最优解,算法在整个优化过程中依靠这2个较优解的差分结果来强化算法的局部搜索能力,并通过优化进程动态调节差分结果的权重,以提高搜索精度;当算法出现“早熟”现象时便会启动反向学习过程,在该过程中,部分粒子利用其个体历史最劣解以及初始种群的多个最劣解的吸引合力而逃逸出局部最优,改善种群的多样性;当反向学习结束后,算法再次进入正常的迭代优化过程.实验结果表明,本文提出的RLPSO算法的优化能力要优于对比算法,Page10而且“早熟”现象出现时采取的反向学习过程比补充随机粒子个体更能改善算法性能.后续将继续研究PSO算法在多峰函数优化时对较差粒子隐含的有益信息的提取和利用,以提高算法在函数优化,尤其是多峰函数优化中的性能.
