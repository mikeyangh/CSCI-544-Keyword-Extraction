Page1基于数据服务的嵌套视图动态更新方法张鹏2),3)韩燕波1)王桂玲1)1)(北方工业大学云计算研究中心北京100144)2)(中国科学院研究生院北京100049)3)(中国科学院计算技术研究所集成应用中心北京100190)摘要数据服务屏蔽了数据访问的复杂性,并且支持用户以可视化方式定义装载异构数据源的嵌套视图.然而,当异构数据源输出的数据发生更新时,该更新需要通过数据服务逐层传播到顶层的嵌套视图,一类挑战性问题是,如何减少更新传播过程中的冗余计算,提高嵌套视图的数据新鲜度.为此文中提出了基于数据服务的嵌套视图动态更新方法,该方法利用指针为嵌套视图中的元组建立嵌套任意层次的数据服务的引用,同时给出了一种记录数据服务更新的日志以及在该日志上的嵌套视图增量更新算法.文中在原型系统中实现了该算法并且进行了实验分析,实验结果表明,该方法减少了70%的嵌套视图的更新时间,提高了60%的嵌套视图的数据新鲜度.关键词数据服务;嵌套视图;数据集成;日志;数据新鲜度1引言数据服务[1-2]是以提供数据资源的访问为目的的软件服务,它接收一组关于对该数据资源进行访Page2资源的松耦合,而且具有良好的可扩展性.更重要地是,数据服务具有相同的数据模式,使得用户无需定义中介模式便能直接进行集成.近年来出现了一些相关工具,可以分为表1中3类.Spreadsheet编程第1类工具通常为用户提供一个可视化的操作环境,通过接受用户操作指令,生成操作数据服务的脚本,其中的数据模型主要包括两种:XML数据模型和对象数据模型.第2类工具是由用户构造数据流,该数据流以数据服务为源头,并经过一系列的数据加工与变换,最终输出数据,这类工具要求用户理解和掌握条件、循环等复杂控制结构,并且用户难以随时观察操作带来的数据变化.第3类工具则为用户提供一个类似于Spreadsheet的操作界面,在这个界面里,数据服务以表格形式呈现,用户直接在表格上对数据进行增、删、改等操作,Mashroom就是其中的典型代表,它采用嵌套关系[11]作为其数据模型,具有以下好处:(1)与对象数据模型相比,嵌套关系模型在表达具有层次结构的复杂对象时更加符合人的直觉习惯;(2)与XML模型相比,嵌套关系模型能够以表格化形式进行呈现,更容易被最终用户理解;(3)嵌套关系代数具有理论基础,其操作采用集合操作方式,操作的一次执行作用于多个元组,这种方式将循环结构隐含于操作内部,用户可以在表格中随时看到操作变化.本文把通过数据服务集成的以嵌套方式呈现的表格称为嵌套视图.然而,由于数据资源自主变更,数据服务需要把该变更传播到受到影响的数据集成方案,如何减少更新传播过程中的冗余计算,提高集成系统的数据新鲜度是增强上述工具可用性的一个必要条件[12],为此本文重点考虑嵌套视图的增量更新,目前的视图增量更新算法主要在关系数据库的背景下,其中视图通过使用关系查询语言在基本表上定义,数据模型是关系模型[13].然而,本文的嵌套视图的数据模型是嵌套关系模型,为此需要对传统基于关系数据模型的增量更新算法进行扩展.本文的目标是给定一个通过数据服务定义的嵌套视图和一个数据服务的更新操作,能够产生一组该视图上的更新原语,使得应用这组更新原语后产生的新的嵌套视图和重新计算产生的嵌套视图相同,贡献包括以下两方面:(1)设计并实现了数据服务更新传播架构,使得嵌套视图的更新只需和日志组件交互而无需和异构数据源交互.(2)提出了嵌套视图的增量更新模型,其中通过日志组件索引不仅提高了增量更新计算的效率,而且支持了嵌套视图的可扩展性.通过在TPC-H①数据集上封装的数据服务的实验表明,嵌套视图的更新时间减少了70%,数据新鲜度提高了60%.2相关工作数据集成目标是使用户可以忽略数据源的异构性,以一个统一的方式来访问分布异构的数据源.现有的数据集成方法可以划为以下3类:模式集成方法是人们最早采用的数据集成方法,例如联邦数据库[14]和中间件[15].其基本思想是在构建集成系统时将各数据源的数据模式映射为全局模式,使用户能够按照全局模式透明地访问各数据源的数据.该方法的优点是映射关系的可扩展性好,适合于数据源变化比较大的情况,缺点是可能会造成“信息丢失”,查询效率低.数据复制方法是将各个数据源的数据复制到与其相关的其它数据源上,并维护数据源整体上的数据一致性、提高数据共享利用的效率,例如数据仓库[16].数据复制方法适用于数据源相对稳定、用户查询模式已知或有限的情况.当数据分布性比较广,网络延迟较大,同时又需要有很短的处理时间时,可以考虑采用数据复制集成方法.以上两种技术是早期数据集成过程中普遍使用的技术.但是由于这些技术存在差异导致使用不同技术开发的组件之间的互操作性很差.另外,即使这些技术能够实现跨平台以及应用程序之间互操作性,还要面临另一个很重要的障碍———防火墙.与上述传统技术相比,服务集成方法是建立在XML和HTTP这些得到了业界广泛采用和认可的标准协议基础之上的,因此能够很好地解决传统技术在数据集成过程中穿越防火墙以及各类中间件互操作性差等问题.同时为了突破前两种方法的局限性,服务集成方法可以借鉴前两种方法的优点,对于用户简①http://www.tpc.org/tpch/Page3单的访问请求,可以通过数据复制方式,在本地数据源或单一数据源上实现用户的访问需求,而对那些复杂的用户请求,无法通过数据复制方式实现时,可以使用中间件方法.借鉴上述思想,前期工作通过缓存选取技术[17],提高了数据服务集成的嵌套视图的运行效率,但是在嵌套视图维护中没有考虑增量更新,当总元组较多,更新元组占比较少,更新相对频繁时会产生大量冗余计算.视图维护是指当基本事实表的内容发生变化时,需要对预先存储的视图集合进行更新,当前主要通过两种方式来实现,即增量更新和重新计算.采用哪种方式取决于不同的场景,在多数情况下,增量更新的代价比重新计算代价要小.当增量更新无法实现时,也必须采用重新计算的方法.文献[13]给出了视图增量更新的基本思想:根据视图的定义生成一段增量更新程序,该程序根据基本数据库关系的变化以及当前基本数据库关系和视图的值,生成增量更新元组.新视图的值可以通过把这些增量更新元组作用在当前视图上得到.这种方法的好处在于,只计算需要更新的部分数据,实现了计算量的最小化.关系型数据库上的增量更新是这类问题最基本的情况.除此之外,研究人员还探索了半结构化数据(包括XML数据)上的增量更新方法[18-19].借助缓存进行增量更新的思想也运用在XML视图上,并取得了良好的效果.然而,上述工作考虑的都是单一同构数据的增量更新,没有考虑多源异构数据的增量更图1问题描述示例如图1所示,相比传统的数据集成技术,数据服务将数据访问接口和数据资源进行分离,不仅实现了嵌套视图V和数据库、CSV文件和XML文件的松耦合,而且具有良好的可扩展性.更重要的是,数据服务输出相同的数据模式,使得小李无需定义中介模式便能直接进行集成.假设v(a,s)是V的一个新,为此本文首先通过数据服务化技术[11]将多源异构数据转换成嵌套关系模型的数据服务,并在此基础上考虑增量更新问题.关于Web应用维护方面,文献[20]提出了一种通过识别应用构造的界面发生改变的时间和方式来帮助开发者维护该应用的技术,然而该技术是通过搜索最佳匹配的Widget来实现界面维护,其中的数据更新只采用了重新计算的方式.3问题分析小李准备购买某汽车的零件,她需要了解该零件的供应信息及零件的使用评价.此时两个数据服务DS1和DS2已经发布到网络上.其中DS1可获得多个供应商提供的零件的供应信息,包括供应商ID、零件型号ID、库存量等等,这些信息虽然来自异构的数据源,但是统一以关系输出,其关系模式记为p.DS2可获得每种零件的使用评价,它以零件型号ID为输入参数,可获取好评人数、差评人数等等,这些信息也以关系输出,其关系模式记为q.小李将DS1的零件型号ID(图中记为Z)的值为参数值逐次调用DS2并连接输出元组,即可得到嵌套视图V,如图1所示.该过程通过Hilog语言[21]表示为V(X,Y)≡defp(X,Z),Z(W),q(W,Y),其中Z是p的嵌套属性,本文采用Hilog语言是为了便于表达嵌套属性.实例(a是p的一个关系,s是q的一个关系),其中{〈1〉,〈2〉,…,〈n〉}是被嵌套的关系s的元组,如果在s上增加一条元组〈n+1〉,通过重新计算的方式更新v(a,s),那么s中每个元组都需要和a重新连接,然而该过程中除了插入一条元组〈n+1〉外,其它操作都是不必要的.文献[13]针对关系模型的视图Page4增量更新设计了日志,该日志中记录了每个视图关联的基本表的更新,无论基本表关联多少视图,每个基本表都只有一个日志,其中的每一条都记录了更新元组的ID(更新操作包括插入、修改、删除).然而当处理嵌套视图的增量更新时,这种日志的设计碰到两个问题.首先,随着数据服务增多,日志如何支持嵌套视图的扩展;其次,日志如何记录被嵌套的关系中的元组的变化.假设数据服务DS2输出关系s的元组的每次更新都在DS2的日志中创建一条记录,并且v的一个元组t通过指针方式引用被嵌套的关系s,当s的元组r发生更新时,该更新必须能够被v和s同时发现.然而,由于元组t通过指针方式引用关系s,所以t的数值只有在删除或者插入关系s时才会改变,因此在v的日志中记录被嵌套的关系的元组变化并不能解决该问题.不仅如此,当s的元组发生更新时,所有嵌套这个关系的嵌套视图都需要遍历,不仅增加了日志的存储开销,而且增加了扫描日志的时间开销,因此本文的日志设计考虑了上述问题.4数据服务更新传播本文对已有数据服务进行了扩展,新增了轻量级的日志组件.整个数据服务更新传播的架构如图2所示,该架构主要包含3个部分:数据服务、日志组件和嵌套视图,分别对应服务提供者、服务监控者和服务使用者3个角色.其中,服务提供者通过数据服务化技术把异构数据源转换成嵌套关系模型的数据服务,当异构数据源发生数据更新时,该事件会触发数据服务执行,并且把执行的结果传给内部的匹配器,匹配器通过比对执行结果得到更新元组,并且通过消息方式把它们传送给日志组件.作为服务监控者,日志组件不断接收来自其对应的数据服务传送来的更新消息,并且以日志的方式记录下来,以备与该数据服务相关的嵌套视图进行更新.作为服务使用者,用户基于数据服务通过可视化操作定义装载异构数据源的嵌套视图,当嵌套视图被定义后,系统通过解析该定义脚本获取数据服务和嵌套视图的关联,并且把这种关联记录到本地文件中.当嵌套视图需要更新时,它会发送更新通知给所有关联的数据服务的日志组件,日志组件接收到该通知后,计算更新要素,并且把它们发回给嵌套视图.嵌套视图接收后,在本地根据增量更新模型计算更新元组,并且执行更新.数据服务更新传播架构的优点概括如下:首先该架构通过数据服务屏蔽了底层多源、异构数据访问的复杂性,使得所有的数据更新都可以通过元组统一表示,为后面的增量更新模型提供了基础;其次,该架构通过数据服务降低了嵌套视图和数据源的耦合度,使得嵌套视图的更新只需和日志组件交互而无需和数据源交互;再次,该架构通过日志组件缓冲了嵌套视图的更新,并且使得数据服务和嵌套视图可以异步执行各自的程序;最后,该架构通过记录数据服务和嵌套视图的关联,消除了不关联的嵌套视图的更新,并且通过增量更新模型减少了关联的嵌套视图的更新过程中的冗余计算.除此之外,该架构还可以适用不同的场景,当总元组少、更新元组占比多、更新次数少时,该架构直接采用重新计算的更新策略,而当总元组多、更新元组占比少、更新次数多时,该架构则采用增量更新的策略.下面重点介绍增量更新模型.4.1增量更新模型增量更新模型根据嵌套视图关联的数据服务的日志记录,进行嵌套视图的增量更新,本节首先介绍关系视图的增量更新模型———计数模型,然后给出嵌套视图增量更新模型.对于关系视图,计数模型为其中的每个元组都计算其来源的个数.例如给定关系的元组{(a,b),(b,c),(b,e),(a,d),(d,c)},其上生成的视图的元组{(a,c),(a,e)}.其中(a,c)可以通过(a,b)和(b,c)的连接得到,也可以通过(a,d)和(d,c)连接得到,因此(a,c)的计数为2,同理(a,e)的计数为1.例如一个连接3个关系的视图V≡defR1R2R3,计数模型根据下面更新原语组成的式(1)计算V的变更元组ΔV.ΔV=Rnew1Rnew2Rnew3-Rold1Rold2Rold3=ΔR1Rnew2Rnew3∪Rold1ΔR2Rnew3∪Page5其中ΔRi表示关系Ri的插入与/或删除的元组集合,Roldi=Ri表示ΔRi应用到Ri更新前的状态,Rnewi=Roldi∪ΔRi表示ΔRi应用到Ri更新后的状态,∪表示集合并.在元组变更集合中,插入(删除)元组是通过正(负)计数来表示,修改元组通过先删除旧元组然后再插入新元组来表示.视图V的每个元组都有一个计数,并且根据下面的3条规则合并变更元组ΔV,从而得到新的视图:(1)如果计数为正数,元组计数则增加.(2)如果计数为负数,元组计数则减少.(3)如果V中元组计数为零,删除该元组.因此如果能够正确地找到嵌套视图变更元组集合,那么嵌套视图增量更新也可以通过式(1)来计算.下面通过一个例子来进一步解释.假设两个数据服务的输出的关系模式是Reviewer=[Nm,Dependent],Supplier=[D-Nm],其中Dependent=[D-Nm,Year],它们返回关系的元组如下:Reviewer={(Fred,D1),(Mary,D2)};Supplier={(Dave),(Jane)};D1={(Dave,1985),(Bob,2010),(Jane,1995)};D2={(Dave,1985),(Alice,2003)},其中,D1和D2是Dependent关系的id.用户通过上述两个数据服务可以定义零件供应商供应的零件的嵌套视图V,其Hilog定义如下:V(X,Z)≡defReviewer(X,Y),Y(Z,A),Supplier(Z).V的缓存结果是{(Fred,Dave),(Fred,Jane),(Mary,Dave)}.当Supplier的元组更新时,根据式(1)计算ΔV.由于Supplier中没有嵌套,因此ΔV直接表示为ΔV(X,Z)=Reviewerold(X,Y)Yold(Z,A)ΔSupplier(Z).如果从Supplier中删除Jane(可以表示成ΔSupplier(Z)={(Jane)-1}),那么将产生ΔV={(Fred,Jane)-1}.上述例子表明在非嵌套的关系上进行增量更新是非常直接和简单的.注意,由于Y是变量,Yold的表示并不是很精确.下面讨论如何通过变换Yold消除变量Y.假设一个嵌套关系R=[…,S,…],其中S是R的一个嵌套属性,里面包含了一个被嵌套的关系.对每一个这样的S,这里定义了一个函数:当X是S表示的被嵌套的关系时,us(X)是真,否则us(X)是假.对每个这样的嵌套属性S,这里定义了它的抽取函数:es(X,A1,…,Ak)=us(X)X(A1,…,Ak)(2)其中S=[A1,…,Ak],Ai是S的关系模式的属性,1ik.对于上述例子中的嵌套属性Dependent,可以得到uDependent={D1,D2}和eDependent={(D1,Dave,1985),(D1,Bob,2010),(D1,Jane,1995),(D2,Dave,1985),(D2,Alice,2003)}.抽取函数通过将嵌套的Dependent关系转换成非嵌套的关系eDependent,消除了变量Dependent,方便了增量更新计算.再次考虑这个嵌套关系R=[…,S,…],其中S是嵌套属性.假设嵌套视图V是在R和S上定义得到,那么V=R(…,X,…)X(…)是V的表达式(这里X是出现在嵌套属性S位置上的变量),相比直接在表达式上进行计算,这里选择计算下面的等价表达式.通过这种变换,V可以不再使用变量作为关系的名称.如果把es看作一个关系,那么根据计数模型,ΔV可以表示成ΔR(…,X,…)enews(X,…)∪Rold(…,X,…)Δes(X,…),如果有多层嵌套的情况,例如S又包含一个被嵌套的关系T作为其中的一个嵌套属性(S=[…,T,…]),那么可以根据S和eT递归地表达Δes.因此V的更新元组ΔV可以通过下面的更新原语进行计算:ΔV(X,Z)=ΔReviewer(X,Y)enew假设V被缓存后,Fred把他的名字修改成Greg,同时供应商不再是Dave.因此ΔReviewer(X,Y)={(Fred,D1)-1,(Greg,D1)+1}并且ΔeDependent(Y,Z,A)={(D1,Dave,85)-l}.根据上面的更新原语,ΔV(X,Z)={(Fred,Dave)-1,(Fred,Jane)-1,(Greg,Jane)+1}.在上述计算的过程中,ΔV只和被嵌套的关系Dependent中变更的元组个数有关,而和被嵌套的关系Dependent的总元组个数无关.为了能够提高增量更新计算的效率,Δes(X,…)必须能被快速得到,以避免扫描R中所有元组,为此本文设计了记录数据服务更新的日志组件.5日志组件实现日志组件主要包括两个部分,一个是嵌套描述文件,该文件记录了同一个数据服务输出的所有关系的元组更新.另一个是描述关系的哪些元组嵌套了另一个的关系的索引,该索引能够加快Δes(X,…)的计算.由于日志组件会带来额外的系统开销(例如存储日志的空间开销,日志更新的时间开销,视图更新的时间开销),所以从以下3个方面Page6考虑日志组件的设计:(1)日志记录的开销必须和嵌套视图个数无关,因此数据服务和嵌套视图需要进行分离,数据服务需要设计独立的日志.(2)为了避免嵌套视图每次更新都重新扫描所有数据服务的日志记录,嵌套视图的更新必须只和相关的数据服务的日志记录有关.(3)存储日志记录的空间开销尽可能少,因此日志记录不能有冗余或者重复,旧的或者冗余的日志记录必须及时清除.5.1日志的数据结构在实现上,数据服务返回的关系是通过一个集合类来表示的.集合类包含缓存的元组和描述文件,其中元组是通过对象来实现,而描述文件包含关系的元信息,例如创建时间、元组的指针以及其它支持嵌套视图的指针.除此之外,集合类也提供了必要的成员函数,例如元组中的insert()、remove()和replace(),其中,insert()是创建一个给定数值的元组,并且把它插入到元组中;remove()首先把元组标记为删除,然后把该元组放到移除元组池中.直到删除操作传播到所有依赖该元组所在关系的嵌套视图后,该元组才在移除元组池中被删除;replace()修改已有元组的数值,同时创建一个保存旧的数值的元组,并且把该元组放到移除元组池中.嵌套视图V的更新只和与V关联的数据服务自从上次V更新后的日志记录有关,其中DeltaIterator提供迭代V关联的数据服务的日志记录,从而满足日志组件设计的第1个条件.当DeltaIterator对象创建后,系统从上次V更新后的指针开始扫描关联的日志记录,并且通过对日志记录的oid进行hashing,在内存中构建hashtable.由于hashtable的创建时间只和关联的日志记录有关,同时使用hashtable的时间开销很少,从而满足日志组件设计的第2个条件.为了在嵌套视图中有效发现被嵌套的关系的更新,必须在嵌套视图中建立嵌套属性的元组和被嵌套的关系之间的关联.在实现上,对于嵌套属性中的元组更新可以记录在被嵌套的关系的日志中.原始的更新传播架构是把被嵌套的关系的元组更新传播到元组中引用了被嵌套的关系的所有嵌套视图.当插入日志记录时,需要遍历所有被嵌套的关系的元组,当嵌套视图的很多元组包含对被嵌套的关系的引用,或者嵌套层次很深时,那么日志查找的代价会很高,存储日志的空间开销也会急剧增长.因此为了满足日志组件设计的第3个条件,这里必须进行额外工作,能够(1)有效地查找和记录被嵌套的关系的更新;(2)有效地建立嵌套-被嵌套关系;(3)实现尽可能小的更新的开销.为此,这里为相同关系模式的所有被嵌套的关系设计一个包含日志的描述文件.一旦嵌套这个关系的嵌套视图被缓存,描述文件就被创建,因此也称为嵌套描述文件.每个嵌套视图定义后都检查其中被嵌套的关系.由于每个被嵌套的关系中的元组都是相同类型的,因此嵌套描述文件中所有的日志记录都是相同类型的.例如,在创建一个嵌套描述文件D后,被嵌套的关系N的每次更新都记录在D的日志中,而不是N的日志中.在N更新的过程中,当调用insert(),remove()或者replace()方法时,这些方法首先检查是否存在包含N的描述文件D,如果存在,那么在D中插入一条日志记录,这里插入操作只做一次,同时日志记录通过hashing消除冗余的更新记录来计算最终的更新净效果,例如in-sert-remove、replace-remove、replace-replace以及insert-replace,从而减少了存储日志的空间开销,满足了日志组件设计的第3个条件.下面给出一个具体例子,假设3个数据服务输出的关系模式R,T,U,其中R=[T,…],T=[U,…],U=[…],并且T包含两个关系T1和T2,U包含两个关系U1和U2.图3给出了R,T1,T2,U1,U2的日志数据结构,目前暂时不考虑日志中的索引.如图所示,R的元组包含指向T1和T2的指针.图中标记R,T1,T2的盒子表示它们的描述文件.假设在R,T和U上定义了两个嵌套视图V1和V2,V1≡defR(X,…)X(Y,…)Y(…),其中,变量X是嵌套属性,表示被嵌套的关系T;变量Y也是嵌套属性,表示被嵌套的关系U.如图3所示,R的描述文件包含指向日志记录的指针(标记为V1和V2),它们指向V1(V2)自从上次更新后的最后一条更新记录.R中oid=1和oid=3这两个元组分别称为t1和t3(oid=2是已经删除的元组,暂时必须被保存).t1引用了被嵌套的关系T2,T2包含oid=20的更新后的元组t20(元组t20开始和元组t21包含相同的内容,当t20被修改后,首先创建它的备份t21,图3中T的嵌套描述文件的最后一条日志记录了这个过程,这条日志记录包含了关系的描述文件的oid).然后从日志记录中获取与V1和V2相关的更新操作.例如,V1和V2需要使用t1计算嵌套属性的抽取函数.由于更新操作只作用到T2和U2,所以t1不在R的日志中,但是可以在T和U的嵌套描述文件中通过索引被发现.Page7图3日志组件的架构为了避免嵌套视图每次更新都重新扫描所有数据服务的日志记录,这里考虑为每个嵌套描述文件设计一个索引.建立索引的目的是能够快速地把被嵌套的关系的更新(尤其是那些出现在深度被嵌套的关系的更新)转换成嵌套属性的抽取函数.索引和对应的描述文件同时被创建,并且在嵌套视图更新的过程中被维护.索引的每个key是嵌套关系的元组引用的被嵌套的关系的描述文件的oid(例如T1,T2),这种设计使得嵌套关系中每个嵌套另一个关系的元组的oid能够被直接发现,例如元组t1包含被嵌套的关系T2能够被直接发现.当嵌套视图首次更新时,通过使用从被嵌套的关系的描述文件的oid(例如T2)到嵌套关系的元组oid(例如t1)的映射初始化索引,其中嵌套关系的每个元组必须被插入到索引中.当索引被创建后,嵌套属性中的新元组也可以插入到嵌套视图中.当嵌套视图开始更新时,这些新元组的oid才出现在被嵌套的关系的描述文件的索引中,新插入的元组的映射必须在索引中创建(例如在上一次V2的更新过程中,当t3插入的日志记录被处理时,T1到t3的映射才被插入到T的索引中).垃圾收集器会删除索引中不再被嵌套视图使用,并且被标注为removed的oid.由于索引不会增加更新的开销,所以满足日志组件设计的第3个条件.类似的,日志记录也可以显示一个嵌套属性的元组已经被删除,这种情况下它的索引也一定要被删除,例如当删除oid=2的日志记录被处理时从T1到oid=2的映射的索引必须被删除.在实现上,本文通过在嵌套描述文件中存储一个反向指针列表来减少查找时间,例如T1包含指向包含2和3的列表.5.2增量更新的Delta算法下面仍以V1为例,重点介绍V1增量更新中的抽取函数eT和eU的计算步骤.步骤1.非嵌套的关系.对在嵌套视图定义中出现的非嵌套的关系,根据5.1节介绍的方式扫描对应的日志记录从而创建hashbucket,一个bucket包含日志记录的内存备份.如果日志记录中包含insert-flag和oid值onew,那么在对应的嵌套描述文件的索引中新增一个从onew的被嵌套的关系到onew的映射(如果之前不存在的话),如果索引中没有出现任何从这个被嵌套的关系的映射,那么对下一级被嵌套的关系递归地进行这个操作.步骤2.被嵌套的关系.对在嵌套视图定义中出现的下一级被嵌套的关系(例如被X绑定的关系T),和步骤1类似,扫描其对应的嵌套描述文件的日志记录,创建hashbucket.接着,通过被扫描的日志记录L中存储的描述文件的oid(例如T1和T2)来查找索引的内容,从而判断L是否影响嵌套这个关系的元组.L中记录的oid的元组用来追踪嵌套描述文件的索引.如果该元组映射到的所有元组的oid都没有出现在hashtable的映射中,那么根据步骤1把这些oid添加到hashbucket中(除了那些被标记为删除的元组或者是旧版本的元组的oid).如Page8果被嵌套的关系包含该元组,递归追踪它包含下一级的关系的嵌套描述文件,并且把包含的元组添加到hashtable中(如果这些元组不在hashtable的话),直到没有要包含的元组或者所有元组都添加到hashtable中才终止.步骤3.递归应用步骤2到下一级的被嵌套的关系中(例如Y绑定的U).这里分析图3所示V1,它的增量计算包括扫描R,T和U的日志记录来计算它们更新的净效果.在步骤1中,非嵌套的关系R的日志被扫描,并且oid=2,3被添加到hashtable中.在步骤2中,嵌套描述文件T的日志被扫描,并且oid=11,12,20被添加到bucket中.同时,把oid=1添加到步骤1中为R创建的hashtable中(oid=2,3已经存在,oid=1是通过追踪T2的描述文件的oid对应的索引发现的,R的元组t1本身不被更新但是它嵌套的关系T2被更新).在步骤3中,U的日志被扫描,并且创建了它的hashbucket(这是步骤2的递归步骤),oid=31,36被插入到U的hashtable中.在步骤2中,oid=10被添加到为T创建的hashtable中,因为oid=10没有在那个hashtable中出现过,而oid=20,11已经在那个hashtable中出现过,同时oid=21是旧的版本,因此被排除.最后R,T和U的hashtable分别包含oid={1,2,3},{10,11,12,20}和{31,36},然后抽取函数通过查找这些hashtable,生成描述文件oid-元组oid的键值对.例如ΔeT={(T1,10),(T1,11),(T1,12),(T2,20)}.基于上述介绍的抽取函数计算方法,下面给出嵌套视图的增量更新算法.表2数据服务PART〈id:003,Params:{partkey},Schema:{partkey,name,mfgr,type,brand…}…〉关系RegionREGION〈id:001,Params:{regionkey},Schema:{regionkey,name,comment}…〉nationNATION〈id:002,Params:{nationkey},Schema:{nationkey,name,comment}…〉partsupplierSUPPLIER〈id:004,Params:{suppkey,nationkey},Schema:{regionkey,nationkey,name,address…}…〉partsupplierPARTSUPPLIER〈id:005,Params:{partkey,suppkey},Schema:{partkey,suppkey,availqty,supplycost…}…〉customerCUSTOMER〈id:006,Params:{custkey,nationkey},Schema:{custkey,nationkey,nameaddress,phone…}…〉orderORDER〈id:007,Params:{orderkey,custkey},Schema:{orderkey,custkey,status,price,date,clerk…}…〉lineitemLINEITEMDeltaIncrementalUpdate.Input:V,DS//V更新前嵌套视图,DS数据服务集合Output:V//V更新后嵌套视图Beginfor(i=0;i<DS.size();i++)Stringlog=DS.get(i).getLog();update+=getRecentUpdate(log);if(update!=null)for(;j<update.length;j++)(ΔRj,hashtable)=getDeltaResult(update(j));(Δe,enew)=extract(hashtable);for(k=0;k<j;k++)if(Rk=Rk(…,X,…)X(…))ΔRk=ΔRk(…,X,…)enew(X,…)∪Rnewk=ΔRk∪Rk;//计算嵌套属性的增量更新ΔV=(ΔR1R2…Rn)∪V=V∪ΔV;End6实验与评价本节通过实验验证Delta算法能够减少嵌套视图的更新时间和提高嵌套视图的数据新鲜度.首先,通过对TPC-H的数据集进行封装得到测试的数据服务,如表2所示.数据服务的结构及业务含义Page9假定每个数据服务输出关系包含1000条元组,由于数据服务不依赖具体封装的数据源的格式,因此数据集也可以替换成其它格式的数据源,目前支持的数据源格式包括关系,CSV文件,XML文件,Excel文件,HTML网页.实验配置如下:Intel3.2GHz的CPU,4GB内存,WindowsXP操作系统,ApacheTomcat6.0.14应用服务器.为了模拟用户主导的可视化数据集成,这里采用类似Yahoo!Pipes①的数据操作构造了20个嵌套视图,并且根据文献[22]统计的syndic8上α=0.9的Zipfian分布,模拟了100个嵌套视图,并且把它们的结果进行缓存.第1个实验比较使用4种不同策略的嵌套视图的更新时间.其中第1种是重新计算策略,即每当数据服务输出的关系中的元组发生更新时,嵌套视图都重新计算;第2种是文献[13]提出的计数算法,该算法应用到嵌套视图时,必须遍历所有元组来查找被嵌套的关系的元组;第3种是AquaLogic提出的数据服务更新策略[19],该策略本来用在XML定义的数据服务上,由于嵌套关系模型也可以通过XML表示,所以该策略也可以用在本文的数据服务上,但是需要维护相对复杂的更新映射描述,并且更新计算代价根据更新映射描述的不同会产生较大差异;第4种是本文提出的扩展计数算法的Delta算法,该算法利用嵌套属性的抽取函数和日志中的索引,理论上可以减少增量更新的计算时间.图4显示了50个嵌套视图时,当更新元组从2%增长到10%后,4种策略的嵌套视图的更新时间.这里根据均匀分布随机选择数据服务,并且通过插入和删除其中的元组来模拟更新元组.当更新元组是2%的时候,由于计数算法和Delta算法都需要额外开销,所以其更新时间比重新计算的更新时间多.然而,当更新元组增多时,计数算法和Delta算法都比重新计算的更新时间少,但是它们的更新时间相差不大,其原因包括两点:第1点是相比重新计算,计数算法和Delta算法都能减少更新过程中的冗余计算,例如只更新与数据服务关联的嵌套视图;第2点是相比计数算法,Delta算法的增量计算过程进行了优化,但是当数据服务和嵌套视图的关联保持不变时,计数算法也无须遍历所有元组来查找被嵌套的关系的元组,因此Delta优化效果只在抽取函数中有所体现,然而整体改进并不明显.虽然AquaLogic表现也不错,但是由于要维护相对复杂的更新映射描述,因此需要更多的时间开销,并且XML的增量更新计算相对式(1)的计算代价较高.图5显示了随着嵌套视图不断增多,更新元组为10%时,4种策略的嵌套视图的平均更新时间.结果显示Delta算法更新时间最少,并且其它3种策略的更新时间的增长幅度大于Delta算法的更新时间增长幅度.其中主要的原因是Delta算法通过日志中的索引能够很快查找引用被嵌套的关系的元组,无须遍历所有元组.不仅如此,图中显示出随着AquaLogic需要维护的更新映射描述的增多,AquaLogic的更新计算代价增长不稳定,其中的主要原因是因为有些嵌套视图的更新映射描述复杂,有些嵌套视图的更新映射描述简单,导致XML的增量更新计算的时间开销差异较大.图6显示了总元组数从50%增长到200%的时候,更新元组为10%,嵌套视图个数为50时,4种不同策略下的嵌套视图的平均更新时间.结果表明,相比其它3种策略,Delta算法的更新时间最少,不仅如此,上述4种策略的更新时间都随着总元组个数的增量而线性增长.其中主要原因是由于均匀选择更新的数据服务,使得更新元组出现在总元组的概率是相同的.①http://pipes.yahoo.com/Page10图7显示了更新元组为10%,视图个数为50时,不同的网络带宽下的嵌套视图更新时间,这里通过网络路由器来控制网络的带宽.从图中可以看出,网络带宽带对重新计算策略影响很大,而对其它3种策略影响不大,主要原因是重新计算策略传输数据量多,网络带宽减少容易引起拥塞.第2个实验比较了使用3种不同更新策略的嵌套视图的数据新鲜度.这里采用了传统的评价Web上更新传播的数据新鲜度的公式,其中通过数据一致的元组占视图总元组的百分比表示视图的数据新鲜度.其中bfresh(tuple)t=0,tuple在t时和数据源不一致图8显示了随着数据服务更新频率增加,在600s的时间段内不同策略更新的嵌套视图的数据新鲜度(在60s内,根据均匀分布随机选取数据服务,被选中的数据服务进行更新,并且根据均匀分布随机选取嵌套视图,被选中的嵌套视图作为考察其数据新鲜度的对象,其中数据服务每次更新10%的元组,因此嵌套视图的数据新鲜度是10个时间段的bfresh(v)的加权平均).如图所示,利用重新计算策略更新的嵌套视图的数据新鲜度下降的最快,而利用Delta算法进行更新的嵌套视图的数据新鲜度下降最平缓,并且一个重要的观察结果是:相比前3种策略分别在42、30和30时趋于相对平稳,Delta算法则在22便趋于相对平稳.在经过计算得知,利用Delta算法进行更新的数据新鲜度比利用重新计算进行更新的数据新鲜度提高了60%,比利用计数算法进行更新的数据新鲜度提高了18%,比AquaLogic进行更新的数据新鲜度提高了20%,其原因是Delta算法减少了冗余计算,并且它的增量计算时间比计数算法和AquaLogic的增量计算时间更少.上述一系列的实验还表明,相比XML,由于嵌套关系模型结构规范,增量更新公式相对简单,使得Delta算法在上述各项指标的比较中好于AquaLogic的更新策略,但是一个不可忽略的问题是,Delta算法不适合XML上的增量更新.在上述实验的过程中,日志组件记录的日志大小保持在1KB到25KB之间,没有出现空间开销急剧增长的情况,因此日志组件支持了嵌套视图的可扩展性,并且证明是有效和可行的.7结论本文提出了基于数据服务的嵌套视图动态更新方法,包括数据服务更新传播架构和增量更新模型,本文从3个方面考虑并设计了加快增量更新计算的日志组件,并且在该日志组件中实现了增量更新算法.本文在原型系统中进行了实验分析,结果表明,该方法不仅带来了明显的性能提高而且支持了嵌套Page11视图的可扩展性.由于该方法目前只涉及数据源到嵌套视图的正向更新操作,因此下一步工作重点考虑嵌套视图到数据源写操作所涉及的反向更新问题.
