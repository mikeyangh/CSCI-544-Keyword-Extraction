Page1类脑智能研究的回顾与展望1)(中国科学院自动化研究所类脑智能研究中心北京100190)2)(中国科学院自动化研究所模式识别国家重点实验室北京100190)3)(中国科学院自动化研究所智能感知与计算研究中心北京100190)4)(中国科学院脑科学与智能技术卓越创新中心上海200031)摘要人工智能学科诞生以来,实现人类水平的智能系统便是本学科探索的长期目标.然而经历了近60年的发展,目前还没有任何一个通用智能系统能够接近人类水平:具有协同多种不同的认知能力;对复杂环境具备极强的自适应能力;对新事物、新环境具备自主学习的能力等.随着脑与神经科学、认知科学的发展,在不同尺度观测各种认知任务下脑神经网络的部分活动并获取相关数据已成为可能.因此,受脑工作机制启发,发展类脑智能成为近年来人工智能与计算科学领域研究的热点.类脑智能是以计算建模为手段,受脑神经机制和认知行为机制启发并通过软硬件协同实现的机器智能.类脑智能系统在信息处理机制上类脑,认知行为和智能水平上类人,目标是使机器实现各种人类具有的多种认知能力及其协同机制,最终达到或超越人类智能水平.文中将从脑科学、认知科学、人工智能研究交叉的视角回顾与类脑智能研究有关的历史、现状与研究焦点,并展望该研究领域的发展方向、可能的应用领域及其潜在的深远影响.关键词类脑智能;人工智能;认知计算;认知脑计算模型;类脑信息处理;智能机器人1引言机器智能的探索可以追溯到图灵[1],甚至是更早的帕斯卡与莱布尼茨[2-4].在这个学科的萌芽期,图灵对智能科学就提出了很高的要求与长远的愿景,即希望未来的智能系统能够像人一样思考[1].在1956年人工智能学科创立之初,相关学者提出了“模拟、延伸、扩展人类智能”以及“制造智能机器的科学与工程”的基本定义和长远目标[5]①.经过近60年的发展,人工智能学科已经奠定了若干重要的理论基础,并取得了诸多进展:如机器感知和模式识别的原理与方法、知识表示与推理理论体系的建立、机器学习相关的理论和系列算法等.在智能系统实践方面,IBMDeepBlue系统击败国际象棋世界冠军卡斯帕罗夫、IBMWatson问答系统在“危险边缘”挑战赛中击败人类对手、Siri等自动人机对话与服务系统的出现、Google汽车自动驾驶等都从不同视角展示了这个领域的进展.然而,上述所有的突破都仅是智能系统从某个视角、在某个特定领域接近、达到或超过人类智能,而相关的理论、算法与系统很难推广到其他领域,用于解决其他类型的问题.在多认知功能协同和通用性智能方面,机器还与人类有明显差距.现有人工智能系统通用性较差与其计算理论基础和系统设计原理有密不可分的关系.从计算基础角度讲,图灵机模型和冯·诺依曼计算机体系结构的提出,从计算本质和计算结构方面分别奠定了现代信息处理和计算技术的两大基石,然而两者共同的问题是缺乏自适应性.图灵计算的本质是使用预定义的规则对一组输入符号进行处理,规则是限定的、输入也受限于预定义的形式.图灵机模型取决于人对物理世界的认知程度,因此人限定了机器描述问题、解决问题的程度.而冯·诺依曼体系结构是存储程序式计算,程序也是预先设定好的,无法根据外界的变化和需求的变化进行自我演化[6-7].这两个基础已经支撑现代信息处理与计算技术近60多年的发展.受限于图灵机与冯·诺依曼体系结构,目前的智能系统在感知、认知、控制等多方面都存在巨大瓶颈,比如难以实现海量多模态信息的选择性感知与注意、模式识别与语言理解在处理机制与效率等方面与人脑相比还存在明显不足,较多依赖人工输入知识或提供训练样本,系统对新环境与新问题需要建立不同的算法,自适应能力还较差等.未来急需突破这种输入与处理形式相对固定的计算方式,取而代之的将是更为灵活的、更类人的智能信息处理与计算模式.从问题求解原理角度讲,目前几乎所有的人工智能系统都需要首先进行人工形式化建模,转化为一类特定的计算问题(如搜索、自动推理、机器学习等)进行处理.虽然人工智能历史上曾有研制通用问题求解系统的努力,但是仍需要由人将问题归纳为一系列合式公式或霍恩子句[8].而人脑却采用同一个信息处理系统进行自动感知、问题分析与求解、决策控制等.因此,未来人工智能系统想要达到通用智能的水平,需要解决的核心问题之一便是问题的自动形式化建模.当前,大数据的出现和深度学习算法的提出与应用,推动了很多特定领域机器智能水平的快速发展(如语音识别和图像分类性能的快速提升正是得益于深度神经网络和基于海量数据的训练),带动了新一轮智能技术研究和创新的热潮.然而,深度学习的优越性能仍然限于特定领域,其实现依赖大量标记样本,而且主要是离线学习,它的环境迁移和自适应能力较差.同时,大数据、云计算、移动终端、物联网等技术的兴起和推广,给信息技术和智能技术提供了无限的创新空间和发展前景.这些应用中要解决的核心问题就是数据分析、理解和有效利用.无论是来自自然环境和交互的感知数据,还是用户产生的合成数①McCarthyJ.Whatisartificialintelligence?http://www-Page3据,大部分为非结构化数据,如图像、视频、语音、自然语言等.机器对这些数据的理解能力与人类相比还有明显的差距,正是这种能力的不足阻碍了大数据的充分和有效利用.可以说,大数据给智能技术带来了巨大的机遇,同时又提出了许多新的挑战.人脑是一个通用智能系统,能举一反三、融会贯通,可处理视觉、听觉、语言、学习、推理、决策、规划等各类问题,可谓“一脑万用”.并且,人类的智能感知和思维能力是在成长和学习中自然形成和不断进化的,其自主学习和适应能力是当前计算机难以企及的.因此,人工智能的发展目标是构建像人脑一样能够自主学习和进化、具有类人通用智能水平的智能系统.文献[9]指出:“除人脑以外,没有任何一个自然或人工系统能够具有对新环境新挑战的自适应能力、新信息与新技能的自动获取能力、在复杂环境下进行有效决策并稳定工作直至几十年的能力.没有任何系统能够在多处损伤的情况下保持像人脑一样好的鲁棒性,在处理同样复杂的任务时,没有任何人工系统能够媲美人脑的低能耗性”.因此,从信息处理与智能本质角度审视人脑信息处理,借鉴其原理并催生类脑智能计算技术是实现人工智能创新的重要源泉.近年来脑与神经科学、认知科学的进展使得在脑区、神经簇、神经微环路、神经元等不同尺度观测各种认知任务下脑组织的部分活动并获取相关数据已成为可能.人脑信息处理过程不再仅凭猜测,通过多学科交叉和实验研究得出的人脑工作机制也更具可靠性.因此,受脑信息处理机制启发,借鉴脑神经机制和认知行为机制发展类脑智能已成为近年来人工智能与计算科学领域的研究热点.在上述背景与理解的基础上,本文对类脑智能进行如下定义:类脑智能是以计算建模为手段,受脑神经机制和认知行为机制启发,并通过软硬件协同实现的机器智能.类脑智能系统在信息处理机制上类脑,认知行为和智能水平上类人,其目标是使机器以类脑的方式实现各种人类具有的认知能力及其协同机制,最终达到或超越人类智能水平.由于类脑智能的手段主要是从机制上借鉴脑,而不是完全模仿脑,其对应的英文术语为“Brain-inspiredIntelligence”更为合适.本文将从脑与神经科学、认知科学、人工智能研究交叉的视角回顾与类脑智能研究有关的历史性进展、研究现状与焦点,并展望该领域未来的发展方向、可能的应用领域与机遇及其对未来智能科学与人类社会潜在的深远影响.2类脑智能的历史文献[7]是初步探索人脑与计算机信息处理机制之间关系的重要著作.作者初步论述了计算机与人脑信息处理机制的异同,特别指出脑神经系统可被理解为数字计算和模拟计算的混合计算系统.同时指出高度并行化、冗余设计等是人脑与当时的计算机系统相比具有的优越性[7].由于类脑智能这个研究领域还处于萌芽期,学术界还尚未形成广泛接受的概念.最早以术语“类脑智能”出现的正式研讨可追溯到2007年Sendhoff、Sporns等人在德国组织召开了首届国际类脑智能研讨会(TheInternationalSymposiumofCreatingBrain-likeIntelligence),随后出版的会议论文集中指出:“类脑智能将实现高度进化的生物脑所表现出的智能”[10].总体而言,经过上百年的研究,人们对于脑信息处理机制的认识仍然比较初步,尚不能依据每一个神经元细节研制出与人脑完全一致的智能系统.且人脑是进化的产物,在进化过程中存在各种设计妥协[11],因此从脑信息处理机制出发推动人工智能研究最优的途径应当是受脑启发、借鉴其工作机制,而不是完全地模仿.从借鉴脑信息处理机制(包括脑神经机制和认知行为机制)的角度,下述工作可以看作是类脑智能的前期探索.2.1认知科学中类脑智能研究的萌芽图灵奖获得者Newell在其最后的演讲当中提出他终其学术生涯希望回答的科学问题:“人类的心智如何能够在物理世界重现”[12],其具体的探索即是人类思维如何在计算机系统上重现.Newell的探索可以被认为是以认知心理学为核心,对类脑智能的早期探索,其重要思想与成果汇聚为认知体系结构.至今在认知心理学与人工智能领域广泛应用于心智建模的认知体系结构SOAR与ACT-R都是在Newell直接领导下或受其启发而发展起来的.SOAR与ACT-R均起源于卡内基梅隆大学,其中SOAR认知体系结构最初由Newell主导,Newell将其提出的认知统一理论倾注在SOAR系列认知体系结构之中,随后由Laird继续发展[13-14].该系统核心是产生式系统,并以此为基石实现对人类各种认知功能的建模.SOAR系统在认知机器人和军事Page4领域有着广泛的应用[15].由Anderson[12]主导的ACT-R认知体系结构也是在Newell工作的启发下发展起来的.其根基可以追溯到人类关联记忆模型HAM[16].Anderson后来将认知神经科学研究关于脑信息处理机制的成果加入ACT-R,特别是基于脑影像技术发展ACT-R对支撑不同认知功能的脑区环路进行计算建模成为ACT-R有别于SOAR以及其他认知体系结构最明显的特点[12].ACT-R不但初步实现了对脑区环路的建模,能够支持特定任务下脑区活动的预测,在智能系统应用方面,ACT-R还被广泛地应用于自然语言处理、教育、军事等领域[12].2.2计算神经科学中类脑智能的早期探索计算神经科学是以计算建模为手段,研究脑神经信息处理原理的学科.这个学科自建立之初就与类脑智能研究的目标密切相关,原因是该学科研究重点之一便是通过多尺度计算建模的方法验证各种认知功能的脑信息处理模型.Marr[17]不仅是计算机视觉的开拓者,他还在计算神经科学领域,奠定了神经元群之间存储、处理、传递信息的计算基础,特别是对学习与记忆、视觉相关环路的计算建模作出了重要贡献[18-21].计算神经科学在神经元信息处理的计算建模方面成果丰硕.Hodgkin与Huxley据生理实验结果创建了第一个精细的动作电位模型,为神经元离子尺度的计算建模奠定了基础.Tsodyks等人[23]构建了神经元之间的突触计算模型,是神经网络信息传递的计算基础.但总体而言,传统的计算神经科学仍然更为关注神经系统表现出来的物理现象(如振荡、相变等)和微观尺度的建模,对于整体的脑认知系统相对缺乏框架级别的计算模型.由瑞士洛桑联邦理工大学(EPFL)发起的蓝脑计划(BlueBrainProject,BBP)自2005年开始实施,该项目试图通过计算模拟的方法在计算机上重建完整的鼠脑,以达到对脑信息处理机制以及智能的深度探索[24].这个项目具有深远的科学愿景,然而脑神经系统是多尺度结构,每个尺度信息处理的机制都还有若干重要问题尚未解决(如神经元尺度精细的连接结构、脑区尺度反馈的机制等),因此即使是全面构建神经元与突触数量只有人脑约1/1000规模的鼠脑计算模型,以现在科研水平来看仍然十分困难.该项目经过10年努力,主要专注于极为精细的微观神经元及其微环路建模,目前较为完整地完成了特定脑区内皮质柱的计算模拟[25],而在此基础上真正实现认知功能的模拟还有很大鸿沟.2.3人工智能中的神经网络研究人工智能领域历史上若干进展都与类脑的思想密不可分.可以认为人工智能的符号主义研究出发点是对人类思维、行为的符号化高层抽象描述,而以人工神经网络为代表的连接主义的出发点正是对脑神经系统结构及其计算机制的初步模拟.早期人工神经网络研究真正借鉴脑神经系统生物证据的并不多,主要是借鉴神经元、突触连接这些基本概念,而具体神经元的工作原理、突触的形成原理、网络结构等则与脑神经网络存在巨大差异[26].人工神经网络的研究可以追溯到20世纪40年代[27],有些人工神经网络模型中还借鉴了脑神经元之间突触连接的赫布法则作为其学习理论[28].感知器(Perceptron)是浅层人工神经网络的代表,由于其权值自学习能力引起了巨大关注.Minsky等人[29]指出单层感知器无法表示异或函数的缺陷使得人工神经网络研究一度陷入低谷,而反向传播算法的提出解决了多层感知机学习的难题[30].随后在文献[29]中提出的第二个问题,即当时计算能力的提升不足以支持大规模神经网络训练的问题长期限制了人工神经网络的发展,直至深度学习的诞生及其支撑硬件平台的发展[31].在深度学习提出之前,Rumelhart等人[32]重新提出误差反向传播算法,其在非线性模式分类中显示的强大性能带动了人工神经网络研究和应用的一轮热潮.LeCun等人[33]提出的卷积神经网络受到了Fukushima等人[34]更早提出的Neocognitron的启发,而Neocognitron的主要特点是采用了早期神经科学中发现的局部感受野[35].深度学习算法提出之后,随着GPU并行计算的推广和大数据的出现,在大规模数据上训练多层神经网络(有的多达20多层)成为可能,从而大大提升了神经网络的学习和泛化能力.然而,增加层数的人工神经网络仍然是脑神经系统的粗糙模拟,且其学习的灵活性仍然远逊于人脑.在人工神经网络的研究中,大多数学者主要关心提升网络学习的性能.Riesenhuber和Poggio等人[36-37]及其合作者的工作是人工神经网络向更类脑方向发展的典范,特别是其模仿人类视觉信息处理通路构建的HMAX模型上的一系列工作.此外,Bengio及其合作者融合了脑的基底神经节与前额叶的信息处理机制,提出了类脑强化学习,也是人工神经网络向更类脑的方向发展有较大影响力的工作[38].在人工智能长期的发展历史上,更多的研究工Page5作集中在类人行为建模上,目标一般为行为尺度接近人类水平.由于过去脑与神经科学研究还不能很好地支撑在不同尺度对智能行为给出深入解释等原因,总体而言,过去在智能系统的实现机理上接近脑神经机理的重要成果并不多.3类脑智能的研究现状人工智能研究者目前已经意识到借鉴脑信息处理的机制可能带来的好处.而脑与神经科学的进展也为人工智能借鉴脑信息处理机制提供了必要的基础(如目前已能够针对不同类型的神经元进行电生理实验来采集其放电活动模式.此外功能性钙成像技术、核磁共振设备等的发展使得研究者可以分别在微观神经元、介观神经簇、宏观脑区等不同尺度获取脑神经系统的影像数据).脑与神经科学的研究者也正在力图将对脑信息处理的认识应用于更广泛的科学领域.该学科的发展得益于信息技术与智能技术的推动,而反过来脑与神经科学也将启发下一代信息技术的变革.在这样的背景下,由学术界倡议、政府资助,欧、美、日等都分别推出了国家级的脑计划,其中几个重大研究计划中都对类脑智能研究进行了战略部署.其中,2013年启动的欧盟脑计划(HumanBrainProject)的核心研究目标就是通过超级计算机构建人脑模型,用计算机模拟的方法研究人脑如何工作,并为未来的计算系统和机器人技术提供启发,促进其变革[9].同样在2013年启动的美国脑计划(BRAIN)原本并没有计划与人工智能研究紧密结合,而随后美国高级情报研究计划署(IARPA)在2014年开始组织全新的机器智能项目MICrONS计划(MachineIntelligencefromCorticalNetworks)①,力图通过对脑皮层的研究来启发全新的机器智能,特别是变革传统的机器学习.2015年内该项目将正式启动,目前已纳入美国脑计划.在具体的研究进展方面,学术界与工业界在2010年以后,都将类脑智能相关研究推向了新高潮.相关工作大体上可分为两大方向:类脑模型与类脑信息处理、类脑芯片与计算平台.3.1类脑模型与类脑信息处理深度神经网络的多层结构以及层次化抽象机制与人脑信息处理的层次化抽象机制具有共通性.相关研究近年来在学术界与工业界取得了突破性的成果.由斯坦福大学的Ng和Google公司Dean共同领导的GoogleBrain项目采用深度神经网络,在16000个CPU核构建的大规模并行计算平台上实现了图像识别领域的突破[39].随后微软研究院、百度研究院在语音和图像领域的研究中都采用了深度神经网络(如文献[40]指出,百度语音识别系统的相对误识别率降低了25%),迅速提升了其在视听觉信息处理领域的识别效果.由神经科学家与深度学习研究者合作创建的DeepMind公司提出深度强化学习模型,并在此基础上研发出具有自主学习能力的神经网络系统,通过与环境交互和不断地试错,自动学会打49种不同的电子游戏,接近或超越人类玩家[41].其网络结构的核心是卷积神经网络与强化学习算法的融合.该方法的优势是不需要手工选取重要的特征,经过大规模图像在深度网络上的训练后能够表现出较好的自适应性.其缺点是对于需要长远规划的游戏则表现较差,因为强化学习算法在进行动作选择前主要关注决策前最近邻的状态.深度神经网络虽然在感知信息处理方面取得了巨大突破和应用成效,然而依然有其发展瓶颈.首先是训练效率问题,绝大多数情况下需要有大量标注样本训练才能保证足够高的泛化性能.其次是网络不够鲁棒,可能把明显不属于某个类别的模式非常自信地判别为该类[42].此外传统的深度神经网络并不善于处理时序问题,而许多应用场景下数据与问题都具有较强的时序性.循环神经网络(RecurrentNeuralNetwork,RNN)正好是针对时序信号设计的.尤其是基于长短时记忆(Long-ShortTermMemory,LSTM)的循环神经网络近年来成为时序信号分析(如语音识别、手写识别)最有效的模型[43].然而其缺点也是需要巨量的训练样本来保证泛化性能.加拿大滑铁卢大学Eliasmith团队的SPAUN脑模拟器是多脑区协同计算领域标志性的工作.该团队早期曾提出神经工程框架理论(NEF),通过定义功能函数并用神经网络逼近函数的思路来建立神经信息处理与认知功能实现之间的联系[44].2012年,该团队基于早期的积累及新提出的语义指针架构统一网络(SemanticPointerArchitectureUnifiedNetwork,SPAUN),将250万个虚拟神经元组织为约10个模块化脑区,并在此基础上构建工作流式的脑区计算环路,发展出模拟笔迹、逻辑填空、简单视①Themachineintelligencefromcorticalnetworksproject:Page6觉处理、归纳推理、强化学习等能力,实现了基于多脑区协同的能够实现多个特定功能的神经网络[45].然而该项目的问题在于为不同任务的实现人工构建了不同的工作流,脑区模型之间的协同并非自组织的.这与人脑的工作机制具有很大差异,即SPAUN脑区计算环路并不具有真正的自适应性和通用性,而是根据不同任务需要人工预先组织与定义的.由Hawkins等人[46-47]提出的分层时序记忆(HierarchicalTemporalMemory)模型更为深度借鉴了脑信息处理机制,主要体现在该模型借鉴了脑皮层的6层组织结构及不同层次神经元之间的信息传递机制、皮质柱的信息处理原理等.该模型非常适用于处理带有时序信息的问题,并被广泛地应用于物体识别与跟踪、交通流量预测、人类异常行为检测等领域.3.2类脑芯片与计算平台借鉴神经元信息处理机制发展类脑芯片与计算平台是在硬件层面发挥类脑智能优势的一大趋势,目前欧美等国都开展了此方向的广泛研究.英国曼彻斯特大学的SpiNNaker项目通过ARM芯片并借鉴神经元放电模式构建了类脑计算硬件平台,该工作的特点是以较少的物理连接快速传递尖峰脉冲[48].该项目目前已成为欧盟脑计划的一部分.类脑芯片与计算平台研究的动机是通过借鉴脑神经系统的工作原理,实现高性能、低功耗的计算系统,终极目标还要达到高智能.2014年,IBM推出TrueNorth芯片,借鉴神经元工作原理及其信息传递机制,实现了存储与计算的融合.该芯片包含4096个核、100万个神经元、2.56亿个突触,能耗不足70毫瓦,可执行超低功耗的多目标学习任务[49].美国加州大学和纽约州立大学石溪分校的Prezioso等人[50]研制出了完全基于忆阻器的神经网络芯片,目前可基于该芯片感知和学习3×3像素的黑白图像.高通公司也推出了神经处理器NPU,并应用于手机使用行为学习、机器人研发等领域①.此外,作为欧盟脑计划的核心组成部分之一,德国海德堡大学提出的BrainScaleS项目也在类脑机制和高性能计算方面取得进展.其基本思路是在晶元上集成超大规模突触,以降低通信代价,提高计算性能[51].有关类脑芯片与计算系统的国际进展及现状,文献[52]进行了更为全面的论述.国内在本领域的研究仍然处于萌芽期.中国科学院计算技术研究所陈云霁团队研发了深度学习系列芯片[53-54],该芯片为实现深度学习做了定制化的优化,其中DaDianNao采用多核体系结构,在深度学习任务上可以达到单GPU的450.65倍,针对64结点能耗可降低150.31倍[54].DianNao系列芯片借鉴神经系统的工作原理在功耗方面取得一系列突破,未来该团队也计划融入更多的脑信息处理机制来改进现有的深度学习芯片.3.3类脑智能研究相关科研机构脑与神经科学、人工智能、计算机科学的深度融合与相互借鉴已成为近年来科学研究领域重要的国际趋势.近期国内外相关研究机构建立了一批与类脑智能密切相关的交叉科学研究中心.瑞士洛桑联邦理工学院(EPFL)建立了脑与心智研究所(BrainMindInstitute),其科研团队包含了基础神经科学、计算神经科学、人工智能、机器人相关的科研人员,共同从事瑞士蓝脑计划、欧盟脑计划相关的研究.美国麻省理工学院成立了脑、心智与机器研究中心(CenterforBrain,MindandMachine,MIT),由著名计算神经科学家、人工智能专家Poggio领导.研究中心由美国国家自然科学基金委支持,旨在集结计算机科学家、认知科学家、神经科学家开展深度合作,从事智能科学与工程研究.其目前主要研究方向是感知学习、推理、神经计算.斯坦福大学成立了心智、脑与计算研究中心(StanfordCenterforMind,BrainandComputation),由认知心理学家、人工神经网络专家McClelland领导.该中心集成理论、计算和实验研究的方法,致力于研究感知、理解、思维、感受、决策的脑神经信息处理机制.为全面提升智能科学与技术研究,中国科学院自动化研究所在凝炼全所科研力量的基础上提出了类脑智能研究战略,并于2015年4月成立类脑智能研究中心.此外,清华大学成立类脑计算研究中心、北京大学成立脑科学与类脑研究中心,上海交通大学成立仿脑计算与机器智能研究中心,厦门大学成立福建省仿脑智能系统重点实验室.近期,中国科学院成立了中国科学院脑科学与智能技术卓越创新中心,由神经科学研究所、自动化研究所等机构共建,将深度实质性融合脑与神经科学、认知科学、人工智能、计算机科学等不同领域的研究,实现脑科学的深度探索与类脑智能的创新研究.①HofRD.NeuromorphicChips.MITTechnologyReview,Page74类脑智能的未来类脑智能研究已取得了阶段性的进展,但是目前仍然没有任何一个智能系统能够接近人类水平,具备多模态协同感知、协同多种不同认知能力,对复杂环境具备极强的自适应能力,对新事物、新环境具备人类水平的自主学习、自主决策能力等.人工智能研究离真正实现信息处理机制类脑、认知能力全面类人的智能系统还有很长的路要走.本文在总结分析类脑智能发展历史与现状的基础上,提出未来类脑智能研究的重要研究方向与设想,并分析其对应用带来的影响.4.1认知脑计算模型的构建传统人工智能系统的设计与实现思路是:从待解决问题相关数据的特点与问题目标的角度出发,从计算的视角设计算法.这使得所实现的智能系统只适用于解决某一类问题.而类脑智能研究长期的目标是实现通用智能系统[55],这就需要首先研究人脑如何通过同一系统实现不同的认知能力,从中得到启发并设计下一代智能系统.因此,类脑智能研究的首要任务是集成两百年来科学界对于人脑多尺度结构及其信息处理机制的重要认识[56]①,受其启发构建模拟脑认知功能的认知脑计算模型,特别需要关注人脑如何协同不同尺度的计算组件,进行动态认知环路的组织,完成不同的认知任务.在未来认知脑计算模型的研究中,需要基于多尺度脑神经系统数据分析结果对脑信息处理系统进行计算建模,构建类脑多尺度神经网络计算模型,在多尺度模拟脑的多模态感知、自主学习与记忆、抉择等智能行为能力.下述研究内容将对认知脑计算模型的发展至关重要:(1)多尺度、多脑区协同的认知脑计算模型:根据脑与神经科学实验数据与运作原理,构建认知脑计算模型的多尺度(神经元、突触、神经微环路、皮质柱、脑区)计算组件和多脑区协同模型,其中包括类脑的多尺度前馈、反馈、模块化、协同计算模型等;(2)认知/智能行为的类脑学习机制:多模态协同与联想的自主学习机制,概念形成、交互式学习、环境自适应的机制等;(3)基于不同认知功能协同实现复杂智能行为的类脑计算模型:通过计算建模实现哺乳动物脑模拟系统,实现具备感知、学习与记忆、知识表示、注意、推理、决策与判断、联想、语言等认知功能及其协同的类脑计算模型.在认知脑计算模型的研究中,处于最核心位置的是学习与记忆的计算模型.传统的人工神经网络(包括深度神经网络)虽然部分受脑神经网络工作机制的启发,但是突触权重的训练模型并不具备深刻的生物实验机理支撑,而与传统人工神经网络的权重训练方法有所差异的是,脑神经网络的突触形成与信息传递有特定的生物工作机理支撑,所有认知任务相关的脑区中,学习与记忆遵循相同的法则:即赫布学习法则(Hebb’sLaw)与脉冲时序依赖的突触可塑性(缩写为STDP)[57-58].以往人工神经网络应用广泛的模型中大多没有采纳这些机制或过于简化.此外,在人脑中不同类型的学习(陈述性知识学习、过程性知识学习)与记忆(短时、长时工作记忆)由不同的认知环路参与,学习模型在不同尺度都存在一定的差别.未来认知脑计算模型的研究应依据这些学习与记忆环路结构及相关学习理论构建多尺度的学习与记忆框架.4.2类脑信息处理由于人脑是一个进化的产物,虽然其结构与信息处理机制在不断优化,但是进化过程中的妥协是不可避免的.因此,需要在认知脑计算模型的基础上进一步抽象,选取最优化的策略与信息处理机制,建立类脑信息处理理论与算法,并应用于多模态信息处理中.类脑信息处理的研究目标是构建高度协同视觉、听觉、触觉、语言处理、知识推理等认知能力的多模态认知机.具体而言,将借鉴脑科学、神经科学、认知脑计算模型的研究结果,研究类脑神经机理和认知行为的视听触觉等多模态感知信息处理、多模态协同自主学习、自然语言处理与理解、知识表示与推理的新理论与方法,使机器具有环境感知、自主学习、自适应、推理和决策的能力.类脑信息处理的关键研究内容主要包括:(1)感知信息特征表达与语义识别模型:针对视觉(图像和视频)、听觉(语音和语言)、触觉等感知数据的分析与理解,借鉴脑神经机理和认知机理研究结果,研究感知信息的基本特征单元表示与提取方法、基于多层次特征单元的感知信息语义(如视觉中的场景、文字、物体、行为等)识别模型与学习方法、感知中的注意机制计算模型以及结合特征驱动和模型驱动的感知信息语义识别方法等;(2)多模态协同自主学习理论与方法:人脑的环境感知是多模态交互协同①LinkedBrainData:Integrating,LinkingandAnalyzinglinked-brain-data.orgPage8的过程,同时感知特征表示和语义识别模型在环境感知过程中不断地在线学习和进化.实现这种多模态协同的自主学习计算模型对提高机器的多模态感知能力具有重要意义.实现的一种途径是结合多种表示和学习方法进行动态自适应的在线学习,同时对多种特征表示和语义识别模型进行适应;(3)多模态感知大数据处理与理解的高效计算方法:面向大数据理解的应用需求,基于类脑感知信息表达和识别模型,研究面向感知大数据处理的新型计算模式与方法,如多层次特征抽取和识别方法,结合特征和先验知识、注意机制的多层次高效学习、识别与理解等;(4)类脑语言处理模型与算法:借鉴人脑语言处理环路的结构与计算特点,实现具备语音识别、实体识别、句法分析、语义组织与理解、知识表示与推理、情感分析等能力的统一类脑语言处理神经网络模型与算法.4.3类脑芯片与类脑计算体系结构现有的类脑芯片大多数还是基于冯·诺依曼体系结构的研究工作,且在芯片制造材料上大多数还采用的是传统半导体材料.未来类脑芯片的发展,应受脑与神经科学、认知脑计算模型、类脑信息处理研究的启发,探索超低功耗的材料及其计算结构,为进一步提高类脑计算芯片的性能奠定基础.国际上一个重要趋势是基于纳米等新型材料研制类脑忆阻器、忆容器、忆感器等神经计算元器件,从而支持更为复杂的类脑计算体系结构的构建.虽然神经形态计算至今已发展了20余年[59],但是目前已研发出的神经芯片还只是借鉴了脑信息处理最基本单元的最基本计算机制(如存储与计算融合、脉冲放电机制、神经元之间的连接机制等),而不同尺度信息处理单元之间的机制尚未融入到类脑计算体系结构的研究中(如目前类脑芯片及类脑计算体系结构尚未很好地借鉴神经微环路、皮质柱、脑区、多脑区协同等的结构及其计算机制),急需将这个研究方向从微观尺度的借鉴提升到借鉴脑的多尺度信息处理机制层面,关注全脑不同尺度计算组件的协同处理给脑信息处理带来的优势.此外,基于传统芯片发展起来的计算系统目前拥有相对完备的指令集、操作系统、编程语言等方面的支持,而基于类脑芯片研发的类脑计算机及大型类脑计算系统的发展也需要相应软件环境来支持其广泛应用,在这方面的研究挑战也是巨大的.4.4类脑智能机器人与人机协同目前智能机器人的研究还主要基于智能控制技术,机器人能够实现的动作及行为能力基本是通过预定义的规则实现的,而人类进行动作、行为的学习主要是通过模仿及与环境的交互.此外,目前智能机器人还不具有类脑的多模态感知及基于感知信息的类脑自主决策能力.在运动机制方面,目前几乎所有的智能机器人都不具备类人的外周神经系统,其灵活性和自适应性与人类运动系统还具有较大差距.未来发展的趋势是基于认知脑计算模型、类脑信息处理的研究来构建机器脑,发展中枢神经系统和外周神经系统(以四肢为核心)高度协同的、具有多模态感知、类人思维、自主学习与决策能力的类脑智能机器人.人类在成长的过程中不断与环境进行交互,获取新知识并与已掌握的知识建立关联,从而提升问题解决和环境自适应的能力[60].受此启发,为提高智能机器人的智能化水平,类脑智能机器人的研究不但要在机理上使其多尺度地接近人类,还要构建机器人自主学习与人机交互平台,使机器人在与人及环境自主交互的基础上实现智能水平的不断提升,最终甚至能够通过语言、动作与行为等与人类协同工作.总体而言,类脑智能机器人不但是未来人工智能研究重要的外显载体,其在未来服务业、智能家居、医疗、国家与社会安全等领域都具有极为广泛的应用价值.4.5类脑智能的应用类脑智能是实现通用人工智能的重要途径,因此类脑智能的应用领域应比传统人工智能的应用领域更为广泛.这使我们从应用视角做出反思:研究类脑智能,让机器实现类人行为和人类水平的智能的意义是什么?从以往工程科学成功的案例来看,完成信息处理和控制任务不一定要用类人的方式,常被提及的例子是飞机飞行不必像鸟那样扇动翅膀.在一些特定领域,比如人脸识别和手写文字识别,深度神经网络经过训练甚至可以超过人的识别精度.然而实现这样的识别系统需要大量的人工设计,且其识别能力仅限于给定领域和限定环境.研究类脑智能的目的则是克服这些局限,通过类人自主学习方式,使机器在少量样本和人工干预的条件下自主进化到类人智能水平,且具有多任务协同的能力.类脑智能未来的应用重点应是适合于人类相对计算机更具优势的信息处理任务,如多模态感知信息(视觉、听觉、触觉等)处理、语言理解、知识推理、类人机器人与人机协同等.即使在大数据(如互联网Page9大数据)应用中,大部分数据也是图像视频、语音、自然语言等非结构化数据,需要类脑智能的理论与技术来提升机器的数据分析与理解能力.具体而言,类脑智能可用于机器的环境感知、交互、自主决策、控制等,基于数据理解和人机交互的教育、医疗、智能家居、养老助残,可穿戴设备,基于大数据的情报分析、国家和公共安全监控与预警、知识搜索与问答等基于知识的服务领域.从承载类脑智能的设备角度讲,类脑智能系统将与数据中心、各种掌上设备等智能终端、汽车、飞行器、机器人等深度融合.5结束语类脑智能研究是人工智能、计算机科学、脑与神经科学、认知科学等研究领域面向下一代智能信息技术的发展面对的跨学科共同挑战.这一挑战需要来自不同学科的科研人员从不同视角审视科学问题,构建开放的公共研究平台进行多学科交叉研究.只有通过上述不同学科之间的深度实质性融合交叉以及相互借鉴与启发,才有希望突破机器智能发展的瓶颈,实现具有通用认知能力和自主学习能力的智能机器.脑与神经科学、认知科学的研究进展将为揭示人类智能本质提供更多线索,为实现类脑智能提供更深层次的启发,受脑启发构建的类脑智能系统将真正实现在信息处理机制上类脑、认知行为上类人,达到并最终超越人类智能水平.
