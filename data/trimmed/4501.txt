Page1李群机器学习十年研究进展杨梦铎李凡长张莉(苏州大学计算机科学与技术学院江苏苏州215006)摘要该文主要从3个方面介绍李群机器学习近年来的研究进展.首先,该文将解释为什么采用李群结构进行数据或特征描述,以此阐明李群机器学习与传统机器学习方法的区别,并且通过李群在人工智能领域的广泛应用来说明李群表示的普遍性.其次,该文概述了李群机器学习自提出以来的主要学习算法,着重强调最近的一些研究进展.最后,针对目前的研究现状,该文给出李群机器学习未来的一些研究方向.关键词李群机器学习;学习算法;李群;分类器1引言由于真实世界中数据的多样性和复杂性,人们经常将数据嵌入到流形结构中表示.这使得传统的基于欧氏空间的机器学习方法变得无效.于是会不可避免地提出这样的疑问———是否存在某种方法:既能够利用流形结构表示数据的便捷性,又能够寻找到相应的可计算模型?对此,流形学习的许多尝试给出了肯定的答案以及两点启发:(1)可以利用流形的性质,对传统的基于欧氏空间的机器学习方法Page2操作下保持光滑结构.近年来,李群不再局限于数学领域的理论研究,这类连续变换群也被许多计算机领域的学者所熟知.在这样的背景下,文献[1-2]将李群表示与机器学习算法结合起来,提出了李群机器学习的理论框架.自2004年提出至今,李群机器学习已经走过了十年的历程,相继出版了两本著作[3-4].为了方便同行们快速的了解相关内容,本文首先介绍李群机器学习的概念,阐述为什么选择李群来研究机器学习.其次,本文给出了目前李群机器学习的主要研究成果并重点介绍一些典型的代表性工作.最后,分析并讨论李群机器学习未来的研究方向与发展趋势.2李群机器学习的概念19世纪后期,挪威数学家索菲斯·李为连续变换群奠定了理论基础,随后这类群被后人命名为李群.在数学中,李群是一个群,同时也是一个微分流形,具有在群操作下保持光滑结构的性质.李群是一类光滑流形,因此能够利用微积分对其进行研究.此外,李群理论的核心思想之一是用李群的线性化版本来替换全局目标李群,这类局部或者线性化表示被索菲斯·李叫做无穷小群,也即后人所称的李代数.定义1.设G是一个非空集合,满足:(1)G是一个群;(2)G也是一个微分流形;(3)群的运算是可微的,即由G×G到G的映射(g1,g2)则称G是一个李群(Liegroup).李群机器学习与传统机器学习方法的不同是李群机器学习采用李群结构对数据或特征进行表示并利用群作用来处理对数据的操作.微分流形的几何性质可以用来便捷地描述数据,群的代数性质能够提供具体的求解方案,这使得李群机器学习的思想得以形成.定义2.李群机器学习.一般用G表示输入空间,M表示输出空间.令GRD,MRd,D>d,借用李群的定义将G对M的左作用可用如下映射表示:满足:(1)对于所有的x∈M,(e,x)=x;(2)对于所有的g,h∈G和x∈M,(g,(h,x))=(gh,x).G对M的右作用可用如下映射ψ表示:满足:(1)对于所有的x∈M,ψ(x,e)=x;(2)对于所有的g,h∈G和x∈M,ψ(ψ(x,g),h)=ψ(x,gh).相对于其他流形而言,李群是被研究得比较深入且被运用得比较多的可微流形.为此,接下来用总结的如下3种原因来解释为什么选择李群结合机器学习任务.2.1李群是变换的自然表示许多模式识别的任务依赖于数据在变换下的不变性问题.因此,在实际应用中经常需要用到“变换”这一概念,例如图像不变性、刚体运动估计等.当需要描述的是变换本身时,所涉及的操作是变换的结合而不是单纯的对变换进行加法或数乘.因此直观上能够理解:采用群这种代数结构来表示变换要比线性空间更加合适.另一方面,群的概念也能够帮助理解群与不变性的关系:如果图像的两个变换都保持一个不变特征,那么很明显这两个变换的合成也不会改变这个特征.因此任意两个这样变换的合成也包含在保持特征不变性的变换集合中.单位变换(不做任何变换)显然能够保持特征,并且任意变换的逆变换也存在于这个集合中.这些都与群的概念一一对应,因此采用群结构表示变换是合适的,从而能够将原始问题转化为寻找相关变换群的问题.群结构和群作用可以保证在实际应用中方便地表示变换.可以说,李群是变换空间的一种自然表示.2.2李群与李代数能够相互转换机器学习方法的性能在很大程度上依赖于数据或特征的表示.采用李群对数据表示所面临的一个问题是:传统的基于向量空间的机器学习方法变得无效.李代数是描述无穷小变换(比如十分小角度的旋转)时用到的代数结构.李的基本定理描述了李群与李代数之间的关系.李代数是李群在单位元处的切空间,它能够完全捕获李群的局部结构.通常,可以将李代数中的元素看作是李群中无限接近于单位元的李群元素.有了李代数的概念,李群能够被看作是局部拓扑等价于向量空间,这使得移植传统的基于向量空间(线性空间)的模型和算法到李空间变得可能.李群和李代数之间的相互转换,使得许多非线性空间问题能够利用李群表示成李代数结构,形成线性空间,这就为非线性问题的线性化表示找到了Page3新途径.除了利用其线性特性构建统计模型之外,李代数还允许沿着李群流形上两点间的最短路径(测地线)引导物体,并且对变换能够给出自然的参数化表示.2.3矩阵群属于李群在模式识别的诸多应用中,尤其是在计算机视觉领域中,经常采用矩阵来存储数据或表示特征.非奇异实方阵在矩阵乘法下构成一般线性群,一般线性群的所有子群构成矩阵群,并且矩阵群具有李群结构.所以诸如仿射群、旋转群、协方差矩阵群这种在人工智能中常见的矩阵群都属于李群.值得一提的是,虽然矩阵群是李群,然而并非所有的李群都是矩阵群.可以说在众多李群中运用得最为广泛的是矩阵群.3李群机器学习模型为了巩固与完善李群机器学习的理论基础,文献[5-7]给出了李群机器学习的4个假设公理与两种学习模型,即几何模型与代数模型.李群机器学习的几何模型利用李群微分流形的性质,致力于学习系统的表示与度量;李群机器学习的代数模型利用李群和李代数之间的相互转换,将向量空间的算法拓展到流形空间.依据两种学习模型,可以概括李群机器学习算法的一些基本思路:一方面,可以利用李群的几何性质来设计算法,包括李群的表示与度量、拓扑性质、流形学习等;另一方面,可以将李群映射到李代数空间,从而能够移植传统的基于向量空间的算法.3.1基于李群的表示李群机器学习利用机器学习方法处理具有李群结构的数据.然而,并不是所有特征都自然地具备李群结构.若要应用基于李群的机器学习方法,首先要做的是构造有效的李群特征.在动态场景中经常会遇到各种各样的变换.这些变换矩阵在矩阵乘法的作用下往往构成一般线性群的某个子群,而这些子群属于李群,因此这些变换特征具有李群结构.如文献[8]总结了常见的的仿射群GA(2)、旋转群SO(3)、特殊欧氏群SE(3)、特殊线性群SL(3)等李子群在计算机领域中的应用.有时在静态场景中也可以利用目标对象到标准模板的变换矩阵,构造李群特征.例如文献[9]为停车场俯视照片中的车辆构建利用旋转角度和缩放比例作为参数的辐条模型,通过建立每个车辆实例到基准车辆的变换构造李群特征并将该变换特征应用在车辆分类问题中.协方差矩阵作为一种正定对称矩阵,能够满足矩阵群的要求,因此是构建李群的另一种方式.文献[10]提出了一种区域协方差特征并将其应用在模板跟踪中.这种特征不仅维数低、可融合多种相关特征而且具有一定程度的旋转和比例不变性.3.2李群度量在李群表示的基础上,遇到的第1个问题就是向量空间的计算不再适用,典型的如李群流形上两点间的距离不能直接用欧氏距离来表示.为此,针对李群流形上的度量问题衍生了一些李群机器学习算法.流形上两点之间具有最短距离的曲线叫做测地线,它定义了流形上的度量.因此,文献[11]在给出李群机器学习模型的同时也给出了相应的等距变换算法和测地线距离算法.算法1.李群机器学习的等距变换算法(IsometricTransformationAlgorithm,IsoT).输入:样本集X={x1,x2,…,xn∈RD}输出:Y={y1,y2,…,yn∈Rd},d<D1.令输入样本集为X={x1,x2,…,xn∈RD},X满足李群结构.2.在X的李代数g上取定一个在自同构Ad(G)的作用下的不变内积:〈Ad(g)x1,Ad(g)x2〉=〈x1,x2〉,x1,x2∈g,g∈G.3.取定一组标准正交基{xi:1in},〈xi,xj〉=δij.用左平移把{xi:1in}分别张成X上左不变向量场,记为xi,即建立起黎曼空间结构.4.在这个黎曼空间上,对X进行左(或右)平移线性变换,即构成了对样本集的等距映射:X→Y,Y={y1,y2,…,yn∈Rd},d<D.算法2.李群机器学习的测地线距离算法(GeometricDistanceAlgorithm,GeoD).输入:样本点a输出:在a的坐标邻域内的所有点与a的距离1.生成样本点a的邻域Ua.2.分析a邻域内信息,在样本集中的单位点上取一个自同构作用下不变的内积gi,j(a),计算gi,j(a)的值.3.将所得gi,j(a)的值,代入中,计算Ua中每一点与a之间的距离.4.输出所有距离值(通常距离值越小表示与要学习的目标结果越相近).在上面的算法中,Ta(M)表示M在点a处的切空间.如果x:U→RD是点a处的坐标系,a处关于xi的方向向量,{那么Page4x()}ngi,j(a)=那么切空间上a点与b点之间的距离为D(a,b)=ngi,j(a)(ai-bi)(aj-bj∑槡i,j=1实际上,算法2给出了一种通用的计算测地线距离的方法.而在实际应用中,更为常见的计算李群中任意两个元素x1,x2之间的距离可以用下面的公式,其中·表示Frobenius范数.对于矩阵李群来说,式(1)·内的部分可以用Baker-Campbell-Hausdorff(BCH)展开公式中的前两项之和-log(x1)+log(x2)近似得到.3.3李群与李代数的相互映射李群与李代数之间的映射关系是通过指数映射以及对数映射来完成的.若要将李群元素映射到相应的李代数向量空间,则需要通过对数映射log:G→g:其中x表示李群元素.若要将李代数元素映射到李群空间中,则需要通过指数映射exp:g→G:其中m表示李代数元素.利用李群对应的李代数元素v∈g,可以唯一确定李群流形上的一条测地线:从表达式看出,测地线是李群G上的一个单参数子群.通过取定t的某个值,就能够确定测地线上的某个群元素.4李群机器学习的相关算法上面简要介绍了李群机器学习模型涉及的3个方面,接下来对目前主要的研究进展进行分析、概括与总结.许多机器学习方法希望从数据中找到某种规律,构建模型并对新样本进行预测.因此,机器学习方法常常被用来完成模式识别的任务.当面临的数据具有李群结构时,人们有时仍然希望能够运用机器学习的方法学习数据的类别信息.从现有的研究成果来看,用于分类的李群机器学习算法,依照算法不同的设计思路大致可以分为两类:第1类是移植基于向量空间的机器学习算法,将其基本思想运用到具有李群结构的数据中;第2类是构造具有分类效果的代数或几何结构,通过结构特性将数据划分开.下面先介绍一个典型的改造向量空间机器学习方法的分类算法.4.1李群均值学习算法一个简单的李群分类器的思想是先计算出训练样本中各个类别的内均值,然后通过比较未知样本与各个均值点之间测地线的距离来确定新样本的类别属性.内均值要求计算出的均值点仍然位于流形结构上,相对于利用欧氏距离计算出的均值点,内均值更能反映流形的真实结构、体现同类样本的共性,因而能够提供更加准确的分类信息.基于内均值分类的思想,文献[9]设计了一个简单的李群分类器,将具有最短李距离的均值点的类别赋给未知的车辆实例,在为停车场俯视照片的车辆分类中取得了非常好的效果.当然,也可以再进一步设计一些基于李群度量的分类算法,比如基于李群的KNN算法、K-Means算法等.如果遇到的问题不再仅仅是空间的度量问题,而是希望能够运用一些基于欧氏空间的机器学习算法时,则需要寻找某种方式使得传统方法能够适用.利用李群和李代数之间的转换关系,可以考虑首先经过对数映射将样本投影到李代数的向量空间,然后在这个局部的线性空间上施加传统的机器学习方法;在学习到李代数参数后,再通过指数映射将数据映射回李群空间.这里给出一个典型的利用李群李代数相互转换解决李群样本分类问题的实例.文献[12]借鉴线性判别分析的思想,在李群流形上寻找一条测地线,将所有样本向这条测地线上投影,使得数据集类间散度和类内散度的比值最大化.李群对应的李代数生成元可通过单参数的指数映射RG:exp(tv),t∈R,v∈g生成李群流形上的一条测地线.李群样本点到测地线的投影被定义成测地线上与样本点距离最近的李群元素,该距离通过流形上的测地线距离来计算.文章中,作者给出的寻找Lie-Fisher投影测地线的算法如算法3.算法3.求Lie-Fisher投影测地线算法(LieFisherAlgorithm,Lie-Fisher).输入:{Mij}j=1,…,n输出:Lie-Fisher投影测地线Hv对应的李代数vPage51.对每一个李群样本Mij去做李代数映射:xij=log(Mij).2.计算每类新样本的均值:μi=以及总体均值:μ=3.计算犛b和犛w:犛b=∑cni∑i=1∑j=1(xij-μi)(xij-μi)T.4.求解Sbv=λSwv,得到的v即可按exp(tv),t∈R生成Lie-Fisher的测地线Hv.算法中犛b和犛w分别代表类间散度矩阵和类内散度矩阵,Fisher的判别函数希望找到某个最佳的投影方向,使得样本在该方向上投影后能够具有最大的类间离散度和最小的类内离散度.一个自然的想法是在李群空间中推导出判别函数,为此文献[12]给出了表达式:J(v)≈但是对于J(v),不能得到显示的解析表达式,求解过程十分困难.于是,作者对每一个李群样本做对数映射,然后利用向量空间中求取平均值的方法计算新样本集的总体均值及各个类别的样本均值.有了这两个计算结果之后,就可以利用标准的Fisher方法得到类间散度矩阵和类内散度矩阵.通过求取特征方程能够求得测地线的李代数生成元,再依照式(4)就可以算得用于最佳分类的那条投影测地线.接下来需要做的就是求取每一类训练样本在李代数空间中向v方向投影后所得的均值,然后通过比较测试样本和各个均值之间的距离来确定新样本T所属的类别信息.判别过程可形式化为下面的表达式:其中,c代表类别的数量,珘μi算法的求解过程从一开始就将李群空间的样本映射到李代数空间中,依据李代数向量空间的性质,可以对映射后的样本运用标准的线性判别分析算法.由于除了映射的过程,后续的计算都是在线性空间中完成的,因此整个算法的效率较高,计算速度快.特别是当数据构成的李群流形几何结构越平坦、越接近于超平面时,算法的精确度越高.除此之外,利用李代数向量空间的欧氏距离表示样本之间的差异还更加适用于低维的李群样本,这也是由于高维样本均值计算误差增大造成的.因此,针对高维的、局部邻域内流形分布不平坦的数据集,可以考虑先在李群空间中求取总体样本的均值以及各类别的均值,然后再将结果映射到李代数空间进而计算v.其中,利用μ每类均值中除去总体均值,用μ某个样本中去掉类内的均值.计算完成后将结果映射回李代数空间求取Fisher的判别函数.由于利用流形测地线计算的内均值更能反应一类样本的共性,因此这样的做法可以提高高维李群样本的分类精度.当然,相对而言在计算方面的开销将会增大.值得说明的是,这里将李群映射到李代数并运用向量空间的方法是可行的,这样的思想在无监督的聚类算法中同样适用并且在相应的文献中也给出了一定的理论证明.例如文献[13]提出了一个适用于任何解析流形的meanshift算法,并以格拉斯曼流形、李群为例,详细地给出了在这两种解析流形上MeanShift算法的推导过程.文献[12-13]给出了设计李群机器学习算法的一种思路,当在原始的李群空间中计算或求解遇到困难时,可以转而映射到相应的李代数空间,这样,线性空间的计算或许能够找到另一种解决途径.而这时,李群的优势也就更加显现出来了,因为李群和李代数之间是能够通过对数和指数映射进行自由转换的.4.2李群半监督学习算法与其他流形相比,李群的特殊之处是李群与李代数之间的关系.李群的基本定理给出了李代数是李群在单位元处的切空间.任意一个李代数存在一个与之对应的连通李群,任意两个具有相同李代数的李群是局部同构的.在实矩阵的例子中,李代数包括那些使得exp(t犡)∈G成立的矩阵犡,其中t∈R,exp表示指数映射.这意味着可以将具有李群结构的数据方便地映射为李代数的形式.而作为李群上的一种局部切空间,李代数具有向量空间的性质.有了这样的前提,将李代数与传统的监督学习、半监督学习方法结合起来能够有效地解决李群空间上的问题.半监督学习问题通常需要解决一类监督学习的任务,但是训练过程经常利用大量的无标签样本以及少量的有标签样本作为辅助.李群上的半监督学习问题可以描述为存在某个样本数量为n=l+k的李群数据集G={xi|xi∈RD,1il+k},其中D表示样本维数,L={(x1,y1),(x2,y2),…,(xl,yl)}表示少量的有标签李群样本,U={xl+1,xl+2,…,xl+k}表示大量无标签李群样本,即满足lk.依据经验的观察,人们发现无标签的数据在结合少量有标签数据之后,学习的准确率能够得到相当大的改进.Page6在这样的研究目的下,文献[14]将半监督的思想引入李群数据集上,设计出相应的李群半监督模型.为了能够利用无标签的李群样本,需要对数据的潜在分布做一定的结构假设.李群的微分流形性质决定了在半监督学习任务中需要用到平滑假设以及流形假设:平滑假设是指通常认为相互邻近的点具有相同的标签;而流形假设意味着相比于输入空间来说,数据往往存在于某个维数低得多的流形上.平滑假设在一定程度上反映了这样一条性质,即相互聚集的点能够形成相同的类别归属,以此尽可能地简化分界边线.流形假设则使得利用无标签数据流形上的距离与密度能够帮助整个学习进程.在假设的基础上,文献[15]利用李群流形上的几何距离(测地线距离)设计基于几何结构的李群半监督学习模型.此外,为了扩展模型以适用于向量空间的半监督学习算法,作者将李群映射到以单参数子群形式存在的李代数空间,设计基于代数结构的李群半监督学习模型.针对李群设计的半监督方法能够对构形空间是李群的数据进行方便地处理.例如,某些医药应用中的药分子特征空间构成李群结构.在监督学习任务中获得大量有标签的数据通常是十分费力的事,有时还需要具有一定经验的专家参与.例如在药物的测定工作中,需要聘请专业的人员对药物分子的活性进行测定.并且在多数情况下,存在大量未被测定的药物分子.这时选用半监督学习的方式不仅能够节约时间与成本,还能在一定程度上保证测定的准确率.传统的学习方法由于受到数据集所在空间的限制不能够提供准确的预测信息.因此,将李群半监督算法应用在药物活性预测中不仅解决了样本的分布问题,而且利用未测定数据提高模型精度,能够在很大程度上减少药物测定的工作成本.4.3李群覆盖学习算法利用李代数解决李群机器学习问题的思路是将李群流形上的数据映射到向量空间中以使得李群机器学习的适用性更加广泛.另一种李群机器学习的解决思路是希望利用李群结构的某些性质,在此之上设计适用的学习算法.有别于改造传统的模式识别方法,这一类用于分类的李群机器学习算法考虑在数据集上构造具有分类性能的结构.例如,寻找原有数据中的某种同构关系暗含了一定的分类信息.群论中规定了两个同构的群具有相同的性质.文献[16]就利用了李群与其覆盖群局域同构的性质,将同类样本采用相同的覆盖群表示,从而将不同类别的样本区分开.在这样的问题中,核心的问题是寻找李群相应的覆盖群.多连通的李群空间必定存在某个同态的、单连通的简单李群与之对应,这个简单李群被称为原李群的一个覆盖群.原李群与其覆盖群之间的映射是一个连续的群同态,被称作覆盖同态.覆盖是研究代数几何的重要工具,其思想在机器学习领域已经得到了广泛的应用.文献[16-17]利用李群特殊的代数几何结构,给出了李群机器学习的单连通覆盖算法和多连通覆盖算法,并将其应用在药物分子设计中,验证了算法的有效性和优越性.在数学中,覆盖群是定义在拓扑群上的一个覆盖空间,这个覆盖空间要构成一个拓扑群并且满足到原拓扑群的映射是一个覆盖同态.并且如果拓扑群H是拓扑群G的一个覆盖群,那么H与G局部同构.作为拓扑群的特例,李群继承覆盖群的所有性质.尤其是对于流形结构,流形的每个覆盖仍然是一个流形,并且在流形上覆盖同态变成了一个光滑映射.李群作为一个微分流形,李群G与其覆盖群是局部同构的,当且仅当G本身为单连通李群时,f为同构.作为单位元处的切空间,李代数还能够辅助李群寻找其覆盖空间.这是因为两个李群是局部同构的当且仅当它们的李代数是同构的.这意味着两个李群之间的映射是覆盖同态当且仅当李代数上的诱导映射是同构映射.除此之外,连通李群G必有连通且单连通的覆盖群(珟G,f),称为G的通用覆盖群.为了简化问题且保证引入的覆盖群仍然是一个李群,需要将研究的范围限制在连通李群中并且引入通用覆盖的概念.连通李群上的覆盖空间存在这样的性质:一个连通李群的通用覆盖仍然是一个李群.事实上,微分流形的任意一个覆盖都是微分流形,但是通过指定通用覆盖保证了李群的群结构.算法4.求连通李群的通用覆盖群算法(Uni-versalCoveringGroupAlgorithm,UCG).输入:连通李群G输出:G的通用覆盖群,覆盖映射f1.取定单位标架(U,φ).从U出发可以构造点集烉烇(U×U×…×∪m=12.取此点集中的元素(u1,u2,…,um)和(v1,v2,…,vp),u,v,uv∈U.根据(u,v)=uv这种规则,对(u1,u2,…,um)进行有限步变化,检查是否可以变为(v1,v2,…,vp).3.将符合等价条件的元素的等价类记为(u1,u2,…,um).继续选择其他元素;将所有符合等价关系的等价类构成集合珟G.4.在等价类集合和(u1,u2,…,um)之间建立覆盖映射Page7f:(u1,u2,…,um)→u1u2…um,则(珟G,f)即为G的覆盖群.对于每一个李代数,存在唯一一个与之对应的单连通李群.那么,一个连通李群G的通用覆盖群是唯一的一个单连通李群H,满足H与G的李代数相同.由于同构的群具有相似的性质,因此可以认为具有相同覆盖群的李群样本共享相同的标签.连通性是主要的拓扑性质之一,可以用来区分两个不同的拓扑空间.一个更强的概念是道路连通空间,在这个空间中任意两个点能够通过一条路径连接起来.在此基础上,文献[16]给出单连通覆盖算法.算法5.李群机器学习的单连通覆盖算法(SimplyConnectedCoveringGroupAlgorithm,SCCG).设定样本集为D={狓i|狓i=(xi,yi),i=1,2…,n},xi表示样本的特征值集合,yi表示样本特征值对应的权值.所有的样本构成一个特征空间,它嵌套在一个微分流形结构中,也就构成了一个简单李群,每个样本点表示群中的一个元素.输入:样本集X={狓1,狓2,…,狓n∈RD}输出:相同类别的样本1.令输入样本集X={狓1,狓2,…,狓n∈RD},X满足李群结构.2.利用求覆盖群算法,得到其覆盖群和覆盖映射.3.求解覆盖群的生成元和结构常数.4.对于新样本,通过覆盖映射将其映射到覆盖群上,判断该点到覆盖群的单位元之间是否存在一条通路,并且通路是否同伦于0.5.若符合条件,则表明新样本是符合输出的,同时将新样本的道路加入到覆盖群的类集,调整覆盖映射的操作算子θ.6.若不符合条件,则此样本不属于要学习的目标结果.7.实例测试.在单连通覆盖算法中,一个拓扑空间X中,点x到点y的路径被定义成单位区间[0,1]到X上的一个连续函数f,其中f(0)=x,f(1)=y.一个非空拓扑空间的极大连通子集称作该空间的连通分支.一个拓扑空间X的连通分支构成了对X的一个划分.划分的概念要求集合是非空的,并且集合之间是不相交的,集合的并集是整个空间.又由于集合的一个划分能够唯一确定一组等价类,这就为分类提供了基础.如果对于每一个有效的分块,都采用对应的覆盖群表示,则可以得到另一类多连通覆盖算法.在文献[16]中,作者在多连通李群群空间分割算法的基础上运用多连通覆盖算法并且给出了相应的应用实例.求解覆盖群的过程是相对复杂的,这说明利用覆盖群的思想做分类问题具有一定的适用范围.李群的性质在很大程度上都与空间的连通度有关.当李群的群空间是多连通的时候,需要利用多值表示,这对问题的分析与求解都是不利的.因此,在遇到连通李群的问题时,可以利用李群与其覆盖群的局部同构关系,不仅可以保持李群流形的拓扑性质,还可以将寻找与李群局部同构的覆盖群问题转化为求解同构的李代数问题并且与在通用覆盖的情况下所求的李代数相同.对于几何性质不太复杂的李群特征,建议采用移植算法的思想.针对一些结构特性较为突出的例子,可以通过寻找数据间的覆盖关系获取一定的分类信息.例如在文献[17]中,作者给出了李群覆盖算法的一个应用实例,将学习算法引入到药物分子设计领域中,进而研究药物构效关系模型和分子对接模型.4.4同调边缘学习算法李群机器学习的优势之一就是集成了代数结构和几何结构,在利用结构特性的模式识别算法中,除了可以构造像覆盖群这样的代数结构也可以从另一个角度思考利用微分流形的一些几何结构.比如,存在另一类基于李群的分类算法是利用特征空间的拓扑性质来设计的.例如,拓扑不变性可用来有效地保持流形内部结构的几何特征,依据对象是否在空间中同胚可以为对象进行分类.文献[18-20]利用同胚的可剖空间与相同维数同调群同构,设计出了同调边缘学习算法.算法的主要思想是:若能够找到两个可剖空间在某一维数的同调群不同构,则可以推断出这两个拓扑空间不同胚.所以同调群构成了判别两个可剖分空间不同胚的一个工具.又由于同调论是边缘划分的有效方法之一,因此作者引用同调代数的方法从机器学习的角度来研究数据的边缘分类问题.当然,除了从同胚的角度考虑分类问题,由于同胚的空间必是同伦等价的,所以可以考虑将同胚的概念推广到同伦等价上.依据拓扑空间的同伦等价关系可将拓扑空间进行分类.同一类拓扑空间具有相同的伦型,不同类拓扑空间具有不同伦型,以此可将拓扑分类拓展成同伦等价分类.4.5李群深层结构学习算法深层结构通常是指将多层非线性的单层模块堆叠起来的学习模型,这些单层模块可以以概率图的形式存在,也可以是具有单个隐藏层的神经网络,并且依据不同的情形可以选择不同的激活函数.相比于浅层模型来说,深层结构能够以一种更紧凑的方式表征十分复杂的函数,并且通常用相对不大的参数规模就可以捕获输入空间多样的配置信息.Page8针对数据的复杂性和图像结构特征的不变性,文献[21-22]在深层结构中嵌入李群半监督学习、李群逐层学习以及李群启发式学习,给出了李群深层结构学习算法.在李群深层结构学习算法中,核心的问题是数据的深层表示.在数据本身以流形形式存在的前提下,作者将输入空间划分成由多个子流形组成.每一个子流形特征化输入数据的某个有效部件.将子流形作为深层结构中的每一层单层模块堆叠起来,可以得到刻画输入的整体模型.在识别阶段,每一层都为最后的分类贡献一定的判别信息,综合各个部件的识别结果,能够反映输入数据的整体描述.该深层结构学习算法与现在流行的深度学习方法有一定的不同.深度学习希望通过特征学习对高层次抽象的特征进行建模.而这里的深层结构强调将样本逐层分结构进行比较.这样分结构比较的原因是因为相同个体不同结构之间的差异性要远远大于不同个体同一结构之间的差异性.就好比人与人之间眼睛的相似度总是大于同一个人眼睛和鼻子的相似度.因此,将一个整体划分为有一定语义的结构,分别相应地进行比较,对于分类任务而言是一种十分有效的方式.当然,对于深度学习的思想,也可以借鉴其特征学习的方式,设计一些李群机器学习的算法.对于已有的初步想法将在最后的展望部分进行描述.4.6Finsler几何学习算法在微分几何中,Finsler流形被定义成一个微分流形M连同定义在M切丛上的Finsler函数F,使得对于每一个切向量狏,F满足平滑性(smoothness)、正定性(positivedefiniteness)、齐次性(homogeneity)以及次可加性(subadditivity).Finsler几何将Finsler流形作为其研究的主要目标,它非平凡地推广了黎曼流形,并采用比黎曼度量更具有一般结构的Finsler度量作为度量准则.文献[23-24]将Finsler度量替换传统K近邻分类(K-NearestNeighbor,KNN)算法中基于欧氏距离的度量,得到基于Finsler度量的KNN改进算法.常见的黎曼几何利用黎曼度量研究黎曼流形与光滑流形,它将欧氏几何扩展到不一定是平坦的空间中,但是在每一点的无穷小处仍然与欧氏空间相似.Finsler几何是一类泛化了黎曼几何的伪黎曼几何(pseudo-Riemanniangeometry),在这个结构中的度量张量不必是正定的.对于流形M上的Finsler结构被定义成这样一个函数F:TM→[0,),TM表示流形M上的切丛,使得F在TM-{0}上是无限可微的,对于TM上的所有x,y满足F(x,my)=|m|F(x,y)并且F2的垂直Hessian是正定的.作者利用实验,将Finsler度量引入到非欧氏的输入空间中,Finsler度量对于分类的有效性得到了验证.除此之外,Finsler度量在多流形数据集上得到进一步扩展,形成了Finsler几何学习模型[24].在该学习模型中,首先需要将多流形的结构划分成单个子流形的集合.文献[24]采用基于中心点的数据集划分方法,预先确定好中心点的个数,然后将每个数据点划分到最近中心点所代表的类别区域中.为了避免维数灾难的问题,对划分好的每个子流形还需做一定的降维处理.接下来,需要利用Finsler度量依据数据集的分布构造相应的邻接图.在邻接图的基础上求出各个子流形中心点间的最短图路径与低维嵌入表示.最后的目标函数是尽量最大化各个子流形中心点之间的Finsler距离,并且保持各个划分开的子流形内部相对紧密,最大限度地降低局部结构的信息丢失.4.7李群机器学习的辛群学习算法在基于结构特性的分类方法中,除了构造数据间的分类结构,还可以利用数据本身所特有的结构帮助分类.矩阵群作为一类特殊的李群,由于它的集合元素是矩阵并且具有方便可计算的李群李代数映射公式,使得它在实际运用中十分常见.在矩阵群中,还可以细分出许多各具特色的群,比如酉群、辛群等.许多李群机器学习算法将这些特殊的群运用在了分类任务中,达到了良好的效果.辛群作为一个典型的李子群,已经被广泛地应用于动力学领域中.文献[25-26]则从机器学习的角度将辛群应用在计算机视觉中,设计基于辛矩阵的分类器并将其应用在人脸识别等模式识别的过程中.定义在域F上的辛群通常具有形式Sp(2n,F),它由2n×2n的辛矩阵在矩阵乘法下构成,其中矩阵元素属于F,矩阵乘法代表群操作.辛矩阵是一个2n×2n的矩阵犕,满足犕TΩ犕=Ω,犕T表示犕矩阵的转置,Ω是一个固定的2n×2n的非奇异、斜对称矩阵.在文献[25-26]涉及的实际应用中,总是令限定域F为实数域R.由于每个辛矩阵的行列式值为1,因此实数范围内的辛矩阵在矩阵乘法下构成了特殊线性群SL(2n,R)的一个子群,也就是实李群的一种特定形式.在辛群分类器中最关键的步骤是保证将输入数据用辛矩阵的形式表示出来.有了辛群表示以后,接下来则可以在辛矩阵的基础上提取相应的特征,以便于进行后续的模式匹配.Page9辛群分类器的特征提取过程可以看做寻找辛表示的过程.辛表示可以以群表示的形式存在,也可以是以辛向量空间(V,ω)上的李代数形式存在,其中ω表示辛向量空间所保持的辛形式ω:V×V→F.在文献[25-26]中,作者采用奇异值分解的方式求取k个最大的奇异值所对应的列向量,以此构建辛空间下原始输入图像的一组基.这样任一训练图像都可以以基的线性加和的形式重构.可以证明,这些基实际上构成了关于辛矩阵的坐标系,称作辛特征子空间.测试图像依据自身到辛特征子空间的投影长度衡量与各个类别图像的相似度,投影长度以辛矩阵内积的方式计算出.存在定理表明两个辛矩阵的乘积仍然是一个辛矩阵,所以整个辛矩阵的集合自然具备群结构.类似于线性变换的概念,辛向量空间中的辛矩阵被称作一个辛变换.由此辛群可以被定义成域F上2n维向量空间中线性变换的集合,并且要求该变换能够保持非退化(nondegenerate)、斜对称(skew-symmetric)和双线性(bilinear)的形式.文献中作者指出辛变换能够帮助对辛矩阵进行化简,并且给出几个常见的辛矩阵的化简形式,特定的化简形式可以做为一类辛群分类器的识别准则.即如果经保形变换得到的输入图像辛矩阵与特定辛矩阵的形式相符合,则可以判定两者的类别一致.利用辛矩阵分解方法的优势是能够直接对原始图像进行运算而不需要事先将图像拉成向量的形式,这就保证了局部位置信息不会丢失.4.8李群机器学习的纤维丛学习算法人们经常希望能够了解样本的统计特性,以此估计一些可能需要的信息.比如通过计算每种类别样本的均值,可以帮助预测新样本的分类信息.因此,如何在李群空间中计算统计量是个迫切需要解决的问题.针对李群的流形统计问题,国内外已有许多学者设计了相应的算法.文献[27-28]采用基于迭代的方法计算李群的均值.依据计算出的均值点是否存在于李群流形上,文献[29]指出李群流形的内均值与外均值的区别.文献[30-31]从微分几何的角度,给出了几种矩阵李群的均值计算方法.此外,文献[32]分析了李群上的高斯分布问题并将其应用在形状统计中.然而,以上这些研究成果仅仅是出于对统计量的考量.有时候仅从单一的统计量中不能获得足够的数据分析信息.因此,还需要设计相应的算法刻画整个数据的分布情况.为了寻找反映数据真实分布的骨架,文献[33]提出了一种主曲线构建算法.该算法的主要思想是将流形数据集分割成一个个的球形邻域,通过邻域切空间的主成分来拟合出一条通过数据分布的光滑曲线.作为利用切空间近似描述几何性质的一种扩展,文献[34-35]将各邻域上的切空间构成切丛,并加入多流形之间联络的概念,给出了主曲线构建算法的一个改进的版本.新算法在逼近方式、收敛条件、参数控制等方面都有显著的不同,并且在抗噪性方面具有明显的优势.下面简要介绍一下这个基于切丛联络的主曲线构建算法.纤维丛在拓扑学中被定义成一个空间,它由四元组(E,B,π,F)构成.其中E,B,F分别代表整个结构的总空间、基空间以及纤维空间,π定义从E到B上一个连续的满射,使得E的每个局部空间存在F令E与B×F同胚.从结构上纤维丛的局部是一个直积空间B×F,而在全局上一般具有一个不同的拓扑空间E.它的一个特殊类被称作向量丛,在当纤维空间为向量空间时成立.在微分几何中,最重要的一类向量丛即是定义在微分流形上的切丛,它由流形M上各点处切空间不相交的并集组成.在许多流形学习的方法中,都会从不同程度运用切空间研究流形的局部结构.从该点出发,文献[34-35]利用切丛分析具有流形结构的数据,切丛的运用不仅能给出流形的局部描述同时也能为研究流形局部与全局的结构关系提供方法.在利用切空间描述局部信息的同时,文献[34-35]中作者选择主曲线(principalcurve)作为描述流形数据整体分布的工具.类似于主成分(principalcomponent)的概念,主曲线是一条描绘流形结构的光滑曲线.通过局部切空间不断逼近的方式,主曲线希望找到真实反映流形数据的分布信息.借助切丛联络构建主曲线的方法是对切空间主曲线构建算法的一个推广.联络从几何的角度指的是数据点所在的空间以平行或者一致性的方式沿着某条曲线或一组曲线进行的转换.联络使得不同局部空间中的元素能够相互联系与比较,也可以成为构建主曲线的参考标准.算法6.基于切丛联络的主曲线构建算法(TangentBundleConnectionBasedPrincipalCurveConstructionAlgorithm,TBCPCC).输入:整个数据集Q0(λ1,δ1)输出:估计的函数主曲线1.初始化k=1.2.如果输入数据集内样本个数小于某个阈值C,则程序结束.Page103.使用两个球形邻域Qk(λ1,δ1),Qk(λ2,δ2)覆盖样本数据,k表示第k层递归.4.对每一个邻域Qk(λi,δi),i=1,2内数据点xi1,xi2,…,xin进行主成分分析,得到主特征向量ξkij=(ξi1,ξi2,…,ξij).5.令ξkl=minξQ(k-1)(λl,δl)内数据点协方差矩阵的主特征向量,并且Qk(λi,δi)包含于Qk(λl,δl),计算Qk(λi,δi),i=1,2,…,k内数据点xki在ξki上的投影及局部重构向量狓^ik,{x^ik},i=1,2是流形局部截面.6.计算{x^ik}的联络D;如果D小于某一阈值β,连接x^ik,应用样条函数或局部光滑化方法近似光滑的主曲线,程序结束.7.否则对于第1个球形邻域,调用本算法,进入第k+1层递归;对于第2个球形邻域,调用本算法,进入第k+1层递归.从算法的设计思路上看,切丛联络与切空间的主曲线构建算法中都试图通过流形多个局部空间的主成分逐渐逼近整体分布的主曲线,并且选用球邻域覆盖的方式辅助局部特征的选取.切空间的主曲线构建算法采用增加球邻域开覆盖数量的方式来逼近最优的主曲线,通过不断细化流形结构能够拟合出一条反映数据分布的主轴.切丛联络的主曲线构建算法则采用一种递归的方式,通过逐渐缩小球邻域覆盖的形式逐一逼近局部切空间.联络作为帮助判断收敛的条件,当相邻局部空间的联络小于一定的范围时可以认为两个球邻域在用于生成主曲线时已经足够紧密.4.9标架丛上的联络学习算法存在一种特殊的纤维丛,其上的满射定义为π:P→X,并且同时存在一个拓扑群G作为该纤维丛的结构群,使得G对总空间P产生连续的右作用,即有P×G→P.这样的纤维丛与结构群一起构成了一个主G丛(principalG-bundle).如果有另一个纤维空间同为结构群G作用的拓扑空间,那么主G丛允许产生一个相伴的配丛,将原纤维空间变换到该纤维空间.当这样的配丛可以是任意一个向量丛时,称主G丛为标架丛.如果将主G丛限定在光滑流形范围内,则π:P→X为一个光滑映射且结构群G为李群.此范畴内标架丛的配丛是定义在光滑流形上的切丛.在基于切丛的流形学习方法中,通常需要构造一个统一的坐标架,将对数据的操作都映射在该坐标架中处理.如果限定对数据的操作到李群G的群作用上,那么便可由结构群(李群G)引出光滑流形上标架丛的概念.标架丛在李群G的作用下能够使P的纤维结构得到保持,即P的纤维上的元素y∈Px,对于所有的g∈G有yg∈Px.然而一个仍需解决的问题是在现实的情况中数据常常体现出多流形的结构,这种多流形不仅体现在数据本身结构的复杂性方面而且体现在大量具有流形结构的异常噪声方面.复杂的多流形结构使得构造统一坐标架的方法变得无效,但如果用与标架丛相伴的切丛表示李群G作用下的其他拓扑空间,可以考虑用整个标架丛将多个切丛联系起来,刻画统一的多流形数据结构.在标架丛中,每个与主G丛相伴的配丛能够自然地构造出对应的坐标架,如果需要联系多个切丛中的流形结构,需要利用切丛上线性联络的概念,它是将近邻数据点连接的一种线性映射,也可以理解为从流形上一点的切空间沿着某条路径平行移动到另一点的切空间中.因此标架丛形成了一个联系各个切丛坐标架的坐标覆盖.借助于标架丛的运用,文献[36-37]针对大数据的多流形结构问题,结合标架丛上的纵空间和横空间联络算子,给出了基于标架丛的纵空间联络、横空间联络学习算法.在纵空间联络学习算法中作者用纵空间场的全局坐标对多流形结构数据进行分类,由于构造多个切空间的坐标架与相应联络算子,算法在性能方面需要付出相应的时间复杂度作为代价.横空间联络学习算法在纵空间算法基础上,对于每个切空间进行一定的维数约简后重新构造坐标场,较纵空间算法而言在一定程度上降低了学习算法的时间复杂度.4.10谱估计学习算法在计算流形数据的统计特性时,不可避免地涉及到的一个问题就是对数据的降维.当数据所在的空间变成李群空间时,一些基于欧氏空间的降维算法将无法适用.针对这样的问题,一些文献继承了原有算法的思想并将其扩展到非线性的流形空间中.例如文献[27-28]是对已被研究得比较深入的主成分分析(PrincipalComponentAnalysis,PCA)方法进行改造,给出了适用于非线性黎曼对称空间的主测地线分析(PrincipalGeodesicAnalysis,PGA)方法,成功地将其运用于李群表示的医学解剖对象的统计分析中.算法的主要思想是将李群样本先映射到对应的李代数空间中,然后在线性空间中进行主成分分析.除此之外,由于高维流形空间中的数据往往存在反映内在属性的几何结构特征,因此还有许多降维算法设计的出发点是希望尽可能地用较少的参数描绘数据这类更加本质的特征.例如现有的许多流形学习的算法如等距映射(IsometricFeatureMapping,Isomap)、局部线性嵌入(LocalLinearPage11Embedding,LLE)、局部切空间排列(LocalTangentSpaceAlignment,LTSA)等,数据约减时的原则是尽量保持流形结构的几何特性,其良好的效果为基于李群的维数约简问题找到了另一种解决途径.然而针对不同的样本分布,这些算法也表现出了一定的局限性.例如,Isomap不适用于曲率变化较大的流形、LLE对噪声十分敏感、LTSA不能有效地处理较大的样本集等.因此接下来简单介绍针对高维空间中李群数据的维数约简问题衍生出的一系列算法.谱理论是在更宽泛的数学空间下,对单一方阵下的特征向量与特征值理论的推广.现阶段赋予计算机应用的李群多为矩阵群.在有限矩阵的范围下,谱可以理解为其特征值的多重集.在应用数学与科学计算中,谱方法是对确定的微分方程进行数值求解的一类技术,它能够被用来解决常微分方程、偏微分方程以及微分方程中所包含的特征值问题.谱方法的思想是将微分方程的解写成基函数线性加和的形式并且选择合适的系数来满足原微分方程.在利用谱方法解决常微分方程的特征值问题中,能够转换成类似于求解矩阵特征值问题的方式求解.流形数据的维数约减涉及从一个拓扑空间连续变换到另一个拓扑空间的动作,而这样连续变换的动作在拓扑学中称为同伦.在代数拓扑中,谱能够反映特定空间中同伦下的不变量.然而,对于多数流形来说精确的谱计算是十分困难的,于是相应的,谱估计计算方法成为目前一种有效的替代方式.文献[38]利用邻接图或拉普拉斯矩阵等图相关矩阵研究图性质,引入谱理论学习图相关的特征多项式、特征值与特征向量描绘计算机视觉中特征流形的拓扑不变量,为高维流形数据的降维提供了途径.无向图具有一个对称的邻接矩阵因而具有实值的特征值以及完整且正交的特征向量,这些特征值的多重集构成了无向图的谱.文献中作者基于谱图理论设计了一种无监督的谱估计学习算法,有效地保持了图的抽象结构与流形的几何特性.谱估计方法的核心是通过寻找合适的谱并将其对应的特征向量作为数据空间的投影向量,以此找到保留图不变量的低维嵌入流形空间.谱的计算需要建立在数据集的邻接矩阵基础上,并且依据邻接矩阵描述的数据相似性关系定义准则函数,最优的解对应最佳的预测或识别结果.在谱估计算法中多重集的选取往往依赖于一定的经验且可以从其他流形学习算法中分析总结.文献[39]基于局部线性嵌入算法选取拉普拉斯算子的两个极大特征值作为流形的谱,该特征选取的方式在降维与分类应用中得到了验证.算法7.图像特征流形拓扑不变性的谱估计学习算法(SpectrumEstimationLearningAlgorithm,SEL).输入:原始数据集X={xi}输出:输出重构数据集X={xi}1.判断数据集是否满足连续映射、局部同胚映射、拓扑空间、连通性这4个假设条件.在满足的情况下,如果图像特征流形的局部维数未知,则通过极大似然估计算法计算出流形的局部维数d.2.对数据样本集运行LLE算法,并且返回第2特征向量{犢n},其中n是所需的特征向量数目.3.寻找每个特征向量犢i的局部极值:对每一个数据点,通过关系矩阵犈求得其相应的邻域{xej}.如果对xej∈{xej},都满足犢k(xi)Yk(xej)(或犢k(xi)犢k(xej)),则xi是局部极大值(或局部极小值).其中,局部极值的数目表示特征向量的分析度.4.计算局部极大极小曲线:初始化,令{xi}={xi};如果犢k(xi)×犢k(xej)0,则依次将其邻接点xej加入到集合{xi}中.对所有{xi}中的点,重复步骤4,直至没有新的点再加入集合.每一个{xi}都是与流形非线性结构一一对应的曲线.尽管邻接矩阵依赖于顶点的标记,然而邻接矩阵的谱是图的同构不变量.算法中局部极值曲线能够依照不同邻域尺度的特征向量形成不同曲率的曲线,对应流形不同局部的非线性特征.谱估计学习算法一方面利用类似于PCA中主成分的概念,从描述数据相似性的关系矩阵中寻找合适的特征向量构成谱,使得计算过程相对快速;另一方面,不同尺度特征向量构成的曲线对应不同曲率的结构,算法中局部曲线的应用可以有效地保持流形内部的非线性结构特征.4.11张量学习算法在数学里,张量是一种几何实体,或者说广义上的“数量”.张量概念包括标量、向量和线性算子.张量是一个可用来表示在一些向量、标量和其他张量之间的线性关系的多线性函数,这些线性关系的基本例子有内积、外积、线性映射以及笛卡儿积.当在描述高维数据时,通常将数据分量用多维数组来表示,进而构成张量并通过张量分解等工具对数据进行有效地降维.文献[40-41]利用张量的特点,结合张量的分解技术和张量场理论工具,提出了基于张量场的数据约简算法,建立张量场学习模型并给出在人脸识别应用中的张量丛学习算法.首先给出张量场的数据约简模型〈X,ψ,Φ,f,Φ〉.X={X1,…,XN}表示输入数据集;Φ表示由输Page12入数据集生成的张量场;f为张量场仿射变换函数;Φ为张量场Φ的约简形式;由ψ可以从数据集Χ抽象出张量场Φ,即ψ:X→Φ.X是需要处理的原始数据对象.这里ψ表示由原始数据抽象出张量场模型的方法,通过ψ得到原始数据的张量场表达形式.而Φ是Φ经过约简处理后的张量场,约简处理的过程通过张量场仿射变换函数f完成.数据约简的方法就是找到一个合适的仿射变换f,求得在f作用下的一个低维空间下的张量场的分量表达形式.这里仿射变换f的求解将借助高阶奇异值分解技术(High-OrderSingularValueDecomposition,HOSVD).HOSVD是一种比较常用的张量分解方法,它使得一个张量可以表达成若干矩阵与核张量的张量积形式.在求解过程采用迭代方法,使得问题在迭代的方式下求得最优值.因为整个算法考虑的张量数据不是单个张量,而且张量阶数不局限于2阶、3阶,这使得整个算法相对于HOOI(High-OrderOrthogonalIteration)等常见的张量算法更具普遍性.4.12李群核学习算法恒定感知在一定程度上依赖于个体检测不变性的能力,因此视觉感知中的重要问题之一就是视觉不变性,它是指物体在经历平移、旋转或缩放等变换后依然被认为是相同的.李群具有自然地表示变换的优势,因而在相当长的一段时间里,李群的连续变换群理论被用于解决视觉空间感知中的不变性问题[42-49].2007年,Xu等人[50]以一种非监督的方式设计了一个基于李群理论的视觉不变量学习方法.文中作者为图像中的物体进行李群仿射运动建模,并用李群对应的李代数生成元对其进行参数化,求解的过程被转化成了通过EM算法对生成元进行迭代估计.这个结果说明了可以从包含变换的图像对中直接学习李变换群的生成元,并且一旦这样的生成元被学习到了,它还能够被运用在图像变换的估计中.文章提出的方法在处理相对较小的变换时具有很大的优势,但是在处理大的变换时需要考虑如何在提出的指数生成模型上找到全局最优值.不同于文献[50]保留全部变换信息的方法,文献[10]设计了一种区域协方差李群特征,将多种可能相关的特征进行融合.虽然这损失了部分变换信息,但在实际运用中取得了良好的效果.上面提到的检测不变性变换的研究方法中,研究者们更倾向于利用李代数向量空间的性质,采用线性的识别算法判别样本.然而针对这种问题需要被处理的数据集是线性可分的.由此对于非线性可分的李群变换样本,必须考虑寻找另一种有效的方式对其进行处理.文献[51-52]将区域协方差的不变特征运用在手写体字符识别中.借鉴核方法的思想,作者将线性不可分的数据集映射到高维特征空间中,运用原空间中的约束函数来实现内积运算,从而使数据集在高维的目标空间中能够线性可分.由于矩阵没有内积运算,对于矩阵李群的样本集不能运用基于向量的核函数,文献[52]还推导了多种适用于李群空间的核函数,包括李群径向基核、李群多项式核、李群线性核、李群感知器核,并在此基础上给出了李群核学习算法.核方法[53]是模式识别中处理这类问题的一种方法,最著名的例子是在支持向量机(SupportVectorMachine,SVM)[54-55]中的应用,它采用与其他数据点间的相似性来替代明确计算数据点特征向量的方式.核方法的命名主要来自于核方法中所用到的核函数,它仅仅计算数据点对在特征空间中的内积从而将样本集映射到一个高维的、隐含的特征空间中.这样做的好处是样本集在映射到更高维空间以后,使得原先线性不可分的性质往往能够变得线性可分,并且内积的计算量常常小于直接计算特征坐标的计算量.已有相当多的方法与核方法结合起来用来弥补线性分类的局限性,如KPCA(KernelPrincipalComponentAnalysis)[54]、KICA(KernelIndependentComponentAnalysis)[56]以及KFDA(KernelFisherDiscriminantAnalysis)[57]等.依据类似的思想,当线性判别分析(LinearDiscriminantAnalysis,LDA)算法遇到线性不可分样本集时,自然的想法是借用核函数将原始空间映射到高维隐含特征空间中,以此将原有的非线性问题转换为线性可分的目标问题.由于矩阵李群样本在群作用后结果值仍属于矩阵范畴,于是文献[51]中作者选用推导出的若干适用于李群结构的核函数,设计出李群核函数的KLieDA算法,对非线性矩阵李群样本进行分类.多类问题的推导思路类似于Lie-Fisher算法,这里仅给出二分类的KLieDA算法.算法8.两分类的李群核KLieDA分类算法(KernelLieGroupDiscriminantAnalysis,KLieDA).输入:{Mij}j=1,…,n输出:每个未知样本的类别归属1.对每一个李群样本xij,求出两类李群样本的均值μ1和μ2,Vμ=expPage132.选择具体李群核函数,求得两类李群样本的Mi=nik(xj,xi1ni∑k=13.计算N=∑i=1,2阵,且(犓i)nm=k(xn,xi4.计算α:α=N-1(M1-M2).5.计算两类均值μ1和μ1到空间6.对未知样本x,先将其投影到空间(狏·Φ(x))=∑得到其类别归属.算法8相比传统KFDA算法,在保持了相同的时空复杂度下有两点创新:(1)使用矩阵李群核函数,能处理矩阵样本;(2)算法的步1和步6中先计算原样本的均值以及均值在知样本映射至距离,计算量较小.KLieDA算法和Lie-Fisher算法都能对非线性矩阵李群样本进行分类.从分类过程来看,KLieDA是通过将非线性可分样本映射到高维空间,使之线性可分,在分类期间采用李群均值加速完成未知样本的类别判别,整个分类过程并不在样本所在的李群流形空间中完成.而Lie-Fisher是利用李群均值以及样本到测地线投影的方法在样本所在流形空间中寻找到一条分类测地线完成样本分类,原始样本的分布特点直接决定学习到的测地线的分类性能.从计算开销来看,KLieDA由于需要计算核矩阵,而核矩阵的计算时间复杂度是O(n2),比Lie-Fisher计算两个散度矩阵的O(n)明显要大,空间复杂度也因为核矩阵的原因达到O(n2),Lie-Fisher只需O(n).因此,对于大样本集的分类问题,KLieDA算法将会明显比Lie-Fisher慢.从算法应用角度来看,Lie-Fisher是学习到一条固定的测地线进行分类,而KLieDA则可根据不同的样本集分布特点选择不同的李群核函数,使算法达到更好的分类结果,因此KLieDA算法比Lie-Fisher算法在应用上更具灵活性.在李群核学习算法中,依据样本集不同的分布情况而选用不同的李群核函数可能使算法得到不同的效果,因而时常需要变换核函数以适应于不同的情形.手写体图像的区域协方差特征虽然分布于流形空间中,但是具有非常好的线性分布特性[51].因此,即使采用线性核或者低阶多项式核也能够达到良好的分类效果.由于核矩阵需要的时间复杂度是O(n2),所以算法相对的计算开销比较大.算法3提出的Lie-Fisher算法将样本向某条分类测地线投影,是一种近似线性的方法.在数据集规模很大的情况下,今后可以尝试将协方差矩阵特征与Lie-Fisher这类计算开销小、近似线性的方法结合起来.4.13李群子空间轨道生成学习算法不论在二维还是三维空间,李代数能够为变换做一个自然的参数化表示.因此许多文献采用李代数进行参数化建模,将李群运用在模版跟踪中[58-60].李代数的主要作用是在保持与几何变换群联系的同时,构建在向量空间的等价表示.并且利用李代数的好处是在不改变物体形状的前提下,允许物体沿着测地线移动.文献[61]采用李群和李代数的形式,对动态视觉现象进行建模,提出了运动的概率建模方法.文献[62-63]用基于协方差的目标描述以及基于李代数的更新机制来对非刚性物体进行跟踪.刚体运动估计是指给定两组对应的三维点,发现从一组点变换到另一组点的旋转和平移量.如果这两组对应点中存在多个刚体运动,那么这就变成了一个更加困难的多运动估计问题.文献[64]从含有噪声的三维点对中估计具有李群结构的多个刚体运动.文献[65]通过李算子迭代搜索算法,对小幅度的物体运动进行参数估计.针对跟踪或检索引发的搜索问题,除了利用李代数参数化的迭代更新方法之外,还可以利用学习空间的某些特殊结构来完成.文献[66-67]引入学习子空间中轨道的概念,给出了李群机器学习轨道生成的广度优先以及深度优先算法.轨道是群作用下的产生物,假设有一个作用在集合X上的群G,集合元素x∈X的轨道是由这样一些元素构成的集合,这些元素由群元素g∈G作用在x上获得.用符号的形式表示x的轨道为Gx={gx|g∈G}.轨道的作用是在群G的作用下形成对集合X的有效划分,它能够很自然地定义一种等价关系:集合中的元素x和y是等价的当且仅当存在群元素g∈G使得gx=y.于是轨道在这样的等价关系下能够形成相应的等价类.将轨道运用在模式识别的应用中主要是依据定理:如果元素x与y等价当且仅当它们的轨道是相同的.如果从几何的角度来看,轨道可以看做包括当前状态集合以及操作算子的一个轨道子空间,所有的轨道构成了整个学习空间.在实现的时候,文章采用Dynkin图[68]来表示整个学习子空间,每一个中间状态看作是一个图结点,结点之间的连接值对应着状态转移的代价.如果能从初始状态出发,并在到达Page14目标状态的所有路径中找到一条正确划分样本标签的最优路径,那么就达到了学习算法的目的.与传统的搜索算法相比,该方法是基于李群几何结构设计的学习算法,十分适用于结构特性显著的数据集.下面简单地介绍一下李群子空间轨道生成学习算法.在矩阵李群的作用下,文献[66-67,69]基于状态结点构成的有向图建立轨道空间.在连通的前提下,有向图中的每条弧对应于一个操作算子,操作算子的相互结合能够完成任意结点之间的相互转换.因此轨道学习算法下的分类任务实质上可以看成寻找在矩阵李群作用下从初始状态结点到目标状态结点的一条轨道,如果这样的轨道存在则说明两个状态结点在某种意义下是等价的.除了为寻找到这样的目标轨道之外,还需要设计一定的算法保证寻找到的这条轨道尽可能是学习空间中的最优轨道.基于这样的思想,文献[67]提出了用于生成目标轨道的轨道生成算法.对于该学习算法,作者选用树结构作为一种特殊的形式并首先考虑两种搜索策略:广度优先和深度优先.广度优先策略要求在进入下一层之前必须扩展完本层的所有状态,因此需要足够大的存储空间,但是能够确保找到从初始状态到目标状态的最短路径;深度优先策略则要求生成结点时孩子结点先于兄弟结点,是一种局部生成的方式,学习效率相对较高,但是不一定能够找到全局最优解.下面简单列出文中轨道生成算法中的广度优先策略.算法9.轨道生成广度优先算法(OrbitBreadthFirst,OBF).输入:m=(m1,…,ml):支配权向量(所有mi>0),犇:输出:权向量列表ω=(ω1,…,ωl)和3个相关整数,第输入m;//初始状态,即未经过学习的原始样例将m插入current-level列表的表头;//权值结点链表令level=0,levelcount[level]=1;//用于每一层计数的整数数组令from=1;//父权值的位置令to=1;//新权值的位置,也是被计算权值当前的总数WHILE(levelcount[level]>0ANDlevel<maxlevel){level++;设from=to;//对current-level列表中权值往下计数FOR(current-level列表中的每一个权值ω){FOR(i=1TOl)IF(ωi>0)}//current-level存储当前计算的权值释放前面的列表current-level;令current-level=next-level;//next-level存储由current-level生成的新权值令next-level=null;//权值计算完毕,释放列表}除此之外,由于广度优先和深度优先策略都具有一定的盲目性,作者考虑在学习一条目标轨道的时候,加入一些启发式信息,也进一步研究了李群机器学习子空间轨道启发式学习算法.4.14李群机器学习的量子群学习算法机械系统的构形空间通常是一个李子群.例如,文献[70-71]用于解决机械系统的自动控制问题,文献[72-74]研究导向汽车移动的运动规划.此外,李群和李代数的优良性质能够被很好地用于非线性控制中[75-78].在机械系统自动控制的文献中,有相当一部分文献将原始问题转化成一个优化问题,李群在这些问题上得到了很好的应用[79-83].由于矩阵李群还可以细分出许多各具特色的群,因此在机械系统构形空间是某种特殊矩阵群时,可以参照各个群的学习算法,比如辛群学习算法[25-26]、量子群学习算法[84-86]以及更一般的张量学习算法[40-41]等.量子群是对经典李群、李代数中基本对称概念的推广,研究的是一类特殊的非交换非余交换的Hopf代数,尤其是从李代数的包络代数和群的函数代数经过“量子化”得到的非交换非余交换的Hopf代数.近年来,量子群及其相关的q变形理论已被应用于物理学的各个分支.文献[84-85]给出了量子群分类器的构造方法,并将其应用在DNA的序列分类中.文献[84,86]基于量子群的基本理论,结合药物分子设计中的分子对接问题,给出了一个基于量子群生成元的分子对接药物设计新方法.作者首先给出了分子对接的数学模型实际上就是最小化相互作用系统结合自由能的一个优化设计问题.其次,进一步分析了分子对接的量子群模型.这个模型利用生成元的形式表示量子群并利用基于量子群生成元的分子匹配算法对量子群的分子对接进行模拟.4.15基于范畴理论的学习算法范畴是描述数学实体及其之间关系的抽象概念.范畴的概念中包括一类物件ob(Page15物件之间的态射hom(范畴对应不同种类的物件及其相互关系,这类物件可以代表任何一种数学结构(如集合),而态射依照物件的不同需做对应的改变.每一个态射f关联物件ob(是从a到b的一个态射,写作f:a→b.这和集合上定义的函数很像,实际上由集合作为物件,函数作为态射正是一种类型的范畴.a到b上态射的全体称作一个态射类,记作hom物件a,b,c,定义三者之上的二元运算hom(b,c)→homhom算.更具体的,针对a,b上的态射f:a→b以及b,c上的态射g:b→c,对应的态射复合为gf:a→c.在集合范畴,态射复合即为函数复合.综上所述,不同的物件、态射与态射复合形成了不同的范畴.例如所有集合构成的范畴,对应的态射就是定义在集合之间的函数;所有群构成的范畴,其态射是群之间的群同态;所有拓扑空间构成的范畴,态射又是拓扑空间上的连续函数,等等.文献[87]希望用范畴来表示机器学习过程中的学习表达式,例如以决策树为研究对象的决策树范畴或者在概率统计范围下的贝叶斯范畴.文中作者不仅详细地规定了学习表达式完整的范畴定义,而且用实例证明了将机器学习过程中的学习表达式表示成范畴形式是可行的.对于每一类学习表达式范畴,文献中都设计了相应的态射类与态射复合并且使得学习表达式范畴满足态射复合的两个公理:结合律公理与单位元公理.结合律公理是指若存在物件类ob(物件a,b,c,d和态射f:a→b,g:b→c及h:c→d,则有h(gf)=(hg)f成立.单位元公理是指对物件类ob(射1x:x→x使得范畴满足1bf=f=f1a.作为扩展,文献中作者还研究了态射的一些基本类型,包括满态射、单态射以及双态射等.除了在学习表达式范畴内研究物件与态射的表示之外,文献[87]还试图将每一类学习表达式范畴看作是一类物件,研究学习表达式范畴与学习表达式范畴之间的态射,这种范畴之间的态射称为函子.函子是将范畴进一步抽象后得到的概念.因为范畴本身又可以被看作另一种数学结构,所以能够进一步定义两类范畴之间的态射关系,即函子.在学习表达式范畴之上定义函子相对定义普通态射而言是困难的,这是因为建立两种范畴之间的函子不仅需要关联一个范畴中的物件和另一个范畴中的物件,而且需要将一个范畴中的态射同另一个范畴中的态射联系起来.选择范畴理论来研究学习表达式的一个好处是范畴的普遍公理能够给出各种数学结构中共性的统一概述,这样的公理能够帮助将这些共同特性推广到学习表达式中.例如在基于矩阵李群的机器学习过程中,如果将学习表达式规范到矩阵李群范畴下,那么可以由范畴的单位元公理自然地推出矩阵李群的单位元是唯一存在的.范畴理论另外一个显著特点是范畴往往更着重关注物件之间的态射而非物件本身.而更加透彻的态射研究又常常能够获取更多的物件结构.就好比研究群同态能够帮助研究更多的群特性.这是因为群同态专注于将一个群在保持群结构的基础上变换到另一个群的过程,由变换相联系之后那么原先群上的信息能够传递到另一个群之上.最后,当将范畴概念抽象化到函子的层次上时,这时研究的态射关系不仅仅停留在同一数学结构之中,而是注重探索不同物件种类之间的关联关系.这样的优势在代数拓扑中体现得尤为明显,这也是为什么能够将几何拓扑的问题转换成用代数方法求解的原因之一.学习表达式之间态射的一个有效应用是将图像数据高维空间对象表示映射到低维空间对象表示中,由此在低维表示中获得原先高维空间中数据的结构信息.于是文献[88-89]依据态射是线性或是非线性的情况给出两种范畴表示的数据降维算法.算法10.基于范畴的线性降维算法(CategoryBasedLinearDimensionalityReductionAlgorithm,CLDR).输入:原始高维数据对象X输出:低维坐标数据对象Y1.构造关联对象M.态射g为构造关联对象的过程,g:X→M.其中关联对象M和态射g需要根据高维数据对象X和已知关系对象Δ确定,不同的关系对象Δ对应不同的关联对象M,得到最终输出的低维坐标数据对象Y的表示意义不同.2.计算关联对象M的特征值对象Ζ和特征向量对象Wh:M→Z,φ:Z→W,根据数据降维范畴的复合运算律(compositionlaw)可得φh:M→W.3.分析数据降维范畴低维坐标数据对象Y.其中需要自定义算子“·”来确定中间过渡对象T,使得:T→Y.算法11.基于范畴的非线性降维算法(CategoryBasedNonlinearDimensionalityReductionAlgorithm,CNDR).输入:原始高维数据对象X输出:低维嵌入数据对象YPage161.确定原始高位数据对象X中各元素的邻域点,构造邻域对象G.态射l为计算各元素邻域点,构造邻域对象的过程,l:X→G.2.构造矩阵对象H.邻域对象G中包含原始高维数据对象X中各元素及其属性和关系(例如距离或权值等),利用邻域对象G中已知元素,寻找合适的态射p映射得到矩阵对象H,p:G→H.其中矩阵对象H的意义与所选邻域对象G中元素的属性有关.3.根据所得矩阵对象H分析计算低维嵌入数据对象Y.利用态射ψ完成从H到Y的映射,即ψ:H→Y.其中态射ψ的形式及其方法取决于矩阵对象H的意义,不同的ψ的过程,需要构造不同的对象和态射.5李群机器学习展望从目前国内外研究的初步成果来看,李群机器学习已被广泛运用于人工智能领域并已逐步表现出了自己鲜明的特点.首先,李群在处理尺度变换、平移变换、旋转变换等部分拓扑变换时具备的显著优势,使得李群成为研究不变性的一个有力的工具.由于人类视觉系统具有一定的变换不变性,且对外部世界的感知极大地依赖于对图像的理解,因此可以将李群理论运用在视觉认知领域中用于研究图像的不变性特征.其次,从计算的角度来看,李群与李代数之间的转换关系能够便捷地改造基于向量空间的传统机器学习算法,这为李群机器学习处理各样纷繁复杂的问题提供了保证.此外,根据已有的进展与现行的发展趋势,接下来给出李群机器学习的一些前进方向供读者参考.5.1李群深度学习由于在现实生活中人们越来越经常地面临着大数据,这为数据的表示、提取以及运算都带来了挑战.近年来,由表示学习引发的深度学习正逐步兴起,并由此激发了对李群机器学习的进一步思考.目前,已有越来越多的算法致力于研究数据的流形表示问题[90].在这其中,文献[91]利用深度学习模型CAE(ContractiveAuto-Encoders)训练图像,并将得到的表示关于输入分量的雅克比矩阵进行奇异值分解,以此提取流形局部的切方向.文中指出流形上某点处的切空间能够捕获数据集局部的有效变换,包括微小的平移与旋转,样本的类别属性应当不受这些变换的影响.基于这样的思想,作者设计了一种流形切空间分类器MTC(ManifoldTangentClassifier).在实验部分,作者将MTC应用于手写体数字识别中.在不使用任何先验领域知识的前提下,分类性能在MNIST数据集上取得了目前为止最好的结果.受到MTC模型的启发,我们可以考虑构建李群深度学习模型.首先,现有的李群机器学习中已经给出一些对流形切空间的研究:文献[34-35]将流形上各点切空间构成切丛,进一步分析和处理流形结构;文献[36-37]针对大数据的多流形结构,设计出标架丛上的联络学习算法.利用这些数学结构可以对模型化的切空间进行推广.其次,针对计算机视觉中数据的复杂性和图像结构的不变性,文献[21-22]考虑利用一种可堆叠的深层结构将人脸图像中的各个部位综合起来表示,并嵌入李群半监督学习[14-15],给出逐层学习的人脸识别算法.为此可以将这种逐层学习的思想与现有的深度学习模型结合起来,并且对于如何利用模型构造具有李群结构的变换也是一个值得探索的问题.5.2李群范畴学习范畴为计算机科学的许多方面提供了形式表示,如程序语言理论、自动机理论、计算理论等,有效地概括了特定对象以及对象之间的映射关系.文献[87-88]利用范畴理论来研究学习系统的表示问题,为机器学习系统的范畴表示给出了证明.在此基础上,考虑将范畴理论运用到李群机器学习中,阐述李群机器学习算法中高维数据与低维表示之间的态射关系以及学习表达式的映射机制,从而构建起统一的范畴表示框架.5.3李群统计学习目前,关于流形统计的研究已日趋成熟.由李群机器学习中引发的流形统计问题使人们思考是否可进一步探索两者之间的内在关系.非线性问题可以用多参数的李群结构表示,而借助李代数又可以得到对应的单参数子群.在李代数向量空间的线性结构之上,能够计算出均值、高斯分布等统计信息.因此,有了这些统计特性我们可以尝试结合李群理论研究李群流形上的统计学习问题.当然,对于李群机器学习未来的研究方向还有很多,这里仅列出一些供读者们参考.
