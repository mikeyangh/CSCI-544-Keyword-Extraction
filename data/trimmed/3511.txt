Page1基于在线百科全书的群体兴趣及其关联性挖掘张海粟1),2)陈桂生3)马于涛3),4)刘玉超3)1)(中国人民解放军理工大学指挥自动化学院南京210007)2)(中国人民解放军国防信息学院武汉430010)3)(中国电子系统工程研究所北京100141)4)(武汉大学软件工程国家重点实验室武汉430072)摘要针对协同过滤、基于内容过滤等个性化推荐方法所存在的用户隐私数据收集、冷启动等问题,提出一种群体兴趣及其关联性的挖掘方法,并应用于推荐领域.以维基百科作为数据源,获取用户社团及其编辑的词条,设计了以词条及其所属类别为基础的泛树结构生长策略,使用泛树结构表征用户社团所对应的兴趣点.结合用户社团的结构特征和兴趣点的语义特征给出了用户社团对兴趣点的关注度及兴趣点间关联性的定义,用此群体兴趣取代个性化推荐方法中的个体兴趣,进行了人工直观评价、测试集对比以及视频点播中的新闻推荐等三种实验.结果表明,测试集上群体兴趣关联性的准确度达到了50%,高于基准协同推荐方法的准确度;新闻推荐实验中,本方法比按热度推荐方法获得了高出近一倍的点击率,验证了群体兴趣及其关联性的合理性.关键词群体兴趣;兴趣点泛树结构;协同推荐;维基百科;社会网挖掘1引言个性化信息服务技术,如个性化推荐等,通过对用户的互联网行为进行分析以发现其兴趣倾向,广泛应用于精准营销、社会关系挖掘和舆情分析等领域.目前实现个性化信息服务的常见方法有协同过滤、基于内容过滤等,侧重于获取、表征和挖掘针对特定个体的特征信息,据此预测或引导个人行为.与现有个性化推荐技术有所不同,本文提出一种新的从公开的用户合作行为数据中挖掘群体兴趣的方法,通过群体兴趣及其关联性给出推荐.该方法不仅针对个体特征,而且更注重社团的共性特征.如,群体兴趣挖掘可以回答此类问题:对于“泰坦尼克号”的观众来说,在观影前是播放香水广告还是汽车广告,会引起他们更大的兴趣?若能给出“泰坦尼克号”观众群的群体兴趣点表征及关联性,就可有针对性地推送更有效果的广告或相关信息,提高营销水平.欲挖掘群体兴趣及其关联性,首先要有能够准确反映出群体兴趣的基础数据源.近年来,包括博客、微博、社交网站和维基等形态在内的Web2.0应用迅速普及,为进行此类挖掘提供了数据来源.维基是一种群体合作模式,在创作需包罗万象的百科全书上取得了成功应用,如维基百科.相对于其它几种Web2.0应用形态,维基百科的数据全部公开,所包含的词条都是具有明确定义的概念,容易转化为兴趣点,而且其噪声数据相对更小,处理起来更为方便.因此,本文选择维基百科作为挖掘群体兴趣的基础数据源.基于维基百科进行群体兴趣挖掘的基本前提假设为:用户对词条做出的编辑表示其对该词条所涉及领域抱有兴趣,而大量用户的合作编辑过程则体现了用户群体的兴趣特征,且往往会呈现出用户社团结构.群体兴趣挖掘首先对用户进行聚类以识别出社团,然后再通过社团的编辑行为特征来获取群体兴趣.本文主要围绕群体兴趣挖掘中的两个核心问题展开研究.其一,群体兴趣的表征.由于用户社团的兴趣点不会局限在一个领域,往往较为广泛,且兴趣点之间也存在上下位、同反义等语义关联,因此不能简单地使用词条来表征兴趣点.本文根据维基百科中词条的“类别”属性,通过基于类别树的生长策略构建泛树结构来表征兴趣点.泛树结构能更准确地体现出兴趣点间的语义关系,得到更易于理解的挖掘结果.其二,用户社团对兴趣点的关注度及兴趣点之间相关性的定义.群体兴趣是社团所表现出的固有的、稳定的偏好特性,为了精确、有效地定义兴趣点,需要考虑兴趣点泛树结构特征.本文给出一种融合语义与结构特征的兴趣点关注度及其关联性度量方法.在测试集上进行的对比实验表明,群体兴趣获得了比基于物品的协同推荐方法[1]更高的精度.群体兴趣可根据用户社团的兴趣点给出推荐结果,这一点和个性化推荐方法[1-2](包括基于内容过滤的推荐、协同推荐和基于点击流的预测等)所达成的效果看似相同,但在实现思路上有很大不同.基于内容过滤的推荐技术利用资源和用户兴趣的相似性来过滤信息,协同推荐利用用户动作历史之间的相似性,基于点击流的预测也是利用用户历史行为进行建模.基于在线百科全书的群体兴趣挖掘则使用群体兴趣点来替代推荐对象的个体兴趣的表征,避免了内容过滤与点击流分析技术中新资源发现能力较弱、协同推荐技术中冷启动和稀疏数据等问题.更突出的是,在推荐中,通过可公开获取的维基百科中的群体兴趣取代个性化推荐方法中用户的购买、观影记录等个人隐私数据,避免了大量收集用户数据时所遇到的隐私保护等社会问题.本文第2节介绍维基百科数据源与合作编辑网的用户聚类方法;第3节针对兴趣点表征提出兴趣点泛树结构的构造方法;第4节给出了兴趣关注度和关联性的定义;第5节使用3种方法对实验结果进行了详细分析;第6节给出相关工作;最后总结全文.2数据源及用户聚类2.1维基百科数据源截至2011年9月15日,维基百科已有用280余种语言编写的1900余万个词条(英文版的词条数量最多,已超过373万),提供包括词条历史版本在内的几乎所有数据(http://dumps.wikimedia.org).统计表明[3-4],维基百科能在大部分领域保持较高的准确度和覆盖度.文献[3]通过与美国国会图书馆的3000篇随机文章的对比发现,除了在法律和医学领域稍有逊色之外,其它方面维基百科几乎都有很好的覆盖;文献[4]统计了不同领域词条数目的分布情况,与传统知识库相比,维基百科在专有名词、新词、俚语、技术术语和新近事件等方面具有很大的覆盖优势.本文以维基百科的中文版本作为数据源,收集数据的具体方法是:以“电影”类别下390个词条的1165名用户作为起始输入,再以这些用户所编辑的Page3所有其它词条向外扩充用户,然后通过新扩充的用户来扩充词条.为获得一定规模的数据量,迭代了5次,共得到84098个词条、179023个用户,其中包括属于“电影”类别的词条1991个.2.2用户聚类两个用户间如果有共同编辑的词条,则在两者间连边,即将用户-词条二部图转换为用户合作编辑网,据此合作编辑网进行社团划分,得到用户聚类.对2.1节的数据集进行处理,最终得到的用户合作编辑网包括176175个节点(删除了2848个孤立节点)、520856条边.此处合作编辑网络的节点规模达到了106数量级,为计算效率考虑,采用Mahout数据挖掘工具进行合作编辑网聚类.通过部署在10台PC上的Hadoop框架,向Mahout中的k均值算法输入参数k=1000.在划分为235个社区的时候,Mahout给出了衡量聚类效果的Silhouette指数[5]的最优值:0.3898.因此取用户社团个数为235,其中最小社团包含的节点数为482,最大社团包含的节点数为2879.在进一步进行兴趣点表征工作之前,在这里首先检查群体兴趣的区分度.区分度是指用户社团所编辑词条的覆盖程度的差异性,通过区分度可以粗略地衡量不同用户社团之间的群体兴趣是否确有倾向性.区分度Dis定义为其中,K为词条总数,Ai表示用户社团i所对应的词条集合;k为用户社团的总数.在K=176175,k=235,Silhouette指数为0.3898的情况下,Dis值达到了97.7%,这说明在最优社团划分的情况下,其词条的重合程度较低.图1显示了区分度随Silhouette指数的变化趋势,可以看出,随着Silhouette指数增加,即用户社团划分趋于合理的时候,其所对应词条的区分度也呈现出增加趋势.由于不同社团所编辑的词条具有良好的区分度,这就说明其兴趣点具有倾向性.注意到这里的区分度直接以词条作为单位来计算,而词条往往包含大量非常细节的概念,因此在表征兴趣点时不能直接使用词条,否则将会由于高区分度而忽略掉关联性,此关联性往往是词条在更高层次的概念上所形成的.下一节将引入词条所属类别来表征兴趣点以解决此问题.3兴趣点泛树结构过于细节的词条除带来了前述关联性的问题外,还可能降低兴趣点表征与挖掘结果的可理解性与准确性.如图2(a)所示,部分细节词条(如杰尔姆·卡尔、盐铁论等人名和专著等),其具体含义不为大众所熟悉,作为挖掘结果返回的话将难以理解.图2(b)示意了处于不同概念层次的词条,此时兴趣点之间存在包含关系,若挖掘结果仍将其看成同一层次,将会降低关联性的准确度.如,中国古典典籍、中国文化和盐铁论之间具有包含关系,因此,若认为中国古典典籍和中国文化之间具有很强的兴趣关联性,则会干扰其与亚洲文学等更合理的关联关系.维基百科中每一词条都有很多所属类别的标注信息,对应于词条所属的上层概念.据此,利用类别标注构造兴趣点泛树结构,通过兴趣点泛树将各个不同层次的概念联系起来,通过层次跃升给出更易理解的兴趣点表征、通过消歧义等给出更为准确的关联性.下面说明兴趣点泛树的生长构造策略.抽取词条所处的分类结构得到一层类别树,生长构造策略以一层类别树形成的森林作为输入,将森林合并成一个大的泛树结构.以词条作为起始节点,其所属的类别标注也看为节点,两者间连边.此过程中不断地合并具有同样名称的节点,从而将森林中原本多棵不连通的树合并为一棵整的泛树.节点合并中的问题有:(a)不一致的标注层次关系(图3(a)),通过合并不一致的节点、删除捷径来调整.(b)矛盾的层次关系(图3(b)),通过合并节点、将任意一条边删除来调整.(c)标注的歧义(图3(c)),判断出不一致的Page4节点并合并.此外还要处理噪声数据,包括设立停用词、删除孤立节点等.针对图3所示的问题,类似于文献[6]的方法,设定节点之间的相似度,以节点间的相似度达到一定阈值作为节点合并的条件.节点A和B间相似度Sim(A,B)的定义由语义相似度和结构相似度两部分组成:Sim(A,B)=(1-α)×semanticSim(A,B)+语义相似度semanticSim主要由两部分组成,一是名字相似性,二是邻居相似性,计算方法为semanticSim(A,B)=β×nameSim(A,B)+其中,nameSim(A,B)是A和B的名字相似度(可根据简单的字符串相似程度计算,也可以引入语义词典计算,本文的实验采用字符串相似程度),neighborSim(A,B)度量邻居相似度,定义为A和B所拥有的共同邻居的名字相似度的均值.结构相似度structuralSim根据一层类别树上词条A和B所处位置的相似性计算:structuralSim(A,B)=k+(1-k)DiffSim(A,B),其中,k=neighbor(A,B)/min(neighbor(A),neighbor(B))度量的是结构特征上两个节点共同邻居的数目比例,其中neighbor(A,B)为A、B的共同邻居数,neighbor(A)和neighbor(B)分B表示A和B的邻居数;DiffSim(A,B)=1-neighborSim(A,B),因此(1-k)×DiffSim(A,B)衡量的是共同邻居节点之外的其它邻居节点的影响.α和β作为权重调整因子,本文采用使得Sim(A,B)结果序列的熵最大化的方法来估计其取值.一个兴趣点泛树结构示例如附录所示(包含了图2中的词条).以类别为基础,可对兴趣点分类进行提升,使其更容易理解,如盐铁论被归类为文集、汉朝典籍、经济史;杰尔姆·卡尔被归类为物理化学家、诺贝尔化学奖得主.还可给出层次性的兴趣点表征,通过不同层次上兴趣点跃升与下降给出合理的关联性.例如,汉朝典籍上层的中国古典典籍和汉朝文化是具有相关性的,而汉朝典籍和中国古典典籍之间的相关性就可以弱化;中国古典典籍上层的中国文学和各国文学之间的相关性则可以相应地强化.4群体兴趣关注度及关联性分析在兴趣点泛树结构基础上,本节结合用户社团的结构特征给出群体兴趣关注度的定义,然后再根据用户社团内部与社团之间两个影响因素来计算兴趣点关联性.4.1群体兴趣关注度兴趣点关注度记为F(I,G),下面统一用I表示泛树结构的节点,它可能是根节点(原始词条),也可能是中间节点或叶节点(更高层次的类别标注),泛树结构上不再区分词条和类别.G是某一个用户社团,G对应的词条集合记为IG.本文主要从编辑行为和兴趣点在泛树结构中的位置这两点来定义F(I,G).对于编辑行为而言,兴趣点I被G中用户编辑的次数NumInG(I,G)与所有社团的作者全体集合对此兴趣点的编辑次数需要联立考虑.类似于评估单词重要性的tf-idf方法,这里提出基于编辑特征的ef-isf(editfrequency-inversesetfrequency)方法:其中,efI,G=NumInG(I,G)/Num(I:I∈IG),分母Num(I:I∈IG)表示在IG中兴趣点出现的次数之和;isfI=log(|G|/(1+|G:I∈IG|)),表示在所有的用户社团中,具有兴趣点I的社团所占比例的大小.efI,G×isfI表示的含义为:兴趣点I在社团G中得到编辑的概率乘上I在所有社团中得到编辑的比例.若兴趣点处在泛树结构的一个回路中,由于可以认为回路中的兴趣点间具有强烈相关性,因此其对关注度的正面影响为Z=|circle(I):circle(I)∈IG|/|circle(I)|,其中,circle(I)为I所处于的最短回路,|circle(I)|为其长度,|circle(I):circle(I)∈IG|的含义为既属于回路circle(I)又属于IG的兴趣点数目,|circle(I)|为兴趣点I所处最短回路的长度.I处于泛树结构的层次特征主要使用其所覆盖的根节点数目、与根节点的距离来刻画.设CI为兴趣点I所覆盖的根节点(词条)数目,C为所有根节点(词条)的数目;HI为距离所覆盖的根节点的平均Page5值,H为根节点到叶子节点的距离之和(泛树的高度).关注度与兴趣点所覆盖根节点的数目、与根节点的距离成衰减关系,取高斯衰减函数刻画此关系:exp[-(C/CI+H/HI)].社团G对兴趣点I的关注度为综合考虑编辑行为和位置信息两个因素,用户F(I,G)=(1-α)×ef-isfI,G+其中α为影响因子,用于调节编辑行为与位置信息两个因素的权重,本文按照使得F(I,G)序列的熵最小化来确定α的取值,Z为归一化因子.4.2兴趣点关联性兴趣倾向是用户社团中稳定的偏好特性,而兴趣倾向之间的关联性通过用户社团联系起来.兴趣点间的关联性需考虑两个因素:(1)用户社团内部结构以及兴趣点关注度等所产生的关联;(2)用户社团之间所体现出的兴趣点关联.对于这两个因素处理的基本原则有:社团内部兴趣点的关联性要比社团之间的更强;社团内部具有更强关注度的兴趣点之间的关联性更强;处于类似位置的兴趣点之间的关联性强.对于用户社团G内部的兴趣点I和J的关联性,转化为对点加权的网络频繁子结构挖掘问题.其中,点权重即为G对于相应兴趣点的关注度F(I,G),频繁子图为同时包含I和J的最小子图.首先暂不考虑节点权重,采用经典的AprioriGraph算法[7]来挖掘频繁子结构.在计算出频繁子结构Sij之后,再使用简单的值和约束法则Sumvlow,其中Sumv为子结构Sij中所有节点的权重之和,low为指定的至少应该满足的阈值.所挖掘出的满足指定支持度的频繁子图Sij的数目记为m,频繁子图Sij所体现的关联性即可定义为Sij在整个泛树结构S中所占的面积比(其中|Sij|和|S|分别表示节点数目):对于分别位于两个社团上的兴趣点I和J的关联性,关键是计算出其在各自所属的泛树结构上的共同祖先节点PI=PJ,然后根据I和J在两个泛树上分别与此公共祖先节点的距离来确定两者的相关性.具体方法为,假设存在此公共祖先节点PI=PJ,I和J到PI和PJ的最短距离分别为d(I-PI),d(J-PJ),则I和J的社团之间关联性为CIJ=exp-[1/d(I-PI)+1/d(J-PJ)].其物理含义是,相关性与公共祖先节点的距离成反比.若公共祖先节点不存在,则定义d(I-PI)和d(I-PJ)为距离泛树结构叶子节点的最短距离.兴趣点I和J的关联性C(I,J)同时考虑社团内部和社团之间两个要素,对前述计算出的社团内部与社团之间的两个关联性结果联立考虑:4.3群体兴趣挖掘算法步骤与复杂度分析总结前述群体兴趣挖掘算法的主要步骤,包括用户聚类、兴趣点泛树构建、计算关注度与相关性等四步,如图4所示.其中,矩形框为算法步骤,椭圆形为数据,实箭头标示了数据的输入输出关系,空箭头标示了数据间的关系.其中,原本复杂度较高的大规模复杂网络聚类通过基于MapReduce的分布式计算平台,复杂度被降至O(N·log(N)),其中N为网络的节点数目.兴趣点表征的复杂度主要在泛树结构的构建步骤,泛树结构的生长策略按照逐步处理一层类别树的方法,且要计算每一个类别的相似度,故复杂度为O(N·(1+sum(O(l))),其中N为所有类别树的总数,l为一层类别树的平均节点数,记li为某类别树的节点数,sum(O(l))=(l1l2+(l1+l2)l3+…+(l1+l2+…+lN-1)lN),因此O(N·(1+sum(O(l)))=O(N+N2/2)=O(N2/2).在兴趣关注度与相关性步骤,因为均要计算出整个矩阵的元素,故计算复杂度为O(|犌|2),其中|犌|为用户社团和兴趣点所构成的矩阵犌的元素个数.泛树结构、兴趣关注度和相关性计算均没有很强耦合的步骤,因此可置于MapRe-duce分布式平台上,进而复杂度可以进一步降低.5实验结果分析5.1实验过程与评价方法在前期抽取的176175个用户节点、520856条边、235个用户社团的基础上,按照图4所示的算法步骤,建立起群体兴趣及其关联的基础数据库,其中,针对每一个社团G和兴趣点I记录了关注度Page6F(G,I),针对所有的兴趣点二元组〈I,J〉记录了关联性程度C(I,J).此基础数据可以定期根据维基百科数据源的变动情况重新计算,达到实时更新的效果.对群体兴趣的合理性和准确度采用3种方法进行评价:(1)人工直观观察结果.实验以维基百科中“电影”类别下的词条为初始内容开始爬取.因此,可以直接人工地输入一部电影作为兴趣点,再借助于常识,定性地评估其返回的关联兴趣点的合理性.(2)借助于测试数据集.引言中已提及,根据用户点击流进行个性化行为预测会遇到新资源发现能力缺乏的问题.但是,已记录下的点击流数据却是验证群体兴趣点关联性较为理想的测试数据集.通过对比群体兴趣的关联性与真实点击流数据所体现出关联性之间的符合程度来验证挖掘结果的准确性.本文的点击流数据源由两部分组成,一是抽取了Amazon.cn中电影书籍和CD类商品的点击浏览数据,二是校园网门户上新闻页的关键词.这两部分的数据必须结合起来,以达到领域较宽(由新闻页关键词保证)和内容较准确(购物网站物品浏览)的目的,从而便于测试群体兴趣的结果.通过点击流衡量群体兴趣的具体方法是,给定任意两个兴趣点I、J及其通过群体兴趣挖掘所得到的关联性C(I,J),计算在点击流中兴趣点I和J之间的距离k(I,J)(若I或J在点击流中没有出现则定义为点击流序列的最长距离).对于点击流中的相关性,采用简单的距离反比,即1/k(I,J)越小,则I和J之间的关联性越大.因此,如果C(I,J)和1/k(I,J)所构成的矩阵犆和犓呈现出很强的正相关,就可以说明群体兴趣关联性挖掘的有效性.矩阵犆和犓的相关性通过每一行数据的皮尔逊相关系数相加得到.作为基准算法进行类比,使用基于物品(兴趣点)的协同推荐方法进行了计算.在这里,协同推荐采用文献[8]中的算法实现:兴趣点拥有的共同用户越多,推荐的关联性越强.(3)网站推荐的实际应用.以在校园网的视频点播服务中添加新闻链接的方式进行测试,通过新闻链接被点击的次数作为对比.实验过程为:在为期一个月的时间内,按照Web新闻页面点击的热度确定概率的大小、随机地分配新闻链接到各视频源上;然后在接下来的一个月时间内,以同样的视频源作为输入,但是将当前的新闻链接按照兴趣点相近的原则重新分配.5.2结果分析(1)直观结果.输入测试用例:电影“建国大业”,“泰坦尼克号”,将返回的关联性最高的9个兴趣点及关联性程度绘制成雷达图,如图5所示.这里返回的兴趣点分布于泛树结构各层次,主要依据是关联性程度的排序.表1列举了另外4部知名电影作为兴趣点输入的测试结果.输入兴趣点相关性(相关性按由前到后降序排列)阿甘正传阿凡达唐山大地震岁月神偷图5群体兴趣关联性示例(与电影“泰坦尼克号”和从定性的角度分析,可以看出,对于图5中这两部电影来说,其导演和所反映的背景事件都是用户社团具有强烈兴趣的(如奥斯卡、战争等).而其它的兴趣点中,“泰坦尼克号”社团更加关注一些时尚话题,如香港小姐竞选等;“建国大业”社团则对于摄影等有兴趣,而“停车场”的意外出现则可能与影院或Page7者生活服务相关.进一步分析表1中所列举的案例,可以看出,每一部电影相关的背景、演员和导演等所涉及的信息往往都是关联性较高的兴趣点所在,同时一些“意料之外”的结果,如“阿甘正传”中的“国际象棋”、“阿凡达”中的“京杭大运河”等,往往更可能提示一些有趣的、隐藏的推荐信息.总之,从直观上看,每一部电影的用户社团都带有较为强烈的群体兴趣的倾向性,这有助于挖掘互联网上大量用户的背景和关注点等有用信息.(2)测试数据集的覆盖度.在具体实验中,本文抽取的测试集数据规模为:Amazon.cn影视分类下的3980部电影和15820个相关的点击数据;校园网新闻(包括时政新闻和校园新闻)的5692个关键词和相关点击排名前5的28460个关键词.最终所得测试集中一共包括53952个关键词(其中包括重合的9802个关键词).
