Page1利用社交关系的实值条件受限玻尔兹曼机协同过滤推荐算法何洁月马贝(东南大学计算机科学与工程学院南京210096)(东南大学计算机网络和信息集成教育部重点实验室南京210096)摘要利用受限玻尔兹曼机(RestrictedBoltzmannMachine,RBM)解决推荐问题已成为一个很有意义的研究方向.目前用于推荐的RBM模型中使用的仅仅是用户评分数据,但用户评分数据存在着严重的数据稀疏性问题.随着互联网对人们生活的不断渗透,社交网络已经成为人们生活中不可缺少的一部分,利用社交网络中的好友信任关系,有助于缓解评分数据的稀疏性问题,提高推荐系统的性能.因此,该文首先提出基于实值的状态玻尔兹曼机(Real-ValuedConditionalRestrictedBoltzmannMachine,R_CRBM)模型,此模型不需要将评分数据转化为一个K维的0-1向量,并且R_CRBM模型在训练过程中使用了训练数据中潜在的评分/未评分信息;同时该文将最近信任好友关系应用到R_CRBM模型推荐过程中.在百度数据集和Epinions数据集上的实验结果表明R_CRBM模型和引入的最近信任好友关系均有助于提高推荐系统的预测精度;最后,针对大数据环境下,普通平台很难完成R_CRBM模型训练的问题,该文提出基于Spark的并行化方案,较好地解决了该问题.关键词受限玻尔兹曼机;数据稀疏性;R_CRBM;社交网络;信任关系;大数据1引言随着互联网和信息技术的快速发展,微博、即时通讯、搜索引擎、电子商务、网络游戏等网络业务越来越普及,网络信息服务已经渗透到人们生活的各个方面,导致互联网用户的数量急剧增长.急剧增加的不仅仅是互联网用户的数量,还包括各种繁多的交易数据.面对互联网上如此海量的商品,用户不得不浪费大量的时间来选择自己感兴趣的商品.基于此,推荐系统应运而生,出现了很多商用推荐系统,比如为用户推荐图书和其它商品的Amazon,中国最大的电子商务平台淘宝网,电影推荐系统MovieLens,文章推荐系统GroupLens等.协同过滤推荐系统的应用最为广泛和成功.协同过滤算法分成两类[1]:基于内存的协同过滤(Memory-basedCF)、基于模型的协同过滤(Model-basedCF).基于内存的协同过滤,首先是计算用户(或项目)之间的相似度,然后是聚合最相似的若干用户(或项目)的评分进行预测.推荐过程中主要根据评分矩阵来进行,评分矩阵就好像是在内存中一样.基于模型的协同过滤是从已有的评分矩阵中学习出一个紧凑的模型,后续推荐中用这个模型进行预测.建立用户模型是该方法的核心,目前常用的模型包括回归模型、贝叶斯模型、聚类模型、马尔可夫模型、隐语义模型、奇异值分解模型、受限玻尔兹曼机(RestrictedBoltzmannMachine,RBM)模型[2]等.其中RBM模型因其准确度较高近年来受到较大关注.RBM(图3(a))可以被视为一个无向图模型,它由两层二进制单元组成:一个可见层,表示数据;一个隐层,可视为特征提取器增加学习能力[3],并且层内无连接.RBM模型已经被实验证明是一种有效的解决推荐问题的方法[2,4].2007年Salakhutdinov等人[2]首次将RBM模型应用于解决推荐问题,作者对传统的RBM做了两点改变:首先,可见层用一个长度为K的0-1向量单元表示评分数据;其次,用户可能只对若干个项目进行评分,对没有评分的项目使用一种特殊的(Missing)单元表示,这种单元不与任何隐层的单元连接.每一个用户都有一个单独的RBM,这些RBMs对应一个共同的隐层.所有的RBMs之间的权重和偏置是共享的,所以如果两个用户对同一项目进行了评分,那么将会使用同一个权重.作者同时提出了条件受限玻尔兹曼机(ConditionalRBM,CRBM)模型,CRBM训练过程中利用潜藏在评分数据中的评分/未评分数息,更加突出评分数据的作用.但是Salakhutdinov等人[2]所提模型的缺陷是:需要将实值的评分数据转化为一个K维的0-1向量,可见层与隐藏层之间的连接权重变为M×K×S维,维数变为了原来的K倍,从而导致参数过多、训练过程复杂、模型训练时间较长;而且该模型只能将整型的评分数据转化为一个K维的0-1向量,如果训练数据中的评分是Double型的就无法转化.2013年Georgiev等人[4]提出了可直接处理实值评分数据的RBM模型并且改进了模型的训练过程,使RBM的可见单元可以直接表示实值,模型的训练和预测过程得到了简化,但是模型只利用评分数据,未能解决数据的稀疏性问题;此外,虽然作者改进了RBM的训练过程,提高了模型的推荐效果,但是此模型使所有用户对同一项目的预测评分都相同,缺乏可解释性.近年来,随着社交网络的流行,利用社交网络中的社交关系来提供推荐服务受到了越来越多学者的关注和研究.相对于传统的推荐系统,基于社交网络的推荐系统具有可靠性高、转化潜在需求为实际购买力强等特点.由于人们在社交网络中表达了很多隐含的兴趣、爱好等社会媒体信息,因此基于社交网络的推荐系统可以充分利用这些隐含的社会媒体信息.目前基于社交网络的推荐系统中一种常用的社会媒体信息是社会信任网络.Golbeck[5]假设用户精确提供了对社交网络中其他用户的信任评分,使用信任值取代相似性的查找,解决数据稀疏性问题.但用户提供对社交网络中所有用户的信任评分是不可能的,于是作者提出了一种TidalTrust[6]推测机制:以广度优先搜索方式推测与其他用户之间的间接信任值.Massa等人[7-8]使用类似于Golbeck[5]的方法,但其推导间接用户间之间的信任值的主要思想是:考虑预先设定的距离范围内的所有用户,对所有到达用户的路径上的信任值进行加权和,该方法被称为MoleTrust[7-8]算法.Ma等人[9-10]提出了一种基于概率矩阵分解的因子分析方法,该方法利用用户的评分信息和社交网络信息,可以很好的解决推荐系统数据稀疏性和Page3预测精度低的问题.Huang等人[11]研究了口碑推荐的后影响,发现口碑推荐可以提高用户对项目的后评价.这些方法均很好地利用了社交网络信息,提高了推荐系统的预测效果.本文借鉴Georgiev等人[4]提出的实值RBM的思想,对Salakhutdinov等人[2]提出的CRBM模型进行了改进,提出了R_CRBM模型.此模型不需要将评分数据转化为一个K维的0-1向量,而且对训练数据的类型没有要求,降低了模型的训练难度,训练过程中使用了潜藏的评分/未评分信息,以提高模型的推荐效果;其次,本文创新性地将最近信任好友的概念加入R_CRBM模型,提出了基于MoleTrust推理的最近信任好友R_CRBM算法.在百度数据集和Epinions数据集上的实验结果表明R_CRBM模型以及基于MoleTrust推理的最近信任好友R_CRBM算法,均提高了推荐系统的推荐效果.本文第2节论述R_CRBM模型和基于Mole-Trust推理的最近信任好友R_CRBM算法;第3节给出了本模型和算法的实验结果及其分析;最后总结本文的工作并提出下一步的研究方向.2算法描述本节首先论述本文提出的R_CRBM模型的原理以及模型中各参数的训练方法;然后论述了基于MoleTrust推理的最近信任好友R_CRBM算法.条件受限玻尔兹曼机(CRBM[2])模型,虽然能利用潜藏在评分数据中的评分/未评分数据信息,但实值的评分数据需转化为一个K维的0-1向量,参数过多、训练过程复杂、模型训练时间较长.为此,我们借鉴文献[3]的思想,提出直接利用实值的R_CRBM模型,同时在模型中加入最近好友关系以进一步强化推荐的有效性.2.1节和2.2节将分别介绍R_CRBM模型和基于MoleTrust推理的最近信任好友R_CRBM算法.2.1Real-ValuedConditionalRBM(R_CRBM)模型在此,我们基于文献[4]的思想提出R_CRBM模型,如图1所示.此模型中可见单元可直接表示实值的评分数据.R_CRBM可以被视为一个无向图模型,v为可见层,表示数据;h为隐层,可视为特征提取器;W为可见层与隐层之间的连接权重矩阵;犇为r层和隐层之间的连接权重矩阵;c表示可见单元的偏置;b表示隐单元的偏置.在给定可见单元状态(输入数据)以及评分/未评分信息时,各隐单元的激活状态条件独立;反之,在给定隐单元状态时,可见层单元的激活状态亦条件独立,并且可通过Gibbs采样有效得到服从R_CRBM所表示分布的随机样本.R_CRBM考虑了评分/未评分这种潜藏信息,用r∈{0,1}M表示评分/未评分信息,其中M表示数据集中总的项目数,0表示未对项目评分,1表示已评过分.由于将评分/未评分信息纳入考虑,因此向量r也将影响隐单元的状态(见图1).R_CRBM将潜藏在评分数据中的评分/未评分数据信息应用到模型的训练过程中,更加突出评分数据的作用.R_CRBM的原理是:从隐单元的偏置中减去一部分权重放到权重矩阵犇中,因为权重犇是r层和隐单元之间的连接权重(见图1)而r表示评分/未评分信息,因此若用户对项目评分,那么从隐单元的偏置中减去的放到犇中的权重将加回隐单元的偏置中(见式(1)),所以若用户对项目评分,那么从隐单元的偏置中减去的放到犇中的权重不会对隐单元或可见单元产生任何影响.但是如果评分缺失,那么从隐单元的偏置中减去的放到犇中的权重将不会加到隐单元的偏置中,因此缺失评分将影响隐单元的特征提取.根据R_CRBM层间全连接、层内无连接的特殊结构可知:可见层和隐层之间是相互独立的.当给定可见单元状态时(包括评分/未评分信息),第j个隐单元的激活概率为P(hj=1|v,r)=σbj+∑i其中,σ(x)=1/1+exp(-x).当给定隐单元的状态时,第i个可见单元的值为[12]2002年,Welling和Hinton[13]提出了RBM的快速学习算法,即对比散度(ContrastiveDivergence,Page4CD)算法.R_CRBM也采用该算法,R_CRBM模型中的参数更新准则为ΔWij=ε(〈vihj〉data-〈vihj〉recon)vi>0(3)Δci=ε(〈vi〉data-〈vi〉recon)vi>0Δbi=ε(〈hj〉data-〈hj〉recon)ΔDij=ε(〈hj〉data-〈hj〉recon)ri其中:〈·〉表示数学期望;〈·〉data表示可见单元已知的情况下,隐层的概率分布;〈·〉recon表示用CD算法重构后模型定义的分布;ε是学习率;r∈{0,1}M是一个长度等于评分矩阵中项目数的0-1向量,用于指示项目是否被用户评分,即评分/未评分信息.训练R_CRBM模型的伪代码见算法1.算法1.基于R_CRBM模型的协同过滤推荐算法(其中CD的步长为1)的伪代码.输入:训练数据集,评分/未评分数据输出:训练好的R_CRBM模型1.FORt=1:NumberEpochsDO:2.FORn=1:NumberDataSamplesDO:3.PositivePhase:P(hj=1v,r)=σbj+∑i4.NegativePhase:①:P(vih)=Νci+∑j或者②:可见单元的值等于该单元和所有隐单元的连接权重的和再加上该可见单元的偏置5.UpdatePhase:ΔWij=ε(〈vihj〉data-〈vihj〉recon)vi>0Δci=ε(〈vi〉data-〈vi〉recon)vi>0Δbi=ε(〈hj〉data-〈hj〉recon)ΔDij=ε(〈hj〉data-〈hj〉recon)ri6.ENDFOR7.ENDFORR_CRBM模型的训练过程主要分为3个阶段:即PositivePhase、NegativePhase和UpdatePhase.第1行:NumberEpochs为训练数据集参与训练的次数;第2行:NumberDataSamples表示训练数据集的行数(或者列数),即将训练数据集中的每行数据(或者每列数据)依次输入模型参与模型的训练;第3行:PositivePhase阶段,已知可见单元状态时(包括评分/未评分信息),求隐单元的激活概率;第4行:NegativePhase阶段,已知隐单元的状态时,求可见单元的值.在该阶段求可见单元的值有两种方法:第1种是P(vi|h)=Νci+∑j第2种方法是可见单元的值等于该单元和所有隐单元的连接权重的和再加上该可见单元的偏置.第5行:UpdatePhase阶段,该阶段更新模型的所有参数.值得注意的是计算ΔW和Δc时训练数据中该可见单元的值应大于0(即用户对该项目评分).2.2基于推理的最近信任好友R_CRBM算法2.2.1直接信任度计算用户之间的直接信任关系可以用直接信任网络来表示.直接信任网络可以用一个有向图G=(U,E)表示,U是图中节点集合,每个节点代表一个用户,E是网络中边的集合,每条边上的值表示朋友间的信任值,如图2所示.直接信任网络中的信任值一般可以表示成[0,1]之间的实数,表达信任的程度,0代表完全不信任,1代表完全信任.然而,社交网络只是一个二值网络,0代表不是好友,1代表是好友.社交网络中好友关系大量存在,但是好友之间的信任值却无法获得.本文的算法中使用Pearson系数计算社交网络中好友之间的直接信任值.Pearson相关系数表示两个变量之间的关联性.用户u和用户v的Pearson相关系数,如式(7)所示.sim(u,v)=其中:Iu,v表示用户u和v共同评分的项目集合;Ru,c表示用户u对项目c的评分;RPage5练集中用户u和v对项目的平均评分.利用Pearson系数计算社交网络中好友之间的直接信任值,基本思想是:首先用训练数据训练一个R_CRBM模型,模型训练好以后若两个用户是好友关系,那么对这两个用户的所有项目进行预测评分,然后使用Pearson系数计算两个用户的相似性,从而就获得了两个直接好友之间的信任值.2.2.2间接信任度计算间接信任表示间接好友间的信任程度.在社交网络中,用户对其他所有用户提供信任评分是不可能的.MoleTrust提供了一种推测机制,用好友之间的直接信任值推测间接好友的信任值,其主要思想是:考虑预先设定的距离范围内的所有用户,对所有到达用户的路径上的信任值进行加权和.2.2.3基于MoleTrust推理的最近信任好友R_CRBM所谓最近信任好友关系是指和用户是好友关系,同时两人之间的信任值大于阈值0.6[6],并且该好友对用户要预测的项目已评分过,我们将这种好友关系称为最近信任好友关系(NearestTrustedFriends,NTF).如图3所示,在图3(a)表示标准的RBM的模型图,图3(b)表示我们提出的R_CRBM模型的结构图.在利用R_CRBM模型进行推荐时,每一个用户都有一个单独的R_CRBM,这些R_CRBMs对应一个共同的隐层,所有的R_CRBMs之间的权重和偏置是共享的,所以如果两个用户对同一项目进行了评分,那么将会使用同一个权重.Ziegler和Golbeck[14]研究了用户兴趣相似性与用户间信任的联系,结果表明两者之间存在着正相关性,即用户之间的信任度较高,则他们兴趣相似性也相对较高.如图3(b),假设要预测用户1对第2个项目的评分,用户u是用户1的好友那么他们的兴趣也必然比较相似,恰好此时用户u对第2项目已评分过,因此,用户u是用户1关于第2个项目的最近信任好友.R_CRBM模型训练好以后就可以利用用户u对第2个项目的预测评分来改善用户1对第2个项目的评分.利用MoleTrust算法得到的信任网络,在信任网络中寻找最近信任好友,从而利用最近信任好友的预测评分来改善预测效果.基于此我们提出了基于MoleTrust推理的最近信任好友(NearestTrustedFriendsBasedonMoleTrust,NTFMT)R_CRBM算法,称其为R_CRBM_NTFMT算法.该算法在预测评分过程中考虑了均值因素的影响,因为即使两个用户的平均评分不同,但是利用Pearson系数求得的相似性也可能很高.R_CRBM_NTFMT算法中用户u对项目i的预测评分如式(8)所示.R^u,i=meanui+其中其中:user_meanu表示训练集中用户u的平均评分;item_meani为训练集中项目i的平均评分;meanui表示用户u的平均评分和项目i的平均评分的平均,综合考虑用户平均评分和项目平均评分的影响;meanki表示用户k的平均评分和项目i的平均评分的平均;F为最近信任好友的数目;friendski表示最近信任好友k的R_CRBM模型对项目i的预测评分;trust_valueuk表示用户u和k之间的信任值(大于阈值0.6[7]).R_CRBM_NTFMT算法的基本思想是:首先用训练数据训练一个R_CRBM模型,然后在用户的信任网络中寻找最近信任好友关系,最后利用最近信任好友的预测评分来改善用户对项目的预测评分.其伪代码如算法2和算法3所示.算法2的R_CRBM_NTFMT算法的输入是训练数据集、评分/未评分数据、好友社交关系网络和距离参数Distance的值,输出是预测评分.而算法3的ConstructTrustNet函数的功能是用好友社交关系网络构建信任网络,其输入为训练好的R_CRBM模型、好友社交关系网络以及距离Distance的值,输出是信任网络Trust_net.Page6算法2.R_CRBM_NTFMT算法的伪代码.输入:训练数据集、评分/未评分数据、好友社交关系网输出:预测评分//Trust_net表示信任网络//F是用户u关于项目i的最近信任好友的数目1.训练一个R_CRBM模型2.调用ConstructTrustNet函数构建Trust_net3.FORallratingswhichneedtobepredictedDO:4.寻找用户u关于项目i的所有最近信任好友;5.meanui=6.meanki=7.R^8.ENDFOR算法3.ConstructTrustNet函数的伪代码.输入:R_CRBM模型、好友社交关系网络和距离参数输出:Trust_net//Trust_net表示信任网络//Trust_net_direct表示直接信任网络1.FORallfriendship(u1,u2)inSocial_networkDO:2.使用R_CRBM模型预测用户u1,u2对所有项目3.使用Pearson相关系数计算u1和u2之间的信任值;4.将u1和u2之间的信任值加入Trust_net_direct5.ENDFOR//使用Trust_net_direct构建Trust_net6.使用MoleTrust算法推理得到Trust_net7.END从算法2可看出R_CRBM_NTFMT算法实现推荐的过程主要可划分为3步:第1行:用训练数据训练一个R_CRBM模型;第2行:调用ConstructTrustNet函数,获得信任网络;第3行~结尾:首先,在信任网络中寻找用户u关于项目i的最近信任好友;然后,根据式(8)~(10)计算R_CRBM_NTFMT算法对相应预测项目的预测评分,即用最近信任好友的预测评分来改善用户对项目的预测评分.算法3是ConstructTrustNet函数的伪代码,该函数的功能是用好友社交关系网络构建信任网络,主要可划分为两步:第1行~第5行:若(u1,u2)是社交网络中的好友关系,用训练好的R_CRBM模型预测u1,u2对所有项目的评分;然后用Pearson系数计算u1,u2的信任值,从而构建了好友之间的直接信任网络;第6行~结尾:用直接信任网络,通过Mole-Trust算法推理得到用户之间的信任网络.3实验结果及分析本节通过实验验证我们所提算法的性能,实验数据采用百度推荐大赛数据集和Epinions数据集,其中80%的数据作为训练数据,20%的数据作为测试数据,MoleTrust算法和RBM[4]模型(包括文献[4]改进的训练过程)作为对比结果.文献[4]改进了标准CD算法的训练过程,改进思想是:可见单元的值等于对应隐单元连接权重的和(sumweight)再加上偏置,我们将此时的RBM模型我们称其为S_RBM.3.1数据集百度推荐大赛的数据集,可从http://www.datatang.com/data/44268下载.首先对数据集进行了预处理,将评分数据中没有好友关系的用户的数据剔除,得到一个3193个用户对7889部电影的评分数据,包括其好友关系网络.Epinions数据集由Massa等人[15]从Epinions.com网站上收集得到,包含40163个用户对139529个项目的评分.我们从该数据集中抽取了一个1963名用户对2436个项目的评分数据集作为实验数据,包括其好友关系.3.2评价指标目前,绝大多数的推荐系统都使用预测准确度来评价推荐算法的性能,预测准确度是比较推荐算法的预测评分与用户实际评分的相似程度.预测准确度的常用度量方法有平均绝对误差(MAE[16-17])、根均方误差(RMSE[18]).平均绝对误差计算预测评分与用户实际评分之间的平均绝对误差值.它的计算公式如式(11)所示.其中:Rtest表示测试集数据;Ru,i表示用户u对项目i的实际评分;R^Rtest是测试集中数据的个数.推荐算法的准确度是所有用户预测评分与用户实际评分之差的平均.根均方误差计算用户实际评分与预测评分之间Page7的根均方误差.它的计算公式如式(12)所示.其中:Rtest表示测试集数据;Ru,i表示用户u对项目i的实际评分;R^Rtest是测试集中数据的个数.根均方误差在求和之前对系统预测评分与用户实际评分的误差进行平方,因此评分之间的误差越大,其对根均方误差的影响会比平均绝对误差更大.3.3百度数据集实验结果及分析3.3.1MoleTrust算法中参数Distance值的确定MoleTrust算法考虑预先设定的距离(Distance)范围内的所有用户.为了计算用户u对用户v的信任值,前节点用户的信任值以信任边为权值进行加权和,即构建了一个以用户u为核心的距离Distance范围内的信任网络.图4和图5验证MoleTrust算法中距离Distance对预测结果的影响.图4MoleTrust算法中参数Distance值对MAE值的影响图5MoleTrust算法中参数Distance值对RMSE值的影响图4坐标系中,横坐标表示最大距离Distance的值,纵坐标为评价指标MAE的值.图5坐标系中,横坐标表示距离Distance的值,纵坐标为RMSE的值.从两张图中可明显看出当Distance达到6以后,MAE和RMSE基本就不再减少.因此在下面的实验中我们使用MoleTrust算法中Distance为6所对应的信任网络,并且将Distance为6所对应MoleTrust算法的预测结果作为一个对比结果.3.3.2RBM模型中隐单元数目的确定本实验的目的是考察RBM[4]模型中隐单元数目对推荐结果的影响,确定隐单元的数目使RBM模型的推荐结果最优,实验是基于训练次数Epochs为10进行的,实验结果如图6和图7所示.图6RBM模型中隐单元数目对MAE值的影响图7RBM模型中隐单元数目对RMSE值的影响图6坐标系中,横坐标表示RBM模型中隐单元数目,纵坐标为评价指标MAE的值.图7坐标系中,横坐标表示RBM模型中隐单元数目,纵坐标为RMSE的值.从图6和图7可发现随着隐单元数目的增加,MAE与RMSE值先降后升,说明模型的效果呈现了先变好后变差的趋势.隐单元用于提取数据的特征,当模型提取的特征较少时这些特征不足以表达数据的特征,此时增加提取的特征数,模型的效果会逐渐变好,但是当模型提取的特征达到一定Page8程度后,此时增加提取的特征会导致特征过多反而影响模型的效果.从图6中可发现隐单元数为80时对应的MAE值最小,图7中隐单元数为90时对应的RMSE值最小,综合考虑隐单元为80和90时的MAE、RMSE值,隐单元数为80时效果更好,因此下面的实验中RBM、S_RBM和R_CRBM模型的隐单元数目都为80.3.3.3训练数据参与训练次数Epochs对推荐结本实验中使用MoleTrust算法中Distance为6所对应的信任网络,RBM、S_RBM和R_CRBM模型的隐单元数目均为80.实验结果如图8和图9所示.图8坐标系中,横坐标表示训练集参与训练的次数Epochs的值,纵坐标为评价指标MAE的值;图9坐标系中,横坐标表示训练集参与训练的次数Epochs的值,纵坐标为评价指标RMSE的值.两图中MoleTrust表示MoleTrust算法中Distance为6所对应的预测结果.从两图中可发现R_CRBM模型的实验结果均略优于RBM模型,说明潜藏的评分/未评分信息可以改善预测效果.S_RBM模型推荐效果比RBM模型有了一定程度的提高,但是其缺点是使所有用户对同一项目的预测评分均相同,这缺乏可解释性.从两图中可看出我们提出的R_CRBM_NTFMT算法预测性能优于所有的算法,而且是一种比较稳定的算法,其MAE和RMSE基本是稳定的,受Epochs的影响不大,达到了较好的预测效果.3.3.4数据稀疏性实验本实验通过改变训练数据集和测试数据集占评分数据的比例,观测数据在不同稀疏性的情况下对实验结果的影响.本实验分别将评分数据中的20%、40%、60%、80%作为训练数据集,相应地测试数据集占评分数据的比例分别为80%、60%、40%、20%.实验结果如图10和图11所示.图10中,横坐标表示不同稀疏度的训练数据集,纵坐标为评价指标MAE的值;图11坐标系中,横坐标表示不同稀疏度的训练数据集,纵坐标为评价指标RMSE的值.从两图中可发现随着训练数据集占整个数据集比例的提高,也就是说随着数据稀疏性的减少,几种算法的MAE值和RMSE值均减小,也就是推荐效果不断变好.两图中R_CRBM模型的推荐效果均优于RBM模型的结果,表明评分/未评分信息确实有利于提高推荐结果,在一定程度上解决了数据稀疏性问题;S_RBM模型的效果较Page9RBM模型也有了一定程度的提高;我们提出的R_CRBM_NTFMT算法的推荐结果远远优于RBM和S_RBM模型,表明我们利用的最近信任好友关系确实有利于提高推荐效果,而且数据越稀疏预测效果比RBM和S_RBM模型提高的越多.当训练数据占20%时,我们的R_CRBM_NTFMT算法,MAE比RBM和S_RBM模型分别提高6.92%和4.25%,RMSE比RBM和S_RBM模型分别提高10.70%和8.55%;当训练数据占80%时,我们的R_CRBM_NTFMT算法,MAE比RBM和S_RBM模型分别提高3.06%和2.27%,RMSE比RBM和S_RBM模型分别提高4.76%和4.03%.3.4Epinions数据集实验结果及分析参数Distance和隐单元数目的确定与百度数据集类似,这里不再展示.实验中使用MoleTrust算法中Distance为3所对应的信任网络,并且将Distance为3所对应MoleTrust算法的预测结果作为一个对比结果,RBM、S_RBM和R_CRBM模型的隐单元数目均为80.3.4.1训练数据参与训练次数Epochs对推荐结本实验主要考查随着训练数据集参与训练次数Epochs的增加,各算法的推荐结果的变化情况.实验结果如图12和图13所示.图12坐标系中,横坐标表示训练集参与训练的次数Epochs的值,纵坐标为评价指标MAE的值;图13坐标系中,横坐标表示训练集参与训练的次数Epochs的值,纵坐标为评价指标RMSE的值.两图中MoleTrust表示MoleTrust算法中Distance为3所对应的预测结果,可发现MoleTrust算法在Epinions数据集上取得了较好的推荐效果.S_RBM、R_CRBM模型在此数据集上的实验结果仍然优于RBM模图12Epinions数据集上各方法的MAE值图13Epinions数据集上各方法的RMSE值型.我们提出的R_CRBM_NTFMT算法取得了最好的预测效果.3.4.2数据稀疏性实验本实验将评分数据中的20%、40%、60%、80%作为训练数据集,相应地测试数据集占评分数据的比例分别为80%、60%、40%、20%.实验结果如图14和图15所示.图14中,横坐标表示不同稀疏度的训练数据集,纵坐标为评价指标MAE的值;图15坐标系中,横坐标表示不同稀疏度的训练数据集,纵坐标为评价指标RMSE的值.从两图中可发现随着训练数据集占整个数据集比例的提高,几种算法推荐效果均不断变好.两图中R_CRBM和S_RBM模型的效果Page10较为接近,R_CRBM和S_RBM模型的推荐结果均优于RBM模型的结果,表明评分/未评分信息确实有利于提高推荐结果,在一定程度上解决了数据稀疏性问题;我们提出的R_CRBM_NTFMT算法的推荐结果远远优于RBM和S_RBM模型,表明我们利用的最近信任好友关系确实有利于提高推荐效果,而且数据越稀疏预测效果比RBM和S_RBM模型提高的越多,充分说明我们的算法能有效缓解数据稀疏性问题.当训练数据占20%时,我们的R_CRBM_NTFMT算法,MAE比RBM和S_RBM模型分别提高15.11%和6.23%,RMSE比RBM和S_RBM模型分别提高17.45%和13.14%;当训练数据占80%时,我们的R_CRBM_NTFMT算法,MAE比RBM和S_RBM模型分别提高5.89%和2.20%,RMSE比RBM和S_RBM模型分别提高5.06%和2.95%.综合对比两个数据集上的实验结果,可发现R_CRBM模型比RBM模型取得了更好的推荐效果,说明R_CRBM模型中利用的潜在的评分/未评分信息有助于提高推荐精度;我们提出的R_CRBM_NTFMT算法取得了最好的推荐效果,推荐效果比RBM、R_CRBM和S_RBM模型均有了较大程度地提高,说明我们算法中使用的最近信任好友关系是值得信赖的.至此我们得出结论:我们的R_CRBM模型和R_CRBM_NTFMT算法中使用的评分/未评分信息和社交关系信息均有助于提高推荐效果,有效地解决了数据稀疏性问题.图16R_CRBM模型并行化3.5.2可扩展性实验结果本实验中,R_CRBM模型的隐单元数量为180,训练次数Epochs为10,实验结果如图17和图18所示.图17中,横坐标表示集群的节点数,纵坐标表3.5基于Spark的大数据环境下的并行化实验在大数据环境下,由于数据量巨大,普通平台无法处理大数据问题并且此时R_CRBM模型的参数数量将变得极其巨大,R_CRBM模型的训练将面临巨大的挑战,因此,针对大数据下的R_CRBM模型,本文提出了基于Spark的并行化方案.本实验的数据集采用完整的Epinions数据集,包含40163个用户对139529个项目的评分以及用户之间的关系数据.本实验使用IBM高性能计算平台,使用其中10个计算节点,每个节点8GB内存.3.5.1基于Spark的R_CRBM_NTFMT算法Spark是一个基于内存计算的开源集群计算系统,其目的是更快速地进行数据分析.Spark创新地提出了“弹性分布式数据集”(ResilientDistributedDatasets,RDD)的概念,RDD是一种内存分布式数据集,它可以将中间结果缓存在内存中从而省去不必要的磁盘读写,提高运行速度.图16为R_CRBM模型的并行化方案.图中参数θ={W,b,c,D}.在并行化分解样本阶段将训练数据集切分到各个分片上;并行化阶段针对每个分片上的训练数据进行参数学习,得到各参数的更新值,即为式(3)~(6);汇总阶段汇总每个分片上的参数得到平均后的参数.本文的R_CRBM_NTFMT算法在R_CRBM模型训练好以后有一个寻找最近邻居的过程,其基本思想与R_CRBM模型的并行化方案类似.示R_CRBM_NTFMT算法的运行时间,时间单位为分钟;图18中横坐标表示集群的节点数,总坐标表示加速比.从两图中可发现随着集群节点数的增加,算法的运行时间越来越少,说明基于Spark的并行化方案是有效的;当集群从1个节点增加到4个Page11节点时算法加速非常明显,加速比是2.64,但是随着集群数量的继续增加,算法的加速情况变得较为缓慢,此时节点之间的通讯开销逐渐占据主导.本实验中使用到3个数据(训练数据、测试数据、社交数据),3个数据总的数据量约为23GB,使用Spark读取这3个数据仅需20s左右,很好地解决了普通环境无法处理大数据的问题.同时10个节点时基于Spark的并行化方案实现了2.84倍左右的加速,较好地解决了大数据环境下R_CRBM模型的训练问题.4总结及展望当前,以RBM为基本模块的深度置信网模型被认为是最有效的深度学习算法,也使其在深度学习领域中占据着核心位置,RBM目前已被应用于多种机器学习问题,协同过滤便是其中之一.目前的研究中RBM使用的还仅仅是用户的评分数据,众所周知推荐领域中存在严重的数据稀疏性问题,以我们实验所采用的百度推荐大赛的数据集为例,其超过97.4%的数据是缺失的,这将大大影响RBM模型的训练效果.基于此,本文提出了R_CRBM模型并将R_CRBM模型和用户的社交关系相结合提出了R_CRBM_NTFMT算法.实验结果表明我们的方法很好地解决了数据稀疏性问题,并且在数据越稀疏的情况下我们的R_CRBM_NTFMT算法的预测效果比RBM和S_RBM模型提高的越多.最后,针对大数据环境下算法面临的挑战,本文提出了基于Spark的R_CRBM_NTFMT算法并行化方案,取得了一些初步的有效结果,未来将进一步优化其性能以适应在大数据下的推荐预测.本论文中采用了文献[4]中的训练方法(包括其所作的改进),本质上都是CD算法,但在深度学习领域,一些研究者在CD算法的基础上,已经对其作了一系列的改进,例如,Tieleman[19]提出了持续对比散度(PersistentContrastiveDivergence,PCD)算法;Tieleman和Hinton[20]进一步改进了PCD算法,引入一组辅助参数以加快马氏链的混合率,提出了快速持续对比散度(FastPersistentContrastiveDivergence,FPCD)算法;Desjardins等人[21]提出了ParallelTempering(PT)算法,通过交换相邻两个分布的状态,可以将低温下的状态传递到高温状态中,这样便可以从局部最优值中跳出,有更大的概率转移到距离较远的峰值中去;Ji等人[22]提出了ParallelTemperingwithEqui-Energy(PTEE)算法,用于解决PT算法中当相邻两个状态的能量差距很大时交换概率低的问题等等,但是这些方法的应用领域都是传统的0-1数据,因此如何改进这些方法使其适用于像推荐这种数据是实值并且数据大量缺失的应用领域,将是我们未来的研究工作.
