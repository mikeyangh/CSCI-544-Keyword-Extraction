Page1面向地址空间分离网络的地址映射模型:AMIA陈文龙1)徐明伟2)1)(首都师范大学信息工程学院北京100048)2)(清华大学计算机科学与技术系北京100084)摘要地址空间分离是解决互联网路由可扩展问题的有效方法,其关键技术是边缘网地址到核心网地址的映射机制.现有典型地址映射模型基于缓存映射项机制实施,其映射信息交互协议复杂,路由器对映射信息缓存的维护开销很大.而且,缓存机制中映射项查询延迟较长,明显影响到端系统用户的网络体验.文中设计了一种新型的面向地址空间分离网络的域间地址映射模型:AMIA,通过BGP协议扩展完成映射信息交互,映射项存储不带有任何缓存机制,方便实施.文中还为AMIA模型设计研制了集成PE和KMS功能的多功能路由系统,并在CERNET2中搭建实验网进行实验验证.理论分析及实验结果证明AMIA模型具有高性能、可行性及易实施等特点.关键词地址映射;封装;PE1引言随着互联网规模的快速发展,互联网路由可扩展Page2开销和FIB表存储开销.上述问题的根源就在于整个互联网一体化的地址及路由机制,这导致大量边缘网路由进入到核心网,使得核心网设备不堪重负.目前,学术界解决路由可扩展问题的主流思路是将互联网地址分为两个空间:边缘网和核心网,从而减少核心网路由容量[3].根据文献[3]的分析,将边缘网地址前缀从核心网剥离后,整个互联网的路由表容量及路由更新频率将降低一个数量级.地址空间分离的思想最早由文献[4]提出,实施的关键是建立好边缘网地址与核心网地址的映射模型,以实现端到端数据在核心网的封装传输.当前,典型的地址空间分离模型,如LISP[5]和APT[6],都是基于核心网边界路由器(ProviderEdge,PE)缓存映射项机制完成.缓存机制最大的问题在于:端系统用户网络体验会受到较大影响,缓存机制的控制协议开销和PE维护开销较大,实际部署难度较大.同时,对于无缓存的地址映射机制,如Softwire[7]中,PE需要存储全网所有映射信息,难以承受.本文设计了一种新型的面向地址空间分离网络的域间地址映射模型:AMIA(AddressMappingforInter-AS),实现全网的边缘网地址与核心网地址空间分离.AMIA模型在每个自治域设置一台核心映射服务器(KernelMappingServer,KMS),PE只与本自治域的KMS通过IBGP扩展[8]进行本自治域映射信息交互.互联网端到端数据在核心网的传输过程通过报文封装完成.AMIA模型信息交互通过对BGP协议扩展完成,映射项存储不带有任何缓存机制,简单易实施.而且,通过对映射表存储容量的分析,论证了AMIA模型较好的存储性能.本文还为AMIA模型设计实现了集成PE和KMS功能的多功能路由系统MFRT(Multi-FunctionRouter),并在CERNET2中搭建网络进行实验,进一步验证了AMIA模型高性能、可行性及易实施等特点.本文主要贡献包括:(1)设计了一种无缓存机制的域间地址映射模型,克服了现有典型地址空间分离模型缓存机制对于用户网络体验影响较大的缺点;(2)研制了集成PE和KMS功能的多功能路由系统,并测试验证了其高带宽、低转发时延等特点;(3)基于VegaNet[9]完成AMIA模型在CERNET2上的真实部署并正常运行.本文第2节介绍地址映射的相关研究工作;第3节描述AMIA模型具体思想和映射项存储分析以及AMIA模型的优劣评价;第4节给出AMIA模型的具体实施方法;第5节介绍AMIA模型在CERNET2上的真实部署实验及相关性能分析;第6节对全文工作进行总结.2相关研究针对互联网的Multi-homing和流量工程导致的核心路由表的快速增长问题,LISP[5]协议提出了地址空间分离模型.它将互联网IP地址分为端系统标识域(EIDs)和路由标识域(RLOCs).LISP无需对主机协议栈和除PE外的核心网路由器做任何修改.数据层面,LISP是一个简单的隧道转发机制.核心网中,源端系统所属的PE路由器将封装报文发至目的端系统所在的PE路由器.边缘网和核心网的数据转发过程和传统转发机制一样,关键点只是PE路由器的报文封装和解封装.控制层面,主要是指映射信息的学习及存储,LISP设定了一种分布式映射系统,并提供了PUSH和PUSH/PULL等几种不同的映射信息学习机制.而且,LISP定义了基于UDP的新型协议报文来交互映射信息.然而,LISP模型中映射项平均查询时间高达3.6s[10],这些额外增加的访问延时对网络用户影响太大.LISP协议较为复杂,PE维护映射信息缓存需要较大开销,在映射信息系统方面也涉及新型设备部署,真实部署难度较大.DAN[6]希望将APT设计成一种能真正在互联网部署的地址空间分离模型.APT模型的映射信息获取是一种PULL/PUSH混杂模式.数据层面,APT也是通过报文封装完成数据在核心网的传输.不过,APT定义了默认映射器DM来存储全部映射信息.PE只缓存部分最近使用的映射信息,对于在缓存中没有找到映射项的报文,PE会将其封装发送给DM,由DM负责转发到对端PE.APT模型中,PE和DM对映射信息缓存的维护代价较高,而且DM根据转发数据向PE发送映射项的机制有较大的安全问题,容易受到攻击.清华大学提出的Softwire[7]架构,虽然是一种IPv4到IPv6的过渡机制,但其处理过程及实施结果却和地址空间分离模型极为相似,是地址映射模型研究的很好借鉴.Softwire模型中,PE通过扩展的BGP协议两两建立邻居关系,并相互传递4~6映射信息.而且,IPv4报文在IPv6网络中的传输也是通过封装机制完成.Softwire模型的不足是PE需要建立太多的BGP邻居,而且尚不能解决全网跨域的映射信息交互.Page33AMIA模型方便描述,定义边缘网地址前缀为E_PFX,核心网地址为C_Addr.AMIA模型关于映射信息存储及信息交互有如下基本思想:(1)PE只存储本自治域的映射信息;(2)KMS存储全网所有的映射信息;(3)PE只与本自治域的KMS交互映射信息;(4)KMS之间通过邻居洪泛模式学习映射信息.定义1(地址映射项).地址映射项用于描述边缘网地址前缀到核心网地址的映射关系,记作“E_PFX→C_Addr”.定义2(通配映射项).任何边缘网地址都可匹配的映射项被称为通配映射项,记作“E_PFXany→C_Addr”.假设边缘网是IPv4地址空间,则E_PFXany就是一个0位掩码的IPv4地址前缀,即0.0.0.0/0.AMIA模型的映射信息传播机制遵循如下原则:(1)PE与本自治域的KMS之间建立IBGP邻居关系,并通过扩展的IBGP协议进行映射信息交互;(2)KMS向所属自治域的PE通告该域所有的图1AMIA模型网络拓扑示例以映射项“E_PFX1→C_Addr1”为例解释上述映射信息传播机制,PE1会把“E_PFX1→C_Addr1”通告给KMS1,KMS1会继续将该映射项转告给PE2和KMS2.不过,KMS2却不会将这种域外学习到的映射项通告给PE3.映射信息传播后,各路由器所拥有映射信息如表1所示.显然,映射信息传播机制达到了既定目标:“PE只存储本域映射信息,KMS存储全网映射信息”.需要说明,KMS生成的通配映射项专为PE服务,无需在自身存储.对于跨域数据通信,PE查询映射项必定匹配通配映射项,映射项,即映射项的E_PFX和C_Addr都属于该域;(3)KMS向所属自治域的每个PE通告一条通配映射项,通配映射项的C_Addr为KMS的地址;(4)PE之间不进行映射信息交互;(5)相邻自治域的KMS之间会建立EBGP邻居关系,并通过扩展的EBGP协议交互映射信息;(6)KMS之间相互传递各自拥有的全部映射信息,保证映射信息在不同自治域的KMS间逐个传递.根据图1所示拓扑,通过PE1~PE3和KMS1~KMS2分析AMIA模型的映射信息传播过程.令PE1、PE2、PE3核心网地址分别为C_Addr1、C_Addr2、C_Addr3,它们连接了边缘网主机H1、H2、H3,各主机所属的地址前缀分别为E_PFX1、E_PFX2、E_PFX3.令KMS1和KMS2的核心网地址为C_Addr4和C_Addr5.PE通过边缘网路由协议获得该边缘网路由信息,并针对每个路由前缀生成一条“边缘网地址前缀到核心网地址”的本地映射项.其中,PE1会生成主机H1所属边缘网地址前缀的映射项:E_PFX1→C_Addr1.同理,PE2和PE3也会生成本地映射项:E_PFX2→C_Addr2和E_PFX3→C_Addr3.并将报文转交给KMS处理.角色PE1E_PFX1→C_Addr1、E_PFX2→C_Addr2、PE2E_PFX1→C_Addr1、E_PFX2→C_Addr2、PE3E_PFX3→C_Addr3、E_PFXany→C_Addr5KMS1E_PFX1→C_Addr1、E_PFX2→C_Addr2、KMS2E_PFX1→C_Addr1、E_PFX2→C_Addr2、Page4AMIA模型中,报文转发过程分为两种情况:域内通信和域间通信.域内通信是指通信两端在同一自治域的不同边缘网,转发过程中发送端所属PE路由器完成报文的封装,接收端所属PE路由器进行解封装.域间通信是指通信两端分属不同自治域,由于PE路由器没有全网的地址映射信息,需要KMS路由器作转发跳板,转发过程会出现两次报文封装和解封装.发送端主机所属PE路由器完成报文的第一次封装,报文送到源端所在自治域的KMS路由器进行第一次解封装;接着,仍是这台KMS路由器进行第二次封装,报文送到目的端所属PE路由器进行第二次解封装.PE或KMS进行报文封装时,根据报文边缘网目的地址进行映射表匹配,当有多条映射项的E_PFX与该地址匹配时,选择E_PFX前缀长度最长的映射项作为匹配结果.继续以图1所示拓扑及表1所述映射表为依据介绍地址空间分离网络中报文转发过程.首先分析H1到H2的域内通信过程,转发步骤如下:1.H1发送原始报文,源地址为H1,目的地址为H2;2.报文到达PE1(路由所致,PE1会向边缘网发布默认路由),PE1根据报文目的地址H2查询映射表,匹配映射项“E_PFX2→C_Addr2”;3.PE1对原始报文进行封装,封装报头源地址为C_Addr1,目的地址为C_Addr2,PE1发出封装报文;PE2将原始报文送达目的主机H2.4.PE2收到封装报文并进行解封装,得到原始报文,H2到H1的反向通信过程与上述步骤类似,是它的逆过程.H1和H2的双向域内通信过程如图2所示.骤如下:接着,分析H1到H3的域间通信过程,转发步1.H1发送原始报文,源地址为H1,目的地址为H3;2.报文到达PE1,PE1根据报文目的地址H3查询映射表,匹配通配映射项“E_PFXany→C_Addr4”;3.PE1对原始报文进行封装,封装报头源地址为C_Addr1,目的地址为C_Addr4,PE1发出封装报文;4.KMS1收到封装报文并进行解封装,得到原始报文;KMS1继续根据报文目的地址H3查询映射表,匹配通配映射项“E_PFX3→C_Addr3”;5.KMS1对原始报文进行封装,封装报头源地址为C_Addr4,目的地址为C_Addr3,KMS1发出封装报文;PE3将原始报文送达目的主机H3.6.PE3收到封装报文并进行解封装,得到原始报文,需要注意,H3到H1的反向通信过程中,封装/解封装的实施点并不同于上述步骤.其中,PE3进行第一次封装,KMS2进行第一次解封装,并继续第二次封装发送给PE1,由PE1完成第二次解封装.H1和H3的域间通信过程如图3所示.AMIA模型中,每一个KMS设备需要负责所属域端系统的所有域间流量的转发,负载较重,需要部署处理能力较强的高性能网关设备充当KMS.当然,我们还可以通过在一个域中部署多个KMS进行负载分摊.负载策略可简单根据地址前若干比特位不同实施流量分摊,本文不做详细阐述.3.1映射项存储分析映射项存储分析有表2定义的评价参数.高端路由器的存储资源紧缺,主要针对数据层转发表项的存储,涉及TCAM和SRAM等芯片.地址空间分离模型的映射表项也需占用上述资源,所以本节分析AMIA模型在数据层的硬件存储消耗.现有非缓存方式的映射地址模型主要有Softwire[7]涉及的PE全存储模型CSPE(CompleteStorageonPE).全网的映射表项数为所有自治域映射项总和:i=1∑Ei∑sPi(j).在CSPE模型中,所有PE路由器转发模块都要存储其它PE产生的映射项,本地产生的映射项无需在自身数据层存储.全网的PE路由器数量为∑s射项总和TCSPE满足式(1).j=1TCSPE=∑sPage5参数/变量s全网自治域数量Ei第i个自治域中边缘网数量(PE个数)Ea平均每个自治域中边缘网数量(PE个数)Pi(j)第i个自治域中第j个边缘网生成的前缀路由数Pa平均每个边缘网生成的前缀路由数PEi(j)第i个自治域中第j个PETCSPECSPE模型全网存储的映射项数TAMIAAMIA模型全网存储的映射项数便于分析,对自治域中边缘网数和边缘网路由数取平均值分析,则TCSPE满足式(2).j=1AMIA模型中,全网映射表项数仍然是i=1∑Ei∑sPi(j),但只有KMS存储全网映射项.所以,s个自治域的s个KMS存储的映射项总数为i=1∑Eis×∑s∑EiPi(j),每个PE的数据层只存储本域其它PE产j=1生的映射项以及一条由KMS发布的通配映射项.即PEi(k)存储的映射项:j=1所以,第i个自治域中Ei个PE总共存储的映射表项数为(Ei-1)×∑Ei存储的映射表项数为∑s所以,AMIA模型全网所有路由器存储的映射项总和TAMIA满足式(4),包括PE和KMS的存储映射项.TAMIA=∑s便于分析,对自治域中边缘网数和边缘网路由数取平均值分析,则AMIA模型存储的映射项总和TAMIA满足式(5).TAMIA=s×Ea×(Ea-1)×Pa+s×Ea+s2×Ea×Pa=s×E2a×Pa+s2×Ea×Pa+s×Ea-s×Ea×Pa继而分析AMIA模型和CSPE模型的存储映射项的差值,见式(6).TCSPE-TAMIA=(s2×E2a×Pa-s×Ea×Pa)-(s×E2a×Pa+s2×Ea×Pa+s×Ea-s×Ea×Pa)=(s×Ea-s-Ea)×(s×Ea×Pa)-s×Ea=((s×Ea-s-Ea)×Pa-1)×(s×Ea)(6)从式(6)可以看出,只要s、Ea两个参数大于2,式(6)就为正值.而且,式中3个参数的值越大,式(6)差值越大.显然,真实互联网中s和Ea都远大于2,所以AMIA较之CSPE模型在映射项存储数量上有很大的减少.由于一个边缘网产生的路由数一般为1或2,图4给出了针对平均边缘网路由数为1和2以及自治域数分别为10和100时,两种模型在不同边缘网数量情况下需要存储映射项数的分析.显然,无论针对哪种情形,AMIA模型全网需要存储的映射项数都要远远少于CSPE模型,有较好的存储性能.3.2AMIA模型性能评价相对现有其它方案,AMIA模型在映射项存储性能、控制协议、表项维护、端系统用户体验、网络安全等方面都有了较大的改善,并容易在真实网络实施,其付出的代价只是少量的冗余转发路径.下面从不同角度对AMIA模型与其它方案进行具体比较分析,并有表3所述总结.(1)映射项存储性能.由于一个边缘网一天的目的地址访问数一般高达106级别[10],所以缓存映射项的模型(如LISP和APT)若想达到较好的转发效果,在PE端需要维护一个容量较大的映射项缓Page6模型存储APT一般复杂达到小有(少量)较差LISP一般非常复杂无法CSPE差简单达到小AMIA好简单达到小存.对于AMIA模型,由于一个边缘网产生的路由数通常为1~2条,而平均一个自治域的边缘网数不超过100.所以,根据式(3)可得AMIA模型PE的映射项存储量不超过200.由于LISP或APT都会为每个自治域部署至少一个存储全网映射项的映射服务器,等效于AMIA模型中的KMS映射项存储,所以AMIA模型在映射项存储总量上也少于LISP或APT.结合3.1节,可知CSPE的映射项存储性能较差.所以,AMIA模型在映射项全网存储或平均每个PE存储等方面,都具有最好的存储性能.(2)控制协议及表项维护.AMIA模型和CSPE模型都是通过对BGP协议扩展完成映射信息的传递,功能简单易实施.APT模型中DM间的信息交互通过一种新型的类似OSPF的洪泛协议完成,而且DM向PE通告映射信息过程需要有抑制机制,控制协议较为复杂.LISP为映射信息交互设计了一种全新的控制协议,而且LISP有多种映射信息存储模式和获取机制,协议极为复杂,难以被广泛接受.对于数据层映射项维护,AMIA模型和CSPE模型与现有单播转发表维护类似,完全根据控制层协议的指示进行表项增、删、改.相对而言,LISP和APT由于采用映射项缓存机制,需要根据数据转发过程中映射项命中频率等参数对缓存进行维护,较为复杂.(3)线速转发.LISP模型中,当PE缓存没有待转发报文所需的映射项时,需要数据层通告控制层发送映射信息请求并等待回应.也就是说,LISP模型中PE数据层无法为所有数据提供线速转发支持.AMIA、CSPE和APT等模型都是通过查询映射项进行报文封装来完成数据在核心网的传输,根据本文第5节的实验,说明都能达到线速转发.然而,APT模型中DM数据层在对封装报文重新封装并转发的同时,需要向控制层提交相关信息,使其向报文源端PE发送映射信息.这种数据层对控制层的反向影响,需要设备在硬件数据层付出较大的逻辑处理开销.(4)通信时延.数据封装及解封装会给转发增加μs级的设备转发时延,但这对端到端路径转发时延来说可忽略不计.CSPE没有任何转发路径冗余.AMIA和APT可能出现转发路径冗余,但只会发生在一个自治域内部,发生在域内的转发路径冗余带来的通信时延较小,端用户不易感知.而且,可以通过对KMS和DM优化部署来减少或完全规避这种额外时延.然而,LISP模型中类似DNS的映射信息查询,在每个连接初始流量的数据转发时,会给端用户带来明显的时延.(5)路径冗余.路径冗余是指地址空间分离网络中端到端的转发路径与传统路由转发路径相比,是否在转发跳数上有所增加.LISP和APT模型在PE没有缓存所需的映射项时,都会产生转发路径冗余,反之则不会有路径冗余.AMIA模型中,对于自治域内部端到端通信没有任何转发路径冗余,对域间通信可能产生转发路径冗余.不过,可以将KMS部署在自治域出口来减小甚至消除AMIA模型的转发路径冗余.CSPE模型针对所有通信都不会产生转发路径冗余,但这是以PE存储全网映射项作为代价.(6)网络安全.本文主要考虑用户通过发送目的地址无法命中映射表的攻击报文给网络带来的破坏性结果,如带宽消耗、产生无效映射信息交互等.CSPE模型防御攻击能力最好,PE拥有全部映射信息,一旦PE查询映射表失败则立刻丢弃报文.AMIA模型和APT模型中,每个PE都有通配映射项,攻击报文在PE中会匹配通配映射项转发到KMS,浪费了网络带宽.当然,AMIA模型的攻击报文最终会在KMS中因映射表匹配失败而丢弃.不过,APT中DM会根据报文回送映射信息的RE-PLY报文,使得PE缓存无效表项,造成无效存储.LISP防范能力最差,收到攻击报文会使PE与映射系统通信并缓存无效表项,大量攻击报文易导致PE拒绝服务.4AMIA模型实现设计本文以边缘网为IPv4地址空间,核心网为IPv6地址空间为例,研究AMIA模型的实现机制.AMIA模型需要在每个自治域设置一台高性能路由器作为KMS,并让KMS和本域PE之间以及相邻域的KMS之间建立带有扩展能力的IPv6BGP邻居关系.传统IPv6BGP连接用来传播IPv6地址前缀和IPv6下一跳信息,而AMIA模型需要对BGP进行扩展,使其能够携带“E_PFX→C_Addr”映射信息.本文实例中,E_PFX是IPv4地址前缀,C_Addr是IPv6地址.BGP扩展主要包括两方面:Page7(1)扩展能力协商.AMIA模型利用OPEN报文的可选参数“OptionalParameters”描述BGP实例的映射信息交互能力,双方都有扩展能力的邻居才能收发映射信息;(2)映射信息通告.利用UPDATE报文的路径属性“PathAttributes”描述通告或撤消通告的IPv4地址前缀信息[8].除了通配映射项由KMS直接发布,普通映射信息总是在PE路由器上产生,并通告给本域的KMS,由KMS向外发布.PE中映射信息是由IPv4路由管理将IPv4前缀通告给IPv6BGP模块生成.考虑实施的高效性,映射信息集成在IPv4转发表中存储.地址映射项区别于普通IPv4转发项之处包括:(1)映射项转发标志位“M”;(2)下一跳是IPv6地址.集成PE和KMS功能的多功能路由系统MFRT功能结构如图5所示,下面根据重要事件处理过程描述该设备的功能特征.(1)学习到IPv4路由.该事件发生在PE,系统学习到IPv4路由.一方面,按传统模式处理,生成IPv4转发项.另一方面,路由管理将IPv4路由前缀通告IPv6BGP模块生成映射信息,继而向它的KMS邻居发送.(2)学习到IPv6路由.该事件发生在PE或KMS设备上,完全按照传统模式处理,生成IPv6转发表项.(3)学习到4~6映射信息.4~6映射信息是通过扩展BGP学习,该事件可能发生在PE或KMS.①若PE收到4~6映射信息,对端BGP邻居肯定是本域的KMS,PE将映射信息存储于IPv4转发表并设置标志位“M”,不再向外通告.②若是KMS收到4~6映射信息,首先将映射信存储于IPv4转发表并设置标志位“M”,并向其它KMS邻居通告.另外,KMS还需确定是否将收到的映射信息向本域PE广播.分析对端邻居角色,如果是PE发来的本域映射信息,则需向本域其它PE邻居通告.相反,如果是KMS邻居发来的其它域映射信息,则无需向本域的PE邻居发送.(4)收到IPv4报文.一般发生在PE.根据最长前缀匹配原则查询IPv4转发表,若查得普通IPv4转发项则按传统模式转发报文.若查得转发项具有封装标志“M”,则说明匹配的是一条映射项,需要进行IPv6封装,封装后进行IPv6转发表查询,并按IPv6查询结果发送报文.具体过程参见图6.(5)收到IPv6报文.事件可能发生在PE或KMS.查询IPv6转发表,若报文目的地址不是本地地址则正常转发.否则,分析其是否封装报文.对于非封装报文,则按传统模式本机接收.对于封装报文,解封装得到内层IPv4报文,并进行IPv4转发处理.后续IPv4报文处理过程和上述功能特征(4)一样,具体参见图6.5实验及性能分析本文基于VegaNet虚拟路由器[9],按照第4节所述机制,设计实现了MFRT原型系统.VegaNet是一种为网络研究提供真实实验环境以及对核心网络进行模拟分析的高性能虚拟网络,它基于CER-NET2的实施能提供一个接近于真实网络状况的网络实验环境,并能灵活支持对核心网络的模拟分析.VegaNet的核心设备———虚拟路由器,基于真正的商业路由平台实现,支持高带宽的虚拟网络流量.首先,在实验室通过测试仪对PE及KMS转发性能进行测试.IXIA测试仪的两个千兆接口分别连接MFRT的千兆接口.测试仪从一个接口发包,通过MFRT系统转发,从另一接口接收报文.MFRT被测试的转发模式包括:模式1,对IPv4报文进行IPv6封装再转发;模式2,对IPv4inIPv6封装报文解封装再转发;模式3,对IPv4inIPv6封装报文解封装再二次封装并转发.测试仪发送64Bytes~1478Bytes随机大小报文,测试结果如图7所示.统计3种转发模式平均转发能力分别为798Mbps、910Mbps、895Mbps.由于转发性能是针Page8对设备接收报文统计,而模式1是对原始IPv4报文进行封装后转发,转发过程增加了报文大小.考虑任何地址空间分离模型都要付出的封装代价,说明支持AMIA模型的MFRT系统各种转发模式基本都能达到线速转发能力.接着,继续基于上述测试环境分析单台MFRT设备的转发时延.IXIA测试仪通过一个接口发送不同字节大小的报文,并在另一接口收包以获取MFRT的报文转发时延,测试分别针对普通IPv4转发、普通IPv6转发和AMIA模型封装转发进行.针对不同大小报文的MFRT转发时延如图8所示,相对于普通的IPv4和IPv6转发,AMIA模型的数据转发时延会略有增加,但最高约为80μs.微秒级的设备转发时延对于端到端通信至少毫秒级的路径传输时延可以忽略,所以MFRT的报文处理不会增加网络应用的额外延迟.其次,本文利用现有VegaNet完成了AMIA模型基于CERNET2的真实部署,通过8个虚拟路由器在CERNET2构建了如图9所示的实验拓扑.实验网由两个AS组成,每个AS包括4台虚拟路由器,D、E分别充当两个AS的KMS路由器,其它6台设备的角色为PE.另外,有4台主机分别下连在4个PE的边缘网中.图9中椭圆范围内接口配置IPv6地址,椭圆外部接口配置IPv4地址,即主机和与之相连路由器的接口为IPv4地址,其它均为IPv6地址.所有虚拟路由器都按照本文的AMIA模型实现,并按图9中连线建立BGP邻居关系.实验中,PE上配置IPv4静态路由生成本地映射表项并向外通告.分析PE上配置不同数量的静态路由时,全网存储的映射项数量和PE平均存储的映射项数量.接着,按照图10所示将KMS撤除,其它6个PE进行BGP全连接,按CSPE模型进行映射信息交互,同样分析相关映射项存储.实验结果如图11所示,无论PE平均存储映射项数还是全网映射项存储数,AMIA模型相对CSPE模型均有减少.结合3.2节分析可知,这种差异随网络规模增大越为明显.最后,在图9中主机间进行了多种IPv4应用测试:PING、FTP、WEB等常用网络应用程序,各项测试均能正常完成,说明了AMIA模型的功能可用性.6总结现有地址空间分离模型尚存许多不足:控制协议复杂、映射项缓存机制需要较大的缓存维护开销、影响端系统网络用户的网络体验等.本文设计了一种新型的面向地址空间分离网络的域间地址映射模型:AMIA,它以少量冗余转发路径为代价实现互联网边缘网地址和核心网地址的空间分离.AMIA通Page9过BGP协议扩展完成映射信息的交互,通过隧道封装完成边缘网分组在核心网的传输.AMIA模型无需任何缓存机制,并且具有很好的映射项存储性能.它的映射信息交互关系简单易实施,具有很好的网络攻击防范能力.AMIA模型区别于其它相关模型的另一贡献还在于它不会影响端到端用户的网络体验.本文基于VegaNet虚拟路由器,设计并研制了集成AMIA模型多种角色功能的多功能路由系统MFRT.实验表明,多功能路由系统在实施AMIA模型数据转发时能达到线速处理及最高80μs的转发时延.AMIA模型基于CERNET2进行了实验网部署,通过实验网的运行及相关实验,进一步验证了AMIA模型的高效存储性能及功能可用性.致谢本论文工作在清华大学完成,感谢清华大学网络研究所的支持!
