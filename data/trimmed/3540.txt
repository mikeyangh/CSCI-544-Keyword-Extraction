Page1一种基于关键路径分析的CPU-GPU异构系统综合能耗优化方法林一松杨学军唐滔王桂彬徐新海(国防科学技术大学并行与分布处理国家重点实验室长沙410073)摘要GPU强大的计算性能使得CPU-GPU异构体系结构成为高性能计算领域热点研究方向.虽然GPU的性能/功耗比较高,但在构建大规模计算系统时,功耗问题仍然是限制系统运行的关键因素之一.现在已有的针对GPU的功耗优化研究主要关注如何降低GPU本身的功耗,而没有将CPU和GPU作为一个整体进行综合考虑.文中深入分析了CUDA程序在CPU-GPU异构系统上的运行特点,归纳其中的任务依赖关系,给出了使用AOV网表示程序执行过程的方法,并在此基础上分析程序运行的关键路径,找出程序中可以进行能耗优化的部分,并求解相应的频率调节幅度,在保持程序性能不变的前提下最小化程序的整体能量消耗.关键词异构系统;GPU;AOV网络;动态电压/频率调节;低功耗优化1引言半导体工艺的发展使得芯片上集成的晶体管数目越来越多,目前已达到10亿的量级,处理器的计算能力也越来越强.图形处理器(GraphicsProcessingUnits,GPU)由于最初仅用于加速图形处理,结构比较简单,芯片资源可以被更为有效地用于提升计算能力,因此目前GPU普遍比通用处理器的性能高出一个量级.此外,随着GPU的编程环境不断完善,使用GPU作为CPU的加速器构造异构并行计算系统成为高性能计算领域的热点方向[1].例如最新发布的天河-1A系统就采用CPU-GPU异构系统结构,峰值计算性能超过4PFlops,位列2010年12月发布的Top500超级计算机排行榜之首①.由于采用了专用的加速部件,异构系统的性能/功耗比一般高于传统的同构系统[2].但不可否认的是,其功耗问题依然很严峻.GPU芯片的计算单元密度高,发热量较大,其绝对功耗超出通用处理器.在构建大规模计算系统时,GPU的功耗将提高计算成本,同时也会降低系统的可靠性,因此研究异构系统的功耗优化问题具有重大的意义.现有的面向CPU-GPU异构系统的低功耗优化研究多关注针对单个任务的划分问题:对于给定的任务,如何在CPU和GPU之间进行任务划分,使得异构系统在满足性能(能量)约束的条件下,取得能量(性能)最优的问题.这里的任务一般是指没有依赖关系的循环迭代,可以任意地在CPU和GPU之间进行划分.然而,很少有工作针对CPU-GPU异构系统的特点研究整个程序的功耗优化问题.CPU-GPU异构系统上执行的程序具有其自身的特点.对于给定的一个CPU-GPU程序来说,其中的任务大致可以分为3个部分:CPU计算部分、GPU计算部分和CPU-GPU通信部分.在某些条件下,这3种任务可以并行执行.此外,数据依赖、资源冲突等原因还使得各任务间存在一定的先后依赖关系.因此对异构系统进行能耗优化,建立能耗优化模型的关键在于建立CPU-GPU程序运行过程的抽象表示,该抽象表示需要描述CPU计算、GPU计算和CPU-GPU通信这3个部分以及它们之间的依赖和并行关系.基于该抽象表示才能进一步建立能耗优化的方法.顶点活动网AOV(ActivityOnVertexnet-work)是描述一项工程或系统进行过程的有效工具.它们描述的系统运行过程中通常包含若干活动,每个活动都持续一定的时间,某些活动之间可以并行执行,某些活动之间存在依赖关系.这一点和本文面向的CPU-GPU异构系统上程序的执行过程有相似之处,但也不完全相同.后者所描述的任务依赖情况更加复杂.此外,AOV网是一种求解系统关键路径的有效方法,而程序的关键路径正是进行功耗优化的重要依据.值得说明的是,AOV网和传统的程序优化经常使用的任务图(TaskGraph)是一种类似的数据结构.从本质上说,使用结点表示任务的任务图也是一种AOV网,在面向具体的应用领域时可以有针对性地对任务图进行附加的定义和操作.而本文只是抽取这种数据结构最基本的特征,即通过任务的时间和依赖关系描述系统运行过程来描述GPU程序的执行过程,并利用该数据结构最基本的分析方法来分析程序的关键路径,从而为功耗优化建模提供依据.具体地说,本文针对CPU-GPU异构系统程序运行的特点,研究如何使用AOV网描述GPU程序的运行过程,并在此基础上对程序的能耗优化问题进行建模和求解.本文的创新点主要包括以下几点:(1)面向典型的CPU-GPU异构系统编程模型CUDA[3],分析并归纳了其中包含的4种任务依赖关系.(2)给出了将CUDA程序描述为AOV网的两个算法;(3)给出了基于AOV网的CUDA程序能耗优化方法.本文第2节简要介绍CUDA程序运行模型并对提出能耗优化的问题;第3节给出基于AOV网络的能耗优化求解方法;第4节给出案例分析;第5节介绍相关工作;最后总结全文.2问题提出本节首先简单介绍CPU-GPU异构体系结构和CUDA编程模型,然后面向能量消耗分析CUDA程序在CPU-GPU异构系统上执行时存在的负载不平衡的问题,进而给出功耗优化的问题描述.2.1程序模型由CPU和GPU构成的异构并行系统结构如图1所示.CPU和GPU一般通过外部总线互连,它们各自也拥有独立的片外DRAM存储器,相互之间可以以DMA的方式进行数据通信.①http://www.top500.org/lists/2010/11Page3CPU和GPU以Master-Slaver的方式协同工作,其中CPU是主控端,负责组织数据和调度GPU的执行.GPU上执行的代码被组织成一系列Kernel函数,CPU以函数调用的方式调度GPU执行.图2给出了一个典型的CUDA程序结构及执行示意图.左边的框图为CUDA程序的伪码,其中block1~4为GPU无关的计算代码,我们称为“CPU任务”.涉及GPU操作的部分包括在CPU和GPU存储空间之间传输数据以及启动Kernel函数的执行,我们将Kernel函数的执行称为“GPU任务”,而数据在CPU和GPU之间的传输称为“通信任务”.图2一个典型的CUDA程序及执行示意图由于CPU和GPU的执行部件相互独立,并且数据通信可以通过单独的DMA硬件完成,因此只要不存在数据依赖,CPU任务、GPU任务和通信任务是可以同时执行的.为此CUDA提供了异步的函数调用接口,在调用Kernel函数完成GPU计算和CudaMemcpy完成数据通信时,可以将其指定为异步模式(以“Async”为后缀),使得它们可以和其后的CPU代码并行执行.此外,异步的函数调用之间如果没有资源冲突,即不占用同一种硬件资源,也可以同时执行.为了保证程序正确执行,CUDA使用如下同步机制描述异步执行的函数和其后的代码之间的依赖关系:(1)为每一个异步的通信任务和GPU任务指定一个任务流(taskstream),同一个任务流中的任务必须按照到达的顺序依次执行,而不同的任务流之间则没有限制.(2)在CPU端的程序中调用同步函数为每个任务流指定一个同步点,在同步点处CPU必须等待指定的任务流中所有的任务执行完毕才能继续执行.我们将同步函数称为“同步任务”.同步任务又可以分为局部同步任务和全局同步任务,前者是指针对某个指定的任务流的同步,而后者是指针对所有任务流的同步.此外,CUDA还规定,除了显式地调用全局同步函数外,没有指定为异步模式的通信和GPU任务也将阻塞所有的任务流直至它们全部完成,即在这些任务之前存在一个隐含的全局同步点.2.2能耗优化问题处理器的功耗包括静态功耗和动态功耗,其中静态功耗取决于芯片的电气特性,而动态功耗则取决于芯片工作的电压和频率,一般来说后者是低功耗优化的重点.动态电压/频率调节DVFS(DynamicVoltage/FrequencyScaling)[4]是一种广泛使用的动态功耗优化技术,它通过在一定范围内降低处理器的电压/频率以减少其能量的消耗.通常,CMOS电路的核心电压和其工作频率一般要同时调节才能保证电路正常工作,它们之间满足f∝(V-Vt)γ/V,其中Vt是阈值电压,γ为工艺相关的参数.通常情况下Vt远小于V且γ∈[1,2].本文假定γ=2,此时频率f和电压V近似为线性关系.此时根据CMOS电路的功耗公式P=αCV2f,功耗P可以看成和频率f的立方成正比,即P∝f3.此外,我们还近似地认为程序在处理器上的执行时间和处理器的工作频率成反比,即T∝f-1,因此程序在处理器上运行所消耗的能量满足E=PT∝f2.综上,本文在进行能耗优化时,只考虑对处理器频率的调节.注意到,这里对CMOS电路以及处理器的功耗计算模型进行的假设只是为了简化后续的描述,并不影响本文所提出的使用AOV网络对程序进行分析并构建功耗优化模型的方法.根据2.1节的描述,CPU任务、GPU任务和通信任务三者间的异步执行意味着CPU和GPU间可能存在负载不平衡的情况,即在某个同步点处CPU(GPU)由于提前完成任务而等待GPU(CPU)任务或通信任务的完成.从能量消耗的角度看,这种情况不是能量最优的:完成较早的任务可以以较低的频率运行,使得它和完成较晚的任务同时到达同步点,此时在不延长整体执行时间的情况下,可以降低程序整体的能量消耗.Page4一般来说,CUDA程序在CPU-GPU异构系统上运行带来的总能量消耗为E=Eactive+Estatic=∑EC+∑EG+∑ET+PstaticT,其中EC,EG和ET分别代表CPU任务,GPU任务和通信任务的能量消耗.在本文的模型中,可以通过DVFS技术调节的是CPU和GPU的工作频率,因此通信部分的动态能量消耗不变;此外,能耗优化的前提是保持程序的总运行时间不变,因此由静态功耗带来的能量消耗也可以视为常数.此时,程序的能量最优问题等价于在程序执行总时间不变的前提下最小化CPU任务和GPU任务的总能量消耗.需要注意的是,这里所指的程序执行总时间是指程序在CPU和GPU分别处于最高工作频率下的执行时间.使用DVFS技术调节CPU或GPU处理器的频率时需要考虑两方面的问题:寻找调节时机和确定调节幅度.程序运行过程中,某些任务的执行时间直接影响整个程序的执行时间,我们称其为“关键任务”.为保持程序运行时间不变,我们不能对关键任务进行频率调节.因此寻找调节时机是指在程序中寻找不影响程序总体执行时间的前提下可以进行频率调节的CPU任务和GPU任务,我们统称为“非关键任务”;而确定调节幅度则根据非关键任务的执行时间以及不影响程序总时间时该任务最大可能的执行时间确定处理器频率调节的幅度.因此,对于给定的CUDA程序,其面向CPU-GPU异构系统的能耗优化问题可以描述为:在程序中寻找一组非关键任务并确定相应的CPU或GPU频率调节系数,使得程序在CPU-GPU异构系统上运行的总时间不变而能量最优.本文求解这一问题的思路为(1)首先从程序中分离出不同类型的任务,然后将运行的过程描述为任务之间的依赖关系,构造表示程序运行过程的AOV网络.(2)其次对AOV网络进行分析,确定关键路径,则非关键路径上的CPU和GPU任务为可以进行频率调节以节省能耗的非关键任务.(3)最后根据关键路径上任务执行的时间确定非关键任务可以放松的执行时间,从而求解每个任务的处理器频率调节幅度以最小化能量的消耗.3问题求解3.1CUDA程序的AOV网表示由于CUDA程序运行过程中存在复杂的并行和同步机制,因此寻找程序中所有的非关键任务的难点在于通过某种抽象表示将程序中任务间的并行和依赖关系描述出来.本文采用AOV网描述CUDA程序中任务之间的并行和依赖关系.CUDA程序中任务之间的并行与依赖关系比较复杂,其中并行关系主要包括CPU任务、GPU任务和通信任务之间的并行,而依赖关系则可以归纳为以下4种:(1)程序依赖(programdependency),是指由程序序决定的依赖;(2)流依赖(streamdependency),是指同一个任务流内部的任务之间的依赖;(3)同步依赖(synchdependency),是指在同步点处,除0号任务流外其它任务流中的任务与同步任务之间的依赖①;(4)资源依赖(resourcedependency),是指使用同一种资源,如通信部件或GPU的多个任务之间存在的依赖关系.注意到,程序依赖、流依赖和同步依赖都描述了一种先后依赖关系,即任务间的先后关系,而资源依赖则描述了任务间的互斥关系.传统的AOV网可以表示先后的依赖关系,而无法表示互斥关系,因此我们需要将互斥关系转化为先后依赖关系才能完整地描述CUDA程序的行为.下面我们首先根据CUDA程序构造初步的AOV网,我们称为任务依赖图,其中包含前3种依赖关系,然后再对任务依赖图进行处理,加入资源依赖关系的描述.定义1.任务依赖图(TaskDependencyGraph).程序P的任务依赖图G=(V,E)是一个有向无圈图,其中V为结点集合,表示程序中的任务,E为连接结点的有向边,表示任务之间的先后依赖关系.每个结点可以用一个二元组表示v:〈type,time〉,其中type表示结点的类型,包括CPU任务、GPU任务、通信任务和同步任务,分别记为C、G、T和S;而time表示该任务需要执行的时间.e:〈v1,v2〉∈E表示v2必须在v1完成之后才能开始.由于同步任务只为描述异步的GPU、通信任务和CPU任务之间的同步关系,它本身的执行时间为0;通信任务的时间可以根据带宽和通信量计算得出;而CPU任务和GPU任务的时间可以参照已有的性能模型[5-6]进行估算.关于任务执行时间的静态分析不是本文研究的重点,因此这里不展开讨论.对于图2中所示的程序段,假定所有的通信任①同步任务由CPU执行,默认在0号任务流中,因此0号任Page5务和GPU任务都指定为异步的,并且每组和GPU相关的两个任务分别放入两条任务流中.此外,还假定程序段结束处调用了全局的同步函数.其任务依赖图如图3所示.如图3所示,程序中包含3条任务流,根据CUDA程序的定义,所有的CPU任务、同步任务以及同步模式的通信、GPU任务都被划入0号任务流.下面讨论任务依赖图的构造方法.假定给定CUDA程序的指令序列中和GPU相关(通信函数、Kernel函数、同步函数)的指令有P个,并且这些指令将CPU指令序列划分为Q段连续的子序列,我们将每个连续的CPU指令子序列和每个GPU相关的指令都对应为一个任务,因此整个程序总共包含P+Q个任务.记=(M1,M2,…,MP+Q)为按照程序序排列的任务序列,对于1iP+Q,Type(Mi)为任务的类型,取值范围为{C,G,T,S},分别表示CPU任务、GPU任务、通信任务和同步任务,Time(Mi)为任务所需的时间.此外,记Q(Mi)为任务Mi所属的任务队列的编号,对于所有的非异步任务,包括CPU任务、同步的GPU、通信任务以及同步任务,都有Q(Mi)=0.除了默认的0号任务流外,假定程序中一共包含q条任务流.特别地,对于同步任务,记TS(Mi)为该同步函数所同步的任务流的编号,若同步函数是全局同步函数,则记TS(Mi)=0.根据CUDA的定义,同步的GPU和通信任务也具有全局同步的作用,因此对于它们也有TS(Mi)=0.算法1给出构造任务依赖图的具体过程.算法1.构造任务依赖图.1.Input:=(M1,M2,…,MP+Q)2.Output:G=(V,E)3.letT0,T1,…,Tqbethelatestnodeineachtask4.T0,T1,…,Tq←//meansnotaskinthestream5.V←∪1iP+Q6.fori=1toP+Qdo7.ifT0≠then8.E←E∪{e:〈T0,vi〉}//aprogramdependency9.endif10.ifQ(Mi)≠0then//forasynchronoustask11.ifTQ(Mi)≠then12.E←E∪{e:〈TQ(Mi),vi〉}//anstreamdependency13.endif14.elseifTS(Mi)=0then//forglobalsynchronous15.forj=1toqdo16.ifTj≠then17.E←E∪{e:〈Tj,vi〉}//ansynchdependency18.Tj←19.endif20.endfor21.else//forlocalsynchronous22.E←E∪{e:〈TTS(Mi),vi〉}//ansynchdependency23.TTS(Mi)←24.endif25.TQ(Mi)←vi26.endfor从算法1可以看出,在所有的任务按照程序序排列构成的序列中,所有的有向边都是从一个编号较小的结点指向一个编号较大的结点,这就保证了依赖图中必然不包含回路,是有向无圈图.生成任务依赖图后,我们再考虑可以并发执行的任务之间的资源冲突,即在任务依赖图中加入因资源冲突导致的任务间的依赖关系.考虑资源冲突的情况下,程序的实际执行过程依赖于一定的冲突仲裁机制.本文的模型中我们假定GPU运行时采用如下冲突仲裁机制:若某一时刻任务流中同时存在多个满足先后依赖关系但存在资源冲突的任务,则优先选择任务流编号较小的任务执行.例如,当CPU任务C1执行完成后,满足依赖关系的任务包括T1、T2和C2,其中T1和T2同为通信任务,存在资源冲突不能同时执行,此时优先执行T1.当两个任务间存在潜在的资源冲突时,必须为其定义一个先后的依赖关系,因此在任务依赖图中加入资源依赖的目标是:对于任意两个任务Mi和Mj,如果它们使用了相同的资源(GPU或通信部件),则它们之间必须存在通路.为了缩小考察的任务范围,我们首先分析任务依赖图中一定存在通路的情况.根据算法1中添加依赖边的方法可以得知AOV网满足以下3个性质.性质1.若Mi和Mj中至少有一个是同步模式的任务,则根据CUDA的规定,同步模式的GPU和通信任务本身隐含着一次全局同步,换言之,它们是任务依赖图中从程序开始到程序结束的必经结Page6点,它们和任意结点间都存在通路;性质2.若Mi和Mj都是异步模式的任务,此时如果Q(Mi)=Q(Mj),即两个任务处于同一条任务流中,则它们之间必然存在通路;性质3.否则,Mi和Mj都是异步模式的任务,且Q(Mi)≠Q(Mj),此时不妨假定在程序序中Mi早于Mj(记为MiMj).根据算法1的第8行可知,对于异步模式的任务Mj,必然存在一条有向边从某个位于0号任务流中任务指向Mj,记这个0号任务流中的任务为Pre(Mj);此外,记Suc(Mi)为由Mi可达的程序序最小的0号任务流中的任务.此时,从Mi到Mj存在通路的等价条件为Suc(Mi)Pre(Mj).只要符合上述3个条件之一,任务Mi和Mj之间一定存在通路,因此分析资源冲突时可以忽略这些情况.根据本文模型中对冲突仲裁机制的假设,加入资源依赖的过程可以简单描述为:对于给定的任务依赖图G,如果两个异步模式的GPU或通信任务Mi和Mj使用的资源相同,即Type(Mi)=Type(Mj),且Mi和Mj之间不存在通路,则计算Mi和Mj最早可能开始执行的时间(EarliestStartTime,EST),分别记为EST(Mi)和EST(Mj),若EST(Mi)=EST(Mj),则添加一条有向边,从任务流编号较小的任务指向任务流较大的任务,表明优先执行任务流编号较小的任务;若EST(Mi)≠EST(Mj),不妨假设EST(Mi)<EST(Mj),则添加一条有向边,从任务Mi指向任务Mj,表示Mi抢占了资源,Mj必须等待Mi完成后才能开始.对于给定的任务依赖图G=(V,E),其中任务Mi的最早可能开始执行时间EST(Mi)可以由如下递推公式求出:{EST(M1)=0EST(Mi)=max〈vj,vi〉∈E{EST(Mj)+Time(Mj式(1)中,要计算EST(Mi)必须先计算所有的满足〈vj,vi〉∈E的那些任务的最早可能开始时间,换言之,递推的过程必须按照图中所有结点的一个拓扑序列(topologicalsequence)的顺序进行.注意到算法1构造任务依赖图时,所有的有向边都满足目标结点的编号大于源结点的编号,因此这里对结点编号的顺序(程序序)本身就是任务依赖图的一个拓扑序列.对于给定的任务依赖图G=(V,E),记M1,M2,…,MP+Q为按程序序排列的任务序列,v(Mi)为任务Mi在G中相应的结点,算法2给出了在任务依赖图加入资源依赖的具体过程.算法2.加入资源依赖到任务依赖图.1.Input:G=(V,E)2.Output:G=(V,E)3.letTT,TGbethelatesttasksonthecommunication4.TT,TG←//meansnotaskontheresource5.E←E6.fori=1toP+Qdo7.CalculateEST(Mi)byEquation(1)8.ifQ(Mi)≠0then//accordingtoproperty19.ifTType(Mi)=then10.TType(Mi)←Mi11.elseifQ(TType(Mi))≠Q(Mi)then12.ifSuc(TType(Mi))Pre(Mi)then13.ifEST(Mi)=EST(TType(Mi))then14.letMs(Ml)bethetaskwithsmaller(larger)15.E←E∪{〈v(Ms),v(Ml)〉}16.EST(Ml)←EST(Ms)+Time(Ms)17.TType(Mi)←Ml18.else19.letMs(Ml)bethetaskwithsmaller(larger)20.E←E∪{〈v(Ms),v(Ml)〉}21.EST(Ml)←22.TType(Mi)←Ml23.endif24.else//thereexistsapath25.TType(Mi)←Mi26.endif27.else//thereexistsapath28.TType(Mi)←Mi29.endif30.endif31.endfor由于算法2中为两个任务结点添加资源依赖相关的有向边的前提是这两个结点间不存在通路,因此添加有向边之后也不会带来回路,即添加资源依赖关系后得到的G依然是有向无圈图.至此,由算法1和算法2,我们可以得到给定CUDA程序的AOV网表示.以图3中所示的程序依赖图为例,各任务的一Page7个拓扑排序(程序序)为C1,T1,T2,C2,G1,G2,C3,T3,T4,C4,S,假定各任务执行时间为1,3,4,2,2,3,1,2,2,4,0,经过算法2处理得到的AOV网如图4所示.3.2非关键任务的确定建立CUDA程序的AOV网表示后,就可以确定降频后不影响程序执行总时间的非关键任务.算法2在得到CUDA程序的AOV网表示的同时,还为每个任务Mi计算出最早可能开始时间EST(Mi).为了确定非关键任务,我们还需要计算每个任务的最晚允许开始时间LST(LatestStartTime),即在程序的总执行时间不变的前提下,每个任务最晚允许开始的时间.为了计算LST,需要对CUDA程序AOV网重新进行拓扑排序,这是由于算法2在分析资源依赖时,根据最早可能开始时间的关系可能加入从程序序编号较大指向程序序编号较小的结点的有向边,因此初始的程序序不一定仍是AOV网的拓扑排序.但需要注意的是,重新构建拓扑排序并不改变算法2中计算的各任务的最早可能开始时间,这是由于算法2在添加表示资源依赖的有向边时,都对目标结点的最早可能开始时间进行了更新(第16,21行).不失一般性,记G=(V,E)为由算法2构造的AOV网络,其拓扑序列为M1,M2,…,MP+Q,此时我们可以按照拓扑序列的逆序列进行如下递推求解总时间不变的前提下每个任务的最晚允许开始时间{LST(MP+Q)=EST(MP+Q)LST(Mi)=min〈vi,vj〉∈E{LST(Mj)-Time(Mi如果任务的最早可能开始时间等于其最晚允许开始时间,则该任务位于AOV网的关键路径上,其运行时间直接影响整个程序的运行时间,不能进行放松.因此可以进行频率调节的任务是那些最早可能开始时间小于最晚允许开始时间的CPU任务和GPU任务.3.3频率调节幅度的求解为了求解能量最优的目标下,每个非关键的CPU任务和GPU任务的频率调节幅度,我们还需要对AOV网进行进一步的划分,以确定每个非关键CPU、GPU任务需要满足的时间约束.我们考察AOV网中的必经结点.所谓必经结点是指从AOV网中第一个任务到最后一个任务的任一路径必然经过的结点.根据CUDA程序的特征容易知道,在AOV网中,具有全局同步属性的结点都是AOV网的必经结点,包括全局同步任务以及非异步模式的GPU和通信任务.此外,如果一个必经结点的出度为1,则其唯一的后继结点也是必经结点.由于必经结点上的任务不和任何其它任务重叠执行,因此必经结点一定在AOV网的关键路径上.假设M1,M2,…,MP+Q为G的一个拓扑序列,G中包含k个必经结点,分别为Mc1=M1,McMc列,我们可以将G中的非必经结点划分为k-1个集合Si(1ik-1),每个集合包含拓扑序列中连续两个必经结点之间的所有结点,即Si={Mx|MciMxMc系.注意到,若两个必经结点在拓扑序列中相邻,则相应的非必经结点集合为空集.前面提到,由于必经结点上的任务一定是关键任务,因此进行频率调节的目标一定位于这里构造的非必经结点集合中.由于我们的能耗优化问题中要求程序的总执行时间不变,显然,程序的总执行时间等于关键路径上的所有任务的执行时间之和,因此每个关键任务的最早可能开始时间和最迟允许开始时间在优化过程中都是常量,不能被改变.换言之,对非必经结点集合Si中的CPU和GPU任务进行降频操作只要不增大Mc面,只要满足上述条件,由于边界结点时间是常量,因此对某一个非必经结点集合中的任务进行优化不会影响其它集合.因此整个程序的能耗优化问题可以归结为对每个非必经结点集合的能耗优化问题.针对非必经结点集合Si,我们构造一个AOV子网AOVSi={Mc关键任务结点,并且通信任务和同步任务结点时间不可变,因此我们只考虑对Si中的非关键的CPU和GPU任务结点进行频率调节.假定AOV子网中有N个非关键的CPU和GPU任务结点,记为1,…,MiMiN,进行频率调节后它们的频率分别变为f(Mi此时各任务的执行时间变为Time(MiPage8f(Mii+1的最早可能开始时间,记为EST(McTime(MiAOV子网中,根据式(1)我们可以计算出调节频率后Mc至此,Si的能量最优化问题可以归结为以下N元极值问题其中,kj表示任务Mi数,即E=kf2.为了简化式(3)的求解,我们还可以根据AOV子网中非关键任务结点的连接情况缩减极值问题的空间.由式(1)可知,对某任务进行频率调节,改变其执行时间后,它只能影响从其可达的结点的最早可能开始时间.因此如果集合Si可以划分为若干个子集合,它们之间两两互相不可达,则对某一个子集合进行频率调节不会影响到其它子集合,它们都可以按照上述方法单独进行求解,因此降低了极值问题的求解空间.算法3给出了对集合Si进行划分的方法.算法3.划分Si为多个相互不可达集合.1.Input:Si2.Output:S1i,S2i,…3.j←14.whileSi≠do5.Sj6.letmbeanarbitrarynodeinSi图5案例分析7.Sj8.repeat9.Sj10.rotatealledgesinAOVSi11.Sj12.untilSj13.returnSj14.Si←Si-Sj15.j←j+116.endwhile4案例分析由于我们的能耗优化方法的重点在于归纳并分析CUDA程序中的依赖关系,将其表示为AOV网络,而将最终AOV网中频率的求解归结为一个规划问题———N元极值问题.因此从理论上说,我们的方法可以给出问题的最优解.极值问题的数学求解过程不是本文关注的重点,因此本节通过案例分析给出我们的程序分析方法的执行过程,并给出模拟的能耗优化结果,以验证我们优化方法的有效性.图5给出了一个案例程序的分析过程.其中图(a)为原始算法流程,共包括6个步骤:首先是对a,b两个数组的初始化,然后调用过程f1和f2分别对a和b进行处理,得到数组c和d.第4行表示函数f3由一个标量α计算出一个数组e;第5行则表示函数f4由a,b两个数组计算出标量结果β;最后一行Page9表示函数f5由β,c,d和e计算出数组g.图(b)给出了上述算法的一个CUDA实现.假设f1,f2,f3和f5函数可以被并行化,因此使用Kernel函数实现,分别对应于Kernel1~Kernel4;f4函数不能被并行化,因此仍由CPU完成.Kernel1和Kernel2执行之前需要调用cudaMemcpy将输入数组a和b载入GPU存储器,Kernel4执行结束后需将数组g回存至CPU存储器.为了开发Kernel计算和通信的并行性,隐藏通信开销,CUDA实现中将Kernel1、Kernel2、Kernel3及其对应的通信操作设定为异步模式,而Kernel4使用到了前3个Kernel函数的输出,因此调用Kernel4之前先进行全局的任务流同步操作.图(c)给出了经过算法1处理后得到的任务依赖图,假定各个任务的执行时间如图(d)中所列,则根据算法2处理后,加入了T1到T2,G3到G1和G1到G2的资源依赖边,生成的AOV网络如图(e)所示.此时利用式(1)和(2)可以推算出各个结点的最早可能开始和最迟允许开始时间,如表1所示.可以看出,任务C1,T1,T2,G2,S1,G4,T3的最早可能开始时间和最晚允许开始时间相等,它们构成AOV网的关键路径,如图(f)中的阴影结点所示.因此系统中可以进行频率调节的非关键任务包括G1、G3和C2.根据3.3节的分析,这3个任务可以通过算法3划分为互不可达的两组,如图(f)中的虚线框所示,可以独立进行功耗调节.C2的情况比较简单,它的最早可能和最晚允许开始时间分别为1和13,因此根据式(3)给出的限定条件,为C2调节CPU的频率只要不影响S1的最早可能开始时间即可.根据式(1)可知C2的执行时间可以延长为16,因此执行任务C2时,CPU的频率最低可降至原来的1/4,C2的能量消耗降为原来的1/16.对于G1和G3,同理可知对GPU的频率调节不能影响S1的最早可能开始时间.由于G1和G3的初始运行时间都是2,不妨假设它们在初始频率下消耗的能量都为E,调节后运行时间变为tG1和tG3.根据式(1),G1和G3任务能量最优的运行时间可表示为其中,最小,为8/9E.求解上式可得,tG1=tG3=3时,两者总能量消耗通过以上的例子说明,我们的方法可以直观地将CUDA程序的能耗优化问题转变为基于AOV网的数学规划问题.需要说明的是,实际中很多数学规划问题是NP问题,因此本文的方法可以获得的能耗优化效果主要取决于规划问题求解的精度,而这不是本文所关注的主要问题,因此这里不做详细讨论.5相关工作本节分两个部分介绍和本文相关的工作.首先是异构系统的任务调度和功耗优化研究.Mudge等人基于Amdahl定律建立了传统多核、同构众核和异构众核体系结构的性能模型,通过分析认为由一个高性能计算核心和大量结构简单的高能效计算核心组成的异构体系结构可以有效提高并行处理能力,并能保证串行执行效率[7].文献[2]通过建立这3种体系结构的功耗模型,指出相对于同构体系结构,异构体系结构具有更高的能效优势.文献[8]中,作者面向同构多核体系结构建立了性能与能耗的关系,分析了在给定加速比约束的前提下调节处理器的频率以达到能耗最优.随着GPU越来越多地被应用到通用计算领域,面向CPU-GPU异构系统的任务调度与功耗优化问题逐渐成为该领域的研究热点.Yang等人[9]提出了一种动态的异构处理器选择方法,通过动态采样程序在不同计算单元上的执行时间,选择性能较高的处理器作为后续执行单元从而优化程序的性能.文献[10]提出了一种Page10多GPU自适应负载平衡手段,通过在CPU和GPU间建立任务队列使得GPU可以根据本地忙闲状态自适应地选择任务执行.Hermann等人[11]提出了一种异构系统的负载平衡策略,在综合考虑任务亲和性和处理器差异性的基础上,结合任务划分和任务窃取指导CPU-GPU间任务调度.文献[12]通过分析程序行为,借用模糊逻辑计算程序与处理器核的适应度,用以指导能量感知的异构多核系统的程序调度.此外,关于异构系统的任务调度的研究还包括文献[13-15].上述研究大部分关于单个任务,通常是循环如何在异构系统上进行调度和功耗优化,而本文则关注整个程序的功耗优化,这里任务在处理器上的分配由程序决定,而优化整个程序的功耗则需要分析各任务在异构的处理器上的依赖关系,这也是本文重点研究的内容.其次是关于GPU性能和功耗分析方面的研究.精确的性能分析模型是根据程序特征进行处理器低功耗优化的重要基础.文献[6]从程序并行度的角度出发,分析GPU程序中计算并行度和访存并行度的关系,从而确定出性能瓶颈,进而给出GPU程序的性能分析模型.文献[16]则引入了工作流图,作为GPUKernel的一种抽象表示,并基于此评估GPUKernel的执行时间.文献[17]则提出了一个整个的GPU性能分析和功耗分析模型,用于预测给定程序所需要的最优的GPU核数.这些模型都可以用于分析给定程序在GPU上的执行时间,因此本文在进行异构系统能耗优化时,假定GPU任务的执行时间已知,没有讨论性能分析问题.6结论异构系统的功耗优化问题成为异构体系结构的研究热点.本文面向CPU-GPU体系结构归纳总结了CUDA程序中包含的任务类型以及任务之间的依赖关系,研究了如何将CUDA程序在异构系统上的执行过程描述为一种抽象的数学表示AOV网络,并基于AOV网络求解程序的关键路径,找到在不影响程序总执行时间的前提下可以进行DVFS降频优化的非关键任务,进而求解能量最优目标下每个非关键任务的频率调节幅度.通过案例分析可以说明,本文方法可以有效地将CUDA程序的能耗优化问题转变为基于AOV网的数学规划问题,从而给出最优或近优的优化策略.
