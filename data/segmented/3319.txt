Page1ELF/ :/ 基于/ 无用/ 块/ 消除/ 和/ 低/ 重用/ 块/ 过滤/ 的/ 共享/ Cache/ 管理策略/ 隋/ 秀峰/ 1/ )/ ,/ 2/ )/ 吴俊敏/ 1/ )/ ,/ 3/ )/ 陈国良/ 1/ )/ 唐轶轩/ 1/ )/ 1/ )/ (/ 中国/ 科学技术/ 大学/ 计算机科学/ 与/ 技术/ 学院/ 合肥/ 230027/ )/ 2/ )/ (/ 中国科学院计算技术研究所/ 北京/ 100190/ )/ 3/ )/ (/ 中国/ 科学技术/ 大学/ 苏州/ 研究院/ 江苏/ 苏州/ 215123/ )/ 摘要/ 当代/ CMP/ 处理器/ 通常/ 采用/ 基于/ LRU/ 替换/ 策略/ 或/ 其/ 近似算法/ 的/ 共享/ 最后/ 一级/ Cache/ 设计/ ./ 然而/ ,/ 随着/ LLC/ 容量/ 和/ 相联/ 度/ 的/ 增长/ ,/ LRU/ 和/ 理论/ 最优/ 替换算法/ 之间/ 的/ 性能/ 差距/ 日趋/ 增大/ ./ 为此/ 已/ 提出/ 多种/ Cache/ 管理策略/ 来/ 解决/ 这一/ 问题/ ,/ 但是/ 它们/ 多数/ 仅/ 针对/ 单一/ 的/ 内存/ 访问/ 类型/ ,/ 且/ 对/ Cache/ 访问/ 的/ 频率/ 信息/ 关注/ 较/ 少/ ,/ 因而/ 性能/ 提升/ 具有/ 很大/ 的/ 局限性/ ./ 文中/ 提出/ 一种/ 统一/ 的/ Cache/ 管理策略/ ELF/ ,/ 不仅/ 可以/ 覆盖/ 多种/ 访存/ 行为/ ,/ 而且/ 能够/ 同时/ 考虑/ 程序/ 中/ 数据/ 的/ 临近/ 性/ 和/ 使用/ 频率/ 信息/ ./ 根据/ LLC/ 中/ Cache/ 块/ 在/ 其/ 生命/ 期内/ 使用/ 频率/ 较/ 低/ 这/ 一/ 实验/ 结果/ ,/ ELF/ 策略/ 能够/ (/ 1/ )/ 通过/ 基于/ 计数/ 的/ 算法/ 预测出/ 无用/ 块/ 并/ 将/ 其/ 尽早/ 替换/ ;/ (/ 2/ )/ 通过/ 动态/ 插入/ 和/ 提升/ 策略/ 过滤/ 低/ 重用/ 数据/ ,/ 从而/ 尽量/ 保留/ 那些/ 潜在/ 的/ 活动/ 数据/ 并且/ 使得/ 一部分/ 工作/ 集/ 免受/ 低/ 使用/ 频率/ 数据/ 的/ 干扰/ ./ 在/ 4/ 路/ CMPs/ 上/ 的/ 实验/ 结果显示/ ,/ ELF/ 可以/ 将/ 全局性/ 能/ 平均/ 提升/ 14.5/ %/ ,/ 同时/ 与/ PIPP/ 和/ TADIP/ 相比/ ,/ 可以/ 分别/ 达到/ 1.06/ 倍/ 和/ 1.09/ 倍/ 的/ 加速/ 比/ ./ 关键词/ 多核/ ;/ 共享/ 高速缓存/ ;/ 插入/ 策略/ ;/ 替换算法/ ;/ 基于/ 计数/ 的/ 算法/ 1/ 引言/ 随着/ 处理器/ 和/ 存储器/ 之间/ 速度/ 差距/ 的/ 日益/ 增大/ ,/ 存储系统/ 设计/ 业已/ 成为/ 影响/ 计算机系统/ 性能/ 的/ 关键/ 要素/ 之一/ ./ 当前/ ,/ 多核/ 处理器/ 普遍/ 通过/ 大容量/ 、/ 高/ 相联/ 度/ 的/ 最后/ 一级/ 片上/ Cache/ (/ Last/ -/ LevelCache/ ,/ LLC/ ,/ 在/ 本文/ 中是/ 二级/ Cache/ )/ 来/ 提供/ 对/ 最近/ 访问/ 过/ 的/ 数据/ 的/ 快速访问/ ./ 从/ 理论/ 上/ 讲/ ,/ 为了/ 达到/ 最高/ 的/ Cache/ 命中率/ ,/ LLC/ 应该/ 采用/ 最优/ 替换/ 策略/ OPT/ [/ 1/ ]/ ,/ 但是/ 由于/ OPT/ 算法/ 要/ 依赖于/ 数据/ 的/ 未来/ 使用/ 信息/ ,/ 在/ 硬件/ 实现/ 上/ 过于/ 复杂/ ,/ 因此/ 长期以来/ 商用/ 处理器/ 中/ 所/ 广泛/ 采用/ 的/ 是/ LRU/ 替换/ 策略/ 或/ 其/ 近似算法/ ./ 然而/ ,/ 近年来/ 大量/ 研究成果/ 表明/ ,/ 在/ 高/ 相联/ 度/ Cache/ 中/ LRU/ 和/ OPT/ 之间/ 的/ 性能/ 差距/ 正在/ 日益/ 增大/ ,/ 突出表现/ 为/ LRU/ 策略/ 对/ 内存/ 受限/ 应用/ 的/ 性能/ 较差/ ,/ 其/ 原因/ 在于/ 以下/ 几个/ 方面/ :/ (/ 1/ )/ LRU/ 策略/ 在/ 缺失/ (/ 命中/ )/ 时/ 将/ 数据/ 直接插入/ (/ 提升/ )/ 到/ MRU/ 位置/ ,/ 这样/ 数据/ 在/ 完成/ 最后/ 一次/ 访问/ 而/ 成为/ 无用/ 数据/ 后/ ,/ 往往/ 需要/ 跨越/ 大部分/ Cache/ 路/ 而/ 最终/ 成为/ 候选/ 替换/ 块/ ;/ (/ 2/ )/ LRU/ 策略/ 在/ 选择/ 替换/ 块/ 时/ 仅仅/ 考虑/ 了/ Cache/ 访问/ 的/ 临近/ 信息/ 而/ 忽略/ 了/ 数据/ 的/ 访问/ 频率/ ;/ (/ 3/ )/ 负载/ 中/ 存在/ 着/ 数据/ 的/ 循环/ 访问/ 模式/ ,/ 若/ 可用/ Cache/ 空间/ 不能/ 完全/ 容纳/ 负载/ 工作/ 集/ ,/ LRU/ 策略/ 可能/ 导致/ Cache/ 抖动/ ./ 目前/ ,/ 围绕/ 如何/ 缩小/ LRU/ 和/ OPT/ 之间/ 的/ 性能/ 差距/ 已经/ 开展/ 了/ 大量/ 的/ 研究/ 工作/ [/ 2/ -/ 7/ ]/ ,/ 而/ 解决/ 此/ 问题/ 的/ 方法/ 之一/ 就是/ 将/ 一部分/ 工作/ 集/ 尽可能/ 长时间/ 地/ 保留/ 在/ Cache/ 中/ ,/ 使得/ 至少/ 这部分/ 数据/ 可以/ 获得/ 较/ 高/ 的/ 命中率/ ./ 基于/ 这一/ 思想/ ,/ 本文/ 提出/ 一种/ 基于/ 无用/ 块/ 消除/ 和/ 低/ 重用/ 块/ 过滤/ 的/ 共享/ Cache/ 管理策略/ ELF/ ,/ 与/ 先前/ 工作/ 的/ 最大/ 区别/ 就/ 在于/ ELF/ 在/ 管理/ LLC/ 时/ 考虑/ 了/ 数据/ 的/ 使用/ 频率/ ,/ 并/ 通过/ 对/ Cache/ 插入/ 、/ 提升/ 和/ 失效/ 选择/ 策略/ 的/ 优化/ 达到/ 缩减/ 工作/ 集/ 的/ 目的/ ./ 具体/ 地/ ,/ 在/ 二级/ Cache/ 和/ 主存/ 之间/ 增加/ 使用/ 频率/ 预测器/ 硬件/ ,/ 可以/ 根据/ 缺失/ 块/ 的/ 访问/ 历史/ 预测出/ 其/ 使用/ 频率/ ,/ 针对/ 预测/ 结果/ ,/ ELF/ 能够/ (/ 1/ )/ 有效/ 地/ 标识/ 出低/ 使用/ 频率/ 数据/ 块/ ,/ 在/ 缺失/ 时依/ 概率/ 将/ 其/ 插入/ 到/ LRU/ 位置/ ,/ 而/ 命中/ 时仅/ 向前/ 提升/ 一个/ 优先级/ 位置/ ;/ (/ 2/ )/ 尽早/ 识别/ 出/ 无用/ 数据/ 块/ 并/ 优先/ 将/ 其/ 替换/ 出/ 二级/ Cache/ ./ 这样/ ,/ 当有/ 足够/ 数量/ 的/ 数据/ 块/ 被/ 过滤/ 和/ 消除/ 后/ ,/ 一部分/ 由/ 高/ 使用/ 频率/ 数据/ 所/ 组成/ 的/ 工作/ 集/ 就/ 可以/ 保留/ 在/ Cache/ 中/ 从而/ 获得/ 高/ 访问/ 命中率/ ./ 评测/ 结果显示/ ,/ 与/ 传统/ 的/ LRU/ 策略/ 相比/ ,/ ELF/ 可以/ 将/ 全局性/ 能/ 平均/ 提升/ 14.5/ %/ ,/ 同时/ 与/ PIPP/ (/ Promotion/ // InsertionPseudo/ -/ Partitioning/ )/ 和/ TADIP/ (/ Thread/ -/ AwareDIP/ )/ 相比/ ,/ 可以/ 分别/ 达到/ 1.06/ 倍/ 和/ 1.09/ 倍/ 的/ 加速/ 比/ ./ 2/ 背景/ 由于/ 二级/ Cache/ 失效/ 会/ 造成/ 处理器/ 停顿/ 数百个/ 周期/ ,/ 因此/ 本文/ 的/ 研究/ 主要/ 集中/ 在/ 怎样/ 通过/ 有效/ 地/ 管理/ 二级/ Cache/ 来/ 减少/ 其/ 缺失/ 数/ ./ 为了/ 简化/ 后文/ 的/ 讨论/ ,/ 本节/ 将/ 重点/ 介绍/ 多核/ 负载/ 特性/ 、/ Cache/ 插入/ // 提升/ 管理/ 等/ 背景/ 知识/ 及/ 本文/ 的/ 部分/ 相关/ 工作/ ./ 2.1/ 负载/ 特性/ 由于/ 部分/ 数据/ 访问/ 会/ 在/ 一级/ Cache/ 中/ 发生/ 命中/ ,/ 因此/ 二级/ Cache/ 可见/ 的/ 访问/ 流经/ 过滤/ 后/ 会/ 损失/ 一定/ 的/ 时间/ 局部性/ ,/ 这/ 在/ 很大/ 程度/ 上/ 降低/ 了/ 二级/ Cache/ 中/ 数据/ 块/ 的/ 使用/ 频率/ ./ 图/ 1/ 给出/ 了/ 25/ 个/ 单线程/ 应用/ (/ 出自/ SPEC2000/ 和/ SPEC2006/ 基准/ 测试程序/ 集/ )/ 的/ 二级/ Cache/ 块/ 使用/ 分布/ 情况/ ,/ 其中/ 每个/ 应用/ 都/ 使用/ ref/ 输入/ 集/ ,/ 并/ 分别/ 执行/ 具有/ 代表性/ 的/ 10/ 亿条/ 指令/ ./ 二级/ Cache/ 的/ 配置/ 为/ 4MB/ 、/ 16/ 路组/ 相联/ 、/ 基于/ LRU/ 替换/ 策略/ ,/ 关于/ 仿真/ 环境/ 的/ 详细描述/ 参见/ 第/ 4/ 节/ ./ Page3/ 图/ 1SPEC2006/ 中/ 部分/ 单线程/ 应用/ 的/ 二级/ Cache/ 块/ 使用/ 分布/ 情况/ 对于/ 图/ 1/ 中/ 的/ 每个/ 应用/ ,/ 根据/ 二级/ Cache/ 块/ 的/ 使用/ 次数/ 将/ 全部/ Cache/ 块/ 分成/ 5/ 类/ ,/ 类别/ [/ x/ ,/ y/ ]/ 包含/ 使用/ 次数/ 至少/ 为/ x/ 、/ 至多/ 为/ y/ 的/ 所有/ 数据/ 块/ ,/ 在/ 此/ 将/ 使用/ 次数/ 只有/ 一次/ 的/ Cache/ 块/ 列为/ 单独/ 的/ 一类/ ./ 从/ 该/ 图/ 中/ 可以/ 看出/ ,/ 绝大多数/ 应用/ 的/ 大部分/ Cache/ 块/ 的/ 使用/ 次数/ 都/ 介于/ 2/ 和/ 4/ 之间/ ,/ 如/ 在/ 173/ ./ applu/ 、/ 445/ ./ gobmk/ 和/ 470/ ./ lbm/ 中/ ,/ 几乎/ 所有/ 的/ 数据/ 块/ 都/ 属于/ 这一/ 区间/ ;/ 另外/ ,/ 还有/ 一些/ 应用/ 中/ 存在/ 着/ 较大/ 比例/ 的/ 单一/ 使用/ Cache/ 块/ ,/ 通常/ 这样/ 的/ Cache/ 块/ 被/ 称为/ 0/ -/ 重用/ 块/ (/ 在/ 被/ 插入/ 和/ 替换/ 之间/ 没有/ 被/ 重新/ 引用/ )/ ,/ 例如/ 在/ 189/ ./ lucas/ 和/ 459/ ./ Gems/ 中/ ,/ 0/ -/ 重用/ Cache/ 块/ 所/ 占/ 的/ 比例/ 几乎/ 可以/ 达到/ 50/ %/ ./ 0/ -/ 重用/ 块/ 的/ 产生/ 一般/ 是/ 基于/ 如下/ 两/ 方面/ 的/ 原因/ :/ 首先/ ,/ 某些/ Cache/ 块/ 并/ 不/ 具有/ 时间/ 局部性/ ,/ 在/ 进入/ Cache/ 后/ 根本/ 不会/ 被/ 再次/ 访问/ ,/ 将/ 这样/ 的/ 数据/ 块/ 插入/ 到/ Cache/ 中是/ 不会/ 有/ 任何/ 收益/ 的/ ;/ 其次/ ,/ 某些/ Cache/ 块/ 的/ 重用/ 距离/ 大于/ 图/ 22.2/ Cache/ 插入/ 和/ 提升/ 传统/ 的/ Cache/ 管理策略/ 可以/ 被/ 划分/ 成/ 3/ 个/ 部分/ :/ 失效/ 选择/ (/ 选择/ 被/ 替换/ 的/ 数据/ 块/ )/ 、/ 插入/ 策略/ (/ 确定/ 新/ 进入/ 的/ 数据/ 块/ 插入/ 到/ Cache/ 中/ 的/ 位置/ )/ 和/ 提升/ 策略/ (/ 如何/ 更新/ 命中/ 块/ 在/ 所在/ 组中/ 的/ 位置/ )/ ./ 图/ 3/ 给出/ 了/ 两个/ 处理器/ 核/ 共享/ 8/ 路组/ 相联/ Cache/ 的/ 实例/ ,/ 图中/ 按照/ 自左至/ 右/ 的/ 顺序/ 对应/ 于/ MRU/ 位置/ 到/ Cache/ 容量/ ,/ 导致/ 这些/ 块/ 在/ 重用/ 前/ 就/ 被/ LRU/ 策略/ 替换/ 出去/ 了/ ./ 图/ 2/ (/ a/ )/ 描绘/ 了/ 应用/ 403/ ./ gcc/ 独占/ 4MB/ 、/ 16/ 路组/ 相联/ 、/ 基于/ LRU/ 替换/ 策略/ 的/ 二级/ Cache/ 时/ ,/ 第/ 0/ 组/ 的/ 地址/ 访问/ 模式/ ./ 从中/ 可以/ 看出/ ,/ 不同/ Cache/ 块/ 的/ 访问/ 频率/ 差异/ 很大/ ,/ 高频/ 块/ 的/ 访问/ 次数/ 平均/ 可/ 占/ 数据/ 访问/ 总数/ 的/ 80/ %/ ./ 然而/ ,/ 这些/ Cache/ 块/ 的/ 访问/ 中间/ 往往/ 夹杂着/ 对/ 低频/ 块/ 的/ 访问/ ./ 图/ 2/ (/ b/ )/ 是/ 其中/ 100/ 个/ Cache/ 块/ (/ 图/ (/ a/ )/ 中非/ 0/ 起点/ )/ 访问/ 的/ 放大/ 片段/ ,/ 从中/ 不难看出/ ,/ 在/ LRU/ 策略/ 下/ ,/ 大部分/ 高频/ Cache/ 块/ 都/ 可能/ 被/ 低频/ 块/ 替换/ 出去/ ./ 因此/ ,/ 当/ 进行/ 替换/ 块/ 选择/ 时/ 如果/ 能够/ 适当/ 地/ 考虑/ 到/ 数据/ 的/ 访问/ 频率/ 信息/ ,/ 将/ 高频/ 数据/ 块/ 尽可能/ 多地/ 保留/ 在/ Cache/ 中/ ,/ 那么/ 在/ 某种程度/ 上/ 就/ 能够/ 显著/ 地/ 降低/ Cache/ 缺失/ 数/ ./ 另外/ ,/ 考虑/ 频率/ 信息/ 对于/ Cache/ 抖动/ 问题/ 同样/ 也/ 是/ 有益/ 的/ ./ LRU/ 位置/ ./ 在/ 传统/ 的/ LRU/ 管理/ 的/ Cache/ 中/ ,/ 对块/ 6/ 的/ 访问/ 导致/ 块/ C/ 被/ 替换/ 出去/ ,/ 而/ 新块/ 6/ 被/ 插入/ 到/ MRU/ 位置/ ;/ 而/ 在/ 随后/ 访问/ 块/ B/ 命中/ 时/ ,/ 它/ 立即/ 被/ 移动/ 到/ MRU/ 位置/ ./ 由图/ 1/ 可知/ ,/ 许多/ 应用/ 中/ 都/ 存在/ 着/ 大量/ 的/ 0/ -/ 重用/ 数据/ 块/ ,/ LRU/ 策略/ 将/ 这些/ 块/ 直接插入/ 到/ 或者/ 命中/ 后/ 直接/ 提升/ 到/ MRU/ 位置/ 实际上/ 延长/ 了/ 它们/ 占据/ Cache/ 空间/ 的/ 时间/ ,/ 但/ 并/ 不能/ 带来/ 任何/ Page4/ 性能/ 收益/ ./ 文献/ [/ 8/ ]/ 提出/ 了/ LRU/ 插入/ 策略/ (/ LRUInsertionPolicy/ ,/ LIP/ )/ 的/ 概念/ ,/ 即将/ 所有/ 新块/ 放入/ 到/ LRU/ 位置/ (/ 如图/ 3/ (/ a/ )/ 中/ 的/ 块/ 6/ )/ ./ 而/ 文献/ [/ 9/ ]/ 则/ 相对/ 于/ 传统/ 的/ MRU/ 提升/ (/ MRUPromotion/ ,/ MP/ )/ 提出/ 了/ 单步/ 提升/ 策略/ (/ SingleIncrementalPromotion/ ,/ SIP/ )/ ,/ 即/ 仅仅/ 将/ 命中/ 块/ 向前/ 移动/ 一个/ 位置/ (/ 如图/ 3/ (/ b/ )/ 中/ 的/ 块/ B/ )/ ./ LIP/ 和/ SIP/ 都/ 可以/ 减少/ 无用/ 块/ 在/ Cache/ 中/ 停留/ 的/ 时间/ ,/ 使得/ 一部分/ 工作/ 集/ 可以/ 长期/ 驻留/ 在/ Cache/ 中/ ,/ 增加/ Cache/ 的/ 命中率/ 从而/ 提高/ 其/ 性能/ ./ 2.3/ 相关/ 工作/ 在/ 微处理器/ 设计/ 领域/ ,/ 有/ 大量/ 研究/ 工作/ 是/ 围绕/ 对/ Cache/ 性能/ 的/ 优化/ 而/ 展开/ 的/ ./ 受/ 文章/ 篇幅/ 所/ 限/ ,/ 在/ 此/ 只/ 讨论/ 一些/ 与/ 本文/ 最/ 直接/ 相关/ 的/ 研究成果/ ./ 基于/ 大量/ 数据/ 块/ 在/ 进入/ Cache/ 后/ 就/ 不再/ 被/ 重用/ 这一/ 实验/ 结果/ ,/ 可以/ 通过/ 将/ 一部分/ 负载/ 工作/ 集/ 保留/ 在/ Cache/ 中以/ 达到/ 对/ 这部分/ 工作/ 集/ 的/ 高/ 命中率/ 来/ 优化/ Cache/ 性能/ ,/ 为此/ 文献/ [/ 8/ ]/ 提出/ 了/ 动态/ 插入/ 策略/ (/ DynamicInsertionPolicy/ ,/ DIP/ )/ ,/ 在/ 这/ 一/ 策略/ 中/ ,/ Cache/ 块/ 的/ 插入/ 策略/ 是/ 根据/ 组/ 表决/ 技术/ 的/ 结果/ 动态/ 确定/ 的/ ./ 新/ 进入/ 的/ 块/ 被/ 插入/ 到/ LRU/ 位置/ ,/ 并且/ 直到/ 再次/ 被/ 访问/ 的/ 时候/ 才/ 会/ 被/ 提升/ 到/ MRU/ 位置/ ./ 这样/ 0/ -/ 重用/ 数据/ 块/ 能够/ 尽快/ 地被/ 替换/ 出/ Cache/ 而/ 并/ 不会/ 干扰/ 组内/ 的/ 其它/ 数据/ ./ 然而/ ,/ 对于/ 只/ 拥有/ 少量/ 0/ -/ 重用/ 数据/ 块/ 的/ 负载/ ,/ DIP/ 和/ LRU/ 策略/ 将/ 展现出/ 类似/ 的/ 性能/ ./ 后续/ 的/ 研究/ 工作/ 在/ DIP/ 基础/ 上/ 增加/ 了/ 线程/ 感知/ 的/ 概念/ ,/ 提出/ 线程/ 感知/ 动态/ 插入/ 策略/ TADIP/ [/ 10/ ]/ ,/ 即/ 在/ 充分考虑/ 每个/ 并发/ 应用/ 的/ 访存/ 请求/ 基础/ 上/ ,/ 通过/ 对/ 单个/ 应用/ 分别/ 设置/ 最优/ 的/ 插入/ 策略/ 来/ 减少/ 共享/ Cache/ 中/ 无效/ 数据/ 块/ 的/ 数量/ ./ 在/ 多个/ 并发/ 线程/ 间/ 共享/ LLC/ 通常/ 会/ 导致/ 破坏性/ 的/ 线程/ 间/ 干扰/ ,/ 在/ 这种/ 情况/ 下/ ,/ 避免/ 短期/ 冲突/ 有时/ 要/ 比/ 保留/ 工作/ 集/ 更加/ 重要/ ./ Cache/ 划分/ 技术/ [/ 2/ ,/ 11/ ]/ 往往/ 可以/ 缓解/ 此类/ 问题/ ,/ 这/ 其中/ 最具/ 代表性/ 的/ 工作/ 就是/ 基于/ 效用/ 的/ Cache/ 划分/ (/ Utility/ -/ basedCachePartitioning/ ,/ UCP/ )/ [/ 2/ ]/ ,/ UCP/ 使用/ 经典/ 的/ 低/ 开销/ 监控器/ 电路/ 来/ 收集/ 每个/ 线程/ 的/ 效用/ 度/ 增益/ 信息/ ,/ 然后/ 通过/ 前瞻/ 算法/ 以/ 最大化/ 加权/ 加速/ 比/ 为/ 目标/ 对/ 共享/ Cache/ 进行/ 划分/ ./ 此外/ ,/ Chang/ 和/ Sohi/ 提出/ 多分/ 时/ 共享/ 划分/ (/ MultipleTime/ -/ sharingPartitions/ ,/ MTP/ )/ 技术/ 来/ 同时/ 优化/ 吞吐量/ 和/ 公平性/ 并且/ 兼顾/ QoS/ [/ 7/ ]/ ./ 每个/ MTP/ 划分/ 通过/ 收缩/ 其它/ 应用/ 所/ 占据/ 的/ Cache/ 容量/ 可以/ 提升/ 至少/ 一个/ 应用/ 的/ 吞吐量/ ,/ 而/ 多个/ 不/ 公平/ 的/ 划分/ 之间/ 分/ 时/ 共享/ Cache/ 资源/ 则/ 可以/ 达到/ 支持/ 不同/ 应用/ 的/ 目的/ ./ Xie/ 和/ Loh/ 则/ 在/ 最近/ 提出/ 将/ DIP/ 和/ UCP/ 整合/ 在/ 一起/ 的/ 提升/ // 插入/ 伪/ 划分/ 方案/ PIPP/ [/ 12/ ]/ ,/ 即将/ 某个/ 线程/ 的/ Cache/ 块/ 插入/ 到/ 访问/ 临近/ 栈/ 中距离/ LRU/ 为/ m/ 的/ 位置/ 上/ ,/ 这里/ m/ 表示/ 划分算法/ 分配/ 给/ 该/ 线程/ 的/ Cache/ 路数/ ./ 同时/ 还/ 在/ 插入/ 策略/ 中/ 集成/ 了/ 概率/ 提升/ 策略/ ,/ 即将/ Cache/ 命中/ 时/ 数据/ 块/ 在/ 访问/ 临近/ 栈中/ 移动/ 的/ 位置/ 与/ 一个/ 静态/ 概率/ 相关联/ ./ 无用/ 块/ 管理/ 也/ 是/ 优化/ 共享/ Cache/ 性能/ 的/ 另/ 一个/ 热点/ 研究/ 问题/ ,/ 其中/ 无用/ 块/ 预测/ 技术/ 就/ 试图/ 预测出/ 对/ 给定/ 数据/ 块/ 的/ 最后/ 一次/ 访问/ ./ 最具/ 代表性/ 的/ 是/ Kharbutli/ 和/ Solihin/ 提出/ 的/ 基于/ 计数/ 的/ 无用/ 块/ 预测器/ LvP/ [/ 13/ ]/ ,/ 在/ LvP/ 中/ ,/ 每个/ Cache/ 行都/ 增加/ 了/ 一个/ 记录/ 数据/ 引用/ 次数/ 的/ 计数器/ ,/ 当其值/ 达到/ 阈值/ 时/ 对应/ 的/ 数据/ 块/ 将/ 被/ 预测/ 为/ 无效/ ,/ 而/ 阈值/ 则/ 是/ 在/ 历史/ 表/ 硬件/ 的/ 辅助/ 下/ 动态/ 学习/ 获得/ 的/ ./ 基准/ LvP/ 算法/ 最初/ 是/ 在/ 多/ 发射/ 单核/ 处理器/ 中/ 提出/ 的/ ,/ 并且/ 仅/ 用来/ 优化/ 二级/ Cache/ 的/ 替换/ 块/ 选择/ 策略/ ,/ 本文/ 则/ 将/ LvP/ 扩展/ 到/ 多/ 核/ 处理器/ 中/ ,/ 并/ 在/ 原有/ 算法/ 基础/ 上/ 增加/ 了/ 对/ 数据/ 块/ 插入/ 和/ 提升/ 的/ 控制/ ,/ 以/ 达到/ 将/ 一部分/ 包含/ 高/ 使用/ 频率/ 数据/ 的/ 工作/ 集/ 保留/ 在/ Cache/ 中/ 的/ 目的/ ./ 而/ 最近/ 的/ 一项/ 工作/ 正是/ 探索/ 如何/ 使用/ 无用/ 块/ 预测/ 机制/ 来/ 改善/ 共享/ Cache/ 的/ 替换/ 精度/ [/ 14/ ]/ ,/ 其/ 思想/ 是/ 当/ 某/ 一组/ 内/ 需要/ 发生/ 替换/ 时/ ,/ 选择/ 在/ 访问/ 临近/ 栈/ 中距离/ LRU/ 位置/ 最近/ 的/ 无用/ 块/ 作为/ 候选/ 对象/ ,/ 并且/ 只有/ 当/ 数据/ 块/ 从/ MRU/ 位置/ 迁移/ 出来/ 时/ ,/ 这一/ 策略/ 才/ 会/ 根据/ 引用/ 计数/ 的/ 历史/ 预测出/ 无用/ 的/ 数据/ 块/ ./ 3/ 无用/ 块/ 消除/ 和/ 低/ 重用/ 块/ 过滤/ Cache/ 管理/ 3.1/ ELF/ 硬件/ 结构/ 为了/ 描述/ 方便/ ,/ 本文/ 将/ Cache/ 块/ 从/ 第一次/ 被/ 引/ Page5/ 用/ 而/ 进入/ Cache/ 直到/ 被/ 淘汰/ 这/ 段/ 间隔/ 内/ 的/ 访问/ 次数/ 定义/ 为/ 使用/ 频率/ ./ ELF/ 的/ 主要/ 思想/ 是/ 通过/ 过滤/ 低/ 使用/ 频率/ 数据/ 块/ 和/ 尽快/ 消除/ 无用/ 数据/ 块/ 而/ 达到/ 缩小/ 负载/ 工作/ 集/ 的/ 目的/ ./ 这样/ ,/ 为了/ 使用/ ELF/ 策略/ 进行/ LLC/ 管理/ ,/ 我们/ 需要/ 在/ 数据/ 插入/ 到/ Cache/ 之前/ 确定/ 它/ 的/ 使用/ 频率/ ,/ 同时/ 能够/ 及时/ 地/ 标识/ 出/ 哪些/ 数据/ 块/ 是/ 无用/ 的/ ,/ 显然/ 这些/ 决定/ 都/ 要/ 依赖于/ Cache/ 块/ 的/ 未来/ 使用/ 信息/ ./ 为此/ 本文/ 将/ 文献/ [/ 13/ ]/ 中/ 所/ 提出/ 的/ 活动/ 时间/ 预测器/ (/ LvP/ )/ 扩展/ 到/ 多/ 核/ 处理器/ 中/ ,/ 用以/ 实现/ 对/ Cache/ 块/ 使用/ 频率/ 及/ 无用/ Cache/ 块/ 的/ 预测/ ./ LvP/ 预测器/ 在/ Cache/ 行/ 被/ 放置/ 到/ 高速缓存/ 后/ 开始/ 记录/ 其/ 访问/ 次数/ ,/ 当/ 计数器/ 的/ 值/ 达到/ 门/ 限值/ 时/ ,/ 就/ 认为/ 该/ Cache/ 行/ 成为/ 无用/ 数据/ ./ ELF/ 保留/ 了/ LvP/ 预测器/ 对/ 无用/ 数据/ 的/ 预测/ ,/ 同时/ 又/ 利用/ 所/ 记录/ 的/ Cache/ 行在/ 前/ 一个/ 生命/ 期内/ 的/ 访问/ 门限/ 来/ 预测/ Cache/ 行/ 的/ 使用/ 频率/ ./ 图/ 4/ 所示/ 的/ 是/ 4/ 核/ 处理器/ 的/ ELF/ 预测器/ 硬件/ 同时/ ,/ 我们/ 还/ 需要/ 在/ 每个/ Cache/ 行中/ 增加/ 4/ 个/ 额外/ 的/ 域/ ,/ 其中/ 引用/ 计数器/ C/ 用于/ 计算/ 该/ Cache/ 块/ 图/ 4ELF/ 的/ 硬件/ 架构/ 结构/ ,/ 该/ 处理器/ 拥有/ w/ 路组/ 相联/ 共享/ 二级/ Cache/ ,/ 每个/ 处理器/ 核/ 都/ 有/ 私有/ 的/ 一级/ Cache/ ,/ 这些/ 一级/ Cache/ 通过/ 总线/ 互联/ 的/ 方式/ 连接/ 在/ 一个/ 共享/ 的/ 二级/ Cache/ 上/ ./ ELF/ 策略/ 在/ L2Cache/ 和/ 主存/ 之间/ 增加/ 了/ 一个/ 独立/ 的/ 预测/ 表/ 结构/ ,/ 用来/ 保存/ 没有/ 被/ 缓存/ 的/ 数据/ 的/ 使用/ 频率/ 历史/ (/ 4/ 位/ 计数器/ maxCstored/ )/ 并且/ 在/ 数据/ 重新/ 进入/ Cache/ 时/ 恢复/ 使用/ 频率/ 信息/ ./ 预测/ 表/ 被/ 组织/ 成/ 一个/ 256/ ×/ 256/ 的/ 直接/ 映射/ 无/ 标记/ 二维/ 矩阵/ 结构/ ,/ 其中/ 行/ 使用/ Cache/ 块/ 的/ hashedPC/ 域/ (/ 导致/ Cache/ 失效/ 的/ 指令/ PC/ 按/ 每/ 8/ 位/ 异或/ 的/ 结果/ )/ 来/ 索引/ ,/ 而列/ 则/ 通过/ 块/ 地址/ 按/ 每/ 8/ 位/ 异或/ 的/ 结果/ 来/ 索引/ ,/ 这种/ 方式/ 可以/ 同时/ 区分/ 出/ 不同/ 的/ 数据/ 块/ 和/ 同一/ 数据/ 的/ 不同/ 程序/ 阶段/ ,/ 具有/ 较/ 高/ 的/ 预测/ 精度/ ./ 另外/ ,/ 预测/ 表/ 的/ 访问/ 只/ 发生/ 在/ 二级/ Cache/ 缺失/ 时/ ,/ 并/ 不/ 修改/ 处理器/ 访问共享/ Cache/ 的/ 关键/ 路径/ ,/ 因此/ ELF/ 并/ 不/ 引入/ 额外/ 时间/ 开销/ ./ 在/ 整个/ 生命/ 期内/ 的/ 引用/ 次数/ ,/ 而/ 计数器/ maxCpast/ 则/ 用于/ 保存/ 数据/ 在/ 上/ 一个/ 生命/ 期内/ 的/ 引用/ 次数/ ,/ 而/ Page6Conf/ 是/ 一位/ 的/ 信任/ 比特/ ,/ 用于/ 标识/ 预测/ 表/ 信息/ 的/ 可靠性/ ,/ 只有/ 当该/ 位/ 被/ 设置/ 时/ ,/ 才/ 能够/ 使用/ 预测器/ 的/ 结果/ 进行/ 插入/ 和/ 提升/ 策略/ 的/ 选择/ ./ 上述/ 全部/ 计数器/ 的/ 宽度/ 都/ 需要/ 根据/ 对/ 典型/ 负载/ 的/ 剖析/ 结果/ 而定/ ,/ 而/ 文献/ [/ 13/ ]/ 中则/ 得出结论/ :/ 在/ 每个/ 生命/ 期内/ 二级/ Cache/ 块/ 的/ 平均/ 访问/ 次数/ 一般/ 相对/ 较/ 小/ ,/ 用/ 一个/ 4/ 位/ 的/ 计数器/ 来/ 保存/ 就/ 可以/ 保证/ 足够/ 的/ 精度/ ./ 为此/ ,/ 本文/ 同样/ 采用/ 4/ 位/ 宽度/ 的/ 计数器/ ./ 3.2/ ELF/ 策略/ Cache/ 访问/ 的/ 临近/ 和/ 频率/ 信息/ 对于/ 替换/ 策略/ 的/ 指定/ 都/ 是/ 至关重要/ 的/ ,/ 本文/ 所/ 提出/ 的/ ELF/ 策略/ 同时/ 对/ 二者/ 进行/ 了/ 考虑/ ,/ ELF/ 进一步/ 改进/ 了/ 文献/ [/ 13/ ]/ 所/ 提出/ 的/ LvP/ 算法/ ,/ 在/ 其中/ 根据/ 预测器/ 的/ 结果/ 增加/ 了/ 对/ 数据/ 块/ 的/ 插入/ 和/ 提升/ 策略/ 的/ 控制/ ,/ 以/ 过滤/ 低/ 使用/ 频率/ 数据/ ./ ELF/ 策略/ 的/ 算法/ 描述/ 如图/ 5/ 所示/ ,/ 实际上/ 其中/ 包括/ 3/ 个/ 主要/ 方面/ :/ 插入/ 、/ 提升/ 以及/ 失效/ 选择/ 策略/ ./ 新来/ 块/ 的/ 插入/ 策略/ ./ 新块/ 插入/ 到/ Cache/ 中/ 的/ 位置/ 主要/ 有/ LRU/ 和/ MRU/ 两种/ ,/ ELF/ 会/ 根据/ 对/ 缺失/ 块/ 的/ 使用/ 频率/ 预测/ 结果/ 来/ 确定/ 插入/ 位置/ ,/ 对于/ 0/ -/ 重用/ 块/ ,/ 直接插入/ 到/ LRU/ 位置/ 以/ 有效/ 滤除/ ;/ 对于/ 低/ 使用/ 频率/ 块/ (/ 使用/ 频率/ 低于/ 3/ )/ ,/ 按/ 插入/ 概率/ Pinsert/ 插入/ 到/ LRU/ 位置/ ,/ 按/ 概率/ 1/ -/ Pinsert/ 插入/ 到/ MRU/ 位置/ ,/ 文中/ Pinsert/ 的/ 值/ 被/ 设为/ 3/ // 4/ ;/ 而/ 对于/ 其它/ 情况/ 则/ 都/ 插入/ 到/ MRU/ 位置/ ./ 可见/ ,/ ELF/ 策略/ 将/ 低/ 使用/ 频率/ 数据/ 以高/ 概率/ 被/ 插入/ 到/ LRU/ 位置/ ,/ 缩短/ 了/ 它们/ 在/ Cache/ 中/ 的/ 停留时间/ ,/ 明显/ 地/ 起到/ 了/ 对/ 数据/ 的/ 过滤/ 作用/ (/ 参见/ 算法/ 2d/ )/ ./ 命中/ 块/ 的/ 提升/ 策略/ ./ 命中/ 块/ 的/ 提升/ 也/ 有/ MP/ 和/ SIP/ 两种/ 策略/ ,/ ELF/ 同样/ 会/ 根据/ 命中/ 块/ 的/ 使用/ 频率/ 预测/ 信息/ 在/ 二者之间/ 进行/ 选择/ ,/ 对于/ 低/ 使用/ 频率/ 块/ ,/ 采用/ SIP/ 策略/ ,/ 这样/ 数据/ 块/ 在/ 整个/ 生命/ 期内/ 会/ 随着/ 访问/ 频率/ 的/ 增加/ 而/ 逐渐/ 向/ 访问/ 临近/ 栈中/ 的/ 高/ 优先级/ 位置/ 靠近/ ,/ 导致/ 高/ 使用/ 频率/ 数据/ 的/ 位置/ 优先/ 于/ 低/ 使用/ 频率/ 数据/ ;/ 而/ 对于/ 高/ 使用/ 频率/ 块/ 则/ 以/ 记录/ 其/ 访问/ 临近/ 性/ 信息/ 为主/ ,/ 在/ 命中/ 后/ 直接/ 提升/ 到/ MRU/ 位置/ ,/ 有利于/ 提供/ 更/ 多/ 的/ 后续/ 访问/ 命中/ ./ 显然/ ,/ ELF/ 策略/ 可以/ 同时/ 开发/ 出/ 程序/ 中/ 数据/ 的/ 访问/ 临近/ 性/ 和/ 访问/ 频率/ 信息/ (/ 参见/ 算法/ 1b/ )/ ./ 替换/ 块/ 的/ 选择/ 策略/ ./ 根据/ 2.1/ 节/ 的/ 介绍/ ,/ 典型/ 负载/ 中/ 存在/ 着/ 大量/ 使用/ 频率/ 较/ 低/ 的/ 数据/ 块/ ,/ 它们/ 在/ 进入/ 二级/ Cache/ 后/ 不久/ 就/ 会/ 成为/ 无用/ 数据/ 块/ ./ 为此/ ELF/ 算法/ 首先/ 试图/ 尽早/ 地/ 标识/ 出/ 这些/ 无用/ Cache/ 块/ ,/ 这样/ 在/ 二级/ Cache/ 发生/ 缺失/ 而/ 需要/ 选择/ 候选/ 替换/ 块/ 时/ ,/ 可以/ 优先/ 从/ ELF/ 算法/ 所/ 预测出/ 的/ 所有/ 无用/ 块/ 中/ 随机/ 选择/ 一块/ 作为/ 候选/ 替换/ 块/ ,/ 若/ 并未/ 发现/ 无用/ 数据/ 块/ ,/ 则/ 仍然/ 选取/ 该组/ 中/ 的/ LRU/ 块/ 进行/ 替换/ (/ 参见/ 算法/ 2a/ 和/ 2b/ )/ ./ 4/ 性能/ 评价/ 方法/ 配置/ ./ 本文/ 使用/ 事件驱动/ 的/ 周期/ 精确/ 多核/ 仿真器/ Multi2sim/ [/ 15/ ]/ 来/ 评测/ ELF/ 的/ 有效性/ ./ 基本/ 的/ 仿真/ 系统/ 是/ 一个/ 4/ 路/ 的/ 多/ 核/ 处理器/ ,/ 具有/ 4MB/ 、/ 16/ 路组/ 相联/ 的/ 共享/ 二级/ Cache/ ./ 每个/ 处理器/ 核是/ 4/ 发射/ 、/ 乱序执行/ 的/ ,/ 采用/ x86/ 指令集/ 体系结构/ ,/ 具有/ 私有/ 的/ 一级/ 指令和数据/ Cache/ ./ 后续/ 实验/ 中/ 模拟器/ 的/ 相关/ 配置/ 信息/ 参见/ 表/ 1/ ./ 参数/ 处理器/ 核/ L2Cache/ (/ LLC/ )/ 4MB/ ,/ 64Bline/ -/ size/ ,/ 16/ -/ way/ ,/ 15/ -/ cyclehit/ ./ L2/ 存储器/ 300/ -/ cycle/ 访问/ 延迟/ ./ Page7/ 测试/ 负载/ ./ 本文/ 采用/ 多道/ 负载/ 来/ 评测/ ELF/ 策略/ 的/ 性能/ ,/ 这些/ 多道/ 负载/ 是/ 由/ SPEC2006/ 和/ MiBench/ [/ 16/ ]/ 中/ 的/ 部分/ 应用/ 组合而成/ 的/ ./ 本文/ 首先/ 对/ SPEC2006/ 中/ 每个/ 应用程序/ 的/ Cache/ 敏感度/ 进行/ 了/ 研究/ ,/ 并/ 将/ 其/ 划分/ 成/ Cache/ 友好/ 、/ Cache/ 适宜/ 、/ Cache/ 抖动/ 以及/ 流媒体/ 等/ 4/ 种/ 类型/ ,/ 然后/ 分别/ 选取/ 不同/ 类型/ 的/ 应用程序/ 组合成/ 相应/ 的/ 测试/ 负载/ ,/ 而/ MiBench/ 的/ 使用/ 则/ 参照/ 于/ PIPP/ ./ 表/ 2/ 列出/ 了/ 本文/ 所/ 使用/ 的/ 全部/ 负载/ 组合/ ./ 负载/ mix00mix01mix02mix03mix04mix05mix06mix07sjeng/ ,/ povray/ ,/ wrf/ ,/ tontomix08mix09/ 对于/ 每个/ 负载/ ,/ 我们/ 首先/ 对/ Cache/ 资源/ 预热/ 500M/ 条/ 指令/ ,/ 然后/ 对/ 负载/ 中/ 的/ 每个/ 应用/ 都/ 精确/ 仿真/ 250M/ 条/ 指令/ ./ 当/ 某个/ 应用/ 达到/ 这一/ 界限/ 时/ ,/ 它会/ 继续执行/ 下去/ 以/ 保证/ 对/ Cache/ 资源/ 的/ 持续/ 竞争/ ./ 这图/ 64/ 路/ CMP/ 系统/ 中/ ELF/ 、/ PIPP/ 和/ TADIP/ 的/ 加权/ 加速/ 比/ 比较/ ELF/ 策略/ 在/ 管理/ LLC/ 上/ 的/ 性能/ 优越性/ 来源于/ 以下/ 3/ 个/ 方面/ :/ (/ 1/ )/ 基于/ 计数/ 的/ Cache/ 块/ 使用/ 频率/ 预测/ 算法/ 可以/ 有效/ 地/ 标识/ 出/ LLC/ 中/ 的/ 无用/ 数据/ 块/ ,/ 并且/ 尽早/ 地/ 将/ 其/ 替换/ 出去/ ,/ 从而/ 延长/ 那些/ 潜在/ 的/ 活动/ 数据/ 在/ Cache/ 中/ 驻留/ 的/ 时间/ ;/ (/ 2/ )/ 将/ 低/ 使用/ 频率/ 数据/ 块/ 依/ 概率/ 插入/ 到/ LRU/ 位置/ ,/ 并且/ 在/ 后续/ 命中/ 仅仅/ 向前/ 提升/ 一个/ 位置/ ,/ 从而/ 保证/ 一部分/ 高/ 使用/ 频率/ 工作/ 集/ 可以/ 保留/ 在/ Cache/ 中/ ,/ 以/ 贡献/ 出较/ 高/ 的/ Cache/ 命中率/ ;/ (/ 3/ )/ 替换/ 和/ 插入/ 时/ 同时/ 考虑/ 了/ 数据/ 的/ 临近/ 性/ 和/ 使用/ 频率/ 信息/ ./ 种/ 评测/ 方案/ 与/ 许多/ 先前/ 工作/ 保持一致/ [/ 11/ ]/ ./ 度量/ 指标/ ./ 本文/ 使用/ 多核/ Cache/ 设计/ 中/ 被/ 普遍/ 采用/ 的/ 两个/ 度量/ 来/ 衡量/ 并发/ 调度/ 负载/ 的/ 性能/ ,/ 分别/ 是/ 吞吐量/ 、/ 加权/ 加速/ 比/ 和/ 公平性/ [/ 17/ ]/ ./ 其中/ ,/ 加权/ 加速/ 比/ 表明/ 系统/ 执行/ 时间/ 的/ 减少/ ,/ 而/ 调和/ 平均/ 公平性/ 则/ 在/ 性能/ 和/ 公平性/ 之间/ 进行/ 均衡/ ./ 二者/ 的/ 定义/ 如下/ :/ Weighted/ -/ Speedup/ =/ ∑/ (/ IPCi/ // IPCsa/ ,/ i/ )/ (/ 2/ )/ Harmonic/ -/ Mean/ -/ Fairness/ =/ N/ ∑/ (/ IPCsa/ ,/ i/ // IPCi/ )/ 在/ 等式/ (/ 1/ )/ 和/ (/ 2/ )/ 中/ ,/ IPCsa/ ,/ i/ 表示/ 应用/ i/ 独占/ 整个/ 共享/ Cache/ 时/ 的/ IPC/ ./ 5/ 实验/ 结果/ 及/ 分析/ 5.1/ 性能/ 加速/ 比图/ 6/ 给出/ 了/ TADIP/ 、/ PIPP/ 和/ ELF3/ 种/ Cache/ 管理策略/ 的/ 加权/ 加速/ 比/ ,/ 所有/ 数据/ 都/ 是/ 以/ 传统/ 的/ LRU/ 策略/ 作为/ 基准/ 的/ ./ 对于/ 表/ 2/ 中/ 的/ 10/ 个/ 多/ 道/ 负载/ ,/ ELF/ 策略/ 都/ 明显/ 超越/ LRU/ ,/ 加权/ 加速/ 比/ 的/ 几何/ 平均值/ 高达/ 14.5/ %/ ;/ 同时/ 与/ PIPP/ 和/ TADIP/ 策略/ 相比/ ,/ ELF/ 可以/ 将/ LLC/ 性能/ 分别/ 平均/ 提升/ 6.5/ %/ 和/ 9.02/ %/ ./ 图/ 7/ 和/ 图/ 8/ 分别/ 给出/ 了/ 各种/ Cache/ 管理策略/ 的/ 调和/ 平均/ 公平性/ 度量/ 及/ 吞吐量/ 度量/ 之间/ 的/ 比较/ ./ 从图/ 中/ 可以/ 看出/ ,/ 除图/ 7/ 中/ 的/ mix09/ 之外/ ,/ 数据/ 变化/ 的/ 趋势/ 和/ 加权/ 加速/ 比/ 非常/ 类似/ ,/ 这/ 说明/ 多数/ 情况/ 下/ ELF/ 在/ 提高/ 性能/ 的/ 同时/ 还/ 保证/ 了/ 各/ 并发/ 线程/ 之间/ 的/ 公平性/ ./ 但/ mix09/ 的/ 存在/ 提醒/ 我们/ ,/ 在/ 以/ 性能/ 为/ 主要/ 优化/ 目标/ 的/ Cache/ 管理策略/ 中/ ,/ 有时/ 可能/ 要/ 以/ 牺牲/ 系统/ 的/ 公平性/ 为/ 代价/ ./ 为此/ ,/ 在/ 设计/ 共享/ Cache/ 优化/ 策略/ 时/ ,/ 要/ 综合/ 考虑/ 这/ 两/ 方面/ 因素/ ./ Page8/ 图/ 74/ 路/ CMP/ 系统/ 中/ ELF/ 、/ PIPP/ 和/ TADIP/ 的/ 调和/ 平均/ 公平性/ 比较/ 图/ 84/ 路/ CMP/ 系统/ 中/ ELF/ 、/ PIPP/ 和/ TADIP/ 的/ 吞吐量/ 比较/ 5.2/ Cache/ 块/ 使用/ 频率/ 预测/ 精度/ 分析/ 由/ 第/ 3/ 节/ 的/ 讨论/ 可知/ ,/ ELF/ 算法/ 的/ 实施/ 要/ 依赖于/ Cache/ 块/ 的/ 未来/ 使用/ 频率/ ,/ 为此/ 本文/ 将/ 文献/ [/ 13/ ]/ 中/ 所/ 提出/ 的/ LvP/ 算法/ 的/ 硬件/ 结构/ 扩展/ 到/ 多/ 核/ 处理器/ 中/ ,/ 用于/ 实现/ 使用/ 频率/ 预测/ ./ 图/ 9/ 给出/ 了/ 在/ 4/ 路多核/ 处理器/ 上/ 对于/ 表/ 2/ 中/ 的/ 所有/ 多道程序/ 负载/ 预测/ 算法/ 有效性/ 的/ 分析/ ./ 从图/ 中/ 可见/ ,/ 对于/ mix00/ 、/ mix02/ 、/ mix07/ ,/ 预测/ 算法/ 的/ 精度/ 可以/ 高达/ 80/ %/ 以上/ ,/ 而/ 算法/ 的/ 平均/ 预测/ 精度/ 也/ 接近/ 60/ %/ ./ 算法/ 之所以/ 具有/ 相对/ 较/ 高/ 的/ 预测/ 精度/ ,/ 是因为/ 我们/ 同时/ 使用/ 数据/ 块/ 地址/ 和/ 导致/ 数据/ 失效/ 的/ 指令/ 的/ PC/ 来/ 索引/ 预测/ 表/ ,/ 这样/ 既/ 可以/ 区分/ 出/ 不同/ 的/ 数据/ 又/ 可以/ 区分/ 出/ 同一/ 数据/ 的/ 不同/ 程序/ 阶段/ ./ 然而/ ,/ 由于/ 预测/ 表/ 大小/ 被/ 设置/ 为/ 固定/ 的/ 256/ ×/ 256/ ,/ 不同/ 数据/ 引用/ 指令/ 的/ PC/ 及其/ 所/ 需/ 访问/ 的/ 数据/ 地址/ 按/ 每/ 8/ 位/ 异或/ 后/ 的/ 结果/ 有/ 可能/ 相同/ ,/ 这样/ 就/ 会/ 导致/ 预测/ 表/ 的/ 伪命/ 中/ 现象/ ./ 尽管/ 扩大/ 预测/ 表/ 的/ 规模/ 可以/ 削弱/ 甚至/ 消除/ 伪命/ 中/ ,/ 从而/ 获得/ 更优/ 的/ 性能/ 收益/ ,/ 但是/ 考虑/ 到/ 硬件/ 设计/ 开销/ 和/ 性能/ 之间/ 的/ 折衷/ ,/ 本文/ 仍然/ 采用/ 与/ 文献/ [/ 13/ ]/ 中/ 相同/ 大小/ 的/ 预测/ 表/ 结构/ ./ 5.3/ 对/ Cache/ 容量/ 的/ 敏感度/ 分析/ Cache/ 的/ 性能/ 可以/ 通过/ 有效/ 地/ 管理/ Cache/ 资源/ 或/ 增加/ Cache/ 容量/ 两种/ 方式/ 来/ 提升/ [/ 8/ ]/ ./ 图/ 8/ 给出/ 了/ 表/ 2/ 中/ 所有/ 负载/ 在/ 基准/ LRU/ 和/ ELF/ 两种/ 策略/ 下/ 的/ 平均/ 每/ 1000/ 条/ 指令/ 的/ 二级/ Cache/ 缺失/ 数/ (/ MissesPer1000Instructions/ ,/ MPKI/ )/ ,/ 其中/ Cache/ 容量/ 分别/ 为/ 1MB/ 、/ 2MB/ 和/ 4MB/ ,/ 并且/ 在/ 这些/ 配置/ 下/ 二级/ Cache/ 的/ 相联/ 度恒为/ 16/ 路/ ./ 根据/ 图/ 10/ ,/ 在/ ELF/ 策略/ 控制/ 下/ ,/ 将/ Cache/ 容量/ 图/ 10ELF/ 策略/ 在/ 不同/ Cache/ 容量/ 下/ 的/ 性能/ Page9/ 从/ 1MB/ 增加/ 到/ 2MB/ ,/ 或/ 从/ 2MB/ 增加/ 为/ 4MB/ 可以/ 将/ 平均/ MPKI/ 分别/ 降低/ 37.7/ %/ 或/ 49.4/ %/ ./ 由此可见/ ,/ ELF/ 和/ LRU/ 具有/ 相同/ 的/ 容量/ 扩展性/ ,/ 并且/ 比/ LRU/ 具有/ 更好/ 的/ 性能/ 而/ 所/ 需/ 的/ 硬件/ 开销/ 并/ 不/ 显著/ ./ 5.4/ 插入/ 和/ 提升/ 行为/ ELF/ 策略/ 可以/ 显著/ 降低/ 使用/ 频率/ 数据/ 块/ 尤其/ 是/ 0/ -/ 重用/ 数据/ 块/ 在/ 共享/ Cache/ 中/ 的/ 驻留/ 时间/ ,/ 这/ 主要/ 是/ 通过/ 将/ 低/ 使用/ 频率/ 数据/ 块/ 依照/ 概率/ 简单/ 地/ 插入/ 到/ LRU/ 位置/ 以及/ 在/ 后续/ 访问/ 命中/ 时仅/ 向前/ 提升/ 一图/ 11ELF/ 策略/ 的/ 插入/ 和/ 提升/ 行为/ 剖析/ 5.5/ 硬件/ 设计/ 开销/ ELF/ 策略/ 的/ 存储/ 开销/ 主要/ 来源于/ 使用/ 频率/ 预测/ 表及/ 在/ 每个/ Cache/ 行中/ 所/ 增加/ 的/ 一些/ 必要/ 的/ 域/ ,/ 详见/ 图/ 4/ ./ 表/ 3/ 详细描述/ 了/ ELF/ 策略/ 的/ 存储/ 开销/ ,/ 假设/ 物理地址/ 空间/ 为/ 32/ 位/ ./ 根据/ 表/ 3/ 的/ 计算结果/ ,/ ELF/ 所/ 需/ 的/ 硬件/ 开销/ 有/ 176KB/ ,/ 相当于/ 片内/ 共享/ LLC/ 面积/ 的/ 4.18/ %/ ,/ 这样/ 的/ 硬件/ 开销/ 在/ 半导体/ 工艺/ 迅速/ 发展/ 的/ 今天/ 还是/ 十分/ 合理/ 的/ ./ 每个/ Cache/ 行所/ 增加/ 的/ 额外/ 域/ 总共/ 的/ Cache/ 行数/ 二级/ Cache/ 中/ 附加/ 域/ 的/ 总计/ 开销/ 每个/ 预测/ 表项/ 的/ 开销/ 预测/ 表项/ 的/ 总数/ 预测/ 表/ 的/ 总计/ 开销/ ELF/ 策略/ 的/ 总开销/ ELF/ 导致/ 的/ LLC/ 面积/ 增加/ 的/ 百分比/ 6/ 结论/ 随着/ 片内/ 共享/ 最后/ 一级/ Cache/ 容量/ 和/ 相联/ 度/ 的/ 增长/ ,/ 传统/ 的/ LRU/ 策略/ 和/ 理论/ 最优/ 替换/ 策略/ OPT/ 之间/ 的/ 性能/ 差距/ 日趋/ 增大/ ,/ 解决/ 上述/ 问题/ 的/ 方法/ 之一/ 就是/ 将/ 一部分/ 工作/ 集/ 尽可能/ 长时间/ 地/ 保留/ 在/ 个/ 优先级/ 位置/ 来/ 实现/ 的/ ./ 图/ 11/ 剖析/ 了/ 在/ ELF/ 管理/ 的/ 二级/ Cache/ 中/ 所有/ 负载/ 的/ 插入/ 和/ 提升/ 行为/ ,/ 从中/ 可以/ 看出/ ,/ 对于/ mix00/ 、/ mix02/ 、/ mix07/ 等/ 多道程序/ ,/ LRU/ 插入/ 占有/ 主导地位/ ,/ 而/ 对于/ mix03/ 、/ mix05/ 和/ mix08/ ,/ 则/ 以/ MRU/ 插入/ 为主/ ,/ 这/ 说明/ ELF/ 策略/ 可以/ 根据/ 负载/ 的/ 访存/ 行为/ 选择/ 合理/ 的/ 插入/ 策略/ ;/ 提升/ 行为/ 并/ 没有/ 插入/ 行为表现/ 得/ 那么/ 明显/ ,/ 几乎/ 所有/ 负载/ 都/ 以/ MP/ 提升/ 为主/ ,/ 但/ SIP/ 提升/ 仍/ 占据/ 一定/ 比例/ (/ 如/ mix02/ )/ ./ Cache/ 中/ ,/ 使得/ 至少/ 这部分/ 数据/ 可以/ 获得/ 较/ 高/ 的/ 命中率/ ./ 基于/ 这一/ 思想/ ,/ 本文/ 提出/ 一种/ 基于/ 无用/ 块/ 消除/ 和/ 低/ 重用/ 块/ 过滤/ (/ ELF/ )/ 的/ Cache/ 管理策略/ ,/ 主要/ 完成/ 以下/ 几个/ 方面/ 的/ 工作/ :/ (/ 1/ )/ 将/ 基于/ 计数/ 的/ 活动/ 时间/ 预测器/ LvP/ 扩展/ 到/ 多/ 核/ 处理器/ 中/ ,/ 即/ 在/ 二级/ Cache/ 和/ 主存/ 之间/ 增加/ 了/ 一个/ 独立/ 的/ 预测/ 表/ 硬件/ ,/ 用来/ 保存/ 没有/ 被/ 缓存/ 的/ 数据/ 的/ 使用/ 频率/ 历史/ 并且/ 在/ 数据/ 重新/ 进入/ Cache/ 时/ 恢复/ 使用/ 频率/ 信息/ ,/ 从而/ 完成/ 对/ 数据/ 块/ 使用/ 频率/ 的/ 预测/ ,/ 算法/ 的/ 全部/ 硬件/ 开销/ 约/ 为/ 4.18/ %/ ./ (/ 2/ )/ 提出/ 一种/ 针对/ 大容量/ 、/ 高/ 相联/ 度/ LLC/ 的/ Cache/ 管理策略/ ,/ 根据/ 预测器/ 的/ 预测/ 结果/ 标识/ 无用/ 数据/ 并/ 将/ 其/ 作为/ Cache/ 替换/ 的/ 优先选择/ ,/ 同时/ 将/ 低/ 使用/ 频率/ 数据/ 块/ 依/ 概率/ 插入/ 到/ LRU/ 位置/ ,/ 并且/ 在/ 后续/ 命中/ 仅/ 采用/ 单一/ 提升/ 策略/ ,/ 从而/ 保证/ 一部分/ 高/ 使用/ 频率/ 工作/ 集/ 可以/ 保留/ 在/ Cache/ 中/ ,/ 以/ 贡献/ 出较/ 高/ 的/ Cache/ 命中率/ ./ 在/ 4/ 路/ CMPs/ 上/ 的/ 实验/ 结果显示/ ,/ ELF/ 可以/ 将/ 全局性/ 能/ 平均/ 提升/ 14.5/ %/ ,/ 同时/ 与/ PIPP/ 和/ TADIP/ 相比/ ,/ 可以/ 分别/ 达到/ 1.06/ 倍/ 和/ 1.09/ 倍/ 的/ 加速/ 比/ ./ 并发/ 运行/ 的/ 应用/ 间/ 的/ 显著/ 干扰/ 会/ 给/ ELF/ 策略/ 的/ 性能/ 带来/ 负面/ 的/ 影响/ ,/ 为此/ 在/ 今后/ 的/ 工作/ 中/ ,/ 我们/ 拟/ 通过/ 分治/ 的/ 策略/ 解决/ 这一/ 问题/ ,/ 即将/ 共享/ LLC/ 划分/ 成/ 与/ 处理器/ 核/ 数目/ 相同/ 的/ 多个/ 组/ ,/ 每个/ 应用/ 映射/ Page10/ 到/ 一个组/ 中/ ,/ 组内/ 可/ 根据/ 应用/ 的/ 访存/ 行为/ 选择/ 适当/ 的/ Cache/ 管理策略/ ./ 

