Page1/ 神经网络/ 极速/ 学习/ 方法/ 研究/ 邓万宇/ 1/ )/ 郑庆华/ 1/ )/ 陈琳/ 2/ )/ 许学斌/ 1/ )/ 1/ )/ (/ 西安交通大学/ 电信/ 学院/ 计算机系/ 智能/ 网络/ 与/ 网络安全/ 教育部/ 重点/ 实验室/ 西安/ 710049/ )/ 2/ )/ (/ 西安/ 邮电学院/ 计算机科学/ 与/ 技术/ 系/ 西安/ 710061/ )/ 摘要/ 单/ 隐藏/ 层/ 前馈/ 神经网络/ (/ Single/ -/ hiddenLayerFeedforwardNeuralNetwork/ ,/ SLFN/ )/ 已经/ 在/ 模式识别/ 、/ 自动控制/ 及/ 数据挖掘/ 等/ 领域/ 取得/ 了/ 广泛/ 的/ 应用/ ,/ 但/ 传统/ 学习/ 方法/ 的/ 速度/ 远远/ 不能/ 满足/ 实际/ 的/ 需要/ ,/ 成为/ 制约/ 其/ 发展/ 的/ 主要/ 瓶颈/ ./ 产生/ 这种/ 情况/ 的/ 两个/ 主要/ 原因/ 是/ :/ (/ 1/ )/ 传统/ 的/ 误差/ 反向/ 传播/ 方法/ (/ BackPropagation/ ,/ BP/ )/ 主要/ 基于/ 梯度/ 下降/ 的/ 思想/ ,/ 需要/ 多次/ 迭代/ ;/ (/ 2/ )/ 网络/ 的/ 所有/ 参数/ 都/ 需要/ 在/ 训练/ 过程/ 中/ 迭代/ 确定/ ./ 因此/ 算法/ 的/ 计算/ 量/ 和/ 搜索/ 空间/ 很大/ ./ 针对/ 以上/ 问题/ ,/ 借鉴/ ELM/ 的/ 一次/ 学习/ 思想/ 并/ 基于/ 结构/ 风险/ 最小化/ 理论/ 提出/ 一种/ 快速/ 学习/ 方法/ (/ RELM/ )/ ,/ 避免/ 了/ 多次/ 迭代/ 和/ 局部/ 最小值/ ,/ 具有/ 良好/ 的/ 泛化/ 性/ 、/ 鲁棒性/ 与/ 可控性/ ./ 实验/ 表明/ RELM/ 综合性/ 能/ 优于/ ELM/ 、/ BP/ 和/ SVM/ ./ 关键词/ 极速/ 学习机/ ;/ 正则/ 极速/ 学习机/ ;/ 支持/ 向量/ 机/ ;/ 结构/ 风险/ ;/ 神经网络/ ;/ 最小/ 二乘/ 1/ 引言/ 单/ 隐藏/ 层/ 前馈/ 神经网络/ (/ Single/ -/ hiddenLayerFeedforwardNeuralNetwork/ ,/ SLFN/ )/ 之所以/ 能够/ 在/ 很多/ 领域/ 得到/ 广泛应用/ ,/ 是因为/ 它/ 有/ 很多/ 优点/ :/ (/ 1/ )/ 具有/ 很强/ 的/ 学习/ 能力/ ,/ 能够/ 逼近/ 复杂/ 非线性/ 函数/ ;/ (/ 2/ )/ 能够/ 解决/ 传统/ 参数/ 方法/ 无法/ 解决/ 的/ 问题/ ./ 但/ 另一方面/ 缺乏/ 快速/ 学习/ 方法/ ,/ 也/ 使/ 其/ 很多/ 时候/ 无法/ 满足/ 实际/ 需要/ ./ 对于/ SLFN/ 的/ 学习/ 能力/ ,/ 很多/ 文献/ 分别/ 从/ 紧集/ (/ compactinputsets/ )/ 和/ 有限/ 集/ (/ infiniteinputsets/ )/ 两种/ 输入/ 情况/ 进行/ 了/ 深入/ 讨论/ ./ Hornik/ 研究/ 表明/ :/ 如果/ 激励函数/ 连续/ 、/ 有界且/ 不是/ 常量/ 函数/ ,/ 那么/ SLFN/ 能够/ 在/ 紧集/ 情况/ 下/ 逼近/ 任何/ 连续函数/ [/ 1/ ]/ ;/ Leshno/ 在/ Hornik/ 基础/ 上/ 的/ 进一步/ 研究/ 表明/ :/ 使用/ 非/ 多项式/ 激励函数/ 的/ SLFN/ 能够/ 逼近/ 任何/ 连续函数/ [/ 2/ ]/ ./ 在/ 实际/ 应用/ 中/ ,/ 神经网络/ 的/ 输入/ 往往/ 是/ 有限/ 集/ ,/ 对于/ 有限/ 集/ 情况/ 下/ SLFN/ 的/ 学习/ 能力/ ,/ Huang/ 和/ Babri/ 等/ 进行/ 了/ 研究/ ,/ 结果表明/ :/ 对于/ 含有/ N/ 个/ 不同/ 实例/ 的/ 有限/ 集/ ,/ 一个/ 具有/ 非线性/ 激励函数/ 的/ SLFN/ 最/ 多只/ 需/ N/ 个/ 隐藏/ 层/ 结点/ ,/ 就/ 可以/ 无/ 误差/ 地/ 逼近/ 这/ N/ 个/ 实例/ [/ 3/ -/ 4/ ]/ ./ 这就是说/ ,/ 一个/ 具有/ N/ 个/ 隐藏/ 层/ 结点/ 的/ SLFN/ ,/ 即使/ 输入/ 权值/ 随机/ 取值/ ,/ 它/ 也/ 能够/ 准确/ 拟合/ N/ 个/ 不同/ 的/ 实例/ ,/ 更/ 明确/ 地/ 讲/ 就是/ :/ SLFN/ 的/ 学习/ 能力/ 只/ 和/ 隐藏/ 层/ 结点/ 的/ 数目/ 有关/ ,/ 而/ 和/ 输入/ 层/ 的/ 权值/ 无关/ ./ 虽然/ 这/ 一点/ 对于/ 提出/ 一种/ 新/ 的/ 学习/ 算法/ 很/ 有/ 启发/ ,/ 但/ 并未/ 引起/ 研究者/ 的/ 注意/ ,/ 迭代/ 调整/ 的/ 思想/ 一直/ 坚持/ 到/ 现在/ ,/ 很多/ 算法/ 都/ 只是/ 围绕/ 这一/ 思想/ 进行/ 技巧性/ 的/ 改进/ ./ 不同于/ 传统/ 的/ 学习/ 方法/ ,/ Huang/ 基于/ 以上/ 研究/ 结论/ 为/ SLFN/ 提出/ 了/ 一种/ 称为/ 极速/ 学习机/ (/ ExtremeLearningMachine/ ,/ ELM/ )/ 的/ 学习/ 方法/ [/ 5/ ]/ :/ 设置/ 合适/ 的/ 隐藏/ 层/ 结点/ 数/ ,/ 为/ 输入/ 权/ 和/ 隐藏/ 层/ 偏差/ 进行/ 随机/ 赋值/ ,/ 然后/ 输出/ 层权值/ 通过/ 最小/ 二/ 乘法/ 得到/ ./ 整个/ 过程/ 一次/ 完成/ ,/ 无需/ 迭代/ ,/ 与/ BP/ 相比/ 速度/ 显著/ 提高/ (/ 通常/ 10/ 倍/ 以上/ )/ ./ 但是/ ELM/ 是/ 基于/ 经验/ 风险/ 最小化/ 原理/ ,/ 这/ 可能/ 会/ 导致/ 过度/ 拟合/ 问题/ [/ 6/ ]/ ./ 此外/ 因为/ ELM/ 不/ 考虑/ 误差/ 的/ 权重/ ,/ 当/ 数据/ 集中/ 存在/ 离群/ 点时/ ,/ 它/ 的/ 性能/ 将会/ 受到/ 严重/ 影响/ [/ 7/ ]/ ./ 为了/ 克服/ 这些/ 缺点/ ,/ 我们/ 结合/ 结构/ 风险/ 最小化/ 理论/ 以及/ 加权/ 最小/ 二/ 乘法/ 对/ ELM/ 算法/ 进行/ 改进/ ,/ 使得/ ELM/ 在/ 保持/ “/ 快速/ ”/ 这一/ 优势/ 的/ 前提/ 下/ ,/ 泛化/ 性能/ 得到/ 进一步/ 的/ 提高/ ./ 2SLFN/ 的/ 统一/ 模型/ 对于/ N/ 个/ 不同/ 样本/ (/ 狓/ i/ ,/ 狋/ i/ )/ ,/ 其中/ 狓/ i/ =/ [/ xi1/ ,/ xi2/ ,/ …/ ,/ xin/ ]/ T/ ∈/ Rn/ ,/ 狋/ i/ =/ [/ ti1/ ,/ ti2/ ,/ …/ ,/ tim/ ]/ T/ ∈/ Rm/ ,/ 一个/ 隐藏/ 层/ 结点/ 数目/ 为/ 珦/ N/ 、/ 激励函数/ 为/ g/ (/ x/ )/ 的/ SLFN/ 的/ 统一/ 模型/ 为/ ∑/ 珦/ Ni/ =/ 1/ β/ igi/ (/ 狓/ j/ )/ =/ ∑/ 珦/ N/ 其中/ 犪/ i/ =/ [/ ai1/ ,/ ai2/ ,/ …/ ,/ ain/ ]/ T/ 是/ 连接/ 第/ i/ 个/ 隐藏/ 层/ 结点/ 的/ 输入/ 权值/ ;/ bi/ 是/ i/ 个/ 隐藏/ 层/ 结点/ 的/ 偏差/ (/ bias/ )/ ;/ β/ i/ =/ [/ β/ i1/ ,/ β/ i2/ ,/ …/ ,/ β/ im/ ]/ T/ 是/ 连接/ i/ 个/ 隐藏/ 层/ 结点/ 的/ 输出/ 权值/ ;/ 犪/ i/ ·/ 狓/ j/ 表示/ 犪/ i/ 和/ 狓/ j/ 的/ 内积/ ./ 激励函数/ g/ (/ x/ )/ 可以/ 是/ “/ Sigmoid/ ”/ 、/ “/ Sine/ ”/ 或/ “/ RBF/ ”/ 等/ ./ 上述/ N/ 个/ 方程/ 的/ 矩阵/ 形式/ 可写/ 为/ 其中/ 犎/ (/ 犪/ 1/ ,/ …/ ,/ 犪/ 珦/ N/ ,/ b1/ ,/ …/ ,/ b/ 珦/ N/ ,/ 狓/ 1/ ,/ …/ ,/ 狓/ N/ )/ =/ g/ (/ 犪/ 1/ ·/ 狓/ 1/ +/ b1/ )/ …/ g/ (/ 犪/ 珦/ N/ ·/ 狓/ 1/ +/ b/ 珦/ N/ )/ 熿/ g/ (/ 犪/ 1/ ·/ 狓/ N/ +/ b1/ )/ …/ g/ (/ 犪/ 珦/ N/ ·/ 狓/ N/ +/ b/ 珦/ N/ 燀/ 熿/ β/ =/ 燀/ E/ (/ 犠/ )/ 表示/ 期望值/ 和/ 实际/ 值/ 之间/ 的/ 误差/ 平方和/ ,/ 问题/ 求解/ 就是/ 寻找/ 最优/ 的/ 权/ 值/ 犠/ =/ (/ 犪/ ,/ 犫/ ,/ β/ )/ 使/ 代价/ 函数/ E/ (/ 犠/ )/ 最小/ ,/ 其/ 数学模型/ 可/ 表示/ 为/ argmin/ 犠/ =/ (/ 犪/ ,/ 犫/ ,/ β/ )/ E/ (/ 犠/ )/ =/ argmin/ 犠/ =/ (/ 犪/ ,/ 犫/ ,/ β/ )/ ‖/ ε/ ‖/ 2/ ,/ s/ ./ t/ ./ ∑/ 珦/ Ni/ =/ 1/ β/ ig/ (/ 犪/ i/ ·/ 狓/ j/ +/ bi/ )/ -/ 狋/ j/ =/ ε/ j/ ,/ j/ =/ 1/ ,/ 2/ ,/ …/ ,/ N/ 其中/ ε/ j/ =/ [/ ε/ j1/ ,/ ε/ j2/ ,/ …/ ,/ ε/ jm/ ]/ 是/ 第/ j/ 个/ 样本/ 的/ 误差/ ./ 为例/ 进行/ 研究/ ,/ 但/ 所得/ 结论/ 仍/ 适用/ 于/ 多维/ 情况/ ./ 3BP/ 为了/ 方便/ 讨论/ ,/ 在/ 后/ 文中/ 将/ 以/ 一维/ 输出/ (/ m/ =/ 1/ )/ 由/ Rumelhart/ 和/ McClelland/ 提出/ 的/ BP/ 神经网络/ 模型/ 是/ 目前/ 应用/ 最/ 广泛/ 的/ 模型/ 之一/ [/ 8/ ]/ ,/ BP/ 训练方法/ 是/ 通过/ 反向/ 误差/ 传播/ 原理/ 不断/ 调整/ 网络/ 权值/ 使得/ 实际/ 输出/ 与/ 期望/ 输出/ 之间/ 的/ 误差/ 平方和/ 达到/ 最小/ 或/ 小于/ 某个/ 阈值/ ./ 当/ 犎/ 未知/ 时/ ,/ 通常/ 采用/ 梯度/ 下降/ 法/ Page3/ 迭代/ 调整/ 犠/ :/ 其中/ η/ 代表/ 学习/ 速率/ ./ 基于/ 梯度/ 下降/ 法/ 的/ BP/ 存在/ 以下/ 缺点/ :/ (/ 1/ )/ 训练/ 速度慢/ ./ 因为/ 需要/ 多次/ 的/ 迭代/ ,/ 所以/ 时间/ 消耗/ 很长/ ./ (/ 2/ )/ 参数/ 选择/ 很/ 敏感/ ,/ 必须/ 选取/ 合适/ 的/ η/ 与/ 犠/ 初值/ ,/ 才能/ 取得/ 理想/ 的/ 结果/ ./ 若/ η/ 太小/ ,/ 算法/ 收敛/ 很/ 慢/ ,/ 而/ η/ 太/ 大/ ,/ 算法/ 不太/ 稳定/ 甚至/ 不再/ 收敛/ ;/ (/ 3/ )/ 局部/ 最小值/ ./ 由于/ E/ (/ 犠/ )/ 非凸/ ,/ 因此/ 在/ 下降/ 过程/ 中/ 可能/ 会/ 陷入/ 局部/ 最小/ 点/ ,/ 无法/ 达到/ 全局/ 最小/ [/ 9/ ]/ ;/ (/ 4/ )/ 过渡/ 拟合/ ./ 在/ 有限/ 样本/ 上/ 训练/ 时/ ,/ 仅以/ 训练/ 误差/ 最小/ 为/ 目标/ 的/ 训练/ 可能/ 导致/ 过渡/ 拟合/ ./ 4ELMSLFN/ 提出/ 了/ ELM/ 学习/ 算法/ ./ 为了/ 解决/ 以上/ 问题/ ,/ Huang/ 基于/ 以下/ 定理/ 为/ 定理/ 1/ [/ 5/ ]/ ./ 对于/ 任意/ N/ 个/ 不同/ 样本/ (/ 狓/ i/ ,/ 狋/ i/ )/ ,/ 其中/ 狓/ i/ =/ [/ xi1/ ,/ xi2/ ,/ …/ ,/ xin/ ]/ T/ ∈/ Rn/ ,/ 狋/ i/ =/ [/ ti1/ ,/ ti2/ ,/ …/ ,/ tim/ ]/ T/ ∈/ Rm/ ,/ N/ 个/ 隐藏/ 层/ 结点/ 和/ 一个/ 任意/ 区间/ 无限/ 可导/ 的/ 激活/ 函数/ g/ :/ R/ →/ R/ ,/ 则/ SLFN/ 在/ 犪/ i/ ∈/ Rn/ 和/ bi/ ∈/ R/ 任意/ 赋值/ 的/ 情况/ 下/ ,/ 所/ 形成/ 的/ 隐藏/ 层/ 矩阵/ 犎/ 可逆/ ,/ 即/ 方程组/ 有/ 精确/ 解/ ,/ 代价/ 函数/ E/ (/ 犠/ )/ =/ 0/ ./ 定理/ 2/ [/ 5/ ]/ ./ 给定/ 任意/ N/ 个/ 不同/ 样本/ (/ 狓/ i/ ,/ 狋/ i/ )/ ,/ 任意/ 小/ 误差/ e/ >/ 0/ ,/ 及/ 在/ 任意/ 区间/ 无限/ 可导/ 的/ 激活/ 函数/ g/ :/ R/ →/ R/ ,/ 总/ 存在/ 一个/ 包含/ 珦/ N/ (/ 珦/ N/ / N/ )/ 个/ 隐藏/ 层/ 结点/ 的/ SLFN/ ,/ 使得/ 在/ 犪/ i/ ∈/ Rn/ 和/ bi/ ∈/ R/ 任意/ 取值/ 情况/ 下/ ,/ 误差/ E/ (/ 犠/ )/ / e/ ./ 定理/ 1/ 和/ 定理/ 2/ 的/ 详细/ 证明/ 可/ 参考文献/ [/ 4/ -/ 5/ ,/ 10/ ]/ ./ 定理/ 表明/ :/ 只要/ 隐含/ 层/ 结点/ 数/ 足够/ 多/ ,/ SLFN/ 就/ 能/ 在/ 输入/ 权/ 随机/ 赋值/ 情况/ 下/ 逼近/ 任何/ 连续函数/ ./ 但/ 为了/ 使/ SLFN/ 具有/ 良好/ 的/ 泛化/ 性能/ ,/ 通常/ 珦/ N/ / N/ ./ 当/ 输入/ 权以/ 随机/ 赋值/ 的/ 方式/ 确定/ 后/ ,/ 所得/ 隐藏/ 层/ 矩阵/ 犎/ 便是/ 一个/ 确定/ 的/ 矩阵/ ,/ 因此/ 训练/ SLFN/ 就/ 转化/ 为/ 计算/ 犎/ β/ =/ 犜/ 的/ 最小/ 二乘解/ 问题/ ./ 关于/ ELM/ 的/ 细节/ 请/ 参考文献/ [/ 5/ ]/ ./ 与/ BP/ 相比/ ELM/ 需要/ 调整/ 的/ 参数/ 只有/ 隐含/ 层/ 结点/ 个数/ 珦/ N/ ,/ 目前/ 虽/ 没有/ 精确/ 估计/ 珦/ N/ 的/ 方法/ ,/ 但/ 珦/ N/ / N/ 大大/ 缩小/ 了/ 搜索/ 范围/ ,/ 在/ 实际/ 应用/ 中/ 珦/ N/ 可以/ 通过/ 交叉/ 验证/ 的/ 方式/ 确定/ ./ 在/ 标准/ UCI/ 数据/ 集上/ 的/ 大量/ 实验/ 表明/ ELM/ 训练/ 速度/ 快/ ,/ 泛化/ 性能/ 良好/ ,/ 但/ ELM/ 仍/ 有/ 一些/ 缺点/ :/ (/ 1/ )/ ELM/ 仅/ 考虑/ 经验/ 风险/ ,/ 没有/ 考虑/ 到/ 结构化/ 风险/ ,/ 因此/ 可能/ 导致/ 过度/ 拟合/ 问题/ ;/ (/ 2/ )/ ELM/ 直接/ 计算/ 最小/ 二乘解/ ,/ 用户/ 无法/ 根据/ 数据/ 集/ 的/ 特征/ 进行/ 微调/ ,/ 可控性/ 差/ ;/ (/ 3/ )/ 当/ 数据/ 集中/ 存在/ 离群/ 点时/ ,/ 模型/ 性能/ 将会/ 受到/ 很大/ 影响/ ,/ 鲁棒性/ 较差/ ./ 为了/ 克服/ 这些/ 缺点/ ,/ 我们/ 把/ 结构/ 风险/ 最小化/ 理论/ 以及/ 加权/ 最小/ 二/ 乘法/ 引入/ 到/ ELM/ 中/ ,/ 提出/ 一种/ 正则/ 极速/ 学习机/ (/ RegularizedExtremeLearningMachine/ ,/ RELM/ )/ ./ 5/ 正则/ 极速/ 学习机/ (/ RELM/ )/ 根据/ 统计学/ 理论/ 可知/ ,/ 实际/ 风险/ 包括/ 经验/ 风险/ 和/ 结构/ 风险/ 两种/ 成分/ [/ 11/ ]/ ./ 一个/ 具有/ 较/ 好/ 泛化/ 性能/ 的/ 模型/ 应该/ 能/ 权衡/ 这/ 两种/ 风险/ ,/ 并/ 取得/ 最佳/ 的/ 折中/ ./ RELM/ 将/ 同时/ 考虑/ 这/ 两种/ 风险/ 因素/ ,/ 并/ 通过/ 参数/ γ/ 调节/ 两种/ 风险/ 的/ 比例/ ,/ RELM/ 的/ 数学模型/ 可/ 表示/ 为/ argmin/ β/ E/ (/ 犠/ )/ =/ argmin/ β/ s/ ./ t/ ./ ∑/ 珦/ Ni/ =/ 1/ β/ ig/ (/ 犪/ i/ ·/ 狓/ j/ +/ bi/ )/ -/ 狋/ j/ =/ ε/ j/ ,/ j/ =/ 1/ ,/ 2/ ,/ …/ ,/ N/ ,/ 其中/ ,/ 误差/ 的/ 平方和/ ‖/ ε/ ‖/ 2/ 代表/ 经验/ 风险/ ;/ ‖/ β/ ‖/ 2/ 代表/ 结构/ 风险/ ,/ 它/ 源于/ 统计/ 理论/ 中/ 边缘/ 距离/ 最大化/ 原理/ [/ 12/ -/ 13/ ]/ ;/ 而/ γ/ 则/ 是/ 两种/ 风险/ 的/ 比例/ 参数/ ,/ 通过/ 交叉/ 验证/ 的/ 方式/ 确定/ γ/ 来/ 获得/ 两种/ 风险/ 的/ 最佳/ 折中/ 点/ ./ 为了/ 获得/ 一个/ 抗干扰/ 模型/ ,/ 我们/ 为/ 不同/ 样本/ 的/ 误差/ 进行/ 加权/ ,/ ‖/ ε/ ‖/ 2/ 被/ 扩展/ 为/ ‖/ 犇/ ε/ ‖/ 2/ ./ 其中/ 犇/ =/ diag/ (/ v1/ ,/ v2/ ,/ …/ ,/ vN/ )/ 表示/ 误差/ 的/ 权值/ 对角/ 阵/ ./ RELM/ 的/ 模型/ 进一步/ 修正/ 为/ argmin/ β/ s/ ./ t/ ./ ∑/ 珦/ Ni/ =/ 1/ β/ ig/ (/ 犪/ i/ ·/ 狓/ j/ +/ bi/ )/ -/ 狋/ j/ =/ ε/ j/ ,/ j/ =/ 1/ ,/ 2/ ,/ …/ ,/ N/ ./ 上式/ 是/ 条件极值/ 问题/ ,/ 通过/ 拉格朗/ 日/ 方程/ 转换/ 为/ 无/ 条件极值/ 问题/ 进行/ 求解/ :/ / (/ β/ ,/ ε/ ,/ α/ )/ =/ γ/ Page4/ 其中/ α/ =/ [/ α/ 1/ ,/ α/ 2/ ,/ …/ ,/ α/ N/ ]/ ;/ α/ j/ ∈/ Rm/ (/ j/ =/ 1/ ,/ 2/ ,/ …/ ,/ N/ )/ 代表/ 拉格朗/ 日/ 乘子/ ./ 求/ 拉格朗/ 日/ 方程/ 的/ 梯度/ 并令/ 其为/ 0/ :/ 把/ 方程/ (/ 5c/ )/ 代入/ 方程/ (/ 5b/ )/ 得/ 把/ 式/ (/ 6/ )/ 代入/ 方程/ (/ 5a/ )/ 得/ 表达式/ (/ 7/ )/ 只/ 含有/ 一个/ 珦/ N/ ×/ 珦/ N/ (/ 珦/ N/ / N/ )/ 矩阵/ 的/ 逆/ 操作/ ,/ 所以/ 计算/ β/ 的/ 速度/ 非常/ 快/ ./ 5.1/ 无权/ RELM/ 在/ 实际/ 应用/ 中/ ,/ 如果/ 数据/ 集中/ 离群/ 点/ 很少/ ,/ 对模型/ 没有/ 太/ 大/ 影响/ ,/ 那么/ 为了/ 加快/ 训练/ 速度/ ,/ 可以/ 认为/ 每个/ 样本/ 的/ 误差/ 权值/ 相同/ ,/ 此时/ 矩阵/ 犇/ =/ diag/ (/ v1/ ,/ v2/ ,/ …/ ,/ vN/ )/ 将/ 是/ 一个/ 单位/ 阵/ ,/ 无须/ 计算/ ./ 我们/ 称/ 这种/ 情况/ 的/ RELM/ 为/ 无权/ RELM/ ,/ 无权/ RELM/ 算法/ 可/ 归结/ 如下/ :/ 算法/ 1/ ./ 无权/ RELM/ ./ 给定/ 一个/ 训练/ 集/ / =/ {/ (/ 狓/ i/ ,/ 狋/ i/ )/ |/ 狓/ i/ ∈/ Rn/ ,/ 狋/ i/ ∈/ Rm/ ,/ i/ =/ 1/ ,/ 2/ ,/ …/ ,/ N/ }/ 、/ 激励函数/ g/ (/ x/ )/ 及/ 隐藏/ 层/ 结点/ 数/ 珦/ N/ ,/ (/ 1/ )/ 随机/ 指定/ 输入/ 权/ 值/ 犪/ i/ 和/ 偏差/ bi/ (/ i/ =/ 1/ ,/ 2/ ,/ …/ ,/ 珦/ N/ )/ ./ (/ 2/ )/ 计算/ 隐藏/ 层/ 输出/ 矩阵/ 犎/ =/ (/ 3/ )/ 计算/ 输出/ 权值/ β/ :/ β/ =/ 犐/ 通过观察/ 不难看出/ ,/ RELM/ 与/ ELM/ 计算/ 量/ 基本/ 一样/ ./ 其实/ ELM/ 是/ 未/ 加权/ RELM/ 的/ 一种/ 特殊/ 情况/ ./ 定理/ 3/ ./ 当/ γ/ →/ 时/ ,/ 未/ 加权/ RELM/ 将/ 退化/ 为/ 证明/ ./ 若/ γ/ →/ ,/ 则/ 犐/ ELM/ ./ β/ =/ 犐/ 5.2/ 加权/ RELM/ 与/ 无权/ RELM/ 相反/ ,/ 如果/ 数据/ 含有/ 离群/ 点/ ,/ 那么/ 使用/ 加权/ RELM/ 有/ 一定/ 的/ 抗干扰能力/ ,/ 这/ 可以/ 从/ 后面/ “/ SinC/ ”/ 数据/ 集/ 离群/ 点/ 加入/ 前后/ 的/ 实验/ 对比/ 中/ 看出/ ./ 加权/ RELM/ 需要/ 计算误差/ 的/ 权值/ ,/ 权值/ 计算/ 已有/ 很多/ 论述/ [/ 7/ ,/ 14/ ]/ ,/ 这里/ 采用/ 文献/ [/ 15/ ]/ 提到/ 的/ 方法/ :/ 其中/ ε/ j/ =/ -/ α/ j/ γ/ ,/ 它/ 是/ 无权/ RELM/ 计算/ 得到/ 的/ 样本/ 误差/ ,/ ^/ s/ 是/ 误差/ ε/ j/ 的/ 标准偏差/ (/ standarddeviation/ )/ 估计/ ,/ 可/ 通过/ 公式/ ^/ s/ =/ 1.483/ MAD/ (/ xj/ )/ 计算/ ./ MAD/ (/ MedianAbsoluteDeviation/ )/ 表示/ 绝对/ 中/ 位差/ ./ 根据/ 高斯分布/ 可知/ :/ 基本/ 不/ 存在/ 大于/ 2.5/ ^/ s/ 的/ 误差/ ,/ 因此/ 常量/ c1/ 和/ c2/ 通常/ 被/ 置/ 为/ c1/ =/ 2.5/ ,/ c2/ =/ 3/ [/ 7/ ]/ ./ 综上所述/ ,/ RELM/ 算法/ 可/ 归结/ 如下/ :/ 算法/ 2/ ./ 加权/ RELM/ ./ 给定/ 一个/ 训练/ 集/ / =/ {/ (/ 狓/ i/ ,/ 狋/ i/ )/ |/ 狓/ i/ ∈/ Rn/ ,/ 狋/ i/ ∈/ Rm/ ,/ i/ =/ 1/ ,/ 2/ ,/ …/ ,/ N/ }/ 、/ 激励函数/ g/ (/ x/ )/ 以及/ 隐藏/ 层/ 结点/ 数/ 珦/ N/ ,/ (/ 1/ )/ 随机/ 指定/ 输入/ 权/ 值/ 犪/ i/ 、/ 偏差/ bi/ (/ i/ =/ 1/ ,/ 2/ ,/ …/ ,/ 珦/ N/ )/ 并且/ 计算/ 隐藏/ 层/ 输出/ 矩阵/ 犎/ ./ (/ 2/ )/ β/ =/ 犐/ (/ 3/ )/ α/ =/ -/ γ/ (/ 犎/ β/ -/ 犜/ )/ T/ ./ (/ 4/ )/ ε/ i/ =/ α/ i/ (/ 5/ )/ ^/ s/ =/ 1.483/ MAD/ (/ 狓/ j/ )/ ./ (/ 6/ )/ 犇/ =/ diag/ (/ v1/ ,/ v2/ ,/ …/ ,/ vN/ )/ :/ (/ 7/ )/ β/ =/ 犐/ 加权/ RELM/ 多/ 了/ 计算/ 权值/ 的/ 过程/ ,/ 时间/ 消耗/ 有所/ 延长/ ,/ 因此/ 如果/ 实际/ 应用/ 中/ 对/ 训练/ 时间/ 要求/ 很强/ ,/ 那么/ 用/ 无权/ RELM/ 比较/ 合适/ ./ 在/ 下面/ 的/ 实验/ 中/ ,/ 除/ 为了/ 验证/ RELM/ 的/ 鲁棒性/ 在/ “/ SinC/ ”/ 数据/ 集上/ 采用/ 加权/ RELM/ 和/ ELM/ 进行/ 比较/ 外/ ,/ 其它/ 数据/ 集/ 的/ 实验/ 一律/ 采用/ 无权/ RELM/ 和/ ELM/ 进行/ 比较/ ./ RELM/ 与/ ELM/ 相比/ ,/ 具有/ 如下/ 特点/ :/ (/ 1/ )/ 方程组/ 的/ 解是/ 犎/ β/ =/ 犜/ 的/ 一个/ 加权/ 最小/ 二/ ‖/ 犎/ β/ ^/ -/ 犜/ ‖/ =/ ‖/ 犎/ (/ 犎/ T/ 犇/ 2/ 犎/ )/ 犎/ T/ 犇/ 2/ 犜/ -/ 犜/ ‖/ 这个/ 解/ 不但/ 可以/ 达到/ 最小/ 的/ 训练/ 误差/ ,/ 同时/ 对/ 乘解/ :/ 离群/ 点/ 具有/ 一定/ 的/ 抗干扰能力/ ./ (/ 2/ )/ 通过/ 引入/ 调节/ 参数/ γ/ ,/ 代价/ 函数/ 不仅/ 包括/ 经/ Page5/ 验/ 风险/ ,/ 还/ 包括/ 结构/ 风险/ ,/ 这/ 使得/ 方程组/ 的/ 解/ 不仅/ 获得/ 尽可能/ 小/ 的/ 训练/ 误差/ ,/ 而且/ 能/ 使/ 边缘/ 距离/ 最大化/ ,/ 从而/ 具有/ 更好/ 的/ 泛化/ 性能/ :/ 犎/ 犐/ argmin/ β/ γ/ ‖/ 犎/ β/ -/ 犜/ ‖/ +/ ‖/ β/ ‖/ 6/ 性能/ 评估/ 这里/ 我们/ 通过/ 实验/ 结果/ 比较/ RELM/ 、/ ELM/ 、/ BP/ 和/ 支持/ 向量/ 机/ (/ SupportVectorMachine/ ,/ SVM/ )/ [/ 12/ -/ 13/ ]/ 的/ 性能/ ./ RELM/ 、/ ELM/ 和/ BP/ 的/ 执行/ 环境/ 是/ Matlab7/ ./ 0/ ,/ SVM/ 的/ 执行/ 环境/ 是/ C语言/ ./ RELM/ 由/ 我们/ 自己/ 实现/ ,/ ELM/ 的/ 源代码/ 可以/ 从/ Huang/ 的/ 个人主页/ 直接/ 下载/ ①/ ,/ 而/ BP/ 算法/ 已经/ 集成/ 在/ Matlab/ 自带/ 的/ 神经网络/ 工具箱/ 中/ ,/ 可以/ 直接/ 使用/ ./ BP/ 算法/ 有/ 很多/ 变种/ ,/ 我们/ 选择/ 最快/ 的/ Levenberg/ -/ Marquardt/ 算法/ 来/ 进行/ 实验/ ./ SVM/ 算法/ 我们/ 采用/ C语言/ 实现/ 的/ SVM/ 包/ :/ LibSVM/ ②/ ./ RELM/ 、/ ELM/ 和/ BP/ 的/ 激励函数/ 都/ 选择/ “/ Sigmoid/ ”/ 函数/ :/ g/ (/ x/ )/ =/ 1/ // (/ 1/ +/ exp/ (/ -/ x/ )/ )/ ,/ 而/ SVM/ 的/ 核/ 函数/ 选择/ 径向/ 基/ 函数/ ./ 实验/ 数据/ 的/ 输入/ 一律/ 归一化/ 到/ [/ 0/ ,/ 1/ ]/ 范围/ 内/ ,/ 而/ 输出/ 则/ 归一化/ 到/ [/ -/ 1/ ,/ 1/ ]/ 范围/ 内/ ./ 值得/ 指出/ 的/ 是/ ,/ 这里/ 汇总/ 的/ 实验/ 结果/ 都/ 是/ 每种/ 算法/ 能够/ 达到/ 的/ 最优/ 实验/ 结果/ ./ 对于/ SVM/ ,/ 我们/ 采用/ Hsu/ 和/ Lin/ 提出/ 的/ 排列组合/ 方式/ [/ 16/ ]/ 选择/ 最优/ 的/ 表/ 14/ 种/ 算法/ 在/ “/ SinC/ ”/ 数据/ 集上/ 的/ 性能/ 比较/ RELMELMBPSVM/ 为了/ 比较/ RELM/ 和/ ELM/ 算法/ 的/ 鲁棒性/ ,/ “/ SinC/ ”/ 训练/ 集中/ 加入/ 了/ 一些/ 离群/ 点后/ 进行/ 重新/ 实验/ ./ 实验/ 结果/ 见图/ 1/ ,/ 从图/ 中/ 可以/ 看出/ ELM/ 的/ 预测/ 曲线/ 明显/ 脱离实际/ 曲线/ ,/ 说明/ 其/ 受到/ 离群/ 点/ 的/ 干扰/ 很大/ ./ 而/ RELM/ 的/ 预测/ 曲线/ 仍能/ 完好/ 地/ 拟合/ 实际/ 曲线/ ,/ 说明/ RELM/ 具有/ 一定/ 的/ 抗干扰能力/ ./ 6.1/ ./ 2/ 实际/ 回归/ 问题/ 我们/ 在/ 13/ 种/ 真实/ 数据/ 集/ ③/ 上将/ RELM/ 与/ ELM/ 、/ BP/ 、/ SVM/ 进行/ 比较/ ,/ 数据/ 集/ 信息/ 见表/ 2.4/ 种/ 算法/ 的/ RMSE/ 见表/ 3/ ./ 从表/ 3/ 可以/ 看出/ ,/ RELM/ 在/ 大多数/ 据集/ 上/ 的/ 测试/ RMSE/ 比/ ELM/ 、/ BP/ 、/ SVM/ 小/ ,/ 参数/ γ/ 和/ C/ :/ γ/ =/ [/ 24/ ,/ 23/ ,/ …/ ,/ 2/ -/ 10/ ]/ ,/ C/ =/ [/ 212/ ,/ 211/ ,/ …/ ,/ 2/ -/ 2/ ]/ ./ 共有/ 15/ ×/ 15/ =/ 225/ 种/ 组合/ ,/ 对/ 每/ 一种/ 组合/ (/ γ/ ,/ C/ )/ ,/ 进行/ 50/ 次/ 随机/ 实验/ ,/ 并/ 对/ 最佳/ 平均值/ 进行/ 汇总/ ./ 对于/ RELM/ ,/ 我们/ 采用/ 类似/ 于/ SVM/ 的/ 方式/ 选择/ 最优/ 的/ 参数/ γ/ 和/ 隐藏/ 层/ 结点/ 数/ 珦/ N/ :/ γ/ =/ [/ 2/ -/ 50/ ,/ 2/ -/ 49/ ,/ …/ ,/ 250/ ]/ ,/ 珦/ N/ =/ [/ 5/ ,/ 10/ ,/ …/ ,/ 珦/ Nmax/ ]/ (/ 珦/ Nmax/ 根据/ 具体/ 数据/ 集/ 设定/ )/ ./ 对于/ 所/ 产生/ 的/ 每个/ 组合/ (/ γ/ ,/ 珦/ N/ )/ ,/ 进行/ 50/ 次/ 随机/ 实验/ ,/ 并/ 对/ 最佳/ 平均值/ 进行/ 汇总/ ./ 对于/ ELM/ 和/ BP/ ,/ 隐藏/ 层/ 结点/ 的/ 个数/ 初始/ 取/ 5/ ,/ 每次/ 递增/ 5/ ,/ 并/ 基于/ 5/ -/ 折/ 交叉/ 验证/ 的/ 方法/ 选择/ 最优/ (/ 接近/ )/ 的/ 数目/ ,/ 然后/ 进行/ 50/ 次/ 实验/ 并/ 将/ 最佳/ 平均/ 结果/ 进行/ 汇总/ ./ 6.1/ 回归/ 问题/ 6.1/ ./ 1/ 人工/ 数据/ :/ “/ SinC/ ”/ “/ SinC/ ”/ 函数/ 表达式/ :/ y/ (/ x/ )/ =/ sinx/ // x/ ,/ x/ ≠/ 0/ 数据/ 产生/ 方法/ :/ 在/ 区间/ (/ -/ 10/ ,/ 10/ )/ 内/ 随机/ 产生/ 5000/ 个/ 训练样本/ 和/ 测试/ 样本/ ,/ 并/ 在/ 所有/ 训练样本/ 上/ 附加/ 取值/ 范围/ 为/ [/ -/ 0.2/ ,/ 0.2/ ]/ 的/ 随机噪声/ ,/ 而/ 测试数据/ 无/ 噪声/ ./ 各种/ 算法/ 的/ 性能/ 见表/ 1/ ./ 从表/ 1/ 可以/ 看出/ RELM/ 的/ RMSE/ (/ RootMeanSquareError/ ,/ 均/ 方根/ 误差/ )/ 比/ ELM/ 小/ ,/ 分别/ 为/ 0.0078/ 和/ 0.0097/ ;/ 不过/ RELM/ 训练/ 时间/ 比/ ELM/ 稍长/ ;/ RELM/ 的/ RMSE/ 明显/ 比/ BP/ 算法/ 和/ SVM/ 算法/ 要/ 小/ ,/ 而/ 训练/ 时间/ 却/ 比/ BP/ 和/ SVM/ 缩短/ 了/ 上/ 百倍/ ./ 由此可见/ 在/ “/ SinC/ ”/ 数据/ 集上/ ,/ RELM/ 综合性/ 能/ 最好/ ./ 0.00780/ ./ 00970.01590/ ./ 0130/ 说明/ 其有/ 更好/ 的/ 泛化/ 性能/ (/ 如果/ 两种/ 算法/ 的/ RMSE/ 相差/ 大于/ 0.005/ 时/ ,/ 较/ 好/ 的/ RMSE/ 加粗/ 表示/ )/ ;/ 表/ 4/ 汇总/ 了/ 4/ 种/ 算法/ 的/ 时间/ 消耗/ ,/ 从表/ 4/ 可以/ 看出/ RELM/ 的/ 训练/ 速度/ 和/ ELM/ 相差无几/ ,/ 却/ 比/ BP/ 和/ SVM/ 快/ 很多/ 倍/ ./ 但是/ 由于/ BP/ 具有/ 最/ 紧凑/ 网络结构/ (/ 隐藏/ 层/ 结点/ 数/ 最少/ )/ ,/ 在/ 4/ 种/ 算法/ 中/ BP/ 测试/ 时间/ 最短/ ;/ 表/ 5/ 汇总/ 了/ 4/ 种/ 算法/ 的/ 标准偏差/ ./ ①/ ②/ ③/ lin/ // libsvm/ // Page6/ 图/ 1/ 加入/ 离群/ 点/ 前后/ “/ SinC/ ”/ 曲线拟合/ 效果/ 比较/ 表/ 2/ 回归/ 数据/ 集/ 信息/ 数据/ 集/ AbaloneDeltaailerons3000412960ServoDeltaelevators4000551760Breastcancer10094320Computeractivity4000419280Bankdomains4500369280CensusAutopriceTriazines/ 表/ 34/ 种/ 不同/ 算法/ 的/ 均/ 方差/ (/ RMSE/ )/ 比较/ SVM/ 的/ RMSE/ 训练样本/ 测试/ 样本/ AbaloneDeltaailerons0/ ./ 04090.04810/ ./ 04180.04290/ ./ 04230.04310/ ./ 02800.0388/ Deltaelevators0/ ./ 05440.05920/ ./ 05340.05400/ ./ 05500.05680/ ./ 00170.0179/ Computeractivity0/ ./ 04640.04700/ ./ 04640.04700/ ./ 03160.03820/ ./ 03210.0185/ Census/ (/ house8L/ )/ 0.07180/ ./ 07460.07180/ ./ 07460.06240/ ./ 06600.06240/ ./ 0360AutopriceTriazinesMachineCPU0/ ./ 03520.08260/ ./ 05740.08110/ ./ 03320.05390/ ./ 01680.0220/ ServoBreastcancer0/ ./ 22780.26430/ ./ 22780.26430/ ./ 24700.26790/ ./ 21450.201/ Bankdomains0/ ./ 04540.04670/ ./ 04540.04670/ ./ 04060.0360/ ./ 0410.015/ Californiahousing0/ ./ 10890.11800/ ./ 10890.11800/ ./ 12170.12670/ ./ 12130.1170/ Stocksdomain0/ ./ 05030.05180/ ./ 05030.05180/ ./ 02510.03480/ ./ 0220.0132/ Page7/ 表/ 44/ 种/ 不同/ 算法/ 的/ 时间/ 比较/ SVM/ 的/ 时间/ 训练样本/ 测试/ 样本/ AbaloneDeltaailerons2/ ./ 0850.0120/ ./ 5100.1690/ ./ 0450.0480/ ./ 0460.048/ Deltaelevators0/ ./ 9040.0090/ ./ 8490.4450/ ./ 2130.1550/ ./ 2210.155/ Computeractivity51/ ./ 0910.0520/ ./ 7690.2290/ ./ 2240.1300/ ./ 2970.132/ Census/ (/ house8L/ )/ 6.1100/ ./ 0358.5233/ ./ 1420.8180/ ./ 4770.8270/ ./ 484AutopriceTriazinesMachineCPUServoBreastcancerBankdomains5/ ./ 6860.0351/ ./ 2180.2290/ ./ 4870.1670/ ./ 5480.169/ Californiahousing4/ ./ 9480.03656/ ./ 2007.9190/ ./ 8470.2300/ ./ 9400.234/ Stocksdomain0/ ./ 7940.0050/ ./ 0520.0480/ ./ 0130.0230/ ./ 0140.023/ 表/ 54/ 种/ 不同/ 算法/ 的/ 标准偏差/ (/ standarddeviations/ )/ 比较/ SVM/ 的/ 标准偏差/ 训练样本/ 测试/ 样本/ AbaloneDeltaailerons0/ ./ 00150.00150/ ./ 00120.00100/ ./ 00300.00350/ ./ 00280.0034/ Deltaelevators0/ ./ 00070.00030/ ./ 00060.00050/ ./ 00280.00290/ ./ 00250.0029/ Computeractivity0/ ./ 00070.00070/ ./ 00150.00160/ ./ 00050.00330/ ./ 00040.0034/ Census/ (/ house8L/ )/ 0.00110/ ./ 00500.00130/ ./ 00130.0010/ ./ 00170.0020/ ./ 0026AutopriceTriazinesMachineCPU0/ ./ 01920.07150/ ./ 00830.01800/ ./ 00600.01560/ ./ 00560.0147/ ServoBreastcancer0/ ./ 15290.09620/ ./ 01150.01510/ ./ 01210.01670/ ./ 01270.0167/ Bankdomains0/ ./ 00060.00040/ ./ 00050.00080/ ./ 00060.00090/ ./ 00060.0008/ Californiahousing0/ ./ 00450.00260/ ./ 00120.00110/ ./ 00210.00330/ ./ 00200.0026/ Stocksdomain0/ ./ 00120.00220/ ./ 00160.00220/ ./ 00110.00160/ ./ 00140.0015/ 前面/ 提到/ 当/ γ/ →/ 时/ ,/ RELM/ 将/ 退化/ 为/ ELM/ ./ 为了/ 说明/ 这/ 一点/ ,/ 我们/ 以/ 数据/ 集/ “/ Triazines/ ”/ 为例/ 展示/ RELM/ 的/ 性能/ (/ RMSE/ )/ 随/ γ/ 变化/ 情况/ ./ 如图/ 2/ 所示/ ,/ 可以/ 看出/ RELM/ 的/ 性能/ 首先/ 随着/ γ/ 的/ 增大/ 不断/ 提高/ (/ 越小越/ 好/ )/ ,/ 当/ γ/ =/ 2/ -/ 2/ 时/ ,/ RELM/ 的/ 性能/ 达到/ 最好/ ,/ 比/ ELM/ 提高/ 了/ 0.05/ ./ 之后/ ,/ 随着/ γ/ 的/ 增大/ ,/ RELM/ 的/ 性能/ 不断/ 降低/ ,/ 并/ 逐渐/ 与/ ELM/ 的/ 性能/ 曲线/ 重叠/ 在/ 一起/ ,/ 这/ 说明/ 当/ γ/ →/ 时/ ,/ RELM/ 退化/ 为/ ELM/ ,/ 由此可见/ RELM/ 的/ 精度/ 至少/ 能/ 与/ ELM/ 相当/ ./ 6.2/ 分类/ 在/ 这/ 一部分/ ,/ 我们/ 来/ 给出/ RELM/ 在/ 分类/ 中/ 的/ 性能/ 测试/ ./ 数据/ 集/ 信息/ 见表/ 6/ ,/ 包括/ Banana/ 数据/ 集/ ①/ 以及/ 一些/ 来自/ UCI/ 的/ 数据/ 集/ ②/ ./ Banana/ 数据/ 集中/ 冗余/ 数据/ 已/ 被/ 删除/ ,/ 只/ 选用/ 其中/ 的/ 5200/ 个/ 不同/ 的/ 训练样本/ ./ 由于/ Forest/ -/ type/ 数据/ 集/ 规模/ 很大/ ,/ 基于/ 梯度/ 的/ BP/ 算法/ 在/ 传统/ PC/ 上会/ 产生/ 内存/ 溢出/ ,/ 因此/ 我们/ 直接/ 引用/ 文献/ [/ 17/ ]/ 中/ 的/ 实验/ 结果/ ./ SVM/ 的/ 参数设置/ 是/ C/ =/ 10/ ./ 不同/ 算法/ 的/ 性能/ 见表/ 7/ ,/ 从表/ 7/ 可以/ 看出/ RELM/ 的/ 运行/ 速度/ 和/ ELM/ 几乎/ 一样/ 快/ ,/ 并/ 获得/ 更好/ 的/ 泛化/ 性能/ ./ ①/ ②/ Page8/ 表/ 6/ 分类/ 问题/ 数据/ 集/ 的/ 信息/ 数据/ 集/ 训练样本/ 测试/ 样本/ 属性/ 类别/ 数据/ 集/ 训练样本/ 测试/ 样本/ 属性/ 类别/ Diabetes57619282Shuttle435001450097Satimage44002000367BananaSegmen/ 表/ 74/ 种/ 算法/ 在/ 分类/ 问题/ 上/ 的/ 性能/ 比较/ 数据/ 集/ 算法/ RELM0/ ./ 0110.00278/ ./ 6978.191/ ./ 0902.55/ DiabetesSatimageSegmentShuttleBananaForest/ -/ typeRELM1/ ./ 64816.18092/ ./ 3391.780/ ./ 0970.105/ RELM1/ ./ 3610.58192/ ./ 2590.330/ ./ 0120.0137/ 结束语/ RELM/ 打破/ 了/ 传统/ BP/ 算法/ 的/ 参数/ 迭代/ 调整/ 的/ 思想/ ,/ 从而/ 获得/ 了/ 快速/ 学习/ 的/ 能力/ ,/ 从/ 不同/ 数据/ 集/ 的/ 实验/ 可以/ 看出/ RELM/ 比/ BP/ 、/ SVM/ 速度/ 提高/ 很多/ 倍/ (/ 通常/ 是/ 10/ 倍/ 以上/ )/ ,/ 而/ 泛化/ 性能/ 却/ 比/ BP/ 、/ SVM/ 高/ ,/ 这/ 无疑/ 为/ 神经/ 网络应用/ 到/ 实时/ 环境/ 提供/ 了/ 有效途径/ ./ 与/ ELM/ 相比/ ,/ RELM/ 不但/ 继承/ 了/ ELM/ 快速/ 训练/ 的/ 特点/ ,/ 还/ 通过/ 引入/ 参数/ γ/ 使得/ 模型/ 可以/ 根据/ 数据/ 集/ 的/ 特点/ 进行/ 微调/ ,/ 从而/ 得到/ 更好/ 的/ 泛化/ 性能/ ,/ 增强/ 了/ 系统/ 的/ 可控性/ ./ 另外/ 如果/ 数据/ 集中/ 存在/ 明显/ 的/ 噪声/ ,/ 那么/ 可以/ 使用/ 加权/ RELM/ ,/ 达到/ 降噪/ 的/ 目的/ ,/ 从/ 对/ “/ SinC/ ”/ 数据/ 集/ 的/ 实验/ 可以/ 看出/ 加权/ RELM/ 对/ 噪声/ 有/ 一定/ 的/ 抗干扰能力/ ./ 在/ 我们/ 下/ 一步/ 研究/ 中/ ,/ 我们/ 打算/ 将/ 在线/ 学习/ 与/ RELM/ 相结合/ ,/ 提出/ 一种/ 能够/ 处理/ 流/ 数据/ 的/ RELM/ ;/ 将/ SOM/ [/ 18/ ]/ 、/ 主动/ 学习/ 等/ 技术/ 与/ RELM/ 相结合/ 以期/ 得到/ 更好/ 的/ 性能/ ./ 在/ 应用/ 方面/ ,/ 我们/ 打算/ 将/ RELM/ 应用/ 到/ 文本/ 分类/ 、/ 协作/ 过滤/ 、/ 数字水印/ 等/ 领域/ ,/ 尤其/ 是/ 文本/ 分类/ 与/ 协作/ 过滤/ 都/ 存在/ 高维/ 稀疏/ 问题/ ,/ 传统/ 方法/ 非常/ 耗时/ ,/ 如何/ 研究/ 一种/ 有效/ 的/ 快速/ Sparse/ -/ RELM/ 将/ 是/ 另/ 一个/ 值得/ 研究/ 的/ 问题/ ./ 

