Page1/ 一种/ 多权值/ 神经元/ 覆盖/ 网络/ 的/ 构造方法/ 魏莱/ 1/ )/ 徐菲菲/ 2/ )/ 王守觉/ 3/ )/ 1/ )/ (/ 上海/ 海事/ 大学/ 计算机科学/ 系/ 上海/ 201305/ )/ 2/ )/ (/ 上海/ 电力/ 学院/ 计算机科学/ 与/ 技术/ 系/ 上海/ 200090/ )/ 3/ )/ (/ 中国科学院/ 半导体/ 研究所/ 神经网络/ 实验室/ 北京/ 100083/ )/ 摘要/ 仿生/ 模式识别/ 利用/ 多权值/ 神经元/ 覆盖/ 网络/ 构造/ 模式/ 类/ 的/ 覆盖/ 来/ 进行/ 相应/ 事物/ 的/ 识别/ ./ 但/ 在/ 构造/ 多权值/ 神经元/ 覆盖/ 网络/ 的/ 过程/ 中/ ,/ 关于/ 构造/ 神经元/ 个数/ 的/ 确定/ 方法/ 没有/ 相关/ 讨论/ ,/ 即/ 需要/ 使用/ 多少/ 个/ 神经元/ 才能/ 完成/ 对/ 模式/ 类/ 的/ 覆盖/ ./ 较/ 多/ 的/ 神经元/ 在/ 精确/ 的/ 对/ 模式/ 类/ 进行/ 覆盖/ 同时/ ,/ 也/ 增大/ 了/ 网络/ 的/ 复杂度/ ./ 文中/ 提出/ 了/ 一种/ 多权值/ 神经元/ 覆盖/ 网络/ 的/ 构造方法/ ./ 在/ 保持/ 神经网络/ 对/ 模式/ 类/ 的/ 覆盖/ 能力/ 的/ 基础/ 上/ 采用/ 尽量少/ 的/ 神经元/ ,/ 从而/ 能/ 有效/ 的/ 降低/ 神经网络/ 构造/ 代价/ ./ 最后/ ,/ 通过/ 实验/ 作者/ 验证/ 了/ 算法/ 的/ 有效性/ ./ 关键词/ 模式识别/ ;/ 神经元/ ;/ 单纯形/ ;/ 覆盖/ ;/ 多维/ 尺度/ 变换/ 1/ 引言/ 仿生/ 模式识别/ [/ 1/ ]/ 是/ 以/ “/ 认识/ ”/ 而/ 非/ “/ 区分/ ”/ 事物/ 为/ 目的/ 的/ ,/ 与/ 传统/ 的/ 模式识别/ 中/ 寻找/ 对/ 模式/ 类/ 的/ “/ 最佳/ 划分/ ”/ 方法/ 不同/ ,/ 仿生/ 模式识别/ 采用/ “/ 覆盖/ ”/ 的/ 方式/ 完成/ 对/ 不同/ 模式/ 类/ 的/ 分类/ ./ 仿生/ 模式识别/ 的/ 实现/ 方法/ 是/ 在/ 对/ 数据/ 样本/ 在/ 特征/ 空间/ 中/ 形成/ 的/ 无穷/ 点集/ 的/ “/ 形状/ ”/ 的/ 分析/ 和/ 认识/ 基础/ 上/ ,/ 通过/ 多权值/ 神经元/ 构造/ 出高/ 维空间/ 中/ 的/ 简单/ 覆盖/ 几何体/ ,/ 再/ 由/ 多个/ 这样/ 的/ 神经元/ 连接/ 而成/ 的/ 神经网络/ 构造/ 出由/ 简单/ 几何体/ 拼接/ 而成/ 的/ 复杂/ 覆盖/ 区域/ ,/ 从而/ 完成/ 对/ 样本/ Page2/ 集/ 的/ 最佳/ 覆盖/ ./ 仿生/ 模式识别/ 相比/ 于/ 传统/ 模式识别/ 方法/ 的/ 优势/ 主要/ 体现/ 在/ 两点/ ./ 首先/ ,/ 传统/ 模式识别/ 克服/ 不了/ 对/ 未/ 训练样本/ 的/ 高/ 误识率/ 问题/ ./ 传统/ 模式识别/ 的/ 分类/ 是/ 对/ 现有/ 的/ 训练样本/ 集/ 的/ 划分/ ,/ 当有/ 不/ 属于/ 现有/ 训练样本/ 集中/ 任/ 一类/ 的/ 样本/ 进入/ 时/ ,/ 其/ 必定会/ 被/ 分到/ 原/ 训练样本/ 中/ 的/ 某/ 一类/ ,/ 从而/ 造成/ 误识/ ./ 而/ 仿生/ 模式识别/ 构造/ 了/ 不同/ 类别/ 样本/ 集/ 的/ 不同/ 覆盖/ ,/ 当/ 数据/ 点/ 不/ 属于/ 任意/ 覆盖/ 区域/ 时/ ,/ 则/ 会/ 将/ 其/ 拒识/ ./ 其次/ ,/ 由/ 传统/ 模式识别/ 建立/ 起来/ 的/ 分类/ 系统/ ,/ 当有/ 新/ 的/ 类别/ 的/ 训练样本/ 增加/ 时/ ,/ 需要/ 对/ 已/ 训练/ 好/ 的/ 系统/ 进行/ 重新/ 训练/ ,/ 即/ 重新/ 划分/ 各种/ 样本/ ,/ 导致系统/ 训练/ 时间/ 加长/ ./ 而/ 对于/ 仿生/ 模式识别/ 来说/ ,/ 只/ 需要/ 对/ 这类/ 新/ 的/ 样本/ 集/ 训练/ 覆盖/ 网络/ 就行了/ ,/ 并不需要/ 对/ 前面/ 已经/ 学习/ 好/ 的/ 覆盖/ 网络/ 进行/ 重新/ 的/ 训练/ ,/ 因此/ 整个/ 系统/ 训练/ 时间/ 必定/ 能/ 大大/ 地/ 减少/ ./ 可以/ 说/ ,/ 仿生/ 模式识别/ 方法/ 更/ 接近/ 于/ 人类/ 对/ 事物/ 的/ 认知/ 方式/ ,/ 也/ 正/ 因为/ 这样/ ,/ 仿生/ 模式识别/ 已经/ 在/ 人脸/ 确认/ [/ 2/ ]/ 、/ 人脸识别/ [/ 3/ ]/ 、/ 语音/ 识别/ [/ 4/ ]/ 方面/ 显示/ 了/ 巨大/ 的/ 优越性/ ./ 示意图/ 见图/ 1/ ./ 图/ 1/ 仿生/ 模式识别/ 示意图/ (/ 图中/ 三角形/ 为/ 要/ 识别/ 的/ 样本/ ,/ 圆圈/ 和/ 十字形/ 为/ 与/ 三角形/ 不同/ 类/ 的/ 两类/ 样本/ ,/ 折线/ 为/ 传统/ BP/ 网络/ 模式识别/ 的/ 划分/ 方式/ ,/ 大圈/ 为/ RBF/ 网络/ 的/ 划分/ 方式/ (/ 等同于/ 以/ 模板/ 匹配/ 的/ 识别/ 方式/ )/ ,/ 细长/ 椭圆形/ 构成/ 的/ 曲线/ 代表/ 仿生/ 模式识别/ 的/ “/ 认识/ ”/ 方式/ )/ 但是/ ,/ 在/ 构造/ 多权值/ 神经元/ 覆盖/ 网络/ 的/ 过程/ 中/ ,/ 关于/ 构造/ 神经元/ 个数/ 的/ 确定/ 方法/ 没有/ 相关/ 讨论/ ,/ 即/ 使用/ 多少/ 个/ 神经元/ 才能/ 完成/ 对/ 模式/ 类/ 的/ 覆盖/ ./ 实际上/ ,/ 仿生/ 模式识别/ 是/ 通过/ 数据/ 点/ 组成/ 的/ 单纯形/ 的/ 拼接/ 去/ 拟合/ 数据/ 集/ 的/ 低维/ “/ 流形/ ”/ [/ 5/ -/ 7/ ]/ 结构/ ./ 每/ 一个/ 单纯形/ ,/ 对应/ 一个多/ 权值/ 神经元/ ,/ 该/ 神经元/ 能/ 覆盖住/ 空间/ 中距离/ 单纯形/ 小于/ 等于/ 一定/ 阈值/ 的/ 区域/ ,/ 这种/ 神经元/ 也/ 叫/ 单纯形/ 神经元/ [/ 8/ -/ 9/ ]/ ./ 目前/ 尚/ 没有/ 明确/ 的/ 规则/ 来/ 确定/ 使用/ 多少/ 个/ 单纯形/ 去/ 逼近/ 数据/ 流形/ 是/ 合适/ 的/ ,/ 经常/ 使用/ 的/ 方法/ 是/ 尽量/ 通过/ 近邻/ 数据/ 点来/ 构造/ 尺度/ 小/ 的/ 单纯形/ ,/ 这样/ 就/ 需要/ 使用/ 较/ 多/ 的/ 单纯形/ 去/ 拟合/ 数据/ 流形/ ,/ 因此/ 得到/ 的/ 神经网络/ 也/ 往往/ 具有/ 较/ 多/ 的/ 神经元/ ./ 对于/ 每/ 一个/ 单纯形/ 神经元/ ,/ 需要/ 存储/ 其/ 相应/ 的/ 单纯形/ 顶点/ 以及/ 一定/ 的/ 阈值/ 来/ 构造/ 相应/ 的/ 覆盖/ 区域/ [/ 1/ ,/ 9/ ]/ ,/ 因此/ 构造/ 每/ 一个多/ 权值/ 神经元/ 的/ 代价/ 是/ 比较/ 高/ 的/ ,/ 故/ 我们/ 就/ 期望/ 有/ 一种/ 合理/ 的/ 方法/ 使得/ 在/ 拟合/ 数据/ 集/ 的/ 几何/ 结构/ 的/ 同时/ 能/ 用/ 最少/ 的/ 多/ 权值/ 神经元/ 将/ 模式/ 类/ 进行/ 完全/ 的/ 覆盖/ ./ 本文/ 尝试/ 进行/ 这方面/ 的/ 探索/ ,/ 提出/ 一种/ 多权值/ 神经元/ 覆盖/ 网络/ 的/ 构造方法/ ,/ 并/ 通过/ 实验/ 证明/ 本文/ 算法/ 的/ 可行/ ./ 2/ 仿生/ 模式识别/ 基本原理/ 简介/ 仿生/ 模式识别/ 认为/ 自然界/ 中/ 任何/ 欲/ 被/ 认识/ 的/ 事物/ (/ 包括/ 事物/ 、/ 图像/ 、/ 声音/ 、/ 语言/ 、/ 状态/ 等等/ )/ 若/ 存在/ 两个/ “/ 同源/ ”/ 同类/ 而/ 不/ 完全/ 相等/ 的/ 事物/ ,/ 而/ 这/ 两个/ 事物/ 的/ 差别/ 是/ 可以/ 渐变/ 的/ 或非/ 量子化/ 的/ ,/ 则/ 这/ 两个/ 同类/ 事物/ 之间/ 必/ 至少/ 存在/ 一个/ 渐变/ 过程/ ,/ 在/ 这个/ 渐变/ 过程/ 中间/ 的/ 各/ 事物/ 都/ 是/ 属于/ 同/ 一类/ 的/ ./ 用/ 数学/ 的/ 语言/ 描述/ 为/ :/ 特征/ 空间/ Rn/ 中/ ,/ 设/ 所有/ 属于/ A/ 类/ 事物/ 的/ 全体/ 所/ 组成/ 的/ 点/ 集为/ A/ ,/ 若/ 集合/ A/ 中/ 存在/ 任意/ 两个/ 元素/ X/ 与/ Y/ ,/ 则/ 对/ ε/ 为/ 任意/ 大于/ 0/ 的/ 值时/ ,/ 必定/ 存在/ 集合/ B/ ,/ 使得/ B/ =/ {/ X1/ ,/ X2/ ,/ …/ ,/ Xn/ |/ X1/ =/ X/ ,/ Xn/ =/ Y/ ,/ n/ / N/ ,/ ρ/ (/ Xm/ ,/ Xm/ +/ 1/ )/ </ ε/ ,/ ε/ >/ 0/ ,/ n/ -/ 1/ / m/ / 1/ ,/ m/ / N/ }/ ,/ B/ / A/ ./ 仿生/ 模式识别/ 对/ 事物/ 的/ 这种/ 规律性/ 认识/ ,/ 实际上/ 就是/ 对/ 事物/ 的/ 全体/ 在/ 特征/ 空间/ 中/ 的/ 数据/ 点/ 的/ 分布/ 规律/ 的/ 把握/ ,/ 也/ 即/ 对/ 数据/ 集/ 形成/ 的/ “/ 流形/ ”/ 的/ 认识/ ./ 而/ 现实/ 中/ 得到/ 的/ 数据/ 集/ 不可避免/ 地带/ 有/ “/ 噪声/ ”/ ,/ 所以/ 数据/ 流形/ 并/ 不会/ 非常/ 地/ “/ 光滑/ ”/ ,/ 数据/ 点会/ 依据/ 流形/ 结构/ 分布/ 在/ 其/ 周围/ 小/ 的/ 区域/ 内/ ,/ 因此/ 要/ 完成/ 对/ 该类/ 数据/ 集/ 的/ 覆盖/ 就/ 需要/ 覆盖住/ 数据/ 流形/ 和/ n/ 维超球/ 的/ 拓扑/ 乘积/ (/ 这里/ 的/ n/ 是/ 数据/ 观测/ 空间/ 维数/ )/ 形成/ 的/ 一个/ 区域/ ./ 仿生/ 模式识别/ 通过/ 单纯形/ 的/ 组合/ 来/ 拟合/ 数据/ 流形/ ,/ 并/ 使用/ 单纯形/ 神经元/ 组成/ 的/ 神经网络/ 来/ 构造/ 覆盖/ 区域/ ./ 我们/ 下面/ 来/ 介绍/ 单纯形/ 和/ 单纯形/ 神经元/ [/ 8/ -/ 9/ ]/ 的/ 概念/ ./ 2.1/ 单纯形/ 单纯形/ 是/ 欧式/ 空间/ 的/ 一类/ 最/ 基本/ 的/ 几何图形/ ./ 定义/ 如下/ ./ 定义/ 1/ (/ 单纯形/ )/ ./ 在/ n/ 维空间/ Rn/ 中/ ,/ 以/ 不同/ 在/ 任何/ 一个/ k/ -/ 1/ 维/ 超平面/ 上/ 的/ k/ +/ 1/ 个点/ W0/ ,/ W1/ ,/ …/ ,/ Wk/ (/ k/ / n/ )/ 为/ 顶点/ ,/ 两/ 两/ 连接/ 得到/ 的/ 有限/ 封闭/ 超/ 多面体/ 称为/ k/ 维/ 单纯形/ ,/ 即/ Page3/ θ/ 〈/ W0W1/ …/ Wk/ 〉/ =/ X/ |/ X/ =/ ∑/ k/ 由/ 上述/ 定义/ 可知/ ,/ 当某/ 一/ α/ i/ 为/ 0/ 时/ ,/ θ/ 〈/ W0W1/ …/ Wk/ 〉/ 成为/ k/ -/ 1/ 维/ 单纯形/ ,/ 此时/ 称之为/ 顶点/ Wi/ 所/ 对应/ 的/ 侧面/ ./ k/ 维/ 单纯形/ 有/ k/ +/ 1/ 个/ 顶点/ 和/ k/ +/ 1/ 个/ 侧面/ ;/ 连接/ 两个/ 顶点/ 的/ 线段/ 称为/ 棱/ ,/ k/ 维/ 单纯形/ 有/ C2k/ (/ k/ +/ 1/ )/ 条棱/ ./ 实际上/ ,/ k/ 维/ 单纯形/ 是/ 某个/ k/ 维/ 以上/ 的/ 欧氏/ 空间/ 中/ 的/ k/ +/ 1/ 个/ 仿射/ 无关/ 的/ 点/ 的/ 凸包/ ./ 例如/ ,/ 0/ -/ 单纯形/ 就是/ 点/ ,/ 1/ -/ 单纯形/ 就是/ 线段/ ,/ 2/ -/ 单纯形/ 就是/ 三角形/ ,/ 3/ -/ 单纯形/ 就是/ 四面体/ ,/ 而/ 4/ -/ 单纯形/ 是/ 一个/ 五胞体/ ./ 所有/ 棱长/ 都/ 相等/ 的/ 单纯形/ 称为/ 正则/ 单纯形/ ./ 例如/ :/ 正三角形/ 是/ 一个二维/ 正则/ 单纯形/ ,/ 正四面体/ 是/ 一个三维/ 正则/ 单纯形/ ./ 更/ 高维/ 正则/ 单纯形/ 的/ 几何图形/ 的/ 认识/ 需/ 借助/ 高维/ 抽象/ 的/ 想象/ ./ 从/ 上面/ 的/ 介绍/ 中/ 知道/ ,/ 单纯形/ 是/ 一种/ 线性/ 的/ 几何体/ ,/ 而/ 数据/ 流形/ 一般/ 是/ 非线性/ 的/ ,/ 因此/ 从/ 全局/ 的/ 角度/ 上/ 不能/ 使用/ 一个/ 单纯形/ 来/ 代替/ 数据/ 流形/ ,/ 但是/ 我们/ 知道/ 流形/ 在/ 局部/ 范围/ 内/ 与/ 欧式/ 空间/ “/ 同/ 胚/ ”/ ,/ 也/ 即/ 在/ 一个/ 比较/ 小/ 的/ 尺度/ 上/ ,/ 局部/ 数据/ 流形/ 是/ 线性/ 的/ ,/ 故/ 可以/ 用/ 一个/ 单纯形/ 来/ 近似/ ,/ 这样/ 就/ 可以/ 使用/ 与/ 流形/ 同维数/ 的/ 小/ 的/ 单纯形/ 组合/ 去/ 实现/ 对/ 流形/ 的/ 整体/ 拟合/ ./ 但/ 需要/ 说明/ 的/ 是/ ,/ 在/ 实际/ 应用/ 中/ ,/ 数据/ 集/ 流形/ 的/ 维数/ 通常/ 是/ 未知/ 的/ ,/ 而/ 如何/ 确定/ 数据/ 集/ 流形/ 的/ 维数/ ,/ 一直/ 是/ 机器/ 学习/ 研究/ 领域/ 的/ 一个/ 复杂/ 问题/ ./ 目前/ 存在/ 的/ 方法/ 包括/ 分形/ 锥/ 方法/ [/ 10/ ]/ 、/ PackingNumber/ 方法/ [/ 11/ ]/ 等等/ ./ 实际上/ ,/ 文献/ [/ 6/ ]/ 中/ 不仅仅/ 给出/ 了/ 一个/ 非线性/ 数据/ 约简/ 算法/ —/ —/ —/ ISOMAP/ ,/ 也/ 给出/ 了/ 一个/ 利用/ 残差/ 曲线/ 来/ 估计/ 数据/ 集/ 内在/ 维数/ 的/ 方法/ ./ 通过/ 残差/ 曲线/ 的/ 拐点/ ,/ 可以/ 大致/ 得出/ 数据/ 集/ 流形/ 的/ 维数/ ./ 本文/ 并/ 不/ 去/ 深入/ 讨论/ 数据/ 流形/ 维数/ 问题/ ,/ 我们/ 这里/ 假设/ 流形/ 维数/ 已知/ ,/ 在/ 实际/ 应用/ 中/ ,/ 可以/ 先/ 通过/ 上述/ 算法/ 确定/ 数据/ 流形/ 维数/ ,/ 然后/ 采用/ 本文/ 算法/ ./ 2.2/ 单纯形/ 神经元/ 一个/ 人工/ 神经元/ ,/ 其/ 基本/ 运算/ 公式/ 为/ 其中/ ,/ f/ 为/ 神经元/ 非线性/ 状态/ 转移/ 函数/ ,/ Th/ 为/ 神经元/ 的/ 阈值/ ,/ Φ/ (/ x1/ ,/ x2/ ,/ …/ ,/ xn/ )/ 为/ 包含/ 各个/ 权值/ 在内/ 的/ 神经元/ 基本/ 运算/ 函数/ ,/ 权值/ 计算/ 可以/ 参见/ 文献/ [/ 9/ ]/ ./ 从/ 几何/ 上/ 解释/ ,/ 一个/ 神经元/ 可以/ 对应/ 一个/ 超平面/ 、/ 超/ 曲面/ 或者/ 超球/ ,/ 而/ 所谓/ 的/ 单纯形/ 神经元/ 就是/ 单纯形/ 与/ Th/ 为/ 半径/ 的/ n/ 维超球/ 的/ 拓扑/ 乘积/ ,/ 是/ 一类/ 特殊/ 的/ 封闭/ 复杂/ 几何/ 形体/ ./ 定义/ 2/ (/ 单纯形/ 神经元/ )/ 在/ n/ 维空间/ Rn/ 中/ ,/ X/ 到/ θ/ 〈/ W0W1/ …/ Wk/ 〉/ 的/ 距离/ 为/ 称/ 与/ θ/ 〈/ W0W1/ …/ Wk/ 〉/ 关联/ 的/ 神经元/ 模型/ y/ =/ f/ [/ Φ/ (/ W0/ ,/ W1/ ,/ …/ ,/ Wk/ ,/ X/ )/ -/ Th/ ]/ ,/ 为/ 拥有/ k/ +/ 1/ 个/ 权值/ 矢量/ 的/ 单纯形/ 神经元/ ./ Φ/ 是/ X/ 到/ k/ 维/ 单纯形/ θ/ 〈/ W0W1/ …/ Wk/ 〉/ 的/ 距离/ 函数/ ,/ Th/ 为/ 覆盖/ 区域/ 距离/ 单纯形/ 的/ 最大/ 距离/ ./ 由/ 定义/ 2/ ,/ 我们/ 可以/ 得到/ 如下/ 推论/ ./ 推论/ 1/ ./ 当/ k/ =/ 0/ 时/ ,/ θ/ 〈/ W0/ 〉/ 是/ 一个点/ ,/ 对应/ RBF/ (/ 单权值/ )/ 神经元/ 模型/ ,/ 图/ 2/ (/ a/ )/ ./ 推论/ 2/ ./ 当/ k/ =/ 1/ 时/ ,/ θ/ 〈/ W0W1/ 〉/ 是/ 一条/ 线段/ ,/ 对应/ 超/ 香肠/ 神经元/ 模型/ ,/ 图/ 2/ (/ b/ )/ ./ 推论/ 3/ ./ 当/ k/ =/ 2/ 时/ ,/ θ/ 〈/ W0W1W2/ 〉/ 是/ 一个/ 三角形/ ,/ 对应/ 三角形/ 神经元/ 模型/ ,/ 图/ 2/ (/ c/ )/ ./ 当/ k/ / 3/ 时/ ,/ 把/ 与/ 单纯形/ θ/ 〈/ W0W1/ …/ Wk/ 〉/ 对应/ 的/ 神经元/ 统称/ 为/ 多维/ (/ 多/ 自由度/ )/ 单纯形/ 神经元/ 模型/ ./ k/ =/ 3/ 时/ 的/ 三棱锥/ 神经元/ 如图/ 2/ (/ d/ )/ 所示/ ./ 通过/ 上述/ 单纯形/ 神经元/ 的/ 组合/ ,/ 我们/ 就/ 能/ 对/ 数据/ 集/ 进行/ 覆盖/ ,/ 训练/ 好/ 覆盖/ 网络/ 后/ ,/ 当/ 数据/ 点落/ 在/ 被/ 单纯形/ 神经元/ 覆盖住/ 的/ 区域/ 时/ 我们/ 就/ 认为/ 数据/ 点为/ 该类/ 数据/ 点/ ,/ 反之/ 则/ 会/ 被/ 拒识/ ./ 用/ 多少/ 个/ 单纯形/ 神经元/ 能够/ 将/ 其/ 覆盖/ ?/ 现在/ 问题/ 浮现/ 了/ ,/ 对于/ 一个/ 模式/ 类/ ,/ 我们/ 需要/ 采/ 为了/ 方便/ ,/ 先/ 考虑/ 一个/ 简单/ 的/ 情况/ ,/ 即/ 数据/ 流形/ 是/ 一维/ 的/ ,/ 那么/ 由于/ “/ 噪声/ ”/ 的/ 影响/ ,/ 真实/ 数据/ 点/ 在/ 特征/ 空间/ 的/ 分布/ 可以/ 是/ 一/ 维流形/ 与/ n/ 维超球/ 的/ 拓扑/ 乘积/ ./ 可以/ 用/ 连接/ 数据/ 点/ 的/ 一系列/ 小/ 的/ 直线/ 段来/ 逼近/ 这个/ 一/ 维流形/ ,/ 而/ 覆盖/ 神经元/ 采用/ 超/ 香肠/ 神经元/ ./ 现在/ 的/ 问题/ 就是/ ,/ 对于/ 每/ 一个/ 直线/ 段/ ,/ 应该/ 取/ 多长/ 是/ 合适/ 的/ ,/ 即/ 应该/ 选择/ 哪些/ 数据/ 点/ 作为/ 直线/ 段/ 的/ 端点/ ,/ 从而/ 用来/ 构造/ 超/ 香肠/ 神经元/ ?/ 当然/ ,/ 线段/ 取/ 的/ 越短/ ,/ 对/ 流形/ 的/ 逼近/ 效果/ 也/ 就/ 越/ 好/ ,/ 但是/ 直线/ 段/ 越短/ ,/ 所/ 需要/ 的/ 直线/ 段/ 数量/ 就/ 越/ 多/ ,/ 而/ 每/ 一个/ 直线/ 段/ 都/ 对应/ 一个/ 超/ 香肠/ 神经元/ ,/ 那么/ 构造/ 超/ 香肠/ 神经元/ 的/ 代价/ 较/ 高/ ./ Page4/ 因此/ ,/ 实际上/ 我们/ 就是/ 希望/ 在/ 保持/ 直线/ 段/ 对/ 流形/ 的/ 逼近/ 能力/ 基础/ 上用/ 尽量少/ 的/ 直线/ 段来/ 拟合/ 这个/ 一/ 维流形/ ./ 推而广之/ ,/ 当/ 数据/ 流形/ 维数/ 不是/ 一维/ 的/ 情况/ 下/ ,/ 就是/ 希望/ 能/ 用/ 尽量少/ 的/ 与/ 数据/ 流形/ 维数/ 相同/ 的/ 单纯形/ 来/ 逼近/ 数据/ 流形/ ,/ 从而/ 减少/ 覆盖/ 神经元/ 的/ 数量/ ,/ 降低/ 整个/ 覆盖/ 网络/ 的/ 复杂度/ ./ 3/ 多权值/ 神经元/ 覆盖/ 网络/ 构造方法/ 由于/ 数据/ 采样/ 技术/ 的/ 限制/ 以及/ 数据/ 集/ 流形/ 几何/ 结构/ 的/ 多变性/ ,/ 使得/ 得到/ 的/ 每/ 一/ 数据/ 点/ 周围/ 的/ 局部/ 密度/ 和/ 空间/ 曲率/ 都/ 会/ 不/ 一样/ ,/ 对于/ 一维/ 数据/ 流形/ 问题/ 来说/ ,/ 就是/ 在/ 不同/ 的/ 区域/ ,/ 直线/ 段/ 的/ 长短/ 不/ 一样/ ./ 在/ 数据/ 曲率/ 大/ 的/ 地方/ 直线/ 段/ 应该/ 短/ 一点/ ,/ 而/ 在/ 数据/ 曲率/ 小/ 的/ 地方/ ,/ 直线/ 段/ 可以/ 长/ 一点/ ,/ 即/ 在/ 一维/ 尺度/ 上/ 是/ 近似/ 线性/ 的/ ./ 这样/ ,/ 可以/ 明确/ 直线/ 段长度/ 的/ 确定/ 方法/ ,/ 即/ 直线/ 段/ 可以/ 尽量/ 地长/ ,/ 只要/ 包含/ 在/ 直线/ 段/ 端点/ 范围/ 内/ 的/ 数据/ 点集/ 在/ 一维/ 上/ 是/ 线性/ 的/ ./ 这样/ 既/ 可以/ 做到/ 尽量/ 地/ 减少/ 直线/ 段/ 的/ 数量/ ,/ 又/ 能/ 对/ 数据/ 流形/ 进行/ 合理/ 的/ 覆盖/ ./ 同样/ 对于/ d/ 维流形/ ,/ d/ 维/ 单纯形/ 也/ 可以/ 尽量/ 地/ 大/ ,/ 只/ 需要/ 在/ 该/ 单纯形/ 区域/ 内/ 的/ 数据/ 集在/ d/ 维/ 尺度/ 上/ 是/ 线性/ 的/ ,/ 这样/ 该/ 局部/ 数据/ 集/ 构成/ 的/ 几何体/ 可以/ 用/ 一个/ 单纯形/ 来/ 代替/ ./ 如何/ 判断/ 数据/ 集在/ 特定/ 维数/ 上/ 是/ 线性/ 的/ ,/ 在/ 这里/ 我们/ 采用/ 多维/ 尺度/ 变换/ (/ MultidimensionalScaling/ ,/ MDS/ )/ [/ 12/ ]/ 的/ 方法/ 来/ 确定/ ./ 3.1/ 多维/ 尺度/ 变换/ MDS/ 算法/ 的/ 原理/ 是/ 基于/ 这样/ 的/ 数学/ 推导/ ./ 假设/ 数据/ 集/ 为/ 犡/ =/ {/ x1/ ,/ x2/ ,/ …/ ,/ xN/ }/ ,/ 如果/ 我们/ 不/ 知道/ 数据/ 点/ 的/ 具体/ 坐标/ ,/ 只/ 知道/ 数据/ 点/ 的/ 距离/ 矩阵/ 犇/ =/ {/ dij/ }/ ,/ dij/ =/ xi/ -/ xj/ 原点/ ,/ 定义/ 内积/ 矩阵/ 犅/ 犡/ =/ 犡/ 犡/ T/ ./ 那么/ ,/ 如果/ 能/ 得到/ 犅/ 犡/ 的/ 值/ ,/ 相应/ 可以/ 得到/ 数据/ 集/ 坐标/ (/ 至多/ 与/ 真实/ 坐标/ 相差/ 一个/ 常数/ )/ ./ 而/ 从/ 距离/ 矩阵/ 犇/ =/ {/ dij/ }/ 出发/ ,/ 令/ 犛/ =/ {/ d2ij/ }/ ,/ 对/ 其/ 进行/ 双/ 中心化/ ,/ 即/ τ/ (/ 犇/ )/ =/ -/ 犎/ 犛/ 犎/ {/ hij/ }/ ,/ 满足/ hij/ =/ δ/ ij/ -/ 1/ 我们/ 发现/ 有/ 犅/ 犡/ =/ τ/ (/ 犇/ )/ ,/ 再/ 对/ τ/ (/ 犇/ )/ 进行/ 奇异/ 值/ 分解/ ,/ 即/ 犅/ 犡/ =/ τ/ (/ 犇/ )/ =/ 犝/ Λ/ 犝/ T/ (/ 犝/ T/ 表示/ 犝/ 的/ 转置/ )/ ,/ 很/ 明显/ 犡/ 的/ 重构/ 坐标/ 就/ 可以/ 表述/ 为/ 犡/ =/ 犝/ 槡/ Λ/ ./ 如果/ 数据分布/ 是/ 由/ 内在/ 低维/ 变量/ 控制/ ,/ 变量/ 个数/ 为/ d/ (/ 这里/ 的/ 内在/ 控制变量/ 个数/ ,/ 就是/ 数据/ 集/ 的/ 内在/ 维数/ ,/ 也/ 就是/ 数据/ 集/ 形成/ 的/ 流形/ 的/ 维数/ )/ ,/ 那么/ 矩阵/ Λ/ 的/ 第/ d/ +/ 1/ 个/ 特征值/ 就/ 接/ 近于零/ ,/ 这时/ 就/ 有/ 犡/ ≈/ 犝/ d/ Λ/ 槡/ d/ ,/ 其中/ Λ/ d/ 为/ Λ/ 的/ 前/ d/ 个/ 特征值/ 组成/ 的/ 矩阵/ ,/ 犝/ d/ 的/ 列为/ 相应/ 的/ 特征向量/ ./ 从/ 上面/ 的/ 叙述/ 可知/ ,/ 如果/ 数据/ 集/ 的/ 内在/ 维数/ 已知/ ,/ 那么/ 数据/ 集/ 犡/ 在/ 该/ 维/ 数下/ 的/ 线性/ 结构/ 越/ 明显/ ,/ 它/ 的/ 低维/ 重构/ 犣/ 越/ 能/ 精确/ 的/ 表示/ 犡/ ,/ 反之/ 则/ 不是/ ,/ 而/ 这种/ 重构/ 的/ 是否/ 合理/ 可以/ 用/ 犅/ 犡/ -/ 犅/ 犣/ L2/ 的/ 值来/ 度量/ (/ 犅/ 犡/ 、/ 犅/ 犣/ 分别/ 是/ 犡/ 、/ 犣/ 的/ 内积/ 矩阵/ ,/ 犅/ 犡/ 通过/ 双/ 中心化/ 局部/ 距离/ 矩阵/ 犇/ =/ {/ dst/ }/ (/ k/ +/ 1/ )/ ×/ (/ k/ +/ 1/ )/ 得到/ ,/ 而/ 犅/ 犣/ =/ 犣/ T/ 犣/ ,/ 这里/ ·/ L2/ 表示/ 矩阵/ 的/ L2/ 的/ 模/ )/ ,/ 差值/ 越小则/ 重构/ 越/ 精确/ ./ 3.2/ 单纯形/ 神经元/ 的/ 构造/ 通过/ 多维/ 尺度/ 变换/ 可以/ 判断/ 一个/ 数据/ 集/ 是否是/ 线性/ 的/ ,/ 那么/ 反过来/ ,/ 对于/ 也/ 可以/ 通过/ 多维/ 尺度/ 变换/ 来/ 确定/ 数据/ 流形/ 上/ 的/ 一个/ 小/ 的/ 子集/ 是否是/ 线性/ 的/ ./ 具体/ 的/ 操作/ 可以/ 表述/ 如下/ (/ 假设/ 数据/ 集/ 内在/ 维数/ 为/ d/ )/ ./ 假设/ 对/ 数据/ 点/ xi/ 选择/ 一个/ 较大/ 的/ 邻域/ 参数/ kmax/ (/ kmax/ 表示/ 邻域/ 集/ 包含/ 的/ 数据/ 点/ 个数/ )/ 组成/ 邻域/ 集/ 犡/ i/ ,/ 然后/ 求得/ 其/ d/ 维/ 重构/ 犣/ i/ ,/ 计算/ 犅/ 犡/ i/ -/ 犅/ 犣/ iL2/ ,/ 并/ 设定/ 阈值/ ε/ (/ 例如/ ε/ =/ 0.1/ )/ ./ 当/ 犅/ 犡/ i/ -/ 犅/ 犣/ iL2/ >/ ε/ 时/ ,/ 减小/ 邻域/ 参数/ kmax/ =/ kmax/ -/ 1/ ,/ 重新/ 计算/ 新/ 的/ 局部/ 邻域/ 犡/ i/ 和/ 相应/ 的/ 低维/ 坐标/ 犣/ i/ ,/ 更新/ 犅/ 犡/ i/ ,/ 犅/ 犣/ i/ ,/ 再次/ 计算/ 犅/ 犡/ i/ -/ 犅/ 犣/ iL2/ ,/ 重复/ 上述/ 循环/ 直到/ 犅/ 犡/ i/ -/ 犅/ 犣/ iL2/ 小于/ ε/ 时/ ,/ 输出/ 合适/ 的/ 邻域/ 大小/ k/ (/ 还/ 可以/ 规定/ 一个/ 最小/ 的/ kmin/ ,/ 使/ k/ 不能/ 小于/ kmin/ )/ ./ 这样/ 的/ k/ 应该/ 可以/ 认为/ 是/ 犡/ i/ 所能/ 包含/ 数据/ 点/ 的/ 最大/ 个数/ ,/ 犡/ i/ 也/ 就是/ 最大/ 的/ 线性/ 数据/ 集/ ./ 我们/ 把/ 这个/ 方法/ 叫做/ 线性/ 邻域/ 集/ 选择/ 算法/ [/ 13/ ]/ ./ 1/ ./ 设定/ 邻域/ 变化/ 范围/ kmax/ ,/ kmin/ 和/ 阈值/ ε/ 和/ 邻域/ 集/ 犡/ i/ =/ WHILE/ 犅/ 犡/ i/ -/ 犅/ 犣/ iL2/ >/ ε/ k/ >/ kmin/ {/ xi0/ ,/ xi1/ ,/ xi2/ ,/ …/ ,/ xikmax/ }/ T/ ,/ 邻域/ 按离/ xi0/ 的/ 距离/ 排序/ ;/ 2/ ./ 对/ 犡/ i/ 做/ MDS/ 得到/ 犣/ i/ ,/ 计算/ 犅/ 犡/ i/ -/ 犅/ 犣/ iL2/ ,/ k/ =/ kmax/ ,/ END3/ ./ 输出/ k/ ./ 通过/ 这个/ 算法/ ,/ 我们/ 能/ 得到/ 数据/ 流形/ 上/ 的/ 最大/ 的/ 线性/ 邻域/ 集/ ,/ 理论/ 上/ 这个/ 邻域/ 集/ 就/ 可以/ 用/ 一个/ 单纯形/ 来/ 代替/ ,/ 对于/ 一/ 维流形/ 来说/ ,/ 直线/ 段/ 就是/ 犡/ i/ 中距离/ 最长/ 的/ 两点/ 连线/ ,/ 而/ 对于/ 高维/ 的/ 数据/ 流形/ ,/ 单纯形/ 构造/ 稍微/ 复杂/ ,/ 我们/ 在/ 下节/ 给出/ 了/ 构造/ 算法/ ./ 3.3/ 单纯形/ 神经元/ 覆盖/ 网络/ 的/ 构造/ 算法/ 盖/ 网络/ 的/ 构造/ 算法/ 可以/ 表述/ 如下/ :/ 假设/ 数据/ 流形/ 维数/ 为/ d/ ,/ 那么/ 单纯形/ 神经元/ 覆/ Page51/ ./ 对/ 任一/ xi/ ∈/ 犡/ 通过/ 自/ 适应/ 邻域/ 算法/ 选择/ 其/ 合适/ 的/ 邻域/ 大小/ 犡/ i/ ;/ 2/ ./ 在/ 邻域/ 集/ 犡/ i/ 中/ 选择/ 距离/ 最远/ 的/ 两个/ 点/ xi1/ ,/ xi2/ ,/ 将/ 这两点/ 相连/ ,/ 然后/ 找到/ 距离/ 线段/ xi1xi2/ 距离/ 最远/ 的/ 点/ xi3/ ,/ 将/ 这/ 三点/ 连接/ ,/ 一直/ 这样/ 做/ ,/ 寻找/ 到/ 第/ d/ +/ 1/ 与/ 前面/ d/ 个点/ 构成/ 的/ d/ -/ 1/ 维/ 单纯形/ 距离/ 最远/ 的/ 点/ ,/ 将/ 这/ d/ +/ 1/ 点/ 连接/ ,/ 构成/ d/ 维/ 单纯形/ θ/ 1/ ,/ 构造/ 覆盖/ 区域/ P1/ =/ {/ 犡/ |/ ρ/ 犡/ θ/ 1/ / Th/ ,/ 犡/ ∈/ 犡/ i/ }/ ,/ 然后/ 将/ 犡/ i/ 中/ 被/ P1/ 覆盖住/ 的/ 点/ 除去/ ./ 在/ 犡/ i/ 剩余/ 点中/ 寻找/ 与/ θ/ 1/ 距离/ 最远/ 的/ 点/ xi1/ ,/ 同时/ 将/ θ/ 1/ 中/ 与/ xi1/ 距离/ 最近/ 的/ d/ -/ 1/ 维/ 单纯形/ 的/ 顶点/ 与/ xi1/ 链接/ ,/ 构成/ d/ 维/ 单纯形/ θ/ 2/ ,/ 构造/ 覆盖/ 区域/ P2/ =/ {/ 犡/ |/ ρ/ X/ θ/ 2/ / Th/ ,/ 犡/ ∈/ 犡/ i/ \/ P1/ }/ 然后/ 在/ 犡/ i/ 除去/ 被/ P2/ 覆盖住/ 的/ 点/ ,/ 一直/ 这样/ 做/ 下去/ 构造/ K/ 个/ 单纯形/ 神经元/ ,/ 直到/ 犡/ i/ 中/ 所有/ 点/ 都/ 被/ 覆盖住/ ;/ 3/ ./ 将/ 犡/ 中/ 被/ 前/ K/ 个/ 单纯形/ 神经元/ 中/ 覆盖住/ 的/ 点/ 及/ 单纯形/ 顶点/ 分别/ 记录/ 在/ 犢/ 和/ 犣/ 中/ ,/ 在/ K/ 个/ 单纯形/ 顶点/ 中/ 任选/ 一个/ 通过/ 自/ 适应/ 邻域/ 算法/ 求出/ 其/ 的/ 最佳/ 邻域/ ,/ 在/ 邻域/ 集中/ 除去/ 在/ 犢/ 和/ 犣/ 中/ 也/ 存在/ 的/ 点/ ,/ 如果/ 邻域/ 集为/ 空/ ,/ 则/ 取/ 另/ 一个/ 顶点/ ;/ 否则/ 除去/ 也/ 在/ 犢/ 中/ 的/ 点/ ,/ 转步/ 2/ ./ 注/ ./ 上述/ 的/ 算法/ 是从/ 数据/ 流形/ 不是/ 一维/ 的/ 情况/ 下/ 出发/ 的/ ,/ 对于/ 覆盖/ 一/ 维流形/ 的/ 超/ 香肠/ 神经元/ 覆盖/ 网络/ ,/ 在步/ 2/ 中/ 只/ 需要/ 将/ 邻域/ 中/ 相互/ 距离/ 最大/ 的/ 数据/ 点/ 链接/ ,/ 组成/ 一维/ 单纯形/ 就/ 可以/ 了/ ./ 4/ 算法/ 分析/ 实际上/ 算法/ 最/ 重要/ 的/ 部分/ 即/ 是/ 选取/ 数据/ 点/ 的/ 一个/ 线性/ 邻域/ 集/ ,/ 使得/ 可以/ 用/ 线性/ 的/ 单纯形/ 去/ 拟合/ 该/ 邻域/ 数据/ 点/ 形成/ 的/ 几何体/ ./ 线性/ 邻域/ 选择/ 算法/ 采用/ 的/ 一个/ 迭代/ 方法/ ,/ 我们/ 首先/ 选取/ 一个/ 确定/ 的/ 较大/ 的/ 图/ 3/ 算法/ 实验/ 效果/ 从图/ 3/ 中/ 可知/ ,/ 覆盖/ 神经元/ 只/ 需要/ 使用/ 13/ 个/ ,/ 而/ 目前/ 一般/ 的/ 构造方法/ 所/ 需/ 神经元/ 个数/ 必定/ 远远/ 大于/ 这个/ 数字/ ./ 如果/ 采用/ 人为/ 观察/ 来/ 确定/ 神经元/ 个数/ ,/ 在/ 数据/ 集/ 简单/ 的/ 情况/ 下/ 可能/ 可行/ ,/ 但/ 风险/ 一定/ 是/ 非常/ 大/ 的/ ,/ 当/ 数据/ 集/ 结构复杂/ 、/ 维数/ 较/ 高时/ ,/ 更是/ 不/ 可能/ 完成/ 的/ ./ 邻域/ ,/ 然后/ 逐步/ 减小/ 邻域/ 内/ 数据/ 点/ 个数/ ,/ 我们/ 知道/ ,/ 当/ 邻域/ 点/ 个数/ 减小/ 到/ d/ +/ 1/ 时/ (/ d/ 为/ 流形/ 维数/ )/ 其/ 一定/ 是/ 线性/ 的/ ,/ 因此/ 算法/ 一定/ 能/ 在/ 有限/ 步内/ 收敛/ ./ 而/ 覆盖/ 神经元/ 的/ 确定/ 是/ 构造性/ 的/ ,/ 在/ 有限/ 数据/ 点集/ 范畴/ 内/ ,/ 构造性/ 算法/ 一定/ 是/ 收敛/ 的/ ./ 我们/ 再/ 来看/ 算法/ 的/ 复杂度/ ./ 邻域/ 选择/ 算法/ 中有/ 一个/ 特征值/ 求解/ 问题/ ,/ 该/ 问题/ 和/ 邻域/ 包含/ 的/ 数据/ 点/ 个数/ 相关/ ,/ 为/ O/ (/ k2/ )/ (/ k/ 为/ 邻域/ 数据/ 点/ 个数/ )/ ,/ 而/ 算法/ 需/ 循环/ 的/ 最大/ 次数/ 为/ kmax/ -/ d/ -/ 1/ ,/ 故自/ 适应/ 邻域/ 选择/ 算法/ 的/ 时间/ 复杂度/ 为/ O/ (/ k3max/ )/ ,/ 而/ kmax/ 一般/ 不会/ 取/ 的/ 太大/ ,/ 因此/ 算法/ 运行/ 时间/ 是/ 可以/ 接受/ 的/ ./ 而/ 每个/ 邻域/ 中/ 覆盖/ 神经元/ 个/ 数最多/ 为/ k/ 来说/ ,/ 覆盖/ 神经元/ 最/ 多/ 需要/ k/ 算法/ 的/ 时间/ 复杂度/ 为/ ON5/ 实验/ 分析/ 5.1/ 人造/ 数据/ 实验/ 1/ ./ 我们/ 来看/ 一下/ 采用/ 上述/ 算法/ 构造/ 的/ 覆盖/ 网络/ ,/ 图/ 3/ 是/ 一组/ 数据/ 集/ ,/ 其/ 分布/ 在/ 一个/ 等速/ 螺旋/ 曲线/ 上/ ,/ 数据/ 点/ 个数/ 为/ 91/ ,/ 左子/ 图为/ 原始数据/ 集/ ,/ 右子/ 图为/ 覆盖/ 神经网络/ 示意图/ ,/ 黑色/ 线段/ 表示/ 用/ 我们/ 算法/ 确定/ 的/ 一个/ 超/ 香肠/ 神经元/ ./ 这里/ ε/ =/ 0.005/ ,/ kmax/ =/ 20/ ,/ kmin/ =/ 3/ ./ 上面/ 实验/ 表明/ 通过/ 提出/ 的/ 算法/ 可以/ 减少/ 覆盖/ 神经元/ 数目/ ./ 我们/ 再/ 来/ 构造/ 一个/ 识别/ 实验/ ,/ 以/ 证明/ 虽然/ 神经元/ 个数/ 减少/ 了/ 但是/ 覆盖/ 网络/ 的/ 识别/ 能力/ 并/ 不会/ 降低/ ./ 实验/ 2/ ./ 实验/ 数据/ 集是/ 分布/ 在/ 3/ 条/ 等速/ 螺旋/ 曲线/ 上/ 的/ 点/ ,/ 每条/ 曲线/ 共取/ 141/ 个点/ ,/ 对/ 其中/ 两条/ 曲/ Page6/ 线上/ 的/ 点/ ,/ 我们/ 取/ 其中/ 71/ 个点/ 作为/ 训练样本/ 构造/ 覆盖/ 网络/ (/ 神经元/ 阈值/ 就/ 取/ 做/ 每/ 一/ 邻域/ 内点/ 到/ 直线/ 段图/ 4/ 识别/ 网络/ 构造/ 效果/ 这个/ 实验/ 中/ 测试/ 样本/ 一共/ 281/ 个/ 其中/ ,/ 经过训练/ 的/ 样本/ 类/ 测试点/ 的/ 识别/ 正确率/ 为/ 100/ %/ ,/ 而/ 没有/ 构造/ 覆盖/ 神经网络/ 的/ 样本/ 集则/ 完全/ 被/ 拒识/ ./ 可见/ ,/ 算法/ 是/ 有效/ 的/ ,/ 这里/ 我们/ 仍然/ 采用/ 超/ 香肠/ 神经元/ 构造/ 神经网络/ ./ 如果/ 采用/ RBF/ 神经元/ ,/ 同样/ 每/ 一段/ 线段/ 对应/ 一个/ 神经元/ ,/ 由于/ RBF/ 神经元/ 可以/ 看作/ 一个/ 超球/ ,/ 这里/ 线段/ 长度/ 大致/ 等于/ 超球/ 直径/ ,/ 则/ 可以/ 想见/ 其/ 覆盖/ 区域/ 要/ 大于/ 超/ 香肠/ 神经元/ ,/ 那么/ 导致/ 的/ 误识率/ 也/ 将/ 较大/ ./ 5.2/ COIL20/ 数据库/ COIL20/ 数据库/ ①/ 包含/ 20/ 个/ 对象/ ./ 图/ 5/ 是/ COIL20/ 数据库/ 的/ 10/ 个/ 对象/ 的/ 样本/ 图片/ ./ 每个/ 对象/ 在/ 水平/ 上/ 旋转/ 360/ °/ ,/ 每隔/ 5/ °/ 拍摄/ 一张/ 照片/ ,/ 因此/ 每个/ 对象/ 共/ 72/ 幅/ 图片/ ./ 每幅/ 图像/ 为/ 32/ ×/ 32/ 像素/ 大小/ 的/ 灰度/ 图/ ,/ 故/ 可以/ 表示/ 成/ 1024/ 维/ 的/ 向量/ ./ 从/ 数据/ 集/ 观察/ ,/ 可见/ 每/ 一类/ 对象/ 的/ 样本/ 点/ 构成/ 一个/ 一/ 维流形/ ./ 我们/ 随机/ 取/ 每个/ 对象/ 图片/ 的/ 60/ 幅/ 图片/ 作为/ 训练样本/ (/ 其中/ 50/ 幅/ 作为/ 神经网络/ 构造/ ,/ 而/ 余下/ 10/ 幅/ 用来/ 训练/ 神经元/ 的/ 覆盖/ 阈值/ ,/ 阈值/ 设定/ 为/ 所有/ 训练/ 距离/ 的/ 最大值/ )/ 其余/ 作为/ 测试/ 样本/ ,/ 而/ 最后/ 一类/ 完全/ 作为/ 测试/ 样本/ ,/ 如图/ 4/ ./ 样本/ 到/ 相应/ 单纯形/ 距离/ 的/ 最大值/ )/ ,/ 其余/ 12/ 幅/ 图片/ 作为/ 测试/ 样本/ ,/ 来/ 测试通过/ 本文/ 算法/ 构造/ 的/ 多/ 权值/ 神经元/ 覆盖/ 网络/ 的/ 识别率/ ./ RBF/ 神经网络/ 、/ 支撑/ 向量/ 机/ (/ SVM/ )/ 以及/ 传统/ 方法/ 构造/ 的/ 多/ 权值/ 神经元/ 覆盖/ 网络/ 作为/ 对比/ 算法/ ./ 整个/ 实验/ 循环/ 10/ 次/ ,/ 平均/ 识别率/ 如表/ 1/ 所示/ :/ 算法/ 类别/ 识别率/ // %/ RBF/ 神经网络/ 87.45/ 尺度/ 参数/ 设/ 为/ 所有/ 样点/ SVM/ 传统/ 覆盖/ 网络/ 99.7549/ 个/ 超/ 香肠/ 神经元/ 本文/ 算法/ 98.8326/ 个/ 超/ 香肠/ 神经元/ 由表/ 1/ 可知/ ,/ 多权值/ 神经元/ 覆盖/ 网络/ 在/ COIL20/ 数据库/ 的/ 识别/ 实验/ 中/ 显示/ 出/ 明显/ 的/ 优势/ ./ 而/ 通过/ 本文/ 算法/ 构造/ 的/ 多/ 权值/ 神经元/ 覆盖/ 网络/ 可以/ 采用/ 较少/ 的/ 神经元/ 构造/ 网络/ ,/ 但/ 识别率/ 没有/ 明显/ 地/ 降低/ ,/ 由此可见/ ,/ 本文/ 算法/ 是/ 有效/ 的/ ./ 6/ 结论/ 本文/ 讨论/ 了/ 仿生/ 模式识别/ 多权值/ 神经网络/ 的/ 构造方法/ ,/ 主要/ 是/ 希望/ 在/ 保持/ 神经网络/ 对/ 数据/ 流形/ 逼近/ 能力/ 的/ 基础/ 上/ 采用/ 尽量少/ 的/ 神经元/ 来/ 完成/ 覆盖/ ,/ 从而/ 降低/ 网络/ 复杂度/ 和/ 构造/ 代价/ ,/ 通过/ 实验/ 证明/ 我们/ 的/ 算法/ 是/ 比较/ 有效/ 的/ ./ 但是/ 需要/ 说明/ 的/ 是/ ,/ 本文/ 的/ 实验/ 都/ 是/ 在/ 数据流/ 形成/ 一维/ 情况/ 下/ 进行/ 的/ ,/ 覆盖/ 神经元/ 采用/ 的/ 是/ 超/ 香肠/ 神经元/ ,/ 而/ 当/ 数据/ 流形/ 维数/ 增加/ 时/ 算法/ 复杂度/ 必定/ 也/ 会/ 增加/ ,/ 但/ 在/ 利用/ 多维/ 尺度/ ①/ COIL20/ 数据库/ ./ http/ :/ // // www/ ./ cs/ ./ columbia/ ./ edu/ // CAVE/ // Page7/ 变换/ 进行/ 线性/ 邻域/ 选择/ 时/ ,/ 我们/ 并/ 没有/ 限定/ 数据/ 流形/ 的/ 本征/ 维数/ ,/ 同时/ 在/ 单纯形/ 覆盖/ 网络/ 的/ 构造/ 算法/ 第/ 2/ 步中/ ,/ 同样/ 没有/ 对/ 数据/ 流形/ 的/ 限制/ ./ 因此/ ,/ 文中/ 所述/ 的/ 单纯形/ 神经元/ 覆盖/ 网络/ 的/ 构造/ 算法/ 实际上/ 对于/ 一维/ 以上/ 的/ 数据/ 流形/ ,/ 仍然/ 是/ 有效/ 的/ ./ 

