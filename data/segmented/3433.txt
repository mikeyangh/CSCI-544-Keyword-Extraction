Page1/ 选择性/ 集成/ 学习/ 算法/ 综述/ 张春霞/ 张/ 讲社/ (/ 西安交通大学/ 理学院/ 西安/ 710049/ )/ (/ 西安交通大学/ 机械制造/ 系统工程/ 国家/ 重点/ 实验室/ 西安/ 710049/ )/ 摘要/ 集成/ 学习/ 因其能/ 显著/ 提高/ 一个/ 学习/ 系统/ 的/ 泛化/ 能力/ 而/ 得到/ 了/ 机器/ 学习/ 界/ 的/ 广泛/ 关注/ ,/ 但/ 随着/ 基/ 学习机/ 数目/ 的/ 增多/ ,/ 集成/ 学习机/ 的/ 预测/ 速度/ 明显/ 下降/ ,/ 其所/ 需/ 的/ 存储空间/ 也/ 迅速/ 增加/ ./ 选择性/ 集成/ 学习/ 的/ 主要/ 目的/ 是/ 进一步/ 改善/ 集成/ 学习机/ 的/ 预测/ 效果/ ,/ 提高/ 集成/ 学习机/ 的/ 预测/ 速度/ ,/ 并/ 降低/ 其/ 存储/ 需求/ ./ 该文/ 对/ 现有/ 的/ 选择性/ 集成/ 学习/ 算法/ 进行/ 了/ 详细/ 综述/ ,/ 按照/ 算法/ 采用/ 的/ 选择/ 策略/ 对/ 其/ 进行/ 了/ 分类/ ,/ 并/ 分析/ 了/ 各种/ 算法/ 的/ 主要/ 特点/ ,/ 最后/ 对/ 选择性/ 集成/ 学习/ 在/ 将来/ 的/ 可能/ 研究/ 方向/ 进行/ 了/ 探讨/ ./ 关键词/ 选择性/ 集成/ 学习/ ;/ 基/ 学习机/ ;/ 集成/ 学习机/ ;/ 多样性/ ;/ 泛化/ 能力/ 1/ 引言/ 模式/ 分类/ 与/ 回归/ 问题/ 是/ 机器/ 学习/ 和/ 模式识别/ 等/ 研究/ 领域/ 中常/ 遇到/ 的/ 最/ 基本/ 任务/ 之一/ ,/ 该/ 任务/ 的/ 主要/ 目标/ 是/ 利用/ 实际/ 数据/ 构建/ 一个/ 具有/ 较强/ 泛化/ 能力/ Page2Dietterich/ [/ 1/ ]/ 曾/ 在/ 《/ AIMagazine/ 》/ 杂志/ 上将/ 集成/ 学习/ 列为/ 机器/ 学习/ 领域/ 的/ 四大/ 研究/ 方向/ 之首/ ./ 集成/ 学习/ 使用/ 多个/ 学习机/ 来/ 解决/ 同一/ 问题/ ,/ 它/ 通过/ 调用/ 一些/ 简单/ 的/ 分类/ 算法/ ,/ 以/ 获得/ 多个/ 不同/ 的/ 基/ 学习机/ ,/ 然后/ 采用/ 某种/ 方式/ 将/ 这些/ 学习/ 机组/ 合成/ 一个/ 集成/ 学习机/ ./ 随着/ 集成/ 学习/ 研究/ 队伍/ 的/ 不断/ 壮大/ ,/ 集成/ 学习/ 技术/ 得到/ 了/ 快速/ 发展/ ,/ 各种/ 集成/ 学习/ 算法/ 目前/ 也/ 正在/ 被/ 广泛应用/ 于/ 生物/ 、/ 工程/ 、/ 医学/ 、/ 计算机/ 视觉/ 和/ 图像处理/ 等/ 研究/ 领域/ [/ 2/ -/ 4/ ]/ ./ 一般/ 地/ ,/ 一个/ 集成/ 学习机/ 的/ 构建/ 分为/ 两步/ :/ 基/ 学习机/ 的/ 生成/ 和/ 基/ 学习机/ 的/ 合并/ ,/ 现有/ 的/ 许多/ 集成/ 学习/ 算法/ 主要/ 是/ 在/ 这/ 两/ 方面/ 存在/ 差异/ ./ 在/ 构建/ 集成/ 学习机/ 时/ ,/ 有效/ 地/ 产生/ 泛化/ 能力/ 强/ 、/ 差异/ 大/ 的/ 基/ 学习机/ 是/ 关键/ ,/ 即基/ 学习机/ 的/ 准确性/ 和/ 它们/ 之间/ 的/ 多样性/ 是/ 两个/ 重要/ 因素/ ./ 目前/ ,/ 常见/ 的/ 用于/ 生成/ 基/ 学习机/ 的/ 方法/ 可以/ 粗略地/ 分为/ 两大类/ :/ 一类/ 是/ 将/ 不同/ 类型/ 的/ 学习/ 算法/ 应用/ 于/ 同一/ 数据/ 集上/ ,/ 这种/ 方法/ 得到/ 的/ 基/ 学习机/ 通常/ 被/ 称为/ 是/ 异质/ 类型/ 的/ (/ heterogeneous/ )/ ;/ 另一类/ 是/ 将/ 同一/ 学习/ 算法/ 应用/ 于/ 不同/ 的/ 训练/ 集/ (/ 可/ 基于/ 原有/ 的/ 训练/ 数据/ 集/ 进行/ 随机抽样/ 等/ 方法/ 得到/ )/ ,/ 这种/ 方法/ 得到/ 的/ 基/ 学习机/ 被/ 称为/ 是/ 同质/ 类型/ 的/ (/ homogeneous/ )/ ./ 对于/ 生成/ 同质/ 类型/ 基/ 学习机/ 的/ 方法/ ,/ 基于/ 它们/ 获取/ 不同/ 训练/ 集所/ 采用/ 的/ 技术/ ,/ 又/ 可以/ 分为/ 对/ 训练/ 集重/ 抽样/ (/ 如/ Bagging/ [/ 5/ ]/ 、/ Boosting/ [/ 6/ ]/ )/ 、/ 操纵/ 输入/ 变量/ (/ 如/ 随机/ 子/ 空间/ 方法/ [/ 7/ ]/ 、/ 旋转/ 森林/ [/ 8/ ]/ )/ 、/ 操纵/ 输出/ 目标/ (/ 如/ 误差/ 校正/ 输出/ 编码/ 集成/ 方法/ (/ Errorcorrectingoutputcodeensemble/ )/ [/ 9/ ]/ )/ 、/ 注入/ 随机性/ (/ 如/ RandomForest/ [/ 10/ ]/ )/ ./ 在/ 生成/ 多个/ 基/ 学习机/ 之后/ ,/ 一个/ 很/ 自然/ 的/ 问题/ 是/ 以/ 何种/ 方式/ 将/ 它们/ 进行/ 合并/ 才能/ 得到/ 具有/ 最强/ 泛化/ 能力/ 的/ 集成/ 学习机/ ?/ 对此/ ,/ 研究者/ 们/ 也/ 提出/ 了/ 很多/ 解决办法/ ,/ 徐雷/ 等/ 人/ [/ 11/ ]/ 针对/ 模式/ 分类/ 问题/ ,/ 根据/ 基/ 分类器/ 提供/ 的/ 信息/ 水平/ 将/ 现有/ 的/ 合并/ 准则/ 分成/ 了/ 三大类/ :/ 抽象/ 水平/ 、/ 秩/ 水平/ 和/ 置信/ 值/ 水平/ ./ 抽象/ 水平/ 是/ 指基/ 分类器/ 的/ 输出/ 是/ 类/ 标签/ ,/ 秩/ 水平/ 假定/ 基/ 分类器/ 的/ 输出/ 是/ 根据/ 分类器/ 的/ 预测/ 效果/ 好坏/ 而/ 对/ 它们/ 赋予/ 的/ 秩序/ 列/ ,/ 而/ 置信/ 值/ 水平/ 则/ 假定/ 每个/ 基/ 分类器/ 的/ 输出/ 是/ 一个/ 概率分布/ ./ 在/ 置信/ 值/ 水平/ 类/ 的/ 合并/ 准则/ 中/ ,/ 根据/ 是否/ 需要/ 估计/ 额外/ 的/ 参数/ ,/ 它们/ 又/ 可以/ 分为/ 固定/ 的/ 合并/ 准则/ (/ fixedrules/ )/ 和/ 可/ 训练/ 的/ 合并/ 准则/ (/ trainablerules/ )/ ./ 固定/ 的/ 合并/ 准则/ 是/ 基于/ 基/ 分类器/ 的/ 输出/ 对基/ 分类器/ 直接/ 进行/ 合并/ ,/ 常用/ 的/ 有/ 最大值/ 、/ 最小值/ 、/ 中位数/ 、/ 乘积/ 、/ 均值/ 和/ 多数/ 投票/ (/ 加权/ 或/ 不/ 加权/ )/ 准则/ ;/ 而/ 可/ 训练/ 的/ 合并/ 准则/ 是/ 将/ 多个/ 基/ 分类器/ 的/ 输出/ 作为/ 新/ 的/ 特征/ 再/ 构建/ 一个/ 更/ 高水平/ 的/ 分类器/ ,/ 常见/ 的/ 方法/ 有/ 神经网络/ 、/ 决策树/ 、/ 支持/ 向量/ 机/ 、/ Bayes/ 准则/ 、/ 行为/ 知识/ 空间/ 、/ Dempster/ -/ Shafer/ 理论/ 等/ ./ 值得注意/ 的/ 是/ ,/ 可/ 训练/ 的/ 合并/ 准则/ 需要/ 额外/ 的/ 数据/ 集/ 估计/ 其中/ 的/ 参数/ ./ 但/ 在/ 实际/ 问题/ 中/ ,/ 一般/ 只有/ 一个/ 数据/ 集/ 可用/ ,/ 因此/ 该/ 数据/ 集/ 必须/ 被/ 用来/ 同时/ 训练/ 基/ 分类器/ 和/ 合并/ 准则/ ./ 在/ 这种/ 情况/ 下/ ,/ 有/ 三种/ 方法/ 可以/ 达到/ 上述/ 目的/ :/ 重复使用/ 策略/ (/ reusingstrategy/ )/ 、/ 随机/ 划分/ 策略/ (/ validationstrategy/ )/ 和/ 层叠/ 泛化/ 策略/ (/ stackedgeneralization/ )/ ,/ 这/ 三种/ 策略/ 的/ 详细/ 介绍/ 和/ 各自/ 的/ 优缺点/ 可/ 参考文献/ [/ 12/ -/ 13/ ]/ ./ 在/ 集成/ 学习/ 的/ 研究/ 初期/ ,/ 大多数/ 方法/ 都/ 是/ 先生/ 成/ 多个/ 基/ 学习机/ ,/ 然后/ 将/ 它们/ 全部/ 用于/ 构建/ 集成/ 学习机/ ./ 尽管/ 采用/ 这些/ 方法/ 得到/ 的/ 集成/ 学习机/ 的/ 预测/ 效果显著/ 优于/ 单个/ 基/ 学习机/ ,/ 但/ 它们/ 存在/ 一些/ 缺点/ :/ 与/ 基/ 学习机/ 相比/ ,/ 其/ 预测/ 速度/ 明显/ 下降/ ,/ 且/ 随着/ 基/ 学习机/ 数目/ 的/ 增多/ ,/ 它们/ 所/ 需/ 的/ 存储空间/ 也/ 急剧/ 增多/ ,/ 这/ 对于/ 在线/ 学习/ 更是/ 一个/ 严重/ 问题/ ./ 因此/ ,/ 人们/ 开始/ 考虑/ :/ 使用/ 少量/ 的/ 基/ 学习机/ 是否/ 可以/ 达到/ 更好/ 的/ 性能/ ?/ 2002/ 年/ ,/ 周志华/ 等/ 人/ [/ 14/ ]/ 首先/ 提出/ 了/ “/ 选择性/ 集成/ ”/ 的/ 概念/ ,/ 肯定/ 地/ 回答/ 了/ 上述/ 问题/ ,/ 并/ 在/ 国内外/ 集成/ 学习/ 界/ 引起/ 了/ 强烈反响/ ./ 理论/ 分析/ 和/ 试验/ 研究/ 表明/ ,/ 从/ 已有/ 的/ 基/ 学习机/ 中将/ 作用/ 不大/ 和/ 性能/ 不好/ 的/ 基/ 学习机/ 剔除/ ,/ 只/ 挑选/ 一些/ 基/ 学习机/ 用于/ 构建/ 集成/ 则/ 可以/ 得到/ 更好/ 的/ 预测/ 效果/ ./ 随后/ ,/ 选择性/ 集成/ 学习/ 引起/ 了/ 研究者/ 们/ 的/ 关注/ 并/ 提出/ 了/ 一些/ 有效/ 的/ 算法/ ./ 这里/ ,/ 值得/ 强调/ 的/ 是/ ,/ 选择性/ 集成/ 学习/ 是/ 在/ 假定/ 已/ 生成/ 多个/ 基/ 学习机/ 的/ 基础/ 上/ ,/ 基于/ 某种/ 选择/ 策略/ 只/ 从中/ 选择/ 一部分/ 用于/ 构建/ 最终/ 的/ 集成/ ./ 换句话说/ ,/ 选择性/ 集成/ 在/ 选择/ 的/ 过程/ 中/ ,/ 不会/ 再/ 生成/ 新/ 的/ 基/ 学习机/ ,/ 这/ 与/ 用/ 训练/ 数据/ 生成/ 一个/ Boosting/ 集成/ 的/ 过程/ 中/ ,/ 直接/ 抛弃/ 精度/ 较差/ 的/ 基/ 学习机/ 是/ 完全/ 不同/ 的/ ./ 为了/ 给/ 选择性/ 集成/ 学习/ 的/ 初学者/ 提供/ 入门/ 指导/ ,/ 并/ 为/ 新/ 算法/ 的/ 设计/ 提供/ 参考/ ,/ 本文/ 将/ 对/ 现有/ 的/ 选择性/ 集成/ 学习/ 算法/ 进行/ 较为/ 全面/ 的/ 综述/ ,/ 阐述/ 近年来/ 对/ 选择性/ 集成/ 学习/ 进行/ 研究/ 的/ 主要/ 内容/ 和/ 特点/ ,/ 通过/ 分析/ 现有/ 算法/ 的/ 特征/ ,/ 将/ 其/ 分类/ ,/ 并/ 对/ 它们/ 在/ 未来/ 的/ 研究/ 方向/ 进行/ 探讨/ ./ 据/ 我们/ 所知/ ,/ 尽管/ 文献/ [/ 15/ ]/ 曾/ 对/ 选择性/ 集成/ 学习/ 算法/ 进行/ 了/ 简短/ 的/ 综述/ ,/ 但/ 该文/ 未/ 对/ 一些/ 代表性/ 的/ 选择性/ 集成/ 学习/ 方法/ 进行/ 详细/ 说明/ ,/ 且/ 该/ 文献/ 出现/ 的/ 时间/ 较/ 早/ ,/ 而/ 近两年来/ 在/ 集成/ 学习/ 领域/ 中/ 已经/ 又/ 涌现出/ 了/ 很多/ 有效/ 的/ 选择性/ 集成/ 学习/ 算法/ ./ 因此/ ,/ 本文/ 的/ 研究/ 是/ 文献/ [/ 15/ ]/ 工作/ 的/ 进一步/ 完善/ Page3/ 和/ 补充/ ./ 本文/ 第/ 2/ 节对/ 用于/ 解决/ 分类/ 问题/ 的/ 选择性/ 集成/ 学习/ 算法/ 进行/ 详细/ 综述/ ,/ 并/ 分析/ 几类/ 算法/ 的/ 特点/ ;/ 第/ 3/ 节/ 讨论/ 选择性/ 集成/ 学习/ 算法/ 在/ 回归/ 预测/ 中/ 的/ 应用/ ;/ 第/ 4/ 节是/ 总结/ 与/ 展望/ ,/ 主要/ 探讨/ 选择性/ 集成/ 学习/ 在/ 未来/ 可能/ 的/ 研究/ 方向/ ./ 2/ 选择性/ 集成/ 学习/ 算法/ 假定/ / tr/ =/ {/ (/ 狓/ i/ ,/ yi/ )/ }/ Ntr/ 由于/ 分类/ 问题/ 和/ 回归/ 问题/ 具有/ 不同/ 的/ 特点/ ,/ 需要/ 使用/ 不同/ 的/ 方法/ 进行/ 解决/ ,/ 而/ 集成/ 学习/ 最早/ 是/ 在/ 解决/ 分类/ 问题/ 的/ 过程/ 中/ 提出/ 的/ ./ 因此/ ,/ 我们/ 在/ 本节/ 中先/ 对/ 现有/ 的/ 关于/ 分类/ 问题/ 的/ 选择性/ 集成/ 学习/ 算法/ 进行/ 讨论/ ,/ 下/ 一节/ 中/ 再/ 探讨/ 基于/ 回归/ 问题/ 的/ 相关/ 算法/ ./ 在/ 此/ ,/ 我们/ 引入/ 一些/ 记号/ 以/ 方便/ 后文/ 的/ 叙述/ ./ 训练/ 个体/ (/ 狓/ i/ ,/ yi/ )/ ,/ 其/ 输入/ 变量/ 狓/ i/ =/ (/ xi1/ ,/ xi2/ ,/ …/ ,/ xip/ )/ ∈/ Rp/ ,/ 输出/ 变量/ yi/ ∈/ Φ/ =/ {/ ω/ 1/ ,/ ω/ 2/ ,/ …/ ,/ ω/ c/ }/ ,/ c/ 为类/ 的/ 个数/ ./ 同时/ ,/ 令/ / val/ 、/ / ts/ 分别/ 表示/ 容量/ 为/ Nval/ 和/ Nts/ 的/ 验证/ 集/ 和/ 检验/ 集/ ./ 在/ 实际/ 应用/ 中/ ,/ 如果/ 只/ 给定/ 了/ 一个/ 数据/ 集/ ,/ 则/ 可以/ 通过/ 随机/ 划分/ 的/ 方法/ 得到/ 相应/ 的/ 训练/ 集/ 、/ 验证/ 集/ 和/ 检验/ 集/ ./ 此外/ ,/ 我们/ 用/ / =/ {/ C1/ ,/ C2/ ,/ …/ ,/ CT/ }/ 表示/ 基于/ / tr/ 训练/ 的/ 基/ 分类器/ 集合/ ,/ / =/ {/ C/ / 2/ ,/ …/ ,/ C/ / C/ / 中/ 选取/ 出来/ 的/ 基/ 分类器/ 集合/ ./ 选择性/ 集成/ 学习/ 的/ 主要/ 思想/ 是/ 基于/ 某种/ 衡量/ 准则/ ,/ 从/ 已有/ 的/ 基/ 分类器/ 中/ 选择/ 一些/ 用于/ 构建/ 集成/ 分类器/ ,/ 以/ 加快/ 分类器/ 的/ 预测/ 速度/ 、/ 降低/ 其/ 存储空间/ 需求/ 并/ 进一步提高/ 分类/ 精度/ ./ 理论/ 上/ ,/ 最优/ 的/ 基/ 分类器/ 子集/ / 可以/ 通过/ 枚举法/ (/ exhaustiveenumeration/ )/ 得到/ ./ 对/ / 的/ 每个/ 子集/ / 器/ 的/ 预测/ 效果/ ,/ 选择/ 具有/ 最小/ 泛化/ 误差/ 的/ 集成/ 分类器/ 所/ 对应/ 的/ 子集/ 即可/ ,/ 即/ / =/ Argmin/ / 们/ 需要/ 对/ ∑/ T/ 目/ T/ 较大/ 时/ ,/ 其/ 计算/ 量/ 极大/ ./ 因而/ ,/ 枚举法/ 在/ 实际/ 中/ 并/ 不/ 可行/ ./ 鉴于/ 上述/ 原因/ ,/ 选择性/ 集成/ 学习/ 在/ 近/ 10/ 年/ 中/ 得到/ 了/ 广泛/ 的/ 研究/ ,/ 我们/ 在/ 下面/ 的/ 图/ 1/ 中/ 给出/ 了/ 选择性/ 集成/ 学习/ 算法/ 的/ 基本/ 框架/ ./ 对于/ 现有/ 的/ 选择性/ 集成/ 学习/ 算法/ ,/ 它们/ 主要/ 在/ 评测/ 方法/ / 的/ 选择/ 上/ 存在/ 差异/ ./ 于是/ ,/ 这些/ 算法/ 大致/ 可以/ 分为/ 以下/ 几类/ :/ 聚类/ 、/ 排序/ 、/ 选择/ 、/ 优化/ 和/ 其它/ 方法/ ./ 下面/ 我们/ 对/ 这/ 几种/ 方法/ 的/ 主要/ 思想/ 和/ 特点/ 进行/ 详细分析/ ./ 择/ 的/ 基/ 分类器/ 个数/ S/ ,/ 评测/ 方法/ / 输入/ :/ 训练/ 集/ / tr/ ,/ 验证/ 集/ / val/ ,/ 基/ 分类/ 算法/ / ,/ 基/ 分类器/ 个数/ T/ ,/ 选/ 输出/ :/ 选择/ 的/ 基/ 分类器/ 集合/ / =/ {/ C/ / 1/ ,/ C/ / 2/ ,/ …/ ,/ C/ / S/ }/ 训练/ 过程/ :/ 初始化/ :/ 令基/ 分类器/ 集合/ / =/ / ./ Fort/ =/ 1/ ,/ 2/ ,/ …/ ,/ T/ 基于/ 训练/ 集/ / tr/ ,/ 采用/ 某种/ 技术/ (/ 如/ Bootstrap/ 随机抽样/ 方法/ )/ 获取/ 新/ 的/ 训练/ 集/ / 应用/ 基/ 分类/ 算法/ / 于/ / EndFor/ (/ 得到/ 初始/ 的/ 基/ 分类器/ 集合/ / =/ {/ C1/ ,/ C2/ ,/ …/ ,/ CT/ }/ )/ 选择/ 过程/ :/ 在/ 验证/ 集/ / val/ 上/ 对/ 每个/ 基/ 分类器/ Ct/ (/ t/ =/ 1/ ,/ 2/ ,/ …/ ,/ T/ )/ 进行/ 测试/ ,/ 得/ 其/ 输出/ Ot/ ./ 利用/ 评测/ 方法/ / 基于/ Ot/ (/ t/ =/ 1/ ,/ 2/ ,/ …/ ,/ T/ )/ 对/ / 中/ 每个/ 元素/ 进行/ 评测/ ,/ 并/ 从中/ 选择/ 出/ S/ 个基/ 分类器/ C/ / 1/ ,/ C/ / 2/ ,/ …/ ,/ C/ / S/ ./ 2.1/ 基于/ 聚类/ 的/ 方法/ 这/ 类/ 方法/ [/ 16/ -/ 21/ ]/ 的/ 主要/ 过程/ 如图/ 2/ 所示/ ./ 输入/ :/ 验证/ 集/ / val/ ,/ 基/ 分类器/ 集合/ / =/ {/ C1/ ,/ C2/ ,/ …/ ,/ CT/ }/ ,/ 聚类/ 算法/ / 输出/ :/ 选择/ 的/ 基/ 分类器/ 集合/ / =/ {/ C/ / 1/ ,/ C/ / 2/ ,/ …/ ,/ C/ / S/ }/ 选择/ 过程/ :/ 利用/ 每个/ 基/ 分类器/ Ct/ (/ t/ =/ 1/ ,/ 2/ ,/ …/ ,/ T/ )/ 对/ 验证/ 集/ / val/ 中/ 的/ 个体/ 进行/ 预测/ ,/ 得到/ 矩阵/ 犗/ =/ (/ oij/ )/ T/ ×/ Nval/ ,/ 其/ 元素/ oij/ 对应/ 于/ 第/ i/ 个基/ 分类器/ Ci/ 对/ 第/ j/ 个/ 个体/ 狓/ j/ 的/ 预测/ 结果/ ,/ 即/ oij/ =/ Ci/ (/ 狓/ j/ )/ (/ i/ =/ 1/ ,/ 2/ ,/ …/ ,/ T/ ;/ j/ =/ 1/ ,/ 2/ ,/ …/ ,/ Nval/ )/ ./ 视/ 矩阵/ 犗/ 的/ 每行/ 狅/ i/ =/ (/ oi1/ ,/ oi2/ ,/ …/ ,/ oiNval/ )/ 为/ 新/ 的/ 特征/ 空间/ 中/ 的/ 一个/ 观测/ ,/ 犗/ 为/ 包含/ T/ 个/ 观测/ 的/ 数据/ 集/ ,/ 将/ 聚类/ 算法/ / 应用/ 于/ 犗/ ,/ 找到/ 具有/ 类似/ 预测/ 结果/ 的/ 基/ 分类器/ 子集/ / 1/ ,/ / 2/ ,/ …/ ,/ / S/ (/ 即/ 聚类/ 算法/ 最终/ 形成/ 的/ 类/ )/ ./ 对/ 每个/ 基/ 分类器/ 子集/ 进行/ 修剪/ ,/ 选择/ 出/ 具有/ 代表性/ 的/ 基/ 分类器/ C/ / 1/ ,/ C/ / 2/ ,/ …/ ,/ C/ / S/ ./ 在/ 上述/ 过程/ 中/ ,/ 有/ 3/ 个/ 关键问题/ 需要/ 解决/ :/ 如何/ 衡量/ 两个/ 基/ 分类器/ (/ 子集/ )/ 预测/ 结果/ (/ 如/ 狅/ i/ 和/ 狅/ j/ ,/ i/ ≠/ j/ )/ 之间/ 的/ 相似性/ ?/ 聚类/ 算法/ / 选用/ 何种/ 算法/ ?/ 如何/ 确定/ 基/ 分类器/ 子集/ 的/ 个数/ S/ ?/ 类器/ Cs/ 和/ Ct/ 之间/ 的/ 距离/ 为/ 在/ 文献/ [/ 16/ ]/ 中/ ,/ Giacinto/ 和/ Roli/ 定义/ 两个/ 基分/ d/ (/ Cs/ ,/ Ct/ )/ =/ 1/ -/ Prob/ (/ Csfails/ ,/ Ctfails/ )/ ,/ 其中/ ,/ Prob/ (/ Csfails/ ,/ Ctfails/ )/ 为/ 基于/ 验证/ 集/ / val/ 估计/ 的/ 两个/ 基/ 分类器/ 同时/ 分类/ 错误/ 的/ 概率/ ./ 同时/ ,/ 他们/ 定义/ 两个/ 基/ 分类器/ 子集/ / i/ 和/ / j/ 之间/ 的/ 距离/ 为/ d/ (/ / i/ ,/ / j/ )/ =/ maxCs/ ∈/ / i/ ,/ Ct/ ∈/ / j/ 然后/ ,/ 采用/ 层次/ 凝聚/ 的/ 聚类/ 算法/ (/ hierarchicalagglomerativeclustering/ )/ 来/ 找到/ 具有/ 相似/ 预测/ 结果/ 的/ 基/ 分类器/ 子集/ ./ 至于/ S/ 的/ 确定/ ,/ 则/ 是/ 在/ 聚类/ 算法/ 的/ 每/ 一步/ ,/ 从/ 每个/ 类中/ 挑选出/ 到/ 其它/ 类/ 的/ 平均/ 距离/ 最大/ 的/ 基/ 分类器/ ,/ 采用/ 简单/ 投票/ 的/ 方式/ 将/ 其/ 组合成/ 集成/ 分类器/ ,/ 并/ 基于/ 验证/ 集/ 衡量/ 其/ 分类/ 精度/ ./ 最后/ ,/ Page4/ 选择/ 具有/ 最高/ 精度/ 的/ 集成/ 分类器/ 对应/ 的/ 基/ 分类器/ 子集/ ,/ 即/ / =/ {/ C/ / Lazarevic/ 和/ Obradovic/ [/ 17/ ]/ 则/ 基于/ 犗/ 中/ 观测/ 的/ 欧氏/ 距离/ ,/ 应用/ K/ -/ 均值/ 聚类/ 算法/ 将基/ 分类器/ 进行/ 分组/ ,/ 并/ 利用/ 基/ 分类器/ 子集/ 的/ 准确性/ 和/ 多样性/ 对/ 它们/ 进行/ 修剪/ ./ 此外/ ,/ 文献/ [/ 18/ -/ 21/ ]/ 采用/ 其它/ 一些/ 聚类/ 技术/ 如/ 基于/ 确定性/ 退火/ (/ deterministicannealing/ )/ 的/ 软聚类/ 算法/ 、/ 谱系/ 聚类/ 法/ 、/ 核聚类/ 算法/ 等/ 对/ 多/ 分类器/ 的/ 选择/ 问题/ 进行/ 了/ 研究/ ./ 2.2/ 基于/ 排序/ 的/ 方法/ 通过/ 对基/ 分类器/ 进行/ 排序/ 来/ 达到/ 修剪/ 集成/ 分类器/ 的/ 目的/ [/ 22/ -/ 29/ ]/ 是/ 比较/ 直观/ 的/ 选择性/ 集成/ 学习/ 方法/ ,/ 它们/ 的/ 步骤/ 大致/ 可以/ 分为/ 两步/ :/ 基于/ 某种/ 衡量标准/ (/ 如/ 准确性/ )/ 对基/ 分类器/ 排序/ ,/ 采用/ 合适/ 的/ 停止/ 准则/ (/ 如/ 事先/ 指定/ 选取/ 的/ 基/ 分类器/ 个数/ )/ 选取/ 一定/ 数量/ 的/ 基/ 分类器/ ./ 在/ 下面/ 的/ 图/ 3/ 中/ ,/ 我们/ 列出/ 了/ 这类/ 算法/ 的/ 主要/ 步骤/ ./ 输入/ :/ 验证/ 集/ / val/ ,/ 评测/ 标准/ / (/ 如/ 准确性/ 、/ 预测/ 误差/ 等/ )/ ,/ 基/ 分类/ 输出/ :/ 选择/ 的/ 基/ 分类器/ 集合/ / =/ {/ C/ / 1/ ,/ C/ / 2/ ,/ …/ ,/ C/ / S/ }/ 排序/ 过程/ :/ Fort/ =/ 1/ ,/ 2/ ,/ …/ ,/ T/ 器/ 集合/ / =/ {/ C1/ ,/ C2/ ,/ …/ ,/ CT/ }/ 在/ 验证/ 集/ / val/ 上/ ,/ 依据/ 评测/ 标准/ / 对/ 每个/ 基/ 分类器/ Ci/ (/ i/ =/ 1/ ,/ 2/ ,/ …/ ,/ T/ )/ 进行/ 评价/ 并/ 排序/ ./ 根据/ 事先/ 指定/ 的/ 基/ 分类器/ 个数/ S/ 或/ 评测/ 方法/ 自身/ 确定/ 的/ S/ ,/ 从/ / 选出/ 性能/ 较/ 好/ 的/ 基/ 分类器/ C/ / 1/ ,/ C/ / 2/ ,/ …/ ,/ C/ / S/ ./ EndFor/ 在/ 文献/ [/ 26/ ]/ 中/ ,/ Mart/ í/ nez/ -/ Muoz/ 和/ Surez/ 提出/ 基于/ Boosting/ 主要/ 思想/ 来/ 对/ Bagging/ 集成/ 分类器/ 进行/ 修剪/ 的/ 算法/ ,/ 并/ 给出/ 了/ 两种/ 确定/ 参数/ S/ 的/ 取值/ 方法/ :/ (/ 1/ )/ 直接/ 令/ S/ ≈/ 40/ %/ ×/ T/ ,/ 因为/ 作者/ 之前/ 进行/ 试验/ 的/ 一些/ 结果/ [/ 23/ ]/ 表明/ 该/ 准则/ 效果/ 较/ 好/ ;/ (/ 2/ )/ 第一个/ Boosting/ 停止/ 点/ 准则/ ,/ 即/ 在/ 选择/ 到/ 某个/ 基/ 分类/ s/ 的/ 加权/ 训练/ 误差/ ε/ s/ >/ 0.5/ 时/ ,/ 停止/ 选择/ 过程/ ./ 器/ C/ / Mart/ í/ nez/ -/ Muoz/ 和/ Surez/ 采用/ 16/ 个/ UCI/ 实际/ 数据/ 集/ 和/ 2/ 个/ 人工/ 数据/ 集/ 进行/ 试验/ ,/ 结果表明/ 上述/ 两种/ 停止/ 准则/ 性能/ 都/ 较/ 好/ ./ 值得/ 指出/ 的/ 是/ ,/ 文献/ [/ 26/ ]/ 中/ 选择/ 基/ 分类器/ 的/ 过程/ 是/ 基于/ 训练/ 集/ / tr/ (/ 同时/ 也/ 用于/ 基/ 分类器/ 的/ 训练/ )/ 进行/ 的/ ,/ 在/ 实际/ 应用/ 中/ ,/ 为了/ 避免出现/ 过/ 拟合/ 现象/ ,/ 上述/ 选择/ 过程/ 一般/ 要/ 基于/ 验证/ 集/ / val/ 进行/ ./ 此外/ ,/ Bryll/ 等/ 人/ [/ 22/ ]/ 先/ 采用/ 绕封/ (/ wrapper/ )/ 的/ 特征选择/ 方法/ 确定/ 特征/ 子集/ ,/ 基于/ 该/ 特征/ 子集/ 训练/ 基/ 分类器/ ,/ 根据/ 其/ 分类/ 准确性/ 对/ 所有/ 的/ 特征/ 子集/ 进行/ 排序/ ,/ 最后/ 选用/ 得到/ 秩数/ 较/ 高/ 的/ 一些/ 子集/ 所/ 训练/ 的/ 基/ 学习机/ 来/ 构建/ 集成/ 分类器/ ./ Mart/ í/ nez/ -/ Muoz/ 和/ Surez/ [/ 24/ ]/ 定义/ 了/ 一个/ 参照/ 向量/ (/ referencevector/ )/ 和/ 一个/ 对应/ 于/ Bagging/ 集成/ 中/ 每个/ 基/ 分类器/ 的/ 标号/ 向量/ (/ signaturevector/ )/ ,/ 利用/ 相应/ 的/ 标号/ 向量/ 偏离/ 参照/ 向量/ 的/ 程度/ 对基/ 分类器/ 进行/ 排序/ ,/ 通过/ 及早/ 停止/ 合并/ 过程/ 而/ 达到/ 修剪/ Bagging/ 集成/ 的/ 目的/ ./ Croux/ 等/ 人/ [/ 25/ ]/ 则/ 采用/ Out/ -/ of/ -/ bag/ 样本/ [/ 30/ ]/ 估计/ 基于/ Bagging/ 技术/ 所/ 生成/ 的/ 每个/ 基/ 分类器/ 的/ 泛化/ 误差/ ,/ 并/ 对/ 其/ 排序/ ,/ 通过/ 预先/ 设置/ 的/ 阈值/ 将/ 泛化/ 误差/ 较大/ 的/ 基/ 分类器/ 剔除/ ./ Mart/ í/ nez/ -/ Muoz/ 等/ 人/ [/ 27/ ]/ 则/ 对/ 通过/ 排序/ 修剪/ Bagging/ 集成/ 分类器/ 的/ 技术/ 作/ 了/ 详细/ 的/ 分析/ 和/ 研究/ ,/ 并/ 指出/ 可/ 用于/ 对基/ 学习机/ 排序/ 的/ 指标/ 大致/ 包括/ 误差/ 的/ 减小/ 量/ 、/ κ/ 统计/ 量/ [/ 31/ ]/ 、/ 互补性/ 、/ 边缘/ 距离/ 等/ ./ Rokach/ [/ 28/ ]/ 提出/ 了/ CAP/ (/ Collective/ -/ Agreement/ -/ basedPruning/ )/ 选择性/ 集成/ 学习/ 算法/ ,/ 对/ 每个/ 基/ 分类器/ 子集/ ,/ CAP/ 基于/ 其中/ 每个/ 成员/ 的/ 预测/ 能力/ 和/ 它们/ 之间/ 的/ 冗余/ 性/ (/ 用/ 对称/ 的/ 不确定性/ 或/ κ/ 统计/ 量/ 来/ 衡量/ )/ 对/ 这些/ 子集/ 进行/ 排序/ ,/ 并/ 选择/ 冗余/ 性小且/ 平均/ 预测/ 精度高/ 的/ 基/ 分类器/ 子集/ ./ 张春霞/ 和/ 张/ 讲社/ [/ 29/ ]/ 也/ 采用/ Boosting/ 的/ 思想/ 提出/ 了/ 对/ Double/ -/ Bagging/ 集成/ 分类器/ [/ 32/ ]/ 进行/ 修剪/ 的/ 技术/ ,/ 并/ 取得/ 了/ 较/ 好/ 的/ 效果/ ./ 2.3/ 基于/ 选择/ 的/ 方法/ 依据/ 某种/ 选择/ 标准/ ,/ 只/ 选择/ 部分/ 基/ 分类器/ 来/ 参与/ 集成/ 学习/ 是/ 最/ 直观/ 的/ 选择性/ 集成/ 学习/ 方法/ ,/ 现有/ 的/ 多数/ 相关/ 算法/ [/ 31/ ,/ 33/ -/ 57/ ]/ 都/ 属于/ 此类/ ./ 前述/ 的/ 基于/ 排序/ 的/ 方法/ 与/ 此类/ 方法/ 密切相关/ ,/ 从/ 广义/ 上/ 讲/ ,/ 基于/ 排序/ 的/ 方法/ 也/ 属于/ 选择/ 类/ 的/ 方法/ ./ 在/ 选择/ 类/ 方法/ 中/ ,/ 按照/ 它们/ 是否/ 采用/ 统一/ 模型/ 对/ 检验/ 集中/ 的/ 所有/ 个体/ 进行/ 预测/ ,/ 又/ 可以/ 分为/ 静态/ 选择/ 法/ (/ staticselectionmethod/ )/ 和/ 动态/ 选择/ 法/ (/ dynamicselectionmethod/ )/ ./ 2.3/ ./ 1/ 静态/ 选择/ 法/ 该类/ 方法/ [/ 31/ ,/ 33/ -/ 46/ ]/ 的/ 主要/ 特点/ 是/ 基于/ 已有/ 的/ 基/ 分类器/ ,/ 从中/ 选择/ 一部分/ 构建/ 集成/ 分类器/ ,/ 并用/ 其/ 对/ 所有/ 的/ 检验/ 个体/ 进行/ 预测/ ./ 各种/ 方法/ 之间/ 的/ 区别/ 是/ 采用/ 不同/ 的/ 度量/ 标准/ 来/ 选择/ 基/ 分类器/ ./ 静态/ 选择性/ 集成/ 学习/ 算法/ 的/ 基本/ 框架/ 如图/ 4/ 所示/ ./ 输入/ :/ 验证/ 集/ / val/ ,/ 评测/ 标准/ / ,/ 基/ 分类器/ 集合/ / =/ {/ C1/ ,/ C2/ ,/ …/ ,/ 输出/ :/ 选择/ 的/ 基/ 分类器/ 集合/ / =/ {/ C/ / 1/ ,/ C/ / 2/ ,/ …/ ,/ C/ / S/ }/ 选择/ 过程/ :/ 初始化/ :/ 令/ / =/ / ./ Fors/ =/ 1/ ,/ 2/ ,/ …/ ,/ S/ 在/ 验证/ 集/ / val/ 上/ ,/ 依据/ 评测/ 标准/ / 从/ / 中/ 选择/ 效果/ 最好/ 的/ 基/ 分类器/ C/ / s/ ./ 将/ C/ / s/ 加入/ 集合/ / 中/ ,/ 并/ 将/ 其/ 从/ / 中/ 删除/ ,/ 即令/ / =/ / ∪/ C/ / s/ ,/ / =/ / \/ C/ / s/ ./ CT/ }/ ,/ 选择/ 的/ 基/ 分类器/ 个数/ SEndForPage5/ 在/ 文献/ [/ 31/ ]/ 中/ ,/ Margineantu/ 和/ Dietterich/ 提出/ 基于/ Kappa/ -/ Error/ 图来/ 修剪/ AdaBoost/ 集成/ 分类器/ ,/ 以/ 保证/ 选择/ 的/ 基/ 分类器/ 的/ 准确性/ 和/ 它们/ 之间/ 的/ 多样性/ ,/ 进而/ 使/ 它们/ 组成/ 的/ 集成/ 分类器/ 的/ 预测/ 性能/ 与/ 原来/ 的/ 相比/ 没有/ 明显/ 的/ 下降/ ;/ Tamon/ 和/ Xiang/ [/ 33/ ]/ 进一步/ 改进/ 了/ 该/ 方法/ ,/ 经/ 理论/ 分析/ ,/ 他们/ 发现/ Boosting/ 集成/ 的/ 修剪/ 问题/ 甚至/ 用/ 逼近/ 的/ 方法/ 都/ 难以解决/ ,/ 于是/ 提出/ 了/ 基于/ 边缘/ (/ margin/ )/ 来/ 选取/ 最优/ 基/ 分类器/ 子集/ 的/ 启发式/ 方法/ ./ Caruana/ 等/ 人/ [/ 34/ ]/ 针对/ 多种不同/ 的/ 学习/ 算法/ 如/ 神经网络/ 、/ 支撑/ 向量/ 机/ (/ SVM/ )/ 、/ 决策树/ 、/ Bagging/ 和/ Boosting/ 分类/ 树/ 集成/ 等/ ,/ 通过/ 将/ 这些/ 算法/ 采用/ 不同/ 的/ 参数/ 生成/ 了/ 大量/ 基/ 分类器/ (/ 2000/ 个/ )/ ,/ 并/ 利用/ 前向/ 逐步/ 选择/ 的/ 方法/ 来/ 最大化/ 选择性/ 集成/ 分类器/ 在/ 验证/ 集上/ 的/ 分类/ 效果/ ./ Banfield/ 等/ 人/ [/ 35/ ]/ 基于/ 基/ 分类器/ 的/ 准确性/ 设计/ 了/ 顺序/ 后/ 向/ 选择/ 方法/ (/ sequentialback/ -/ wardselection/ )/ 、/ AID/ (/ AccuracyInDiversity/ )/ 修剪/ 算法/ 和/ 协同/ (/ concurrency/ )/ 修剪/ 算法/ ./ Demir/ 和/ Alpaydin/ [/ 36/ ]/ 基于/ 效用/ 理论/ (/ utilitytheory/ )/ ,/ 提出/ 了/ 一种/ 对/ 损失/ 敏感/ 且/ 期望/ 效用/ 最大化/ 的/ 选择性/ 集成/ 学习/ 算法/ ,/ 试验/ 结果表明/ :/ 该/ 方法/ 在/ 实际/ 中/ 通过/ 达到/ 准确性/ 和/ 检验/ 损失/ 之间/ 的/ 折中/ ,/ 可以/ 成功/ 地/ 选择/ 一些/ 基/ 分类器/ 使得/ 它们/ 组成/ 的/ 集成/ 分类器/ 具有/ 较强/ 的/ 泛化/ 能力/ ./ Aksela/ 和/ Laaksonen/ [/ 37/ ]/ 定义/ 了/ 指数/ 误差/ 数/ (/ ExponentialErrorCount/ ,/ EEC/ )/ 用于/ 度量/ 基/ 分类器/ 误差/ 之间/ 的/ 多样性/ ,/ 通过/ 最小化/ EEC/ 来/ 选择/ 最优/ 的/ 基/ 分类器/ 子集/ ,/ 在/ 手写/ 字符/ 数据/ 集上/ 进行/ 试验/ 的/ 结果表明/ 该/ 方法/ 具有/ 较/ 好/ 的/ 效果/ ./ Rokach/ 等/ 人/ [/ 38/ ]/ 针对/ 异质/ 类型/ 基/ 分类器/ 的/ 选择/ 进行/ 了/ 研究/ ,/ 通过/ 定义/ PEM/ 量/ (/ potentialextractmeasure/ )/ 提出/ 了/ 一种/ 选择性/ 投票/ (/ selectivevoting/ )/ 方法/ ./ Shahjahan/ 和/ Murase/ [/ 39/ ]/ 则/ 提出/ 了/ 修剪/ 相互协作/ 神经网络/ 集成/ 的/ 算法/ PNNE/ (/ PruningNNen/ -/ semble/ )/ ./ 对/ 每个/ NN/ ,/ 他们/ 引入/ 了/ 隐/ 节点/ 的/ 一个/ 协作/ 函数/ 来/ 支持/ 衰减/ 过程/ ,/ 并/ 基于/ 负相关/ 学习/ (/ nega/ -/ tivelearning/ )/ 增加/ 各个/ NN/ 间/ 的/ 多样性/ ,/ 进而/ 将/ 过/ 拟合/ 的/ NN/ 从中/ 剔除/ ./ Hu/ 等/ 人/ [/ 40/ ]/ 提出/ 了/ FS/ -/ PP/ -/ EROS/ (/ ForwardSearch/ -/ PostPruning/ -/ Ensemblemul/ -/ tipleROughsubspaces/ )/ 算法/ ,/ 该/ 算法/ 首先/ 基于/ 粗糙集/ 理论/ 对/ 数据/ 的/ 特征/ 进行/ 约简/ (/ roughset/ -/ basedattributereduction/ )/ ,/ 得到/ 一些/ 特征/ 子集/ ,/ 然后/ 基于/ 每个/ 特征/ 子集/ 训练/ 一个/ 基/ 分类器/ ,/ 并/ 采用/ 精度/ 驱动/ 的/ 前/ 向搜索/ 和/ 修剪/ 的/ 策略/ 选择/ 基/ 分类器/ ./ 唐/ 耀华/ 等/ 人/ [/ 43/ ]/ 利用/ ξ/ α/ 误差/ 估计/ 法/ 度量/ 个体/ SVM/ 泛化/ 性/ ,/ 并/ 基于/ 负相关/ 学习/ 引入/ 差异性/ ,/ 通过/ 递归/ 删除/ 法/ 选择/ 一组/ 泛化/ 能力/ 优良/ 、/ 差异性/ 大/ 的/ SVM/ 参与/ 集成/ 学习/ ./ 针对/ 半/ 朴素/ 贝叶斯/ 分类器/ (/ seminaiveBayesianclassifier/ )/ 族/ 中/ 的/ 超/ 1/ -/ 依赖/ 贝叶斯/ 分类器/ (/ Super/ -/ Parent/ -/ One/ -/ DependenceEstimator/ ,/ SPODE/ )/ 在/ 集成/ 学习/ 过程/ 中/ 应该/ 进行/ 选择/ 还是/ 加权/ 合并/ 的/ 问题/ ,/ Yang/ 等/ 人/ [/ 41/ ]/ 采用/ 58/ 个/ 数据/ 集对/ 16/ 种/ 方法/ 进行/ 了/ 大规模/ 的/ 研究/ ,/ 为/ 该类/ 方法/ 在/ 实际/ 中/ 的/ 应用/ 提供/ 了/ 有效/ 的/ 指导/ ./ Folino/ 等/ 人/ [/ 42/ ]/ 提出/ 基于/ 分格/ 遗传/ 规划/ (/ cellulargeneticprogramming/ )/ 的/ 方法/ 来/ 构建/ Boosting/ 集成/ 分类器/ ,/ 并/ 采用/ 遗传/ 规划/ 中/ 的/ 结构/ 多样性/ (/ structuraldiversity/ )/ 度量/ (/ 主要/ 有/ 两个/ 树/ 之间/ 的/ 距离/ 、/ 一个/ 树到/ 空树/ 的/ 距离/ 和/ κ/ 统计/ 量/ )/ 来/ 对/ 集成/ 分类器/ 进行/ 修剪/ ./ Meynet/ 和/ Thiran/ [/ 44/ ]/ 在/ 信息论/ 框架/ 下/ 建立/ 了/ 基/ 分类器/ 的/ 准确性/ 和/ 多样性/ 之间/ 的/ 联系/ ,/ 并/ 建议/ 基于/ 信息/ 理论/ 得分/ (/ InformationTheoreticScore/ ,/ ITS/ )/ 来/ 修剪/ 集成/ 分类器/ ,/ 相比/ 于/ 使用/ 多样性/ 来/ 选择/ 最优/ 基/ 分类器/ 子集/ 的/ 方法/ ,/ ITS/ 算法/ 更具/ 优势/ ./ Ting/ 和/ Witten/ [/ 45/ ]/ 则/ 提出/ 用/ 交叉/ 确认/ 法/ 选择/ 一个/ 最好/ 性能/ 的/ 基/ 分类器/ 来/ 对/ 检验/ 数据/ 进行/ 预测/ ./ 对于/ 商业/ 中/ 的/ 破产/ 预测/ (/ bankruptcyprediction/ )/ 二/ 分类/ 问题/ ,/ Hung/ 和/ Chen/ [/ 46/ ]/ 建议/ 基于/ 破产/ 和/ 不/ 破产/ 的/ 期望/ 概率/ 从/ 决策树/ 、/ 后/ 向/ 传播/ 神经网络/ 和/ SVM/ 三个/ 分类器/ 中/ 进行/ 选择/ ,/ 以/ 汲取/ 它们/ 的/ 优点/ 并/ 克服/ 其/ 缺点/ ./ 经/ 实际/ 验证/ ,/ 这种/ 方法/ 比/ 其它/ 的/ 加权/ 或/ 投票/ 方法/ 的/ 预测/ 效果/ 要/ 好/ ./ 2.3/ ./ 2/ 动态/ 选择/ 法/ 这类/ 方法/ [/ 47/ -/ 57/ ]/ 的/ 主要/ 特点/ 是/ 对/ 检验/ 集/ / ts/ 中/ 的/ 每个/ 个体/ 狓/ ,/ 从/ 已有/ 的/ 基/ 分类器/ C1/ ,/ C2/ ,/ …/ ,/ CT/ 中/ 动态/ 挑选/ 合适/ 的/ 一部分/ 对/ 其/ 进行/ 预测/ ,/ 每个/ 个体/ 选用/ 的/ 基/ 分类器/ 子集/ 一般/ 是/ 不同/ 的/ ./ 图/ 5/ 给出/ 了/ 动态/ 选择性/ 集成/ 学习/ 算法/ 的/ 主要/ 步骤/ ./ 输入/ :/ 验证/ 集/ / val/ ,/ 检验/ 数据/ 集/ / ts/ =/ {/ 狓/ i/ }/ Nts/ 输出/ :/ 检验/ 数据/ 的/ 类/ 标签/ 集合/ Φ/ =/ {/ yi/ }/ Nts/ 选择/ 过程/ :/ Fori/ =/ 1/ ,/ 2/ ,/ …/ ,/ Nts/ 针对/ 检验/ 样本/ 点/ 狓/ i/ ,/ 在/ 验证/ 集/ / val/ 上/ 寻找/ 它/ 的/ k/ 个/ 最近/ 邻/ 样本/ 点/ ;/ 根据/ 评测/ 标准/ / 评价/ 每个/ 基/ 分类器/ Ct/ (/ t/ =/ 1/ ,/ 2/ ,/ …/ ,/ T/ )/ 在/ k/ 个/ 最近/ 邻/ 样本/ 点上/ 的/ 性能/ ;/ 选取/ 一个/ 或/ 多个/ 较/ 好/ 的/ 基/ 分类器/ 对/ 狓/ i/ 进行/ 预测/ ,/ 得到/ 估计/ 的/ 类/ 标签/ yi/ ./ 类器/ 集合/ / =/ {/ C1/ ,/ C2/ ,/ …/ ,/ CT/ }/ ,/ 邻域/ 点/ 个数/ kEndForWoods/ 等/ 人/ [/ 47/ ]/ 提出/ 了/ 一种/ 基于/ 局部/ 精度/ 的/ 动态/ 选择/ 法/ DCS/ -/ LA/ (/ DynamicClassifierSelection/ -/ Page6LocalAccuracy/ )/ ,/ 通过/ 在/ 5/ 个/ 实际/ 数据/ 集/ 上将/ DCS/ -/ LA/ 的/ 分类/ 精度/ 和/ ROC/ (/ ReceiverOperatingCharacteristic/ )/ 曲线/ 下/ 的/ 面积/ 与/ 其它/ 几种/ 合并/ 准则/ (/ 行为/ 知识/ 空间/ BKS/ 、/ 基于/ 秩/ 的/ 方法/ 和/ 改进/ 的/ 秩/ 方法/ )/ 进行/ 比较/ ,/ 发现/ DCS/ -/ LA/ 总能/ 改进/ 具有/ 最高/ 预测/ 精度/ 的/ 单个/ 分类器/ 的/ 性能/ ./ Giacinto/ 和/ Roli/ [/ 48/ ]/ 根据/ 多/ 分类器/ 的/ 行为/ 提出/ 了/ DCS/ -/ MCB/ 算法/ (/ DynamicClassifierSelection/ -/ MultipleClassifierBehavior/ )/ ,/ 它/ 与/ 上述/ 的/ DCS/ -/ LA/ 算法/ 存在/ 两点/ 差别/ ./ 在/ DCS/ -/ MCB/ 中/ ,/ k/ 是/ 随着/ 检验/ 个体/ 的/ 不同/ 而/ 发生变化/ 的/ ./ 另外/ ,/ 只有/ 当/ 一个/ 基/ 分类器/ 的/ LA/ 明显/ 高于/ 其它/ 分类器/ 时/ ,/ DCS/ -/ MCB/ 才/ 选择/ 单个/ 分类器/ 对/ 狓/ 预测/ ;/ 否则/ ,/ 它/ 采用/ 简单/ 多数/ 投票/ 的/ 方式/ 构建/ 集成/ 分类器/ 来/ 对/ 狓/ 分类/ ./ 与/ DCS/ -/ LA/ 密切相关/ 的/ 还有/ Kuncheva/ [/ 50/ ]/ 提出/ 的/ DCS/ -/ DT/ 算法/ (/ DynamicClassifierSelection/ -/ DecisionTemplates/ )/ ,/ 该/ 方法/ 的/ 思想/ 与/ DCS/ -/ MCB/ 类似/ ,/ 但/ 它/ 采用/ 成对/ 的/ t/ 检验/ (/ pairedt/ -/ test/ )/ 方法/ 来/ 判别/ 一个/ 基/ 分类器/ 是否/ 在/ LA/ 方面/ 具有/ 显著/ 优势/ ,/ 如果/ 各个/ 基/ 分类器/ LA/ 之间/ 的/ 差别/ 不/ 显著/ ,/ 则/ 基于/ 决策表/ 矩阵/ (/ decisiontemplatematrix/ )/ 来/ 构建/ 集成/ 分类器/ 对/ 狓/ 预测/ ./ Didaci/ 和/ Giacinto/ [/ 51/ ]/ 发现/ DCS/ -/ LA/ 方法/ 的/ 性能/ 不仅/ 依赖于/ 邻域/ 形状/ 和/ 大小/ 的/ 选择/ ,/ 同时/ 还/ 与/ 训练/ 个体/ 的/ 局部/ 密度/ 分布/ (/ localdensitydistribution/ )/ 有关/ ./ 于是/ ,/ 他们/ 提出/ 了/ 一种/ 自/ 适应/ 选取/ 邻域/ 以/ 更好/ 估计/ LA/ 的/ 方法/ ,/ 试验/ 结果表明/ 通过/ 适当/ 调整/ 一些/ 额外/ 参数/ ,/ 可以/ 进一步/ 改进/ DCS/ -/ LA/ 的/ 预测/ 效果/ ./ Canuto/ 等/ 人/ 在/ 文献/ [/ 52/ ]/ 中较/ 全面/ 地/ 研究/ 了/ 异质/ 类型/ 基/ 分类器/ 的/ 数目/ T/ 的/ 变化/ 对/ 上述/ 几种/ DCS/ 方法/ (/ DCS/ -/ LA/ ,/ DCS/ -/ MCB/ 和/ DCS/ -/ DT/ )/ 性能/ 的/ 影响/ ,/ 并/ 得出结论/ :/ DCS/ -/ DT/ 在/ 多数/ 情况/ 下/ 效果/ 较/ 好/ ./ 此外/ ,/ Fan/ 等/ 人/ [/ 49/ ]/ 针对/ 集成/ 学习/ 在/ 对/ 损失/ 敏感/ (/ cost/ -/ sensitive/ )/ 的/ 大规模/ 数据/ 集上/ 的/ 应用/ ,/ 提出/ 了/ 动态/ 策略/ (/ dynamicscheduling/ )/ 与/ 基于/ 收益/ 的/ 贪婪/ 方法/ (/ benefit/ -/ basedgreedypruning/ )/ 相结合/ 的/ 集成/ 分类器/ 修剪/ 算法/ ,/ 该/ 方法/ 可以/ 在/ 不/ 损失/ 预测/ 精度/ 的/ 前提/ 下/ ,/ 剔除/ 约/ 90/ %/ 的/ 基/ 分类器/ ./ Ko/ 等/ 人/ [/ 53/ ]/ 基于/ Oracle/ 的/ 概念/ 提出/ 了/ 4/ 种/ 动态/ 选择/ 基/ 分类器/ 子集/ 的/ 方法/ (/ KNORA/ -/ ELIMINATE/ 、/ KNORA/ -/ UNION/ 、/ KNORA/ -/ ELIMINATE/ -/ W/ 、/ KNORA/ -/ UNION/ -/ W/ )/ ./ 它们/ 的/ 特点/ 是/ 对/ 检验/ 个体/ 狓/ ,/ 基于/ 验证/ 集/ / val/ 确定/ 狓/ 的/ k/ 个/ 邻域/ 点/ ,/ 挑选出/ 那些/ 对/ k/ 个/ 邻域/ 点/ 分类/ 正确/ 的/ 基/ 分类器/ ,/ 并/ 根据/ 简单/ 投票/ 或/ 加权/ 投票/ 的/ 方式/ 合并/ 被/ 选出/ 的/ 基/ 分类器/ 来/ 预测/ 狓/ 的/ 类/ 标签/ ./ DosSantos/ 等/ 人/ [/ 54/ ]/ 提出/ 了/ 优化/ 和/ 动态/ 选择/ 相结合/ 的/ 两/ 阶段/ 选择/ 法/ ,/ 目的/ 是/ 对/ 检验/ 集/ / tr/ 中/ 的/ 每个/ 个体/ 都/ 搜索/ 到/ 最优/ 的/ 基/ 分类器/ 子集/ ./ 优化/ 阶段/ 主要/ 是/ 为了/ 产生/ 具有/ 高精度/ 的/ 集成/ 分类器/ 总体/ ,/ 优化/ 目标/ 是/ 集成/ 分类器/ 的/ 分类/ 误差/ 和/ 多样性/ ;/ 而/ 动态/ 选择/ 阶段/ 则/ 为/ 每个/ 检验/ 个体/ ,/ 挑选出/ 具有/ 最高/ 置信度/ 的/ 集成/ 分类器/ ,/ 用于/ 度量/ 置信度/ 的/ 指标/ 可以/ 是/ 模糊性/ (/ ambiguity/ )/ 、/ 边缘/ (/ margin/ )/ 和/ 相对/ 于/ 最近/ 类/ 的/ 力量/ (/ strengthrelativetotheclosestclass/ )/ ./ Cavalin/ 等/ 人/ [/ 56/ ]/ 则/ 从/ 文献/ [/ 54/ ]/ 提出/ 的/ 方法/ DSA/ (/ DosSantosetal/ ’/ sApproach/ )/ 出发/ ,/ 通过/ 利用/ 验证/ 集/ / val/ 提供/ 的/ 上下文/ 信息/ (/ contextualinformation/ )/ 和/ 基/ 分类器/ 提供/ 的/ 证据/ (/ evidence/ )/ ,/ 并/ 引入/ 切换/ 策略/ (/ switchmechanism/ )/ 以/ 处理/ 类/ 得票/ 相等/ (/ tie/ -/ breaking/ )/ 和/ 大/ 边缘/ 决策/ (/ large/ -/ margindecision/ )/ 问题/ ,/ 提出/ 了/ 一种/ 新/ 的/ 动态/ 选择/ 分类器/ 集成/ 的/ 方法/ DSAc/ ./ 考虑/ 到/ 实际/ 数据/ 中/ 通常/ 含有/ 噪声/ ,/ Xiao/ 等/ 人/ [/ 57/ ]/ 在/ 对/ 噪声/ 具有/ 较强/ 免疫性/ 的/ 启发式/ 数据挖掘/ 方法/ GMDH/ (/ GroupMethodofDataHandling/ )/ 的/ 基础/ 上/ ,/ 根据/ 基/ 分类器/ 的/ 准确性/ 和/ 多样性/ 提出/ 了/ 动态/ 选择/ 集成/ 分类器/ 的/ GDES/ -/ AD/ 算法/ (/ GMDH/ -/ basedDynamicclassifierEnsembleSelectionaccordingtoAccuracyandDiversity/ )/ ./ 采用/ 误差/ 的/ 偏差/ -/ 方差/ 分解/ 对/ 集成/ 分类器/ 的/ 研究/ 结果表明/ ,/ GDES/ -/ AD/ 对/ 噪声/ 的/ 强/ 免疫能力/ 主要/ 在于/ 它/ 在/ 降低/ 分类/ 误差/ 的/ 偏差/ 方面/ 更具/ 优势/ ./ 此外/ ,/ Hernndez/ -/ Lobato/ 等/ 人/ [/ 55/ ]/ 在/ 贝叶斯/ 理论/ 框架/ 下/ ,/ 探讨/ 了/ 通过/ 将/ 一个/ 随机/ 学习/ 算法/ 应用/ 于/ 一个/ 给定/ 的/ 训练/ 集上/ 所/ 生成/ 的/ 独立/ 的/ 同质/ 类型/ 基/ 分类器/ 的/ 选择/ 问题/ ,/ 提出/ 了/ 基于/ 个体/ 的/ 修剪/ 方法/ (/ Instance/ -/ Basedpruning/ ,/ IB/ )/ ./ Hernndez/ -/ Lobato/ 等/ 人经/ 理论/ 分析/ ,/ 得出结论/ :/ 对/ 需要/ 预测/ 的/ 个体/ 狓/ ,/ 若/ 基于/ 逐一/ 添加/ 基/ 分类器/ 和/ 简单/ 多数/ 投票/ 的/ 合并/ 方式/ 来/ 构建/ 集成/ 分类器/ ,/ 当对/ 狓/ 预测/ 的/ 精度/ 达到/ 事先/ 给定/ 的/ 置信水平/ 且/ 对/ 狓/ 预测/ 的/ 类/ 标签/ 不再/ 发生变化/ 时/ ,/ 即可/ 停止/ 基/ 分类器/ 的/ 添加/ ./ 基于/ 一些/ 分类/ 问题/ 的/ 基准/ 数据/ 集/ ,/ Hernndez/ -/ Lobato/ 等/ 人/ 采用/ Bagging/ 和/ RandomForest/ 技术/ 生成/ 基/ 分类器/ ,/ 验证/ 了/ 理论/ 分析/ 的/ 正确性/ 和/ IB/ 算法/ 的/ 有效性/ ,/ 并/ 指出/ 需要/ 选择/ 的/ 基/ 分类器/ 个数/ S/ 是/ 与/ 要/ 预测/ 的/ 个体/ 狓/ 密切相关/ 的/ ./ 当基/ 分类器/ 对/ 狓/ 的/ 预测/ 结果/ 基本一致/ 时/ ,/ 只/ 需/ 少数几个/ 来/ 构建/ 集成/ 分类器/ 即可/ 达到/ 较/ 好/ 效果/ ;/ 对于/ 其它/ 情形/ ,/ 尤其/ 是/ 狓/ 接近/ 分类/ 边界/ 时/ ,/ 则/ 需较/ 多/ 的/ 基/ 分类器/ ./ Page72/ ./ 4/ 基于/ 优化/ 的/ 方法/ 这/ 类/ 方法/ [/ 14/ ,/ 58/ -/ 69/ ]/ 的/ 主要/ 思想/ 是/ 在/ 基/ 分类器/ 的/ 合并/ 过程/ 中/ 对/ 它们/ 赋予/ 权重/ ,/ 通过/ 稀疏/ 性/ 约束/ 或/ 设置/ 阈值/ ,/ 借助于/ 优化/ 算法/ 来/ 选择/ 最优/ 的/ 基/ 分类器/ 子集/ ./ 图/ 6/ 列出/ 了/ 基于/ 优化/ 的/ 选择性/ 集成/ 学习/ 算法/ 的/ 一般/ 步骤/ ./ 输入/ :/ 验证/ 集/ / val/ ,/ 基/ 分类器/ 集合/ / =/ {/ C1/ ,/ C2/ ,/ …/ ,/ CT/ }/ ,/ 评测/ 标准/ 输出/ :/ 选择/ 的/ 基/ 分类器/ 集合/ / =/ {/ C/ / 1/ ,/ C/ / 2/ ,/ …/ ,/ C/ / S/ }/ 选择/ 过程/ :/ 对/ 每个/ 基/ 分类器/ Ct/ (/ t/ =/ 1/ ,/ 2/ ,/ …/ ,/ T/ )/ 赋予/ 初始/ 权重/ ω/ t/ ;/ 根据/ 评测/ 标准/ / ,/ 选择/ 合适/ 的/ 目标/ 函数/ f/ (/ 如/ 遗传算法/ 中/ 的/ 适应/ 基于/ 验证/ 集/ / val/ ,/ 利用/ 算法/ / 优化/ 目标/ 函数/ f/ ,/ 得到/ 最优/ 权重/ 向量/ 选择/ 满足条件/ ω/ / >/ λ/ 的/ 元素/ 所/ 对应/ 的/ 基/ 分类器/ C/ / 1/ ,/ C/ / 2/ ,/ …/ ,/ C/ / S/ ./ 值/ 函数/ 等/ )/ ;/ ω/ / =/ (/ ω/ 1/ ,/ ω/ 2/ ,/ …/ ,/ ω/ T/ )/ ;/ / ,/ 优化/ 算法/ / ,/ 阈值/ λ/ 图/ 6/ 基于/ 优化/ 方法/ 的/ 选择性/ 集成/ 学习/ 算法/ 框架/ 在/ 基于/ 优化/ 方法/ 的/ 选择性/ 集成/ 学习/ 算法/ 中/ ,/ 文献/ [/ 14/ ,/ 58/ -/ 60/ ]/ 均/ 采用/ 遗传算法/ (/ GeneticAlgorithm/ ,/ GA/ )/ 来/ 优化/ 每个/ 基/ 分类器/ 被/ 赋予/ 的/ 权重/ ,/ 而/ 它们/ 之间/ 的/ 主要/ 区别/ 在于/ 采用/ 了/ 不同/ 的/ 遗传算法/ 编码方法/ (/ 二进制/ 或/ 实值/ )/ ./ 在/ 2002/ 年/ ,/ 周志华/ 等/ 人/ [/ 14/ ]/ 首次/ 从/ 理论/ 上/ 证明/ 了/ 选择性/ 集成/ 学习/ 的/ 有效性/ ,/ 并/ 提出/ 了/ 基于/ 实值/ 编码/ 遗传算法/ 的/ 选择性/ 集成/ 学习/ 方法/ GASEN/ (/ GeneticAlgorithmbasedSelectiveENsemble/ )/ ./ 在/ 试验/ 过程/ 中/ ,/ 他们/ 将/ 算法/ 中/ 的/ 阈值/ λ/ 设定/ 为/ 0.05/ ,/ 研究/ 了/ 上述/ 策略/ 修剪/ Bagging/ 和/ Boosting/ 神经网络/ 集成/ 的/ 效果/ ,/ 并/ 得出结论/ :/ 在/ 所/ 探讨/ 的/ 数据/ 集上/ ,/ GASEN/ 方法/ 都/ 可以/ 用/ 较/ 少/ 的/ 神经网络/ 得到/ 更好/ 的/ 泛化/ 效果/ ./ 同时/ ,/ 他们/ 还/ 指出/ 通过/ 调整/ 遗传算法/ 中/ 的/ 适应/ 值/ 函数/ 、/ 编码方法/ 、/ 遗传/ 算子/ 以及/ 阈值/ λ/ ,/ GASEN/ 算法/ 的/ 性能/ 都/ 可以/ 得到/ 进一步/ 改进/ ./ 王丽丽/ 和/ 苏德富/ [/ 61/ ]/ 针对/ 已有/ 的/ 选择性/ 集成/ 学习/ 方法/ 计算/ 复杂性/ 高/ 、/ 效率/ 低/ 的/ 特点/ ,/ 提出/ 将/ 具有/ 快速/ 收敛/ 性质/ 的/ 群体/ 智能算法/ 用于/ 多/ 分类器/ 的/ 选择/ ./ Zhang/ 等/ 人/ [/ 62/ ]/ 将/ 多/ 分类器/ 的/ 选择/ 问题/ 看成/ 是/ 二次/ 整数/ 规划/ 问题/ (/ quadraticintegerprogramming/ )/ ,/ 并/ 给出/ 了/ 一种/ 半定/ 规划/ 方法/ SDP/ (/ Semi/ -/ DefinitePro/ -/ gramming/ )/ ,/ 试验/ 结果表明/ 该/ 方法/ 可以/ 比/ 其它/ 启发式/ 方法/ 更好/ 地/ 逼近/ 基/ 分类器/ 的/ 最优/ 子集/ ./ Chen/ 等/ 人/ [/ 63/ ]/ 则/ 从/ 概率/ 推理/ 的/ 角度/ 出发/ 提出/ 了/ 一种/ 新/ 的/ 选择性/ 集成/ 学习/ 算法/ ,/ 为了/ 使/ 每个/ 基/ 分类器/ 的/ 权重/ 非/ 负且/ 尽量/ 稀疏/ (/ 即/ 多数/ 基/ 分类器/ 得到/ 的/ 权重/ 为/ 0/ )/ ,/ 算法/ 采用/ 左/ 截断/ 的/ 高斯分布/ (/ left/ -/ truncatedGaussiandistribution/ )/ 对/ 每个/ 基/ 分类器/ 的/ 初始/ 权重/ 赋予/ 先验/ 知识/ ,/ 并/ 基于/ 期望/ 扩散/ (/ ExpectationPropagation/ ,/ EP/ )/ 算法/ 来/ 估计/ 权重/ 的/ 后验/ 分布/ ./ 该/ 算法/ 的/ 优点/ 是/ 在/ EP/ 算法/ 的/ 训练/ 过程/ 中/ ,/ 不/ 需要/ 额外/ 的/ 计算/ 即可/ 获得/ LOO/ (/ Leave/ -/ One/ -/ Out/ )/ 误差/ ,/ 结合/ 贝叶斯/ 证据/ (/ Bayesianevidence/ )/ 也/ 可以/ 实现/ 模型/ 选择/ ./ 为了/ 避免/ 标准/ 的/ 线性/ 最小/ 二乘/ 回归/ 合并/ 准则/ (/ standardlinearleastsquaresregression/ )/ 出现/ 过/ 拟合/ 现象/ ,/ Reid/ 和/ Grudic/ [/ 66/ ]/ 提出/ 将/ 基于/ 层叠/ 泛化/ 策略/ (/ stackedgeneralization/ )/ 的/ 正则/ 化/ 线性/ 模型/ 用于/ 基/ 分类器/ 的/ 合并/ ,/ 模型/ 中/ 的/ 未知/ 参数/ 可以/ 用岭/ 回归/ (/ ridgeregression/ )/ 、/ Lasso/ 回归/ (/ Lassoregression/ )/ 和/ 弹性/ 网/ 回归/ (/ elasticnetregression/ )/ 等/ 方法/ 估计/ 得到/ ./ Li/ 和/ Zhou/ [/ 65/ ]/ 在/ 正则/ 化/ 的/ 理论/ 框架/ 下/ ,/ 基于/ Hinge/ 损失/ 函数/ (/ 对于/ Φ/ =/ {/ -/ 1/ ,/ +/ 1/ }/ 的/ 二/ 分类/ 问题/ ,/ 其/ 定义/ 为/ l/ (/ yi/ ,/ C/ (/ 狓/ i/ )/ )/ =/ max/ (/ 0/ ,/ 1/ -/ yiC/ (/ 狓/ i/ )/ )/ )/ 和/ 图/ 的/ 拉普拉斯/ 正则/ 子/ (/ graphLaplacianregularizer/ )/ 将基/ 分类器/ 的/ 选择/ 问题/ 归结为/ 具有/ 稀疏/ 解/ 的/ 二次/ 规划/ 问题/ ,/ 并/ 通过/ 相关/ 的/ 优化/ 算法/ (/ 文中/ 用/ 的/ 是/ MOSEK/ 软件/ )/ 进行/ 求解/ ./ 算法/ 除了/ 能/ 用/ 少数/ 的/ 基/ 学习机/ 达到/ 较强/ 的/ 泛化/ 能力/ 之外/ ,/ 还/ 可以/ 充分利用/ 无/ 标签/ 的/ 数据/ (/ unlabeleddata/ )/ 来/ 进一步提高/ 分类/ 系统/ 的/ 性能/ ./ Zhang/ 和/ Zhou/ [/ 69/ ]/ 也/ 基于/ 正则/ 化/ 理论/ ,/ 采用/ Hinge/ 损失/ 函数/ 和/ / 1/ 正则/ 项/ 提出/ 了/ 一种/ 基于/ 线性规划/ 的/ 方法/ ,/ 优化/ 的/ 目标/ 是/ 最小化/ 集成/ 分类器/ 的/ 训练/ 误差/ 同时/ 控制权/ 向量/ ,/ 以/ 使得/ 最终/ 得到/ 的/ 权/ 向量/ 尽量/ 稀疏/ ./ DosSantos/ 等/ 人/ [/ 64/ ]/ 针对/ 决策树/ 和/ K/ -/ NN/ (/ KNearestNeighbors/ )/ 作为/ 基/ 学习/ 算法/ ,/ 采用/ Bagging/ 和/ 随机/ 子/ 空间/ 技术/ 训练/ 的/ 基/ 分类器/ ,/ 提出/ 以/ 分类/ 误差/ 和/ 多样性/ 为/ 优化/ 目标/ ,/ 并/ 基于/ 单/ 目标/ 和/ 多/ 目标/ 的/ 遗传算法/ (/ multi/ -/ objectivegeneticalgorithm/ )/ 进行/ 优化/ 求解/ ./ 试验/ 结果表明/ ,/ 多/ 目标/ 优化/ 的/ 遗传算法/ 除了/ 能/ 找到/ 近似/ 最优/ 的/ 基/ 分类器/ 子集/ 之外/ ,/ 还/ 可以/ 控制/ 过/ 拟合/ 现象/ 的/ 产生/ ./ 此外/ ,/ 文献/ [/ 64/ ]/ 中以/ 多样性/ 为单/ 目标/ 优化/ 函数/ 的/ 研究/ 还/ 有助于/ 探索/ 基/ 分类器/ 之间/ 的/ 多样性/ 与/ 集成/ 分类器/ 性能/ 之间/ 的/ 关系/ ./ 杨晓霜/ 和/ 汪/ 源源/ [/ 68/ ]/ 则/ 提出/ 了/ 一种/ 基于/ Moore/ -/ Penrose/ 逆/ 矩阵/ 的/ 新型/ 选择性/ 集成/ 学习/ 算法/ PISEN/ (/ Pseudo/ -/ InversematrixbasedSelectiveENsemble/ )/ ,/ 它/ 基于/ 矩阵/ 的/ 伪/ 逆/ 理论/ 对/ 每个/ 基/ 学习机/ 的/ 权值/ 进行/ 优化/ ,/ 并/ 通过/ 预先/ 设定/ 的/ 阈值/ 来/ 选择/ 最后/ 的/ 基/ 学习机/ 子集/ ,/ 算法/ 的/ 优点/ 是/ 简单/ 、/ 易于/ 实现/ 且/ 效率/ 较/ 高/ ./ 基于/ 8/ 个/ UCI/ 实际/ 数据/ 集/ ,/ 作者/ 将/ PISEN/ 算法/ (/ 阈值/ 设为/ 0.1/ )/ 与/ 文献/ [/ 14/ ]/ 提出/ 的/ GASEN/ 算法/ (/ 采用/ 该文/ 中/ 的/ 参数设置/ )/ 进行/ 了/ 比较/ ,/ 发现/ 二者/ 的/ 泛化/ 误/ Page8/ 差/ 相当/ ,/ 但/ 前者/ 的/ 计算/ 效率/ 要/ 远远/ 高于/ 后者/ ./ 此外/ ,/ 王磊/ [/ 67/ ]/ 则/ 基于/ 约束/ 投影/ 矩阵/ 法/ 首先/ 训练/ 多个/ SVM/ ,/ 然后/ 采用/ 遗传/ 优化/ 和/ 最小化/ 偏离/ 度/ 误差/ 的/ 技术/ 来/ 对/ SVM/ 进行/ 组合/ ./ 2.5/ 其它/ 方法/ 除了/ 上面/ 提到/ 的/ 几类/ 选择性/ 集成/ 学习/ 算法/ ,/ 还有/ 一些/ 算法/ 不能/ 归入/ 其中/ ,/ 我们/ 在/ 此/ 对/ 其作/ 一/ 简单/ 介绍/ ./ Prodromidis/ 和/ Stolfo/ [/ 70/ ]/ 基于/ 基/ 分类器/ 的/ 预测/ 结果/ 构建/ 一个/ 决策树/ ,/ 并/ 对/ 树/ 进行/ 修剪/ ,/ 如果/ 某个/ 基/ 分类器/ 的/ 预测/ 结果/ 不/ 在/ 被/ 修剪/ 后/ 的/ 树/ 中/ ,/ 则/ 将/ 它/ 从/ 构建/ 集成/ 分类器/ 的/ 过程/ 中/ 剔除/ ./ Tsoumakas/ 等/ 人/ [/ 71/ ]/ 建议/ 采用/ 多重/ 统计/ 检验/ 的/ 方法/ (/ 如/ Turkey/ 检验/ 、/ Hsu/ 检验/ 、/ Scott/ 和/ Knott/ 检验/ 等/ )/ 来/ 选择/ 最优/ 的/ 基/ 分类器/ 集合/ ,/ 使得/ 其中/ 每个/ 基/ 分类器/ 的/ 预测/ 精度/ 基本/ 相当/ ,/ 且/ 集合/ 中/ 至少/ 有/ 一个/ 基/ 分类器/ 的/ 预测/ 性能/ 显著/ 优于/ 未/ 被/ 选择/ 的/ 任何/ 一个/ 基/ 分类器/ ./ Partalas/ 等/ 人/ [/ 72/ ]/ 则/ 首次/ 将/ 增强/ 学习/ (/ reinforcementlearning/ )/ 的/ 概念/ 引入/ 选择性/ 集成/ 学习/ 中/ ,/ 提出/ 了/ 一种/ 新/ 的/ 有效/ 算法/ ./ 盛高斌/ [/ 73/ ]/ 针对/ 小/ 数据量/ 聚类/ 的/ 有/ 标记/ 样本/ 问题/ ,/ 提出/ 了/ 一种/ 基于/ 半/ 监督/ 回归/ 的/ 选择性/ 集成/ 学习/ 算法/ SSRES/ (/ Semi/ -/ SupervisedRegressionEn/ -/ sembleSelection/ )/ ./ Zhang/ 和/ Chau/ [/ 74/ ]/ 提出/ 了/ 基于/ 多子/ 群/ 粒子/ 群/ 优化/ 算法/ (/ Multi/ -/ Sub/ -/ SwarmParticleSwarmOptimi/ -/ zation/ ,/ MSSPSO/ )/ 的/ 多层次/ 修剪/ 模型/ ,/ 在/ 每/ 一层/ 修剪/ 过程/ 中/ ,/ 模型/ 假定/ 每个/ 基/ 分类器/ 都/ 产生/ 一个/ 明智/ 的/ 输出/ (/ oracleoutput/ )/ ,/ 并/ 把/ 基/ 分类器/ 的/ 选择/ 看成/ 是/ 多/ 模态/ 的/ 优化/ 问题/ ,/ 基于/ 前/ 一层/ 基/ 分类器/ 的/ 输出/ 采用/ MSSPSO/ 算法/ 进行/ 求解/ ,/ 最终/ 选择/ 出/ 包含/ 重要/ 信息/ 的/ 基/ 分类器/ ./ Soto/ 等/ 人/ [/ 75/ ]/ 针对/ 二/ 分类/ 问题/ ,/ 将/ 前述/ 的/ 对/ 基/ 分类器/ 进行/ 排序/ 的/ 方法/ 与/ 基于/ 个体/ (/ Instance/ -/ Based/ ,/ IB/ )/ 的/ 动态/ 修剪/ 技术相结合/ ,/ 提出/ 了/ 一种/ 两层/ 的/ 修剪/ 算法/ ./ 算法/ 首先/ 采用/ 排序/ (/ 如/ 基于/ Boosting/ 的/ 主要/ 思想/ [/ 26/ ]/ )/ 的/ 方法/ 选出/ 约/ 20/ %/ 的/ 基/ 分类器/ 并/ 设定/ 置信/ 值/ α/ ,/ 在/ 对/ 某个/ 个体/ 狓/ 预测/ 时/ ,/ 通过/ 简单/ 多数/ 投票/ 的/ 方式/ 逐一/ 合并/ 选出/ 的/ 基/ 分类器/ ,/ 直至/ 集成/ 分类器/ 预测/ 的/ 某个/ 类/ 的/ 概率/ 大于/ α/ ./ 该/ 算法/ 的/ 优点/ 是/ 能/ 明显提高/ 集成/ 分类器/ 的/ 预测/ 精度/ 、/ 降低/ 存储/ 需求/ (/ 只/ 需/ 存储/ 约/ 20/ %/ 的/ 基/ 学习机/ )/ 、/ 加快/ 预测/ 过程/ (/ 基/ 学习机/ 的/ 数目/ 减少/ 且/ IB/ 修剪/ 技术/ 加快/ 了/ 对/ 每个/ 个体/ 的/ 预测/ )/ ./ 3/ 基于/ 回归/ 问题/ 的/ 选择性/ 集成/ 学习/ 算法/ 解决/ 回归/ 问题/ 的/ 多数/ 选择性/ 集成/ 学习/ 算法/ 都/ 是/ 经过/ 对/ 用于/ 分类/ 问题/ 的/ 相关/ 算法/ 进行/ 推广/ 得到/ 的/ ,/ 如/ 文献/ [/ 3/ ,/ 14/ ,/ 29/ ,/ 76/ -/ 81/ ]/ 等/ ./ 若/ 将/ 这些/ 算法/ 按照/ 其/ 特点/ 进行/ 分类/ ,/ 则/ 也/ 可以/ 类似/ 地/ 分为/ 基于/ 聚类/ 、/ 排序/ 、/ 优化/ 和/ 选择/ 的/ 方法/ ./ 其中/ ,/ Partalas/ 等/ 人/ [/ 3/ ]/ 针对/ 选择性/ 集成/ 学习/ 在/ 水/ 质量/ 预测/ 问题/ 中/ 的/ 应用/ ,/ 提出/ 基于/ 学习机/ 的/ 均/ 方/ 误差/ 根/ (/ root/ -/ mean/ -/ squared/ -/ error/ )/ 采用/ 前向/ 选择/ (/ forwardselection/ )/ 和/ 后/ 向/ 删除/ (/ back/ -/ wardelimination/ )/ 的/ 策略/ 贪婪/ 地/ 搜索/ 最优/ 的/ 基/ 学习机/ 子集/ ./ 周志华/ 等/ 人/ [/ 14/ ,/ 78/ ]/ 建议/ 采用/ 实值/ 编码/ 的/ 遗传算法/ 和/ 设置/ 阈值/ 的/ 方法/ 来/ 对/ 基/ 学习机/ 进行/ 选择/ ./ Hernndez/ -/ Lobato/ 等/ 人/ [/ 77/ ]/ 基于/ 基/ 学习机/ 之间/ 的/ 互补性/ 对/ 它们/ 进行/ 排序/ ,/ 并/ 采用/ 贪婪/ 算法/ 从中/ 选取/ 约/ 20/ %/ 的/ 基/ 学习机/ ./ 与/ 分类/ 问题/ 相比/ ,/ 对/ 基于/ 回归/ 问题/ 的/ 选择性/ 集成/ 学习/ 算法/ 进行/ 的/ 研究/ 相对/ 较/ 少/ ,/ 究其原因/ ,/ 大概/ 是/ 由/ 以下/ 因素/ 造成/ 的/ ./ 选择性/ 集成/ 学习/ 的/ 目的/ 是/ 在/ 不/ 降低/ 甚至/ 进一步提高/ 原/ 集成/ 学习机/ 预测/ 精度/ 的/ 前提/ 下/ ,/ 尽可能减少/ 参与/ 集成/ 学习/ 的/ 基/ 学习机/ 的/ 数目/ ,/ 以/ 大大降低/ 其/ 对/ 存储空间/ 的/ 需求/ 并/ 加快/ 预测/ 速度/ ./ 然而/ ,/ 在/ 回归/ 问题/ 中/ ,/ 采用/ 某种/ 策略/ 对基/ 学习机/ 进行/ 选择/ 之后/ ,/ 被/ 剔除/ 的/ 基/ 学习机/ 往往/ 较/ 少/ ,/ 而/ 在/ 预测/ 精度/ 的/ 改进/ 方面/ 效果/ 也/ 不/ 太/ 明显/ ./ 4/ 总结/ 与/ 展望/ 本文/ 对/ 机器/ 学习/ 领域/ 中/ 一些/ 具有/ 代表性/ 的/ 选择性/ 集成/ 学习/ 算法/ 作/ 了/ 一个/ 比较/ 全面/ 的/ 综述/ ,/ 并/ 分析/ 了/ 几类/ 方法/ 的/ 主要/ 特点/ ./ 选择性/ 集成/ 学习/ 的/ 提出/ 极大/ 地/ 丰富/ 了/ 集成/ 学习/ 的/ 相关/ 理论/ ,/ 并/ 为/ 其它/ 相关/ 领域/ 的/ 研究/ 提供/ 了/ 新/ 技术/ 和/ 新思路/ ,/ 研究/ 前景/ 广阔/ ./ 近年来/ 虽然/ 仍/ 有/ 很多/ 研究/ 人员/ 致力于/ 该/ 方面/ 的/ 研究/ ,/ 发表/ 了/ 很多/ 研究成果/ ,/ 但/ 目前/ 的/ 方法/ 多/ 是/ 针对/ 某个/ 具体任务/ 而言/ 的/ ,/ 其中/ 尚有/ 一些/ 问题/ 需要/ 在/ 未来/ 研究/ 中/ 得到/ 突破/ :/ (/ 1/ )/ 若干/ 关键/ 参数/ 的/ 确定/ ./ 例如/ ,/ 在/ 基于/ 聚类/ 技术/ 、/ 排序/ 和/ 选择/ 的/ 方法/ 中/ ,/ 如何/ 确定/ 最终/ 保留/ 的/ 基/ 学习机/ 的/ 数目/ S/ ?/ 在/ 基于/ 优化/ 的/ 方法/ 中/ ,/ 如何/ 设置/ 权重/ 的/ 阈值/ 以/ 剔除/ 某些/ 效果/ 较差/ 的/ 基/ 学习机/ ?/ 针对/ 这些/ 参数/ ,/ 目前/ 采用/ 的/ 大多/ 是/ 启发式/ 的/ 方法/ ./ 如果/ 选取/ 不/ 合适/ ,/ 则/ 会/ 大大/ 影响/ 预测/ 效果/ ./ 如何/ 根据/ 具体/ 问题/ ,/ 自/ 适应/ 地/ 选取/ 这些/ 关键/ 参数/ 将/ 是/ 一个/ 值得/ 研究/ 的/ 内容/ ./ (/ 2/ )/ 选择/ 基/ 学习机/ 的/ 衡量/ 指标/ 的/ 选定/ ./ 基/ 学习机/ 的/ 准确性/ 和/ 它们/ 之间/ 的/ 多样性/ 在/ 集成/ 学习机/ 的/ 构建/ 过程/ 中起/ 着/ 至关重要/ 的/ 作用/ ,/ 只有/ 当/ 两者/ 达到/ 一/ Page9/ 个/ 较/ 好/ 的/ 折中/ ,/ 集成/ 学习机/ 才能/ 具有/ 较强/ 的/ 泛化/ 能力/ ./ 然而/ ,/ 多样性/ 在/ 实际/ 中/ 难以/ 衡量/ ,/ 且/ 多样性/ 和/ 准确性/ 与/ 集成/ 学习机/ 预测/ 性能/ 之间/ 的/ 有效/ 联系/ 也/ 较/ 难/ 建立/ ./ 在/ 选择性/ 集成/ 学习/ 算法/ 的/ 设计/ 中/ ,/ 如何/ 选取/ 合适/ 的/ 准则/ 或/ 度量/ 标准/ 将/ 准确性/ 和/ 多样性/ 因素/ 充分考虑/ 在内/ ,/ 也/ 是/ 一个/ 需要/ 解决/ 的/ 关键问题/ ./ (/ 3/ )/ 选择性/ 集成/ 学习/ 算法/ 的/ 应用/ 研究/ ./ 目前/ ,/ 一些/ 选择性/ 集成/ 学习/ 方法/ 已经/ 应用/ 在/ 疾病诊断/ 、/ 人脸识别/ 、/ 图像/ 挖掘/ 等/ 方面/ ./ 研究/ 该类/ 方法/ 更/ 广泛/ 的/ 实际/ 应用/ 以及/ 现有/ 的/ 机器/ 学习/ 方法/ 在/ 选择性/ 集成/ 学习/ 中/ 的/ 应用/ 都/ 将/ 有/ 十分/ 重要/ 的/ 意义/ ./ 

