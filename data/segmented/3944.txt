Page1/ 使用/ 异构/ 互联网/ 图像/ 组/ 的/ 视频/ 标注/ 王晗/ 吴心/ 筱/ 贾云得/ (/ 北京理工大学/ 计算机/ 学院/ 智能/ 信息技术/ 北京市/ 重点/ 实验室/ 北京/ 100081/ )/ 摘要/ 标注/ 用户/ 视频/ 中/ 的/ 事件/ 是/ 一项/ 极具/ 挑战性/ 的/ 工作/ ./ 目前/ 的/ 研究/ 主要/ 关注/ 如何/ 从/ 大量/ 的/ 已/ 标注/ 视频/ 中/ 获取/ 视频/ 相关/ 概念/ ,/ 并/ 用来/ 标注/ 未知/ 的/ 用户/ 视频/ ./ 现实/ 场景/ 下/ 的/ 视频/ 具有/ 复杂性/ 和/ 多样性/ 的/ 特点/ ,/ 建模/ 需要/ 收集/ 大量/ 已/ 标注/ 的/ 视频/ 训练样本/ ,/ 这个/ 过程/ 非常/ 费时费力/ ./ 为了/ 缓解/ 这一/ 问题/ ,/ 作者/ 利用/ 大量/ 互联网/ 图像/ 来/ 建立/ 模型/ ,/ 这些/ 图像/ 数据/ 涵盖/ 了/ 各种/ 环境/ 下/ 的/ 各种/ 事件/ ./ 然而/ ,/ 从/ 互联网/ 上/ 得到/ 的/ 知识/ 变化/ 多样/ 且/ 有/ 噪声/ ,/ 如果/ 不/ 加/ 选择/ 而/ 盲目/ 进行/ 知识/ 迁移/ ,/ 反而/ 会/ 影响/ 视频/ 标注/ 的/ 效果/ ./ 因此/ ,/ 作者/ 提出/ 了/ 一种/ 联合/ 组/ 权重/ 学习/ 框架/ 来/ 权衡/ 互联网/ 上/ 不同/ 但/ 相关/ 的/ 图像/ 组/ ,/ 并用/ 这些/ 知识/ 建立/ 视频/ 标注/ 模型/ ./ 在/ 该/ 框架/ 下/ ,/ 作者/ 采用/ 联合/ 优化/ 的/ 方法/ 来/ 获得/ 不同/ 图像/ 组/ 的/ 权重/ ,/ 每/ 一个/ 权重/ 值/ 表示/ 了/ 相应/ 的/ 图像/ 组在/ 知识/ 迁移/ 中所起/ 的/ 作用/ ./ 为了/ 解决/ 视频/ 与/ 图像/ 特征/ 的/ 异构/ 问题/ ,/ 作者/ 建立/ 了/ 一个/ 共同/ 特征/ 子/ 空间/ 来/ 连接/ 视频/ 和/ 图像/ 这/ 两个/ 特征/ 空间/ ./ 两个/ 视频/ 数据库/ 上/ 的/ 实验/ 结果表明/ 了/ 文中/ 方法/ 的/ 有效性/ ./ 关键词/ 知识/ 迁移/ ;/ 视频/ 标注/ ;/ 互联网/ 图像/ 搜索引擎/ ;/ 共同/ 特征/ 子/ 空间/ 1/ 引言/ 移动/ 设备/ 和/ 数码设备/ 的/ 广泛/ 普及/ 使得/ 用户/ 可以/ 随时随地/ 拍摄/ 视频/ 图像/ ,/ 形成/ 海量/ 数据/ ./ 对/ 视频/ 的/ 人工/ 标注/ 常常/ 出现/ 缺少/ 标注/ 或者/ 标注/ 过于/ 主观/ 的/ 情况/ ,/ 导致/ 传统/ 的/ 基于/ 文本/ 的/ 视频/ 检索/ 方法/ 越来越/ 不适/ 用于/ 海量/ 视频/ 数据/ 的/ 检索/ [/ 1/ -/ 2/ ]/ ./ 另外/ ,/ 由于/ 现实/ 世界/ 中/ 的/ 视频/ 往往/ 是/ 非常复杂/ 的/ ,/ 存在/ 剧烈/ 的/ 摄像机/ 运动/ 以及/ 很多/ 的/ 类/ 内/ 变化/ ,/ 给/ 海量/ 视频/ 检索/ 带来/ 了/ 困难/ ./ 然而/ ,/ 收集/ 涵盖/ 各种/ 情况/ 下/ 足够/ 多/ 的/ 视频/ 又/ 费时费力/ ,/ 因此/ 我们/ 试图/ 从/ 日渐/ 成熟/ 的/ 互联网/ 图像/ 搜索引擎/ 中/ 获得/ 大量/ 的/ 图像/ 知识/ ,/ 并/ 把/ 这些/ 知识/ 迁移/ 到/ 视频/ 中/ ./ 实际上/ 从/ 互联网/ 上/ 获得/ 的/ 图像/ 比/ 实验室/ 生成/ 的/ 数据/ 更/ 具有/ 多样性/ ,/ 更/ 有利于/ 完成/ 现实/ 世界/ 的/ 任务/ ./ 为了/ 从/ 互联网/ 上/ 获得/ 所/ 需/ 知识/ ,/ 我们/ 使用/ 与/ 事件/ 相关/ 的/ 关键字/ 在/ 互联网/ 图像/ 搜索引擎/ 上/ 收集/ 图片/ ./ 现实/ 世界/ 中/ 的/ 视频/ 具有/ 复杂性/ 和/ 多样性/ 的/ 特点/ ,/ 单一/ 的/ 检索/ 词/ 并/ 不能/ 很/ 好/ 地/ 描述/ 复杂/ 场景/ 下/ 的/ 视频/ ./ 例如/ ,/ 可以/ 由/ 关键词/ “/ 篮球/ ”/ 联想/ 到/ “/ 篮球赛/ ”/ 、/ “/ NBA/ ”/ 、/ “/ Kobe/ ”/ 等等/ ./ 在/ 本文/ 中/ ,/ 为了/ 搜集/ 到/ 尽可能/ 全面/ 的/ 事件/ 知识/ ,/ 使用/ 了/ 联想/ 关键词/ 对/ 图像/ 进行/ 检索/ ./ 从/ 互联网/ 上/ 为/ 每/ 一个/ 关键词/ 收集/ 一组/ 图片/ ,/ 每/ 一个/ 事件/ 都/ 对应/ 了/ 多组/ 从/ 互联网/ 检索/ 来/ 的/ 图片/ ./ 我们/ 将/ 互联网/ 上/ 获得/ 的/ 已/ 标注/ 图像/ 数据/ 称为/ 源域/ (/ sourcedomain/ )/ ,/ 将/ 未/ 标注/ 的/ 用户/ 视频/ 数据/ 称为/ 目标/ 域/ (/ targetdomain/ )/ ./ 尽管/ 从/ 互联网/ 很/ 容易/ 获得/ 大量/ 的/ 标记/ 数据/ ,/ 然而/ 用户/ 向/ 互联网/ 上传/ 图像/ 时/ 标注/ 的/ 随意性/ 和/ 主观性/ ,/ 使得/ 与/ 所/ 检索/ 事件/ 相关性/ 较/ 小/ 的/ 噪声/ 图像/ 大量/ 存在/ ./ 在/ 这样/ 的/ 情况/ 下/ ,/ 使用/ 蛮力/ 迁移/ (/ brute/ -/ forcetransfer/ )/ 很/ 可能/ 会/ 降低/ 视频分类/ 器/ 的/ 分类/ 效果/ ,/ 这样/ 的/ 知识/ 迁移/ 称为/ 负/ 迁移/ (/ negativetransfer/ )/ ./ 由此可见/ ,/ 如何/ 总结/ 图像/ 知识/ 并/ 选择/ 最/ 有效/ 最/ 相关/ 的/ 那/ 部分/ 数据/ 来/ 对/ 未知/ 视频/ 进行/ 标注/ 显得/ 尤为重要/ ./ 为/ 避免/ 负/ 迁移/ ,/ 我们/ 提出/ 了/ 一种/ 联合/ 分组/ 权重/ 学习/ 方法/ ,/ 即/ 把/ 互联网/ 上/ 获取/ 的/ 图像/ 集/ (/ 源域/ )/ 按照/ 联想/ 词/ 的/ 不同/ 进行/ 分组/ ,/ 并/ 根据/ 这些/ 源域/ 的/ 分组/ 数据/ 与/ 视频/ 数据/ (/ 目标/ 域/ )/ 的/ 相关性/ ,/ 给/ 不同/ 组/ 赋予/ 不同/ 的/ 权重/ ./ 通过/ 为/ 每/ 一类/ 事件/ 的/ 分组/ ,/ 自动/ 学习/ 一个/ 相关性/ 权重/ 来/ 提高/ 目标/ 域/ 从源域/ 中/ 获取/ 有效/ 知识/ 的/ 概率/ ./ 在/ 知识/ 从/ 图像/ 迁移/ 到/ 视频/ 的/ 过程/ 中/ ,/ 如何/ 解决/ 图像/ 与/ 视频/ 特征/ 空间/ 的/ 异构/ 问题/ 是/ 知识/ 迁移/ 的/ 又/ 一个/ 难点/ ./ 这里/ 需要/ 设计/ 一个/ “/ 翻译器/ ”/ ,/ 来/ 建立/ 两个/ 异构/ 特征/ 空间/ 之间/ 的/ 联系/ ./ 我们/ 引入/ 典型/ 相关性/ 分析/ (/ CanonicalCorrelationAnalysis/ ,/ CCA/ )/ 方法/ 来/ 帮助/ 知识/ 从/ 图像/ 迁移/ 到/ 视频/ ./ 使用/ CCA/ ,/ 源域/ 的/ 图像/ 特征/ 和/ 目标/ 域/ 的/ 视频/ 特征/ 通过/ 两个/ 投影/ 矩阵/ 同时/ 被/ 映射/ 到/ 一个/ 共同/ 的/ 特征/ 子/ 空间/ ./ 借助/ 这个/ 共同/ 子/ 空间/ ,/ 从源域/ 上学/ 到/ 的/ 分类器/ 可以/ 直接/ 分类/ 目标/ 域/ 的/ 数据/ ./ 图/ 1/ 所示/ 是/ 我们/ 提出/ 的/ 使用/ 互联网/ 图像/ 知识/ 来/ 标注/ 用户/ 视频/ 的/ 迁移/ 学习/ 框架/ ./ 2/ 相关/ 工作/ 迁移/ 学习/ 在/ 语音/ 识别/ [/ 3/ ]/ 、/ 文本/ 分类/ [/ 4/ ]/ 和/ 图像/ 标注/ [/ 5/ ]/ 等/ 方面/ 有/ 广泛/ 的/ 应用/ ./ 通过/ 知识/ 迁移/ ,/ 人们/ 可以/ 使用/ 先验/ 知识/ 来/ 更/ 快/ 更/ 有效/ 地/ 解决/ 新/ 问题/ ./ 近年来/ ,/ 知识/ 迁移/ 在/ 多媒体/ 内容分析/ 领域/ 引起/ 了/ 学者/ 的/ 广泛/ 重视/ [/ 6/ -/ 9/ ]/ ./ Yang/ 等/ 人/ [/ 10/ ]/ 使用/ 自/ 适应/ SVM/ (/ A/ -/ SVM/ )/ 方法/ 来/ 提高/ 对/ 视频/ 事件/ 的/ 检测/ 效果/ ,/ 新/ 的/ 分类器/ 是从/ 现有/ 的/ 源域/ SVM/ 分类器/ 上/ 自/ 适应/ 学习/ 得来/ 的/ ./ Duan/ 等/ 人/ [/ 11/ ]/ 通过/ 最小化/ 正则/ 项/ 误差/ ,/ 同时/ 优化/ 源域/ 分类器/ 的/ 线性组合/ 得到/ 目标/ 域/ 分类器/ ./ 目前/ 有关/ 如何/ 利用/ 互联网/ 中/ 的/ 图像/ 资源/ 来/ 标注/ 视频/ 的/ 工作/ 较/ Page3/ 少/ ./ Ikizler/ -/ Cinbis/ 等/ 人/ [/ 12/ ]/ 利用/ 互联网/ 图像/ 迁移/ 得到/ 行为/ 识别/ 模型/ ,/ 但/ 他们/ 的/ 工作/ 没有/ 利用/ 视频/ 的/ 运动/ 信息/ 来/ 指导/ 视频/ 标注/ ,/ 对于/ 某些/ 动作/ 的/ 识别率/ 较/ 低/ ,/ 例如/ :/ “/ 站/ 起/ ”/ 、/ “/ 坐下/ ”/ 等/ 动作/ 类别/ ./ Duan/ 等/ 人/ [/ 13/ ]/ 提出/ 了/ 一种/ 新/ 的/ 使用/ 互联网/ 图像/ 进行/ 用户/ 视频/ 事件/ 识别方法/ ,/ 该/ 方法/ 把/ 视频/ 特征/ 和/ 图像/ 特征/ 放在/ 一个/ 统一/ 的/ 框架/ 下/ 进行/ 学习/ ,/ 但/ 他们/ 把/ 视频/ 特征/ 和/ 图像/ 特征/ 分开/ 处理/ ,/ 并/ 没有/ 考虑/ 到/ 这些/ 异性/ 特征/ 之间/ 的/ 内在联系/ ./ Wang/ 等/ 人/ [/ 14/ ]/ 提出/ 使用/ 关键字/ 从/ 互联网/ 检索/ 相关/ 图像/ 并/ 结合/ 一些/ 少量/ 带/ 标注/ 的/ 目标/ 域/ 数据/ 来/ 标注/ 视频/ ./ 他们/ 的/ 方法/ 联合/ 学习/ 了/ 视频/ 特征/ 和/ 图像/ 特征/ ,/ 但/ 目标/ 域/ 的/ 函数/ 需要/ 少量/ 标注/ 视频/ 进行/ 辅助/ 学习/ ,/ 并/ 不是/ 完全/ 的/ 无/ 监督/ 学习/ ./ 3/ 问题/ 描述/ 我们/ 的/ 目标/ 是/ 借助/ 源域/ 和/ 目标/ 域/ 的/ 知识/ 来/ 学习/ 目标/ 域/ 的/ 决策函数/ ft/ (/ ·/ )/ ./ 在/ 迁移/ 学习/ 机制/ 中/ ,/ 假设/ 目标/ 域/ 中/ 的/ 一些/ 未/ 标注/ 数据/ 在/ 训练/ 阶段/ 是/ 可见/ 的/ ./ 这种/ 源域/ 中/ 有/ 标注/ 数据/ ,/ 目标/ 域/ 中/ 没有/ 标注/ 数据/ 的/ 知识/ 迁移/ 也/ 被/ 称为/ 直/ 推式/ 知识/ 迁移/ (/ transductivelearning/ )/ [/ 15/ ]/ ./ 在/ 迁移/ 学习/ 中/ ,/ 源域/ 中/ 学习/ 得到/ 的/ 决策函数/ 可以/ 通过/ 一些/ 未/ 标注/ 的/ 目标/ 域/ 数据/ 更好/ 地/ 迁移/ 到/ 目标/ 域/ 中/ ./ 我们/ 的/ 方法/ 通过/ 权衡/ 源域/ 中/ 不同/ 图像/ 组并/ 通过/ 建立/ 源域/ 和/ 目标/ 域/ 共同/ 的/ 子/ 空间/ ,/ 逐渐/ 地/ 将/ 源域/ 知识/ 迁移/ 到/ 目标/ 域/ ./ 所/ 得到/ 的/ 目标/ 域/ 的/ 决策函数/ 能/ 具有/ 更好/ 的/ 泛化/ 性/ ./ 我们/ 提出/ 的/ 框架/ 不仅/ 能/ 挖掘出/ 源域/ 中/ 最/ 有用/ 的/ 那/ 部分/ 知识/ ,/ 也/ 提供/ 了/ 将/ 知识/ 从源域/ 迁移/ 到/ 目标/ 域/ 的/ 有效/ 方法/ ./ 注/ 图像/ 数据/ ;/ 目标/ 域/ / 注/ 的/ 用户/ 视频/ ./ P/ (/ Xs/ )/ 和/ P/ (/ Xt/ )/ 分别/ 表示/ 源域/ 数据/ 的/ 特征/ 空间/ χ/ s/ 和/ 目标/ 域/ 数据/ 特征/ 空间/ χ/ t/ 的/ 分布/ ./ 我们/ 使用/ 不同/ 的/ 联想/ 关键词/ 来/ 收集/ 图像/ 集/ ./ 一个/ 关键词/ 检索/ 得到/ 的/ 一个/ 图像/ 集合/ 被/ 称为/ 一个组/ ./ 每/ 一个组/ 对应/ 于/ 相应/ 事件/ 的/ 一个/ 概念/ 集/ ./ 由此/ ,/ 对于/ 从/ 互联网/ 图像/ 搜索引擎/ 得到/ 的/ 图像/ 样本/ 根据/ 它们/ 所/ 对应/ 的/ 联想/ 词/ 的/ 不同/ 自动/ 划分/ 为/ 不用/ 的/ 图像/ 组/ ./ 借助于/ 多组/ 图像/ ,/ 可以/ 获得/ 一个/ 事件/ 各/ 方面/ 的/ 知识/ ./ 将/ 一个/ 事件/ 的/ 第/ g/ 个/ 图像/ 组/ 定义/ 为/ Xg/ =/ {/ 狓/ g/ {/ 1/ ,/ …/ ,/ G/ }/ ,/ 其中/ 狓/ g/ 特征/ ,/ ds/ 表示/ 图像/ 特征/ 的/ 维度/ ,/ Ng/ 表示/ 第/ g/ 组/ 图像/ 样本/ 的/ 数目/ ./ 另外/ ,/ 我们/ 还/ 将/ 目标/ 域/ 中/ Nt/ 个/ 未/ 标注/ 定义/ 源域/ / 的/ 视频/ 定义/ 为/ Xt/ =/ {/ xt/ 中/ 的/ 第/ i/ 个/ 视频/ 特征/ ,/ dt/ 表示/ 目标/ 域/ 视频/ 特征/ 的/ 维度/ ./ 4/ 从/ 网络/ 图像/ 到/ 用户/ 视频/ 的/ 知识/ 迁移/ 4.1/ 共同/ 特征/ 子/ 空间/ 由于/ 图像/ 特征/ 和/ 视频/ 特征/ 存在/ 于/ 异性/ 的/ 特征/ 空间/ 中/ ,/ 在/ 源域/ 的/ 图像/ 上/ 学习/ 到/ 的/ 分类器/ 并/ 不能/ 直接/ 在/ 目标/ 域/ 的/ 视频/ 上/ 进行/ 分类/ ./ 为了/ 克服/ 这种/ 不/ 适用性/ ,/ 我们/ 引入/ 共同/ 特征/ 子/ 空间/ 的/ 概念/ ./ 在/ 目标/ 域/ 和/ 源域/ 的/ 特征/ 空间/ 之间/ 建立/ 共同/ 特征/ 子/ 空间/ ,/ 使得/ 不同/ 特征/ 空间/ 中/ 的/ 特征/ 可以/ 在/ 这个/ 子/ 空间/ 上/ 进行/ 对照/ ./ 任意/ 的/ 源域/ 样本/ (/ 图像/ )/ 和/ 任意/ 目标/ 域/ 样本/ (/ 视频/ )/ 可以/ 通过/ 两个/ 映射/ 矩阵/ 投影/ 到/ 这个/ 子/ 空间/ 上/ ./ 设/ 两个/ 映射/ 矩阵/ 分别/ 为/ 狑/ s/ ∈/ / 共同/ 特征/ 子/ 空间/ 的/ 维度/ ./ 定义/ 映射函数/ 的/ 一般/ 形式/ 为/ 狓/ 可以/ 是/ 目标/ 域/ 或者/ 是/ 源域/ 的/ 样本/ ./ 本文/ 使用/ 典型/ 相关性/ 分析/ [/ 16/ -/ 18/ ]/ (/ CanonicalCorrelationAnalysis/ ,/ CCA/ )/ 方法/ 来/ 学习/ 这/ 两个/ 映射/ 矩阵/ 狑/ s/ 和/ 狑/ s/ ./ CCA/ 通过/ 假定/ 不同/ 特征/ 空间/ 中/ 的/ 特征/ 来自/ 于/ 同一个/ 样本/ ,/ 从而/ 达到/ 在/ 不同/ 的/ 特征/ 空间/ 中/ 联合/ 降维/ 的/ 目的/ ./ 由于/ 要求/ 不同/ 的/ 特征/ 来自/ 同一个/ 样本/ ,/ 传统/ 的/ CCA/ 方法/ 通常/ 是/ 有/ 监督/ 的/ 方法/ ./ 而/ 本文/ 中/ 目标/ 域/ 的/ 视频/ 数据/ 都/ 是/ 无/ 标注/ 的/ ,/ 所以/ 不能/ 直接/ 使用/ CCA/ 建立/ 两个/ 域/ 的/ 链接/ ./ 实践/ 中/ 我们/ 发现/ 了/ 视频/ 与/ 它/ 关键帧/ 的/ 对应/ 关系/ ,/ 这种/ 关系/ 为/ CCA/ 提供/ 了/ 一种/ 自然/ 的/ 监督/ 信息/ ,/ 从而/ 可以/ 在/ 图像/ 特征/ 空间/ (/ 来自/ 于/ 关键帧/ )/ 和/ 视频/ 特征/ 空间/ (/ 来自/ 于/ 相应/ 的/ 视频/ )/ 之间/ 建立/ 起/ 一一对应/ 的/ 关系/ ./ 给定/ N/ 个/ 样本/ 对/ {/ (/ 犛/ 1/ ,/ 犜/ 1/ )/ ,/ …/ ,/ (/ 犛/ N/ ,/ 犜/ N/ )/ }/ ,/ 其中/ 犛/ i/ ∈/ / (/ 关键帧/ )/ 特征/ 空间/ 的/ 样本/ 和/ 视频/ 特征/ 空间/ 的/ 样本/ ./ CCA/ 的/ 目标/ 是/ 利用/ 典型/ 相关性/ 学习/ 两个/ 映射/ 矩阵/ 狑/ s/ ∈/ / dc/ ×/ ds/ 和/ 狑/ t/ ∈/ / 这里/ E/ ^/ 表示/ 经验/ 期望值/ ,/ 犆/ 犛/ 犜/ 表示/ 图像/ 特征/ 空间/ 犛/ Page4/ 和/ 视频/ 特征/ 空间/ 犜/ 的/ 相关性/ 矩阵/ ,/ 犆/ 犛/ 犛/ 和/ 犆/ 犜/ 犜/ 分别/ 表示/ 图像/ 特征/ 空间/ 犛和/ 视频/ 特征/ 空间/ 犜/ 的/ 自/ 相关矩阵/ ./ 4.2/ 预/ 分类器/ 定义/ 源域/ 第/ g/ 组/ 图像/ 的/ 预/ 分类器/ 为/ 狑/ =/ [/ w1/ ;/ w2/ ]/ 为预/ 分类器/ 模板/ ,/ 狓/ s/ ,/ g/ 是/ 第/ g/ 组/ 图像/ 中/ 的/ 第/ s/ 个/ 图像/ 样本/ ./ ψ/ (/ 狓/ s/ ,/ g/ )/ 和/ υ/ (/ 狓/ s/ ,/ g/ )/ 分别/ 是/ 共同/ 特征/ 和/ 图像/ 特征/ ./ 注意/ 到/ ,/ 目标/ 域/ 关键帧/ 中/ 的/ 图像/ 特征/ 分布/ 与/ 源域/ 的/ 图像/ 特征/ 分布/ 在/ 某种程度/ 上/ 是/ 不/ 一样/ 的/ ./ 因此/ ,/ 使用/ DASVM/ [/ 19/ ]/ 来/ 优化/ 预/ 分类器/ 的/ 模板/ w1/ 和/ w2/ ,/ 使/ 它们/ 更/ 适应/ 于/ 目标/ 域/ 的/ 数据/ ./ 在/ 该/ 方法/ 中/ ,/ 源域/ 数据/ 只/ 在/ 初始化/ 组预/ 分类器/ 时/ 使用/ ./ 在/ 完成/ 初始化/ 后/ ,/ 源域/ 样本/ 就/ 逐渐/ 地被/ 目标/ 域/ 样本/ 替代/ ,/ 从而/ 得到/ 最终/ 的/ 分类/ 平面/ ./ 4.3/ 联合/ 组/ 权重/ 本/ 节/ 主要/ 讨论/ 如何/ 将/ 上/ 一节/ 得到/ 的/ 预/ 分类器/ 整合/ 起来/ 得到/ 目标/ 分类器/ ./ 我们/ 提出/ 一种/ 新/ 的/ 联合/ 组/ 权重/ 学习/ 方法/ ,/ 根据/ 不同/ 组与/ 目标/ 域/ 的/ 相关性/ 进行/ 加权/ 整合/ 起来/ ./ 每组/ 的/ 权重/ 代表/ 了/ 这个/ 组对/ 分类/ 目标/ 视频/ 的/ 贡献/ ./ 在/ 联合/ 组/ 权重/ 学习/ 中/ ,/ 将/ 视频/ 的/ 目标/ 分类器/ 定义/ 为/ 这里/ α/ g/ >/ 0/ 是/ 第/ g/ 组/ 的/ 权重/ ,/ 将/ α/ 归一化/ :/ ∑/ G/ 基于/ 对/ 不同/ 组/ 的/ 平滑/ 假设/ ,/ 既/ 需要/ 最小化/ 目标/ 函数/ 在/ 标注/ 的/ 源域/ 数据/ 上/ 的/ 误差/ ,/ 也/ 需要/ 最小化/ 不同/ 组/ 分类器/ 在/ 目标/ 域/ 数据/ 上/ 的/ 差距/ ./ 学习/ 计算/ 框架/ 表示/ 如下/ :/ (/ Ω/ (/ ft/ )/ +/ λ/ L/ Ω/ L/ (/ ft/ )/ +/ λ/ T/ Ω/ T/ (/ ft/ )/ +/ λ/ G/ Ω/ G/ (/ ft/ )/ )/ minft/ 这里/ λ/ L/ ,/ λ/ G/ ,/ λ/ T/ >/ 0/ 为/ 平衡/ 参数/ ./ 下面/ 详细/ 介绍/ 式/ (/ 5/ )/ 中/ 的/ 每一项/ 内容/ ./ Ω/ (/ ft/ )/ =/ 1/ α/ =/ (/ α/ 1/ ,/ α/ 2/ ,/ …/ ,/ α/ g/ )/ T/ 为/ 所有/ 分组/ 的/ 权重/ 向量/ ./ 的/ 损失/ 函数/ :/ Ω/ L/ (/ ft/ )/ 是/ 目标/ 域/ 分类/ 函数/ 在/ 源域/ 的/ 标注/ 数据/ 上/ 这里/ 的/ xsi/ 表示/ 源域/ 中/ 的/ 第/ i/ 幅/ 图像/ ./ ysi/ 是/ xsi/ 的/ 事件/ 标签/ ,/ Ns/ 是/ 源域/ 中/ 训练样本/ 的/ 数量/ ,/ 即/ Ns/ =/ ∑/ G/ 这个/ 正则/ 项/ 强制/ 目标/ 函数/ 在/ 源域/ 样本/ 上/ 的/ 决策/ 值/ 尽可能/ 接近/ 源域/ 样本/ 的/ 真实/ 值/ ./ 如果/ 仅仅/ 使用/ 源域/ 中/ 的/ 已/ 标注/ 数据/ 训练/ 目标/ 函数/ 会/ 导致/ 目标/ 函数/ 在/ 训练/ 数据/ 上/ 的/ 过/ 拟合/ ,/ 从而/ 降低/ 了/ 目标/ 函数/ 的/ 泛化/ 性能/ ./ 在/ 一些/ 传统/ 的/ 直/ 推式/ 学习/ 方法/ 中/ ,/ 目标/ 域/ 的/ 未/ 标注/ 数据/ 也/ 能/ 提供/ 一些/ 约束/ 信息/ 从而/ 提高/ 分类/ 效果/ ./ 由此/ ,/ 我们/ 也/ 考虑/ 使用/ 一个/ 分组/ 损失/ 函数/ Ω/ G/ (/ ft/ )/ 来/ 保证/ 目标/ 函数/ 在/ 分组/ 上/ 的/ 平滑/ 性/ :/ Ω/ G/ (/ ft/ )/ =/ ∑/ Nt/ 这个/ 损失/ 函数/ 约束/ 同一个/ 事件/ 在/ 不同/ 的/ 分组/ 应该/ 具有/ 相似/ 的/ 决策/ 值/ ./ 从域/ 适应/ 的/ 角度/ 来看/ ,/ 假定/ 属于/ 同一/ 事件/ 类别/ 的/ 不同/ 预/ 分类器/ 对于/ 目标/ 域/ 的/ 未/ 标注/ 样本/ 应该/ 具有/ 相似/ 的/ 决策/ 制/ ./ 例如/ ,/ 假设/ 源域/ 的/ 第/ k/ 个/ 分类器/ 和/ 第/ g/ 个/ 分类器/ 属于/ 同一个/ 事件/ ,/ 那么/ 我们/ 认为/ fk/ 上/ ,/ 引入/ Ω/ G/ (/ ft/ )/ 来/ 惩罚/ 那些/ 远远/ 偏离/ 大部分/ 事件/ 相关/ 组/ 的/ 图像/ 组/ ./ 我们/ 还/ 使用/ 目标/ 域/ 的/ 未/ 标注/ 样本/ 来/ 增强/ 所学/ 得/ 模型/ 的/ 泛化/ 性能/ ,/ 表示/ 为/ 正则/ 项/ :/ 整合/ 以上/ 所有/ 各项/ ,/ 得到/ 如下/ 优化/ 问题/ :/ min/ α/ s/ ./ t/ ./ ∑/ G/ 式/ (/ 9/ )/ 中/ 的/ 优化/ 问题/ 可以/ 通过/ 二次/ 优化/ 算法/ 得到/ 解决/ ./ 5/ 实验/ 5.1/ 数据库/ CCV/ 数据库/ [/ 20/ ]/ 包含/ 了/ 4659/ 个/ 训练/ 视频/ 和/ 4658/ 个/ 测试/ 视频/ ,/ 所有/ 视频/ 被/ 标注/ 为/ 20/ 个/ 语义/ 类别/ ./ 由于/ 我们/ 关注/ 于/ 事件/ 标注/ ,/ 并/ 没有/ 考虑/ 该/ 数据库/ 中/ 的/ 非/ 事件/ 视频/ (/ 如/ “/ playground/ ”/ 、/ “/ bird/ ”/ ,/ “/ beach/ ”/ ,/ “/ cat/ ”/ 和/ Page5/ “/ dog/ ”/ )/ ./ 为了/ 便于/ 图像/ 检索/ ,/ 将/ “/ weddingceremony/ ”/ ,/ “/ weddingreception/ ”/ 和/ “/ weddingdance/ ”/ 合并/ 为/ 一个/ 关键字/ “/ wedding/ ”/ ,/ 将/ “/ non/ -/ musicperformance/ ”/ 和/ “/ musicperformance/ ”/ 合并/ 为/ “/ performance/ ”/ ./ 最终/ ,/ 得到/ 如下/ 事件/ 类别/ :/ “/ basketball/ ”/ 、/ “/ baseball/ ”/ 、/ “/ soccer/ ”/ 、/ “/ iceskating/ ”/ 、/ “/ biking/ ”/ 、/ “/ swimming/ ”/ 、/ “/ graduation/ ”/ 、/ “/ birthday/ ”/ 、/ “/ wedding/ ”/ 、/ “/ show/ ”/ 、/ “/ parade/ ”/ ./ Kodak/ 数据库/ 是/ Kodak/ 公司/ 历时/ 一年/ 多/ 从/ 大约/ 100/ 位/ 真实/ 用户/ 中/ 收集/ 的/ 视频/ ./ 同样/ 地/ ,/ 在/ 我们/ 的/ 实验/ 中/ 只/ 考虑/ 6/ 类/ 事件/ 相关/ 类别/ (/ “/ sports/ ”/ 、/ “/ birthday/ ”/ 、/ “/ wedding/ ”/ 、/ “/ show/ ”/ 、/ “/ parade/ ”/ 、/ “/ picnic/ ”/ )/ ./ 对于/ 每/ 一个/ 用户/ 视频/ ,/ 我们/ 使用/ 两种/ 特征/ :/ 视频/ 特征/ 和/ 图像/ 特征/ ./ 在/ CCV/ 数据库/ 上/ 提取/ 144/ 维/ 三维/ 时空/ 兴趣/ 点/ 特征/ 作为/ CCV/ 的/ 视频/ 特征/ [/ 21/ ]/ ,/ 在/ Kodak/ 数据库/ 上/ 提取/ 96/ 维/ 梯度方向/ 直方图/ (/ HOG/ )/ 和/ 108baseballgamesfoullinesoftballdemonstrationprocessionprotest/ 图/ 2/ 实验/ 中/ 所/ 使用/ 的/ 联想/ 关键词/ 5.2/ 实验/ 设置/ 我们/ 使用/ 词袋/ 模型/ 对/ 图像/ 和/ 视频/ 特征/ 进行/ 聚类/ ./ 提取/ 所有/ 图像/ 的/ SIFT/ 特征/ 并/ 进行/ k/ -/ means/ 聚类/ ,/ 得到/ 2000/ 个/ 视觉/ 单词/ ./ 根据/ 这些/ 视觉/ 单词/ 进而/ 量化/ 得到/ 一个/ 2000/ 维/ 的/ 图像/ // 关键帧/ 特征/ ./ 同样/ ,/ 我们/ 对/ CCV/ 和/ Kodak/ 数据库/ 上/ 的/ 视频/ 特征/ 进行/ 聚类/ ,/ 分别/ 得到/ 5000/ 维和/ 2000/ 维/ 的/ 视频/ 特征/ ./ 对于/ 一个/ 给定/ 的/ 事件/ ,/ 使用/ 5/ 个/ 联想/ 关键词/ 在/ 维光流/ 直方图/ (/ HOF/ )/ [/ 13/ ]/ 作为/ Kodak/ 数据库/ 上/ 的/ 视频/ 特征/ ./ 在/ 每/ 一个/ 视频/ 上/ 随机/ 抽取/ 一帧/ 作为/ 该/ 视频/ 的/ 关键帧/ ,/ 并/ 在/ 这个/ 关键帧/ 上/ 使用/ DoG/ 检测/ 子/ 检测/ 显著/ 区域/ 提取/ 128/ 维/ 的/ SIFT/ 特征/ 作为/ 图像/ 特征/ [/ 22/ ]/ ./ 本文/ 实验/ 中/ 的/ 网络/ 图像/ 均/ 是/ 使用/ 谷歌/ 图像/ 搜索引擎/ 进行/ 关键字/ 检索/ 收集/ 得来/ 的/ ./ 根据/ CCV/ 和/ Kodak/ 所/ 对应/ 的/ 的/ 事件/ 类型/ ,/ 从/ 搜索引擎/ 上/ 收集/ 13/ 类/ 事件/ 图像/ :/ “/ basketball/ ”/ 、/ “/ baseball/ ”/ 、/ “/ soccer/ ”/ 、/ “/ iceskating/ ”/ 、/ “/ biking/ ”/ 、/ “/ swimming/ ”/ 、/ “/ graduation/ ”/ 、/ “/ birthday/ ”/ 、/ “/ wedding/ ”/ 、/ “/ skiing/ ”/ 、/ “/ show/ ”/ 、/ “/ parade/ ”/ 、/ “/ picnic/ ”/ ./ 图/ 2/ 显示/ 了/ 实验/ 中/ 所/ 使用/ 的/ 联想/ 关键字/ ./ 每/ 一个/ 事件/ 对应/ 于/ 多组/ 知识/ ./ 每组/ 知识/ 对应/ 于/ 一个/ 联想/ 关键词/ 在/ 图像/ 搜索引擎/ 上/ 检索/ 到/ 的/ 图像/ 集/ ./ 所有/ 的/ 这些/ 图像/ 集/ 构成/ 了/ 源域/ 数据/ ./ 图/ 3/ 显示/ 了/ “/ basketball/ ”/ 对应/ 的/ 图像/ 组/ ./ 最/ 左/ 一列/ 显示/ 了/ 对于/ 事件/ “/ basketball/ ”/ 所/ 使用/ 的/ 联想/ 关键词/ ./ 每/ 一行/ 显示/ 了/ 与/ 该/ 联想/ 关键词/ 所/ 对应/ 的/ 检索/ 图像/ ./ 第/ 3/ 组/ NBAbikecandlecelebrateskatesledfootballrealmadridACmilanswimmingsynchronisedaquaticscookoutfood/ 搜索引擎/ 中/ 检索/ 图片/ ./ 对于/ 每/ 一个/ 关键词/ 返回/ 的/ 检索/ 结果/ ,/ 收集/ 前/ 300/ 张/ 图片/ 作为/ 一个/ 源域/ 图像/ 组/ ./ 为了/ 获得/ 每/ 一个/ 图像/ 组/ 的/ 分类器/ ,/ 使用/ 该组/ 所/ 包含/ 的/ 300/ 张/ 图像/ 作为/ 正/ 样本/ ,/ 从/ 其它/ 事件/ 的/ 任意/ 图像/ 组中/ 随机/ 抽取/ 300/ 张/ 图像/ 作为/ 负/ 样本/ ./ 在/ 训练/ 阶段/ ,/ 对于/ CCV/ 数据库/ ,/ 使用/ 数据库/ 给定/ 的/ 4659/ 个/ 视频/ 作为/ 未/ 标注/ 的/ 目标/ 域/ 训练样本/ ;/ 对于/ Kodak/ 数据库/ ,/ 使用/ 数据库/ 中/ 全部/ 195/ 个/ 视频/ 作为/ 未/ 标注/ 训练样本/ ./ 我们/ 将/ 本文/ 的/ 方法/ 与/ 标准/ SVM/ 方法/ 、/ DASVM/ 方法/ [/ 19/ ]/ 、/ DSM/ 方法/ [/ 13/ ]/ 进行/ 比较/ ./ 以上/ 这些/ 方法/ 可以/ 在/ 目标/ 域/ 没有/ 任何/ 标注/ 数据/ 的/ 情况/ 下/ ,/ 对/ 目标/ 域/ 数据/ 进行/ 分类/ ./ 对于/ 标准/ 的/ SVM/ 和/ DASVM/ 等/ 方法/ ,/ 在/ 每/ 一个/ 图像/ 组上/ 学习/ 一个/ 分类器/ ,/ 再/ 将/ 单组分/ 类/ 结果/ 进行/ 融合/ 得到/ 多组分/ 类/ 的/ 结果/ ./ 在/ DSM/ 方法/ Page6/ 中/ ,/ 使用/ 非线性/ 核/ χ/ 2/ 并/ 使用/ SVM/ 训练/ 得到/ 预/ 分类器/ ./ 本文/ 使用/ AveragePrecision/ (/ AP/ )/ 评价/ 所有/ 方法/ 的/ 标注/ 结果/ ,/ 并/ 将/ mAP/ (/ meanAveragePrecision/ )/ 定义/ 为/ 所有/ 事件/ 的/ 平均/ AP/ 值/ ./ 5.3/ 实验/ 结果/ 在/ CCV/ 和/ Kodak/ 数据库/ 上将/ 我们/ 的/ 方法/ 与/ 现有/ 的/ 一些/ 方法/ 进行/ 比较/ ./ 图/ 4/ 和/ 图/ 5/ 显示/ 了/ 这/ 几种/ 方法/ 的/ 标注/ 性能/ ./ 在/ 表/ 1/ 列出/ 了/ mAP/ 结果/ ./ 数据库/ CCV8/ ./ 5210.9012/ ./ 6316.48/ Kodak23/ ./ 2928.6331/ ./ 5433.54/ 从表/ 1/ 可以/ 看出/ 本文/ 的/ 方法/ 在/ 视频/ 标注/ 上/ 的/ 有效性/ ./ 在/ CCV/ 数据库/ 上/ ,/ 本文/ 的/ 方法/ 在/ 性能/ 上/ 分别/ 比/ SVM/ 、/ DASVM/ 和/ DSM/ 相对/ 提高/ 了/ 46.95/ %/ ,/ 24.03/ %/ 和/ 7/ %/ ./ 在/ Kodak/ 数据库/ 上/ ,/ 分别/ 相对/ 提高/ 了/ 40.40/ %/ 、/ 14.21/ %/ 和/ 3.7/ %/ ./ 实验/ 还/ 验证/ 了/ 共同/ 特征/ 子/ 空间/ 在/ CCV/ 和/ Kodak/ 数据库/ 上/ 的/ 有效性/ ./ 图/ 6/ 和/ 图/ 7/ 显示/ 了/ 不同/ 特征/ 的/ 标注/ 性能/ ./ 本文/ 测试/ 了/ 3/ 种/ 特征/ :/ SIFT/ 特征/ (/ SIFT/ )/ 、/ 中间/ 特征/ (/ inter/ )/ [/ 5/ ]/ 和/ 共同/ 特征/ (/ common/ )/ ./ 可以/ 发现/ ,/ 在/ 大多数/ 事件/ 中/ 共同/ 特征/ 取得/ 了/ 与/ SIFT/ 特征/ 等同/ 的/ 效果/ ,/ 特别/ 是/ 在/ 一些/ 与/ 动态/ 信息/ 相关/ 的/ 事件/ 中/ ,/ 如/ “/ birthday/ ”/ 、/ “/ parade/ ”/ 和/ “/ picnic/ ”/ ,/ 共同/ 特征/ 起到/ 了/ 非常/ 重要/ 的/ 作用/ ./ 将/ SIFT/ 和/ 共同/ 特征/ 融合/ 对/ 事件/ 进行/ 标注/ 时/ ,/ 取得/ 了/ 最好/ 的/ 标注/ 效果/ ./ 图/ 6/ 共同/ 特征/ 子/ 空间/ 在/ CCV/ 数据库/ 上/ 的/ 标注/ 性能/ (/ AP/ )/ 图/ 7/ 共同/ 特征/ 子/ 空间/ 在/ Kodak/ 数据库/ 上/ 的/ 标注/ 性能/ (/ AP/ )/ 为/ 验证/ 分组/ 个数/ 对/ 标注/ 结果/ 的/ 影响/ ,/ 我们/ 列出/ 了/ 在/ 使用/ 不同/ 组数/ 时/ 的/ 实验/ 结果/ ./ 从图/ 8/ 中/ 可以/ 看出/ ,/ 多组/ 图像/ 上/ 的/ 实验/ 结果/ 始终/ 比/ 单组/ 图像/ 要/ 好/ ./ 这/ 说明/ 我们/ 的/ 分组/ 机制/ 可以/ 获得/ 对/ 视频/ 标注/ 有用/ 的/ 信息/ ./ 同时/ 也/ 发现/ mAP/ 并/ 不/ 随着/ 组数/ 单调/ 递增/ ./ 一种/ 可能/ 的/ 解释/ 是/ ,/ 知识/ 迁移/ 的/ 有效性/ 取决于/ 在/ 源域/ 数据/ 与/ 目标/ 域/ 数据/ 的/ 相关性/ ./ 当/ 这/ 两个/ 域/ 的/ 相关性/ 越大时/ ,/ 知识/ 迁移/ 越/ 有效/ ./ 最后/ 我们/ 验证/ 了/ 式/ (/ 9/ )/ 中/ 各个/ 正则/ 项/ 的/ 有效性/ ./ 表/ 2/ 列出/ 了/ 当/ λ/ G/ =/ 0/ 和/ λ/ T/ =/ 0/ 时/ 标注/ 的/ 结果/ ./ 从/ 结果/ 中/ 可以/ 看出/ ,/ 当/ Ω/ G/ (/ ft/ )/ 和/ Ω/ T/ (/ ft/ )/ 从/ 优化/ 函数/ 中/ 移除/ 时/ ,/ mAP/ 结果/ 大大降低/ 了/ ./ 同时/ 也/ 列出/ 了/ 当/ 所有/ 组/ 的/ 权重/ 都/ 相等/ α/ g/ =/ 1/ // G/ 的/ 结果/ ,/ 可以/ 看出/ 不/ 相关/ 的/ 图像/ 噪声/ 在/ 很大/ 程度/ 上/ 影响/ 了/ 标注/ 的/ 效果/ ./ Page7/ 数据库/ CCV10/ ./ 3010.1311/ ./ 4016.48/ Kodak24/ ./ 9020.9019/ ./ 7933.546/ 总结/ 本文/ 提出/ 了/ 一种/ 联合/ 组/ 权重/ 学习/ 的/ 框架/ ,/ 利用/ 互联网/ 上/ 不同/ 分组/ 图像/ 的/ 知识/ 来/ 完成/ 用户/ 视频/ 的/ 标注/ ./ 在/ 这个/ 框架/ 下/ ,/ 通过/ 不同/ 的/ 联想/ 词/ ,/ 将/ 所/ 得到/ 的/ 图像/ 集/ 划分/ 为/ 不同/ 的/ 组/ ./ 根据/ 不同/ 图像/ 组与/ 视频/ 之间/ 的/ 相关性/ ,/ 通过/ 一种/ 联合/ 优化/ 学习/ 的/ 方法/ ,/ 根据/ 源域/ 各组/ 之间/ 、/ 源域/ 与/ 目标/ 域/ 之间/ 的/ 关系/ ,/ 自动/ 学习/ 各组/ 的/ 权重/ ./ 实验/ 结果表明/ :/ (/ 1/ )/ 对/ 多种/ 相关/ 的/ 知识/ 进行/ 权衡/ 能够/ 得到/ 更好/ 的/ 结果/ ;/ (/ 2/ )/ 给/ 不同/ 组/ 赋予/ 不同/ 的/ 权重/ 对/ 知识/ 的/ 有效/ 迁移/ 有/ 重要/ 的/ 作用/ ,/ 通过/ 实验/ 证明/ 本文/ 对组/ 的/ 赋值/ 策略/ 是/ 有效/ 的/ ;/ (/ 3/ )/ 在/ 图像/ 与/ 视频/ 之间/ 进行/ 知识/ 迁移/ 时/ ,/ 应/ 考虑/ 使用/ 图像/ 与/ 视频/ 特征/ 之间/ 的/ 关系/ 来/ 提高/ 标注/ 效果/ ./ 

