Page1/ 混合/ 体系结构/ 中有/ 状态/ 硬件/ 加速器/ 的/ 优化/ 马宜科/ 1/ )/ ,/ 2/ )/ ,/ 3/ )/ 常晓涛/ 2/ )/ 范东/ 睿/ 1/ )/ 刘志勇/ 1/ )/ 1/ )/ (/ 中国科学院计算技术研究所/ 系统结构/ 重点/ 实验室/ 北京/ 100190/ )/ 2/ )/ (/ IBM/ 中国/ 研究院/ 北京/ 100193/ )/ 3/ )/ (/ 中国科学院/ 研究生院/ 北京/ 100049/ )/ 摘要/ 在/ 诸多/ 计算/ 领域/ 中/ ,/ 硬件/ 加速器/ 可以/ 代替/ 通用/ 处理器/ 上/ 执行/ 的/ 软件/ 完成/ 专用/ 功能/ ,/ 达到/ 提高/ 性能/ 和/ 降低功耗/ 的/ 目的/ ./ 网络应用/ 中/ ,/ 许多/ 硬件/ 加速器/ 是/ 无/ 状态/ 的/ ,/ 这/ 就/ 需要/ 一个/ 网络/ 流/ 的/ 全部/ 数据包/ 到达/ 后/ 才能/ 被/ 处理/ ./ 有/ 状态/ 加速器/ 则/ 可以/ 确保/ 每个/ 数据包/ 到达/ 后/ 即可/ 被/ 处理/ ,/ 因而/ 具有/ 更好/ 的/ 性能/ 和/ 灵活性/ ./ 由于/ 网络/ 流/ 的/ 并发/ 性/ ,/ 有/ 状态/ 加速器/ 需要/ 维护/ 众多/ 并发/ 网络/ 流/ 的/ 状态/ ,/ 并/ 在/ 需要/ 时/ 进行/ 硬件/ 状态/ 切换/ ,/ 从而/ 增加/ 了/ 加速器/ 的/ 性能/ 开销/ ./ 该文/ 基于/ 请求/ 队列/ 提出/ 对/ 不同/ 网络/ 流/ 的/ 请求/ 进行/ 动态/ 重/ 排序/ 的/ 方法/ ,/ 其中/ 请求/ 所在/ 的/ 队列/ 可以/ 在/ 片/ 上/ 也/ 可以/ 在/ 片外/ ,/ 从而/ 有效/ 减少/ 加速器/ 的/ 状态/ 切换/ 次数/ ./ 对/ 多种/ 流行/ 的/ 有/ 状态/ 加速器/ 进行/ 的/ 实验/ 结果表明/ ,/ 该/ 方法/ 可以/ 有效/ 降低/ 加速器/ 的/ 平均/ 响应/ 时间/ 并/ 提高/ 吞吐/ 率/ ./ 实验/ 结果表明/ :/ 与/ 传统/ 的/ FIFO/ 设计/ 对比/ ,/ 解压缩/ 加速器/ 的/ 吞吐/ 率/ 最大/ 提高/ 了/ 26.7/ %/ ,/ 响应/ 时间/ 最大/ 减少/ 了/ 50/ %/ ./ 关键词/ 硬件加速/ ;/ 混合/ 体系结构/ ;/ 有/ 状态/ 加速器/ 1/ 引言/ CMOS/ 技术/ 的/ 发展/ 是/ 计算机/ 性能指标/ 的/ 主要/ 推动力/ 之一/ ./ 通过/ 在/ 处理器/ 内/ 集成/ 网络接口/ 和/ 数据/ 解压/ 加速器/ 等/ 部件/ ,/ 越来越/ 多/ 的/ 处理器/ 被/ 设计/ 成/ 既有/ 通用/ 处理单元/ 又/ 有/ 专用/ 加速器/ 的/ 混合/ 体系结构/ 的/ 芯片/ ./ 网络应用/ 的/ 性能/ 会/ 受到/ 数据/ 传输速率/ 、/ 延迟/ 、/ 吞吐/ 率及/ 流/ 特性/ 等/ 因素/ 的/ 限制/ ./ 当前/ 的/ 网络应用/ 已经/ 增加/ 到/ 10Gbits/ // s/ 的/ 带宽/ 量级/ ,/ 正在/ 向/ 100Gbits/ // s/ 发展/ ,/ 这/ 就/ 需要/ 能/ 同时/ 满足/ 低/ 延迟/ 、/ 高带宽/ 和/ 低功耗/ 需求/ 的/ 新一代/ 处理器/ 的/ 支持/ ./ 这些/ 系统/ 的/ 重要/ 特性/ 包括/ 使用/ 大规模/ 硬件/ 多线程/ 以及/ 集成/ 对/ 网络/ 的/ 硬件/ 支持/ 和/ 特定/ 应用/ 的/ 硬件/ 加速器/ [/ 1/ ]/ ./ 硬件/ 加速器/ 的/ 优势/ 体现/ 在/ 网络/ 流/ 处理/ 的/ 多个/ 方面/ :/ 一方面/ ,/ 当/ 网络/ 流/ 的/ 数据包/ 到达/ 的/ 时候/ ,/ 系统对/ 接收/ 的/ 全部/ 数据包/ 进行/ 缓存/ 和/ 分析/ ,/ 再/ 由/ 硬件/ 线程/ 对/ 数据包/ 进行/ 调度/ 和/ 进一步/ 的/ 处理/ ./ 因为/ 每个/ 包都/ 需要/ 经过/ 这个/ 流程/ 的/ 处理/ ,/ 对/ 这些/ 步骤/ 进行/ 加速/ 可以/ 显著/ 增加/ 性能/ ./ 另/ 一个/ 方面/ ,/ 网络/ 数据/ 解密/ [/ 2/ ]/ ①/ 也/ 可以/ 体现/ 加速器/ 的/ 优势/ ,/ 这/ 是因为/ 硬件/ 实现/ 的/ 解密/ 算法/ 比/ 软件/ 更/ 高效/ ,/ 特别/ 是/ 当/ 需要/ 解密/ 的/ 数据包/ 的/ 数量/ 很大/ 的/ 时候/ ,/ 硬件/ 加速器/ 可以/ 显著/ 提高/ 系统/ 性能/ ./ 数据/ 解压缩/ 方面/ ,/ 在/ 虚拟/ 专用网/ 的/ 网络层/ 和/ 应用层/ ,/ 大量/ 的/ 数据包/ 经过/ 压缩/ 之后/ 再/ 传输/ 以/ 降低/ 对/ 广域网/ 的/ 带宽/ 需求/ ;/ 在/ 应用层/ ,/ HTTP/ // 1.1/ 通过/ 压缩/ 网页内容/ 来/ 减少/ 带宽/ 需求/ ;/ 通过/ 邮件/ 传输/ 的/ 大/ 文件/ 也/ 经常/ 使用/ 压缩/ 传输/ ./ 因此/ 减少/ 接收/ 方/ 的/ 解压缩/ 开销/ ,/ 可以/ 在/ 很大/ 程度/ 上/ 提高/ 吞吐/ 率/ ./ 此外/ ,/ 正则表达式/ 匹配/ (/ RegulareXpression/ ,/ RegX/ )/ [/ 3/ ]/ 是/ 实现/ 网络安全/ 领域/ 中/ 深度/ 包/ 检测/ 的/ 重要/ 方面/ ,/ 通过/ 对/ 其/ 进行/ 硬件加速/ ,/ 也/ 可以/ 获得/ 明显/ 的/ 性能/ 收益/ ./ 在/ 传统/ 应用/ 中/ ,/ 同一个/ 网络/ 流/ 的/ 数据包/ 必须/ 被/ 接收/ 方/ 全部/ 接收/ ,/ 并/ 在/ 应用层/ 重新/ 组装/ 成/ 整块/ 数据/ 之后/ 再/ 进入/ 硬件/ 加速器/ 进行/ 处理/ ./ 网络/ 流中/ 单个/ 的/ 数据包/ 在/ 到达/ 之后/ 并/ 不能/ 被/ 硬件/ 加速器/ 处理/ ,/ 我们/ 称/ 这种/ 处理/ 方式/ 的/ 加速器/ 为/ 无/ 状态/ 的/ (/ Stateless/ )/ 加速器/ ./ 有/ 状态/ (/ Stateful/ )/ 加速器/ 不/ 需要/ 等待/ 一个/ 网络/ 流上/ 的/ 全部/ 数据包/ 到达/ ,/ 它/ 可以/ 在/ 网络/ 流/ 的/ 任一/ 数据包/ 到达/ 之后/ 立刻/ 进行/ 处理/ ./ 为此/ ,/ 每/ 处理/ 完/ 网络/ 流中/ 的/ 一个/ 数据包/ ,/ 加速器/ 需要/ 保存/ 被/ 加速/ 网络/ 流/ 的/ 当前/ 状态/ ,/ 而/ 当该/ 网络/ 流/ 的/ 下/ 一个/ 数据包/ 到达/ 之后/ ,/ 加速器/ 首先/ 需要/ 恢复/ 其前/ 一个/ 数据包/ 处理/ 完/ 之后/ 的/ 状态/ ,/ 然后/ 才能/ 处理/ 刚/ 到达/ 的/ 数据包/ ./ 因此/ ,/ 有/ 状态/ 加速器/ 具有/ 更好/ 的/ 实时性/ 和/ 吞吐/ 率/ ,/ 更/ 适合/ 网络/ 中/ 的/ 各种/ 应用/ ,/ 例如/ 压缩/ // 解压缩/ 、/ 加密/ // 解密/ 、/ 正则表达式/ 匹配/ 和/ XML/ 处理/ 等/ ./ 在/ 带来/ 灵活性/ 的/ 同时/ ,/ 有/ 状态/ 加速器/ 的/ 状态/ 切换/ 会/ 引入/ 性能/ 开销/ ./ 网络/ 流/ 的/ 高/ 并发/ 性会/ 导致/ 频繁/ 的/ 状态/ 切换/ ,/ 尤其/ 在/ 所/ 切换/ 的/ 状态/ 数据/ 较多时/ ,/ 会/ 付出/ 显著/ 的/ 性能/ 代价/ ./ 一般来说/ ,/ 加速器/ 按照/ 先进先出/ (/ FIFO/ )/ 的/ 原则/ 从/ 加速/ 请求/ 队列/ 中/ 取出/ 请求/ 并/ 进行/ 处理/ ./ 本文/ 基于/ 片上/ // 主存/ 混合/ 请求/ 队列/ ,/ 提出/ 对/ 队列/ 中/ 的/ 请求/ 进行/ 重/ 排序/ 的/ 方法/ ,/ 从而/ 减少/ 状态/ 的/ 切换/ 次数/ 即/ 访存/ 次数/ 以/ 提高/ 性能/ ,/ 并/ 对/ 其/ 进行/ 仿真/ 实验/ 和/ 性能/ 评估/ ./ 本文/ 第/ 2/ 节/ 介绍/ 硬件/ 请求/ 队列/ 的/ 一般性/ 设计/ ;/ 第/ 3/ 节/ 描述/ 有/ 状态/ 硬件/ 加速器/ 设计/ 的/ 优化/ 方法/ ;/ 第/ 4/ 节/ 给出/ 实验/ 的/ 模型/ 和/ 参数/ 以及/ 模拟器/ 的/ 实验/ 结果/ ;/ 第/ 5/ 节是/ 本文/ 结论/ ./ 2/ 研究/ 背景/ 通常/ ,/ 一个/ 数据包/ 通过/ 网络协议/ 栈/ 的/ 处理/ 之后/ ,/ 处理器/ 线程/ 将/ 为/ 其/ 创建/ 一个/ 协处理器/ 请求/ 块/ (/ Cop/ -/ rocessorRequestBlock/ ,/ CRB/ [/ 4/ ]/ )/ ,/ 并发/ 往/ 硬件/ 加速器/ ./ CRB/ 至少/ 包含/ 源/ 数据/ 地址/ 、/ 目的/ 数据/ 地址/ 和/ 状态/ 地址/ ./ 其中/ ,/ 源/ 数据/ 地址/ 指向/ 需要/ 硬件/ 加速器/ 进行/ 处理/ 的/ 数据/ ;/ 目的/ 数据/ 地址/ 指向/ 由/ 处理器/ 分配/ 给/ 即将/ 产生/ 的/ 结果/ 数据/ 的/ 存储空间/ ;/ 状态/ 地址/ 所/ 指向/ 的/ 空间/ 则/ 是/ 用于/ 维护/ 当前/ 网络/ 流/ 状态/ 的/ 专用/ 区域/ ./ 这里/ 给/ 每/ 一个/ 网络/ 流/ 分配/ 唯一/ 的/ ID/ (/ ContextID/ ,/ CID/ )/ 进行/ 状态/ 检索/ ./ 来自/ 众/ 多线程/ 的/ 大量/ 并发/ 请求/ 将/ 导致/ 加速器/ 十分/ 繁忙/ ,/ 为了/ 使/ 处理/ 线程/ 可以/ 不/ 被/ 阻塞/ 从而/ 继续/ 进行/ 其它/ 处理/ ,/ 通常/ 需要/ 在/ 硬件/ 上/ 设计/ 能够/ 缓存/ 大量/ 请求/ 的/ 队列/ (/ FIFO/ )/ ./ 由于/ 处理器/ 芯片/ 的/ 面积/ 有限/ ,/ 片上/ 队列/ 只能/ 保存/ 数量/ 很/ 有限/ 的/ 请求/ ,/ 例如/ 当前/ 工艺/ 下/ ,/ 一个/ 片上/ 硬/ ①/ AdvancedEncryptionStandard/ ./ http/ :/ // // en/ ./ wikipedia/ ./ org/ // Page3/ 件/ 请求/ 队列/ 大约/ 可以/ 容纳/ 数百项/ CRB/ ./ 但是/ 在/ 当前/ 网络/ 中/ ,/ 每秒钟/ 可能/ 有/ 上百万/ 个/ 包/ 到达/ ,/ 因此/ 片上/ 的/ 队列/ 资源/ 在/ 短时间/ 内/ 很/ 有/ 可能/ 被/ 迅速/ 耗尽/ ./ 一旦/ 片上/ 队列/ 被/ 填满/ ,/ 发送/ 请求/ 的/ 线程/ 将/ 不能/ 继续/ 提交/ CRB/ ,/ 从而/ 进入/ 阻塞状态/ ./ 由于/ 当前/ 片外/ 存储/ (/ 如/ 主存/ )/ 相比/ 片上/ 存储/ 来说/ 可以/ 认为/ 容量/ 是/ 无限大/ 的/ ,/ 一种/ 解决/ 片上/ 队列/ 容量/ 不足/ 问题/ 的/ 方法/ 是/ 通过/ 使用/ 片/ 外存储器/ 中/ 的/ 空间/ 维护/ 一个/ 片外/ 队列/ (/ 本文/ 也/ 称/ 其图/ 1/ 硬件/ 加速器/ 的/ 请求/ 队列/ 在/ 硬件/ 加速器/ 中/ 使用/ 溢出/ 队列/ 管理/ 技术/ 之后/ ,/ 可以/ 近似/ 认为/ 整个/ 请求/ 队列/ 是/ 无限/ 长/ 的/ ,/ 这是/ 排队/ 论/ [/ 5/ ]/ 中/ 标准/ 的/ M/ // M/ // 1/ 模型/ ./ 在/ 下面/ 的/ 章节/ 中/ ,/ 我们/ 将/ 基于/ M/ // M/ // 1/ 模型/ 生成/ 不同/ 并发/ 程度/ 的/ 网络/ 流/ 进行/ 实验/ ./ 因为/ 大量/ 并发/ 网络/ 流/ 的/ CRB/ 交错/ 到达/ 硬件/ 加速器/ ,/ 网络应用/ 需要/ 加速器/ 为/ 每/ 一个/ 网络/ 流/ 保存/ 状态/ (/ 上下文/ )/ ./ 由于/ 受/ 处理器/ 芯片/ 面积/ 所/ 限/ ,/ 特别/ 是/ 当/ 某种/ 加速器/ 所/ 需要/ 保存/ 的/ 状态/ 数据/ 较大/ 时/ ,/ 例如/ 压缩/ 加速器/ 需要/ 32KBytes/ 空间/ 保存/ 状态/ ,/ 在/ 片/ 上/ 保存/ 全部/ 网络/ 流/ 的/ 状态/ 是/ 不/ 现实/ 的/ ./ 因此/ ,/ 通常/ 选用/ 主存/ 来/ 存储/ 不同/ 网络/ 流/ 的/ 状态/ ./ 如图/ 2/ 所示/ ,/ CRBC1/ 是/ 网络/ 流/ C/ 的/ 第一个/ 请求/ ,/ 一旦/ 它/ 被/ 处理/ 完成/ ,/ 网络/ 流/ C/ 的/ 当前/ 状态/ 就/ 被/ 图/ 2/ 多个/ 网络/ 流/ 请求/ 的/ 交错/ 到达/ 3/ 有/ 状态/ 加速器/ 的/ 请求/ 重/ 排序/ 技术/ 本节/ 将/ 提出/ 对/ 请求/ 队列/ 项/ 进行/ 动态/ 重/ 排序/ 的/ 方法/ ,/ 从而/ 将/ 来自/ 相同/ 网络/ 流中/ 等待/ 处理/ 的/ CRB/ 放到/ 相邻/ 的/ 位置/ 上/ ./ 此/ 方法/ 通过/ 减少/ 加速器/ 状态/ 切换/ 为/ 溢出/ 队列/ ,/ spillqueue/ )/ ,/ 从而/ 达到/ 增加/ 请求/ 队列/ 容量/ 的/ 目的/ ./ 在/ 图/ 1/ 中/ ,/ 放置/ 于/ 加速器/ 之前/ 的/ 请求/ 队列/ 包含/ 了/ 片/ 上/ 队列/ 和/ 片外/ 队列/ ./ 当片/ 上/ 队列/ 已满/ 的/ 时候/ ,/ 溢出/ 队列/ 控制/ 模块/ 自动/ 将/ 新/ 到达/ 的/ CRB/ 放入/ 片外/ 队列/ 中/ ./ 一旦/ 加速器/ 处理/ 完/ 一项/ CRB/ ,/ 片上/ 队列/ 将会/ 空出/ 一项/ 位置/ ,/ 溢出/ 队列/ 控制/ 模块/ 将/ 自动/ 把/ 片外/ 队列/ 中/ 位于/ 队首/ 的/ CRB/ 取到/ 片/ 上/ 队列/ 中/ ,/ 避免/ 了/ 处理/ 线程/ 上/ 软件/ 的/ 干预/ ./ 写回/ 主存/ 中/ 网络/ 流/ C/ 的/ 状态/ 空间/ ,/ 以备/ 网络/ 流/ C/ 的/ 下/ 一个/ CRB/ 使用/ ./ 随后/ ,/ 网络/ 流/ A/ 的/ CRBA1/ 和/ 网络/ 流/ B/ 的/ CRBB1/ 相继/ 被/ 处理/ ,/ 其/ 状态/ 也/ 随之/ 被/ 写/ 回/ 主存/ 中/ 自己/ 的/ 状态/ 空间/ ./ 接着/ ,/ 加速器/ 从/ 请求/ 队列/ 中/ 取出/ 网络/ 流/ C/ 的/ CRBC2/ ,/ 然后/ 从/ 主存/ 中/ 加载/ 之前/ 存储/ 的/ 状态/ 来/ 恢复/ CRBC1/ 完成/ 时/ 的/ 加速器/ 状态/ ,/ 一直/ 等到/ 状态/ 从/ 主存/ 中/ 完全/ 取回/ ,/ 才/ 可以/ 进行/ 对源/ 数据/ 的/ 处理/ ./ 图/ 2/ 中/ ,/ CRBC3/ 和/ CRBC4/ 相邻/ 并且/ 来自/ 同一个/ 网络/ 流/ ,/ 因此/ 在/ CRBC3/ 完成/ 后/ ,/ 就/ 不/ 需要/ 进行/ 状态/ 切换/ ./ 频繁/ 的/ 状态/ 切换/ 意味着/ 频繁/ 的/ 访存/ ,/ 由于/ 当前/ 计算机系统/ 中/ 存储/ 访问/ 带宽/ 瓶颈/ 的/ 存在/ ,/ 必然/ 会/ 造成/ 显著/ 的/ 延迟/ ,/ 从而/ 降低/ 性能/ ./ 我们/ 将/ 在/ 下/ 一节/ 给出/ 针对/ 这一/ 问题/ 的/ 优化/ 方法/ ./ 次数/ ,/ 来/ 降低/ 跟/ 状态/ 保存/ 和/ 恢复/ 相关/ 的/ 内存/ 操作/ 次数/ ,/ 以/ 达到/ 提高/ 加速器/ 性能/ 的/ 目的/ ,/ 包括/ 片上/ 请求/ 队列/ 的/ 重/ 排序/ 技术/ 和/ 对/ 溢出/ 队列/ 的/ 请求/ 查找/ 技术/ 两/ 部分/ ./ 这/ 两种/ 技术/ 的/ 重/ 排序/ 结果/ 都/ 保证/ 了/ 原先/ 同一个/ 网络/ 流/ 的/ 多个/ CRB/ 在/ 重/ 排序/ 之后/ 的/ 相对/ 次序/ 不变/ ./ Page43/ ./ 1/ 片上/ 请求/ 重/ 排序/ 技术/ (/ On/ -/ chipRequestReordering/ ,/ ORR/ )/ ORR/ 技术/ 的/ 主要/ 作用/ 如下/ 所述/ :/ 将/ 新/ 到达/ 的/ CRB/ 的/ CID/ 与/ 片/ 上/ 请求/ 队列/ 中/ 所有/ 等待/ 处理/ 的/ CRB/ 的/ CID/ 进行/ 比较/ ./ 如果/ 没有/ 找到/ 相同/ 的/ CID/ ,/ 说明/ 在/ 请求/ 队列/ 中/ 不/ 存在/ 来自/ 同一个/ 网络/ 流/ 的/ 请求/ ,/ 新/ 的/ CRB/ 将/ 被/ 插/ 到/ 队尾/ ./ 如果/ 找到/ ,/ 说明/ 在/ 请求/ 队列/ 中/ 存在/ 来自/ 相同/ 网络/ 流/ 的/ 加速/ 请求/ ,/ 新/ 的/ CRB/ 将/ 通过/ 片上/ 请求/ 重排/ 续表/ (/ On/ -/ chip/ -/ requestReor/ -/ derTable/ ,/ ORT/ )/ 将/ 其/ 插入/ 到/ 这/ 一个/ 网络/ 流/ 的/ 最后/ ,/ 从而/ 使得/ 当/ 加速器/ 在/ 完成/ 了/ 一个/ CRB/ 并且/ 还有/ 多个/ CRB/ 正在/ 等待/ 的/ 时候/ ,/ 直接/ 取/ 到/ 同一个/ 网络/ 流/ 的/ 下/ 一个/ CRB/ ,/ 避免/ 了/ 状态/ 切换/ ./ 对比/ 图/ 2/ ,/ 图/ 3/ 中/ 给出/ 了/ 同一个/ CRB/ 序列/ 在/ 采用/ ORR/ 技术/ 之后/ 的/ 处理过程/ ./ 图/ 3/ 中/ ,/ CRBC2/ 、/ C3/ 和/ C4/ 由于/ 进行/ 了/ 重/ 排序/ ,/ 紧随/ 同一个/ 网络/ 流/ 的/ CRBC1/ 之后/ ,/ 因此/ 加速器/ 在/ CRBC1/ 完成/ 之后/ 不/ 需要/ 切换/ 状态/ ,/ 可以/ 直接/ 处理/ CRBC2/ 、/ C3/ 和/ C4/ ,/ 在/ C4/ 完成/ 后/ 才/ 需要/ 进行/ 一次/ 状态/ 切换/ ./ 与/ 图/ 2/ 中/ 的/ 情况/ 相比/ ,/ ORR/ 大大减少/ 了/ 加速器/ 的/ 状态/ 切换/ 次数/ ./ 当片/ 上/ 队列/ 由于/ 请求/ 过量/ 而/ 耗尽/ 时/ ,/ 可以/ 使用/ 溢出/ 队列/ 来/ 维护/ 更/ 多/ 的/ 请求/ ./ 只要/ 片上/ 请求/ 队列/ 中/ 出现/ 空位/ ,/ 溢出/ 队列/ 控制/ 模块/ 将/ 立即/ 把/ 溢出/ 队列/ 中/ 位于/ 队首/ 的/ CRB/ 取到/ 片/ 上/ 队列/ 中/ ./ 一旦/ 这些/ 请求/ 进入/ 片上/ 请求/ 队列/ ,/ 它们/ 都/ 将/ 按/ ORT/ 的/ 信息/ 重/ 排序/ ,/ 从而/ 减少/ 加速器/ 的/ 状态/ 切换/ 开销/ ./ 但是/ ,/ 由于/ ORR/ 技术/ 只能/ 对片/ 上/ 请求/ 队列/ 进行/ 重/ 排序/ ,/ 因此/ 短时间/ 内/ 的/ 大量/ 并发/ 网络/ 流/ (/ ConcurrentStreams/ ,/ CS/ )/ 可能/ 会/ 减少/ 重/ 排序/ 的/ 机会/ ./ 例如/ ,/ 如果/ CS/ 数量/ 大于/ 片上/ 队列/ 容量/ ,/ 并且/ 队列/ 中/ 多个/ 网络/ 流/ 之间/ 基本上/ 都/ 是/ 交错/ 到达/ 的/ ,/ 那么/ ORT/ 获得/ 的/ 收益/ 将会/ 非常/ 有限/ ./ 因此/ ,/ 下/ 一/ 小节/ 将/ 给出/ 对/ 溢出/ 队列/ 中/ 的/ CRB/ 进行/ 重/ 排序/ 的/ 方法/ ./ 3.2/ 溢出/ 请求/ 查找/ 技术/ (/ SpillRequestLookup/ ,/ SRL/ )/ ORR/ 技术/ 局限于/ 对片/ 上/ 请求/ 队列/ 中/ 的/ CRB/ 进行/ 重/ 排序/ ./ 如果/ 我们/ 把/ 片/ 上/ 队列/ 看作/ 一个/ 窗口/ ,/ 显然/ ,/ 窗口/ 的/ 尺寸/ 越大/ ,/ 可以/ 重/ 排序/ 的/ 机会/ 就/ 越/ 多/ ./ 溢出/ 队列/ 中/ 的/ 所有/ CRB/ 都/ 在/ 这个/ 窗口/ 之外/ ,/ 因此/ 本/ 节/ 定义/ 一个/ 附加/ 的/ 窗口/ ,/ 即流/ 查找/ 表/ (/ StreamLookupTable/ ,/ SLT/ )/ ,/ 它/ 基于/ 内容/ 可/ 寻址/ 存储器/ (/ ContentAddressableMemory/ ,/ CAM/ )/ ①/ ,/ 扩展/ 了/ 溢出/ 队列/ 控制/ 模块/ 的/ 功能/ ,/ 涵盖/ 了/ 溢出/ 队列/ 中/ 部分/ 最/ 常用/ 的/ 信息/ ,/ 如图/ 4/ 所示/ ./ 首先/ ,/ 从/ 逻辑/ 上将/ 溢出/ 队列/ 分成/ 多个/ CRB/ 组/ ,/ 相同/ 组/ 的/ 全部/ CRB/ 属于/ 同一个/ 网络/ 流/ ,/ 每个/ 组有/ 多个/ 用来/ 存放/ CRB/ 的/ 槽/ ,/ CRB/ 组中/ 槽/ 的/ 数量/ 是/ 由/ 软件/ 配置/ 的/ ,/ 图/ 4/ 中/ 设置/ 为/ 8/ ./ 其次/ ,/ SLT/ 中/ 的/ 每/ 一个/ 表项/ 由/ CID/ 、/ 在/ 溢出/ 队列/ 中/ 的/ 组/ 地址/ 以及/ 该组/ 空槽/ 的/ 偏移量/ 组成/ ./ 一旦/ 一个/ 新/ 的/ CRB/ 到达/ ,/ 它/ 的/ CID/ 将/ 与/ SLT/ 中/ 所有/ 的/ 有效/ 表项/ 作/ 匹配/ ./ 如果/ 与/ 其中/ 一项/ 匹配/ ,/ 这个/ CRB/ 将/ 被/ 放入/ 相应/ 的/ CRB/ 组/ 的/ 空槽/ 中/ ,/ 同时/ ,/ 空槽/ 偏移量/ 循环/ 增长/ ,/ 其中/ 空槽/ 的/ 地址/ 可以/ 通过/ 所/ 匹配/ 的/ 组/ 地址/ 与/ 空槽/ 偏移量/ 计算/ 得到/ ./ 如果/ 没有/ 任何/ 匹配/ ,/ SLT/ 将/ 给/ 此/ CRB/ 分配/ 一个/ 新/ 表项/ ,/ 同时/ ,/ 这个/ CRB/ 将/ 被/ 放到/ 内存/ 中/ 该组/ 的/ 第一个/ 槽/ 中/ ./ 当/ 一个/ CRB/ 完成/ 时/ ,/ 加速器/ 将/ 从片/ 上/ 队列/ 中/ 取出/ 下/ 一个/ CRB/ 进行/ 处理/ ./ 在/ 片/ 上/ 队列/ 满/ 的/ 情况/ 中/ ,/ 溢出/ 队列/ 控制/ 模块/ 将/ 立即/ 把/ 溢出/ 队列/ 中/ 位于/ 队首/ 的/ CRB/ 取到/ 片/ 上/ 队列/ 刚空/ 出来/ 的/ 位置/ 中/ ./ 然后/ ,/ 随着/ CRB/ 持续/ 的/ 完成/ ,/ 在/ 溢出/ 队列/ 同/ 一组/ 中/ 的/ 所有/ 其它/ CRB/ 都/ 将/ 被/ 依次/ 取到/ 片/ 上/ 队列/ 新空/ 出来/ 的/ 位置/ 中/ ./ 当/ 这个/ 组中/ 的/ 所有/ CRB/ 都/ 被/ 取到/ 片/ 上/ 之后/ ,/ 溢出/ 队列/ 中/ 的/ 下/ 一组/ CRB/ 将会/ 继续/ 被/ 取到/ 片/ 上/ ,/ 以此类推/ ./ 由于/ 大量/ 连续/ 的/ CRB/ 都/ 已经/ 被/ 排好/ 了/ 顺序/ ,/ 因此/ 加速器/ 状态/ 切换/ 次数/ 大大降低/ ./ SRL/ 技术/ 进一步/ 扩展/ 了/ 重/ 排序/ 窗口/ ,/ 后面/ 的/ 实验/ 结果/ 将/ 表明/ ,/ ORR/ 技术/ 只能/ 在/ 小规模/ 并发/ 的/ 情形/ 下/ 获得/ 收益/ ,/ 而/ SRL/ 技术/ 在/ 更/ 高/ 的/ 并发/ 规模/ 下/ 仍然/ 能/ 获得/ 收益/ ./ 目前/ 国内外/ 鲜有/ 有/ 状态/ 硬件/ 加速器/ 性能/ 优化/ 的/ 相关/ 工作/ ,/ 相关/ 文献/ 只有/ 参考文献/ [/ 6/ ]/ ./ 但是/ 文献/ [/ 6/ ]/ 是/ 利用/ 解/ 压缩算法/ 的/ 本身/ 特性/ 设计/ 而成/ 的/ 有/ 状态/ 解/ ①/ CAM/ ./ http/ :/ // // en/ ./ wikipedia/ ./ org/ // wiki/ // Content/ -/ addressablePage5/ 图/ 4/ 溢出/ 请求/ 查找/ (/ SRL/ )/ 的/ 结构/ 示意图/ 压缩/ 加速/ 部件/ ;/ 而/ 我们/ 的/ 研究成果/ 适用/ 于/ 所有/ 有/ 状态/ 加速器/ 的/ 通用/ 优化/ 方法/ ,/ 利用/ 了/ 对/ 网络/ 流预/ 排序/ 的/ 方法/ 来/ 减少/ 上下文/ 交换/ ./ 因此/ 这/ 两种/ 方法/ 是/ 正交/ 的/ ,/ 在/ 使用/ 了/ 文献/ [/ 6/ ]/ 所/ 描述/ 的/ 部件/ 上/ 附加/ 我们/ 的/ 部件/ ,/ 在/ 不/ 影响/ 原有/ 部件/ 性能/ 的/ 基础/ 上/ ,/ 仍然/ 可以/ 获得/ 我们/ 的/ 部件/ 所/ 带来/ 的/ 性能/ 提升/ ./ 3.3/ 硬件/ 实现/ 代价/ 为/ ORR/ 技术/ 设计/ 的/ ORT/ 和/ 为/ SRL/ 技术/ 设计/ 的/ SLT/ 的/ 核心部件/ 都/ 是/ 内容/ 可/ 寻址/ 存储器/ ,/ 它/ 是/ 一种/ 在/ 高速/ 查找/ 应用/ 中/ 广泛/ 使用/ 的/ 电路/ ,/ 其/ 主要/ 工作/ 机制/ 是/ 将/ 一个/ 输入/ 数据项/ 与/ 存储/ 在/ 内容/ 可/ 寻址/ 存储器/ 中/ 的/ 所有/ 数据项/ 同时/ 进行/ 比较/ 以/ 判断/ 是否/ 匹配/ ,/ 并/ 输出/ 是否/ 匹配/ 的/ 布尔/ 信号/ 及/ 数据项/ 的/ 对应/ 地址/ ./ 由于/ 大量/ 使用/ CAM/ 会/ 显著/ 增加/ 芯片/ 的/ 面积/ 和/ 功耗/ ,/ 当前/ 芯片/ 上/ 内容/ 可/ 寻址/ 存储器/ 通常/ 最/ 多/ 只有/ 几百/ 项/ ./ 因此/ ,/ ORT/ 和/ SLT/ 的/ 容量/ 可能/ 会/ 受到限制/ ./ 理论/ 上/ ,/ SLT/ 的/ 容量/ 与/ 并发/ 网络/ 流/ 的/ 数量/ 相当/ 是/ 最合适/ 的/ ./ 由于/ 网络/ 流有/ 突发性/ [/ 7/ ]/ ,/ 即/ 同一个/ 网络/ 流/ 的/ 不同/ 数据包/ ,/ 会/ 在/ 一个/ 相对/ 较/ 短/ 的/ 时间/ 内/ 到达/ ,/ 因此/ 使用/ 较/ 少/ 容量/ 的/ SLT/ 就/ 可以/ 满足/ 需求/ ./ 后面/ 的/ 章节/ 将/ 表明/ ,/ 数百项/ 的/ ORT/ 和/ SLT/ 对/ 性能/ 的/ 提高/ 已经/ 非常明显/ ./ 这里/ 假设/ ORT/ 和/ SLT/ 的/ 项数/ 都/ 是/ 128/ ,/ 与/ 整个/ IBMWSP/ 处理器/ [/ 8/ ]/ 的/ 面积/ 进行/ 比较/ ,/ 用以/ 支持/ ORR/ 和/ SRL/ 的/ 全部/ 硬件/ 代价/ 不/ 超过/ 0.05/ %/ ./ 3.4/ 公平性/ 上面/ 所述/ 的/ 重/ 排序/ 方法/ 可能/ 会/ 改变/ 某些/ CRB/ 的/ 响应/ 时间/ ,/ 从而/ 影响/ 某些/ 网络/ 流/ 的/ 请求/ 延迟/ ,/ 造成/ 不/ 公平/ 现象/ ./ 我们/ 可以/ 通过/ 限制/ 重/ 排序/ 的/ 时间跨度/ 来/ 使/ 这个/ 影响/ 降到/ 可/ 承受/ 的/ 范围/ 之内/ ./ 例如/ ,/ 通过/ 软件/ 设定/ 一个/ 时间跨度/ ,/ 新/ 到达/ 的/ CRB/ 相比/ 等待/ 最久/ 的/ CRB/ 已经/ 超出/ 了/ 这个/ 时间跨度/ ,/ 这个/ CRB/ 将/ 不会/ 被/ 重/ 排序/ ,/ 而是/ 被/ 放到/ 当前/ 请求/ 队列/ 的/ 队尾/ ,/ 从而/ 不会/ 影响/ 到/ 先于/ 它/ 发出/ 的/ 那些/ 请求/ ./ 本文/ 中/ ,/ 我们/ 仅/ 给出/ 在/ 不/ 加入/ 公平性/ 限制/ 的/ 情况/ 下/ ,/ 重/ 排序/ 对/ 网络/ 流/ 最大/ 响应/ 时间/ 的/ 影响/ ./ 我们/ 会/ 在/ 将来/ 的/ 工作/ 中/ 对/ 加入/ 公平性/ 策略/ 后/ 的/ 重/ 排序/ 方法/ 进行/ 实现/ 和/ 评估/ ./ 4/ 实验/ 结果/ 与/ 分析/ 对/ 本文/ 方法/ 进行/ 性能/ 评估/ 的/ 指标/ 包括/ 两个/ 方面/ :/ 吞吐/ 率/ 和/ 响应/ 时间/ ./ 我们/ 在/ 解压缩/ 加速器/ 上/ 进行/ 了/ 详细/ 的/ 性能/ 研究/ ,/ 对于/ 其它/ 的/ 加速器/ ,/ 我们/ 只/ 给出/ 性能/ 提高/ 的/ 峰值/ 结果/ ./ 我们/ 在/ 实现/ 了/ IBMWire/ -/ SpeedPowerTMProcessor/ (/ WSP/ )/ 的/ Mambo/ 模拟器/ 上/ 进行/ 实验/ ,/ 其/ 主要参数/ 如表/ 1/ 所示/ ./ Mambo/ [/ 9/ ]/ 是/ 一个/ IBM/ 全/ 系统/ 模拟器/ ,/ 而/ IBMWSP/ [/ 4/ ,/ 8/ ]/ 是/ 一个/ 集成/ 了/ 16/ 个/ IBM/ 处理器/ 核数/ // 线程/ 数/ 一级/ 指令/ // 数据/ Cache16x/ (/ 16KB/ +/ 16KB/ )/ SRAM/ 二级/ Cache/ 硬件/ 加速器/ 内存/ 带宽/ 2xDDR3controllers4Channels/ @/ 800/ ~/ 1600MHz/ 系统/ I/ // O/ 带宽/ 4x10GBEthernet/ ,/ 2xPCIGen2Page6PowerPC/ 核/ (/ 每核/ 含/ 4/ 硬件/ 线程/ )/ 和/ 多个/ 专用/ 加速器/ 的/ 处理器/ ./ 我们/ 首先/ 参照/ 加速器/ 的/ 状态/ 切换/ 开销/ 得到/ 一个/ 近似/ 的/ 服务/ 时间/ ./ 假设/ 平均/ 的/ 负载/ 为/ 每个/ 数据包/ 1200Bytes/ ,/ 平均/ 压缩率/ 因子/ 为/ 4.91/ [/ 6/ ]/ ,/ 状态/ 信息/ 大小/ 取为/ 2.5/ KB/ (/ 2KB/ 历史/ 状态/ [/ 6/ ]/ 和/ 0.5/ KB/ 动态/ 哈夫曼/ 表/ [/ 10/ ]/ ①/ )/ ./ 对/ 解压缩/ 加速器/ 来说/ ,/ 状态/ 写回/ 开销/ 可以/ 忽略/ ,/ 这/ 是因为/ 其/ 状态/ 就是/ 上/ 一次/ 输出/ 的/ 数据/ ,/ 它/ 的/ 写/ 回/ 过程/ 已经/ 包含/ 在/ 结果/ 数据/ (/ 平均/ 5892Bytes/ ,/ 1200Bytes/ ×/ 4.91/ )/ 的/ 写/ 回/ 阶段/ ./ 无论/ 是否/ 存在/ 加载/ 或者/ 写回/ 停顿/ ,/ 加速器/ 的/ 解压缩/ 性能/ 都/ 约/ 为/ 每/ 时钟/ 周期/ 1/ 字节/ ./ 因此/ ,/ 处理/ 完成/ 一个/ 加速/ 请求/ 大约/ 需要/ 1200/ 个/ 时钟/ 周期/ ./ 因为/ 在/ WSP/ 中写/ 回/ 8/ 个/ Cache/ 行/ (/ 64Bytes/ )/ 需要/ 花费/ 300/ 个/ 时钟/ 周期/ ,/ 所以/ 写回/ 5892/ 个/ 字节/ 的/ 输出/ 结果/ 需要/ 3452/ 个/ 时钟/ 周期/ ./ 对于/ 一次/ 状态/ 切换/ ,/ 我们/ 需要/ 1464/ 个/ 时钟/ 周期/ 来/ 加载/ 2.5/ KB/ 的/ 状态/ 信息/ ./ 基于/ 服从/ 泊松/ 分布/ 的/ M/ // M/ // 1/ 的/ 排队/ 论/ 模型/ ,/ 我们/ 生成/ 了/ 多组/ 不同/ 到达/ 速率/ 以及/ 多种/ 并发流/ 数/ (/ 从/ CS/ =/ 8/ 到/ CS/ =/ 2048/ )/ 的/ 模拟/ 网络/ 流/ ,/ 用来/ 研究/ 在/ 不同/ 的/ ORT/ 和/ SLT/ 大小/ 以及/ 传统/ FIFO/ 下/ 处理/ 性能/ ./ 4.1/ 吞吐/ 率/ 优化/ 我们/ 首先/ 分析/ 了/ ORT/ 从/ 只有/ 1/ 个/ 表项/ (/ FIFO/ )/ 到/ 有/ 128/ 个/ 表项/ 的/ 情况/ ,/ 从而/ 得到/ 在/ 各种/ 不同/ 配置/ 下/ 可以/ 进行/ 重/ 排序/ 的/ 总/ 次数/ ,/ 如图/ 5/ 所示/ ./ FIFO/ 意味着/ 只有/ 相邻/ 到达/ 的/ 两个/ CRB/ 恰好/ 是/ 来自/ 同一/ 网络/ 流/ 的/ 时候/ ,/ 才/ 不/ 需要/ 加速器/ 切换/ 状态/ ./ 随着/ CS/ 的/ 增加/ ,/ 相同/ 的/ 窗口/ 大小/ 下/ ,/ 可以/ 重/ 排序/ 的/ 次数/ 是/ 逐渐/ 减少/ 的/ ./ 同时/ ,/ 随着/ 窗口/ 大小/ 的/ 增加/ ,/ 可以/ 重/ 排序/ 的/ 数量/ 是/ 逐渐/ 增加/ 的/ ./ 在/ 某些/ 情况/ 下/ ,/ 可重/ 排序/ 的/ CRB/ 数量/ 能/ 达到/ 总/ CRB/ 数量/ 的/ 90/ %/ ,/ 这/ 也/ 反映/ 了/ 请求/ 重/ 排序/ 技术/ 具有/ 较大/ 的/ 优化/ 空间/ ./ 图/ 6/ 给出/ 了/ 仅/ 使用/ ORR/ 技术/ 的/ 解压缩/ 加速器/ 得到/ 的/ 吞吐/ 率/ 优化/ 结果/ ./ 随着/ 重/ 排序/ 表/ 大小/ 的/ 增加/ ,/ 吞吐/ 率/ 最大/ 可以/ 提高/ 26.7/ %/ ./ 当/ CS/ 远大于/ 窗口/ 大小/ 的/ 时候/ ,/ 最差/ 的/ 情况/ (/ CS/ =/ 2048/ )/ 将/ 获得/ 2/ %/ 的/ 吞吐/ 率/ 提升/ ./ 图/ 6/ 相对/ 传统/ FIFO/ 、/ ORR/ 对/ 硬件/ 解压缩/ 吞吐/ 率/ 的/ 提升/ 根据/ 参考文献/ [/ 6/ ]/ 中/ 所/ 收集/ 的/ 大量/ 来自/ 热门/ 门户网站/ 的/ 网页/ 测试/ 集/ ,/ 单个/ 网页/ 压缩/ 后/ 的/ 平均/ 长度/ 大约/ 为/ 7/ 个/ 网络/ 包/ ,/ 因此/ 我们/ 设置/ 槽/ 数为/ 10/ ,/ 既/ 能/ 满足/ 基本/ 需求/ ,/ 也/ 便于/ 展示/ 我们/ 的/ 设计/ ./ 本文/ 后续/ 实验/ 中/ CRB/ 组/ 的/ 槽/ 数/ 都/ 设置/ 为/ 10/ ./ 我们/ 将/ ORT/ 的/ 大小/ 固定/ 为/ 128/ ,/ 并且/ 设定/ SLT/ 的/ 大小/ 在/ 128/ ~/ 512/ 个/ 表项/ 之间/ 变化/ ,/ 以/ 观察/ 溢出/ 队列/ 在/ 使用/ SRL/ 之后/ 的/ 效果/ ./ 图/ 7/ 表明/ ,/ 采用/ SRL/ 技术/ 之后/ ,/ 吞吐/ 率/ 得到/ 了/ 提高/ ,/ 尤其/ 是/ 随着/ CS/ 增加/ 的/ 时候/ 将/ 更加/ 明显/ ./ 当/ 并发流/ 数/ 小于/ 或/ 等于/ SLT/ 大小/ 的/ 时候/ ,/ 这种/ 机制/ 非常/ 有效/ ,/ 带来/ 了/ 超过/ 20/ %/ 的/ 性能/ 提高/ ;/ 当/ 并发流/ 数/ 4/ 倍/ 于/ SLT/ 表大/ 小时/ ,/ 相对/ FIFO/ ,/ 我们/ 仍然/ 得到/ 了/ 7.2/ %/ 的/ 性能/ 提升/ ./ 图/ 7/ 相对/ 传统/ FIFO/ ,/ SRL/ 对/ 硬件/ 解压缩/ 吞吐/ 率/ 的/ 提升/ 除了/ 解压缩/ 加速器/ 之外/ ,/ 我们/ 也/ 分析/ 了/ IBMWSP/ 处理器/ 中/ 的/ 其它/ 几种/ 硬件/ 加速器/ ,/ 如表/ 2/ 所/ ①/ DeutschLP/ ./ RFC1951/ :/ DeflateCompressedDataFormatPage7/ 示/ ,/ 我们/ 给出/ 了/ 请求/ 重/ 排序/ 的/ 峰值/ 吞吐/ 率/ 收益/ ./ 这里/ 给出/ 的/ 峰值/ 依据/ 各种/ 不同/ 配置/ 下/ 所/ 观察/ 到/ 的/ 最大/ 性能/ 收益/ ,/ 包括/ (/ CS/ =/ 8/ ,/ ORT/ =/ 64/ )/ ,/ (/ CS/ =/ 32/ ,/ ORT/ =/ 256/ )/ 和/ (/ CS/ =/ 128/ ,/ SLT/ =/ 256/ )/ ./ 其中/ ,/ 加解密/ 加速器/ 的/ 吞吐/ 率/ 收益/ 大约/ 只有/ 4/ %/ ./ 这/ 是因为/ 加解密/ 加速器/ 的/ 状态/ 信息/ 一般/ 最/ 多/ 只有/ 64Bytes/ ,/ 其/ 状态/ 切换/ 开销/ 相比/ 处理/ 时间/ 来说/ 并/ 不是/ 限制/ 吞吐/ 率/ 的/ 关键因素/ ./ 加速器/ 解压缩/ XMLRegX/ 加解密/ 4.2/ 响应/ 时间/ 优化/ 本节/ 将/ 评估/ 请求/ 重/ 排序/ 对/ 平均/ 和/ 最大/ 响应/ 时间/ 的/ 收益/ ./ 在/ 很多/ 应用/ 中/ ,/ 响应/ 时间/ 是/ 应用程序/ 性能/ 的/ 关键因素/ ./ 一些/ 对/ 响应/ 时间/ 敏感/ 的/ 应用/ ,/ 例如/ 入侵/ 检测/ ,/ 我们/ 可能/ 无法/ 让/ 加速器/ 运行/ 在/ 最大/ 的/ 服务/ 速率/ 上/ ./ 基于/ 已经/ 生成/ 的/ 模拟/ 网络/ 流/ ,/ 我们/ 提高/ 请求/ 到达/ 速率/ λ/ 并且/ 评估/ 加速器/ 在/ 不同/ λ/ 下/ 的/ 平均/ 响应/ 时图/ 8/ γ/ 对/ 平均/ 响应/ 时间/ 的/ 影响/ 间/ ./ 我们/ 把/ 平均/ 响应/ 时间/ 作为/ 归一化/ 负载/ γ/ 的/ 一个/ 函数/ ,/ 其中/ μ/ FIFO/ 表示/ 在/ 没有/ 重/ 排序/ 的/ 情况/ 下/ 的/ 平均/ 服务/ 速率/ ,/ 这里/ 的/ γ/ =/ λ/ 的/ 服务/ 速率/ 进行/ 归一化/ ./ 我们/ 分别/ 研究/ 了/ 并发流/ 数为/ 128/ 、/ 512/ 和/ 2048/ 时/ 平均/ 响应/ 时间/ 的/ 情况/ ./ 图/ 8/ (/ a/ )/ 、/ 8/ (/ b/ )/ 、/ 8/ (/ c/ )/ 分别/ 显示/ 了/ 对于/ 不同/ 配置/ 的/ ORT/ 和/ SLT/ ,/ 归一化/ 负载/ (/ γ/ )/ 带给/ 平均/ 响应/ 时间/ 的/ 影响/ ./ 图/ 8/ (/ a/ )/ ,/ 当/ 并发流/ 数/ 比较/ 低/ (/ CS/ =/ 128/ )/ 时/ ,/ 在/ 归一化/ 负载/ γ/ 到达/ 0.8/ 之前/ ,/ 平均/ 响应/ 时间/ 上/ 基本上/ 没有/ 收益/ ./ 在/ γ/ >/ 0.8/ 之后/ ,/ 增加/ ORT/ 和/ SLT/ 的/ 大小/ 才/ 会/ 得到/ 收益/ ,/ 例如/ γ/ =/ 0.95/ 的/ 情况/ 下/ ,/ ORT/ =/ 128/ 在/ 所有/ 的/ SLT/ 配置/ 下/ 平均/ 响应/ 时间/ 都/ 减少/ 了/ 50/ %/ ./ 更大/ 的/ SLT/ 使得/ 在/ γ/ >/ 1.0/ 时/ 平均/ 响应/ 时间/ 获得/ 更/ 多/ 收益/ ,/ 例如/ 当/ γ/ =/ 1.2/ 时/ ,/ 在/ ORT/ 项数/ 为/ 128/ 的/ 条件/ 下/ ,/ SLT/ =/ 512/ 使得/ 平均/ 响应/ 时间/ 减少/ 了/ 36/ %/ ./ 图/ 8/ (/ b/ )/ 为/ 中等/ 并发/ 规模/ (/ CS/ =/ 512/ )/ ,/ 尽管/ 可以/ 观察/ 到/ 平均/ 响应/ 时间/ 的/ 减少/ ,/ 但是/ 单独/ 的/ ORT/ 基本上/ 没有/ 效果/ ./ 而/ 当/ γ/ >/ 1.05/ 时/ ,/ 可以/ 观察/ 到/ SLT/ =/ 512/ 时使/ 平均/ 响应/ 时间/ 减少/ 了/ 12/ %/ ./ 图/ 8/ (/ c/ )/ 显示/ 了/ 高/ 并发/ 的/ 情况/ (/ CS/ =/ 2048/ )/ ,/ Page8/ 我们/ 发现/ γ/ </ 0.95/ 时/ ,/ 没有/ 任何/ 的/ 收益/ ./ 在/ γ/ =/ 1.0/ 时/ ,/ 我们/ 观察/ 到/ 对于/ 所有/ 的/ ORT/ 和/ SLT/ 配置/ 都/ 使/ 平均/ 响应/ 时间/ 减少/ 了/ 31/ %/ ./ 而/ 当/ γ/ =/ 1.2/ 时/ ,/ 平均/ 响应/ 时间/ 减少/ 了/ 10/ %/ ./ 这个/ 结果表明/ ,/ 如果/ 并发流/ 数/ 高于/ ORT/ 或者/ SLT/ 的/ 大小/ ,/ 我们/ 的/ 方法/ 所/ 获得/ 的/ 平均/ 响应/ 时间/ 收益/ 将会/ 减少/ ./ 对于/ 最大/ 响应/ 时间/ ,/ 我们/ 也/ 研究/ 了/ 并发流/ 数为/ 128/ 、/ 512/ 和/ 2048/ 的/ 情况/ ./ 图/ 9/ (/ a/ )/ 、/ 9/ (/ b/ )/ 、/ 9/ (/ c/ )/ 分别/ 显示/ 了/ 对于/ 不同/ 配置/ 的/ ORT/ 和/ SLT/ ,/ 归一化/ 负载/ (/ γ/ )/ 带给/ 最大/ 响应/ 时间/ 的/ 影响/ ./ 图/ 9/ (/ a/ )/ ,/ 当/ 并发流/ 数/ 比较/ 低/ (/ CS/ =/ 128/ )/ 时/ ,/ 在/ 归一化/ 负载/ γ/ 到达/ 0.8/ 之前/ ,/ 最大/ 响应/ 时间/ 上/ 基本/ 没有/ 收益/ ./ 在/ γ/ >/ 0.8/ 之后/ ,/ 增加/ ORT/ 和/ SLT/ 的/ 大小/ 才/ 会/ 得到/ 收益/ ,/ 例如/ γ/ =/ 1/ 的/ 情况/ 下/ ,/ ORT/ =/ 128/ 在/ 所有/ 的/ SLT/ 配置/ 下/ 最大/ 响应/ 时间/ 都/ 减少/ 了/ 68.6/ %/ ./ 更大/ 的/ SLT/ 使得/ 在/ γ/ >/ 1.0/ 时/ 最大/ 响应/ 时间/ 获得/ 更/ 多/ 收益/ ,/ 例如/ 当/ γ/ =/ 1.2/ 时/ ,/ 图/ 9/ γ/ 对/ 最大/ 响应/ 时间/ 的/ 影响/ 在/ 响应/ 时间/ 方面/ ,/ 我们/ 还/ 没有/ 在/ 其它/ 的/ 加速器/ 上/ 进行/ 分析/ ,/ 但是/ 我们/ 预期/ 其它/ 几种/ 加速器/ 上/ 的/ 收益/ 会/ 少于/ 解压缩/ 的/ 加速器/ ./ 我们/ 会/ 在/ 将来/ 的/ 工作/ 中/ 对/ 其/ 进行/ 实现/ 和/ 评估/ ./ 在/ ORT/ 项数/ 为/ 128/ 的/ 条件/ 下/ ,/ SLT/ =/ 512/ 使得/ 最大/ 响应/ 时间/ 减少/ 了/ 95/ %/ ./ 图/ 9/ (/ b/ )/ 为/ 中等/ 并发/ 规模/ (/ CS/ =/ 512/ )/ ,/ 尽管/ 可以/ 观察/ 到/ 最大/ 响应/ 时间/ 的/ 减少/ ,/ 但是/ 单独/ 的/ ORT/ 效果/ 不/ 明显/ ./ 而/ 当/ γ/ >/ 1.05/ 时/ ,/ 可以/ 观察/ 到/ SLT/ =/ 512/ 时使/ 最大/ 响应/ 时间/ 减少/ 了/ 91/ %/ ./ 图/ 9/ (/ c/ )/ 显示/ 了/ 高/ 并发/ 的/ 情况/ (/ CS/ =/ 2048/ )/ ,/ 我们/ 发现/ γ/ </ 1/ 时/ ,/ 基本/ 没有/ 收益/ ./ 在/ γ/ =/ 1.05/ 时/ ,/ 我们/ 观察/ 到/ 所有/ ORT/ =/ 128/ 的/ 配置/ 都/ 使/ 最大/ 响应/ 时间/ 减少/ 了/ 40.8/ %/ ./ 而/ 当/ γ/ =/ 1.2/ 时/ ,/ SLT/ =/ 512/ 的/ 配置/ 使得/ 最大/ 响应/ 时间/ 减少/ 了/ 26.9/ %/ ,/ 而/ 其它/ 的/ 几种/ 配置/ 的/ 收益/ 都/ 不/ 明显/ ./ 这个/ 结果表明/ ,/ 如果/ 并发流/ 数/ 高于/ ORT/ 或者/ SLT/ 的/ 大小/ ,/ 我们/ 的/ 方法/ 所/ 获得/ 的/ 最大/ 响应/ 时间/ 收益/ 将会/ 减少/ ./ 从图/ 9/ 的/ 上/ 可以/ 看出/ ,/ 尽管/ 重/ 排序/ 可能/ 会/ 影响/ 到/ 某些/ 网络/ 流/ 的/ 请求/ 延迟/ ,/ 但是/ 由于/ 减少/ 了/ 最大/ 响应/ 时间/ ,/ 在/ 总体/ 上/ ,/ 重/ 排序/ 的/ 方法/ 并/ 不会/ 对/ 请求/ 延迟/ 造成/ 很大/ 影响/ ./ 5/ 结论/ 和/ 下/ 一步/ 的/ 工作/ 本文/ 提出/ 了/ 对/ 硬件/ 加速器/ 请求/ 重/ 排序/ 的/ 方法/ ,/ Page9/ 同时/ 对片/ 上/ 和/ 片外/ 存储/ 的/ 队列/ 进行/ 优化/ ,/ 可以/ 显著/ 减少/ 有/ 状态/ 加速器/ 状态/ 切换/ 的/ 开销/ ,/ 从而/ 减少/ 处理器/ 的/ 响应/ 时间/ 并/ 增加/ 其/ 吞吐/ 率/ ./ 实验/ 结果表明/ ,/ 与/ 传统/ 的/ FIFO/ 设计/ 对比/ ,/ 解压缩/ 加速器/ 的/ 吞吐/ 率/ 最大/ 提高/ 了/ 26.7/ %/ ,/ 响应/ 时间/ 最大/ 减少/ 了/ 50/ %/ ./ 实验/ 结果/ 还/ 表明/ ,/ 并发/ 网络/ 流数/ 大于/ SLT/ 表/ 的/ 容量/ 时/ ,/ 优化/ 效果/ 将会/ 减小/ ./ 重/ 排序/ 方法/ 可能/ 会/ 改变/ 某些/ CRB/ 的/ 响应/ 时间/ ,/ 从而/ 影响/ 某些/ 网络/ 流/ 的/ 请求/ 延迟/ ,/ 造成/ 不/ 公平/ 现象/ ,/ 对于/ 这个/ 问题/ ,/ 我们/ 将/ 在/ 下/ 一步/ 的/ 工作/ 中/ 通过/ 限制/ 重/ 排序/ 的/ 时间跨度/ 来/ 使/ 这个/ 影响/ 降到/ 可/ 承受/ 的/ 范围/ 之内/ ,/ 但/ 仅/ 从/ 本文/ 中/ 给出/ 的/ 最大/ 响应/ 时间/ 来看/ ,/ 与/ 无重/ 排序/ 的/ 方法/ 相比/ ,/ 在/ 相同/ 最大/ 响应/ 时间/ 要求/ 的/ 前提/ 下/ ,/ 重/ 排序/ 已经/ 可以/ 提供/ 更/ 高/ 的/ 处理/ 能力/ ./ 

