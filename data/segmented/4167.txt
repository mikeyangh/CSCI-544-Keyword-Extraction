Page1/ 面向/ 人机接口/ 的/ 多种/ 输入/ 驱动/ 的/ 三维/ 虚拟/ 人头/ 1/ )/ (/ 语音/ 及/ 语言/ 信息处理/ 国家/ 工程/ 实验室/ 合肥/ 230027/ )/ 於/ 俊/ 1/ )/ ,/ 2/ )/ 汪增福/ 1/ )/ ,/ 2/ )/ ,/ 3/ )/ 2/ )/ (/ 中国/ 科学技术/ 大学/ 自动化系/ 合肥/ 230027/ )/ 3/ )/ (/ 中国科学院/ 合肥/ 智能/ 机械/ 研究所/ 合肥/ 230031/ )/ 摘要/ 面向/ 人机接口/ 领域/ ,/ 文中/ 提出/ 了/ 一个/ 可/ 由/ 多种/ 输入/ 驱动/ 的/ 三维/ 虚拟/ 人头/ 系统/ ./ 该/ 系统/ 具有/ 如下/ 特性/ :/ (/ 1/ )/ 由/ 视频/ 、/ 文本/ 和/ 语音/ 多种/ 输入/ 驱动/ ,/ 增加/ 了/ 与/ 人/ 交互/ 的/ 多样性/ ;/ (/ 2/ )/ 在/ 粒子/ 滤波/ 框架/ 下/ 根据/ 在线/ 外观/ 模型/ 跟踪/ 视频/ 中/ 的/ 人脸/ 三维/ 运动/ ,/ 并且/ 融合/ 多种/ 观测/ 信息/ 来/ 降低/ 在线/ 外观/ 模型/ 的/ 光照/ 敏感性/ 和/ 个体/ 相关性/ ;/ (/ 3/ )/ 参数/ 模型/ 和/ 肌肉/ 模型/ 相结合/ 的/ 三维/ 人脸/ 动画/ ,/ 在/ 保持/ 生理/ 结构/ 的/ 基础/ 上/ 描述/ 人脸/ 运动/ ,/ 进而/ 达到/ 高/ 真实感/ ,/ 同时/ 大大降低/ 了/ 计算/ 量/ ;/ (/ 4/ )/ 在/ 保持/ 正确率/ 的/ 前提/ 下/ ,/ 采用/ 三音子/ 模型/ 降低/ 了/ 可视化/ 协同/ 发音/ 模型/ 的/ 计算/ 复杂度/ ./ 对/ 该/ 虚拟/ 人头/ 的/ 客观/ 和/ 主观/ 测试/ 验证/ 了/ 其/ 在/ 人机交互/ 上/ 的/ 有效性/ ./ 关键词/ 人机接口/ ;/ 虚拟/ 人头/ ;/ 人脸/ 运动/ 跟踪/ ;/ 人脸/ 动画/ 1/ 引言/ 面对面/ 的/ 交流/ 是/ 人类/ 之间/ 的/ 一种/ 可靠/ 和/ 有效/ 的/ 沟通/ 方式/ [/ 1/ ]/ ,/ 因此/ 在/ 人机交互/ 中/ ,/ 采用/ 拟人化/ 的/ 接口/ 会/ 使得/ 交流/ 更加/ 自然/ ,/ 促进/ 人们/ 设计/ 出/ 个性化/ 、/ 富有/ 情感/ 的/ 、/ 符合/ 人类/ 习惯/ 的/ 机器/ ./ 其中/ ,/ 视频/ 、/ 文本/ 和/ 语音/ 多/ 驱动/ 的/ 三维/ 虚拟/ 人头/ (/ 3DVirtualHead/ ,/ Page23DVH/ )/ 相比/ 于/ 机器人/ 头/ ,/ 具有/ 如下/ 特点/ :/ (/ 1/ )/ 易于/ 调整结构/ ;/ (/ 2/ )/ 更改/ 外貌/ 和/ 行为/ 更加/ 直接/ ;/ (/ 3/ )/ 设计/ 自由度/ 和/ 可扩展性/ 更大/ ./ 另外/ ,/ 国内外/ 语音/ 产业化/ 企业/ 近年/ 在/ 语音/ 合成/ 、/ 识别/ 和/ 评测/ 等/ 领域/ 取得/ 了/ 令人瞩目/ 的/ 成绩/ ./ 但/ 也/ 存在/ 着/ 人机交互/ 界面/ 过于/ 单调/ (/ 只有/ 语音/ 输出/ )/ 的/ 问题/ ,/ 这/ 是因为/ 人类/ 在/ 面对面/ 交流/ 的/ 时候/ ,/ 不仅/ 听到/ 声音/ 而且/ 还/ 可以/ 观察/ 到/ 对方/ 的/ 面部/ 运动/ 来/ 辅助/ 理解/ ./ 鉴于/ 上述/ 原因/ ,/ 构建/ 人机/ 实时/ 自然/ 交互/ 的/ 3DVH/ 系统/ 是/ 极具/ 意义/ 的/ 研究课题/ ./ 3DVH/ 的/ 设计/ 分为/ 从/ 人脸/ 运动/ 行为/ 出发/ 的/ 方法/ 和/ 从/ 人脸/ 生理/ 结构/ 出发/ 的/ 方法/ ./ Cole/ 等/ 人/ [/ 2/ ]/ 对/ 这/ 两/ 方面/ 的/ 工作/ 以及/ 它们/ 的/ 结合/ 进行/ 了/ 详细/ 的/ 阐述/ ,/ 并/ 指出/ 将/ 两者/ 的/ 优点/ 相结合/ 是/ 未来/ 发展/ 的/ 方向/ ./ Simmons/ 等/ 人/ [/ 3/ ]/ 介绍/ 了/ 3DVH/ 在/ 机器人/ 头/ 辅助设计/ 方面/ 的/ 工作/ ,/ 并/ 指出/ 3DVH/ 的/ 设计/ 方法/ 和/ 机器人/ 头/ 的/ 设计/ 方法/ 是/ 相互促进/ 、/ 最终/ 可以/ 统一/ 的/ ./ 进一步/ ,/ 在/ 机器人/ 的/ 真实感/ 与/ 人/ 对/ 它/ 的/ 接受度/ 之间/ 的/ 关系/ 上/ ,/ 心理学/ 中/ 的/ 恐怖/ 谷/ 理论/ [/ 4/ -/ 7/ ]/ (/ 图/ 1/ )/ 指出/ :/ 随着/ 机器人/ 与/ 人类/ 在/ 外表/ 、/ 动作/ 上/ 逼真度/ 的/ 增加/ ,/ 人类/ 也/ 随之/ 增加/ 对/ 它/ 的/ 好感度/ ,/ 但/ 至/ 某个/ 程度/ (/ 称为/ 恐怖/ 谷/ )/ 人类/ 会/ 突然/ 变得/ 极其/ 反感/ (/ 比如/ ,/ 虽然/ 死尸/ // 僵尸/ 比/ 毛绒/ 娃娃/ 更/ 像/ 人类/ ,/ 但/ 人类/ 明显/ 反感/ 前者/ 而/ 喜爱/ 后者/ )/ ./ 可是/ 当/ 逼真度/ 继续/ 上升/ 的/ 时候/ ,/ 人类/ 对/ 它/ 的/ 反应/ 亦/ 会/ 变回/ 好感/ ,/ 且/ 比/ 进入/ 恐怖/ 谷前/ 的/ 程度/ 更强/ ./ 同样/ 地/ ,/ 构建/ 高/ 真实感/ 的/ 3DVH/ 使/ 之/ 能够/ 跨越/ 恐怖/ 谷是/ 3DVH/ 研究/ 追求/ 的/ 目标/ 之一/ ./ (/ 1/ )/ 三维/ 人脸/ 动画/ 因为/ 人脸/ 生理/ 结构/ 的/ 复杂性/ 、/ 表情/ 的/ 丰富性/ 和/ 明显/ 的/ 个性化/ 特点/ ,/ 要/ 想/ 快速/ 、/ 逼真/ 地/ 生成/ 三维/ 人脸/ 动画/ 仍然/ 是/ 非常/ 困难/ 的/ ./ 第/ 1/ 步是/ 人脸/ 模型/ 特定/ 化/ ./ 它/ 可/ 通过/ 扫描仪/ [/ 8/ ]/ 、/ 多/ 视角/ 图像/ [/ 9/ ]/ 、/ 视频/ [/ 10/ ]/ 或/ 单幅/ 图像/ [/ 11/ ]/ 来/ 完成/ ./ 这些/ 方法/ 都/ 有/ 独特/ 的/ 优势/ ,/ 其中/ 基于/ 单幅/ 图像/ 的/ 方法/ 因/ 其/ 便捷性/ 是/ 目前/ 研究/ 的/ 热点/ ,/ 但/ 其/ 得到/ 的/ 人脸/ 模型/ 只有/ 正面/ 纹理/ ,/ 而/ 侧面/ 纹理/ 对/ 后续/ 人脸/ 动画/ 是/ 至关重要/ 的/ ./ 基于/ 单幅/ 图像/ 的/ 方法/ 进一步/ 可/ 分为/ 基于/ 几何/ 变形/ 的/ 和/ 基于/ 学习/ 的/ ./ 前者/ 通过/ 变形/ 人脸/ 通用/ 模型/ 得到/ 描述/ 输入/ 正面/ 人脸/ 图像/ 的/ 特定/ 模型/ ,/ 简单/ 有效/ ,/ 但/ 需要/ 精确定位/ 图像/ 上/ 的/ 人脸/ 特征/ 点/ 以及/ 足够/ 灵活/ 的/ 插值/ 算法/ ;/ 后者/ 运用/ 统计分析/ 方法/ 从/ 人脸/ 库/ 重建/ 出/ 期望/ 人脸/ ,/ 真实感/ 较强/ ,/ 但/ 其/ 重建/ 结果/ 受限于/ 人脸/ 库/ 的/ 泛化/ 性能/ 和/ 质量/ ,/ 且/ 所/ 需/ 代价/ 昂贵/ ./ 第/ 2/ 步是/ 人脸/ 运动/ 控制/ 建模/ [/ 12/ -/ 13/ ]/ ./ 参数/ 模型/ [/ 14/ ]/ 快速/ 有效/ ,/ 但/ 难以达到/ 高/ 真实感/ ;/ 通过/ 模拟/ 人脸/ 动力学/ 特性/ 的/ 物理/ 模型/ [/ 15/ ]/ 真实感/ 较强/ ,/ 但/ 计算/ 和/ 设置/ 复杂/ ;/ 通过/ 统计分析/ 学习/ 人脸/ 运动/ 规律/ 的/ 数据/ 驱动/ 模型/ [/ 11/ ]/ 受限于/ 训练/ 库/ 的/ 泛化/ 性能/ ;/ 基于/ 人脸/ 生理/ 知识/ 的/ 肌肉/ 模型/ [/ 16/ -/ 17/ ]/ 是/ 一种/ 从/ 本质/ 上/ 表示/ 人脸/ 运动/ 的/ 方法/ ,/ 但/ 建模/ 复杂度/ 和/ 真实感/ 有待/ 改进/ ./ (/ 2/ )/ 基于/ 视频/ 的/ 人脸/ 三维/ 运动/ 跟踪/ 基于/ 视频/ 的/ 人脸/ 三维/ 运动/ 跟踪/ 是从/ 已经/ 获得/ 的/ 前/ 一帧/ 的/ 人脸/ 运动/ 参数/ 出发/ ,/ 根据/ 当前/ 帧/ 的/ 图像/ 信息/ 、/ 人脸/ 三维/ 模型/ 、/ 人脸/ 先验/ 知识/ 、/ 滤波/ 算法/ 以及/ 跟踪/ 中/ 获得/ 的/ 知识/ ,/ 得到/ 当前/ 帧/ 的/ 人脸/ 运动/ 参数/ ./ 基于/ 特征/ 的/ 方法/ [/ 18/ ]/ 会/ 累积/ 估计/ 误差/ 进而/ 发散/ ,/ 故需/ 增加/ 多种/ 措施/ [/ 19/ -/ 22/ ]/ 来/ 提高/ 鲁棒性/ ./ 基于/ 外观/ 模型/ 的/ 方法/ 没有/ 发散/ 问题/ ,/ 它/ 分为/ 确定性/ 的/ 和/ 统计/ 性/ 的/ ./ 前者/ [/ 23/ -/ 24/ ]/ 通过/ 对/ 确定性/ 的/ 参考/ 纹理/ 进行/ 几何/ 变形/ 来/ 匹配/ 当前/ 帧/ ,/ 从而/ 难以/ 应付/ 光照/ 和/ 表情/ 变化/ 下/ 的/ 情况/ ./ 后者/ 也/ 分为/ 离线/ 的/ 和/ 在线/ 的/ ./ 离线/ 方法/ [/ 25/ -/ 27/ ]/ 鲁棒性/ 强/ ,/ 但/ 无法/ 适应/ 训练/ 库中/ 没有/ 的/ 新/ 情况/ ./ 在线/ 方法/ [/ 28/ -/ 30/ ]/ 不/ 需要/ 训练/ 库/ ,/ 故/ 更/ 有/ 优势/ ,/ 但/ 如何/ 在线/ 更新/ 模型/ 以/ 应对/ 光照/ 、/ 个体/ 相关性/ 的/ 影响/ 是/ 难点/ [/ 31/ -/ 34/ ]/ ./ 进一步/ ,/ 对于/ 非线性/ 、/ 非/ 高斯分布/ 的/ 人脸/ 运动/ ,/ 粒子/ 滤波/ [/ 32/ ]/ 得到/ 了/ 广泛应用/ ,/ 但/ 也/ 面临/ 着/ 计算/ 盲目/ 、/ 计算/ 量/ 大/ 和/ 粒子/ 退化/ 等/ 问题/ 的/ 挑战/ ./ (/ 3/ )/ 连续/ 人脸/ 语音/ 动画/ 连续/ 人脸/ 语音/ 动画/ 区别/ 一般/ 人脸/ 动画/ 的/ 最/ 主要/ 一点/ 是/ ,/ 当前/ 口型/ 既受/ 当前/ 发音/ 的/ 影响/ 又/ 受/ 前后/ 发音/ 的/ 影响/ ./ 该/ 现象/ 称为/ 可视化/ 协同/ 发音/ ./ 对/ 该/ 现象/ 的/ 建模/ 是/ 制约/ 连续/ 人脸/ 语音/ 动画/ 达到/ 高/ 真实感/ 的/ 重要/ 瓶颈/ [/ 35/ -/ 36/ ]/ ./ 针对/ 于/ 此/ ,/ Cohen/ 模型/ [/ 37/ ]/ 基于/ 发音器官/ 状态/ 模型/ [/ 38/ ]/ 提出/ 了/ 权值/ 融合/ 的/ 思想/ ,/ 但/ 参数设置/ 复杂/ ;/ Bregler/ 等/ 人/ [/ 39/ ]/ 利用/ 上下文/ 相关/ 的/ 音素/ 模型/ 寻找/ 图像/ 数据库/ 中/ 当前/ 音素/ 最/ 匹配/ 的/ 发音器官/ 运动/ ,/ 但/ 代价/ 较大/ ;/ Pelachaud/ 等/ 人/ [/ 40/ ]/ 建立/ 规则/ 集来/ 描述/ 协同/ 发音/ ,/ 但/ 适用范围/ 有限/ ./ Page32/ 系统/ 框架/ 本文/ 面向/ 人机接口/ 研究/ 领域/ ,/ 提出/ 了/ 一个/ 视频/ 、/ 文本/ 和/ 语音/ 多种/ 输入/ 驱动/ 的/ 3DVH/ 系统/ (/ 图/ 2/ )/ :/ (/ 1/ )/ 建立/ 参数/ 模型/ 与/ 肌肉/ 模型/ 相结合/ 的/ 三维/ 人脸/ 动画/ 算法/ ;/ (/ 2/ )/ 当/ 输入/ 视频/ 时/ ,/ 首先/ 提取/ 多种/ 观测/ 量/ (/ Multi/ -/ Measurements/ ,/ MM/ )/ ,/ 接着/ 在/ 粒子/ 滤波/ (/ ParticleFilter/ ,/ PF/ )/ 框架/ 下/ 根据/ 在线/ 外观/ 模型/ (/ OnlineAppearanceModel/ ,/ OAM/ )/ 从/ 视频/ 中/ 提取/ 出/ 人脸/ 运动/ 参数/ ,/ 然后/ 根据/ 三维/ 人脸/ 动画/ 算法/ ,/ 由/ 人脸/ 运动/ 参数/ 驱动/ 生成/ 人脸/ 动画/ ,/ 并/ 同步/ 播放/ 伴随/ 视频/ 中/ 的/ 语音/ 信息/ ;/ (/ 3/ )/ 当/ 输入/ 文本/ 或/ 语音/ 时/ ,/ 首先/ 根据/ 文语/ 转换/ 引擎/ (/ MicrosoftTexttoSpeech/ ,/ MS/ -/ TTS/ )/ 或/ 语音/ 识别/ 引擎/ (/ MicrosoftSpeechRecognition/ ,/ MS/ -/ SR/ )/ 输出/ 的/ 发音/ 信息/ ,/ 建立/ 可视化/ 协同/ 发音/ 模型/ (/ VisualCo/ -/ articulationModel/ ,/ VCM/ )/ ,/ 接着/ 根据/ 三维/ 人脸/ 动画/ 算法/ 合成/ 与/ 发音/ 信息/ 对应/ 的/ 视素/ ,/ 然后/ 结合/ VCM/ 对视/ 素/ 的/ 影响/ ,/ 由非/ 均匀/ 有理/ B/ 样条/ (/ Non/ -/ UniformRationalB/ -/ Spline/ ,/ NURBS/ )/ 在/ 视素间/ 插值/ 生成/ 人脸/ 动画/ ./ 3/ 从/ 视频/ 中/ 提取/ 人脸/ 三维/ 运动/ 信息/ 因为/ 在线/ 外观/ 模型/ 在/ 不/ 需要/ 额外/ 离线/ 信息/ 等方/ 犫/ =/ [/ 犺/ T/ ,/ β/ T/ ,/ α/ T/ ]/ T/ =/ [/ θ/ x/ ,/ θ/ y/ ,/ θ/ z/ ,/ s/ ,/ tx/ ,/ ty/ ,/ β/ T/ ,/ α/ T/ ]/ T/ (/ 1/ )/ 其中/ ,/ 犺/ =/ [/ θ/ x/ ,/ θ/ y/ ,/ θ/ z/ ,/ s/ ,/ tx/ ,/ ty/ ]/ T/ 是/ 全局/ 刚体/ 运动/ 参数/ ,/ β/ 和/ α/ 是/ 形状/ 、/ 局部/ 运动/ 参数/ ./ 面有/ 独特/ 优势/ ,/ 在/ 此/ ,/ 我们/ 深入/ 挖掘/ 它/ 的/ 潜力/ ./ 3.1/ 用于/ 人脸/ 运动/ 跟踪/ 的/ 三维/ 几何/ 模型/ 采用/ CANDIDE3/ [/ 41/ ]/ 三维/ 模型/ (/ 图/ 3/ (/ a/ )/ )/ ./ 该/ 模型/ 由/ 以下/ 人脸/ 运动/ 参数/ 来/ 控制/ :/ (/ 其中/ (/ a/ )/ 为/ CANDIDE3/ 模型/ ;/ (/ b/ )/ ~/ (/ e/ )/ 为/ GNFI/ 的/ 获取/ 过程/ )/ 3.2/ 提取/ 多种/ 观测/ 量/ 观测/ 量/ 从/ 对应/ 于/ 输入/ 人脸/ 图像/ 的/ 几何/ 归一化/ 人脸/ 图像/ (/ GeometricalNormalizedFacialImage/ ,/ GNFI/ )/ [/ 25/ ]/ 中/ 提取/ (/ 图/ 3/ (/ b/ )/ ~/ (/ e/ )/ )/ ./ 我们/ 首先/ 从/ GNFI/ 中/ 提取/ 颜色/ 值/ 作为/ 观测/ 量/ ,/ 但/ 它/ 易/ 受/ 光照/ 影响/ 且/ 与/ 个体/ 高度/ 相关/ ,/ 因此/ 需要/ 寻找/ 更加/ 鲁棒/ 的/ 观测/ 量/ 作为/ 补充/ ./ 考虑/ 到/ 光照/ 比/ 图像/ [/ 33/ ]/ 和/ Gabor/ 小波/ [/ 42/ ]/ 的/ 优良/ 特性/ ,/ 将/ 当前/ 帧/ 的/ GNFI/ 和/ 首帧/ 的/ GNFI/ 之间/ 的/ 光照/ 比/ 图像/ 的/ Gabor/ 小波/ 变换/ 系数/ 的/ 幅值/ 作为/ 第/ 2/ 部分/ 的/ 观测/ 量/ ./ 3.3/ 构建/ 在线/ 外观/ 模型/ 与/ 融合/ 多种/ 观测/ 量/ 为/ 3/ 个/ 分量/ 的/ 混合/ 高斯/ 模型/ (/ 观测/ 模型/ )/ :/ p/ (/ 狔/ t/ // 犫/ t/ )/ =/ ∏/ dmi/ ,/ t/ (/ j/ )/ =/ (/ 1/ -/ c/ )/ mi/ ,/ t/ -/ 1/ (/ j/ )/ +/ cmi/ ,/ t/ -/ 1/ (/ j/ )/ N/ (/ yt/ -/ 1/ (/ j/ )/ ;/ μ/ s/ ,/ t/ (/ j/ )/ =/ (/ 1/ -/ c/ )/ μ/ s/ ,/ t/ -/ 1/ (/ j/ )/ // ms/ ,/ t/ (/ j/ )/ +/ σ/ 2s/ ,/ t/ (/ j/ )/ =/ (/ 1/ -/ c/ )/ σ/ 2s/ ,/ t/ -/ 1/ (/ j/ )/ // ms/ ,/ t/ (/ j/ )/ +/ 如/ 文献/ [/ 32/ ]/ 中/ 所述/ ,/ 将/ 第/ 1/ 部分/ 观测/ 量/ 狔/ t/ 建模/ 相应/ 外观/ 模型/ 的/ 在线/ 更新/ 方式/ 为/ 对应/ 第/ 2/ 部分/ 观测/ 量/ 犌/ t/ 的/ 处理过程/ 同上/ ./ 最后/ 采用/ 乘法/ 方式/ 来/ 融合/ 多种/ 观测/ 量/ :/ p/ (/ 狔/ t/ // 犫/ t/ )/ ·/ p/ (/ 犌/ t/ // 犫/ t/ )/ ,/ 该/ 融合/ 结果/ 将/ 在/ 粒子/ 滤波/ 中/ 被/ 设为/ 粒子/ 的/ 权重/ ./ 3.4/ 应对/ 遮挡/ 挡/ 的/ 措施/ 分为/ 如下/ 两个/ 阶段/ :/ 借助于/ 人脸/ 三维/ 模型/ 和/ 在线/ 外观/ 模型/ ,/ 应对/ 遮/ 第/ 1/ 阶段/ 是/ 判断/ 遮挡/ ./ 首先/ 计算/ 视线/ 与/ 人脸/ 三维/ 模型/ 中/ 每个/ 3D/ 面片/ 法/ 向量/ 的/ 夹角/ 的/ 余弦/ 值/ ,/ 如果/ 为/ 负则/ 该/ 3D/ 面片/ 被/ 遮挡/ ,/ 否则/ 没有/ 被/ 遮挡/ ./ 第/ 2/ 阶段/ 是/ 处理/ 遮挡/ ./ 当/ 第/ k/ 个/ 3D/ 面片/ 被/ 遮挡/ 时/ ,/ 它/ 对应/ 的/ GNFI/ 中/ 的/ 2D/ 面片/ (/ 图/ 3/ (/ d/ )/ )/ 中/ 的/ 观测/ 量/ 由/ 前/ 一/ 时刻/ 的/ 值/ 和/ 在线/ 外观/ 模型/ 来/ 估计/ :/ y/ (/ j/ )/ 烅/ 烄/ y/ (/ j/ )/ 烆/ Page4/ 当/ 观测/ 量/ 为/ Gabor/ 小波/ 系数/ 时/ ,/ 与/ 上述/ 类似/ ./ 3.5/ 基于/ 改进/ 粒子/ 滤波/ 的/ 运动/ 滤波/ 策略/ 如前所述/ ,/ 粒子/ 滤波/ 在/ 处理/ 非线性/ 非/ 高斯分布/ 的/ 人脸/ 运动/ 上/ 具有/ 独特/ 的/ 优势/ ,/ 但/ 也/ 面临/ 着/ 一些/ 问题/ ./ 鉴于/ 此/ ,/ 本文/ 采取/ 一些/ 有/ 针对性/ 的/ 措施/ ./ 3.5/ ./ 1/ 结合/ 局部优化/ 来/ 降低/ 计算/ 复杂度/ 因为/ 局部优化/ 可以/ 结合/ 当前/ 时刻/ 的/ 最新/ 观测/ 值来/ 生成/ 与/ 真实/ 状态/ 分布/ 产生/ 的/ 粒子/ 偏差/ 较/ 小/ 的/ 粒子/ ,/ 所以/ 在/ 更新/ 粒子/ 权重/ 之前/ 增加/ 局部优化/ 步骤/ 来/ 降低/ 计算/ 盲目性/ :/ 然后/ 设置/ 粒子/ 数目/ 正比/ 于/ 局部优化/ 后/ 得到/ 的/ 误/ 为了/ 应对/ 粒子/ 退化/ 问题/ ,/ 在/ 标准/ 重/ 采样/ 前/ 加入/ 差/ e/ ,/ 从而/ 自/ 适应/ 地/ 降低/ 计算/ 量/ ./ 3.5/ ./ 2/ 基于/ 改进/ 重/ 采样/ 来/ 减少/ 粒子/ 退化/ PERM/ 采样/ [/ 43/ ]/ :/ 如果/ 粒子/ 权值/ π/ (/ j/ )/ a/ 保留/ 粒子/ ,/ 且/ π/ (/ j/ )/ 留/ K/ 次/ ,/ 且/ π/ (/ j/ )/ 进行/ 自/ 适应/ 的/ 调整/ :/ 如果/ 6.1/ ./ 5/ 节/ (/ 1/ )/ 中/ 定义/ 的/ 量化/ 指标/ 小/ 则/ 表示/ 当前/ 保留/ 的/ 粒子/ 是/ 好/ 的/ ,/ 就/ 增大/ a/ 、/ π/ +/ 和/ 减小/ K/ 、/ π/ -/ 来/ 弱化/ PERM/ 采样/ 的/ 作用/ ;/ 否则/ 强化/ PERM/ 采样/ 的/ 作用/ ./ 综上所述/ ,/ 上述/ 改进/ 粒子/ 滤波/ 方法/ 被/ 称为/ LOPSAPF/ (/ LocalizedOptimizationPERMSam/ -/ plingAdaptiveParticleFilter/ )/ ./ 3.6/ 人脸/ 和/ 头发/ 纹理/ 的/ 更新/ 因为/ 侧面/ 纹理/ 对/ 后续/ 人脸/ 动画/ 是/ 至关重要/ 的/ ,/ 所以/ 我们/ 在/ 人脸/ 运动/ 跟踪/ 过程/ 中/ 适时地/ 更新/ 人脸/ 和/ 头发/ 的/ 纹理/ ./ 当/ 跟踪/ 结果/ 中/ 的/ 旋转/ 角/ 大于/ 设定/ 阈值/ 时/ 进行/ 纹理/ 更新/ :/ 首先/ 由/ 人脸/ 三维/ 模型/ 在/ 像/ 平面/ 上/ 的/ 投影/ 来/ 得到/ 人脸/ 外/ 轮廓/ ;/ 其次/ 获得/ 头发/ 外/ 轮廓/ [/ 44/ ]/ ;/ 然后/ 将/ 两个/ 外/ 轮廓/ 组成/ 的/ 闭合/ 区域/ 中/ 的/ 图像/ 作为/ 更新/ 纹理/ ./ 算法/ 流程/ ./ 1/ ./ 根据/ 人脸/ 模型/ 特定/ 化/ 得到/ 的/ 人脸/ 运动/ 参数/ 初始值/ 犫/ 0/ 、/ 先验/ 分布/ p/ (/ 犫/ 0/ )/ 和/ 初始/ 粒子/ 数/ N0/ 来/ 得到/ 初始/ 粒子/ 集合/ S0/ =/ {/ 犫/ (/ j/ )/ 0/ ,/ π/ (/ j/ )/ 2/ ./ 预测/ ./ 基于/ 前/ 一帧/ 的/ 估计值/ 犫/ t/ -/ 1/ ,/ 由/ 局部优化/ 得到/ Δ/ 犫/ t/ ;/ 然后/ 移动/ 粒子/ 犫/ (/ j/ )/ 确定/ 粒子/ 的/ 数量/ Nt/ ;/ 3/ ./ 重/ 采样/ ./ 首先/ PERM/ 采样/ ,/ 接着/ 标准/ 重/ 采样/ ;/ 4/ ./ 由/ 犫/ (/ j/ )/ 5/ ./ 更新/ ./ π/ (/ j/ )/ 6/ ./ 由/ 犫/ t/ =/ ∑/ Nt7/ ./ 更新/ 梯度/ 矩阵/ 、/ 外观/ 模型/ 和/ π/ -/ 、/ π/ +/ 、/ a/ 、/ K/ ;/ 8/ ./ t/ =/ t/ +/ 1/ ,/ 返回/ 步/ 2.4/ 三维/ 人脸/ 动画/ 4.1/ 用于/ 人脸/ 动画/ 的/ 三维/ 几何/ 模型/ 器官/ ,/ 为/ 高/ 真实感/ 人脸/ 动画/ 提供/ 了/ 坚实/ 的/ 基础/ ./ 采用/ Alice/ [/ 45/ ]/ 三维/ 模型/ (/ 图/ 4/ (/ a/ )/ )/ ,/ 包含/ 完整/ 的/ 图/ 4/ 三维/ 人脸/ 几何/ 模型/ (/ 其中/ (/ a/ )/ 是/ Alice/ 模型/ ;/ 4.2/ 基于/ 动态/ 纹理/ 更新/ 的/ 人脸/ 模型/ 特定/ 化/ 综合/ 考虑/ 精度/ 、/ 代价/ 和/ 实时性/ ,/ 采用/ 单幅/ 图像/ 方法/ 中/ 简单/ 有效/ 的/ 几何/ 变形/ 方法/ ,/ 并且/ 针对/ 该/ 方法/ 重建/ 出来/ 的/ 人脸/ 模型/ 只有/ 正面/ 纹理/ 的/ 问题/ ,/ 在/ 视频/ 驱动/ 的/ 人脸/ 动画/ 过程/ 中/ 动态/ 地/ 更新/ 映射/ 到/ 人脸/ 三维/ 模型/ 上/ 的/ 纹理/ 贴图/ ./ 具体/ 过程/ 如下/ ./ 在/ 第/ 1/ 阶段/ ,/ 对于/ 首帧/ 人脸/ 图像/ :/ (/ 1/ )/ 由/ 动态/ 外观/ 模型/ (/ ActiveAppearanceModel/ ,/ AAM/ )/ [/ 26/ ]/ 来/ 确定/ 图像/ 中/ 的/ 特征/ 点/ ;/ (/ 2/ )/ 由/ 数个/ 特征/ 点/ 和/ 文献/ [/ 46/ ]/ 来/ 得到/ 全局/ 运动/ 参数/ ;/ (/ 3/ )/ 特征/ 网格/ 点/ 的/ 位移/ 由/ 对/ 特征/ 点/ 进行/ 最小/ 二乘/ 拟合/ 来/ 得到/ ;/ (/ 4/ )/ 其它/ 网格/ 点/ 的/ 位移/ 由/ 径向/ 基/ 插值/ 来/ 得到/ ./ 在/ 第/ 2/ 阶段/ ,/ 当/ 后续/ 帧/ 产生/ 如/ 3.6/ 节/ 所述/ 的/ 更新/ 纹理/ 的/ 时候/ ,/ 相应/ 地/ 更新/ 映射/ 到/ 人脸/ 三维/ 模型/ 上/ 的/ 纹理/ 贴图/ :/ (/ 1/ )/ 根据/ 当前/ 帧/ 与/ 首帧/ 的/ 人脸/ 全局/ 运动/ 参数/ 的/ 差值/ 将/ 更新/ 纹理/ 变换/ 到/ 首帧/ 的/ 坐标系/ 下/ ;/ (/ 2/ )/ 将/ 变换/ 后/ 的/ 更新/ 纹理/ 和/ 首帧/ 中/ 的/ 纹理/ 的/ 拼接/ 结果/ 作为/ 纹理/ 贴图/ ./ 4.3/ 人脸/ 运动/ 控制/ 建模/ 我们/ 结合/ 参数/ 模型/ 和/ 肌肉/ 模型/ 合成/ 动画/ ./ 前者/ 采用/ 径向/ 基/ 插值/ ,/ 这里/ 不/ 作/ 赘述/ ./ 后者/ 采用/ Waters/ 肌肉/ 模型/ [/ 16/ -/ 17/ ]/ ,/ 该/ 模型/ 根据/ 人脸/ 肌肉/ (/ 图/ 5/ )/ 的/ 运动/ 和/ 方向性/ 特性/ ,/ 建立/ 了/ 相应/ 的/ 向量/ 肌肉/ 模型/ ,/ 是/ 人脸/ 生理/ 动画/ 模型/ 的/ 主流/ 方法/ 之一/ ./ Page5/ 首先/ ,/ 人脸/ 模型/ 的/ 网格/ 点/ 根据/ 脸部/ 器官/ 的/ 运动/ 特征/ 进行/ 分区/ ./ 在/ 各区/ 中/ ,/ 网格/ 点/ 分为/ 3/ 类/ :/ 主/ 特征/ 点/ 、/ 次/ 特征/ 点/ 和/ 非/ 特征/ 点/ ./ 主/ 特征/ 点/ 是/ 与/ MPEG/ -/ 4/ 标准/ 中/ FDP/ 定义/ 的/ 人脸/ 特征/ 点/ 相对/ 应/ 的/ 网格/ 点/ ;/ 次/ 特征/ 点/ 是/ 主/ 特征/ 点/ 所在/ 肌肉/ 模型/ 作用/ 范围/ 内/ 的/ 网格/ 点/ ;/ 非/ 特征/ 点/ 是/ 其它/ 网格/ 点/ ./ 下巴/ 、/ 上/ 嘴唇/ 的/ 功能区/ 及其/ 中/ 的/ 3/ 类/ 网格/ 点如图/ 4/ (/ b/ )/ ~/ (/ c/ )/ 所示/ ./ 在/ 某/ 一/ 分区/ ,/ 首先/ ,/ 主/ 特征/ 点/ 的/ 位移/ 等于/ 相应/ 的/ 人脸/ 运动/ 参数值/ ;/ 然后/ ,/ 次/ 特征/ 点/ 的/ 位移/ 由/ Waters/ 模型/ 根据/ 主/ 特征/ 点/ 的/ 位移/ 来/ 得到/ ;/ 最后/ ,/ 非/ 特征/ 点/ 的/ 位移/ 由/ 径向/ 基/ 插值/ 根据/ 主/ 特征/ 点/ 的/ 位移/ 来/ 得到/ ./ 5/ 三维/ 连续/ 人脸/ 语音/ 动画/ 5.1/ 视频/ 驱动/ 下/ 的/ 人脸/ 语音/ 动画/ 我们/ 根据/ 从/ 视频/ 中/ 提取/ 的/ 人脸/ 运动/ 参数/ 犫/ 以及/ 4.3/ 节/ 的/ 三维/ 人脸/ 动画/ 算法/ 来/ 合成/ 人脸/ 动画/ ,/ 并/ 同步/ 播放/ 伴随/ 视频/ 的/ 音频/ 信息/ ./ 5.2/ 文本/ 或/ 语音/ 驱动/ 下/ 的/ 人脸/ 语音/ 动画/ 在/ 第/ 1/ 阶段/ ,/ 我们/ 合成/ 未/ 采用/ 可视化/ 协同/ 发音/ 模型/ (/ VCM/ )/ 的/ 视素/ ./ 因为/ 合成/ 的/ 视素/ 要/ 真实/ 地/ 反映/ 音素/ 对应/ 的/ 唇部/ 运动/ ,/ 且/ 舌头/ 和/ 牙齿/ 的/ 运动/ 也/ 要/ 与/ 唇/ 型/ 保持一致/ ./ 所以/ 我们/ 根据/ 英语/ 音素/ 和/ 视素/ 的/ 分类/ ①/ 及/ 对应/ 的/ 发音器官/ 运动/ 规律/ 、/ 人脸/ 动作/ 编码/ 系统/ (/ FacialActionCodingSystem/ ,/ FACS/ )/ [/ 41/ ,/ 47/ ]/ 定义/ 的/ 视素/ 对/ 面部/ 肌肉/ 的/ 影响/ 和/ 4.3/ 节/ 的/ 人脸/ 运动/ 控制算法/ 来/ 完成/ ./ 在/ 第/ 2/ 阶段/ ,/ 我们/ 首先/ 基于/ MS/ -/ TTS/ 引擎/ 或/ MS/ -/ SR/ 引擎/ ,/ 从/ 文本/ 或/ 语音/ 中/ 得到/ 发音/ 信息/ (/ 音素/ 序列/ 及时/ 长/ )/ ,/ 然后/ 根据/ 发音/ 信息/ 建立/ VCM/ ./ 在/ 各种/ VCM/ 中/ ,/ Cohen/ 模型/ [/ 37/ ]/ 取得/ 了/ 较/ 好/ 的/ 效果/ ./ 该/ 模型/ 的/ 音素/ 具有/ 相关/ 的/ 人脸/ 动画/ 参数/ 及/ 对应/ 的/ 权值/ 函数/ ,/ 当前/ 视素/ 是/ 发音/ 中/ 所有/ 视素/ 对/ 它/ 的/ 加权/ 融合/ 结果/ ./ 但/ 在/ 实际/ 中/ ,/ 相隔/ 较远/ 的/ 音素/ 对/ 当前/ 音素/ 的/ 影响/ 是/ 可以/ 忽略/ 的/ ./ 鉴于/ 此/ ,/ 采用/ 三音子/ 模型/ 来/ 设计/ 权值/ 函数/ ,/ 即/ 只/ 考虑/ 前/ 一/ 和/ 后/ 一/ 音素/ 为/ 对/ 当前/ 音素/ 的/ 影响/ ,/ 从而/ 降低/ 了/ 计算/ 复杂度/ ./ 设权值/ 函数/ W/ (/ t/ )/ 为/ 三阶/ 多项式/ 函数/ ./ 令/ t/ -/ 1/ 、/ t0/ 、/ t1/ 分别/ 为/ 前/ 一/ 、/ 当前/ 和/ 后/ 一/ 音素/ 的/ 开始/ 时间/ ,/ t2/ 为/ 后/ 一/ 音素/ 的/ 结束/ 时间/ ;/ λ/ 为/ 当前/ 音素/ 在/ (/ t0/ +/ t1/ )/ // 2/ 处/ 的/ 幅度/ ,/ 表示/ 它/ 的/ 协同/ 发音/ 影响/ 程度/ ;/ k/ 为/ 当前/ 音素/ 的/ 扩散/ 程度/ ,/ 表示/ 它/ 的/ 协同/ 发音/ 影响/ 范围/ ./ 据此/ 得到/ W/ (/ t/ )/ 的/ 受限/ 条件/ 为/ (/ 1/ )/ W/ (/ t/ -/ 1/ )/ =/ 0/ ,/ W/ (/ t2/ )/ =/ 0/ ,/ (/ 2/ )/ W/ (/ t/ -/ 1/ )/ =/ 0/ ,/ W/ (/ t2/ )/ =/ 0/ ,/ (/ 3/ )/ W/ (/ (/ t0/ +/ t1/ )/ // 2/ )/ =/ λ/ ,/ (/ 4/ )/ W/ (/ t0/ )/ =/ k/ λ/ ,/ W/ (/ t1/ )/ =/ k/ λ/ ./ 在/ 解得/ 权值/ W/ (/ t/ )/ 后/ ,/ 利用/ 它/ 融合/ 前/ 一/ 、/ 当前/ 和/ 后/ 一/ 音素/ 即/ 得到/ 我们/ 所/ 采用/ 的/ VCM/ :/ 其中/ Fs/ 为/ 未/ 采用/ VCM/ 的/ 视素/ 对应/ 的/ 人脸/ 动画/ 参数/ ./ 对于/ 占/ 支配/ 地位/ 的/ 元音/ 音素/ ,/ λ/ 、/ k/ 为/ 1/ 、/ 0.8/ ;/ 对于/ 占/ 被/ 支配/ 地位/ 的/ 辅音/ 音素/ ,/ λ/ 、/ k/ 为/ 0.1/ 、/ 0.5/ ./ 在/ 得到/ VCM/ 后/ ,/ 我们/ 根据/ 它/ 和/ 第/ 1/ 阶段/ 得到/ 的/ 未/ 采用/ VCM/ 的/ 视/ 素来/ 合成/ 采用/ VCM/ 的/ 视素/ ./ 在/ 第/ 3/ 阶段/ ,/ 考虑/ 到/ 细微/ 的/ 抖动/ 会/ 轻易/ 地被/ 人眼/ 所/ 察觉/ 并/ 产生/ 不/ 自然/ 的/ 感觉/ ,/ 进而/ 抗拒/ 与/ 3DVH/ 的/ 交互/ ./ 我们/ 采用/ 光滑/ 的/ NURBS/ 来/ 插值/ 生成/ 视素/ 之间/ 的/ 过渡/ 动画/ ./ 在/ 第/ 4/ 阶段/ ,/ 考虑/ 到/ 人们/ 说话/ 时/ 的/ 内容/ 应/ 与/ 表情/ 相互/ 协调/ ,/ 否则/ 会/ 在/ 交流/ 时/ 产生误会/ ,/ 我们/ 进行/ 添加/ 表情/ 的/ 人脸/ 语音/ 动画/ ./ 首先/ 根据/ 人脸/ 表情/ 的/ 生理/ 知识/ [/ 47/ ]/ 和/ 4.3/ 节/ 的/ 三维/ 人脸/ 动画/ 算法/ 来/ 合成/ 在/ 给定/ 幅度/ 下/ 的/ 带有/ 6/ 种/ 基本/ 表情/ 的/ 人脸/ 动画/ ;/ 接着/ 在/ 需要/ 以/ 某种/ 表情/ 说出/ 的/ 文本/ 内容/ 的/ 首尾/ 加上/ 相应/ 的/ 标签/ ;/ 最后/ 当/ 在/ 人脸/ 动画/ 中/ 遇到/ 这些/ 标签/ 的/ 时候/ ,/ 进行/ 表情/ 和/ 视素/ 的/ 混合/ ,/ 即/ 对于/ 同时/ 受到/ 表情/ 和/ 视素/ 影响/ 的/ 模型/ 顶点/ ,/ 将/ 视素/ 与/ 表情/ 在/ 该/ 点/ 的/ 运动/ 值/ 的/ 平均/ 作为/ 该点/ 的/ 运动/ 值/ ./ 在/ 第/ 5/ 阶段/ ,/ 将/ 第/ 4/ 阶段/ 的/ 结果/ 和/ 发音/ 信息/ 同步/ 播放/ 即/ 得到/ 最终/ 结果/ ./ 6/ 实验/ 结果/ 与/ 分析/ 实验/ 配置/ :/ CPU3/ ./ 01GHz/ ,/ 内存/ 2GB/ ,/ 显卡/ GT200/ ./ ①/ http/ :/ // // msdn/ ./ microsoft/ ./ com/ // downloads/ // sdks/ // platform/ // Page66/ ./ 1/ 基于/ 视频/ 的/ 人脸/ 三维/ 运动/ 跟踪/ 6.1/ ./ 1/ 人脸/ 运动/ 跟踪/ 结果/ 从图/ 6/ 可见/ ,/ 针对/ 受/ 光照/ 影响/ 和/ 人脸/ 姿态/ 变化/ 较大/ 的/ 视频/ 以及/ 具有/ 细微/ 眼部/ 动作/ 的/ 视频/ ,/ 人脸/ 运动/ 跟踪/ 的/ 效果/ 较/ 好/ ./ 6.1/ ./ 2/ 单个/ 观测/ 量/ Vs/ 多个/ 观测/ 量/ 受/ 光照/ 影响/ 较大/ 的/ 视频/ 被/ 用来/ 验证/ 融合/ 多个/ 观测/ 量/ 的/ 有效性/ ./ 由图/ 7/ 可见/ ,/ 采用/ 多个/ 观测/ 量/ 的/ 结果/ 更好/ ./ 6.1/ ./ 5/ 节将/ 给出/ 进一步/ 的/ 比较/ ./ 6.1/ ./ 3/ 不同/ 粒子/ 滤波/ 算法/ 的/ 比较/ 采用/ 文献/ [/ 30/ ]/ 中/ 的/ 非线性/ 状态/ 空间/ 模型/ :/ xk/ =/ 1/ +/ sin/ [/ 0.06/ π/ (/ k/ -/ 1/ )/ ]/ +/ 0.8/ xk/ -/ 1/ +/ vk/ -/ 1/ (/ 6/ )/ 3.5/ 节/ 所述/ 的/ LOPSAPF/ 的/ 初始/ 粒子/ 数为/ 200/ ,/ 被/ 比较/ 的/ 其它/ 算法/ 的/ 粒子/ 数目/ 为/ 200/ ./ 从表/ 1/ 可见/ LOPSAPF/ 在/ 估计/ 精度/ 上/ 的/ 优越性/ ./ 算法/ EKF0/ ./ 368460.01427160/ ./ 054UKF0/ ./ 259120.0113/ SIR0/ ./ 181890.0411270/ ./ 085EKPF0/ ./ 281280.0148190/ ./ 076UPF0/ ./ 0435930.00432390/ ./ 064LOPSAPF0/ ./ 0167540.00041590/ ./ 0696.1/ ./ 4/ 应对/ 遮挡/ 更加/ 合理/ ,/ 进而/ 可以/ 得到/ 更/ 准确/ 的/ 跟踪/ 结果/ ./ 6.1/ ./ 5/ 人脸/ 运动/ 跟踪/ 算法/ 的/ 评测/ 与/ 比较/ (/ 1/ )/ 定义/ 一个/ 量化/ 指标/ :/ QT/ =/ ∑/ N/ 从图/ 8/ 的/ 遮挡/ 处理过程/ 可见/ ,/ 处理/ 后/ 的/ 右/ 眉毛/ org/ )/ // (/ N/ ·/ Mi/ )/ ,/ N/ 为/ 输入/ 视频/ 的/ 帧/ 数/ ,/ Mi/ 为/ 视频/ y/ (/ i/ ,/ j/ )/ 第/ i/ 帧/ 中/ 人脸/ 区域/ 的/ 像素/ 的/ 个数/ ,/ y/ (/ i/ ,/ j/ )/ 第/ j/ 个/ 像素/ 的/ 颜色/ 值/ ,/ y/ (/ i/ ,/ j/ )/ 映射/ 到/ 人脸/ 三维/ 模型/ 上/ 得到/ 的/ 合成/ 图像/ 中/ 人脸/ 区域/ 内/ 第/ j/ 个/ 像素/ 的/ 颜色/ 值/ ./ 由表/ 2/ 可见/ ,/ 对于/ MPEG/ -/ 4/ 中/ 的/ 13/ 个人/ 脸/ 视频/ ,/ CMUCohn/ -/ KanadeDataBase/ [/ 48/ ]/ 中/ 的/ 110/ 个/ 视频/ 和/ 捕捉/ 的/ 78/ 个人/ 脸/ 视频/ ,/ 本/ 系统/ 在/ 跟踪/ 精度/ 上/ 优于/ 在线/ 外观/ 模型/ 的/ 代表性/ 方法/ [/ 31/ ]/ ./ 本/ 系统/ 文献/ [/ 31/ ]/ (/ 2/ )/ 首先/ 在/ 给定/ 的/ 人脸/ 运动/ (/ 真实/ 值/ )/ 和/ 光照/ 下用/ 计算机/ 图形/ 绘制/ 技术/ 来/ 合成/ 人脸/ 图像/ [/ 49/ -/ 50/ ]/ (/ 图/ 9/ )/ ,/ 然后/ 定义/ 量化/ 指标/ 为/ 在/ 合成/ 人脸/ 图像/ 上/ 估计/ 的/ 运动/ 值/ 与/ 真实/ 值间/ 误差/ 的/ 平均值/ ./ 从表/ 3/ 可见/ ,/ 本/ 系统/ 在/ 跟踪/ 精度/ 上/ 优于/ 文献/ [/ 31/ ]/ ,/ 且/ 采用/ 多个/ 观测/ 量/ 要/ 优于/ 采用/ 单个/ 观测/ 量/ ./ 采用/ 单个/ 观测/ 量/ 的/ 本/ 系统/ 2.381/ ./ 751.69/ 采用/ 多个/ 观测/ 量/ 的/ 本/ 系统/ 2.731/ ./ 941.866/ ./ 2/ 三维/ 人脸/ 动画/ 从图/ 10/ 可见/ ,/ 在/ 单幅/ 图像/ 驱动/ 下/ ,/ 得到/ 的/ 特定/ 人脸/ 模型/ 只有/ 正面/ 纹理/ ;/ 而/ 在/ 视频/ 驱动/ 下/ ,/ 得到/ 的/ 特定/ 人脸/ 模型/ 既有/ 正面/ 纹理/ 也/ 有/ 侧面/ 纹理/ ,/ 为/ 后续/ 的/ 人脸/ 动画/ 提供/ 了/ 坚实/ 的/ 基础/ ./ Page7/ 与/ 6.1/ ./ 5/ 节/ (/ 1/ )/ 中/ 定义/ 的/ 量化/ 指标/ 类似/ ,/ 这里/ 也/ 定义/ 一个/ 量化/ 指标/ :/ QY/ =/ ∑/ N/ (/ N/ ·/ Mi/ )/ ./ 所/ 不同/ 的/ 是/ ,/ y/ (/ i/ ,/ j/ )/ 中/ 人脸/ 区域/ 内/ 第/ j/ 个/ 像素/ 的/ 颜色/ 值/ ./ 对于/ 同样/ 的/ 输入/ 人脸/ 运动/ 参数/ ,/ 从表/ 4/ 可见/ ,/ 与/ 主流/ 的/ 人脸/ 生理/ 动画/ 模型/ 相比/ ,/ 本文/ 算法/ 以/ 牺牲/ 较少/ 的/ 真实感/ 为/ 代价/ ,/ 大大减少/ 了/ 耗时/ ./ 表/ 4/ 本文/ 算法/ 和/ Waters/ 模型/ 的/ 动画/ 量化/ 指标/ 算法/ 本文/ 算法/ Waters/ 模型/ 6.3/ 视频/ 驱动/ 下/ 的/ 人脸/ 语音/ 动画/ 根据/ 6.1/ 节/ 提取/ 的/ 人脸/ 运动/ 参数/ 来/ 驱动/ 生成/ 人脸/ 动画/ ./ 由图/ 11/ 可见/ ,/ 人脸/ 动画/ 较/ 真实/ 地/ 复现/ 视频/ 中/ 人脸/ 的/ 运动/ 情况/ ./ 6.4/ 文本/ 或/ 语音/ 驱动/ 下/ 的/ 人脸/ 语音/ 动画/ 6.4/ ./ 1/ 未/ 采用/ VCM/ 的/ 视素/ 合成/ 由图/ 12/ 可见/ ,/ 在/ 未/ 采用/ VCM/ 情况/ 下/ ,/ 本/ 系统/ 合成/ 的/ 视素/ 真实/ 地/ 反映/ 了/ 音素/ 对应/ 的/ 唇部/ 运动/ ,/ 且/ 舌头/ 和/ 牙齿/ 的/ 运动/ 与/ 唇/ 型/ 较/ 好/ 地/ 保持一致/ ./ 6.4/ ./ 2/ 采用/ VCM/ 的/ 视素/ 合成/ 实验/ 对象/ 为/ 文本/ “/ Istewtwocupoftea/ ”/ ,/ 它/ 可/ 分割/ 为/ 以下/ 音素/ 序列/ :/ “/ ay/ ,/ s/ ,/ t/ ,/ uw/ ,/ t/ ,/ uw/ ,/ k/ ,/ ae/ ,/ p/ ,/ ah/ ,/ f/ ,/ t/ ,/ iy/ ”/ ./ 当/ 人们/ 在读/ “/ stew/ ”/ 的/ 时候/ ,/ 对应/ 于/ 音素/ “/ s/ ,/ t/ ”/ 的/ 嘴型/ 会/ 被/ 后面/ 的/ 对应/ 于/ 音素/ “/ uw/ ”/ 的/ 嘴型/ 影响/ ,/ 同样/ 的/ 现象/ 也/ 发生/ 在/ “/ two/ ”/ 的/ 音素/ “/ t/ ”/ 上面/ ./ 由图/ 13/ 可见/ ,/ 在/ 采用/ VCM/ 情况/ 下/ ,/ 本/ 系统/ 合成/ 的/ 视素/ 较/ 好/ 地/ 描述/ 了/ 上述/ 现象/ :/ “/ stew/ ”/ 中/ 音素/ “/ s/ ,/ t/ ”/ 的/ 嘴型/ 和/ “/ two/ ”/ 中/ 音素/ “/ t/ ”/ 的/ 嘴型/ ,/ 出现/ 了/ 与/ 后面/ 音素/ “/ uw/ ”/ 的/ 嘴型/ 相似/ 的/ 圆唇/ 动作/ ,/ 且/ 离/ “/ uw/ ”/ 越近/ 受到/ 的/ 影响/ 越大/ ./ 需要/ 指明/ 的/ 是/ ,/ 在/ 图/ 中/ ,/ 受/ 协同/ 发音/ 影响/ 较强/ 的/ 采用/ 纹理/ 方式/ 显示/ ,/ 否则/ 采用/ 网格/ 方式/ 显示/ ./ 6.4/ ./ 3/ 过渡/ 动画/ 的/ 合成/ 在/ 对/ 文本/ “/ Istewtwocupoftea/ ”/ 合成/ 了/ 采用/ VCM/ 的/ 视素/ 后/ ,/ 我们/ 采用/ 3/ 阶/ NURBS/ 来/ 插值/ 生成/ 视素/ 之间/ 的/ 过渡/ 动画/ ./ 由图/ 14/ 可见/ ,/ 所/ 得到/ 的/ 连续/ 人脸/ 动画/ 能够/ 提供/ 无缝/ 而/ 稳定/ 的/ 视觉/ 体验/ ./ 6.4/ ./ 4/ 添加/ 表情/ 的/ 人脸/ 语音/ 动画/ 当/ 在/ 文本/ “/ sobadweather/ ”/ 的/ 首尾/ 加上/ 愤怒/ 和/ 眨眼/ 等/ 表情/ 标签/ 后/ ,/ 所/ 产生/ 的/ 人脸/ 动画/ 如图/ 15/ 所示/ ./ 由此可见/ ,/ 当本/ 系统/ 遇到/ 表情/ 标签/ 时/ ,/ 它/ 能够/ 产生/ 良好/ 的/ 视素/ 和/ 表情/ 同步/ 的/ 人脸/ 动画/ ,/ 该/ 同步性/ 在/ 3DVH/ 带/ 表情/ 说话/ 的/ 时候/ 是/ 至关重要/ 的/ ./ 6.4/ ./ 5/ 可视化/ 协同/ 发音/ 模型/ 的/ 比较/ 我们/ 首先/ 构建/ 了/ 具有/ 协同/ 发音/ 现象/ 的/ 数十条/ 文本/ 语句/ ,/ 接着/ 分别/ 结合/ 本文/ 的/ VCM/ 与/ Cohen/ 模型/ ,/ 利用/ 这些/ 文本/ 语句/ 来/ 驱动/ 生成/ 人脸/ 动画/ ./ Page8/ 图/ 13/ 对/ “/ Istewtwocupoftea/ ”/ 采用/ VCM/ 的/ 合成/ 视素表/ 5/ 是/ 本文/ VCM/ 与/ Cohen/ 模型/ 在/ 合成/ 人脸/ 动画/ 的/ 正确率/ 和/ 耗时/ 方面/ 的/ 比较/ 结果/ ./ 由此可见/ :/ 相较/ 于/ Cohen/ 模型/ ,/ 本文/ VCM/ 在/ 保持/ 正确率/ 的/ 前提/ 下/ ,/ 大大/ 节约/ 了/ 耗时/ ./ 本文/ VCMCohen/ 模型/ 6.5/ 对/ 虚拟/ 人头/ 的/ 客观/ 评测/ 综合/ 上述/ 多种/ 输入/ 下/ 驱动/ 3DVH/ 的/ 过程/ ,/ 下面/ 将/ 该/ 3DVH/ 作为/ 一个/ 整体/ 来/ 进行/ 评测/ ./ 该/ 3DVH/ 在/ 视频/ 输入/ 下/ 驱动/ 生成/ 三维/ 人脸/ 动画/ 的/ 全过程/ 详见/ 如下/ 录像/ http/ :/ // // staff/ ./ ustc/ ./ edu/ ./ cn/ // ~/ harryjun/ // links/ // facial/ _/ motion/ _/ tracking/ _/ results/ _/ 图/ 14/ 对/ “/ Istewtwocupoftea/ ”/ 中视/ 素/ NURBSCarphone/ ./ wmv/ ;/ 在/ 文本/ 或/ 语音输入/ 下/ 驱动/ 生成/ 三维/ 人脸/ 动画/ 的/ 过程/ 详见/ 如下/ 录像/ http/ :/ // // staff/ ./ ustc/ ./ edu/ ./ cn/ // ~/ harryjun/ // links/ // text/ -/ driven/ ./ wmv/ ./ 从/ 上述/ 录像/ 可见/ ,/ 本文/ 构建/ 的/ 多/ 输入/ 驱动/ 的/ 3DVH/ 较/ 好/ 地/ 满足/ 了/ 作为/ 人机接口/ 的/ 要求/ ./ Page9/ 图/ 15/ 添加/ 愤怒/ 表情/ 和/ 眨眼/ 动作/ 的/ “/ sobadweather/ ”/ 动画/ 表/ 6/ 是/ 本文/ 3DVH/ 在/ 各种/ 输入/ 驱动/ 下/ 生成/ 动画/ 的/ 时间/ 效率/ 的/ 评测/ 结果/ ./ 由此可见/ ,/ 它/ 基本/ 满足/ 了/ 实时性/ 的/ 要求/ ./ 进一步/ ,/ 将/ 其/ 与/ 文献/ [/ 1/ ]/ 进行/ 比较/ ./ 从中/ 可见/ ,/ 尽管/ 文献/ [/ 1/ ]/ 比/ 本文/ 3DVH/ 的/ 时间/ 效率/ 更高/ ,/ 但/ 这/ 是/ 在/ 不同/ 系统配置/ 和/ 不同/ 任务/ 复杂度/ 下/ 比较/ 的/ 结果/ ,/ 故/ 需要/ 进行/ 更/ 详细/ 的/ 综合/ 评测/ ./ 本文/ 3DVH/ 的/ 每/ 帧/ 动画/ 耗时/ // s/ 视频/ 输入/ 文本/ 输入/ 语音输入/ 0.080/ ./ 0450.043/ 与/ 文献/ [/ 1/ -/ 3/ ,/ 5/ ,/ 7/ ]/ 中/ 的/ 3DVH/ 相比/ ,/ 本文/ 3DVH/ 具有/ 以下/ 特点/ 和/ 优势/ :/ 首先/ ,/ 它/ 可/ 由/ 视频/ 、/ 文本/ 和/ 语音/ 多种/ 输入/ 来/ 驱动/ ,/ 从而/ 增加/ 了/ 与/ 人/ 交互/ 的/ 多样性/ ,/ 尽管/ 现在/ 也/ 有/ 3DVH/ 可/ 被/ 多种/ 输入/ 来/ 驱动/ ,/ 但/ 现在/ 还/ 没有/ 将/ 视频/ 、/ 文本/ 和/ 语音/ 这些/ 最/ 自然/ 和/ 有效/ 的/ 人机交互/ 媒介/ 综合/ 起来/ 研究/ 的/ 系统/ ;/ 其次/ ,/ 对于/ 人脸/ 三维/ 运动/ 跟踪/ ,/ 它/ 不仅/ 可以/ 跟踪/ 人脸/ 姿态/ 、/ 缩放/ 和/ 位置/ ,/ 还/ 可以/ 跟踪/ 人脸/ 表情/ 运动/ ,/ 尤其/ 是/ 眨眼/ 幅度/ 检测/ ,/ 从而/ 具有/ 理解/ 人类/ 情感/ 的/ 能力/ ./ 而/ 现有/ 的/ 许多/ 3DVH/ 只能/ 跟踪/ 人脸/ 的/ 位置/ 或者/ 只能/ 跟踪/ 人脸/ 的/ 全局/ 刚体/ 运动/ ,/ 基本/ 没有/ 理解/ 人类/ 情感/ 的/ 能力/ ./ 本文/ 3DVH/ 使用/ 在线/ 更新/ 的/ 外观/ 模型/ 来/ 匹配/ 获取/ 人脸/ 三维/ 运动/ 参数/ ,/ 从而/ 不/ 需要/ 大量/ 的/ 离线/ 训练/ 库/ ./ 而/ 现有/ 的/ 许多/ 3DVH/ 的/ 跟踪/ 性能/ 依赖于/ 这些/ 离线/ 训练/ 库/ ./ 进一步/ ,/ 本文/ 3DVH/ 深入/ 挖掘/ 了/ 在线/ 外观/ 模型/ 的/ 潜力/ ,/ 即/ 融合/ 多种/ 外观/ 观测/ 量/ 来/ 减少/ 光照/ 和/ 个体/ 相关性/ 对/ 其/ 的/ 影响/ ,/ 根据/ 人脸/ 三维/ 模型/ 和/ 在线/ 外观/ 模型/ 来/ 处理/ 遮挡/ ./ 为了/ 应对/ 运动/ 滤波/ 中/ 面临/ 的/ 计算/ 盲目/ 和/ 计算/ 量/ 大/ 的/ 问题/ ,/ 本文/ 3DVH/ 基于/ 局部优化/ 和/ 改进/ 重/ 采样/ 来/ 改进/ 粒子/ 滤波/ ,/ 进而/ 获取/ 了/ 高精度/ 的/ 人脸/ 运动/ 估计/ ;/ 再次/ ,/ 对于/ 人脸/ 模型/ 特定/ 化/ ,/ 本文/ 3DVH/ 结合/ 几何/ 变形/ 和/ 动态/ 纹理/ 更新/ ,/ 在/ 只有/ 单个/ 摄像机/ 的/ 情况/ 下/ ,/ 获得/ 了/ 高/ 真实感/ 的/ 人脸/ 三维/ 模型/ ./ 现有/ 的/ 许多/ 3DVH/ 使用/ 三维/ 扫描仪/ 直接/ 获取/ 人脸/ 三维/ 模型/ ,/ 尽管/ 精度/ 较/ 高/ ,/ 但/ 代价/ 昂贵/ 、/ 耗时/ 且/ 需要/ 复杂/ 的/ 设置/ ;/ 然后/ ,/ 对于/ 普通/ PC机/ 上/ 的/ 实时/ 三维/ 人脸/ 动画/ ,/ 本文/ 3DVH/ 将/ 参数/ 模型/ 和/ 肌肉/ 模型/ 结合/ 起来/ ,/ 在/ 保持/ 利用/ 肌肉/ 模型/ 从/ 生理/ 结构/ 上/ 描述/ 人脸/ 运动/ 来/ 获得/ 高/ 真实感/ 的/ 同时/ ,/ 利用/ 参数/ 模型/ 大大降低/ 了/ 计算/ 量/ ./ 而/ 现有/ 的/ 许多/ 3DVH/ 需要/ 在/ 高性能/ 计算机/ 上/ 才能/ 达到/ 实时/ ;/ 最后/ ,/ 对于/ 视素/ 合成/ ,/ 本文/ 3DVH/ 在/ 保持/ 正确率/ 的/ 前提/ 下/ ,/ 采用/ 三音子/ 模型/ 大大降低/ 了/ 可视化/ 协同/ 发音/ 模型/ 的/ 计算/ 复杂度/ ./ 而/ 现有/ 的/ 许多/ 3DVH/ 忽略/ 了/ 可视化/ 协同/ 发音/ 的/ 影响/ ./ 6.6/ 对/ 虚拟/ 人头/ 的/ 主观/ 评测/ 对/ 虚拟/ 人头/ 的/ 主观/ 评测/ 分为/ 3/ 步来/ 实施/ ./ 第/ 1/ 步是/ 确定/ 调查/ 对象/ ./ 我们/ 的/ 调查/ 对象/ 共/ 34/ 个人/ ,/ 他们/ 的/ 情况/ 如表/ 7/ 所示/ ./ 从中/ 可见/ ,/ 调查/ 对象/ 的/ 分布/ 具有/ 广泛/ 的/ 代表性/ ./ 组/ 年龄/ 1/ ./ 小于/ 20/ ;/ 2.20/ 和/ 30/ 之间/ ;/ 3/ ./ 大于/ 308/ // 18/ // 8/ 性别/ 1/ ./ 男性/ ;/ 2/ ./ 女性/ 籍贯/ 1/ ./ 东部/ 地区/ ;/ 2/ ./ 中部/ 地区/ ;/ 3/ ./ 西部/ 地区/ 7/ // 14/ // 13Page10/ 第/ 2/ 步是/ 建立/ 问卷/ ./ 表/ 8/ 展示/ 了/ 其中/ 的/ 问题/ ./ 对于/ 调查/ 对象/ 的/ 回答/ 从/ “/ 绝对/ 不/ 同意/ ”/ 到/ “/ 完全同意/ ”/ 分为/ 10/ 级/ ,/ 并且/ 采用/ Cronbach/ ’/ salpha/ 测试/ 来/ 验证/ 问卷/ 的/ 内在/ 可信度/ (/ 测试/ 结果/ 在/ 0.7/ 以上/ 表示/ 问卷/ 是/ 可信/ 的/ )/ ./ 分组/ 表现力/ 人脸/ 运动/ 跟踪/ 积极/ 期望/ 外貌/ 1/ ./ 我/ 喜欢/ 虚拟/ 人头/ 的/ 外貌/ ./ 焦虑/ 度/ 1/ ./ 与/ 虚拟/ 人头/ 交互/ 时/ 感到/ 舒适/ ./ 语音/ 合成/ 自然/ 度/ 第/ 3/ 步是/ 基于/ 以上/ 问卷/ 获取/ 调查/ 对象/ 对/ 本文/ 3DVH/ 的/ 可/ 接受度/ ./ 首先/ 本文/ 3DVH/ 进行/ 文本/ 驱动/ 下/ 的/ 添加/ 表情/ 的/ 人脸/ 动画/ ,/ 文本/ 由/ 带有/ 6/ 种/ 基本/ 表情/ 标签/ 的/ 6/ 段/ 文字/ 组成/ ,/ 然后/ 在/ 调查/ 对象/ 观察/ 完/ 该段/ 动画/ 后/ ,/ 让/ 他们/ 自由/ 地/ 通过/ 摄像机/ 、/ 键盘/ 和/ 麦克风/ 与/ 本文/ 3DVH/ 进行/ 交互/ ,/ 最后/ 让/ 他们/ 填写/ 问卷/ ,/ 回答/ 的/ 最高分/ 是/ 10/ 分/ ,/ 最低/ 分是/ 0/ 分/ ./ 由表/ 9/ 可见/ ,/ 本/ 系统/ 的/ 得分/ 在/ 7.5/ 以上/ ,/ 这/ 表明/ 本/ 系统/ 能够/ 增强/ 人机交互/ 的/ 友好/ 自然/ 度/ 和/ 有效性/ ./ 分组/ 表现力/ 人脸/ 运动/ 跟踪/ 积极/ 期望/ 外貌/ 1/ ./ 我/ 喜欢/ 虚拟/ 人头/ 的/ 外貌/ ./ 焦虑/ 度/ 1/ ./ 与/ 虚拟/ 人头/ 交互/ 时/ 感到/ 舒适/ ./ 语音/ 合成/ 自然/ 度/ 7/ 结论/ 与/ 展望/ 本文/ 面向/ 人机接口/ 研究/ 领域/ ,/ 提出/ 了/ 一个/ 视频/ 、/ 文本/ 和/ 语音/ 多种/ 输入/ 驱动/ 的/ 3DVH/ 方案/ ./ 对/ 该/ 方案/ 的/ 客观/ 性能/ 测试/ 和/ 主观/ 互动/ 测试/ ,/ 验证/ 了/ 其/ 在/ 人机交互/ 方面/ 的/ 有效性/ ./ 针对/ 本文/ 的/ 实验/ 结果/ 提出/ 进一步/ 研究/ 方向/ :/ (/ 1/ )/ 将/ 本文/ 3DVH/ 从/ 个人/ 计算机/ 移植/ 到/ 嵌入式/ 系统/ 中/ ;/ (/ 2/ )/ 将/ 单种/ 语言/ (/ 英语/ )/ 驱动/ 扩展/ 到/ 可以/ 被/ 多种语言/ 驱动/ ,/ 比如/ 中文/ 、/ 日文/ 等/ ;/ (/ 3/ )/ 利用/ 跟踪/ 到/ 的/ 人脸/ 运动/ 参数/ 进行/ 表情/ 识别/ ./ 

