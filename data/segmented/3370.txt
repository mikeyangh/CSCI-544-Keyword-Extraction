Page1/ 存储/ 级/ 并行/ 与/ 处理器/ 微/ 体系结构/ 谢伦国/ 刘德峰/ (/ 国防科学技术大学/ 计算机/ 学院/ 长沙/ 410073/ )/ 摘要/ 随着/ 处理器/ 和/ 主存/ 之间/ 性能/ 差距/ 的/ 不断/ 增大/ ,/ 长/ 延迟/ 访存/ 成为/ 影响/ 处理器/ 性能/ 的/ 主要/ 原因/ 之一/ ./ 存储/ 级/ 并行/ 通过/ 多个/ 访存/ 并行执行/ 减少/ 长/ 延迟/ 访存/ 对/ 处理器/ 性能/ 的/ 影响/ ./ 文中/ 回顾/ 了/ 存储/ 级/ 并行/ 出现/ 的/ 背景/ ,/ 介绍/ 了/ 存储/ 级/ 并行/ 的/ 概念/ 及其/ 与/ 处理器/ 性能/ 模型/ 之间/ 的/ 关系/ ;/ 分析/ 了/ 限制/ 处理器/ 存储/ 级/ 并行/ 的/ 主要/ 因素/ ;/ 详细/ 综述/ 了/ 提高/ 处理器/ 存储/ 级/ 并行/ 的/ 各种/ 技术/ ,/ 进行/ 了/ 分析/ 比较/ ;/ 最后/ 分析/ 讨论/ 了/ 该/ 领域/ 研究/ 存在/ 的/ 问题/ 和/ 进一步/ 的/ 研究/ 方向/ ./ 关键词/ 存储/ 级/ 并行/ ;/ 微/ 体系结构/ ;/ Runahead/ ;/ 检查点/ ;/ 值/ 预测/ 1/ 引言/ 从/ 1980/ 年/ 开始/ ,/ 微处理器/ 性能/ 以/ 每年/ 60/ %/ 的/ 速度/ 增长/ ,/ 而/ 存储器/ 访问/ 性能/ 的/ 提高/ 每年/ 不到/ 10/ %/ ,/ 处理器/ 和/ 存储器/ 之间/ 的/ 性能/ 差距/ 还/ 在/ 不断/ 增大/ ,/ 存储器/ 性能/ 瓶颈/ ,/ 即/ “/ 存储/ 墙/ ”/ 问题/ [/ 1/ ]/ ,/ 已经/ 成为/ 提高/ 计算机系统/ 性能/ 的/ 主要/ 制约/ 因素/ ./ 为了/ 缓解/ “/ 存储/ 墙/ ”/ 问题/ ,/ 人们/ 在/ 减少/ 访存/ 延迟/ 和/ 隐藏/ 访存/ 延迟/ 两个/ 方面/ 进行/ 了/ 大量/ 的/ 研究/ ./ 除了/ 不断/ 改善/ 存储器/ 访问/ 性能/ 之外/ ,/ 使用/ cache/ 层次/ 存储/ 结构/ 是/ 最/ 主要/ 、/ 也/ 是/ 最/ 有效/ 的/ 减少/ 访存/ 延迟/ 的/ 体系结构/ 方法/ ./ 只要/ 程序/ 呈现/ 良好/ 的/ 时间/ 和/ 空间/ 局部性/ ,/ 大部分/ 访存/ 请求/ 都/ 可以/ 在/ Cache/ 中/ 得到/ 满足/ ,/ 从而/ 减少/ 处理器/ 对/ 主存/ 的/ 访问/ ./ 然而/ ,/ 一方面/ 对于/ 局部性/ 较差/ 的/ 程序/ ,/ Cache/ 的/ 效率/ 将会/ 大大降低/ ./ 另一方面/ ,/ 随着/ 处理器/ 和/ 存储器/ 之间/ 性能/ 差距/ 的/ 不断扩大/ ,/ 由/ Cache/ 失效/ 引起/ 的/ 外部/ 访存/ 操作/ 延迟/ ,/ 即/ 从/ Load/ 失效/ 到/ 数据/ 可用/ (/ Load/ -/ Use/ )/ 的/ 时间/ ,/ 目前/ 已达/ 上/ 百个/ 处理器/ 时钟/ 周/ Page2/ 期/ ,/ 例如/ ,/ Intel2/ ./ 933GHzNehalem/ 处理器/ 访问/ 本地/ DDR3/ -/ 1333/ 存储器/ 延迟/ 达/ 65ns/ [/ 2/ ]/ ,/ 折合/ 190/ 个/ 处理器/ 时钟/ 周期/ ./ 预计/ ,/ 未来/ 可能/ 增加/ 到/ 数百个/ 处理器/ 时钟/ 周期/ [/ 3/ ]/ ./ 有/ 模拟实验/ 结果表明/ ,/ 当/ 外部/ 访存/ 延迟/ 由/ 200/ 延长/ 到/ 1000/ 个/ 处理器/ 时钟/ 周期/ 时/ ,/ 程序执行/ 时间/ 将/ 增加一倍/ ,/ 最多/ 可达/ 三倍/ 以上/ [/ 4/ ]/ ./ 因此/ ,/ 访存/ 延迟/ 隐藏/ 技术/ 变得/ 更为重要/ ./ 传统/ 的/ 访存/ 延迟/ 隐藏/ 技术/ 包括/ 软硬件/ 预取/ [/ 5/ ]/ 、/ 超标/ 量/ 乱序执行/ 和/ 多线程/ 技术/ ./ 预取/ 通过/ 计算/ 和/ 访存/ 操作/ 重叠/ ,/ 将/ 数据/ 在/ 实际/ 使用/ 前/ 先行/ 取到/ 离/ 处理器/ 较近/ 的/ 地方/ ,/ 关键/ 是/ 预取/ 数据/ 和/ 预取/ 时机/ 的/ 选择/ ./ 超标/ 量/ 乱序执行/ 旨在/ 提高/ 单线程/ 内/ 指令/ 级/ 并行/ (/ InstructionLevelParallelism/ ,/ ILP/ )/ 度/ ,/ 并/ 以此/ 隐藏/ 长/ 外部/ 访存/ 延迟/ ,/ 但/ 这/ 需要/ 大/ 指令/ 窗口/ 的/ 支持/ ,/ 而/ 大/ 指令/ 窗口/ 通常/ 受/ 系统/ 设计/ 复杂度/ 和/ 芯片/ 面积/ 及/ 功耗/ 的/ 严格/ 限制/ ./ 多线程/ 技术/ 则/ 通过/ 线程/ 级/ 并行/ (/ ThreadLevelParallelism/ ,/ TLP/ )/ 来/ 隐藏/ 访存/ 延迟/ ,/ 如果/ 一个/ 线程/ 因访存/ 指令/ 引起/ Cache/ 失效/ ,/ 处理器/ 切换/ 到/ 另/ 一线/ 程/ 执行/ ,/ 从而/ 提高/ 处理器/ 的/ ILP/ ./ 多线程/ 技术/ 也/ 同时/ 提高/ 了/ 系统资源/ 的/ 利用率/ ./ 这些/ 技术/ 的/ 基本/ 思想/ 都/ 是/ 通过/ 指令/ 级/ 并行/ ,/ 特别/ 是/ 计算/ 指令/ 和/ 长/ 延迟/ 访存/ 操作/ 重叠/ 来/ 隐藏/ 访存/ 延迟/ ./ 长期以来/ ,/ 处理器/ 设计者/ 一直/ 致力于/ 提高/ 处理器/ 的/ 指令/ 级/ 并行/ ,/ 也/ 包括/ 线程/ 级/ 并行/ ,/ 但/ 遗憾/ 的/ 是/ ,/ 指令/ 级/ 并行/ 虽然/ 有效/ 地/ 减少/ 了/ 处理器/ 的/ 计算/ 时间/ ,/ 但/ 对/ 因/ 外部/ 访存/ 延迟/ 造成/ 的/ 处理器/ 停顿/ 时间/ 的/ 减少/ 却/ 作用/ 不/ 大/ ,/ 并且/ 随着/ 处理器/ 和/ 存储器/ 之间/ 性能/ 差距/ 的/ 不断扩大/ ,/ 单纯/ 依靠/ 快速/ 计算/ (/ 依赖于/ 寄存器/ 和/ Cache/ 命中/ 数据/ 的/ 计算/ )/ 的/ 指令/ 级/ 并行/ 来/ 隐藏/ 长/ 延迟/ 的/ 外部/ 访存/ 已经/ 变得/ 很/ 不/ 现实/ ./ 因此/ ,/ 人们/ 提出/ 了/ 利用/ 长/ 延迟/ 外部/ 访存/ 隐藏/ 长/ 延迟/ 外部/ 访存/ 的/ 方法/ ,/ 这/ 就是/ 存储/ 级/ 并行/ ./ Glew/ 于/ 1998/ 年/ 在/ 他/ 的/ 文章/ “/ MLPyes/ !/ ILPno/ !/ ”/ 中/ 第一次/ 提出/ 了/ 存储/ 级/ 并行/ (/ MemoryLevelParal/ -/ lelism/ ,/ MLP/ )/ 的/ 概念/ [/ 6/ ]/ ,/ 他/ 认为/ :/ 在/ 处理器/ 和/ 存储器/ 性能/ 差距/ 不断扩大/ 的/ 情况/ 下/ ,/ 人们/ 更应/ 关注/ 微/ 体系结构/ 的/ 存储/ 级/ 并行/ ,/ 而/ 不是/ 指令/ 级/ 并行/ ./ 所谓/ 存储/ 级/ 并行/ ,/ 就是/ 处理器/ 以/ 重叠/ 的/ 方式/ 并行执行/ 多个/ 因/ Cache/ 失效/ 导致/ 的/ 外部/ 访存/ 的/ 能力/ ./ 存储/ 级/ 并行/ 揭示/ 了/ 长/ 外部/ 访存/ 延迟/ 隐藏/ 技术/ 的/ 关键/ ,/ 人们/ 开始/ 从/ 存储/ 级/ 并行/ 的/ 角度/ 重新/ 审视/ 微处理器/ 体系结构/ ,/ 对/ 提高/ 处理器/ 存储/ 级/ 并行/ 的/ 方法/ 进行/ 研究/ ,/ 存储/ 级/ 并行/ 正在/ 逐渐/ 成为/ 处理器/ 微/ 体系结构/ 研究/ 的/ 热点/ 技术/ ./ 定性/ 地说/ ,/ 存储/ 级/ 并行/ 就是/ 处理器/ 并行执行/ 外/ 本文/ 将/ 对/ 处理器/ 存储/ 级/ 并行/ 技术/ 进行/ 综述/ ,/ 第/ 2/ 节/ 介绍/ 存储/ 级/ 并行/ 的/ 概念/ 及其/ 对系统/ 性能/ 的/ 影响/ ;/ 第/ 3/ 节/ 指出/ 传统/ 乱序执行/ 、/ 超标/ 量/ 处理器/ 体系结构/ 限制/ 存储/ 级/ 并行/ 的/ 主要/ 因素/ ;/ 第/ 4/ 节/ 重点/ 介绍/ 当前/ 提高/ 处理器/ 存储/ 级/ 并行/ 的/ 研究进展/ ;/ 最后/ 第/ 5/ 节/ 探讨/ 了/ 存储/ 级/ 并行/ 今后/ 的/ 研究/ 方向/ ./ 2/ 存储/ 级/ 并行/ 的/ 定义/ 2.1/ 存储/ 级/ 并行/ 的/ 定义/ 部访存/ 操作/ 的/ 能力/ 或/ 方法/ ./ Chou/ 在/ 文献/ [/ 4/ ]/ 中/ 首次/ 定量/ 地/ 给出/ 了/ 存储/ 级/ 并行/ (/ MLP/ )/ 的/ 形式化/ 定义/ 及/ MLP/ 与/ 系统/ 性能/ 之间/ 的/ 关系/ 模型/ ,/ 有效/ 地/ 揭示/ 了/ 存储/ 级/ 并行/ 的/ 特征/ ./ Chou/ 将/ 时钟/ 周期/ t/ 时/ 有效/ 外/ 部长/ 延迟/ 访存/ 的/ 个数/ 定义/ 为/ 瞬时/ 存储/ 级/ 并行/ MLP/ ,/ 用/ MLP/ (/ t/ )/ ,/ 所有/ 不/ 等于零/ 的/ 瞬时/ 存储/ 级/ 并行/ MLP/ (/ t/ )/ 的/ 平均值/ ,/ 即/ 所有/ 至少/ 存在/ 一个/ 有效/ 外/ 部长/ 延迟/ 访存/ 的/ 时钟/ 周期/ 内/ 每个/ 时钟/ 周期/ 访存/ 操作/ 的/ 平均/ 个数/ 定义/ 为/ 平均/ MLP/ ,/ 用/ MLP/ 表示/ ./ 这里/ 特别/ 限定/ 的/ “/ 有效/ 外/ 部长/ 延迟/ 访存/ ”/ 意指/ 因/ 处理器/ 片内/ Cache/ 失效/ 导致/ 的/ 对片/ 外存储器/ 的/ 有效/ 访问/ ,/ 不/ 包括/ 因误/ 预测/ 等/ 造成/ 的/ 无效/ 片/ 外存储器/ 访问/ ,/ 即/ 访存/ 的/ 数据/ 要/ 被/ 程序/ 真正/ 使用/ ./ 按照/ 该/ 定义/ ,/ 有效/ 外/ 部长/ 延迟/ 访存/ 包括/ 指令/ Fetch/ ,/ Load/ 和/ 硬件/ // 软件/ 预取/ ./ 在/ 图/ 1/ 所示/ 的/ 示例/ 中/ ,/ 外部/ 访存/ 延迟/ 为/ 200/ 周期/ ,/ MLP/ (/ t/ )/ =/ 1/ 的/ 周期/ 为/ 90/ ~/ 100/ 、/ 290/ ~/ 300/ 、/ 350/ ~/ 550/ ,/ MLP/ (/ t/ )/ =/ 2/ 的/ 周期/ 为/ 100/ ~/ 290/ ,/ MLP/ =/ (/ 10/ +/ 10/ +/ 200/ +/ 2/ ×/ 190/ )/ // 410/ =/ 1.463/ ./ 2.2/ 存储/ 级/ 并行/ 对/ 程序执行/ 性能/ 的/ 影响/ 性能/ 的/ 影响/ 如式/ (/ 1/ )/ 所示/ ./ 在/ 外部/ 访存/ 延迟/ 固定/ 情况/ 下/ ,/ MLP/ 对/ 程序执行/ 式/ 中/ ,/ Cycles/ 为/ 程序执行/ 总/ 时钟/ 周期/ 数/ ;/ Cyclesperf/ 为/ 计算/ 执行/ 时钟/ 周期/ 数/ ;/ OverlapCM/ 为/ 计算/ 与/ 片/ 外访/ 存/ Page3/ 重叠/ 执行/ 所/ 占/ 计算/ 执行/ 周期/ 数/ 的/ 百分比/ ;/ NumMisses/ 为/ Cache/ 失效/ 导致/ 的/ 片/ 外访/ 存/ 次数/ ;/ MissPenalty/ 为/ 每次/ 片/ 外访/ 存/ 延迟/ 时钟/ 周期/ 数/ ;/ MLP/ 为/ 平均/ 存储/ 级/ 并行/ ./ 式/ (/ 1/ )/ 的/ 结论/ 是/ 显然/ 的/ ,/ 第/ 1/ 项/ 表示/ 计算/ 执行/ 周期/ 数/ 减去/ 与/ 存储器/ 操作/ 重叠/ 的/ 周期/ 数/ ;/ 第/ 2/ 项/ 表示/ 外部/ 访存/ 的/ 周期/ 数/ ./ 随着/ 处理器/ 和/ 存储器/ 之间/ 性能/ 差距/ 的/ 不断扩大/ ,/ 处理器/ 片/ 外访/ 存/ 延迟/ 时钟/ 周期/ 数将/ 越来越/ 大/ ,/ 通过/ 计算/ 执行/ 与/ 片/ 外访/ 存/ 重叠/ 隐藏/ 访存/ 延迟/ 的/ 作用/ 将/ 越来越/ 小/ ,/ 以至于/ Chou/ 在/ 建立/ MLP/ 模型/ 时/ 假设/ OverlapCM/ ≈/ 0/ ./ 在/ 外部/ 访存/ 延迟/ 固定/ 情况/ 下/ ,/ 减少/ Cache/ 失效/ 、/ 提高/ 存储/ 级/ 并行度/ 将/ 是/ 提高/ 程序/ 整体/ 执行/ 性能/ 最/ 有效/ 的/ 方法/ ./ 2.3/ MLP/ 的/ 提升/ 空间/ 根据/ Chou/ 的/ 平均/ MLP/ 定义/ ,/ YangZhen/ 等/ 人/ [/ 7/ ]/ 对/ SPEC2000/ 和/ Olden/ 应用/ 中/ 的/ 9/ 种/ 实际/ 负载/ 进行/ 了/ 模拟/ 研究/ ,/ 比较/ 了/ 在/ 存在/ 数据/ 相关/ 实际/ 条件/ 下/ 的/ 基本/ MLP/ 和/ 不/ 考虑/ 数据/ 相关/ 、/ Cache/ 失效/ Load/ 指令/ 无/ 任何/ 延迟/ 流出/ 情况/ 下/ 的/ 理想/ MLP/ ,/ 模拟/ 结果/ 如图/ 2/ 所示/ ./ 结果表明/ ,/ 基本/ MLP/ 和/ 理想/ MLP/ 之间/ 存在/ 着/ 较大/ 差距/ ,/ 即/ MLP/ 存在/ 较大/ 的/ 提升/ 空间/ ./ 3/ 限制/ 处理器/ 存储/ 级/ 并行/ 的/ 主要/ 因素/ 尽管/ 微处理器/ 体系结构/ 在/ 不断/ 的/ 发展/ ,/ 从/ 超标/ 量/ 乱序执行/ 处理器/ 到/ 多线程/ 、/ 同时/ 多线程/ 处理器/ ,/ 再/ 到/ 目前/ 的/ 多/ 核/ 、/ 众核/ 处理器/ ,/ 但是/ 其/ 基础/ 仍然/ 是/ 超标/ 量/ 乱序执行/ 处理器/ ,/ 因此/ 对/ 传统/ 的/ 乱序/ 、/ 超标/ 量/ 处理器/ 限制/ 存储/ 级/ 并行/ 的/ 主要/ 因素/ 进行/ 分析/ 仍/ 具有/ 普遍/ 的/ 指导意义/ ./ 3.1/ 指令/ 流出/ 队列/ 和/ 重定序/ 缓冲/ 的/ 大小/ 指令/ 流出/ 队列/ (/ IQ/ )/ 和/ 重定序/ 缓冲/ (/ ROB/ )/ 是/ 乱序/ 超标/ 量/ 处理器/ 指令/ 窗口/ 中/ 实现/ 指令/ 乱序执行/ 最/ 重要/ 的/ 两个/ 硬件/ 结构/ ./ 只有/ 存入/ IQ/ 的/ 不/ 相关/ 指令/ 才/ 有/ 可能/ 乱序/ 流出/ ,/ IQ/ 越大/ ,/ 存入/ IQ/ 的/ 不/ 相关/ 访存/ 指令/ 的/ 可能性/ 越大/ ./ 指令/ 在/ 存入/ IQ/ 的/ 同时/ 存入/ ROB/ ,/ 用以/ 记录/ 进入/ IQ/ 的/ 指令/ 原来/ 在/ 程序/ 中/ 的/ 取指/ 顺序/ ,/ 确保/ 指令/ 在/ 完成/ 时能/ 按/ 原来/ 的/ 顺序/ 提交/ ,/ 同时/ 为/ 精确/ 中断/ 提供/ 支持/ ./ ROB/ 是/ 一个/ FIFO/ 队列/ ,/ 只有/ 当/ 队列/ 中/ 前面/ 所有/ 的/ 指令/ 全部/ 正确/ 提交/ (/ 完成/ )/ 后/ ,/ 当前/ 指令/ 才能/ 从/ ROB/ 移出/ ./ 当/ ROB/ 头/ 是/ 一条/ 长/ 延迟/ 外部/ 访存/ 指令/ 时/ ,/ 如果/ 在/ 这条/ 访存/ 指令/ 完成/ 之前/ ,/ ROB/ 已经/ 被/ 占用/ 满/ ,/ 将会/ 造成/ 后面/ 访存/ 指令/ 的/ 阻塞/ ,/ 因此/ 存储/ 级/ 并行/ 受限于/ ROB/ 的/ 长度/ ./ 增加/ ROB/ 的/ 长度/ 将/ 有利于/ 提高/ MLP/ ./ 与/ 指令/ 窗口/ 相关/ 的/ 其它/ 系统资源/ 还/ 包括/ 寄存器/ 文件/ 、/ StoreBuffer/ 等/ ,/ 这些/ 资源/ 必须/ 与/ 指令/ 窗口/ 同步增长/ ./ 3.2/ 串行化/ 指令/ 几乎/ 所有/ 的/ 指令集/ 结构/ (/ ISA/ )/ 都/ 包含/ 用于/ 实现/ 同步/ 原语/ 或/ 维持/ 存储/ 一致性/ 的/ 指令/ ,/ 例如/ SPARCISA/ 中/ 的/ CASA/ 和/ MEMBAR/ [/ 8/ ]/ 指令/ ./ 因/ 这类/ 指令/ 在/ 流出/ 之前/ ,/ 必须/ 清空/ 处理器/ 的/ 流水线/ ,/ 即/ 这类/ 指令/ 之前/ 的/ 所有/ 指令/ 必须/ 执行/ 完毕/ ,/ 所以/ 称之为/ 串行化/ 指令/ ./ 这/ 意味着/ ,/ 串行化/ 指令/ 之后/ 的/ 外部/ 访存/ 指令/ ,/ 即使/ 和/ 之前/ 的/ 所有/ 外部/ 访存/ 指令/ 不/ 相关/ ,/ 也/ 不/ 可能/ 并行/ 流出/ ./ 4.2/ ./ 1/ 小节/ 和/ 4.2/ ./ 2/ 小节/ 介绍/ 的/ 两种/ 技术/ 可以/ 减少/ 串行化/ 指令/ 对/ 存储/ 级/ 并行/ 的/ 影响/ ./ 3.3/ 取指/ 失效/ 和/ 分支/ 预测/ 失败/ 取指/ 失效/ 意味着/ 指令/ Cache/ 中/ 没有/ 指令/ 可/ 提供/ 给/ IQ/ ,/ 此时/ 必须/ 到/ 外部/ 存储器/ 取指令/ ./ 分支/ 预测/ 失败/ 或/ 分支/ 预测/ 错误/ 意味着/ 在/ 分支/ 预测/ 判定/ 之前/ ,/ 处理器/ 在/ 按照/ 一条/ 错误/ 的/ 路径/ 取指/ 和/ 执行/ 指令/ ,/ 通常/ 这些/ 指令/ 的/ 执行/ 都/ 是/ 无用/ 的/ ./ 而且/ ,/ 分支/ 预测/ 判定/ 依赖于/ 与/ Cache/ 失效/ 相关/ 的/ 外部/ 访存/ 返回/ 的/ 值/ ./ 因此/ 分支/ 预测/ 的/ 精度/ 和/ 延迟/ 对/ 处理器/ 的/ MLP/ 具有/ 较大/ 的/ 影响/ ./ 3.4/ Load/ 指令/ 流出/ 策略/ 对于/ 乱序执行/ 的/ 处理器/ 而言/ ,/ 虽然/ 不同/ 类型/ 指令/ 之间/ 的/ 指令/ 可以/ 乱序/ 流出/ ,/ 但是/ 某些/ 类型/ 指令/ 之间/ 仍然/ 存在/ 不同/ 的/ 限制/ ,/ 特别/ 是/ Load/ 指令/ ./ Load/ 指令/ 相对/ 于/ 其它/ 的/ Load/ 指令/ 和/ Store/ 指令/ ,/ 它们/ 之间/ 存在/ 3/ 种/ 不同/ 的/ 流出/ 策略/ :/ 全部/ 顺序/ 流出/ ;/ Load/ 指令/ 之间/ 乱序/ 、/ Load/ 与/ Store/ 指令/ 之间/ 顺序/ ;/ 全部/ 乱序/ ./ 这类/ 指令/ 流出/ 策略/ 涉及/ 访存/ 指令/ 的/ 流出/ 和/ 存储/ 一致性/ ,/ 指令/ 流出/ 约束/ 越松/ ,/ 对/ 提高/ MLP/ 越/ 有利/ ./ Page43/ ./ 5Cache/ 失效/ 处理/ 机制/ 当代/ 通用/ 微处理器/ 几乎/ 无一例外/ 地/ 使用/ Cache/ 层次/ 存储/ 结构/ ,/ Cache/ 存储器/ 参数/ 的/ 选择/ 、/ Cache/ 失效/ 处理/ 机制/ 允许/ 处理/ Cache/ 失效/ 的/ 个数/ 将/ 直接/ 影响/ Cache/ 失效/ 次数/ 和/ MLP/ ./ Cache/ 失效/ 处理/ 结构/ (/ MHA/ )/ 对/ 存储/ 级/ 并行/ 的/ 影响/ 最大/ ,/ 一般/ 地/ ,/ Cache/ 失效/ 处理/ 结构/ 的/ 入口/ 数目/ 越大越/ 有利于/ MLP/ 的/ 提高/ ./ 具体/ 细节/ 将/ 在/ 4.3/ ./ 1/ 节/ 介绍/ ./ 以上/ 仅/ 对/ 传统/ 的/ 乱序/ 、/ 超标/ 量/ 处理器/ 微/ 体系结构/ 限制/ 存储/ 级/ 并行/ 的/ 主要/ 因素/ 进行/ 分析/ ./ 随着/ 半导体/ 工艺/ 的/ 进步/ ,/ 微处理器/ 体系结构/ 正在/ 向/ 多/ 核/ 、/ 众核/ 单芯片/ 多处理器/ (/ CMP/ )/ 方向/ 发展/ ,/ 片/ 外存储器/ 的/ 带宽/ 及/ 带宽/ 的/ 有效/ 利用/ 越来越/ 成为/ 微处理器/ 存储/ 级/ 并行/ 的/ 重要/ 限制/ 因素/ ./ 此外/ ,/ 应用程序/ 的/ 访存/ 特征/ ,/ 特别/ 是/ 数据/ 相关性/ 也/ 是/ 限制/ 处理器/ 存储/ 级/ 并行/ 的/ 重要/ 因素/ ./ 本文/ 将/ 主要/ 从/ 处理器/ 微/ 体系结构/ 的/ 角度/ 探讨/ 提高/ 处理器/ 存储/ 级/ 并行/ 的/ 方法/ ./ 4/ 提高/ 处理器/ 存储/ 级/ 并行/ 的/ 技术/ 近/ 10/ 年来/ ,/ 人们/ 从/ 软件/ 到/ 微处理器/ 结构/ ,/ 从/ 指令/ 流出/ 到片/ 内/ 存储系统/ ,/ 对/ 处理器/ 存储/ 级/ 并行/ 技术/ 进行/ 了/ 广泛/ 深入/ 的/ 研究/ ,/ 提出/ 了/ 许多/ 新型/ 微/ 体系结构/ 和/ 新/ 技术/ ,/ 如/ 千条/ 指令/ 处理器/ KIP/ (/ Kilo/ -/ InstructionProcessor/ )/ [/ 9/ -/ 10/ ]/ 、/ 检查点/ 处理/ 和/ 恢复/ CPR/ (/ CheckpointProcessingandRecovery/ )/ 体系结构/ [/ 11/ ]/ 、/ 连续流/ 流水线/ CFP/ (/ ContinualFlowPipeline/ )/ 处理器/ [/ 12/ ]/ 等/ ./ 存储/ 级/ 并行/ 就/ 其本质/ 而言/ ,/ 仍/ 属于/ 指令/ 级/ 并行/ ,/ 只不过/ 存储/ 级/ 并行/ 强调/ 的/ 是/ 因片/ 内/ Cache/ 失效/ 导致/ 的/ 外部/ 访存/ 指令/ 的/ 并行/ ./ 所以/ ,/ 传统/ 的/ 用于/ 提高/ 指令/ 级/ 并行/ 的/ 方法/ ,/ 包括/ 扩展/ 指令/ 窗口/ 、/ 数据/ 预取/ 、/ 提高/ Cache/ 利用率/ 等/ ,/ 原则上/ 都/ 适用/ 于/ 提高/ 存储/ 级/ 并行/ ./ 同时/ 存储/ 级/ 并行/ 是/ 一个/ 系统性/ 课题/ ,/ 它/ 不仅/ 依赖于/ 微处理器/ 体系结构/ ,/ 也/ 依赖于/ 和/ 处理器/ 配套/ 的/ 存储/ 子系统/ ,/ 依赖于/ 使用/ 处理器/ 的/ 软件/ ./ 下面/ 将/ 就/ 提高/ 处理器/ 存储/ 级/ 并行/ 的/ 主要/ 微/ 体系结构/ 技术/ 进行/ 介绍/ ./ 4.1/ 扩展/ 指令/ 窗口/ 从/ 理论/ 上/ 讲/ ,/ 只要/ 指令/ 窗口/ 足够/ 大/ ,/ 允许/ 足够/ 多/ 的/ 与/ 长/ 延迟/ 访存/ 指令/ 不/ 相关/ 的/ 指令/ 在/ 长访存/ 延迟时间/ 内/ 并行执行/ ,/ 就/ 能/ 消除/ 因长/ 延迟/ 访存/ 造成/ 的/ 处理器/ 停顿/ ,/ 隐藏/ 长访存/ 延迟/ ./ 基于/ 此/ ,/ KIP/ 、/ CPR/ 、/ CFP/ 等/ 都/ 能/ 支持/ 一千条/ 飞行/ (/ 未/ 完成/ )/ 指令/ 并行执行/ ,/ 从而/ 隐藏/ 长/ 达到/ 1000/ 个/ 处理器/ 时钟/ 周期/ 的/ 外部/ 访存/ 延迟/ ./ 勿容/ 置疑/ ,/ 指令/ 窗口/ 越大/ ,/ 存储/ 级/ 并行/ 的/ 可能性/ 越高/ ./ 影响/ 指令/ 窗口/ 的/ 主要/ 数据结构/ 包括/ 指令/ 流出/ 队列/ (/ IQ/ )/ 、/ 重定序/ 缓冲/ (/ ROB/ )/ 、/ Load/ // Store/ 队列/ (/ LSQ/ )/ 和/ 物理/ 寄存器/ 文件/ (/ PRF/ )/ ./ 在/ 实际/ 实现/ 中/ ,/ 由于/ 实现/ 复杂度/ 、/ 芯片/ 面积/ 、/ 温度/ 、/ 功耗/ 及时/ 钟/ 频率/ 等/ 诸多/ 因素/ 的/ 限制/ ,/ 仅仅/ 简单/ 地/ 通过/ 按/ 比例/ 增加/ 与/ 指令/ 窗口/ 相关/ 的/ 系统结构/ 资源/ 来/ 扩展/ 指令/ 窗口/ 是/ 不切实际/ 的/ ./ 为了/ 有效/ 扩展/ 指令/ 窗口/ ,/ 人们/ 通常/ 采用/ 两类/ 方法/ :/ (/ 1/ )/ 层次/ 式/ 指令/ 窗口/ ;/ (/ 2/ )/ 积极/ 的/ 资源/ 回收/ 机制/ ./ 下面/ 将/ 分别/ 予以/ 讨论/ ./ 4.1/ ./ 1/ 层次/ 式/ 指令/ 窗口/ 所谓/ 层次/ 式/ 指令/ 窗口/ ,/ 就是/ 在/ 原有/ 的/ 单个/ 指令/ 窗口/ 的/ 基础/ 上/ ,/ 增加/ 一个/ 二级/ 指令/ 窗口/ ,/ 专门/ 对长/ 延迟/ 指令/ 进行/ 处理/ ./ 原/ 指令/ 窗口/ (/ 主/ 指令/ 窗口/ )/ 处于/ 指令/ 执行/ 流水线/ 的/ 关键/ 路径/ 上/ ,/ 当/ 处理器/ 检测/ 到长/ 延迟/ 指令/ ,/ 例如/ Cache/ 失效/ Load/ 指令/ 时/ ,/ 长/ 延迟/ 指令/ 及其/ 与/ 该长/ 延迟/ 指令/ 直接/ 或/ 间接/ 相关/ 的/ 其它/ 指令/ 被/ 送入/ 二级/ 指令/ 窗口/ ,/ 使长/ 延迟/ 及其/ 相关/ 指令/ 移出/ 指令/ 执行/ 关键/ 路径/ ,/ 允许/ 主/ 指令/ 窗口/ 流出/ 更/ 多/ 的/ 指令/ ./ 当长/ 延迟/ 指令/ 服务/ 得到/ 满足/ 时/ ,/ 长/ 延迟/ 及其/ 相关/ 指令/ 返回/ 主/ 指令/ 窗口/ 优先/ 执行/ ./ 针对/ 长/ 延迟/ 相关/ 指令/ 的/ 检测/ 、/ 缓冲/ 和/ 处理/ ,/ 近年来/ 人们/ 提出/ 了/ 许多/ 层次/ 式/ 指令/ 窗口/ 结构/ ,/ 如/ 等待/ 指令/ 缓冲器/ WIB/ (/ WaitingInstructionBuffer/ )/ [/ 13/ ]/ 、/ Slice/ 指令/ 处理部件/ SPU/ (/ SliceProcessingUnit/ )/ [/ 12/ ]/ 、/ 慢车道/ 指令/ 队列/ SLIQ/ (/ SlowLaneInstructionQueue/ )/ [/ 9/ ]/ 等/ ./ WIB/ 使用/ 现有/ 的/ 小/ 的/ 流出/ 队列/ ,/ 通过/ 对源/ 操作数/ 增加/ 一个/ “/ 等待/ ”/ 位/ 标记/ 该/ 操作数/ 处于/ “/ 伪/ 就绪/ ”/ 状态/ ,/ 目前/ 尚/ 不可/ 用/ ./ 凡是/ 操作数/ 被/ 标记/ 为/ “/ 伪/ 就绪/ ”/ 的/ 指令/ 即/ 为/ “/ 伪/ 就绪/ ”/ 指令/ ,/ 以此/ 来/ 检测/ Cache/ 失效/ Load/ 指令/ 及其/ 相关/ 指令/ ./ 伪/ 就绪/ 指令/ 按真/ 就绪/ 指令/ 一样/ 从/ 流出/ 队列/ 流出/ ,/ 只是/ 它们/ 不是/ 流出/ 到/ 功能/ 部件/ ,/ 而是/ 流入/ 等待/ 指令/ 缓冲器/ WIB/ ./ 当/ Cache/ 失效/ Load/ 指令/ 的/ 数据/ 从/ 主存/ 中/ 返回/ 时/ ,/ WIB/ 中/ 的/ 相关/ 指令/ 重新/ 并/ 优先/ 插入/ 指令/ 流出/ 队列/ ./ WIB/ 设计/ 的/ 与/ 指令/ 活动/ 列表/ 一样/ 大/ ,/ 允许/ 重新/ 插入/ 流出/ 队列/ 的/ 指令/ 因/ 与/ 另/ 一个/ Cache/ 失效/ Load/ 指令/ 相关/ 而/ 重新/ 流入/ WIB/ ./ CFP/ 结构/ [/ 12/ ]/ 将长/ 延迟/ Load/ 失效/ 及其/ 相关/ 指令/ 定义/ 为/ Slice/ 指令/ ./ 与/ WIB/ 类似/ ,/ CFP/ 动态/ 识别/ Slice/ 指令/ ,/ Slice/ 指令/ 从/ 调度/ 器/ 流出/ 直接/ 送入/ Slice/ 指令/ 处理部件/ SPU/ ,/ 同时/ 释放/ Slice/ 指令/ 对应/ 的/ 全部/ 指令/ 调度/ 资源/ ,/ 供/ 后续/ 指令/ 使用/ ./ SPU/ 比/ WIB/ 功能/ 更为/ 强大/ ,/ 除了/ 缓存/ Slice/ 指令/ 外/ ,/ SPU/ 还/ 保存/ 有/ Page5/ 执行/ 这些/ Slice/ 指令/ 所/ 需/ 的/ 所有/ 信息/ ,/ 包括/ 源/ 寄存器/ 数据/ 和/ 数据/ 相关/ 信息/ ./ 当长/ 延迟/ 数据/ 返回/ 时/ ,/ SPU/ 根据/ 保存/ 的/ Slice/ 指令/ 的/ 源/ 寄存器/ 数据/ 和/ 数据/ 相关/ 信息/ 为/ Slice/ 指令/ 重新分配/ 物理/ 寄存器/ ,/ 然后/ 重新/ 插入/ 指令/ 流水线/ 调度/ 执行/ ./ KIP/ [/ 9/ ]/ 在/ 指令/ 重命名/ 后/ 送入/ IQ/ 和/ 伪/ ROB/ ,/ 当/ 检测/ 到长/ 延迟/ 指令/ 及其/ 相关/ 指令/ 到达/ 伪/ ROB/ 头时/ ,/ 长/ 延迟/ 指令/ 及其/ 相关/ 指令/ 从伪/ ROB/ 流入/ 慢车道/ 指令/ 队列/ SLIQ/ ,/ 同时/ 作废/ IQ/ 中/ 的/ 相应/ 指令/ ./ 当/ SLIQ/ 中/ 的/ 长/ 延迟/ 指令/ 操作/ 完成/ 后/ ,/ 该长/ 延迟/ 指令/ 及其/ 相关/ 指令/ 重新/ 插回/ IQ/ 队列/ 执行/ ./ 由于/ SLIQ/ 不/ 在/ 指令/ 流水线/ 的/ 关键/ 路径/ 上/ ,/ 因此/ ,/ 在/ 不/ 扩大/ IQ/ 条件/ 下/ 有效/ 实现/ 了/ 大/ IQ/ 的/ 功能/ ./ 虽然/ KIP/ 在/ 长/ 延迟/ 指令/ 及其/ 相关/ 指令/ 到达/ 伪/ ROB/ 头时/ 才/ 送入/ SLIQ/ ,/ 但/ 这种/ 延迟/ 策略/ 为/ 准确/ 判断/ L2Cache/ 失效/ 长/ 延迟/ 指令/ 提供/ 了/ 时间/ ./ 为了/ 支持/ 大/ 指令/ 窗口/ ,/ 物理/ 寄存器/ 文件/ (/ PRF/ )/ 和/ Load/ // Store/ 队列/ (/ LSQ/ )/ 需要/ 按/ 指令/ 窗口/ 大小/ 成/ 比例/ 地/ 增长/ ./ 为了/ 适应/ 这种/ 增长/ ,/ 人们/ 同样/ 采用/ 了/ 层次/ 式/ 结构/ ./ 典型/ 地/ ,/ CPR/ [/ 13/ ]/ 利用/ Store/ 队列/ 向/ Load/ 指令/ 转发/ 数据/ 的/ 局部性/ 设计/ 了/ 一个/ 两级/ Store/ 队列/ STQ/ ./ 一级/ Store/ 队列/ L1STQ/ 类似/ 于/ 通常/ 处理器/ 的/ Store/ 队列/ ,/ 循环/ 缓冲/ 处理器/ 最近/ 的/ n/ 条/ Store/ 指令/ ,/ 新/ 指令/ 进入/ L1STQ/ 的/ 尾/ ./ 当/ L1STQ/ 存满时/ ,/ 最老/ 的/ 指令/ 从/ L1STQ/ 的/ 头/ 溢出/ ,/ 存入/ 二级/ Store/ 队列/ L2STQ/ ,/ 直至/ 指令/ 提交/ ./ Load/ 指令/ 地址/ 同时/ 送往/ L1STQ/ 、/ L2STQ/ 和/ DCache/ ,/ 根据/ 地址/ 命中/ 情况/ ,/ 分别/ 由/ L1STQ/ 、/ L2STQ/ 和/ DCache/ 向/ Load/ 指令/ 转发/ 或/ 提供数据/ ./ 4.1/ ./ 2/ 积极/ 的/ 资源/ 回收/ 机制/ 除了/ 采用/ 层次/ 式/ 结构/ 扩展/ 指令/ 窗口/ 外/ ,/ 如何/ 提高/ 重定序/ 缓冲/ (/ ROB/ )/ 、/ Load/ // Store/ 队列/ (/ LSQ/ )/ 和/ 物理/ 寄存器/ 文件/ (/ PRF/ )/ 这些/ 结构/ 资源/ 的/ 利用率/ ,/ 减小/ 对/ 这些/ 资源/ 的/ 需求/ ,/ 是/ 另/ 一种/ 扩展/ 指令/ 窗口/ 的/ 重要/ 方法/ ./ 下面/ 仅/ 就/ ROB/ 和/ PRF/ 的/ 资源/ 回收机/ 制作/ 一/ 介绍/ ./ 4.1/ ./ 2.1/ 检查点/ 技术/ 与/ 提前/ 释放/ ROB/ 在/ 传统/ 的/ 超标/ 量/ 处理器/ 中/ ,/ ROB/ 保持/ 所有/ 飞行/ 指令/ 的/ 状态/ ,/ 以/ 确保/ 所有/ 指令/ 能/ 乱序执行/ 、/ 顺序/ 提交/ ,/ 同时/ 支持/ 精确/ 中断/ 和/ 例外/ ,/ 包括/ 分支/ 预测/ 错误/ 、/ 图/ 3/ 物理/ 寄存器/ 生命周期/ 支持/ 寄存器/ 重命名/ 和/ 回收/ ./ 飞行/ 指令/ 越/ 多/ ,/ 指令/ 占用/ ROB/ 时间/ 越长/ ,/ ROB/ 越/ 可能/ 成为/ 性能/ 瓶颈/ ./ 即使/ ROB/ 可以/ 做/ 得/ 很大/ ,/ 与其/ 相关/ 的/ 机制/ ,/ 如/ 分支/ 误/ 预测/ 恢复/ 机制/ 等/ 却/ 限制/ 了/ 其/ 性能/ 的/ 发挥/ ./ 检查点/ (/ Checkpoint/ )/ 技术/ 通常/ 用于/ 系统/ 修复/ ./ 检查点/ 是/ 程序执行/ 时/ 某/ 一/ 特定/ 指令/ 点/ 处理器/ 系统结构/ 状态/ 的/ 快照/ ,/ 包含/ 着/ 系统/ 从/ 该点/ 继续执行/ 所/ 需/ 的/ 所有/ 信息/ ./ 系统/ 出错/ 时/ ,/ 回滚/ 到/ 上/ 一个/ 检查点/ ,/ 系统/ 就/ 可/ 从/ 该/ 检查点/ 继续/ 正确/ 运行/ ./ 文献/ [/ 13/ ]/ 提出/ ,/ 采用/ 选择性/ 的/ 检查点/ 技术/ ,/ 可以/ 将/ ROB/ 所有/ 功能/ 卸载/ 到/ 其它/ 可/ 扩展/ 机制/ ,/ 从而/ 取消/ ROB/ ./ CPR/ 结构/ 根据/ 对/ 分支/ 预测/ 可信度/ 评估/ ,/ 对/ 低/ 可信/ 分支/ 点/ 建立/ 检查点/ ,/ 通过/ 维护/ 映像/ 表/ 检查点/ 的/ 踪迹/ ,/ 实现/ 了/ 快速/ 分支/ 误/ 预测/ 恢复/ 机制/ ,/ 8/ 个/ 检查点/ 就/ 足以/ 支持/ 基于/ ROB/ 分支/ 误/ 预测/ 恢复/ 机制/ 的/ 2048/ 个/ 入口/ 的/ 指令/ 窗口/ ./ 使用/ 相同/ 的/ 机制/ ,/ 可以/ 实现/ 精确/ 中断/ 、/ 例外/ 以及/ 与/ 系统结构/ 相关/ 的/ 串行化/ 指令/ 的/ 处理/ ./ 虽然/ 使用/ 选择性/ 检查点/ 技术/ 可以/ 取消/ ROB/ ,/ 但是/ KIP/ [/ 9/ ]/ 并未/ 完全/ 取消/ ROB/ ,/ 而是/ 在/ 使用/ 多/ 检查点/ 技术/ 的/ 同时/ ,/ 使用/ 了/ 一个/ 小/ 的/ 伪/ ROB/ ./ 伪/ ROB/ 具有/ 和/ ROB/ 同样/ 的/ 功能/ ,/ 不管/ 指令/ 是否/ 完成/ ,/ 处理器/ 以/ 固定/ 的/ 速率/ 移出/ 到达/ 伪/ ROB/ 头部/ 的/ 指令/ ./ 由于/ 处理器/ 状态/ 可以/ 从伪/ ROB/ 恢复/ ,/ 所以/ 只有/ 当/ 没有/ 完成/ 的/ 指令/ 离开/ 伪/ ROB/ 时才/ 有/ 必要/ 生成/ 检查点/ ./ 因为/ 超过/ 90/ %/ 的/ 分支/ 误/ 预测/ 的/ 指令/ 仍旧/ 保留/ 在/ 伪/ ROB/ 中/ ,/ 这/ 就/ 意味着/ 大部分/ 的/ 分支/ 误/ 预测/ 不必/ 回滚/ 到/ 检查点/ 来/ 恢复/ 系统/ 状态/ ./ 这种/ 使用/ 伪/ ROB/ 延迟/ 生成/ 检查点/ 的/ 方法/ 减少/ 了/ 分支/ 误/ 预测/ 恢复/ 对/ 性能/ 的/ 影响/ ./ 4.1/ ./ 2.2/ 物理/ 寄存器/ 文件/ 当/ 指令/ 进入/ IQ/ 和/ ROB/ 时/ ,/ 传统/ 的/ 超标/ 量/ 处理器/ 为/ 体系结构/ 寄存器/ 分配/ 一个/ 物理/ 寄存器/ ,/ 直到/ 后来/ 写/ 同一/ 体系结构/ 寄存器/ 的/ 指令/ 完成/ 确认/ ./ 这样/ ,/ 一条/ 指令/ 将/ 在/ 整个/ 飞行/ 时间/ 内/ 保留/ 它/ 的/ 物理/ 寄存器/ ./ 物理/ 寄存器/ 的/ 生命周期/ 如图/ 3/ 所示/ ,/ 从图/ 3/ 可以/ 看出/ ,/ 物理/ 寄存器/ 的/ 生命周期/ 长于/ 分配/ 它/ 的/ 指令/ 的/ 生命周期/ ./ 由于/ 大多数/ 飞行/ 指令/ 都/ 需/ 分配/ 物理/ 寄存器/ ,/ 因此/ ,/ 物理/ 寄存器/ 文件/ 的/ 大小/ 需要/ 与/ 指令/ 窗口/ 的/ 大小/ 成/ 比例/ 增加/ ./ Page6/ 物理/ 寄存器/ 虽然/ 分配/ 很早/ ,/ 但是/ 写入/ 却/ 很/ 晚/ ./ 期间/ ,/ 其/ 主要/ 功能/ 是/ 跟踪/ 数据/ 相关性/ ./ 因此/ ,/ 实际上/ 物理/ 寄存器/ 资源/ 很/ 长时间/ 是/ 没用/ 的/ ;/ 唯一/ 重要/ 的/ 是/ 它/ 的/ 名字/ ./ 基于/ 此/ ,/ 人们/ 提出/ 了/ 基于/ 虚拟/ 寄存器/ (/ VR/ )/ 的/ 物理/ 寄存器/ 晚/ 分配/ 技术/ ,/ 对/ 每条/ 重命名/ 指令/ 仅/ 分配/ 一个/ 虚拟/ 标志/ ,/ 用以/ 跟踪/ 数据/ 相关性/ ,/ 而/ 不/ 分配/ 实际/ 物理/ 寄存器/ ,/ 直到/ 产生/ 结果/ 时/ ,/ 才/ 分配/ 物理/ 寄存器/ ./ 传统/ 的/ 释放/ 物理/ 寄存器/ 的/ 规则/ 也/ 过于/ 保守/ ./ 理论/ 上/ ,/ 只要/ 没有/ 后续/ 指令/ 再读/ 该/ 物理/ 寄存器/ 的/ 值/ ,/ 该/ 物理/ 寄存器/ 就/ 可/ 释放/ ./ 早/ 释放/ 物理/ 寄存器/ 的/ 一种/ 可行/ 的/ 实现/ 方法/ 是/ ,/ 为/ 每个/ 物理/ 寄存器/ 关联/ 一个/ 使用/ 计数器/ ,/ 用来/ 跟踪/ 读该/ 寄存器/ 的/ 未/ 执行/ 指令/ ./ 指令寄存器/ 重命名/ 后/ ,/ 将会读/ 这个/ 寄存器/ 的/ 指令/ 加/ “/ 1/ ”/ 使用/ 计数器/ ;/ 读完/ 之后/ 减/ “/ 1/ ”/ 使用/ 计数器/ ./ 当/ 使用/ 计数器/ 为/ “/ 0/ ”/ 时/ ,/ 释放/ 该/ 物理/ 寄存器/ ./ CPR/ 基于/ 多/ 检查点/ 机制/ 实现/ 了/ 寄存器/ 早/ 释放/ 策略/ ,/ 因为/ 检查点/ 提供/ 了/ 恢复/ 正确/ 体系结构/ 状态/ 的/ 能力/ ./ 只要/ 对应/ 的/ 检查点/ 不/ 释放/ ,/ 属于/ 该/ 检查点/ 的/ 寄存器/ 就/ 不/ 应该/ 释放/ ./ CPR/ 在/ 创建/ 检查点/ 时/ ,/ 将/ 属于/ 该/ 检查点/ 的/ 所有/ 寄存器/ 的/ 使用/ 计数器/ 加/ “/ 1/ ”/ ,/ 释放/ 时减/ “/ 1/ ”/ ,/ 寄存器/ 的/ 使用/ 计数器/ 为/ “/ 0/ ”/ 时/ 释放/ 该/ 寄存器/ ./ 文献/ [/ 12/ ]/ 提出/ 了/ “/ 后/ 端/ 重命名/ ”/ 的/ 概念/ ./ CFP/ 在/ 将/ cache/ 失效/ 及其/ 相关/ 指令/ (/ Slice/ 指令/ )/ 送入/ Slice/ 指令/ 处理部件/ SPU/ 的/ 数据/ 缓冲器/ SDB/ 的/ 同时/ ,/ 将/ Slice/ 指令/ 的/ 源/ 寄存器/ 数据/ 和/ 物理/ 寄存器/ 映射/ 等/ 信息/ 一并/ 存入/ SDB/ ,/ 在/ Slice/ 指令/ 返回/ 指令/ 流水线/ 之前/ ,/ 使用/ 物理/ 寄存器/ 到/ 物理/ 寄存器/ 的/ 重/ 映射/ 为/ 前端/ 已/ 重命名/ 的/ Slice/ 指令/ 分配/ 新/ 的/ 物理/ 寄存器/ ./ 这/ 使得/ CFP/ 可以/ 在/ Slice/ 指令/ 送入/ SPU/ 后/ 立即/ 释放/ Slice/ 指令/ 的/ 物理/ 寄存器/ ./ 和/ CPR/ 类似/ ,/ KIP/ 也/ 是/ 基于/ 多/ 检查点/ 机制/ ,/ 提出/ 的/ 一种/ 称之为/ “/ 短暂/ (/ ephemeral/ )/ ”/ 寄存器/ 的/ 技术/ [/ 9/ ]/ ,/ 将/ 寄存器/ 释放/ 与/ 指令/ 提交/ 分离/ 、/ 寄存器/ 分配/ 与/ 指令/ 重命名/ 分离/ ,/ 结合/ 了/ 上述/ 寄存器/ 早/ 释放/ 和/ 晚/ 分配/ 两种/ 技术/ ,/ 有效/ 缩减/ 了/ 物理/ 寄存器/ 的/ 生命期/ ./ Cherry/ [/ 14/ ]/ 则/ 结合/ ROB/ 和/ 单/ 检查点/ 技术/ ,/ 将/ ROB/ 分为/ 两个/ 区/ :/ 前瞻/ 区/ 和/ 非/ 前瞻/ 区/ ,/ 仅/ 对/ 非/ 前瞻/ 区内/ 指令/ 的/ 物理/ 寄存器/ 和/ LSQ/ 入口/ 实施/ 早/ 释放/ 策略/ ,/ 利用/ 检查点/ 提供/ 精确/ 处理/ ./ 对/ 前瞻/ 区/ 的/ 指令/ 仍然/ 依赖/ ROB/ 恢复/ 正确/ 的/ 系统结构/ 状态/ ./ 4.2/ 数据/ 预取/ 与/ 推测/ 执行/ 如果说/ ,/ 扩展/ 指令/ 窗口/ 是/ 通过/ 提高/ ILP/ 间接/ 提高/ MLP/ 的话/ ,/ 数据/ 预取/ 则/ 是/ 通过/ 数据/ 预取/ 访存/ 操作/ 直接/ 提高/ MLP/ ./ 数据/ 预取/ 的/ 通常/ 方法/ 是/ ,/ 通过/ 硬件/ 或/ 软件/ 的/ 方法/ 启发式/ 地/ 识别/ 应用程序/ 的/ 寻址/ 模式/ ,/ 预测/ 未来/ 最/ 可能/ 被/ 请求/ 的/ Load/ 指令/ 的/ 存储器/ 地址/ ,/ 在/ 数据/ 实际/ 使用/ 之前/ 对/ 数据/ 提前/ 读取/ ./ 然而/ ,/ 由于/ 应用/ 的/ 复杂性/ ,/ 程序/ 的/ 寻址/ 模式/ 有时/ 很难/ 预测/ ,/ 例如/ 指针/ 追踪/ (/ pointer/ -/ chasing/ )/ 应用/ ;/ 而且/ ,/ 随着/ 访存/ 延迟/ 越来越/ 大/ ,/ 预取/ 地址/ 预测/ 也/ 越来越/ 困难/ ;/ 加之/ 无效/ 预取/ 将/ 加大/ 存储器/ 访问/ 流量/ 的/ 浪费/ ,/ 因此/ ,/ 提高/ 预取/ 的/ 精度/ 已/ 成为/ 数据/ 预取/ 的/ 关键/ ./ 4.2/ ./ 1Runahead/ 执行/ Runahead/ 执行/ [/ 15/ ]/ 或预/ 执行/ [/ 16/ ]/ 模式/ 是/ 一种/ 硬件/ 精确/ 预取/ 方法/ ./ 当/ 处理器/ 由于/ 长/ 延迟/ L2Cache/ 失效/ 指令/ 停顿/ 时/ ,/ 当前/ 状态/ 进入/ 检查点/ ,/ 处理器/ 从/ 正常/ 执行/ 模式/ 转入/ Runahead/ 执行/ 模式/ ,/ 使用/ 空闲/ 的/ 执行/ 逻辑/ 执行/ 后续/ 不/ 相关/ 指令/ ,/ 实现/ 对/ 未来/ 数据/ 的/ 精确/ 预取/ ./ 当/ L2Cache/ 失效/ 指令/ 完成/ 时/ ,/ 处理器/ 返回/ 正常/ 执行/ 模式/ ,/ 回滚/ 到/ 检查点/ ,/ 重新/ 执行/ L2Cache/ 失效/ 后/ 的/ 指令/ ./ Runahead/ 执行/ 模式/ 如图/ 4/ 所示/ ./ 处理器/ 由于/ Mem1/ 指令/ 停顿/ 以后/ ,/ 建立/ 检查点/ ,/ 进入/ Runahead/ 执行/ 模式/ ,/ 向前/ 执行/ 与/ Mem1/ 无关/ 的/ 指令/ ./ 这些/ 无关/ 指令/ 中/ 包括/ Mem2/ 指令/ ,/ 使得/ Mem2/ 得以/ 提前/ 执行/ ,/ 实现/ 了/ 为/ Exe3/ 精确/ 预取/ 的/ 目的/ ./ Mem1/ 完成/ 后/ ,/ 处理器/ 回到/ 正常/ 模式/ ,/ 回滚/ 到/ 检查点/ ,/ 重新/ 执行/ 停顿/ 后/ 的/ 指令/ ./ 由于/ Mem2/ 已/ 完成/ ,/ 处理器/ 不会/ 因为/ Mem2/ 造成/ 停顿/ ./ 在/ 图/ 4/ 所示/ 的/ 例子/ 中/ ,/ 假设/ Exe2/ 全部/ 为/ 与/ Mem1/ 无关/ 的/ 指令/ ,/ 在/ 不/ 改变/ 指令/ 执行/ 顺序/ 情况/ 下/ ,/ MLP/ 将/ 由/ 图/ 4/ (/ a/ )/ 的/ 1/ 提高/ 到/ 图/ 4/ (/ b/ )/ 的/ 1.48/ ./ Runahead/ 执行/ 模式/ 利用/ 处理器/ 空闲/ 逻辑/ 资源/ 向前/ 执行/ Runahead/ 指令/ ,/ 返回/ 正常/ 模式/ 后/ ,/ Runahead/ 执行/ 结果/ 无论/ 正确/ 与否/ ,/ 全部/ 被/ 丢弃/ ,/ 其/ 优点/ 是/ 不/ 需要/ 多线程/ 的/ 支持/ ,/ 结构/ 简单/ ./ 但/ 同时/ 也/ 存在/ 两大/ 不足/ :/ (/ 1/ )/ 由于/ Runahead/ 模式/ 执行/ 完毕/ 后/ ,/ 总要/ 回滚/ 到/ 检查点/ 重新/ 执行/ ,/ 执行/ 了/ 大量/ 无效/ 的/ 指令/ ,/ 执行/ 的/ Page7/ 总/ 指令/ 数/ 甚至/ 达到/ 程序/ 本身/ 指令/ 数/ 的/ 两三倍/ 以上/ [/ 17/ ]/ ,/ 大大/ 浪费/ 了/ 处理器/ 性能/ 和/ 功耗/ ;/ (/ 2/ )/ 由于/ 不能/ 执行/ 与/ 停顿/ 相关/ 的/ 指令/ ,/ 特别/ 是/ 相关/ 的/ 长/ 延迟/ 存储/ 指令/ ,/ 不利于/ 存储/ 级/ 并行/ ,/ 影响/ 了/ Runahead/ 的/ 预取/ 效果/ ./ 4.2/ ./ 2/ 基于/ 值/ 预测/ 的/ 推测/ 执行/ 针对/ Runahead/ 模式/ 的/ 上述/ 两点/ 不足/ ,/ 人们/ 结合/ 值/ 预测/ 技术/ 提出/ 了/ 许多/ 改进/ 方法/ ./ CAVA/ [/ 18/ ]/ 和/ CLEAR/ [/ 19/ ]/ 等/ 采用/ 基于/ 检查点/ 的/ 值/ 预测/ 方法/ ,/ 在/ 长/ 延迟/ Load/ 失效/ 到达/ ROB/ 头时/ 设置/ 检查点/ ,/ 提交/ Load/ 指令/ ,/ 并/ 预测/ Load/ 值/ ,/ 使用/ 预测值/ 推测/ 地/ 继续执行/ ./ 当/ 失效/ Load/ 指令/ 最终/ 从/ 存储器/ 返回/ 数据/ 时/ ,/ 返回/ 数据/ 和/ 预测/ Load/ 值/ 进行/ 比较/ ,/ 如果/ 预测/ 正确/ ,/ 就/ 不/ 进行/ 回滚/ ,/ 程序/ 继续/ 正常/ 执行/ ./ 如果/ 预测/ 不/ 正确/ ,/ 就/ 回滚/ 到/ 检查点/ 重新/ 执行/ ./ 与/ CAVA/ 不同/ 的/ 是/ ,/ CLEAR/ 采用/ 了/ 多/ 检查点/ 的/ Runahead/ 设计/ ,/ 在/ 推测/ 执行/ 模式/ 下/ ,/ 如果/ 出现/ 另/ 一个/ Load/ 失效/ ,/ 硬件/ 可/ 根据/ 预测器/ 的/ 可信度/ 决定/ 是否/ 创建/ 另/ 一个/ 检查点/ ./ 显然/ ,/ CAVA/ 和/ CLEAR/ 通过/ 值/ 预测/ ,/ 能够/ 推测/ 执行/ 与/ 长/ 延迟/ Load/ 失效/ 指令/ 无关/ 和/ 相关/ 的/ 指令/ ;/ 当/ 预测值/ 正确/ 的/ 时候/ ,/ 不/ 需要/ 回滚/ ,/ 推测/ 执行/ 的/ 指令/ 正常/ 提交/ ,/ 处理器/ 继续/ 正常/ 执行/ ;/ 当/ 预测值/ 错误/ 的/ 时候/ ,/ 处理器/ 回滚/ 到/ 检查点/ 重新/ 执行/ ,/ 但/ 仍旧/ 实现/ 了/ 精确/ 预取/ ,/ 从而/ 提高/ 了/ Runa/ -/ head/ 执行/ 模式/ 的/ 效率/ ./ 这里/ 重要/ 的/ 是/ 允许/ 与/ 长/ 延迟/ Load/ 失效/ 指令/ 相关/ 的/ 指令/ 、/ 特别/ 是/ 相关/ 的/ Load/ 指令/ 推测/ 执行/ ,/ 提高/ 了/ 处理器/ 的/ 存储/ 级/ 并行/ ./ 虽然/ 值/ 预测/ 允许/ 其它/ 相关/ 指令/ 预先/ 执行/ ,/ 较之/ 预取/ 更/ 能/ 有效/ 提高/ MLP/ ,/ 但是/ 实现/ 值/ 预测/ 需要/ 复杂/ 的/ 硬件/ 支持/ ,/ 包括/ 预测/ 检验/ 和/ 误/ 预测/ 恢复/ ./ Zhou/ 和/ Conte/ [/ 20/ ]/ 提出/ 了/ 一种/ 提高/ MLP/ 的/ 无/ 恢复/ 值/ 预测/ 方法/ ,/ 该/ 方法/ 在/ 指令/ 流水线/ 的/ 前端/ 设置/ 一个/ 值/ 预测器/ ,/ 并/ 为/ 每个/ 物理/ 寄存器/ 增加/ 一位/ “/ 值/ 预测/ 就绪/ (/ vp/ -/ ready/ )/ ”/ 标志/ ,/ 为/ 每个/ 指令流/ 出入口/ 增加/ 一位/ “/ 值/ 预测/ // 推测/ (/ vp/ )/ ”/ 标志/ ./ 指令/ 分派/ 阶段/ ,/ Load/ 预测值/ 写入/ 物理/ 寄存器/ ,/ 并置位/ vp/ -/ ready/ 标志/ ./ 指令/ 流出/ 阶段/ ,/ 如果/ 指令/ 源/ 寄存器/ “/ 就绪/ (/ ready/ )/ ”/ ,/ 指令/ 非/ 推测/ (/ 正常/ )/ 流出/ ;/ 如果/ 指令/ 源/ 寄存器/ “/ 未/ 就绪/ ”/ ,/ 而/ vp/ -/ ready/ 置位/ ,/ 指令/ 推测/ 流出/ ./ 推测/ 流出/ 保存/ 在/ 指令/ 队列/ 中/ ,/ 直到/ 它们/ 使用/ ready/ 源/ 寄存器/ 非/ 推测/ 流出/ 为止/ ./ 这里/ ,/ 值/ 预测/ // 推测/ 执行/ 的/ 结果/ 仅/ 用于/ 数据/ 预取/ ,/ 所有/ 被/ 推测/ 执行/ 的/ 指令/ 都/ 将/ 再次/ 被/ 值/ 预测/ 执行/ ,/ 因而/ 避免/ 了/ 复杂/ 的/ 预测/ 检验/ 和/ 误/ 预测/ 恢复/ 机制/ ,/ 硬件/ 改动/ 很小/ ./ 4.3/ 片上/ 存储系统/ 本文/ 定义/ 的/ 处理器/ 存储/ 级/ 并行/ 是/ 指/ 处理器/ 支持/ 多个/ 因/ 最末/ 一级/ Cache/ 失效/ 导致/ 长/ 延迟/ 外部/ 存储器/ 访问/ 并行执行/ 的/ 能力/ ./ 而要/ 提高/ 处理器/ 的/ 存储/ 级/ 并行/ 能力/ ,/ 一方面/ 需要/ 处理器/ 采取/ 上述/ 技术/ 提高/ CPU/ 流出/ 更/ 多/ 的/ 访存/ 请求/ ,/ 另一方面/ 则/ 需要/ 处理器/ 存储/ 子系统/ ,/ 包括/ 片内/ Cache/ 存储器/ 和/ 片外/ Cache/ 存储器/ ,/ 能够/ 支持/ CPU/ 流出/ 的/ 访存/ 请求/ 并行执行/ ./ 当前/ 对于/ 片上/ 存储/ 子系统/ 的/ 改进/ 主要/ 有/ 两/ 方面/ :/ 第一/ 增大/ Cache/ 失效/ 处理/ 结构/ ,/ 提高/ 对/ 存储/ 级/ 并行/ 的/ 支持/ ;/ 第二/ 采用/ 面向/ MLP/ 优化/ 的/ Cache/ 替换/ 策略/ ./ 4.3/ ./ 1Cache/ 失效/ 处理/ 结构/ (/ MHA/ )/ 存储/ 子系统/ 中/ 不同/ 层次/ 存储器/ 支持/ 的/ 存储/ 级/ 并行度/ 是/ 不同/ 的/ ,/ 越里层/ 存储器/ 的/ 存储/ 级/ 并行/ 需求/ 越高/ ./ Ceze/ 等/ 人/ 对/ 3/ 种/ 处理器/ 类型/ 的/ 并行/ L1Cache/ 读/ 失效/ 数目/ 分布/ 进行/ 了/ 模拟/ 分析/ [/ 21/ ]/ ,/ 结果表明/ ,/ 常规/ 处理器/ 90/ %/ 应用/ 的/ 并行/ L1Cache/ 读/ 失效/ 数/ 小于/ 等于/ 16/ ;/ 而/ 基于/ 检查点/ 和/ 使用/ 大/ 指令/ 窗口/ 的/ 高/ MLP/ 新型/ 处理器/ ,/ 某些/ 应用/ 的/ 并行/ L1Cache/ 读/ 失效/ 数/ 大于/ 等于/ 120/ ,/ 并/ 占有/ 较大/ 比例/ ./ 新近/ 提出/ 的/ CPR/ 和/ CFP/ 微/ 体系结构/ 也/ 都/ 假设/ 同时/ 支持/ 128/ 个/ L1Cache/ 失效/ ./ 而/ 现在/ 的/ 处理器/ ,/ 即使/ 是/ 高端/ 微处理器/ 也/ 远/ 不能/ 支持/ 这个/ 级别/ 的/ 需求/ ,/ 例如/ Pentium4/ 仅/ 同时/ 支持/ 8/ 个/ L1Cache/ 失效/ [/ 22/ ]/ ./ Cache/ 失效/ 处理/ 结构/ MHA/ (/ MissHandlingArchitecture/ )/ 是/ Cache/ 中/ 处理/ Cache/ 失效/ 的/ 逻辑/ ./ 失效/ 信息/ // 状态/ 保存/ 寄存器/ MSHR/ (/ MissInforma/ -/ tion/ // StatusHoldingRegister/ )/ [/ 23/ ]/ 是/ 实现/ 非/ 阻塞/ MHA/ 的/ 关键/ 数据结构/ ,/ 用于/ 保存/ Cache/ 失效/ 请求/ 地址/ 、/ 请求/ 大小/ 和/ 请求/ 类型/ 等/ 信息/ ./ Ceze/ 等/ 人/ 评估/ 了/ 上述/ 3/ 类/ 处理器/ 对/ MHA/ 的/ 需求/ [/ 21/ ]/ ,/ 假设/ 一个/ MSHR/ 保存/ 同一/ L1Cache/ 行/ 所有/ 失效/ 的/ 状态/ 信息/ ,/ 对/ 大多数/ 应用/ ,/ 要/ 覆盖/ 95/ %/ 的/ L1Cache/ 读/ 失效/ ,/ 常规/ 处理器/ 需要/ 8/ 个/ MSHR/ ,/ 基于/ 检查点/ 的/ 处理器/ 需要/ 32/ 个/ MSHR/ ,/ 使用/ 大/ 指令/ 窗口/ 的/ 处理器/ 需要/ 更/ 多/ 的/ MSHR/ ./ Ceze/ 等/ 人/ 同时/ 提出/ 了/ 一种/ 新型/ 的/ 可/ 扩展/ MHA/ 设计/ [/ 24/ ]/ ,/ 采用/ 层次/ 式/ MSHR/ 文件/ 扩展/ MHA/ 的/ 大小/ ,/ 同时/ 使用/ Bloom/ 过滤器/ 缩减/ MSHR/ 文件/ 的/ 搜索/ 时间/ ,/ 可/ 实现/ 接近/ 于/ 无限/ 大小/ 的/ 理想/ MHA/ 的/ 性能/ ./ 4.3/ ./ 2Cache/ 替换/ 策略/ 对于/ 每个/ Cache/ 失效/ 的/ 访存/ 操作/ ,/ 有些/ 可以/ 和/ 其它/ 失效/ 访存/ 并行执行/ ,/ 比如/ 读取/ 数组/ ,/ 有些/ 则/ 无法/ 和/ 其它/ 失效/ 访存/ 并行/ ,/ 如/ 指针/ 追踪/ ,/ 它们/ 的/ 系统/ 性能/ Page8/ 成本/ 是/ 不同/ 的/ ./ 无法/ 并行执行/ 的/ 独立/ 失效/ 访存/ 的/ 性能/ 成本/ 远大于/ 并行/ 失效/ 访存/ 的/ 性能/ 成本/ ./ 据此/ ,/ Qureshi/ 等/ 人/ 提出/ 了/ 一种/ 存储/ 级/ 并行/ 敏感/ 的/ Cache/ 替换/ 策略/ [/ 25/ ]/ ./ 通过/ 实时/ 计算/ 每个/ Cache/ 失效/ 的/ 基于/ 存储/ 级/ 并行/ 的/ 性能/ 代价/ mlp/ -/ cost/ ,/ 优先/ 替换/ mlp/ -/ cost/ 低/ 的/ Cache/ 块/ ,/ 以/ 达到/ 尽量减少/ 无法/ 并行执行/ 的/ 独立/ Cache/ 失效/ 的/ 数目/ ,/ 提高/ 系统/ 性能/ 的/ 目的/ ./ 4.4/ 多线程/ 处理器/ 前面/ 介绍/ 的/ 提高/ 存储/ 级/ 并行/ 技术/ 主要/ 着眼于/ 提高/ 传统/ 处理器/ 单线程/ 流出/ 与/ 停顿/ 指令/ 相关/ 和/ 非/ 相关/ 访存/ 指令/ 的/ 能力/ ,/ 而/ 实际上/ ,/ 由于/ 受到/ 设计/ 复杂性/ 、/ 时钟/ 频率/ 、/ 面积/ 有效性/ 和/ 能耗/ 有效性/ 等/ 因素/ 的/ 限制/ ,/ 单线程/ MLP/ 的/ 提高/ 是/ 有限/ 的/ ./ 多线程/ 处理器/ 则/ 是/ 通过/ 硬件/ 线程/ 维护/ 每个/ 线程/ 的/ 系统结构/ 状态/ (/ Context/ )/ ,/ 支持/ 线程/ 切换/ 和/ 并行/ 来/ 提高/ 处理器/ 流出/ 更多/ 访存/ 指令/ 的/ 能力/ ,/ 提高/ 处理器/ 的/ 存储/ 级/ 并行/ ./ 多线程/ 处理器/ 提高/ 存储/ 级/ 并行/ 如图/ 5/ 所示/ ./ 同时/ 多线程/ (/ SMT/ )/ 利用/ 乱序执行/ 机制/ ,/ 允许/ 每个/ 时钟/ 周期/ 流出/ 多个/ 线程/ 的/ 指令/ ,/ 同时/ 支持/ 活跃/ 线程/ 占用/ 其它/ 因长/ 延迟/ 指令/ 而/ 导致/ 流水线/ 停顿/ 线程/ 的/ 流出/ 窗口/ ,/ 多个/ 线程/ 可/ 同时/ 执行/ ,/ 线程/ 间/ 无需/ 文本/ 切换/ ,/ 从而/ 进一步提高/ 了/ 多线程/ 处理器/ 的/ 存储/ 级/ 并行/ ,/ 同时/ 提高/ 了/ 处理器/ 的/ 资源/ 利用率/ ./ 不同/ 线程/ 的/ 访存/ 并行执行/ ,/ 虽然/ 看起来/ 不会/ 提高/ 单线程/ 的/ MLP/ ,/ 但是/ ,/ 多线程/ 处理器/ 使/ 利用/ 辅助线/ 程/ [/ 26/ ]/ 协助/ 主线/ 程/ 的/ 预取/ 成为/ 可能/ ,/ 从而/ 可以/ 提高/ 单线程/ 的/ MLP/ ./ 现有/ 的/ 同时/ 多线程/ 处理器/ 取指/ 策略/ 主要/ 包括/ 两类/ ./ 一类/ 选择/ 流水线/ 中/ 指令/ 数/ 最少/ 的/ 线程/ 取指/ ,/ 试图/ 平衡/ 流水线/ 中/ 各/ 线程/ 的/ 指令/ 数/ ;/ 一类/ 检测/ 或/ 预测/ 到/ 线程/ 长/ 延迟/ Load/ 指令/ 时/ 暂停/ 该/ 线程/ 的/ 取指/ ,/ 甚至/ 清除/ 该/ 线程/ 长/ 延迟/ Load/ 指令/ 后/ 的/ 指令/ ,/ 以/ 释放/ 暂停/ 线程/ 分配/ 的/ 资源/ ,/ 提高/ 其它/ 非/ 暂停/ 线程/ 的/ 性能/ ./ 但是/ 它们/ 都/ 未/ 考虑/ 长/ 延迟/ Load/ 指令/ 的/ 存储/ 级/ 并行/ ,/ 由于/ 暂停/ 被/ 阻塞/ 线程/ 的/ 取指/ ,/ 可能/ 使/ 原本/ 可以/ 并行执行/ 的/ 不/ 相关/ 长/ 延迟/ Load/ 指令/ 串行化/ ./ Eyeman/ 等/ [/ 27/ ]/ 提出/ 了/ 一种/ 存储/ 级/ 并行/ 感知/ 的/ 取指/ 策略/ ,/ 通过/ 预测/ 给定/ 线程/ 长/ 延迟/ Load/ 指令/ 的/ 存储/ 级/ 并行/ 数/ ,/ 按/ 预测/ 的/ 存储/ 级/ 并行/ 数控/ 制取/ 指/ 数目/ ,/ 使得/ 存在/ 存储/ 级/ 并行/ 的/ 线程/ 可以/ 获得/ 与/ 存储/ 级/ 并行/ 数/ 相适应/ 的/ 执行/ 资源/ ,/ 达到/ 进一步提高/ 性能/ 的/ 目的/ ./ Ram/ í/ rez/ 等/ [/ 28/ ]/ 将/ Runahead/ 技术/ 与/ SMT/ 相结合/ ,/ 在/ 一个/ 线程/ 因长/ 延迟/ Load/ 指令/ 而/ 停止/ 时/ ,/ 进入/ Runahead/ 执行/ 模式/ ,/ 尽量/ 使用/ 最少/ 的/ 资源/ 来/ 推测/ 执行/ ,/ 在/ 解决/ SMT/ 资源/ 竞争/ 的/ 同时/ ,/ 提高/ MLP/ ./ 为了/ 减少/ Ram/ í/ rez/ 方法/ 在/ Runahead/ 执行/ 周期/ 中线/ 程/ 可能/ 执行/ 的/ 无效/ 指令/ 数目/ ,/ VanCraeynest/ 等/ [/ 29/ ]/ 使用/ MLP/ 预测器/ 来/ 决定/ 线程/ 是否/ 进入/ Runahead/ 模式/ ,/ 如果/ 无法/ 产生/ 有效/ 的/ 存储/ 级/ 并行/ ,/ 线程/ 将/ 不/ 进入/ Runahead/ 模式/ ,/ 从而/ 减少/ 能量/ 的/ 浪费/ ./ 4.5/ 多核/ 处理器/ 多核/ (/ MultiCore/ )/ 、/ 众核/ (/ Many/ -/ Core/ )/ 处理器/ ,/ 或者/ 片上/ 多处理器/ (/ ChipMultiProcessor/ ,/ CMP/ )/ 在/ 单芯片/ 上/ 集成/ 多个/ 处理器/ 核/ ,/ 每个/ 处理器/ 核/ 拥有/ 各自/ 的/ CPU/ 和/ 私有/ Cache/ ,/ 它们/ 可以/ 是/ 单线程/ 的/ ,/ 也/ 可以/ 是/ 多线程/ 的/ ./ 多核/ 处理器/ 可以/ 理解/ 为/ 多线程/ 处理器/ 的/ 自然/ 延伸/ ,/ 不同/ 的/ 是/ ,/ 多核/ 处理器/ 的/ 处理器/ 核比/ 多线程/ 处理器/ 的/ 硬件/ 线程/ 更/ 独立/ ,/ 它们/ 仅/ 共享/ 片上/ 最末/ 级/ Cache/ (/ Last/ -/ LevelCache/ ,/ LLC/ )/ 和/ 互连/ 网络/ ,/ 其/ 工作/ 方式/ 仍然/ 是/ 线程/ 级/ 并行/ ./ 目前/ ,/ 多核/ 处理器/ 已经/ 成为/ 现代/ 高性能/ 微处理器/ 发展/ 的/ 主流/ ./ 多核/ 处理器/ 通过/ 在/ 多个/ 处理器/ 核上/ 并行/ 运行/ 多个/ 线程/ 来/ 提高/ 处理器/ 的/ 存储/ 级/ 并行/ 能力/ ,/ 多核/ 处理器/ 存储/ 级/ 并行/ 如图/ 6/ 所示/ ./ 4.5/ ./ 1/ 高/ 存储/ 级/ 并行/ 顺序/ 处理器/ 核/ 由于/ 多核/ 处理器/ 芯片/ 面积/ 和/ 功耗/ 的/ 限制/ ,/ 顺序/ (/ in/ -/ order/ )/ 处理器/ 再度/ 受到/ 人们/ 的/ 关注/ ./ 某些/ 设计/ 强调/ 吞吐量/ 计算/ ,/ 而/ 不是/ 单线程/ 的/ 性能/ ,/ 如/ SunUltra/ -/ SPARCT1/ ,/ 采用/ 较/ 多/ 的/ 简单/ 的/ 顺序/ 处理器/ 核/ 取代/ 较少/ 的/ 复杂/ 的/ 乱序/ 处理器/ 核/ ./ 像/ IBMPower6/ 这样/ 的/ 高性能/ 处理器/ 也/ 放弃/ 了/ 乱序执行/ ,/ 转而/ 采用/ 顺序/ 处理器/ 核/ ./ 为了/ 弥补/ 顺序/ 处理器/ 核/ 带来/ 的/ 单线程/ 性能/ 的/ 不足/ ,/ 人们/ 试图/ 将/ 前面/ 介绍/ 的/ 乱序/ 超标/ 量/ 处理器/ 提高/ 存储/ 级/ 并行/ 的/ 方法/ 应用/ 于/ 顺序/ 流水线/ ,/ 提高/ 顺序/ 处/ Page9/ 理器/ 核/ 的/ 存储/ 级/ 并行/ ,/ 改善/ 单核/ 单线程/ 的/ 处理/ 性能/ ./ IBMPower6/ [/ 30/ ]/ 首先/ 将/ Runahead/ 执行/ 模式/ 应用/ 于/ 顺序/ 处理器/ 核/ ,/ Power6/ 称之为/ LoadLookAhead/ (/ LLA/ )/ 模式/ ./ 处理器/ 的/ 每个/ 核/ 可以/ 同时/ 执行/ 两个/ 线程/ ,/ 当/ 一个/ 线程/ 发生/ Cache/ 失效/ 时/ ,/ 该/ 线程/ 进入/ LLA/ 模式/ ,/ 预取/ 后继/ 不/ 相关/ 指令/ 的/ 数据/ ,/ 同时/ 降低/ 该/ 线程/ 的/ 优先级/ ,/ 以/ 减少/ 对/ 正常/ 执行/ 线程/ 资源/ 的/ 竞争/ ,/ 当/ Cache/ 失效/ 数据/ 返回/ 时/ ,/ 该/ 线程/ 回复/ 到/ 初始/ 的/ 优先级/ ./ LLA/ 模式/ 所有/ 的/ 执行/ 结果/ 都/ 会/ 被/ 丢弃/ ,/ 但/ 如果/ 处理器/ 核/ 处于/ 单线程/ 模式/ ,/ 执行/ 结果/ 会/ 写入/ 空闲/ 线程/ 的/ 寄存器/ 中/ ,/ 使/ 更/ 多/ 的/ 后继/ 指令/ 可以/ 执行/ ,/ 以/ 提高/ 预取/ 的/ 效果/ ./ SunROCK/ [/ 30/ -/ 32/ ]/ 处理器/ 同样/ 吸取/ 了/ Runahead/ 的/ 思想/ ,/ Sun/ 称之为/ ExecuteAhead/ (/ EA/ )/ 模式/ ./ 当/ 线程/ 遇到/ 长/ 延迟/ 指令/ 时/ ,/ 建立/ 检查点/ ,/ 启动/ EA/ 模式/ ./ 长/ 延迟/ 指令/ 的/ 目标/ 寄存器/ 标记/ 为/ 不可/ 用/ (/ NA/ )/ ,/ 长/ 延迟/ 指令/ 送入/ 推迟/ 执行/ 队列/ DQ/ ,/ 至少/ 有/ 一个/ 源/ 操作数/ 标记/ 为/ NA/ 的/ 后续/ 指令/ 的/ 目标/ 寄存器/ 也/ 标记/ 为/ NA/ ,/ 指令/ 送入/ DQ/ ./ 没有/ 操作数/ 标记/ 为/ NA/ 的/ 后续/ 指令/ 继续执行/ ,/ 结果/ 写入/ 目标/ 寄存器/ 的/ 推测/ 拷贝/ ./ 当长/ 延尺/ 指令/ 完成/ 时/ ,/ 线程/ 从/ EA/ 模式/ 转换/ 到/ 重/ 执行/ 模式/ ,/ 从/ DQ/ 中/ 读出/ 被/ 推迟/ 指令/ 重新/ 执行/ ./ 当/ DQ/ 中/ 的/ 指令/ 执行/ 完毕/ ,/ 处理器/ 执行/ 合并/ 操作/ ,/ 并/ 将/ 目标/ 寄存器/ 的/ 推测/ 拷贝/ 中/ 的/ 结果/ 更新/ 到/ 体系结构/ 寄存器/ 中/ ,/ 处理器/ 恢复/ 到/ 正常/ 执行/ 模式/ ./ SLTP/ (/ SimpleLatencyTolerantProcessor/ )/ [/ 30/ ]/ 和/ iCFP/ (/ in/ -/ orderCFP/ )/ 处理器/ [/ 33/ ]/ 将/ CFP/ [/ 12/ ]/ 技术/ 应用/ 于/ 顺序/ 处理器/ 核中/ ./ SLTP/ 在/ Load/ 指令/ Cache/ 失效/ 时/ 建立/ 第一个/ 检查点/ ,/ 失效/ 指令/ 及其/ 相关/ 指令/ 移出/ 流水线/ ,/ 失效/ 指令/ 及其/ 相关/ 指令/ 连同/ 它们/ 的/ 输入/ 寄存器/ 的/ 值/ 按程序/ 顺序/ 存入/ SDB/ ,/ 失效/ 无关/ 指令/ 与/ 失效/ 指令/ 并行执行/ ./ 当/ 失效/ 数据/ 返回/ 时/ ,/ SLTP/ 建立/ 第二个/ 检查点/ ,/ 执行/ 切换/ 到/ SDB/ 指令/ ./ 当/ SDB/ 中/ 所有/ 指令/ 被/ 执行/ ,/ 执行/ 结果/ 从/ 第二/ 检查点/ 与/ 失效/ 无关/ 指令/ 执行/ 结果/ 合并/ ,/ 然后/ 取消/ 检查点/ ,/ 恢复/ 到/ 正常/ 执行/ 状态/ ./ SLTP/ 和/ iCFP/ 通过/ 将/ 非/ 阻塞/ 流水/ 技术/ 应用/ 于/ 顺序/ 处理器/ 核/ ,/ 既保证/ 了/ 处理器/ 核/ 的/ 简单/ 性/ ,/ 又/ 提高/ 了/ 单/ 处理器/ 核/ 的/ 性能/ ,/ 以便/ 在/ 单芯片/ 中/ 集成/ 更/ 多/ 的/ 处理器/ 核/ ./ 4.5/ ./ 2/ 面向/ 存储/ 级/ 并行/ 的/ 异构/ 多核/ 处理器/ Patsilaras/ 等/ 人/ [/ 34/ ]/ 首次/ 设计/ 了/ 一个/ 结合/ 高/ ILP/ 处理器/ 核/ 和/ 定制/ 高/ MLP/ 处理器/ 核/ 的/ 非对称/ 多核/ 处理器/ AMP/ (/ AsymmetricMulticoreProcessors/ )/ ,/ 定制/ 高/ MLP/ 处理器/ 核/ 采用/ 类似/ 于/ CAVA/ [/ 18/ ]/ 和/ CLEAR/ [/ 19/ ]/ 设计/ 思想/ 的/ CLP/ +/ VP/ (/ CheckpointedL2MissProcessingwithValuePrediction/ )/ 结构/ ./ 作者/ 提出/ 了/ 一种/ 细粒度/ 的/ 硬件/ 调度/ 算法/ ,/ 根据/ 应用/ 的/ L2Cache/ 失效/ 行为/ 即时/ 地/ 将/ 具有/ MLP/ 潜能/ 的/ 应用/ 段/ 切换/ 到/ MLP/ 处理器/ 核上/ 执行/ ,/ 将/ 不具/ MLP/ 潜能/ 的/ 应用/ 段/ 放在/ 通用/ 处理器/ 核上/ 执行/ ,/ 以此/ 提高/ 多核/ 处理器/ 的/ 性能/ ./ 灵活/ 异构/ 多核/ 处理器/ FMC/ (/ FlexibleHeteroge/ -/ neousMulti/ -/ CoreProcessor/ )/ [/ 35/ ]/ 由/ 快速/ 的/ Cache/ 处理器/ 和/ 存储/ 处理器/ 组成/ ./ Cache/ 处理器/ 用于/ 处理/ 数据/ 来自/ 寄存器/ 和/ Cache/ 的/ 指令/ ,/ 存储/ 处理器/ 则/ 用于/ 处理/ 与/ 主存/ 相关/ 的/ 指令/ ./ 小型/ 顺序存储/ 处理器/ 以/ 类似/ runahead/ 执行/ 的/ 方式/ 将/ Cache/ 失效/ 数据/ 读取/ 到/ Cache/ 中/ ,/ 使得/ Cache/ 处理器/ 可以/ 高速/ 地/ 执行/ 指令/ ,/ 而/ 不/ 发生/ Cache/ 失效/ ./ FMC/ 中/ 存储/ 处理器/ 的/ 预取/ 能力/ 及/ 多个/ 存储/ 处理器/ 的/ 可/ 配置/ 能力/ 有效/ 提高/ 了/ FMC/ 的/ 存储/ 级/ 并行/ ./ 4.5/ ./ 3/ 面向/ 存储/ 级/ 并行/ 优化/ 的/ Cache/ 管理/ 多核/ 处理器/ 的/ Cache/ 划分/ 大部分/ 基于/ 减少/ 失效/ 次数/ 或者/ 系统/ 公平性/ ,/ 而/ 没有/ 考虑/ 存储/ 访问/ 的/ 并行性/ ./ 单个/ 的/ Cache/ 失效/ 和/ 成/ “/ 簇/ ”/ 的/ Cache/ 失效/ 对/ 处理器/ 性能/ 的/ 影响/ 是/ 不同/ ,/ 单个/ Cache/ 失效/ 由于/ 无法/ 并行/ ,/ 对系统/ 性能/ 影响/ 更大/ ./ 因此/ Moret/ ó/ 等/ 人/ [/ 36/ ]/ 提出/ 了/ 一种/ 存储/ 级/ 并行/ 敏感/ 的/ Cache/ 划分/ 方法/ ./ 通过/ 修改/ MSHR/ 来/ 记录/ Cache/ 失效/ 发生/ 的/ 时机/ ,/ 并且/ 根据/ MSHR/ 记录/ 的/ 信息/ 计算/ 不同/ 程序/ 的/ 实际/ 失效/ 开销/ ,/ 并/ 据此/ 开销/ 进行/ 共享/ Cache/ 的/ 划分/ ./ 最后/ 一级/ Cache/ 的/ MSHR/ 通常/ 是/ 多/ 核/ 处理器/ 的/ 共享资源/ ,/ 多个/ 线程/ 的/ 存储/ 访问/ 会/ 互相/ 影响/ ,/ 使得/ 线程/ 的/ 性能/ 难以预测/ ./ 尤其/ 当/ 部分/ 处理器/ 核/ 恶意/ 地/ 发出/ 大量/ 的/ 存储器/ 访问/ 请求/ 时/ ,/ 会/ 完全/ 占用/ MSHR/ 的/ 入口/ ,/ 从而/ 形成/ 拒绝服务/ 攻击/ ./ 针对/ 这个/ 问题/ ,/ Jahre/ 等/ [/ 37/ ]/ 在/ 最后/ 一级/ CacheMSHR/ 的/ 分配/ 时/ 加以/ 管理/ ,/ 限制/ 一个/ 线程/ 过多地/ 占用/ MSHR/ 入口/ ,/ 在/ 提高/ 存储/ 级/ 并行/ 的/ 同时/ 保证/ 不同/ 任务/ 之间/ 的/ 公平性/ ./ 5/ 今后/ 的/ 研究/ 方向/ 上面/ 介绍/ 了/ 存储/ 级/ 并行/ 概念/ 的/ 提出/ 及其/ 定义/ ,/ 分析/ 了/ 传统/ 乱序执行/ 、/ 超标/ 量/ 处理器/ 体系结构/ 限制/ 存储/ 级/ 并行/ 的/ 主要/ 因素/ ,/ 重点/ 介绍/ 了/ 当前/ 提高/ 处理器/ 存储/ 级/ 并行/ 的/ 新型/ 微/ 体系结构/ 技术/ ./ 下面/ 简要/ 介绍/ 针对/ 存储/ 级/ 并行/ 需要/ 深入开展/ 的/ 工作/ ,/ 并/ 对/ 今后/ 的/ 研究/ 方向/ 进行/ 探讨/ ./ Page10/ 存储/ 级/ 并行/ 作为/ 一个/ 新/ 的/ 研究课题/ ,/ 虽然/ 对/ 其/ 研究/ 内容/ 已经/ 有/ 了/ 一定/ 的/ 共识/ ,/ 并/ 提出/ 了/ 很多/ 不同/ 的/ 解决方案/ ,/ 但/ 由于/ 许多/ 研究/ 才/ 刚刚/ 起步/ ,/ 很多/ 工作/ 还有/ 待/ 进一步/ 的/ 深入研究/ ,/ 主要/ 包括/ 以下/ 几个/ 方面/ :/ (/ 1/ )/ 进一步/ 研究/ 应用程序/ 的/ 存储/ 级/ 并行/ 特性/ 以及/ 存储/ 级/ 并行/ 对/ 处理器/ 应用/ 性能/ 和/ 执行/ 方式/ 的/ 影响/ ,/ 建立/ 存储/ 级/ 并行执行/ 模型/ 和/ 测试工具/ ,/ 系统性/ 地/ 指导/ 处理器/ 体系结构/ 存储/ 级/ 并行/ 优化/ ./ (/ 2/ )/ 目前/ 存储/ 级/ 并行/ 的/ 研究/ 对/ 浮点/ 应用/ 非常/ 有效/ ,/ 而/ 对/ 整数/ 程序/ 的/ 性能/ 提高/ 不/ 明显/ ./ 整数/ 程序/ 性能/ 提高/ 的/ 主要/ 限制/ 是/ 分支/ 难以预测/ 和/ 指针/ 追踪/ 数据/ 加载/ 难以/ 并行/ 化/ ./ 虽然/ 目前/ 针对/ 指针/ 追踪/ 加载/ 提出/ 了/ 一些/ 预取/ 方法/ ,/ 但/ 仍/ 有待/ 进一步/ 研究/ ./ (/ 3/ )/ 目前/ 存储/ 级/ 并行/ 研究/ 大多/ 集中/ 在/ 存储器/ 读/ 操作/ 上/ ,/ 对/ 存储器/ 写/ 操作/ 并行/ 研究/ 很少/ ,/ 如何/ 克服/ StoreBuffer/ 对/ 处理器/ 性能/ 的/ 限制/ 需要/ 进一步/ 研究/ ./ (/ 4/ )/ 以往/ 的/ 存储/ 级/ 并行/ 研究/ 主要/ 集中/ 在/ 传统/ 乱序/ 超标/ 量/ 处理器/ 体系结构/ 基础/ 上/ ,/ 对多核/ 多线程/ 处理器/ 的/ 存储/ 级/ 并行/ 研究/ 刚刚开始/ ./ 如何/ 利用/ 存储/ 级/ 并行/ 技术/ 平衡/ 多核/ 处理器/ 吞吐量/ 计算/ 与/ 单线程/ 性能/ 是/ 未来/ 的/ 一个/ 研究/ 重点/ ,/ 同时/ 多核/ 多线程/ 处理器/ 的/ 存储系统/ 明显/ 不同于/ 超标/ 量单/ 处理器/ 系统/ ,/ 私有/ 或/ 分布/ 共享/ 多层次/ 片上/ 存储系统/ MHA/ 实现/ 机制/ 、/ 存储/ 级/ 并行/ 与/ Cache/ 一致性/ 的/ 协同/ 、/ 存储/ 控制器/ 及/ 存储/ 访问/ 调度/ 等/ 均/ 需要/ 进一步/ 研究/ ./ (/ 5/ )/ 编译/ 如何/ 根据/ 存储/ 级/ 并行/ 对/ 指令/ 进行/ 调度/ ,/ 这部分/ 研究/ 工作/ 尚未/ 得到/ 足够/ 的/ 重视/ ./ 

