Page1/ 一种/ 基于/ Google/ 的/ OCR/ 结果/ 校对/ 新/ 方法/ 颜建强/ 高新/ 波/ (/ 西安电子科技大学/ 电子/ 工程学院/ 西安/ 710071/ )/ 摘要/ 为了/ 提高/ OCR/ 识别率/ ,/ 许多/ 校对/ 算法/ 被/ 提出/ 用作/ 后处理/ ./ 这些/ 方法/ 利用/ 自然语言/ 规律/ 统计/ 大量/ 的/ 语料库/ 进行/ 语法/ 判断/ ./ 由于/ 语料库/ 规模/ 有限/ 且/ 无法/ 及时/ 更新/ ,/ 导致/ 一些/ 网络/ 新词/ 、/ 专用名词/ 等常/ 被/ 错误处理/ ./ 为此/ ,/ 文中/ 将/ 传统/ 的/ 语料库/ 和/ Google/ 知识库/ 相结合/ ,/ 利用/ Google/ 知识库/ 获得/ 网络/ 新词/ 等/ 出现/ 的/ 频率/ ,/ 建立/ N/ -/ Gram/ 模型/ ,/ 利用/ 词语/ 间/ 的/ 接续/ 关系/ 进行/ 查错/ ,/ 再/ 借助/ Google/ 的/ 拼写/ 校对/ 功能/ 和/ 词语/ 之间/ 的/ 可信度/ 进行/ 改错/ ./ 相比/ 传统/ 的/ 方法/ ,/ 该/ 方法/ 的/ 语料库/ 源于/ 互联网/ ,/ 对/ 一些/ 新词/ 有/ 更好/ 的/ 校对/ 效果/ ,/ 更/ 适合/ 图像/ 中/ 嵌入/ 的/ 文字/ 信息/ 识别/ 结果/ 的/ 校正/ ./ 关键词/ OCR/ ;/ 校对/ ;/ 语料库/ ;/ Google/ ;/ 纠错/ 1/ 引言/ 随着/ 互联网/ 的/ 发展/ ,/ 视频/ 和/ 图像/ 已经/ 成为/ 人们/ 传递信息/ 的/ 主要/ 手段/ ./ 视频/ 、/ 图像/ 中/ 的/ 文字/ 与/ 媒体/ 内容/ 密切相关/ ,/ 有助于/ 媒体/ 内容/ 的/ 理解/ ./ 通过/ 光学/ 字符识别/ (/ OCR/ )/ 技术/ 可以/ 从/ 视频/ 、/ 图像/ 中/ 提取/ 出/ 其中/ 的/ 文字/ 信息/ ./ 目前/ ,/ 该/ 技术/ 已经/ 广泛/ 地/ 应用/ 在/ 了/ 图像/ 检/ Page21971/ 年/ ,/ 斯坦福大学/ 的/ Ralph/ 实现/ 了/ 一个/ 英文/ 拼写/ 检查程序/ SPEN/ [/ 2/ ]/ ./ 随着/ 新/ 技术/ 的/ 不断涌现/ ,/ 针对/ 该/ 问题/ 的/ 研究/ 取得/ 了/ 一些/ 突破性/ 的/ 进展/ ./ Hisao/ 等/ 人/ [/ 3/ ]/ 提出/ 了/ 一种/ 基于/ 模式/ 学习/ 的/ OCR/ 识别/ 结果/ 校对/ 算法/ ,/ 通过/ 字典/ 生成/ 一个/ 候选/ 错误/ 列表/ ,/ 根据/ 词汇表/ 和/ 字符/ 的/ 语法/ 环境/ 选择/ 一个/ 最合适/ 的/ 候选词/ ./ Liu/ 等/ 人/ [/ 4/ ]/ 提出/ 了/ 一种/ OCR/ 错误/ 校对/ 的/ 统计/ 方法/ ,/ 基于/ N/ -/ Gram/ 模型/ 字典/ 生成/ 候选/ 的/ 错误/ 列表/ ,/ 根据/ 频率/ 矩阵/ 选择/ 一个/ 频率/ 最高/ 的/ 词/ ./ Wang/ 等/ 人/ [/ 5/ ]/ 提出/ 了/ 一种/ 手写/ 中文/ 字符识别/ 的/ 框架/ ,/ 在/ 识别/ 过程/ 中/ 组合/ 字符/ 分类/ 、/ 几何/ 和/ 上下文/ 语境/ 利用/ 贝叶斯/ 决策/ 评价/ 候选/ 路径/ ,/ 使用/ 最大/ 字符/ 精度/ 准则/ 确定/ 候选/ 字符/ ,/ 并/ 在/ 识别/ 过程/ 中/ 实现/ 了/ 自动/ 纠错/ ./ 微软/ 亚洲/ 研究院/ [/ 6/ ]/ 实现/ 了/ 一个/ 基于/ 多/ 特征/ 的/ 中文/ 自动/ 校对/ 方法/ ,/ 采用/ Winnow/ 方法/ 进行/ 特征/ 学习/ ,/ 利用/ 这些/ 上下文/ 特征/ 对/ 目标/ 词/ 混淆/ 集中/ 的/ 词/ 进行/ 选择/ ./ Zhang/ [/ 7/ ]/ 提出/ 一种/ 利用/ 综合/ 近似/ 字集/ 替换/ ,/ 并用/ 统计/ 语言/ 模型/ 评分/ 的/ 方法/ ,/ 将/ 评分/ 最高/ 的/ 字符串/ 与/ 待/ 校对/ 文本/ 中/ 的/ 句子/ 进行/ 对照/ ./ 这些/ 文本校对/ 算法/ 的/ 提出/ ,/ 有效/ 地/ 提高/ 了/ 扫描/ 文档/ 中/ OCR/ 的/ 识别率/ ./ 然而/ ,/ 随着/ 我们/ 把/ 校对/ 范围/ 扩展/ 到/ 更/ 复杂/ 的/ 情况/ ,/ 又/ 有/ 一些/ 新/ 的/ 问题/ 出现/ ,/ 比如/ ,/ 网络/ 上/ 自然/ 图像/ 中/ 字符识别/ 校对/ 问题/ ./ 由于/ 自然/ 图/ 1/ 系统/ 框架图/ 2/ 犖/ -/ Gram/ 模型/ 计算机/ 语言学/ 认为/ 自然语言/ 的/ 知识/ 可/ 由/ 连续/ 符/ 图像/ 语法/ 规则/ 较弱/ ,/ 专有名词/ 和/ 新词/ 较/ 多/ ,/ 传统/ 的/ 文本校对/ 方法/ 很难/ 取得/ 好/ 的/ 效果/ ,/ Bassil/ 和/ Alwani/ [/ 8/ ]/ 总结/ 了/ 传统/ 方法/ 的/ 缺点/ ,/ 他们/ 认为/ “/ 一是/ 需要/ 一个/ 足够/ 大/ 的/ 字典/ ,/ 二是/ 不能/ 同时/ 支持/ 多种语言/ ,/ 三是/ 对/ 一些/ 人/ 名/ 、/ 国家/ 地区/ 名/ 和/ 专有名词/ 支持/ 不够/ ,/ 四是/ 字典/ 是/ 静态/ 的/ ,/ 无法/ 动态/ 的/ 增加/ 新词/ ”/ ./ 所以/ 他们/ 提出/ 了/ 一种/ 利用/ Google/ 拼写/ 校对/ 接口/ 进行/ 校对/ 的/ 方法/ ,/ Google/ 具有/ 海量/ 的/ 数据库/ ,/ 将/ 一个/ 错误/ 的/ 词/ 送入/ Google/ 搜索引擎/ 时/ ,/ Google/ 搜索引擎/ 能/ 通过/ 比/ 对/ 海量/ 数据/ 来/ 预测出/ 这个/ 错误/ ,/ 并/ 给出/ 一个/ 建议/ 的/ 代替/ 词/ ./ 受其/ 启发/ ,/ 我们/ 将/ 传统/ 的/ 文字/ 校对/ 方法/ 和/ Google/ 知识库/ 相结合/ 来/ 解决/ 传统/ 字典/ 在/ 专业/ 词汇/ 方面/ 不足/ 的/ 问题/ ./ 本文/ 所/ 提出/ 的/ 系统/ 框架/ 如图/ 1/ 所示/ ./ 先以/ 北京大学/ 标注/ 的/ 1998/ 年/ 《/ 人民日报/ 》/ 语料库/ 为/ 基础/ ,/ 利用/ N/ -/ Gram/ 模型/ 训练/ 一个/ 语料库/ ./ 然后/ 利用/ 互联网/ 不断/ 地/ 完善/ 语料库/ ,/ 对于/ 语料库/ 中/ 的/ 词/ ,/ 利用/ 词语/ 之间/ 的/ 互信息/ 判断/ 接续/ 关系/ 是否/ 合理/ ,/ 不/ 包含/ 在/ 语料库/ 中/ 时/ ,/ 利用/ Google/ 搜索引擎/ 得到/ 词语/ 出现/ 的/ 次数/ ,/ 计算/ 概率/ 并/ 加入/ 到/ 语料库/ 进行/ 进一步/ 处理/ ./ 对于/ 不合理/ 的/ 接续/ 关系/ ,/ 先用/ Google/ 拼写/ 校对/ 功能/ 进行/ 校对/ ,/ 对于/ 不能/ 正确/ 校对/ 的/ ,/ 再/ 利用/ 词语/ 之间/ 的/ 可信度/ 提供/ 若干个/ 纠错/ 意见/ 供/ 用户/ 选择/ ./ 号/ 组成/ 序列/ 的/ 概率/ 来/ 表示/ [/ 9/ ]/ ./ 如果/ 用/ 变量/ W/ 代表/ 文本/ 中/ 一个/ 任意/ 的/ 词/ 序列/ ,/ 它/ 由/ 顺序排列/ 的/ n/ 个/ 词/ 组成/ ,/ 即/ W/ =/ w1w2/ …/ wn/ ,/ 该词/ 序列/ W/ 在/ 文本/ 中/ 出现/ 的/ 概率/ 为/ P/ (/ W/ )/ ,/ 利用/ 概率/ 的/ 乘积/ 公式/ 表示/ 如下/ :/ Page3P/ (/ W/ )/ =/ P/ (/ w1/ )/ P/ (/ w2/ |/ w1/ )/ P/ (/ w3/ |/ w1w2/ )/ …/ 被/ 称为/ N/ -/ Gram/ 模型/ ./ 要/ 预测/ 词/ wn/ 的/ 出现/ 概率/ ,/ 必须/ 知道/ 它/ 前面/ 所有/ 词/ 的/ 出现/ 概率/ ,/ 从/ 计算/ 量/ 上/ 来看/ ,/ 这种/ 方法/ 太/ 复杂/ ./ Markov/ 模型/ 认为/ ,/ 任何时刻/ 的/ 信源/ 符号/ 发生/ 的/ 概率/ 只/ 与/ 前面/ 已经/ 发生/ 的/ 数个/ 符号/ 有关/ ,/ 而/ 与/ 更/ 前面/ 发生/ 的/ 符号/ 无关/ ./ 由于/ 自然语言/ 可以/ 看成/ 是/ 一个/ 离散/ 的/ Markov/ 模型/ ,/ 任意/ 一个/ 词/ wi/ 的/ 出现/ 概率/ 可以/ 认为/ 只/ 与/ 它/ 前面/ 的/ 若干个/ 词/ 有关/ ./ 这样/ ,/ 问题/ 就/ 可以/ 得到/ 极大/ 的/ 简化/ ,/ 通常/ N/ =/ 2/ ,/ 也/ 就是/ 二元关系/ 模型/ [/ 10/ ]/ 如下/ :/ 在/ 二元关系/ 模型/ 中/ ,/ 把/ 组成/ 这/ 条/ 语句/ 的/ 单词/ 看作/ 一连串/ 的/ 随机/ 事件/ ,/ 然后/ 借助/ 互信息/ 来/ 研究/ 和/ 分析/ 它们/ ./ 互信息/ 是/ 一种/ 计算/ 两个/ 随机变量/ 之间/ 共有/ 信息/ 的/ 度量/ ,/ 当/ 两个/ 随机变量/ 相关/ 时/ ,/ 他们/ 的/ 互信息/ 大于/ 零/ ,/ 互信息/ 越大/ ,/ 结合/ 程度/ 越强/ ,/ 当/ 变量/ 之间/ 不/ 存在/ 依赖/ 关系/ 时/ ,/ 它们/ 的/ 互信息/ 小于/ 零/ [/ 11/ ]/ ./ 词间/ 的/ 互信息/ 可以/ 表示/ 词串/ 之间/ 的/ 前后/ 接续/ 关系/ ,/ 定义/ 如下/ :/ 其中/ ,/ MI/ (/ wi/ ,/ wi/ +/ 1/ )/ 为/ 两个/ 词/ wi/ 和/ wi/ +/ 1/ 的/ 互信息/ ,/ P/ (/ wi/ )/ 为/ 词串/ wi/ 在/ 语料库/ 中/ 单独/ 出现/ 时/ 的/ 概率/ ,/ P/ (/ wi/ ,/ wi/ +/ 1/ )/ 为/ 词串/ wi/ ,/ wi/ +/ 1/ 在/ 语料库/ 中/ 的/ 同现/ 概率/ ./ 用/ M/ 表示/ 语料库/ 中/ 的/ 总/ 词数/ ,/ R/ (/ wi/ )/ 表示/ wi/ 在/ 语料库/ 中/ 单独/ 出现/ 的/ 次数/ ,/ R/ (/ wi/ ,/ wi/ +/ 1/ )/ 表示/ wi/ ,/ wi/ +/ 1/ 在/ 语料库/ 中/ 的/ 同现/ 的/ 次数/ ,/ 结果/ 如下/ :/ P/ (/ wi/ )/ =/ R/ (/ wi/ )/ 互信息/ 表示/ 字符串/ 序列/ (/ wi/ ,/ wi/ +/ 1/ )/ 形成/ 可信赖/ 的/ 搭配/ 出现/ 的/ 概率/ ,/ 设定/ 一/ 阈值/ ζ/ 1/ ,/ 若/ 词间/ 的/ 互信息/ 大于/ ζ/ 1/ ,/ 则/ 认为/ 上下文/ 衔接/ 合理/ ,/ 否则/ 认为/ 上下文/ 衔接/ 不合理/ ./ 3/ 查错/ 要/ 判断/ 词串/ 的/ 接续/ 关系/ ,/ 需要/ 在/ 大规模/ 的/ 语料库/ 上/ 进行/ 统计分析/ ./ 很多/ 研究/ 机构/ 发布/ 了/ 语料库/ 的/ 研究成果/ [/ 12/ ]/ ,/ 1998/ 年/ 北京大学/ 发布/ 的/ 《/ 1998/ 年/ 人民日报/ 》/ 免费/ 文本/ 语料库/ 是/ 已经/ 标记/ 好/ 的/ 语料库/ ./ 通过/ 对/ 语料库/ 进行/ 分析/ ,/ 可以/ 得到/ 每个/ 词语/ 单独/ 出现/ 和/ 同时/ 出现/ 的/ 概率/ ,/ 利用/ 概率/ 计算/ 两个/ 词/ 的/ 接续/ 关系/ ./ 由于/ 该/ 语料库/ 较/ 早/ ,/ 包含/ 的/ 人名/ 、/ 地名/ 和/ 一些/ 专有名词/ 较/ 少/ ,/ 特别/ 是/ 近两年/ 互联网/ 新词/ 不断/ 出现/ ,/ 该/ 语料库/ 不能/ 适应/ 自然/ 图像/ 和/ 视频/ 的/ 文本校对/ ./ 为此/ ,/ 我们/ 利用/ Google/ 知识库/ 进行/ 大/ 范围/ 的/ 训练/ ,/ 完善/ 语料库/ 的/ 覆盖范围/ ./ 对于/ 输入/ 的/ 一个/ 新词/ ,/ 如果/ 没有/ 在/ 语料库/ 中/ ,/ 利用/ Google/ 搜索引擎/ 得到/ 词语/ 的/ 概率/ 如下/ 所示/ :/ 这里/ ,/ Totalpagesnumber/ 表示/ 互联网/ 的/ 词库/ 总数/ ,/ 我们/ 使用/ Google/ 收录/ 的/ 网页/ 数目/ 来/ 代替/ ,/ 2008/ 年/ 7/ 月/ Google/ 软件/ 工程师/ 耶西/ ·/ 阿尔波/ 特/ (/ JesseAlpert/ )/ 和尼森/ ·/ 哈扎/ 伊/ (/ NissanHajaj/ )/ 公布/ 称/ Google/ 收录/ 的/ 网页/ 总数/ 达到/ 了/ 一万亿/ 幅/ ①/ ./ Wordsindexednumber/ 表示/ Google/ 检索/ 到/ 包含/ 该/ 词组/ 的/ 网页/ 总数/ ,/ 如图/ 2/ 框中/ 标记/ 所示/ ,/ 可以/ 通过/ Google/ 的/ 接口/ ②/ 获得/ ./ 这样/ 就/ 可以/ 计算/ 该词/ 出现/ 的/ 概率/ P/ (/ wi/ )/ ./ 在/ 实验/ 中/ ,/ 我们/ 对/ 所/ 得到/ 的/ 概率/ 进行/ 了/ 如下/ 的/ 归一化/ :/ P/ (/ wi/ )/ =/ I/ 这里/ ,/ I/ 表示/ Google/ 搜索引擎/ 检索/ 到/ 的/ 词条/ 数/ ,/ N/ 表示/ Google/ 包含/ 的/ 页面/ 总数/ ,/ M/ 表示/ 语料库/ 包含/ 的/ 词数/ ,/ A/ 表示/ 词/ 在/ 语料库/ 中/ 出现/ 的/ 平均/ 次数/ ,/ T/ 表示/ 语料库/ 的/ 大小/ ./ 图/ 2Google/ 检索/ 界面/ (/ 框中/ 是/ 检索/ 到/ 的/ 词条/ 数/ )/ 通过/ 以上/ 方法/ ,/ 新词/ 被/ 不断/ 地/ 加入/ ,/ 语料库/ 被/ 不/ ①/ ②/ Page4/ 停地/ 更新/ ,/ 语料库/ 的/ 适用性/ 和/ 准确性/ 也/ 在/ 不断/ 的/ 提高/ ,/ 可以/ 用来/ 检查/ 各种/ 词语/ 的/ 接续/ 关系/ ./ 对于/ 一个/ 测试/ 的/ 句子/ S/ 表示/ 为/ S/ =/ c1c2/ …/ cici/ +/ 1/ …/ ck/ =/ w1w2/ …/ wjwj/ +/ 1/ …/ w/ / (/ 7/ )/ 其中/ ,/ ci/ 表示/ 句子/ S/ 中/ 的/ 字/ ,/ wj/ 表示/ S/ 中/ 的/ 词/ ,/ i/ =/ 1/ ,/ …/ ,/ k/ ,/ j/ =/ 1/ ,/ …/ ,/ / ,/ ci/ 、/ ci/ +/ 1/ 为/ 相邻/ 字/ ,/ wj/ 、/ wj/ +/ 1/ 为/ 相邻/ 词/ ./ 由于/ 词是/ 由/ 字/ 组成/ 的/ ,/ 故/ wj/ =/ c1c2/ …/ ck/ ,/ 可以/ 通过/ 词/ 与/ 相邻/ 字/ 之间/ 的/ 接续/ 关系/ 判断/ 词语/ 的/ 合法性/ ./ 对于/ 句子/ S/ 中/ 的/ 任意/ 连续/ 出现/ 的/ 两个/ 词/ wi/ 和/ wi/ +/ 1/ 的/ 接续/ 关系/ 定义/ 为/ MI/ (/ wj/ ,/ wj/ +/ 1/ )/ ≈/ log2P/ (/ wj/ ·/ ck/ ,/ wj/ +/ 1/ ·/ c1/ )/ 其中/ ,/ P/ (/ wj/ ·/ ck/ )/ 为/ 词/ wj/ 的/ 最后/ 一个/ 字/ ck/ 在/ 语料库/ 中/ 出现/ 的/ 频率/ ,/ P/ (/ wj/ +/ 1/ ·/ c1/ )/ 为/ 词/ wj/ +/ 1/ 的/ 第/ 1/ 个/ 字/ c1/ 在/ 语料库/ 中/ 出现/ 的/ 频率/ ,/ P/ (/ wj/ ·/ ck/ )/ P/ (/ wj/ +/ 1/ ·/ c1/ )/ 为/ 两个/ 字/ 在/ 语料库/ 中/ 连续/ 出现/ 的/ 频率/ ./ 在/ 实验/ 中/ ,/ 我们/ 使用/ 基于/ 字符串/ 匹配/ 中/ 的/ 逆向/ 最大/ 匹配/ 法/ 进行/ 分词/ ,/ 然后/ 使用/ 两个/ 相连/ 词/ 的/ 相连/ 字/ 的/ 互信息/ 和/ 两个/ 相连/ 词/ 的/ 互信息/ 的/ 加权/ 作为/ 连续性/ 判断/ 依据/ ,/ 如果/ 互信息/ 小于/ 阈值/ ζ/ 1/ ,/ 则/ 认为/ 该处/ 存在/ 错误/ ./ 4/ 纠错/ 文本/ 纠错/ 是/ 把/ 查错/ 过程/ 中/ 检测/ 出来/ 的/ 错误/ 字符串/ 修改/ 为/ 正确/ 字符串/ 或者/ 给出/ 修改/ 建议/ ./ 由于/ OCR/ 识别/ 后/ 文本/ 中/ 的/ 错误/ 形式/ 变化多端/ ,/ 无法/ 预测/ 何时/ 有/ 何种/ 噪音/ 影响/ ,/ 所以/ 目前/ 还/ 没有/ 有效/ 的/ 方法/ ./ 我们/ 将/ Google/ 的/ 拼写/ 校对/ 功能/ 和/ 词串/ 的/ 可信度/ 结合/ ,/ 对于/ 查出/ 的/ 错误/ ,/ 先/ 使用/ Google/ 提供/ 的/ 拼写/ 校对/ 功能/ 改错/ ①/ ,/ 当/ 用户/ 输入/ 一个/ 错误/ 的/ 词/ 进行/ 搜索/ 时/ ,/ Google/ 会/ 给出/ 一个/ 合理/ 的/ 拼写/ 建议/ ./ 如图/ 3/ 所示/ ./ 算法/ 1/ 通过/ 调用/ Google/ 提供/ 的/ 接口/ 获取/ 拼写/ 建议/ 图/ 3Google/ 拼写/ 校对/ 界面/ (/ 框中/ 是/ Google/ 拼写/ 校对/ )/ 进行/ 修正/ ,/ 由于/ Google/ 是/ 基于/ 整个/ 互联网/ 信息/ 的/ ,/ 所以/ 对/ 新词/ 、/ 专用名词/ 一些/ 不/ 正确/ 的/ 拼写/ 会/ 进行/ 修正/ ./ 算法/ 1/ ./ Google/ 拼写/ 校对/ 算法/ ./ 输入/ :/ 句子/ S/ ;/ 错误/ 位置/ ErrorBegin/ ,/ ErrorEnd/ 输出/ :/ 句子/ S/ 过程/ :/ // // 将/ 错误/ 字符串/ 赋给/ PP/ =/ Substring/ (/ S/ ,/ ErrorBegin/ ,/ ErrorEnd/ )/ // // 调用/ Google/ 搜索引擎/ 检索/ PResult/ =/ GoogleSearch/ (/ P/ )/ IF/ (/ 有/ 校对/ 建议/ )/ ThenEndifUpdateS/ // // 更新/ 句子/ S/ 对于/ Google/ 不能/ 给出/ 拼写/ 建议/ 的/ 错误/ 词串/ ,/ 我们/ 使用/ 词语/ 的/ 可信度/ 来/ 选择/ 合理/ 的/ 词/ ,/ 词语/ 的/ 可信度/ 函数/ 定义/ 如下/ :/ 其中/ ,/ n/ 为/ 语料库/ 中/ 的/ 词数/ ./ 对于/ 两个/ 不同/ 的/ 字串/ ,/ 可以/ 使用/ 它们/ 之间/ 可信度/ 的/ 差来/ 计算/ 哪个/ 串/ 的/ 可信度/ 更高/ ./ 串/ S2/ 对串/ S1/ 的/ 可信度/ 定义/ 为/ 设定/ 阈值/ ζ/ 2/ ,/ 当/ 存在/ 串/ S2/ 对于/ 串/ S1/ 的/ 可信度/ 大于/ 给定/ 的/ 阈值/ ζ/ 2/ 时/ ,/ 则/ 对于/ 出错/ 串/ S1/ ,/ S2/ 为/ 一个/ 纠错/ 建议/ ./ 统计/ 发现/ ,/ OCR/ 识别/ 错误/ 一般/ 包含/ 3/ 种/ 情况/ :/ 漏字/ 、/ 多字/ 和/ 别字/ ,/ 因此/ ,/ 分别/ 构造/ 漏字/ 校对/ 候选/ 集/ 、/ 多字/ 校对/ 候选/ 集/ 和/ 别字/ 校对/ 候选/ 集来/ 形成/ 候选/ 串/ ,/ 过程/ 如/ 算法/ 2/ ,/ 按/ 可信度/ 的/ 大小/ 对/ 这些/ 候选/ 字串/ 进行/ 排序/ ,/ 显示/ 纠错/ 建议/ 供/ 用户/ 选择/ ,/ 软件/ 界面/ 如图/ 4/ 所示/ ./ ①/ GoogleSpellCheckerGuide/ [/ EB/ // OL/ ]/ ./ http/ :/ // // www/ ./ Page5/ 算法/ 2/ ./ 纠错/ 校对/ 候选/ 集/ 构造/ 算法/ ./ 输入/ :/ 错误/ 字符串/ P/ ;/ 语料库/ C/ ;/ 常用/ 别字/ 替换/ 集/ FC/ ;/ P/ 输出/ :/ P/ 的/ 漏字/ 校对/ 候选/ 集/ ,/ 多字/ 校对/ 候选/ 集合/ 别字/ 校对/ 过程/ :/ P/ =/ c1/ …/ cici/ +/ 1/ …/ cn/ // // 构造/ P/ 的/ 漏字/ 校对/ 候选/ 集/ InsSet/ (/ P/ )/ Fori/ =/ 1/ ../ nDoEndFor/ // // 构造/ P/ 的/ 多/ 字/ 校对/ 候选/ 集/ DelSet/ (/ P/ )/ Fori/ =/ 1/ ../ nDoP/ =/ c1c2/ …/ ci/ -/ 1ci/ +/ 1ci/ +/ 2/ …/ cnIF/ (/ AC/ (/ P/ ,/ P/ )/ >/ ξ/ 2/ )/ 加入/ P/ 的/ 多/ 字/ 校对/ 候选/ 集/ EndFor/ // // 构造/ P/ 的/ 别字/ 校对/ 候选/ 集/ RepSet/ (/ P/ )/ Fori/ =/ 1/ ../ nDo/ 图/ 5/ 文字/ 识别/ 结果/ (/ 下划线/ 标记/ 文字/ 为/ OCR/ 识别/ 错误/ 的/ 文字/ ,/ 底色/ 阴影/ 标记/ 为/ 算法/ 正确/ 校对/ 的/ 文字/ )/ 方法/ 正确/ 表/ 1OCR/ 识别/ 结果/ 校对/ 算法/ 比较/ 汪维家/ 等/ 方法/ [/ 15/ ]/ 223750336762514272.9658/ ./ 7238.6983/ 林晖/ 等/ 方法/ [/ 14/ ]/ 223750339560316778.5265/ ./ 5142.2875/ Bassil/ 等/ 方法/ [/ 8/ ]/ 223750324330412848.3179/ ./ 9352.671720/ 本文/ 方法/ 223750340252725779.9276/ ./ 2863.93416/ EndFor5/ 实验/ 为了/ 测试/ 本文/ 提出/ 的/ 校对/ 方法/ 的/ 有效性/ ,/ 我们/ 采用/ C++/ 进行/ 了/ 系统/ 的/ 开发/ 实现/ 及/ 测试/ ./ 测试/ 库/ 来源于/ vLecture/ 项目/ (/ 一个/ 虚拟/ 的/ 学习/ 社区/ ,/ 提供/ 基于/ 内容/ 的/ 视频/ 片段/ 搜索/ )/ 和/ 互联网/ ,/ 我们/ 使用/ Yan/ 的/ 方法/ [/ 13/ ]/ 提取/ 文字/ 区域/ 进行/ OCR/ 识别/ ,/ 该/ 方法/ 将/ 文字/ 作为/ 一种/ 特殊/ 的/ 纹理/ ,/ 利用/ Gabor/ 滤波器/ 提取/ 4/ 个/ 方向/ 的/ 纹理/ 信息/ ,/ 然后/ 使用/ SVM/ 分类器/ 得到/ 文字/ 区域/ ,/ 对/ 复杂/ 背景/ 下/ 文字/ 区域/ 的/ 定位/ 具有/ 较/ 好/ 的/ 效果/ ./ 为了/ 测试/ 算法/ 的/ 有效性/ ,/ 采用/ 召回/ 率/ 、/ 查准率/ 和/ 改正/ 率来/ 评价/ 系统/ [/ 14/ ]/ ./ 测试/ 图片/ 从/ vLecture/ 项目/ 和/ 互联网/ 上/ 选择/ 了/ 50/ 幅/ 图像/ ,/ 原始/ 图像/ 如图/ 5/ (/ a/ )/ 所示/ ,/ OCR/ 识别/ 结果/ 如图/ 5/ (/ b/ )/ 所示/ ,/ 识别/ 错误/ 部分/ 用/ 下划线/ 标记/ ./ 图/ 5/ (/ c/ )/ 为/ 最终/ 的/ OCR/ 校对/ 结果/ ,/ 校对/ 时/ 默认/ 采用/ 可信度/ 最大/ 的/ 一个/ 词/ 自动/ 校对/ ,/ 正确/ 校对/ 的/ 结果/ 用/ 阴影/ 底色/ 标记/ ./ 50/ 幅/ 图片/ 共/ 包含/ 文字/ 2740/ 个/ ,/ 其中/ 正确/ 识别/ 2237/ 个/ ,/ 错误/ 503/ 个/ ./ 与/ 传统/ OCR/ 校对/ 方法/ 的/ 比较/ 如表/ 1/ 所示/ ./ 纠正/ 的/ 错误/ 总数/ 召回/ 率/ // %/ 查准率/ // %/ 改正/ 率/ // %/ 时间/ 复杂度/ // sPage6/ 汪维家/ 等/ 方法/ [/ 15/ ]/ 是/ 目前/ 比较/ 经典/ 的/ 传统/ 方法/ ,/ 林晖/ 等/ 方法/ [/ 14/ ]/ 是/ 对/ Markov/ 算法/ 的/ 改进/ ,/ 召回/ 率/ 较/ 高/ ,/ 这/ 两种/ 方法/ 的/ 语料库/ 都/ 是/ 固定/ 的/ ,/ 对/ 互联网/ 上/ 出现/ 的/ 一些/ 新词/ 和/ 专用词/ 效果/ 不佳/ ,/ 查准率/ 都/ 比较/ 低/ ./ Bassil/ 等/ 方法/ [/ 8/ ]/ 完全/ 依赖于/ Google/ 搜索引擎/ ,/ 由于/ Google/ 包含/ 的/ 内容/ 太/ 多/ ,/ 词语/ 组合/ 形式/ 复杂/ ,/ 召回/ 率/ 较/ 低/ ./ 另外/ ,/ Google/ 提供/ 的/ 纠错/ 功能/ 对/ 英文/ 的/ 校对/ 效果/ 要/ 好/ 于/ 对/ 中文/ 的/ 校对/ 效果/ ,/ 对/ 很多/ 中文/ 句子/ ,/ Google/ 不能/ 给出/ 正确/ 的/ 纠错/ 建议/ ,/ 改正/ 率/ 也/ 有限/ ./ 因此/ ,/ 本文/ 在/ 此基础/ 上/ 对/ Google/ 不能/ 处理/ 的/ 词语/ 分别/ 构造/ 漏字/ 校对/ 候选/ 集/ 、/ 多字/ 校对/ 候选/ 集/ 和/ 别字/ 校对/ 候选/ 集来/ 形成/ 候选/ 串/ ,/ 根据/ 可信度/ 的/ 大小/ 选择/ 纠错/ 词/ ,/ 实验/ 结果表明/ ,/ 改正/ 率/ 提高/ 了/ 10/ %/ 以上/ ./ 本文/ 的/ 方法/ 原理/ 上/ 属于/ 林晖/ 等/ 方法/ [/ 14/ ]/ 和/ Bassil/ 等/ 方法/ [/ 8/ ]/ 的/ 结合/ ,/ 由于/ 语料库/ 是/ 不断完善/ 的/ ,/ 能/ 处理/ 包含/ 新词/ 、/ 专业名词/ 等/ 各种/ 词语/ ,/ 召回/ 率/ 比较/ 高/ ,/ 另外/ ,/ 本文/ 提出/ 的/ 方法/ 不但/ 能/ 有效/ 地/ 利用/ 词语/ 之间/ 的/ 可信度/ 关系/ 给出/ 正确/ 建议/ ,/ 而且/ 具有/ Google/ 拼写/ 校对/ 的/ 优势/ ,/ 改正/ 率/ 较/ 高/ ./ 本文/ 的/ 方法/ 和/ Bassil/ 等/ 方法/ [/ 8/ ]/ 都/ 需要/ 调用/ Google/ 的/ 接口/ 获取数据/ ,/ 而/ 调用/ Google/ 接口/ 受/ 网速/ 的/ 影响/ 较大/ ,/ 在/ 实验室/ (/ 100MB/ 共享/ )/ 网络/ 环境/ 下/ ,/ 各/ 算法/ 的/ 时间/ 复杂度/ 如表/ 1/ 所示/ ./ 汪维家/ 等/ 方法/ [/ 15/ ]/ 和/ 林晖/ 等/ 方法/ [/ 14/ ]/ 不/ 需要/ 访问/ 网络/ ,/ 速度/ 非常/ 快/ ,/ 分别/ 耗时/ 83s/ 和/ 75s/ ./ Bassil/ 等/ 方法/ [/ 8/ ]/ 对/ 每个/ 词/ 都/ 需要/ 调用/ Google/ 接口/ ,/ 耗时/ 1720s/ ./ 我们/ 的/ 方法/ 对/ 大部分/ 传统/ 词汇/ 通过/ 语料库/ 来/ 处理/ ,/ 只有/ 少量/ 的/ 语料库/ 中/ 没有/ 的/ 新词/ 需要/ 调用/ Google/ 接口/ ,/ 耗时/ 416s/ ,/ 而且/ 随着/ 语料库/ 不断/ 的/ 积累/ ,/ 需要/ 通过/ Google/ 接口/ 获取/ 的/ 新词/ 会/ 越来越少/ ,/ 速度/ 会/ 逐步/ 逼近/ 林晖/ 等/ 方法/ [/ 14/ ]/ ./ 6/ 小结/ 文字/ 识别/ 一直/ 是/ 模式识别/ 中/ 研究/ 的/ 重点/ ,/ 许多/ 文字/ 识别方法/ 被/ 提出/ [/ 16/ ]/ ,/ 这些/ 方法/ 主要/ 集中/ 在/ OCR/ 识别/ 前/ 的/ 去/ 干扰/ 上/ ,/ 但/ 由于/ 很多/ 字符/ 、/ 文字/ 的/ 相似性/ ,/ OCR/ 识别/ 依然/ 有/ 很多/ 错误/ ,/ 为了/ 进一步提高/ OCR/ 识别率/ ,/ 本文/ 提出/ 了/ 一种/ 基于/ Google/ 的/ 识别/ 结果/ 校对/ 方法/ ./ 该/ 方法/ 将/ 传统/ 的/ 基于/ N/ -/ Gram/ 方法/ 和/ Google/ 知识库/ 相结合/ ,/ 利用/ Google/ 知识库/ 来/ 不断/ 的/ 丰富/ 传统/ 的/ 语料库/ ,/ 有效/ 地/ 解决/ 了/ 传统/ N/ -/ Gram/ 方法/ 在/ 字典/ 词汇量/ 有限/ ,/ 对/ 新词/ 、/ 专有名词/ 无法/ 校对/ 的/ 问题/ ./ 该/ 方法/ 首先/ 利用/ 词语/ 之间/ 的/ 互信息/ 判断/ 接续/ 关系/ 的/ 合理性/ ,/ 对于/ 找出/ 的/ 错误/ ,/ 先用/ Google/ 的/ 拼写/ 校对/ 功能/ 进行/ 校对/ ,/ 再/ 利用/ 词语/ 之间/ 的/ 可信度/ 提供/ 纠错/ 意见/ 供/ 用户/ 选择/ ./ 本/ 方法/ 实用性/ 比较/ 强/ ,/ 在/ vLecture/ 项目/ 中/ 有效/ 地/ 提高/ 了/ OCR/ 的/ 识别率/ ./ 

