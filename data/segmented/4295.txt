Page1/ 基于/ GPU/ 的/ 稀疏/ 矩阵/ Cholesky/ 分解/ 邹丹/ 窦勇/ 郭松/ (/ 国防/ 科学/ 与/ 技术/ 大学/ 计算机/ 学院/ 长沙/ 410073/ )/ 摘要/ 稀疏/ 矩阵/ Cholesky/ 分解/ 是/ 求解/ 大规模/ 稀疏/ 线性方程组/ 的/ 核心/ 算法/ ,/ 也/ 是/ 求解/ 过程/ 中/ 最/ 耗时/ 的/ 部分/ ./ 近年来/ ,/ 一系列/ 并行算法/ 通过/ 图形/ 处理器/ (/ GPU/ )/ 获得/ 了/ 显著/ 的/ 加速/ 比/ ,/ 然而/ ,/ 由于/ 访存/ 的/ 不规则/ 性/ 以及/ 任务/ 间/ 的/ 大量/ 数据/ 依赖/ 关系/ ,/ 稀疏/ 矩阵/ Cholesky/ 分解/ 算法/ 在/ GPU/ 上/ 的/ 计算/ 效率/ 很/ 低/ ./ 文中/ 实现/ 了/ 一种/ 新/ 的/ 基于/ GPU/ 的/ 稀疏/ 矩阵/ Cholesky/ 分解/ 算法/ ./ 在/ 数据组织/ 方面/ ,/ 改进/ 了/ 稀疏/ 矩阵/ 超/ 节点/ 数据结构/ ,/ 通过/ 超/ 节点/ 合并/ 和/ 分块/ 控制/ 计算/ 粒度/ ;/ 在/ 计算/ 调度/ 方面/ ,/ 将/ 稀疏/ 矩阵/ Cholesky/ 分解/ 过程/ 映射/ 为/ 一系列/ 的/ 数据/ 块/ 任务/ ,/ 并/ 设计/ 了/ 相应/ 的/ 任务/ 生成/ 与/ 调度/ 算法/ ,/ 在/ 满足/ 数据/ 依赖性/ 的/ 前提/ 下/ 提高/ 任务/ 的/ 并行性/ ./ 实验/ 结果表明/ ,/ 该/ 算法/ 能够/ 显著/ 提高/ 稀疏/ 矩阵/ Cholesky/ 分解/ 算法/ 在/ GPU/ 上/ 的/ 实现/ 效率/ ,/ 在/ 单个/ GPU/ 上/ 获得/ 了/ 相对/ 4/ 核/ CPU/ 平台/ 2.69/ ~/ 3.88/ 倍/ 的/ 加速/ 比/ ./ 关键词/ 稀疏/ 矩阵/ ;/ Cholesky/ 分解/ ;/ GPU1/ 引言/ 稀疏/ 矩阵/ Cholesky/ 分解/ 是/ 科学/ 工程/ 计算/ 领域/ Page2/ 入/ 了/ 大量/ 不规则/ 间接/ 寻址/ 操作/ ,/ 造成/ 了/ 访存/ 和/ 计算/ 的/ 不规则/ ./ 相应/ 的/ ,/ 稀疏/ 矩阵/ Cholesky/ 分解/ 并行算法/ 需要/ 解决/ 数据组织/ 与/ 计算/ 调度/ 两个/ 基本/ 问题/ ,/ 即/ 如何/ 提高/ 访存/ 和/ 计算/ 的/ 效率/ ./ 近年来/ ,/ 以/ 高性能/ 和/ 高带宽/ 为/ 设计/ 目标/ 的/ GPU/ 在/ 高性能/ 计算/ 领域/ 发挥/ 了/ 日益/ 重要/ 的/ 作用/ ./ 与/ 通用/ 多核/ 处理器/ 相比/ ,/ GPU/ 简化/ 了/ 计算/ 核心/ 的/ 分支/ 处理/ 能力/ 并/ 减小/ 了/ 缓存/ 容量/ ,/ 将/ 大量/ 的/ 晶体管/ 资源/ 用于/ 计算/ 单元/ 设计/ ,/ 从而/ 获得/ 了/ 高于/ 通用/ 多核/ 处理器/ 的/ 计算/ 性能/ ,/ CPU/ +/ GPU/ 异构/ 并行/ 体系结构/ 已经/ 成为/ 高性能/ 计算/ 系统/ 的/ 主流/ 体系结构/ 之一/ ./ 以/ 稠密/ 矩阵/ 运算/ 为/ 代表/ 的/ 具有/ 规则/ 的/ 访存/ 和/ 计算/ 特性/ 的/ 并行算法/ 易于/ 在/ GPU/ 上/ 获得/ 高于/ 通用/ 处理器/ 的/ 计算/ 性能/ ,/ 然而/ ,/ 以/ 稀疏/ 矩阵/ Cholesky/ 分解/ 为/ 代表/ 的/ 具有/ 不规则/ 的/ 访存/ 和/ 计算/ 特性/ 的/ 并行算法/ 在/ GPU/ 上/ 的/ 计算/ 效率/ 很/ 低/ ./ 大量/ 的/ 离散/ 数据/ 访问/ 和/ 分支/ 计算/ 使得/ GPU/ 的/ 线程/ 串行化/ 执行/ ,/ 无法/ 发挥/ GPU/ 的/ 并行/ 化/ 优势/ ,/ 这种/ 情况/ 下/ GPU/ 的/ 实际/ 性能/ 往往/ 低于/ 多核/ CPU/ ./ 为了/ 在/ GPU/ 上/ 高效/ 实现/ 稀疏/ 矩阵/ Cholesky/ 分解/ ,/ 需要/ 从/ 数据组织/ 和/ 计算/ 调度/ 两/ 方面/ 对/ 现有/ 算法/ 重新/ 设计/ ./ 我们/ 发现/ 将/ 相邻/ 的/ 具有/ 相似/ 稀疏/ 结构/ 的/ 矩阵/ 列/ 合并/ 为/ 多列/ 存储/ 的/ 超/ 节点/ 数据结构/ ,/ 能够/ 有效/ 地/ 减少/ 间接/ 访存/ 的/ 开销/ 并/ 提高/ 计算/ 粒度/ ,/ 但会/ 增加/ 额外/ 的/ 存储/ 和/ 计算/ 开销/ ,/ 并且/ 由于/ 计算/ 粒度/ 分布/ 不/ 均匀/ 而/ 使得/ 计算/ 负载/ 不/ 均衡/ ./ 为了/ 降低/ 额外/ 开销/ 以及/ 控制/ 计算/ 粒度/ ,/ 我们/ 对/ 大规模/ 超/ 节点/ 进行/ 分块/ ,/ 得到/ 了/ 适合/ GPU/ 存储/ 和/ 计算/ 的/ 规则/ 数据结构/ ./ 另外/ 我们/ 还/ 发现/ ,/ 通过/ 将/ 稀疏/ 矩阵/ 压缩/ 存储/ 数据结构/ 中/ 的/ 矩阵/ 元素/ 数据/ 和/ 索引/ 数据/ 分离/ ,/ 在/ 计算/ 过程中将/ 矩阵/ 元素/ 数据/ 存储/ 在/ GPU/ 端/ ,/ 而/ 索引/ 数据/ 存储/ 在/ CPU/ 端/ ,/ 能够/ 显著/ 降低/ CPU/ 与/ GPU/ 的/ 通信/ 开销/ ./ 在/ 超/ 节点/ 分块/ 存储/ 数据结构/ 的/ 基础/ 上/ ,/ 我们/ 将/ 稀疏/ 矩阵/ Cholesky/ 分解/ 过程/ 映射/ 为/ 一系列/ 面向/ 数据/ 块/ 对象/ 的/ 计算/ 任务/ ./ 为了/ 在/ 满足/ 任务/ 数据/ 依赖性/ 的/ 前提/ 下/ 实现/ 任务/ 并行/ 的/ 最大化/ ,/ 我们/ 设计/ 了/ 基于/ 队列/ 的/ 任务/ 生成/ 与/ 调度/ 方法/ ,/ 解决/ 了/ 任务/ 间/ 的/ 并行/ 与/ 互斥/ 问题/ ./ 在/ 此基础/ 上/ ,/ 我们/ 实现/ 了/ 基于/ GPU/ 的/ 稀疏/ 矩阵/ Cholesky/ 分解/ 算法/ ./ 实验/ 表明/ ,/ 该/ 算法/ 能够/ 充分发挥/ GPU/ 的/ 计算能力/ ,/ 获得/ 了/ 相对/ 于/ 4/ 核/ 处理器/ 2.69/ ~/ 3.88/ 倍/ 的/ 加速/ 比/ ./ 本文/ 的/ 贡献/ 如下/ :/ (/ 1/ )/ 数据组织/ 我们/ 改进/ 了/ 面向/ GPU/ 的/ 稀疏/ 矩阵/ 数据组织/ 方法/ ./ 通过/ 将/ 稀疏/ 矩阵/ 稀疏/ 结构/ 相似/ 的/ 列/ 合并/ 成超/ 节点/ 后/ 再/ 进行/ 数据/ 分块/ ,/ 使得/ 计算/ 任务/ 处理/ 的/ 对象/ 由/ 不规则/ 的/ 稀疏/ 列/ 转换/ 为了/ 规则/ 的/ 稠密/ 数据/ 块/ ./ 通过/ 将/ 矩阵/ 数据/ 存储/ 在/ GPU/ 端/ ,/ 索引/ 和/ 控制数据/ 存储/ 在/ CPU/ 端/ ,/ 降低/ 了/ CPU/ 与/ GPU/ 的/ 通信/ 开销/ ./ (/ 2/ )/ 任务/ 生成/ 与/ 调度/ 方法/ 我们/ 设计/ 了/ 基于/ 队列/ 的/ 任务/ 生成/ 与/ 调度/ 方法/ ./ 计算/ 任务/ 在/ 集成/ 树/ 的/ 指导/ 下/ 生成/ 并/ 加入/ 任务/ 队列/ ./ 在/ 同一个/ 时间/ 内/ ,/ 可以/ 有/ 多个/ GPU/ 任务/ 同时/ 执行/ ,/ 这些/ 任务/ 间/ 的/ 并行/ 是/ 通过/ 流/ 机制/ 实现/ 的/ ,/ 而/ 任务/ 间/ 的/ 数据/ 依赖性/ 则/ 是/ 通过/ 事件/ 同步/ 机制/ 进行/ 控制/ ./ 通过/ 流/ 并行/ 以及/ 事件/ 同步/ 机制/ ,/ 在/ 保证/ 计算/ 正确性/ 的/ 前提/ 下/ 提高/ 了/ 计算/ 效率/ ./ (/ 3/ )/ 高性能/ 在/ 双/ 精度/ 条件/ 下/ ,/ 我们/ 获得/ 了/ 相对/ 于/ 4/ 核/ 处理器/ 2.69/ ~/ 3.88/ 倍/ 的/ 加速/ 比/ ./ 据/ 我们/ 所知/ ,/ 这是/ 当前/ 稀疏/ 矩阵/ Cholesky/ 分解/ 算法/ 在/ GPU/ 平台/ 上/ 获得/ 的/ 相对/ 多核/ 通用/ CPU/ 平台/ 的/ 最高/ 加速/ 比/ ./ 2/ 算法/ 及/ 平台/ 介绍/ 2.1/ 稀疏/ 矩阵/ Cholesky/ 分解/ 算法/ 稀疏/ 矩阵/ Cholesky/ 分解/ 算法/ 将/ 对称/ 正定/ 稀疏/ 矩阵/ 犃/ 分解/ 为/ 犔/ 犔/ T/ ,/ 其中/ 犔/ 是/ 对角/ 元素/ 为/ 正/ 的/ 下/ 三角/ 矩阵/ ./ 由于/ 犃/ 为/ 对称/ 矩阵/ ,/ 只/ 需要/ 存储/ 和/ 处理/ 矩阵/ 犃/ 的/ 下/ 三角/ 部分/ 的/ 非/ 零/ 元素/ ,/ 犔/ 的/ 数值/ 直接/ 覆盖/ 矩阵/ 犃/ 的/ 下/ 三角/ 部分/ ./ 稀疏/ 矩阵/ Cholesky/ 分解/ 算法/ 按照/ 从/ 左向右/ 的/ 顺序/ 逐列/ 更新/ 犔/ ./ 为了/ 便于/ 描述/ 计算/ 过程/ ,/ 我们/ 定义/ 两类/ 计算/ 任务/ :/ 列/ 分解/ 任务/ cdiv/ 和/ 列/ 更新/ 任务/ cmod/ ./ 其中/ ,/ cdiv/ (/ k/ )/ 对/ 第/ k/ 列/ 进行/ 分解/ ,/ cmod/ (/ k/ ,/ j/ )/ 使用/ 第/ j/ 列/ 更新/ 第/ k/ 列/ ./ 稀疏/ 矩阵/ Cholesky/ 分解/ 过程/ 可以/ 表示/ 为/ 一系列/ 计算/ 任务/ :/ 按照/ 由/ 左/ 至/ 右/ 的/ 顺序/ ,/ 首先/ 生成/ cdiv/ (/ j/ )/ 任务/ ,/ 对/ 当/ 前列/ j/ 进行/ 分解/ ;/ 然后/ 生成/ cmod/ (/ j/ +/ 1/ :/ n/ ,/ j/ )/ 任务/ ,/ 使用/ 当/ 前列/ j/ 更新/ 右侧/ 所有/ 相关/ 列/ ./ 在/ 分解/ 过程/ 中/ ,/ 矩阵/ 犃/ 中/ 的/ 一部分/ 零/ 元素/ 会/ 转变/ 为/ 非/ 零/ 元素/ ,/ 这种/ 元素/ 称为/ 填充/ 元/ ./ 稀疏/ 矩阵/ Cholesky/ 算法/ 描述/ 如/ 算法/ 1/ 所示/ ./ 算法/ 1/ ./ 稀疏/ 矩阵/ Cholesky/ 分解/ 算法/ ./ 输入/ :/ 分解/ 前/ 的/ 稀疏/ 下/ 三角/ 矩阵/ 犔/ (/ li/ ,/ j/ )/ ,/ 矩阵/ 规模/ n/ 输出/ :/ 分解/ 后/ 的/ 稀疏/ 下/ 三角/ 矩阵/ 犔/ (/ li/ ,/ j/ )/ FORj/ =/ 0ton/ -/ 1DOFORi/ =/ jton/ -/ 1DOFORk/ =/ j/ +/ 1ton/ -/ 1DOPage3/ 计算/ 任务/ 间/ 的/ 数据/ 相关性/ 通常/ 采用/ 消去/ 树/ T/ 表示/ [/ 1/ ]/ ./ 消去/ 树中/ 的/ 节点/ 编号/ 与/ 矩阵/ 犃/ 中/ 的/ 列/ 编号/ 一一对应/ ./ 消去/ 树/ 节点/ 间/ 关系/ 由/ 稀疏/ 矩阵/ 犃/ 的/ 分解/ 因子/ 犔/ 的/ 稀疏/ 结构/ 决定/ ,/ 定义/ 如下/ :/ 其中/ ,/ parent/ (/ j/ )/ 表示/ 节点/ j/ 的/ 父/ 节点/ 编号/ ./ 对于/ 图/ 1/ (/ a/ )/ 中/ 的/ 稀疏/ 矩阵/ ,/ 实心/ 点/ 表示/ 矩阵/ 分解/ 前/ 的/ 非/ 零/ 元素/ ,/ 空心/ 点/ 表示/ 矩阵/ 分解/ 过程/ 中/ 产生/ 的/ 填充/ 元/ ,/ 其/ 对应/ 的/ 消去/ 树如图/ 1/ (/ b/ )/ 所示/ ./ 为/ 简便/ 起/ 见/ ,/ 在/ 本文/ 接下来/ 的/ 部分/ 将/ 不再/ 区分/ 节点/ 与/ 对应/ 的/ 矩阵/ 列/ ./ 消去/ 树/ 的/ 父子/ 节点/ 间/ 存在/ 数据/ 依赖/ 关系/ ,/ 只有/ 当子/ 节点/ 计算/ 完成/ 后/ ,/ 父/ 节点/ 才能/ 开始/ 计算/ ./ 因此/ ,/ 稀疏/ 矩阵/ Cholesky/ 分解/ 过程/ 的/ 任务/ 执行/ 顺序/ 可以/ 表示/ 为/ 消去/ 树自/ 底向上/ 的/ 节点/ 遍历/ 过程/ ./ 稀疏/ 矩阵/ 通常/ 采用/ 压缩/ 存储/ 数据结构/ ,/ 仅为/ 矩阵/ 的/ 非/ 零/ 元素/ 分配/ 存储空间/ ,/ 从而/ 降低/ 存储量/ 和/ 计算/ 量/ ./ 基本/ 的/ 稀疏/ 矩阵/ 存储/ 数据结构/ 是/ 列/ 压缩/ (/ CompressedSparseColumn/ ,/ CSC/ )/ 数据结构/ [/ 2/ -/ 3/ ]/ ,/ 由/ 3/ 个/ 数组/ 构成/ ,/ 其中/ val/ 按列/ 存放/ 非零/ 元素/ ,/ rowSub/ 记录/ 对应/ 于/ val/ 中/ 每个/ 非零/ 元素/ 的/ 行号/ ,/ colPtr/ 记录/ 每列/ 第/ 1/ 个/ 非/ 零/ 元素/ 在/ val/ 和/ rowSub/ 中/ 的/ 位置/ ./ CSC/ 数据结构/ 节省/ 了/ 存储空间/ ,/ 但/ 增加/ 了/ 访存/ 的/ 开销/ ,/ 每个/ 矩阵/ 元素/ 都/ 需要/ 通过/ 间接/ 索引/ 才能/ 访问/ ./ 为了/ 降低/ 间接/ 寻址/ 的/ 开销/ ,/ 稀疏/ 矩阵/ 分解/ 算法/ 的/ 一种/ 常用/ 策略/ 是/ 将/ 具有/ 相同/ 稀疏/ 结构/ 的/ 列/ 合并/ ,/ 按照/ 稠密/ 矩阵/ 方式/ 存储/ 合并/ 的/ 列/ 内部/ 的/ 非/ 零/ 元素/ ./ 这样/ 的/ 数据结构/ 称为/ 超/ 节点/ ,/ 由/ 相邻/ 的/ 列/ 集合/ {/ i/ ,/ i/ +/ 1/ ,/ …/ ,/ i/ +/ w/ }/ 组成/ ./ 超/ 节点/ 中/ 的/ 列/ 满足/ 以下/ 条件/ :/ Adj/ (/ i/ )/ =/ {/ i/ +/ 1/ ,/ i/ +/ 2/ ,/ …/ ,/ i/ +/ w/ }/ ∪/ Adj/ (/ i/ +/ w/ )/ (/ 2/ )/ 其中/ ,/ Adj/ (/ i/ )/ 表示/ 第/ i/ 列/ 对角线/ 下方/ 非零/ 元素/ 的/ 行/ 坐标/ 集合/ ./ 以图/ 1/ (/ a/ )/ 中/ 的/ 稀疏/ 矩阵/ 为例/ ,/ 由于/ Adj/ (/ 0/ )/ =/ {/ 1/ }/ ∪/ Adj/ (/ 1/ )/ =/ {/ 1/ ,/ 5/ }/ ,/ 第/ 0/ 列/ 与/ 第/ 1/ 列/ 合并/ ;/ 由于/ Adj/ (/ 3/ )/ =/ {/ 4/ }/ ∪/ Adj/ (/ 4/ )/ =/ {/ 4/ ,/ 5/ }/ ,/ 并且/ Adj/ (/ 4/ )/ =/ {/ 5/ }/ ∪/ Adj/ (/ 5/ )/ =/ {/ 5/ }/ ,/ 第/ 3/ 列/ 、/ 第/ 4/ 列/ 与/ 第/ 5/ 列/ 合并/ ./ 经过/ 列/ 合并/ 后/ 形成/ 的/ 超/ 节点/ 数据结构/ 如图/ 2/ 所示/ ,/ 形成/ 了/ s0/ ,/ s1/ ,/ s2/ 共/ 3/ 个/ 超/ 节点/ ./ 超/ 节点/ 数据结构/ 由/ 6/ 个/ 数组/ 构成/ ,/ colSub/ 记录/ 首列/ 的/ 列/ 号/ ,/ colNum/ 记录/ 相邻/ 列/ 数量/ ,/ rowSub/ 记录/ 了/ 对角线/ 下方/ 的/ 行号/ ,/ val/ 按行/ 记录/ 元素/ 数值/ ,/ rowPtr/ 和/ snPtr/ 分别/ 指向/ 各超/ 节点/ 对应/ 于/ rowSub/ 和/ val/ 数组/ 中/ 的/ 开始/ 位置/ ./ 以/ 引进/ 了/ 额外/ 的/ 零/ 元素/ 并/ 增加/ 了/ 存储/ 和/ 计算/ 开销/ 为/ 代价/ ,/ 超/ 节点/ 数据结构/ 使得/ 稀疏/ 矩阵/ 的/ 非/ 零/ 数据/ 存储/ 相对/ 集中/ ./ 一方面/ ,/ 在/ 超/ 节点/ 内部/ 可以/ 直接/ 寻址/ ,/ 减少/ 了/ 间接/ 寻址/ 次数/ ;/ 另一方面/ ,/ 超/ 节点/ 内部/ 数据/ 访问/ 相对/ 集中/ ,/ 提高/ 了/ 数据/ 的/ 复用/ 率/ ./ 由于/ 超/ 节点/ 采用/ 稠密/ 矩阵/ 数据/ 块/ 存储/ ,/ 可以/ 调用/ BLAS/ (/ BasicLinearAlgebraSubprograms/ )/ 库函数/ 以/ 提高/ 计算/ 效率/ [/ 4/ ]/ ./ 因此/ ,/ 现有/ 的/ 稀疏/ 矩阵/ 分解/ 算法/ 大多/ 采用/ 超/ 节点/ 数据结构/ ./ 2.2/ GPU/ 架构/ 当前/ 用于/ 通用/ 计算/ 的/ 主流/ GPU/ 架构/ 是/ CUDA/ (/ ComputeUnifiedDeviceArchitecture/ )/ 架构/ ./ 硬件/ 结构/ 方面/ ,/ GPU/ 由/ 多个/ 流/ 多处理器/ (/ StreamingMultiprocessor/ ,/ SM/ )/ 组成/ ,/ 每个/ SM/ 包含/ 多个/ 标量/ 处理器/ (/ ScalarProcessor/ ,/ SP/ )/ ./ 每个/ SM/ 中/ 的/ 指令/ 发射/ 部件/ 将/ 相同/ 的/ 指令/ 发射/ 到/ 各个/ SP/ 上/ ,/ 各/ SP/ 在/ 不同/ 的/ 数据/ 集上/ 执行/ 相同/ 的/ 指令/ ./ 软件结构/ 方面/ ,/ GPU/ 的/ 基本/ 编程/ 单元/ 是/ 核/ 程序/ (/ kernel/ )/ ,/ 基本/ 运算/ 单元/ 是/ 线程/ ./ 每个/ 线程/ 执行/ 同一个/ 核/ 程序/ 的/ 代码/ ,/ 根据/ 线程/ 编号/ 处理/ 不同/ 的/ 数据/ ./ 多个/ 线程/ 构成/ 线程/ 块/ ,/ 线程/ 块/ 内/ 的/ 线程/ 以/ 单指令/ 多线程/ (/ SingleInstructionMultipleThreads/ ,/ SIMT/ )/ 方式/ 执行/ ./ CUDA/ 的/ 流/ 机制/ 能够/ 支持/ 多个/ 核/ 程序/ 在/ GPU/ 上/ 同时/ 执行/ ./ 流是/ 一系列/ 顺序/ 执行/ 的/ 操作/ ,/ 流/ 之间/ 并发/ 执行/ 各自/ 的/ 命令/ ./ 每个/ 流/ 拥有/ 唯一/ 的/ 编号/ ./ 发射/ 到/ 同一个/ 流/ 的/ 核/ 程序/ 按照/ 发射/ 顺序/ 执行/ ,/ 发射/ 到/ 不同/ 流/ 的/ 核/ 程序/ 在/ 计算资源/ 满足/ 的/ 前提/ 下/ 能够/ 同时/ 运行/ ./ CUDA/ 的/ 事件/ 机制/ 提供/ 了/ 检测/ 流内/ 的/ 任务/ 执行/ 进度/ 的/ 方式/ ./ 事件/ 插入/ 流/ 的/ 位置/ 称为/ 事件/ 记载/ 点/ ,/ 只有/ 当流/ 中/ 在/ 时间/ 记载/ 点/ 之前/ 的/ 所有/ 任务/ 全部/ 完成/ 后/ ,/ 事件/ 才/ 会/ 被/ 记载/ ./ 在/ CPU/ -/ GPU/ 异构/ 系统/ 中/ ,/ GPU/ 作为/ 协处理器/ ,/ 由/ CPU/ 控制/ 将/ 数据/ 从/ 主机/ 的/ DRAM/ (/ DynamicRandomAccessMemory/ )/ 传输/ 到/ GPU/ 的/ DRAM/ ,/ 然后/ 将/ 计算/ 任务/ 对应/ 的/ 核/ 程序/ 发射/ 到/ GPU/ 上/ ,/ 由/ GPU/ 完成/ 对/ 数据/ 的/ 处理/ ./ 当/ GPU/ 运算/ 结束/ 后/ ,/ 再/ 由/ Page4CPU/ 控制/ 将/ 数据/ 从/ GPU/ 的/ DRAM/ 传回/ 主机/ 的/ DRAM/ ./ 3/ 相关/ 工作/ 稀疏/ 矩阵/ Cholesky/ 分解/ 算法/ 包括/ 预处理/ 和/ 数值/ 分解/ 两个/ 阶段/ ./ 预处理/ 阶段/ 包括/ 矩阵/ 行列/ 重/ 排序/ 和/ 符号/ 分解/ ,/ 所有/ 的/ 数值/ 计算/ 都/ 在/ 数值/ 分解/ 部分/ 完成/ ./ 在/ 预处理/ 阶段/ ,/ 首先/ ,/ 通过/ 启发式/ 矩阵/ 排序/ 算法/ 交换/ 稀疏/ 矩阵/ 犃/ 的/ 行/ 和/ 列/ ,/ 试图/ 降低/ 矩阵/ 分解/ 过程/ 中/ 产生/ 的/ 填充/ 元/ 的/ 数量/ ,/ 从而/ 减小/ 矩阵/ 分解/ 的/ 存储量/ 和/ 计算/ 量/ ;/ 然后/ ,/ 通过/ 符号/ 分解/ 算法/ 确定/ 犃/ 分解/ 后/ 的/ 分解/ 因子/ 犔/ 的/ 稀疏/ 结构/ ,/ 即/ 确定/ 在/ 分解/ 过程/ 中/ 增加/ 的/ 非/ 零/ 元素/ 位置/ ,/ 预先/ 分配/ 存储空间/ 并/ 生成/ 超/ 节点/ 数据结构/ 和/ 消去/ 树/ ./ 在/ 数值/ 分解/ 阶段/ ,/ 计算/ 分解/ 因子/ 犔/ 中/ 的/ 所有/ 非/ 零元/ 数值/ ./ 对于/ 大规模/ 稀疏/ 矩阵/ ,/ 数值/ 分解/ 时间/ 是/ 整个/ 矩阵/ 分解/ 过程/ 中/ 最/ 耗时/ 的/ 部分/ ,/ 通过/ 加速/ 数值/ 分解/ 能够/ 有效/ 提高/ 矩阵/ 的/ 分解/ 效率/ [/ 5/ -/ 6/ ]/ ./ 根据/ 数值/ 分解/ 算法/ 的/ 不同/ ,/ 稀疏/ 矩阵/ Cholesky/ 分解/ 算法/ 主要/ 包括/ 多/ 波前法/ (/ MultifrontalMethod/ )/ [/ 7/ -/ 8/ ]/ 和/ 超/ 节点/ 法/ (/ SupernodalMethod/ )/ [/ 5/ -/ 6/ ]/ ./ 这/ 两种/ 方法/ 都/ 是/ 基于/ 超/ 节点/ 数据结构/ ,/ 通过/ 减少/ 间接/ 地址/ 访问/ ,/ 提高/ Cache/ 的/ 命中率/ ,/ 利用/ 优化/ 的/ BLAS/ 库函数/ 进行/ 面向/ 稠密/ 数据/ 块/ 的/ 浮点/ 计算/ 以/ 提高/ 计算/ 性能/ ./ 不同之处/ 在于/ 超/ 节点/ 间/ 更新/ 的/ 方法/ :/ 多/ 波前法/ 通过/ 形成/ 波前/ 阵/ (/ FrontalMatrix/ )/ 将/ 超/ 节点/ 间/ 的/ 更新/ 累积/ 起来/ ,/ 延迟/ 对/ 后续/ 超/ 节点/ 的/ 更新/ [/ 7/ ]/ ;/ 超/ 节点/ 法/ 直接/ 进行/ 超/ 节点/ 间/ 的/ 更新/ [/ 8/ ]/ ./ 近年来/ ,/ 一些/ 研究/ 致力于/ 将/ 稀疏/ 矩阵/ Cholesky/ 分解/ 算法/ 移植/ 到/ GPU/ ,/ 主要/ 思想/ 是/ 根据/ 计算/ 任务/ 的/ 特性/ 和/ 粒度/ ,/ 将/ 数值/ 分解/ 过程/ 中/ 一部分/ 稠密/ 矩阵/ 的/ BLAS/ 计算/ 任务/ 映射/ 到/ GPU/ 上/ [/ 9/ -/ 12/ ]/ ./ 多/ 波前法/ 的/ 稠密/ 矩阵/ 操作/ 粒度/ 通常/ 大于/ 超/ 节点/ 法/ ,/ 更/ 易于/ 在/ GPU/ 上/ 实现/ ,/ 因此/ 这些/ 研究/ 都/ 选择/ 了/ 多/ 波前法/ 作为/ 研究/ 对象/ ./ Vuduc/ 等/ 人/ [/ 9/ ]/ 将/ 计算/ 任务/ 直接/ 映射/ 到/ GPU/ ,/ 而/ George/ 等/ 人/ [/ 10/ ]/ 在/ 模型/ 的/ 指导/ 下/ 选择/ 计算/ 任务/ 的/ 映射/ 方式/ ,/ 只/ 将/ GPU/ 上/ 预期/ 运行/ 效率/ 高于/ CPU/ 的/ 任务调度/ 到/ GPU/ 上/ ./ Lucas/ 等/ 人/ [/ 11/ ]/ 在/ 消去/ 树/ 的/ 底部/ 使用/ 多个/ CPU/ 线程/ 加速/ 小规模/ 计算/ 任务/ ,/ 而/ 在/ 消去/ 树/ 的/ 顶端/ 使用/ GPU/ 加速/ 大规模/ 计算/ 任务/ ./ Faverge/ 使用/ 通用/ 的/ 任务调度/ 框架/ 替换/ 现有/ 稀疏/ 矩阵/ 分解/ 算法/ 中/ 的/ 任务调度/ 模块/ ,/ 试图/ 为/ 稀疏/ 矩阵/ 分解/ 应用/ 提供/ CPU/ -/ GPU/ 异构/ 并行/ 平台/ 上/ 统一/ 的/ 编程/ 接口/ [/ 12/ ]/ ./ 当前/ 研究/ 的/ 共同/ 方法/ 是/ 在/ 现有/ 稀疏/ 矩阵/ 分解/ 算法/ 的/ 基础/ 上/ ,/ 不/ 改变/ 符号/ 分解/ 部分/ ,/ 只/ 修改/ 数值/ 分解/ 部分/ 计算/ 任务/ 的/ 调度/ 方法/ ,/ 将/ 一部分/ 计算/ 任务分配/ 到/ GPU/ ./ 这种/ 方法/ 的/ 优势/ 是/ 易于/ 将/ 现有/ 算法/ 移植/ 到/ GPU/ ,/ 但/ 没有/ 产生/ 适合/ GPU/ 处理/ 的/ 数据结构/ ,/ 因此/ 实际/ 的/ 算法/ 性能/ 较/ 低/ ./ 在/ 双/ 精度/ 条件/ 下/ ,/ Vuduc/ 等/ 人/ [/ 9/ ]/ 的/ 实现/ 达到/ 串行/ 程序/ 性能/ 的/ 3/ 倍/ ,/ Faverge/ 的/ 实现/ 最高/ 能够/ 达到/ 串行/ 程序/ 性能/ 的/ 5/ 倍/ [/ 12/ ]/ ./ George/ 等/ 人/ [/ 10/ ]/ 的/ 实现/ 最高/ 能够/ 达到/ 串行/ 程序/ 性能/ 的/ 9/ 倍/ ,/ Lucas/ 等/ 人/ [/ 11/ ]/ 的/ 实现/ 最高/ 能够/ 达到/ 串行/ 程序/ 性能/ 的/ 6/ 倍/ ,/ 但/ 两者/ 都/ 是/ 使用/ 单精度/ 的/ GPU/ 程序/ 与/ 双/ 精度/ 的/ CPU/ 程序/ 进行/ 比较/ ./ GPU/ 的/ 单精度/ 计算能力/ 是/ 双/ 精度/ 计算能力/ 的/ 2/ 倍/ ~/ 8/ 倍/ ,/ 并且/ 双/ 精度/ 访存/ 数据量/ 是/ 单精度/ 访存/ 数据量/ 的/ 2/ 倍/ ,/ 因此/ 在/ 单精度/ 条件/ 下/ 的/ GPU/ 性能/ 是/ 双/ 精度/ 情况/ 下/ 的/ 2/ 倍/ 以上/ ./ 可见/ ,/ 在/ CPU/ -/ GPU/ 异构/ 平台/ 上/ ,/ 稀疏/ 矩阵/ Cholesky/ 分解/ 目前/ 所/ 能/ 达到/ 的/ 性能/ 最高/ 仅为/ 单核/ 处理器/ 性能/ 的/ 4/ 倍/ 左右/ ,/ 与/ 多/ 核/ 处理器/ 的/ 性能/ 相当/ ./ 现有/ 的/ 稀疏/ 矩阵/ Cholesky/ 分解/ 算法/ 无法/ 充分发挥/ GPU/ 的/ 性能/ 优势/ ,/ 其/ 原因/ 主要/ 包括/ :/ (/ 1/ )/ 没有/ 针对/ GPU/ 进行/ 专门/ 的/ 数据结构/ 优化/ ,/ 生成/ 的/ 数据结构/ 通常/ 更/ 适合/ CPU/ 而/ 不是/ GPU/ ./ (/ 2/ )/ 频繁/ 的/ 数据传输/ 开销/ ,/ 每次/ 调用/ GPU/ 计算/ 任务/ 的/ 时候/ 都/ 需要/ 产生/ 多次/ 数据传输/ ./ (/ 3/ )/ 没有/ 实现/ GPU/ 端/ 多个/ 任务/ 间/ 的/ 并行/ ,/ 降低/ 了/ GPU/ 的/ 利用率/ ./ 针对/ 以上/ 问题/ ,/ 我们/ 设计/ 了/ 基于/ GPU/ 的/ 稀疏/ 矩阵/ Cholesky/ 分解/ 算法/ ,/ 提出/ 以下/ 的/ 解决方案/ ./ (/ 1/ )/ 修改/ 符号/ 分解/ 部分/ ,/ 形成/ 适合/ GPU/ 处理/ 的/ 数据结构/ ./ 一方面/ ,/ 采用/ 超/ 节点/ 合并/ 算法/ 将/ 规模/ 小/ 的/ 相邻/ 超/ 节点/ 合并/ ,/ 增大/ 计算/ 任务/ 的/ 规模/ ;/ 另一方面/ ,/ 采用/ 超/ 节点/ 分块/ 算法/ 降低/ 超/ 节点/ 合并/ 过程/ 中/ 额外/ 引入/ 的/ 零/ 元素/ 存储/ 和/ 计算/ 开销/ ./ (/ 2/ )/ 将/ 稀疏/ 矩阵/ 压缩/ 存储/ 数据结构/ 中/ 的/ 矩阵/ 元素/ 数据/ 和/ 索引/ 数据/ 分开/ 存储/ ,/ 在/ 计算/ 过程中将/ 矩阵/ 元素/ 数据/ 存储/ 在/ GPU/ 端/ ,/ 而/ 索引/ 数据/ 存储/ 在/ CPU/ 端/ ,/ 降低/ CPU/ 与/ GPU/ 的/ 通信/ 开销/ ./ (/ 3/ )/ 设计/ 了/ 基于/ 队列/ 的/ 任务/ 生成/ 与/ 调度/ 方法/ ,/ 使用/ 流/ 重叠/ 和/ 事件/ 同步/ 机制/ ,/ 使得/ 满足/ 数据/ 依赖性/ 的/ 多个/ GPU/ 任务/ 能够/ 并行执行/ ,/ 提高/ GPU/ 的/ 利用率/ ./ 多/ 波前法/ 虽然/ BLAS/ 操作/ 效率/ 更高/ ,/ 但/ 存储/ 需求量/ 较大/ ;/ GPU/ 上/ 的/ 存储空间/ 有限/ ,/ 因此/ 我们/ 选择/ 了/ 存储/ 需求量/ 较/ 小/ 的/ 超/ 节点/ 法/ 作为/ 研究/ 对象/ ,/ 直接/ 进行/ 超/ 节点/ 间/ 的/ 更新/ ./ Page54/ 基于/ GPU/ 的/ 稀疏/ Cholesky/ 分解/ 在/ 本节/ 中/ ,/ 我们/ 介绍/ 了/ 基于/ GPU/ 的/ 稀疏/ 矩阵/ Cholesky/ 分解/ 算法/ ./ 为了/ 形成/ 适合/ GPU/ 处理/ 的/ 数据结构/ ,/ 首先/ ,/ 介绍/ 超/ 节点/ 的/ 生成/ 与/ 合并/ 过程/ ,/ 将/ 稀疏/ 矩阵/ 组织/ 成/ 一系列/ 规则/ 的/ 数据/ 块/ ./ 接下来/ ,/ 介绍/ 了/ 对应/ 于/ 扩展/ 超/ 节点/ 分块/ 存储/ 数据结构/ 的/ 计算/ 任务/ 定义/ ./ 最后/ ,/ 设计/ 了/ 基于/ 队列/ 的/ 任务/ 生成/ 与/ 调度/ 算法/ ,/ 实现/ 了/ 多个/ GPU/ 任务/ 间/ 的/ 并行/ 化/ ./ 4.1/ 超/ 节点/ 的/ 生成/ 、/ 合并/ 与/ 分块/ 稀疏/ 矩阵/ 犃/ 如/ 图/ 3/ (/ a/ )/ 所示/ ,/ 其中/ ,/ 实心/ 点/ 表示/ 犃/ 中原/ 有/ 的/ 非/ 零元/ ,/ 空心/ 点/ 表示/ 填充/ 元/ ./ 超/ 节点/ 生成/ 算法/ 合并/ 相邻/ 的/ 稀疏/ 结构/ 相同/ 的/ 矩阵/ 列/ ,/ 形成/ 超/ 节点/ 数据结构/ ,/ 合并/ 规则/ 如下/ :/ merge/ (/ ci/ ,/ ci/ +/ 1/ )/ iffi/ +/ 1/ =/ parent/ (/ i/ )/ 其中/ ci/ 表示/ 第/ i/ 列/ ,/ parent/ (/ i/ )/ 表示/ 消去/ 树中/ 节点/ i/ 的/ 父/ 节点/ 编号/ ,/ nnz/ (/ i/ )/ 表示/ 第/ i/ 列中/ 对角线/ 下方/ 的/ 非/ 零元/ 数量/ ./ 列/ 合并/ 后/ ,/ 稀疏/ 矩阵/ 被/ 划分/ 为/ 一系列/ 超/ 节点/ ,/ 如图/ 3/ (/ a/ )/ 与/ 图/ 3/ (/ b/ )/ 所示/ ./ 相应/ 的/ ,/ 消去/ 树中/ 各/ 节点/ 合并/ 后/ 形成/ 新/ 的/ 树结构/ ,/ 称为/ 集成/ 树/ ,/ 如图/ 3/ (/ c/ )/ 所示/ ./ 集成/ 树/ 的/ 节点/ 对应/ 于/ 各超/ 节点/ ,/ 节点/ 间/ 父子关系/ 对应/ 于超/ 节点/ 间/ 的/ 数据/ 相关性/ ./ 大多数/ 超/ 节点/ 的/ 宽度/ (/ 合并/ 的/ 列/ 数量/ )/ 较/ 小/ ,/ 相应/ 的/ 计算/ 任务/ 处理/ 的/ 矩阵/ 规模/ 也/ 较/ 小/ ,/ 直接/ 将/ 这些/ 计算/ 任务/ 映射/ 到/ GPU/ 上/ 无法/ 充分发挥/ GPU/ 的/ 高带宽/ 和/ 高/ 并行计算/ 性能/ 的/ 优势/ ,/ 因此/ 需要/ 将/ 一些/ 稀疏/ 结构/ 相近/ 的/ 相邻/ 超/ 节点/ 进一步/ 合并/ ,/ 通过/ 增加/ 超/ 节点/ 的/ 宽度/ 以/ 增大/ 计算/ 任务/ 的/ 粒度/ ./ 为了/ 区分/ 合并/ 前后/ 的/ 超/ 节点/ ,/ 我们/ 将/ 合并/ 前/ 的/ 超/ 节点/ 称为/ 基本/ 超/ 节点/ ,/ 合并/ 后/ 的/ 超/ 节点/ 称为/ 扩展/ 超/ 节点/ ./ 超/ 节点/ 合并/ 规则/ 采用/ 与/ Hogg/ 相同/ 的/ 方法/ [/ 13/ ]/ ,/ 具体/ 描述/ 为/ 其中/ ,/ si/ 表示/ 第/ i/ 个/ 基本/ 超/ 节点/ ,/ parent/ (/ i/ )/ 表示/ 集成/ 树中/ 节点/ i/ 的/ 父/ 节点/ 编号/ ,/ width/ (/ s/ )/ 表示/ 基本/ 超/ 节点/ s/ 的/ 宽度/ ,/ t/ 为/ 合并/ 阈值/ ./ 宽度/ 小于/ t/ 的/ 相邻/ 父子/ 基本/ 超/ 节点/ 将/ 被/ 合并/ 为/ 扩展/ 超/ 节点/ ./ 设/ t/ 为/ 2/ ,/ 通过/ 合并/ 满足/ 合并/ 条件/ 的/ 相邻/ 基本/ 超/ 节点/ 得到/ 图/ 4/ 所示/ 的/ 扩展/ 超/ 节点/ 结构/ ./ 其中/ ,/ s0/ 与/ s1/ 合并/ 生成/ 了/ s0/ ,/ s6/ 与/ s7/ 合并/ 生成/ 了/ s5/ ./ 超/ 节点/ 的/ 生成/ 与/ 合并/ 增加/ 了/ 矩阵/ 分解/ 过程/ 中/ 计算/ 任务/ 处理/ 的/ 矩阵/ 规模/ ,/ 提高/ 了/ 任务/ 的/ 计算/ 效率/ ./ 但是/ ,/ 超/ 节点/ 也/ 增加/ 了/ 额外/ 的/ 存储/ 和/ 计算/ 量/ ./ s5/ 的/ 生成/ 过程/ 如图/ 5/ (/ a/ )/ 与/ 图/ 5/ (/ b/ )/ 所示/ ,/ 其中/ 三角形/ 和/ 正方形/ 分别/ 表示/ 基本/ 超/ 节点/ 生成/ 过程/ 与/ 合并/ 过程/ 所/ 引进/ 的/ 额外/ 零/ 元素/ ./ 额外/ 的/ 零/ 元素/ 增加/ 了/ 存储/ 和/ 计算/ 的/ 开销/ ./ 为了/ 减少/ 额外/ 的/ 零/ 元素/ ,/ 我们/ 对/ 规模/ 超过/ 阈值/ 的/ 扩展/ 超/ 节点/ 进行/ 分块/ 处理/ ./ 当/ 阈值/ 为/ 2/ 时/ ,/ 我们/ 对/ s5/ 分块/ 结果/ 如图/ 5/ (/ c/ )/ 所示/ ./ 分块/ 后/ 的/ 扩展/ 超/ 节点/ 包含/ 一系列/ Page6/ 由/ 数据/ 块/ 组成/ 的/ 列/ ,/ 我们/ 将/ 这样/ 的/ 结构/ 称为/ 块/ 列/ ./ 扩展/ 超/ 节点/ 分块/ 数据结构/ 中/ ,/ 矩阵/ 数据/ 按照/ 块/ 列/ 顺序/ 逐块/ 存储/ ,/ 块/ 内/ 数据/ 逐行/ 存储/ ./ 在/ 基本/ 超/ 节点/ 数据结构/ 的/ 基础/ 上/ ,/ 增加/ 了/ 指向/ 块/ 列/ 元素/ 起始/ 地址/ 的/ blkColPtr/ 数组/ ,/ 而/ snPtr/ 数组/ 指向/ 扩展/ 超/ 节点/ 对应/ 的/ blkColPtr/ 数组/ 的/ 起始/ 位置/ ./ 4.2/ 任务/ 定义/ 通过/ 将/ 稀疏/ 矩阵/ 由/ CSC/ 数据结构/ 转换/ 为/ 扩展/ 超/ 节点/ 分块/ 数据结构/ ,/ 计算/ 任务/ 处理/ 的/ 对象/ 由/ 矩阵/ 列/ 转换/ 为/ 扩展/ 超/ 节点/ 中/ 的/ 数据/ 块/ ./ 按照/ 处理/ 数据结构/ 的/ 层次/ 关系/ ,/ 计算/ 任务/ 分为/ 3/ 级/ ,/ 自上而下/ 包括/ 扩展/ 超/ 节点/ 任务/ 、/ 块/ 列/ 任务/ 和/ 数据/ 块/ 任务/ ./ 扩展/ 超/ 节点/ 任务/ 包括/ 扩展/ 超/ 节点/ 内/ 更新/ 任务/ snScale/ 和/ 扩展/ 超/ 节点/ 间/ 更新/ 任务/ snUpdate/ ./ 其中/ ,/ snUpdate/ (/ sk/ ,/ si/ )/ 表示/ si/ 更新/ sk/ ./ 块/ 列/ 任务/ 包括/ 块/ 列内/ 更新/ 任务/ bcScale/ 、/ 扩展/ 超/ 节点/ 内块/ 列间/ 更新/ 任务/ bcUpdateInternal/ 与/ 扩展/ 超/ 节点/ 间块/ 列间/ 更新/ 任务/ bcUpdateBetween/ ./ 数据/ 块/ 任务/ 完成/ 对/ 矩阵/ 元素/ 的/ 更新/ ,/ 包括/ (/ 1/ )/ potrf/ (/ 犅/ )/ Cholesky/ 分解/ 犅/ =/ 犔/ 犔/ T/ ./ (/ 2/ )/ trsm/ (/ 犅/ ,/ 犆/ )/ 计算/ 犅/ =/ 犅/ \/ 犆/ ./ (/ 3/ )/ syrk/ (/ 犅/ ,/ 犆/ )/ 计算/ 犅/ =/ 犅/ -/ 犆/ 犆/ T/ ./ (/ 4/ )/ gemm/ (/ 犅/ ,/ 犆/ ,/ 犇/ )/ 计算/ 犅/ =/ 犅/ -/ 犆犇/ T/ ./ (/ 5/ )/ modify/ (/ 犅/ ,/ Buffer/ )/ 使用/ Buffer/ 更新/ B/ ./ 其中/ ,/ 犅/ 、/ 犆/ 、/ 犇/ 、/ 犈/ 为/ 数据/ 块/ ,/ Buffer/ 为/ 数据/ 缓冲区/ ./ 前/ 4/ 种/ 任务/ 是/ 标准/ 的/ 稠密/ 矩阵/ 操作/ ,/ 能够/ 直接/ 调用/ 优化/ 的/ 高性能/ 算法/ 库/ 实现/ ./ 扩展/ 超/ 节点/ 间/ 的/ 数据/ 块/ 往往/ 没有/ 对齐/ ,/ 在/ 块/ 列/ 更新/ 的/ 时候/ ,/ 需要/ 将/ 更新/ 的/ 数据/ 先/ 存入/ Buffer/ ,/ 再/ 根据/ 索引/ 关系/ 更新/ 目标/ 块/ 中/ 相应/ 位置/ 的/ 元素/ ,/ 因此/ 在/ 以上/ 4/ 种/ 任务/ 外/ ,/ 还/ 需要/ 实现/ modify/ 任务/ ,/ 以/ 完成/ 不同/ 扩展/ 超/ 节点/ 间/ 的/ 数据/ 块/ 更新/ ./ 由/ 扩展/ 超/ 节点/ 任务/ 到/ 数据/ 块/ 任务/ 的/ 映射/ 如图/ 6/ 和/ 图/ 7/ 所示/ ./ 其中/ ,/ pv/ ,/ k/ 表示/ sv/ 中/ 的/ 第/ k/ 个块/ 列/ ,/ bv/ ,/ k/ 表示/ 块/ 列/ pv/ ,/ k/ 的/ 数据/ 块/ 个数/ ,/ Bv/ ,/ k/ ,/ i/ 表示/ 块/ 列/ pv/ ,/ k/ 中/ 第/ i/ 个/ 数据/ 块/ ./ findBlk/ (/ pv/ ,/ k/ ,/ m/ ,/ pv/ ,/ i/ )/ 查找/ 块/ 列/ pv/ ,/ i/ 中/ 与/ 块/ 列/ pv/ ,/ k/ 中/ 第/ m/ 个/ 数据/ 块/ 同行/ 的/ 数据/ 块/ 起始/ 位置/ ,/ 如果/ 不/ 存在/ 同行/ 数据/ 块/ 则/ 返回/ -/ 1/ ./ clear/ (/ Buffer/ )/ 将/ Buffer/ 中/ 的/ 所有/ 元素/ 值设/ 为/ 0/ ./ 图/ 6/ 扩展/ 超/ 节点/ 内/ 更新/ 任务/ 到/ 数据/ 块/ 任务/ 的/ 映射/ 图/ 7/ 扩展/ 超/ 节点/ 间/ 更新/ 任务/ 到/ 数据/ 块/ 任务/ 的/ 映射/ 至此/ ,/ 我们/ 已经/ 将/ 稀疏/ 矩阵/ Cholesky/ 分解/ 的/ 计算/ 任务/ 由/ 扩展/ 超/ 节点/ 任务/ 映射/ 到/ 数据/ 块/ 任务/ ./ 接下来/ ,/ 介绍/ 面向/ GPU/ 的/ 任务/ 生成/ 与/ 调度/ 方法/ ./ 4.3/ 任务/ 的/ 生成/ 与/ 调度/ 我们/ 设计/ 了/ 面向/ GPU/ 的/ 任务/ 生成/ 与/ 调度/ 方/ Page7/ 法/ ./ 按照/ 数据/ 相关性/ ,/ CPU/ 生成/ 计算/ 任务/ 并/ 插入/ 任务/ 队列/ ./ GPU/ 任务/ 通过/ 流/ 和/ 事件/ 进行/ 组织/ ,/ 不同/ 流间/ 的/ 任务/ 在/ 满足/ 数据/ 依赖性/ 的/ 前提/ 下/ 能够/ 并行执行/ ./ 接下来/ ,/ 我们/ 首先/ 介绍/ 集成/ 树/ 指导/ 的/ 任务/ 生成/ 算法/ ,/ 然后/ 介绍/ 基于/ 流/ 和/ 事件/ 的/ 任务调度/ 算法/ ./ 在/ 集成/ 树/ 的/ 指导/ 下/ ,/ 稀疏/ 矩阵/ Cholesky/ 分解/ 的/ 计算/ 任务/ 生成/ 算法/ 描述/ 如/ 算法/ 2/ 所示/ ./ 算法/ 2/ ./ 任务/ 生成/ 算法/ ./ 输入/ :/ 集成/ 树/ T/ ,/ 稀疏/ 矩阵/ 输出/ :/ 任务/ 队列/ WHILE/ !/ isEmpty/ (/ T/ )/ DO/ 生成/ 消去/ 树/ T/ 的/ 叶/ 节点/ 编号/ 集合/ GFORi/ ∈/ GDOFORi/ ∈/ EDO/ 任务/ 按照/ 生成/ 的/ 先后顺序/ 插入/ 任务/ 队列/ ,/ 所有/ 与/ 任务/ I/ 存在/ 数据/ 依赖性/ 的/ 任务/ 都/ 在/ 任务/ I/ 之后/ 插入/ 队列/ ./ 对于/ 图/ 4/ (/ a/ )/ 中/ 的/ 稀疏/ 矩阵/ ,/ 任务/ 生成/ 过程/ 如图/ 8/ 所示/ ./ 任务调度/ 算法/ 按照/ FIFO/ 的/ 顺序/ ,/ 由/ 任务/ 队列/ 中/ 取出/ 任务/ 并/ 发射/ 到/ GPU/ ./ 为了/ 实现/ 多任务/ 并行/ ,/ 将/ 数据/ 块/ 任务/ 插入/ 不同/ 的/ 流/ ./ 每个/ 任务/ 插入/ 流后/ 都/ 随之/ 插入/ 一个/ 事件/ ,/ 作为/ 该/ 任务/ 完成/ 的/ 标志/ ./ 当/ 后续/ 任务/ 与/ 该/ 任务/ 存在/ 数据/ 依赖性/ 的/ 时候/ ,/ 在/ 将/ 后续/ 任务/ 插入/ 流/ 之前/ 需要/ 先/ 插入/ 一个/ 事件/ 等待/ 命令/ ,/ 使得/ 该/ 任务/ 只有/ 在/ 对应/ 事件/ 完成/ 之后/ 才能/ 启动/ ,/ 从而/ 保证/ 了/ 任务/ 的/ 执行/ 顺序/ ./ 任务调度/ 算法/ 描述/ 如/ 算法/ 3/ 所示/ ./ 算法/ 3/ ./ 任务调度/ 算法/ ./ 输入/ :/ 任务/ 队列/ taskQueue/ ,/ 稀疏/ 矩阵/ ,/ 流及/ 事件/ 数组/ 输出/ :/ 无/ streamID/ =/ 1/ ;/ WHILE/ !/ isEmpty/ (/ taskQueue/ )/ task/ =/ getTask/ (/ taskQueue/ )/ // // 取/ 任务/ StreamSynchronize/ (/ stream/ [/ streamID/ ]/ )/ // // 等待/ 任务/ i/ =/ (/ streamID/ -/ 1/ +/ streamNum/ )/ modstreamNumDOWHILEi/ !/ =/ streamIDInsertTask/ (/ stream/ [/ streamID/ ]/ ,/ task/ )/ // // 将/ 任务/ 插入/ 流/ InsertEvent/ (/ stream/ [/ streamID/ ]/ ,/ event/ [/ streamID/ ]/ )/ // // 记录/ 当前/ 流/ 的/ 目标/ 数据/ 块/ target/ [/ streamID/ ]/ =/ task/ ./ destID/ 算法/ 实现/ 中/ ,/ 为了/ 防止/ 任务/ 发送/ 速度/ 超过/ 任务/ 执行/ 速度/ 所/ 带来/ 的/ GPU/ 缓冲区/ 溢出/ ,/ 我们/ 规定/ 每个/ 流内/ 只能/ 有/ 一个/ 未/ 完成/ 任务/ ./ 5/ 实验/ 与/ 讨论/ 5.1/ 环境/ 配置/ 及/ 测试/ 集合/ 硬件/ 方面/ ,/ 主机/ 配置/ 为/ 主频/ 为/ 2.67/ GHz/ 的/ IntelQuadQ9400/ 四核/ 处理器/ ,/ 8GBDDR2800/ 内存/ ./ GPU/ 为/ NVIDIAGTX480/ ,/ 工作频率/ 为/ 1.4/ GHz/ ,/ 共有/ 15/ 个/ SM/ ,/ 每个/ SM/ 包含/ 32/ 个/ SP/ ,/ 显存/ 位/ 宽/ 为/ 384/ 位/ ,/ 显存/ 容量/ 为/ 1.5/ GB/ ./ 软件/ 方面/ ,/ 采用/ 64/ 位/ RedHatRHEL5/ ./ 5/ 操作系统/ ./ C/ 编译器/ 为/ gcc4/ ./ 1.2/ ,/ Fortran/ 编译器/ 为/ ifort12/ ./ 1.0/ ./ GPU/ 运行/ 环境/ 为/ CUDASDK4/ ./ 0.17/ ,/ CUDAToolkit4/ ./ 0.17/ ,/ CUDADriver4/ ./ 0/ ./ CPU/ 端/ BLAS/ 库函数/ 采用/ IntelMKL10/ ./ 3.7/ 数学/ 库/ ./ GPU/ 端/ ,/ trsm/ 、/ syrk/ 和/ gemm/ 任务/ 使用/ CuBLAS/ 数学/ 库/ 实现/ ,/ potrf/ 与/ modify/ 任务/ 使用/ 自定义/ 核/ 程序实现/ ./ 预处理/ 过程/ 中/ 矩阵/ 排序/ 采用/ Metis4/ ./ 0/ 算法/ 包/ 的/ Metis/ _/ NodeND/ 算法/ ①/ ./ 测试/ 矩阵/ 集如表/ 1/ 所示/ ,/ 所有/ 数据/ 来自/ UniversityofFloridaSparseMatrixCollection/ ②/ ./ ①/ ②/ Page8/ 编号/ 矩阵/ 名称/ 规模/ (/ 103/ )/ 非/ 零元/ 数量/ (/ 106/ )/ 123Trefethen/ _/ 2000020.004/ Trefethen/ _/ 20000b20/ ./ 05.2/ 实验/ 与/ 分析/ 在/ 本/ 部分/ ,/ 我们/ 从/ 基本/ 的/ 超/ 节点/ 稀疏/ 矩阵/ Cholesky/ 分解/ 算法/ 出发/ ,/ 采用/ 在/ 第/ 4/ 节中/ 介绍/ 的/ 数据组织/ 与/ 任务/ 组织/ 方法/ ,/ 以/ 矩阵/ 1/ 为例/ ,/ 逐步/ 将/ 其/ 由/ CPU/ 平台/ 移植/ 到/ GPU/ 平台/ ,/ 通过/ 实验/ 和/ 数据分析/ 验证/ 我们/ 的/ 稀疏/ 矩阵/ Cholesky/ 分解/ 算法/ 中/ 的/ 关键技术/ 的/ 有效性/ ./ 实验/ 数据/ 中/ 的/ 计算/ 时间/ 为/ 符号/ 分解/ 时间/ 与/ 数值/ 分解/ 时间/ 之/ 和/ ./ 5.2/ ./ 1/ 任务/ 映射/ 与/ 数据/ 存储/ 方案/ 配置/ 1/ 是/ 作为/ 基准/ 程序/ 的/ 基本/ 超/ 节点/ 稀疏/ 矩阵/ 分解/ 算法/ ./ 配置/ 2/ 将/ 除/ modify/ 外/ 的/ 数据/ 块/ 任务/ 映射/ 到/ GPU/ (/ modify/ 任务/ 根据/ 索引/ 直接/ 对/ 矩阵/ 数据/ 进行/ 修改/ ,/ 因此/ 当/ 矩阵/ 数据/ 存储/ 在/ CPU/ 端时/ ,/ modify/ 任务/ 需要/ 在/ CPU/ 端/ 实现/ )/ ./ 配置/ 3/ 将/ 所有/ 数据/ 块/ 任务/ 映射/ 到/ GPU/ ,/ 并/ 将/ 稀疏/ 矩阵/ 数据/ 在/ 分解/ 开始/ 前/ 传递/ 到/ GPU/ 端/ ,/ 分解/ 完成/ 后/ 再/ 传递/ 回/ CPU/ 端/ ./ 3/ 种/ 配置/ 下/ ,/ 稀疏/ 矩阵/ 分解/ 时间/ 如表/ 2/ 所示/ ./ 与/ 配置/ 1/ 相比/ ,/ 由于/ GPU/ 的/ 计算能力/ 高于/ CPU/ ,/ 配置/ 2/ 的/ 矩阵/ 分解/ 时间/ 低于/ 配置/ 1/ ./ 然而/ ,/ 由于/ 每次/ 执行/ GPU/ 任务/ 都/ 需要/ 产生/ CPU/ 与/ GPU/ 数据传输/ ,/ 由此/ 带来/ 的/ 频繁/ 的/ 数据传输/ 开销/ 使得/ 配置/ 2/ 的/ 总/ 时间/ 多于/ 配置/ 1/ ./ 可见/ ,/ 简单/ 的/ 将/ 计算/ 任务/ 映射/ 到/ GPU/ 上/ 并/ 不能/ 提高/ 算法/ 的/ 性能/ ./ 通过/ 在/ 分解/ 开始/ 前/ 将/ 矩阵/ 数据/ 迁移/ 到/ GPU/ 端/ ,/ 配置/ 3/ 减少/ 了/ 分解/ 过程/ 中/ CPU/ 与/ GPU/ 间/ 的/ 通信/ 开销/ ,/ 并且/ 由于/ GPU/ 的/ 访存/ 带宽/ 高于/ CPU/ ,/ 计算/ 时间/ 随着/ modify/ 任务/ 性能/ 的/ 提高/ 而/ 有所/ 降低/ ./ 配置/ 1/ 配置/ 2/ 配置/ 35.2/ ./ 2/ 超/ 节点/ 合并/ 与/ 分块/ 虽然/ 配置/ 3/ 与/ 配置/ 2/ 相比/ 性能/ 有所提高/ ,/ 然而/ 加速/ 比仅/ 为/ 配置/ 1/ 的/ 3/ 倍/ 左右/ ./ 这是/ 由于/ 形成/ 的/ 基本/ 超/ 节点/ 大多/ 宽度/ 较/ 小/ ,/ 相应/ 的/ GPU/ 任务/ 计算/ 粒度/ 小/ ,/ 无法/ 有效/ 发挥/ GPU/ 的/ 计算/ 性能/ ./ 为了/ 提高/ GPU/ 任务/ 的/ 计算/ 粒度/ ,/ 需要/ 增大/ 超/ 节点/ 的/ 宽度/ ./ 我们/ 使用/ 超/ 节点/ 合并/ 方法/ ,/ 按照/ 4.1/ 节中/ 的/ 规则/ (/ 4/ )/ ,/ 将/ 相邻/ 的/ 满足条件/ 的/ 父子/ 基本/ 超/ 节点/ 合并/ ./ 与/ 基本/ 超/ 节点/ 相比/ ,/ 扩展/ 超/ 节点/ 的/ 规模/ 更大/ ,/ 有利于/ 提高/ GPU/ 计算/ 效率/ ./ 但是/ ,/ 超/ 节点/ 合并/ 会/ 增加/ 超/ 节点/ 中零/ 元素/ 的/ 数量/ ,/ 从而/ 增加/ 了/ 存储量/ 和/ 计算/ 量/ ./ 测试/ 矩阵/ 包括/ 2115/ 个/ 基本/ 超/ 节点/ ,/ 对于/ 不同/ 的/ 合并/ 阈值/ ,/ 其/ 分解/ 因子/ 的/ 扩展/ 超/ 节点/ 数量/ 、/ 存储量/ 和/ 计算/ 时间/ 如表/ 3/ 所示/ ./ 合并/ 阈值/ 扩展/ 超/ 节点/ 数量/ 存储量/ // GB/ 计算/ 时间/ // s0163264128256/ 实验/ 结果表明/ ,/ 随着/ 扩展/ 超/ 节点/ 规模/ 的/ 增大/ ,/ 起初/ ,/ 由于/ 计算/ 任务/ 粒度/ 的/ 增大/ ,/ GPU/ 计算/ 效率/ 提高/ ,/ 分解/ 时间/ 减少/ ;/ 随后/ ,/ 额外/ 的/ 零/ 元素/ 带来/ 的/ 开销/ 超过/ 了/ GPU/ 计算/ 效率/ 的/ 影响/ ,/ 计算/ 时间/ 开始/ 增加/ ./ 在/ 合并/ 阈值/ 为/ 64/ 时/ ,/ 矩阵/ 分解/ 时间/ 最小/ ,/ 因此/ 在/ 接下来/ 的/ 部分/ ,/ 选用/ 64/ 作为/ 默认/ 合并/ 阈值/ ./ 为了/ 减少/ 扩展/ 超/ 节点/ 引入/ 的/ 非/ 零元/ 数量/ ,/ 我们/ 对/ 扩展/ 超/ 节点/ 进行/ 分块/ 处理/ ./ 对于/ 不同/ 的/ 分块/ 大小/ ,/ 稀疏/ 矩阵/ 分解/ 因子/ 的/ 存储量/ 和/ 计算/ 时间/ 如表/ 4/ 所示/ ./ 在/ 分块/ 规模/ 为/ 1024/ 时/ ,/ 矩阵/ 分解/ 时间/ 达到/ 最小/ ,/ 因此/ 在/ 接下来/ 的/ 部分/ ,/ 选用/ 1024/ 作为/ 默认/ 分块/ 规模/ ./ 分块/ 规模/ 1024204840965.2/ ./ 3/ 基于/ 流/ 和/ 事件/ 的/ GPU/ 任务/ 并行/ 在/ 前面/ 的/ 实现/ 中/ ,/ GPU/ 任务/ 按照/ 生成/ 的/ 顺序/ 串行/ 执行/ ./ 为了/ 提高/ 算法/ 性能/ ,/ 需要/ 使得/ 满足/ 数据/ 依赖性/ 的/ 多个/ GPU/ 任务/ 能够/ 同时/ 执行/ ./ 通过/ 采用/ 4.3/ 节中/ 介绍/ 的/ 基于/ 流/ 并行/ 以及/ 事件/ 同步/ 的/ 任务调度/ 方法/ ,/ 在/ 不同/ 流/ 数量/ 下/ 的/ 计算/ 时间/ 如表/ 5/ 所示/ ./ 随着/ 流/ 数量/ 的/ 增加/ ,/ 起初/ ,/ 由于/ 任务/ 间/ 的/ 计算/ 重叠/ ,/ 算法/ 分解/ 时间/ 降低/ ;/ 随后/ ,/ 由于/ 流间/ 同步控制/ 的/ 开销/ 随流/ 数量/ 增加/ 而/ 增加/ ,/ 算法/ 分解/ 时间/ 又/ 逐渐/ 回升/ ./ 当流/ 数量/ 为/ 4/ 时/ ,/ 算法/ 分解/ 时间/ 达到/ 最小/ ,/ 因此/ 采用/ 4/ 作为/ 默/ Page9/ 认流/ 数量/ ./ 5.3/ 性能/ 对比/ 在/ 本节/ 中/ ,/ 我们/ 将/ 本文/ 中/ 面向/ GPU/ 的/ 稀疏/ 矩阵/ Cholesky/ 分解/ 算法/ 与/ 面向/ 多核/ CPU/ 平台/ 的/ 并行算法/ 进行/ 了/ 性能/ 对比/ ./ 多核/ CPU/ 并行算法/ 我们/ 选择/ 了/ HSL/ _/ MA87/ [/ 13/ ]/ ./ HSL/ _/ MA87/ 是/ 由/ Hogg/ 开发/ 的/ 稀疏/ 线性方程组/ 求解/ 程序/ ,/ 包含/ 了/ 目前为止/ 多核/ 处理器/ 平台/ 上/ 性能/ 最高/ 的/ 稀疏/ 矩阵/ Cholesky/ 分解/ 算法/ 实现/ ./ HSL/ _/ MA87/ 所有/ 参数/ 使用/ 了/ 默认设置/ ,/ 两种/ 算法/ 的/ 性能/ 对比/ 数据/ 如表/ 6/ 所示/ ./ 矩阵/ 编号/ CPU/ 分解/ 时间/ // sGPU/ 分解/ 时间/ // s/ 加速/ 比/ 1234/ 测试数据/ 表明/ ,/ 与/ 4/ 核/ CPU/ 平台/ 下/ 的/ 并行/ 稀疏/ 矩阵/ Cholesky/ 分解/ 算法/ 相比/ ,/ 面向/ GPU/ 的/ 稀疏/ 矩阵/ Cholesky/ 分解/ 能够/ 达到/ 2.69/ ~/ 3.88/ 倍/ 加速/ 比/ ./ 6/ 结语/ 本文/ 中/ ,/ 我们/ 提出/ 了/ 面向/ GPU/ 的/ 稀疏/ 矩阵/ 数据组织/ 方法/ ./ 通过/ 将/ 稀疏/ 矩阵/ 稀疏/ 结构/ 相似/ 的/ 列/ 合并/ 成超/ 节点/ 后/ 再/ 进行/ 数据/ 分块/ ,/ 使得/ 计算/ 任务/ 处理/ 的/ 对象/ 由列/ 转换/ 为了/ 规则/ 的/ 稠密/ 矩阵/ 数据/ 块/ ./ 通过/ 将/ 矩阵/ 数据/ 存储/ 在/ GPU/ 端/ ,/ 控制数据/ 存储/ 在/ CPU/ 端/ ,/ 减低/ 了/ CPU/ 与/ GPU/ 间/ 的/ 通信/ 开销/ ./ 在/ 扩展/ 超/ 节点/ 分块/ 存储/ 数据结构/ 的/ 基础/ 上/ ,/ 我们/ 将/ 稀疏/ 矩阵/ Cholesky/ 分解/ 过程/ 映射/ 为/ 一系列/ 面向/ 数据/ 块/ 对象/ 的/ 计算/ 任务/ ./ 为了/ 在/ 满足/ 任务/ 数据/ 依赖性/ 的/ 前提/ 下/ 实现/ 任务/ 并行/ 的/ 最大化/ ,/ 我们/ 设计/ 了/ 面向/ GPU/ 的/ 任务/ 生成/ 与/ 调度/ 方法/ ,/ 解决/ 了/ 任务/ 间/ 的/ 并行/ 与/ 互斥/ 问题/ ./ 在/ 此基础/ 上/ ,/ 我们/ 实现/ 了/ 面向/ GPU/ 的/ 稀疏/ 矩阵/ Cholesky/ 分解/ 算法/ ./ 实验/ 表明/ ,/ 该/ 算法/ 能够/ 充分发挥/ GPU/ 的/ 计算能力/ ,/ 获得/ 了/ 相对/ 于/ 单个/ 多核/ 处理器/ 2.69/ ~/ 3.88/ 倍/ 的/ 加速/ 比/ ./ 在/ 接下来/ 的/ 工作/ 中/ ,/ 我们/ 将/ 研究/ 多/ GPU/ 下/ 的/ 数据组织/ 与/ 任务调度/ 算法/ ./ 一方面/ ,/ 研究/ 矩阵/ 稀疏/ 结构/ 和/ 排序/ 算法/ 对/ 任务/ 粒度/ 与/ 并行度/ 的/ 影响/ ;/ 另一方面/ ,/ 研究/ 多个/ CPU/ 与/ 多个/ GPU/ 间/ 的/ 任务/ 并行/ 策略/ ./ 最终/ 我们/ 的/ 目标/ 是/ 实现/ 能够/ 高效/ 运行/ 在/ 由/ 多个/ GPU/ 节点/ 组成/ 的/ 计算/ 阵列/ 上/ 的/ 稀疏/ 矩阵/ 分解/ 算法/ ./ 

