Page1/ 针对/ 高速/ 数据流/ 的/ 大规模/ 数据/ 实时处理/ 方法/ 亓/ 开元/ 1/ )/ ,/ 2/ )/ 赵卓峰/ 1/ )/ ,/ 3/ )/ 房俊/ 1/ )/ ,/ 3/ )/ 马强/ 1/ )/ ,/ 2/ )/ 1/ )/ (/ 中国科学院计算技术研究所/ 北京/ 100190/ )/ 2/ )/ (/ 中国科学院/ 研究生院/ 北京/ 100190/ )/ 3/ )/ (/ 北方工业大学/ 信息/ 工程学院/ 北京/ 100144/ )/ 摘要/ 以/ 实时/ 传感/ 数据/ 和/ 历史/ 感知/ 数据/ 为/ 基础/ 的/ 各类/ 计算/ 需求/ 逐渐/ 成为/ 当前/ 物/ 联网/ 应用/ 建设/ 中/ 的/ 关键/ ,/ 如何/ 实现/ 基于/ 高速/ 数据流/ 和/ 大规模/ 历史数据/ 的/ 实时/ 计算/ 成为/ 数据处理/ 领域/ 的/ 新/ 挑战/ ./ 现有/ 批处理/ 方式/ 的/ MapReduce/ 大规模/ 数据处理/ 技术/ 难以/ 满足/ 此类/ 计算/ 的/ 实时/ 要求/ ./ 文中/ 结合/ 城市/ 车辆/ 数据/ 的/ 实时/ 采集/ 与/ 处理/ 应用/ ,/ 在/ 理论/ 和/ 实践/ 分析/ 的/ 基础/ 上/ ,/ 提出/ 了/ 一种/ 针对/ 高速/ 数据流/ 的/ 大规模/ 数据/ 实时处理/ 方法/ ,/ 并/ 对/ 方法/ 中/ 的/ 本地/ 阶段/ 化/ 流水线/ 、/ 中间/ 结果/ 缓存/ 等/ 关键技术/ 瓶颈/ 进行/ 了/ 改进/ ./ 其中/ ,/ 根据/ 系统/ 参数/ 控制/ 阶段/ 化/ 流水线/ ,/ 使/ CPU/ 得到/ 了/ 充分/ 、/ 有效/ 利用/ ;/ 通过/ 改造/ 内外/ 存/ 数据结构/ 、/ 读写/ 策略/ 和/ 替换算法/ ,/ 优化/ 了/ 本地/ 中间/ 结果/ 的/ 高/ 并发/ 读写/ 性能/ ./ 实验/ 表明/ ,/ 上述/ 方法/ 可以/ 显著/ 提升/ 大规模/ 历史数据/ 上/ 数据流/ 处理/ 的/ 实时性/ 和/ 可伸缩性/ ./ 关键词/ 数据流/ 处理/ ;/ 大规模/ 数据处理/ ;/ MapReduce/ ;/ 物/ 联网/ ;/ 大/ 数据/ ;/ 云/ 计算/ 1/ 引言/ 随着/ 物/ 联网/ 的/ 发展/ ,/ 以/ 实时/ 传感/ 数据/ 为/ 基础/ 的/ 各类/ 数据流/ 处理/ 逐渐/ 成为/ 当前/ 物/ 联网/ 应用/ 构造/ 的/ 关键/ ./ 面对/ 持续/ 到达/ 的/ 数据流/ ,/ 数据流/ 处理/ 系统/ 必须/ 快速/ 对/ 其/ 进行/ 响应/ 并/ 即时/ 输出/ 结果/ ./ 由于/ 数据流/ 的/ 连续性/ 和/ 无限性/ ,/ 有限/ 的/ 处理机/ 不/ 可能/ 处理/ 数据流/ 的/ 完整/ 信息/ ,/ 因而/ 采用/ 窗口/ 机制/ (/ 时间/ 、/ 数据量/ )/ 来/ 划定/ 处理/ 边界/ ,/ 窗口/ 边界/ 范围/ 内/ 已/ 积累/ 的/ 数据/ 称之为/ 历史数据/ ./ 传统/ 数据流/ 处理/ [/ 1/ -/ 3/ ]/ 受/ 数据/ 采集/ 速度/ 、/ 传输/ 带宽/ 和/ 内存容量/ 等/ 因素/ 的/ 限制/ ,/ 侧重于/ 针对/ 一个/ 相对/ 小/ 的/ 历史数据/ 规模/ 进行/ ./ 随着/ 数据/ 采集/ 和/ 传输技术/ 的/ 进步/ ,/ 使得/ 短时间/ 内/ 积累/ 大量/ 历史数据/ 成为/ 可能/ ./ 同时/ ,/ 当前/ 物/ 联网/ 环境/ 下/ 数据流/ 处理/ 应用/ 的/ 长期性/ 、/ 全面性/ 和/ 准确性/ 需求/ 也/ 要求/ 扩大/ 历史数据/ 规模/ ./ 以/ 一个/ 物/ 联网/ 环境/ 下/ 的/ 车辆/ 监管/ 应用/ 为例/ ./ 该/ 应用/ 通过/ 传感/ 设备/ 对/ 城市/ 车辆/ 实时/ 数据/ (/ 包括/ 道路/ 运行/ 车辆/ 和/ 停车场/ 静止/ 车辆/ )/ 进行/ 收集/ ,/ 并/ 在/ 已/ 收集/ 数据/ 的/ 基础/ 上/ 进行/ 套牌/ 、/ 超速/ 、/ 限行/ 等/ 多种/ 违法/ 车辆/ 的/ 自动识别/ 计算/ ./ 应用/ 面对/ 的/ 数据/ 一方面/ 是/ 高速/ 到达/ 的/ 数据流/ ,/ 另一方面/ 是/ 持久/ 化/ 的/ 历史数据/ ,/ 要求/ 实时/ 的/ 完成/ 数据流/ 同/ 历史数据/ 的/ 分析/ 、/ 比较/ 等/ 计算/ ./ 类似/ 的/ 应用/ 还/ 包括/ 网络/ 入侵/ 检测/ 、/ Web/ 个性化/ 搜索/ 等/ ./ 在/ 这类/ 应用/ 中/ ,/ 由于/ 窗口/ 范围/ 的/ 不断/ 变/ 大/ ,/ 数据处理/ 对象/ (/ 如/ 车牌/ )/ 数量/ 的/ 急速/ 增加/ ,/ 以及/ 每个/ 数据/ 对象/ 数据量/ (/ 如/ 车辆/ 监控/ 信息/ )/ 的/ 迅速/ 增加/ ,/ 造成/ 了/ 历史数据/ 规模/ 不断扩大/ ./ 在/ 上述/ 趋势/ 下/ ,/ 面向/ 大规模/ 历史数据/ 的/ 数据流/ 实时处理/ 需求/ 同/ 计算/ 、/ 存储/ 能力/ 不足/ 之间/ 的/ 矛盾/ 成为/ 云/ 计算/ 和物/ 联网/ 领域/ 的/ 新/ 挑战/ ./ 本文/ 将/ 此/ 问题/ 定义/ 为/ 数据流/ 处理/ 的/ 可伸缩性/ 问题/ ./ 现有/ 数据流/ 处理/ 的/ 可伸缩性/ 研究/ 可/ 分为/ 集中式/ 和/ 分布式/ 两类/ ./ 在/ 集中式/ 环境/ 下/ ,/ 受/ 计算/ 和/ 存储/ (/ 主要/ 是/ 内存/ )/ 资源/ 限制/ ,/ 主要/ 通过/ 概要/ 数据/ [/ 4/ ]/ 、/ 准入/ 控制/ [/ 1/ ]/ 、/ QoS/ 降阶/ [/ 2/ ]/ 等/ 方法/ ,/ 以/ 牺牲/ 服务质量/ 为/ 代价/ 保障/ 伸缩性/ ./ 在/ 分布式/ 环境/ 下/ ,/ 针对/ 由/ 多个/ 处理/ 算子/ 组成/ 的/ 数据流/ 处理/ 网络/ ,/ 主要/ 通过/ 在/ 多个/ 节点/ 上/ 平衡/ 算子/ 的/ 分布/ 来/ 保障/ 伸缩性/ [/ 2/ -/ 3/ ]/ ,/ 但/ 处理/ 能力/ 仍/ 局限于/ 单个/ 算子/ 所在/ 节点/ 所/ 能/ 处理/ 的/ 数据/ 窗口/ ,/ 在/ 面对/ 大规模/ 历史数据/ 的/ 情况/ 下/ 伸缩/ 能力/ 不足/ ./ 面向/ 大规模/ 历史数据/ 的/ 数据流/ 处理/ 需要/ 突破/ 单个/ 节点/ 的/ 内存/ 和/ 计算能力/ 限制/ ./ 计算/ 、/ 存储设备/ 性能/ 的/ 提高/ 、/ 成本/ 的/ 降低/ 和/ 大规模/ 数据处理/ 技术/ 的/ 不断/ 成熟/ ,/ 为/ 采用/ 无/ 共享/ 集群/ 架构/ 解决/ 此类/ 数据处理/ 问题/ 创造/ 了/ 条件/ ./ 为了/ 支撑/ 大规模/ 数据/ 的/ 存储/ 和/ 计算/ ,/ 当前/ 往往/ 采用/ 具有/ 多个/ CPU/ 的/ 多/ 核/ 集群/ 计算/ 架构/ ,/ 以及/ Cache/ 、/ 内存/ 、/ 外存/ 和/ 分布式/ 存储/ 四层/ 存储/ 结构/ ,/ 如图/ 1/ ./ 在/ 这种/ 架构/ 中/ ,/ 节点/ 上/ 的/ 多/ 核/ CPU/ 构成/ 了/ 本地/ 计算资源/ ;/ 相比/ 于/ 分布式/ 存储/ ,/ 节点/ 上/ 的/ 内存/ 和/ 外存/ 组成/ 了/ 高速/ 的/ 本地/ 存储/ ./ 在/ 无/ 共享/ 集群/ 架构/ 下/ ,/ 利用/ MapReduce/ [/ 5/ ]/ 编程/ 模型/ 解决/ 大规模/ 数据处理/ 需求/ 同/ 计算/ 、/ 存储/ 能力/ 不足/ 之间/ 的/ 矛盾/ 是/ 云/ 计算/ 的/ 核心技术/ ,/ MapReduce/ 通过/ 简单/ 的/ 编程/ 接口/ 为/ 并行处理/ 可/ 划分/ 的/ 大规模/ 数据/ 提供/ 了/ 支持/ ,/ 向/ 程序员/ 屏蔽/ 了/ 任务调度/ 、/ 数据/ 存储/ 和/ 传输/ 等/ 细节/ ,/ 非常适合/ 解决/ 数据处理/ 问题/ 的/ 伸缩性/ 需求/ ./ 然而/ ,/ 现有/ 的/ MapReduce/ 方法/ ,/ 如/ Hadoop/ ①/ 、/ Phoenix/ [/ 6/ ]/ 等/ ,/ 属于/ 对/ 持久/ 化/ 数据/ 的/ 批处理/ 方式/ ,/ 在/ 每次/ 处理/ 时/ ,/ 都/ 需要/ 初始化/ 运行/ 环境/ ,/ 重复/ 载入/ 、/ 处理/ 大规模/ 数据/ ,/ 同步/ 执行/ Map/ 和/ Reduce/ 阶段/ ,/ 并/ 在/ 节点/ 间/ 传递/ 大量/ 数据/ ./ 以/ 批处理/ 方式/ 处理/ 持续/ 到达/ 的/ 数据流/ ,/ 若/ 每次/ 处理/ 小规模/ 批/ 的/ 数据/ ,/ 则/ 系统/ 开销/ 太/ 大/ ,/ 实时性/ 受到限制/ ,/ 若/ 等待/ 批/ 达到/ 一定/ 规模/ 又/ 增加/ 了/ 处理/ 延迟/ ,/ 同样/ 无法/ 满足/ 实时/ 需求/ ./ 因此/ ,/ 针对/ 高速数据/ 流下/ 的/ 大规模/ 数据/ 实时处理/ 需求/ ,/ 如何/ 利用/ MapReduce/ 模型/ 是/ 需要/ 考虑/ 的/ 问题/ ./ 为/ 增强/ MapReduce/ 的/ 数据流/ 处理/ 能力/ ,/ 可以/ 通过/ 预处理/ 、/ 分布/ 缓存/ 和/ 复用/ 中间/ 结果/ 的/ 方法/ 避免/ 每次/ 数据流/ 到达/ 时/ 的/ 历史数据/ 重复/ 处理/ 开销/ ,/ 并/ 使得/ 数据流/ 处理/ 本地化/ ,/ 减少/ 节点/ 间/ 的/ 数据传输/ 开销/ ./ 针对/ 本地化/ 的/ 数据流/ 处理/ ,/ 可以/ 采用/ 事件驱动/ 的/ 阶段/ 化/ 处理/ 架构/ [/ 7/ ]/ (/ StagedEventDrivenArchitecture/ ,/ ①/ ApacheHadoop/ [/ EB/ // OL/ ]/ ./ http/ :/ // // hadoop/ ./ apache/ ./ org/ // Page3SEDA/ )/ ,/ 利用/ 线程/ 池/ 技术/ 减少/ 每次/ 处理/ 的/ 初始化/ 开销/ ,/ 并/ 通过/ 划分/ 阶段/ 和/ 在/ 阶段/ 间/ 异步/ 传递数据/ ,/ 消除/ 阶段/ 之间/ 的/ 数据/ 同步/ ./ 基于/ 以上/ 思想/ ,/ 本文/ 首先/ 通过/ 理论/ 和/ 实践/ 分析/ 证明/ 了/ 采用/ MapReduce/ 模型/ 解决/ 此类/ 问题/ 的/ 适应性/ ,/ 并/ 在/ 此基础/ 上/ 提出/ 了/ 一种/ 支持/ 高速数据/ 流下/ 大规模/ 数据/ 实时处理/ 的/ 方法/ RTMR/ (/ Real/ -/ TimeMapReduce/ )/ ./ RTMR/ 的/ 处理过程/ 为/ 预处理/ 历史数据/ 并/ 将/ 中间/ 结果/ 分布/ 缓存/ 到/ 各个/ 节点/ 上/ ,/ 在/ 节点/ 上/ 基于/ SEDA/ 构造/ 从/ Map/ 阶段/ 到/ Reduce/ 阶段/ 的/ 本地/ 阶段/ 化/ 流水线/ ,/ 充分利用/ 本地/ 计算/ 和/ 存储资源/ 实现/ 数据流/ 同/ 历史数据/ 的/ 实时/ 计算/ ./ 在/ 上述/ 方法/ 中/ ,/ 还/ 存在/ 以下/ 挑战性/ 问题/ :/ (/ 1/ )/ Esper/ ①/ 公布/ 的/ 数据/ 表明/ ,/ CPU/ 是/ 影响/ 数据流/ 处理/ 性能/ 的/ 关键/ 资源/ ./ 在/ 大规模/ 历史数据/ 情况/ 下/ ,/ 计算/ 量/ 骤增/ ,/ 使得/ 有效/ 利用/ CPU/ 更为重要/ ./ 因此/ ,/ 如何/ 充分/ 、/ 有效/ 地/ 利用/ CPU/ (/ 包括/ CPUCache/ )/ 提高/ 实时处理/ 能力/ ,/ 是/ 本地/ 阶段/ 化/ 处理/ 面临/ 的/ 关键问题/ ./ (/ 2/ )/ 在/ 本地/ 阶段/ 化/ 架构/ 下/ ,/ 针对/ Map/ 和/ Reduce/ 线程/ 对/ 中间/ 结果/ 的/ 频繁/ 读写/ ,/ 应该/ 如何/ 支持/ 对/ 中间/ 结果/ 本地/ 存储/ 的/ 高/ 并发/ 访问/ 也/ 是/ 需要/ 解决/ 的/ 问题/ ./ 针对/ 上述/ 问题/ ,/ RTMR/ 方法/ 包括/ 了/ 一种/ 基于/ 系统/ 参数/ 的/ 本地/ 阶段/ 化/ 处理/ 优化/ 方法/ 和/ 支持/ 高/ 并发/ 读写/ 的/ 本地/ 存储/ 方法/ ./ 2/ 针对/ 高速/ 数据流/ 的/ 大规模/ 数据/ 实时处理/ 方法/ 批处理/ 方式/ 的/ MapReduce/ 无法/ 满足/ 物/ 联网/ 环境/ 下/ 数据流/ 的/ 实时处理/ 需求/ ./ 本节/ 在/ 理论/ 和/ 实践/ 分析/ 的/ 基础/ 上/ ,/ 基于/ MapReduce/ 模型/ 提出/ 了/ 支持/ 高速数据/ 流下/ 大规模/ 数据/ 实时处理/ 的/ 方法/ RTMR/ ./ 2.1/ RTMR/ 方法/ MapReduce/ 模型/ 的/ 定义/ [/ 5/ ]/ 为/ 其/ 处理过程/ 是/ ,/ Map/ 方法/ 将/ [/ k1/ ,/ v1/ ]/ 键值/ 对/ 转换/ 为/ [/ k2/ ,/ v2/ ]/ 键值/ 对/ ,/ Reduce/ 方法/ 针对/ 每个/ k2/ 的/ 值/ 列表/ list/ (/ v2/ )/ 做/ list/ 操作/ ./ 将/ 上述/ 模型/ 改造/ 为/ 函数/ 形式/ ,/ 若/ 待处理/ 数据/ 为/ D/ ,/ Map/ 阶段/ 中间/ 结果/ 为/ I/ ,/ MapReduce/ 过程/ 可以/ 表示/ 为/ 其中/ ,/ M/ 表示/ Map/ 方法/ ,/ R/ 表示/ Reduce/ 方法/ ,/ list/ 表示/ Reduce/ 方法/ 所/ 做/ 的/ 操作/ ./ 下面/ 分析/ MapRe/ -/ duce/ 模型/ 的/ 性质/ ./ 定义/ 1/ ./ 对于/ 函数/ F/ :/ I/ →/ O/ ,/ 若/ 存在/ 函数/ P/ :/ O/ ×/ O/ →/ O/ ,/ 使得/ F/ (/ D/ +/ Δ/ )/ =/ P/ (/ F/ (/ D/ )/ ,/ F/ (/ Δ/ )/ )/ ,/ 则/ 称/ F/ 为/ 可/ 合并/ 的/ ./ 定义/ 2/ ./ 对于/ 数据/ 集/ D/ 的/ n/ 个/ 数据/ 子集/ D1/ ,/ D2/ ,/ …/ ,/ Dn/ ,/ 若/ D1/ ∩/ D2/ ∩/ …/ ∩/ Dn/ =/ / 并且/ D1/ ∪/ D2/ ∪/ …/ ∪/ Dn/ =/ D/ ,/ 则/ 称/ D1/ ,/ D2/ ,/ …/ ,/ Dn/ 为/ D/ 上/ 的/ 一个/ 划分/ ./ 定义/ 3/ ./ 对于/ 键值/ 对/ 数据/ 集合/ D/ ,/ 键/ 集合/ K/ ,/ 称/ 集合/ {/ d/ |/ d/ ./ key/ ∈/ K/ ,/ d/ ∈/ D/ }/ 为/ D/ 在/ K/ 上/ 的/ 投影/ ,/ 记/ 为/ σ/ K/ (/ D/ )/ ./ 由/ MapReduce/ 模型/ 和/ 上述/ 定义/ 可知/ ,/ MapReduce/ 具有/ 以下/ 性质/ :/ (/ 1/ )/ Map/ 方法/ 满足/ 分配率/ ./ 即/ 两个/ 数据/ 集合/ 并/ 集上/ 的/ Map/ 等于/ 分别/ 对/ 两个/ 集合/ Map/ 的/ 并/ 集/ (/ 2/ )/ Reduce/ 方法/ 具有/ 可/ 合并/ 性/ ./ 即/ (/ 3/ )/ Reduce/ 方法/ 满足/ 分配率/ ,/ 即/ 若/ K1/ ,/ K2/ ,/ …/ ,/ Kn/ 为/ 中间/ 结果/ I/ 键/ 集合/ 的/ 一个/ 划分/ ,/ 则/ list/ (/ I/ )/ =/ list/ (/ σ/ K1/ (/ I/ )/ )/ +/ list/ (/ σ/ K2/ (/ I/ )/ )/ +/ …/ +/ list/ (/ σ/ Kn/ (/ I/ )/ )/ ./ 定理/ 1/ ./ MapReduce/ 为/ 可/ 合并/ 的/ ./ 证明/ ./ 根据/ MapReduce/ 的/ 性质/ ,/ 对于/ 数据/ D/ 和/ 增量/ Δ/ 有/ 因此/ ,/ 由/ 定义/ 1/ 可知/ MapReduce/ 是/ 可/ 合并/ 的/ ./ 定理/ 1/ 表明/ MapReduce/ 模型/ 可/ 通过/ 预处理/ 历史数据/ 并/ 缓存/ 中间/ 结果/ 的/ 方法/ 降低/ 每次/ 数据流/ 到达/ 时/ 的/ 重复/ 处理/ 开销/ ,/ 提高/ 实时处理/ 能力/ ./ 将/ 上述/ 过程/ 用/ 函数/ 表示/ 为/ MR/ (/ D/ +/ Δ/ )/ =/ list/ (/ ID/ +/ I/ Δ/ )/ =/ MR/ (/ Δ/ |/ ID/ )/ ./ 定理/ 2/ ./ K1/ ,/ K2/ ,/ …/ ,/ Kn/ 为/ MapReduce/ 中间/ 结果/ I/ 键/ 集合/ 的/ 一个/ 划分/ ,/ 对于/ 数据/ 增量/ Δ/ 在/ I/ 上/ 的/ MapReduce/ ,/ 有/ MR/ (/ Δ/ |/ I/ )/ =/ MR/ (/ Δ/ |/ σ/ K1/ (/ I/ )/ )/ +/ MR/ (/ Δ/ |/ σ/ K2/ (/ I/ )/ )/ +/ …/ +/ ①/ Esperperformance/ [/ EB/ // OL/ ]/ ./ http/ :/ // // docs/ ./ codehaus/ ./ org/ // Page4/ 证明/ ./ 由/ MapReduce/ 的/ 性质/ ,/ 对于/ 中间/ 结果/ I/ 和/ 数据/ 增量/ Δ/ ,/ 有/ MR/ (/ Δ/ |/ I/ )/ =/ list/ (/ I/ +/ I/ Δ/ )/ =/ list/ (/ σ/ K1/ (/ I/ +/ I/ Δ/ )/ )/ +/ list/ (/ σ/ K2/ (/ I/ +/ I/ Δ/ )/ )/ +/ …/ +/ list/ (/ σ/ Kn/ (/ I/ +/ I/ Δ/ )/ )/ ./ 对于/ Reduce/ 方法/ 来说/ ,/ 在/ 中间/ 结果/ 的/ K1/ 投影/ 上/ 处理/ 的/ 数据/ 增量/ 仅/ 与/ K1/ 有关/ ,/ 即/ MR/ (/ Δ/ |/ σ/ K1/ (/ I/ )/ )/ =/ list/ (/ I/ Δ/ +/ σ/ K1/ (/ I/ )/ )/ 同理/ ,/ =/ list/ (/ σ/ K1/ (/ I/ Δ/ +/ σ/ K1/ (/ I/ )/ )/ )/ =/ list/ (/ σ/ K1/ (/ I/ Δ/ +/ I/ )/ )/ ./ 因此/ ,/ MR/ (/ Δ/ |/ I/ )/ =/ MR/ (/ Δ/ |/ σ/ K1/ (/ I/ )/ )/ +/ MR/ (/ Δ/ |/ σ/ K2/ (/ I/ )/ )/ +/ …/ +/ 定理/ 2/ 表明/ MapReduce/ 模型/ 通过/ 分布/ 缓存/ 中间/ 结果/ ,/ 可以/ 使/ 数据流/ 同/ 中间/ 结果/ 的/ 计算/ 仅/ 发生/ 在/ 节点/ 本地/ ./ 由于/ 避免/ 了/ 节点/ 间/ 的/ 数据传输/ ,/ 因此/ 合理/ 的/ 分布/ 中间/ 结果/ 能够/ 保障/ 整个/ 架构/ 的/ 可伸缩性/ ./ 从/ 实践/ 角度/ ,/ 以/ 套牌车/ 计算/ 为例/ ,/ 在/ 2.93/ GHzCPU/ ,/ 2GB/ 内存/ 和/ 1Gbps/ 以太网/ 连接/ 的/ 服务器/ 集群/ 上/ 处理/ 数据流/ ,/ 在/ 已有/ 100MB/ 历史数据/ 的/ 情况/ 下/ ,/ 针对/ 每条/ 200B/ 的/ 数据流/ ,/ 从/ 接收/ 到/ 完成/ Hash/ 分组/ 操作/ 的/ 平均/ 耗时/ 是/ 4/ (/ ±/ 0.5/ μ/ s/ )/ ,/ 完成/ 数据流/ 同/ 历史数据/ 之间/ 比较/ 操作/ 的/ 平均/ 耗时/ 是/ 1/ (/ ±/ 0.2/ ms/ )/ ,/ 在/ 服务器之间/ 完成/ 数据传输/ 的/ 平均/ 延迟/ 为/ 40/ (/ ±/ 4/ μ/ s/ )/ ./ 上述/ 实验/ 数据/ 表明/ 一颗/ 2.93/ GHzCPU/ 能够/ 以/ 超过/ 50MB/ // s/ 的/ 速度/ 接收/ 和/ 分组/ 数据流/ ,/ 而/ 在/ 实际/ 应用/ 中/ ,/ 受/ 采集/ 端/ 带宽/ 等/ 限制/ ,/ 数据流/ 远达/ 不到/ 这个/ 速度/ ./ 因此/ ,/ 对于/ 多核/ 系统/ ,/ 接收/ 和/ 分组/ 数据流/ (/ Map/ 阶段/ )/ 只/ 需/ 占用/ 很少/ 一部分/ CPU/ 资源/ ,/ 是/ 套牌/ 计算/ 这/ 类/ 应用/ 所/ 要/ 面对/ 的/ 次要矛盾/ ,/ 主要矛盾/ 是/ 数据流/ 同/ 大规模/ 数据/ 之间/ 的/ 统计/ 、/ 比较/ 等/ 计算/ (/ Reduce/ 阶段/ )/ 以及/ 节点/ 之间/ 的/ 数据传输/ ./ 为了/ 降低/ 处理/ 主要矛盾/ 的/ 系统/ 开销/ ,/ 也/ 就是/ 减少/ 历史数据/ 重复/ 处理/ 和/ 避免/ 节点/ 间/ 数据传输/ ,/ 可以/ 采用/ 前述/ 理论/ 分析/ 论证/ 的/ 技术/ 路线/ :/ 将/ 预处理/ 的/ 历史数据/ 中间/ 结果/ 分布/ 缓存/ 于/ 各/ 节点/ ;/ 每个/ 节点/ 冗余/ 地/ 接收/ 数据流/ ,/ 通过/ Map/ 阶段/ 过滤/ 出本/ 节点/ 负责/ 处理/ 的/ 数据/ 并/ 在/ 本地/ 缓存/ 上/ 进行/ Reduce/ 计算/ ./ 当/ 已有/ 节点/ 的/ 本地/ 计算/ 和/ 存储资源/ 不能/ 满足/ 实时性/ 需求/ 时/ ,/ 可以/ 在/ 新增/ 节点/ 上/ 通过/ 重新/ 划分/ 和/ 移动/ 缓存数据/ 进行/ 扩展/ ./ 有鉴于此/ ,/ 我们/ 设计/ 了/ 大规模/ 历史数据/ 上/ 的/ 数据流/ 处理/ 方法/ RTMR/ ,/ 如图/ 2/ ./ RTMR/ 的/ 工作/ 过程/ 如下/ ./ 过程/ 1/ ./ RTMR/ 过程/ ./ 1/ ./ 中间/ 结果/ 缓存/ ./ 预处理/ 相关/ 历史数据/ 生成/ 中间/ 结果/ ,/ 根据/ k2/ 的/ Hash/ 值/ 划分/ 区间/ ,/ 分布/ 缓存/ 到/ 各个/ 工作/ 节点/ 的/ 本地/ 存储/ 上/ ./ 2/ ./ 本地/ 阶段/ 化/ 处理/ ./ Map/ 阶段/ 通过/ 作用/ 于/ k2/ 的/ Hash/ 函数/ 分组/ 数据流/ ,/ 并/ 按照/ 区间/ 划分/ 过滤/ 出/ 与/ 本地/ 中间/ 结果/ 相关/ 的/ 数据/ ,/ 异步/ 的/ 传递/ 给/ Reduce/ 阶段/ 进行/ 与/ 中间/ 结果/ 的/ 计算/ ./ 3/ ./ 数据/ 同步/ ./ 将/ 本地/ 计算结果/ 同步/ 到/ 分布式/ 存储/ ./ 在/ RTMR/ 方法/ 中/ ,/ 工作/ 节点/ 负责/ 维护/ 本地/ 中间/ 结果/ 缓存/ 和/ 阶段/ 化/ 流水线/ ./ 控制/ 节点/ 负责/ RTMR/ 任务/ 的/ 生命周期/ 管理/ 、/ 可靠性/ 和/ 可伸缩性/ 保障/ ./ 本文/ 主要/ 对/ 中间/ 结果/ 本地/ 存储/ 、/ 本地/ 阶段/ 化/ 流水线/ 等/ 技术/ 进行/ 讨论/ ,/ 对于/ 在/ 控制/ 节点/ 中/ 需要/ 解决/ 的/ 关键问题/ ,/ 将/ 在/ 后续/ 工作/ 介绍/ ./ 2.2/ 编程/ 接口/ 根据/ RTMR/ 的/ 处理过程/ ,/ RTMR/ 编程/ 接口/ 除/ map/ 和/ reduce/ 方法/ 外/ ,/ 还/ 包括/ 预/ 加载/ 方法/ load/ 和/ 数据/ 同步/ 方法/ update/ ,/ 如/ 代码/ 1/ ./ load/ 方法/ 默认/ 以/ map/ 和/ reduce/ 方法/ 预处理/ 相关/ 持久/ 化/ 历史数据/ 生成/ 中间/ 结果/ ,/ 程序员/ 还/ 可以/ 在/ load/ 方法/ 中/ 实现/ 其他/ 相关/ 数据/ 的/ 预/ 加载/ ,/ 如/ 车辆/ 监管/ 应用/ 中/ 的/ 套牌/ 阈值/ 、/ 布控/ 黑名单/ 列表/ 等/ ./ update/ 默认/ 将/ 中间/ 结果/ 同步/ 到/ 分布式/ 存储/ ,/ 为了/ 增强/ 适应性/ ,/ RTMR/ 支持/ 定时/ 和/ 即时/ 两种/ 同步/ 机制/ ./ Page5/ 代码/ 1/ ./ RTMR/ 编程/ 接口/ ./ publicclassFakeLicenseCarJobimplementsJob/ {/ publicvoidload/ (/ )/ {/ …/ }/ publicvoidupdate/ (/ )/ {/ …/ }/ publicstaticclassFakeLicenseCarMapTaskimplementsMapTask/ {/ publicvoidmap/ (/ )/ {/ …/ }/ }/ publicstaticclassFakeLicenseCarReduceTaskimplementsReduceTask/ {/ publicvoidreduce/ (/ )/ {/ …/ }/ }/ }/ 3/ 支持/ 高/ 并发/ 读写/ 的/ 中间/ 结果/ 本地/ 存储/ 为/ 减少/ 每次/ 数据流/ 到达/ 时/ 的/ 历史数据/ 重复/ 计算/ 开销/ ,/ RTMR/ 支持/ 中间/ 结果/ 缓存/ ./ 在/ 本地/ 阶段/ 化/ 架构/ 下/ ,/ Map/ 和/ Reduce/ 工作/ 线程/ 将/ 对/ 中间/ 结果/ 频繁/ 地/ 进行/ 读写/ ,/ 优化/ 中间/ 结果/ 的/ 高/ 并发/ 读写/ 性能/ 是/ 提高/ 数据流/ 处理/ 能力/ 的/ 关键/ ./ 本节/ 在/ 介绍/ 中间/ 结果/ 内存/ 数据结构/ 和/ 外存/ 文件/ 结构/ 基础/ 上/ ,/ 提出/ 了/ 一种/ 支持/ 高/ 并发/ 读写/ 的/ 本地/ 存储/ 优化/ 方法/ ./ 3.1/ 中间/ 结果/ 存储/ 结构/ 定义/ 4/ ./ 在/ MapReduce/ 模型/ 中/ ,/ 将/ [/ k2/ ,/ list/ (/ v2/ )/ ]/ 以及/ list/ (/ v2/ )/ 称为/ 中间/ 结果/ ./ 借鉴/ Metis/ [/ 8/ ]/ 的/ 思路/ ,/ 中间/ 结果/ 在/ 内存/ 中/ 采用/ HashB/ +/ 树结构/ 存储/ ,/ 如图/ 3/ ./ 在/ 这种/ 结构/ 中/ ,/ 具有/ 相同/ Hash/ 值/ 的/ k2/ 在/ Hash/ 表/ 的/ 同/ 一项/ 中用/ B/ +/ 树/ 组织/ ,/ [/ k2/ ,/ list/ (/ v2/ )/ ]/ 在/ B/ +/ 树/ 的/ 叶/ 节点/ 用/ 链表/ 组织/ ,/ list/ (/ v2/ )/ 存储/ 在/ B/ +/ 树/ 的/ 叶/ 节点/ ./ HashB/ +/ 树结构/ 具有/ 很/ 高/ 的/ 读写/ 性能/ ./ 如果/ k2/ 可/ 预测/ 并且/ 具有/ 唯一/ 的/ Hash/ 值/ ,/ 则/ 可以/ 通过/ 为/ Hash/ 表/ 分配/ 足够/ 的/ 项来/ 避免/ 冲突/ 和/ B/ +/ 树/ 查找/ ,/ 插入/ 和/ 查找/ 操作/ 都/ 只有/ O/ (/ 1/ )/ 的/ 复杂度/ ./ 如果/ k2/ 没有/ 唯一/ 的/ Hash/ 值/ 或/ 不可/ 预测/ ,/ 则/ 在/ Hash/ 表项/ 中/ 维护/ 一个/ B/ +/ 树/ ,/ 插入/ 和/ 查找/ 操作/ 也/ 只有/ O/ (/ 1/ )/ +/ O/ (/ logn/ )/ 的/ 复杂度/ ./ 为了/ 扩大/ 中间/ 结果/ 的/ 本地/ 存储容量/ ,/ 在/ 外存/ 构造/ SSTable/ 文件/ [/ 9/ ]/ 存储/ 中间/ 结果/ ./ SSTable/ 文件/ 结构/ 包括/ 一个/ 索引/ 块/ 和/ 多个/ 64KB/ 的/ 数据/ 块/ (/ 如图/ 4/ )/ ,/ 以块/ 为/ 单位/ 为/ Hash/ 表项/ 分配/ 外存/ 空间/ ./ 在/ 数据流/ 处理过程/ 中/ ,/ 如果/ 所/ 需/ 的/ 中间/ 结果/ Hash/ 表项/ 不/ 在/ 内存/ 而/ 在/ 外存/ 并且/ 内存/ 已/ 无/ 空间/ ,/ 将/ 发生/ 内外/ 存/ 替换/ ./ 针对/ 大规模/ 的/ 历史数据/ ,/ 为/ 在/ 集群/ 环境/ 下/ 保障/ 可/ 伸缩/ ,/ RTMR/ 为/ 工作/ 节点/ 划分/ 其所/ 负责/ 的/ 中间/ 结果/ Hash/ 区间/ ./ 如图/ 5/ 所示/ ,/ k2/ 的/ Hash/ 区间/ 分布/ 在/ n/ 个/ 工作/ 节点/ 上/ (/ P1/ ,/ P2/ ,/ …/ ,/ Pn/ )/ ./ 由/ RTMR/ 过程/ 可知/ ,/ Map/ 阶段/ 包括/ 一个/ 对于/ k2/ 的/ Hash/ 分组/ 操作/ ,/ 每个/ 节点/ 只/ 负责/ 区间/ 内/ 数据流/ 的/ 处理/ ./ 如果/ Hash/ 区间/ 划分/ 采用/ 对/ 节点/ 数取/ 余/ 的/ 方法/ ,/ 那么/ 在/ 伸缩/ 时/ (/ 增减/ 节点/ )/ 会/ 引发/ 大量/ 数据/ 的/ 移动/ ./ 为了/ 减少/ 伸缩/ 时/ 的/ 数据/ 移动/ 规模/ ,/ RTMR/ 采用/ 一致性/ Hash/ 算法/ [/ 10/ ]/ 在/ 节点/ 上/ 划分/ 中间/ 结果/ ./ 例如/ ,/ 原有/ P1/ 、/ P2/ 和/ P33/ 个/ 分区/ ,/ 当/ 增加/ 一个/ 节点/ 时/ ,/ 只/ 需要/ 将/ P1/ 和/ P3/ 的/ 一部分/ 划分/ 为/ P4/ 即可/ ,/ 如图/ 6/ ./ 在/ 上述/ 存储/ 结构/ 基础/ 上/ ,/ 阶段/ 化/ 流水线/ 中/ Map/ 和/ Reduce/ 线程/ 对/ 中间/ 结果/ 内存/ 结构/ 的/ 并发/ 读写/ 同步/ ,/ 以及/ 对/ 中间/ 结果/ 外存/ 文件/ 的/ 并发/ 读写/ 开销/ 制约/ Page6/ 了/ 数据流/ 实时处理/ 能力/ ./ 为了/ 提高/ 本地/ 中间/ 结果/ 的/ 并发/ 读写/ 性能/ ,/ 还/ 应从/ 两/ 方面/ 进行/ 考虑/ :/ (/ 1/ )/ 建立/ 内存/ 缓冲区/ 减少/ 并发/ 线程/ 之间/ 的/ 同步/ ;/ (/ 2/ )/ 改造/ 外存/ 文件/ 读写/ 策略/ 和/ 替换算法/ 降低/ 外存/ 的/ 并发/ 读写/ 开销/ ./ 3.2/ 内存/ 缓冲区/ 由/ 上节/ 可知/ ,/ 工作/ 节点/ 在/ 内存/ 中/ 维护/ HashB/ +/ 树/ 存放/ 中间/ 结果/ ./ 在/ 本地/ 阶段/ 化/ 架构/ 下/ ,/ Map/ 和/ Reduce/ 线程/ 都/ 会/ 对/ 中间/ 结果/ 频繁/ 地/ 进行/ 读写/ ,/ Map/ 线程/ 写入/ 处理结果/ ,/ Reduce/ 线程/ 读取/ Map/ 结果/ ,/ 处理/ 图/ 7/ 本地/ 存储/ 结构/ 3.3/ 外存/ 读写/ 策略/ 现有/ 基于/ SSTable/ 结构/ 的/ 文件/ 读写/ 策略/ 是/ 写/ 优化/ 的/ ,/ 如/ BigTable/ [/ 9/ ]/ 在/ 将/ 内存/ 缓存数据/ 写/ (/ dump/ )/ 到/ 磁盘/ 时/ 采用/ 直接/ 写入/ 一个/ 新/ 文件/ 的/ 追加/ 写/ (/ minorcompaction/ )/ 方式/ ,/ 而/ 在读/ 时/ 需要/ 将/ 缓存数据/ 和/ 若干个/ 小/ 文件/ 进行/ 合并/ (/ mergecompaction/ )/ ,/ 开销/ 较大/ ./ 对于/ 中间/ 结果/ 本地/ 存储/ 文件/ 来说/ ,/ 读写操作/ 都/ 比较/ 频繁/ 并且/ 比例/ 均衡/ ,/ 不能/ 盲目/ 地/ 只/ 优化/ 写/ 操作/ ./ 为/ 提高/ 并发/ 读写/ 性能/ ,/ 可以/ 根据/ 开销/ 选择/ 读写/ 方式/ ./ 下面/ 给出/ 各种/ 读写/ 开销/ 的/ 估算/ 方法/ ./ 后/ 写入/ 或/ 更新/ 中间/ 结果/ ./ 因此/ ,/ 为了/ 提高/ 内存/ 并发/ 读写/ 性能/ ,/ 关键/ 是/ 减少/ Map/ 和/ Reduce/ 工作/ 线程/ 之间/ 对/ 同一/ 块内存/ 区域/ 的/ 并发/ 读写/ 同步/ 开销/ ./ 通过/ 建立/ Map/ 和/ Reduce/ 阶段/ 之间/ 的/ 缓冲区/ 能够/ 避免/ 对/ 中间/ 结果/ 的/ 读写/ 同步/ ./ 为了/ 避免/ 多个/ Map/ 线程/ 之间/ 对/ 缓冲区/ 的/ 写/ 同步/ ,/ 每个/ Map/ 线程/ 独占/ 一个/ 缓冲区/ ./ 为了/ 避免/ Map/ 和/ Reduce/ 线程/ 之间/ 对/ 缓冲区/ 的/ 读写/ 同步/ ,/ 缓冲区/ 设计/ 成/ 一个/ FIFO/ 队列/ ,/ Map/ 线程/ 向/ 队列/ 尾部/ 写入/ ,/ Reduce/ 线程/ 从/ 队列/ 头部/ 读出/ ./ 根据/ Reduce/ 的/ 分配率/ ,/ 每个/ Reduce/ 线程/ 负责/ 一个/ Hash/ 区间/ ,/ Reduce/ 线程/ 之间/ 不/ 存在/ 同步/ 关系/ ./ Map/ 和/ Reduce/ 线程/ 之间/ 对应/ Hash/ 区间/ 建立/ 缓冲区/ ,/ Map/ 线程/ 在/ 数据流/ 中/ 过滤/ 出本/ 节点/ 负责/ 的/ 数据/ 并/ 将/ 其/ 写入/ 相应/ 区间/ 的/ 缓冲区/ ,/ Reduce/ 线程/ 处理/ 负责/ 区间/ 内/ 的/ 缓冲/ 数据/ 并/ 将/ 计算结果/ 写到/ HashB/ +/ 树中/ ./ 按照/ 上述/ 设计/ ,/ 根据/ Map/ 和/ Reduce/ 线程/ 数量/ ,/ 在/ 内存/ 中/ 的/ 缓冲/ 数据/ 形成/ 一个/ M/ ×/ N/ 的/ 缓冲区/ 矩阵/ ,/ 如图/ 7/ ./ 若/ 寻道/ 时间/ 为/ 常数/ Cs/ ,/ 数据/ 读写/ 开销/ 函数/ 为/ Cr/ 和/ Cw/ ,/ 数据/ 合并/ 开销/ 函数/ 为/ Cm/ ./ 追加/ 写/ (/ dumpbyminorcompaction/ )/ 数据/ d/ 包括/ 寻道/ 和/ 写/ 数据/ 开销/ ,/ 即/ 合并/ 读/ (/ readbymergecompaction/ )/ 已有/ 数据/ d/ 和/ 新增/ 数据/ d/ 包括/ 两次/ 寻/ 道/ 、/ 两次/ 读数据/ 以及/ 数据/ 合并/ 开销/ ,/ 即/ Costrmc/ =/ 2Cs/ +/ Cr/ (/ d/ )/ +/ Cr/ (/ d/ )/ +/ Cm/ (/ d/ ,/ d/ )/ ./ 合并/ 写/ (/ dumpbymergecompaction/ )/ 数据/ d/ 包/ Page7/ 括/ 寻道/ 和/ 写/ 数据/ 开销/ ,/ 即/ 随机/ 读/ (/ readrandomly/ )/ 数据/ d/ 包括/ 寻道/ 和/ 读数据/ 开销/ ,/ 即/ 基于/ 上述/ 计算方法/ ,/ 在/ 出现/ 内外/ 存/ 替换/ 时/ ,/ 对于/ 要/ 替换/ 的/ Hash/ 表项/ ,/ 应该/ 首先/ 利用/ Map/ 和/ Reduce/ 阶段/ 间/ 的/ 缓冲区/ 查看/ 该/ 表项/ 是否/ 即将/ 被/ 访问/ ./ 若此/ 表项/ 不会/ 很快/ 被/ 访问/ ,/ 采用/ 写/ 开销/ 较/ 小/ 的/ 追加/ 写/ 方式/ ;/ 若此/ 表项/ 很快/ 被/ 访问/ ,/ 则/ 比较/ 若/ Cost1/ 开销/ 大/ ,/ 选择/ 合并/ 写/ 和/ 随机/ 读/ 方式/ ,/ 若/ Cost2/ 开销/ 大/ ,/ 选择/ 追加/ 写/ 和/ 合并/ 读/ 方式/ ./ 此外/ ,/ 针对/ 追加/ 写/ 方式/ 产生/ 的/ 小/ 文件/ ,/ 通过/ 管理/ 线程/ 进行/ 合并/ 以/ 优化/ 读/ 操作/ ,/ 尤其/ 在/ 系统/ 由于/ 负载/ 低/ 而/ CPU/ 空闲/ 时/ ,/ 可以/ 增加/ 用于/ 合并/ 文件/ 的/ 管理/ 线程/ ./ 3.4/ 替换算法/ 提高/ 替换算法/ 的/ 命中率/ 也/ 是/ 降低/ 外存/ 读写/ 开销/ 的/ 重要/ 方法/ ./ 在/ 传统/ 的/ 操作系统/ 页面/ 替换算法/ 中/ ,/ 最优/ 算法/ [/ 11/ ]/ 根据/ 将要/ 访问/ 的/ 页/ 信息/ 确定/ 替换/ 页/ ,/ 所以/ 命中率/ 最高/ ,/ 但/ 在/ 实际/ 系统/ 中/ ,/ 由于/ 无法/ 预知/ 将要/ 访问/ 的/ 页/ ,/ 该/ 方法/ 较/ 少/ 使用/ ./ 在/ RTMR/ 的/ 本地/ 阶段/ 化/ 流水线/ 中/ ,/ Map/ 和/ Reduce/ 阶段/ 之间/ 的/ 缓冲区/ 包含/ 着/ 将要/ 访问/ 的/ Hash/ 表项/ 信息/ ,/ 所以/ 可以/ 利用/ 最优/ 算法/ 的/ 思想/ ./ 此外/ ,/ 数据/ 访问/ 的/ 局部性/ 和/ 替换/ 代价/ 也/ 是/ 需要/ 考虑/ 的/ 因素/ ./ 因此/ ,/ RTMR/ 内外/ 存/ 替换算法/ 按照/ 是否/ 即将/ 访问/ 、/ 是否/ 最近/ 访问/ 、/ 替换/ 代价/ 最小/ 的/ 顺序/ 确定/ 被/ 替换/ 的/ Hash/ 表项/ ./ 其中/ ,/ 检索/ 缓冲区/ 数据/ 确定/ 表项/ 是否/ 将/ 被/ 访问/ ,/ 基于/ LRU/ 算法/ 记录表/ 项/ 的/ 最近/ 访问/ 时间/ ,/ 按照/ 数据量/ 选择/ 能/ 容纳/ 替入/ 表项/ 的/ 最小/ 表项/ ./ 4/ 基于/ 系统/ 参数/ 的/ 阶段/ 化/ 处理/ 优化/ 为了/ 提高/ 数据流/ 处理/ 能力/ ,/ RTMR/ 在/ 每个/ 工作/ 节点/ 构造/ 阶段/ 化/ 流水线/ (/ 如图/ 8/ )/ ,/ 利用/ 线程/ 池/ 减少/ 每次/ 处理/ 时/ 的/ 初始化/ 开销/ ,/ 并/ 通过/ 异步/ 的/ 传递数据/ 消除/ Map/ 和/ Reduce/ 阶段/ 间/ 的/ 同步/ ./ 在/ 阶段/ 划分/ 时/ ,/ 为/ 减少/ 阶段/ 化/ 的/ 开销/ ,/ 将/ 数据/ 接收/ 阶段/ 和/ Map/ 阶段/ 合并/ ,/ 每个/ 阶段/ 由/ 工作/ 线程/ 池/ 、/ 输入/ 缓冲区/ 和/ 阶段/ 内/ 控制器/ 组成/ ,/ 阶段/ 之间/ 通过/ 控制器/ 调整/ 资源分配/ ./ 在/ RTMR/ 本地/ 阶段/ 化/ 流水线/ 中/ ,/ Map/ 和/ Reduce/ 阶段/ 各/ 占用/ 一部分/ 工作/ 线程/ ,/ 关键/ 的/ 共享资源/ 是/ CPU/ ./ 如何/ 充分/ 、/ 有效/ 地/ 利用/ CPU/ (/ 包括/ CPUCache/ )/ 是/ 提高/ 数据流/ 处理/ 能力/ 的/ 关键问题/ ./ 阶段/ 化/ 流水线/ 可以/ 通过/ 阶段/ 内/ 的/ 批/ 调整/ 和/ 阶段/ 间/ 的/ 线程/ 池/ 调整/ 优化/ 对/ CPU/ 的/ 利用/ ./ 4.1/ 阶段/ 内/ 控制/ 批/ 控制/ 能/ 提高/ 阶段/ 处理/ 能力/ 的/ 原因/ 在于/ :/ 工作/ 线程/ 每次/ 从/ 缓冲区/ 取/ 一批/ 数据/ 的/ 时间/ 相当于/ 取/ 一条/ 数据/ 的/ 时间/ ,/ 减少/ 了/ 访问/ 缓冲区/ 的/ 次数/ ;/ 根据/ 局部性/ 原理/ ,/ 工作/ 线程/ 对/ 一批/ 数据/ 的/ 处理过程/ 共享/ 一个/ 代码段/ 和/ 数据结构/ ,/ 可以/ 有效/ 提高/ CPUCache/ 的/ 命中率/ ,/ 从而/ 提高/ 阶段/ 处理速度/ ./ 在/ SEDA/ 设计/ 中/ ,/ 由于/ 无法/ 精确/ 刻画/ 批/ 大小/ 同/ 阶段/ 处理/ 能力/ 的/ 关系/ ,/ 所以/ 批/ 控制/ 一般/ 基于/ 启发式/ 的/ 反馈/ 控制/ 方式/ ,/ 通过观察/ 系统/ 参数/ 调整/ 批/ 大小/ ./ 现有/ 的/ SEDA/ 批/ 控制/ 方法/ 通过观察/ 阶段/ 吞吐量/ 调整/ 批/ ,/ 当/ 吞吐量/ 降低/ 时/ 增大/ 批/ ,/ 当/ 吞吐量/ 增大/ 时/ 减小/ 批/ ./ 为了/ 说明/ 这种/ 方法/ 的/ 不足/ ,/ 给出/ 如下/ 定理/ ./ 定理/ 3/ ./ 阶段/ 吞吐量/ 不能/ 决定/ 处理速度/ ./ 证明/ ./ 设某/ 阶段/ 在/ 时间/ T/ 内/ 处理/ 了/ n/ 条/ 数据/ ,/ 吞吐量/ 观察/ 周期/ 为/ W/ ,/ 则/ 阶段/ 处理速度/ 为/ 吞吐量/ 为/ 根据/ 排队/ 稳态/ 理论/ ,/ 当/ 处理速度/ 低于/ 数据/ 到达/ 速度/ 时/ ,/ 系统/ 吞吐量/ 由/ 处理速度/ 决定/ ,/ 此时/ 吞吐量/ η/ 提高/ (/ 降低/ )/ 说明/ 处理速度/ μ/ 提高/ (/ 降低/ )/ ./ 当/ 处理速度/ 不/ 低于/ 数据/ 到达/ 速度/ 时/ ,/ 系统/ 吞吐量/ 由/ 数据/ 到达/ 速度/ 决定/ ./ 此时/ 吞吐量/ 的/ 变化/ 与/ 数据处理/ 速度/ 无关/ ./ 定理/ 3/ 说明/ 以/ 阶段/ 吞吐量/ 作为/ 参数/ 控制/ 批/ 大小/ 会/ 造成/ 控制/ 不/ 准确/ ,/ 从而/ 制约/ 阶段/ 处理/ 能力/ 提升/ ./ 为了/ 充分利用/ 阶段/ 内/ 的/ 优化/ 机制/ (/ 主要/ 是/ CPUCache/ )/ ,/ 应该/ 以/ 阶段/ 处理速度/ 作为/ 控制参数/ ,/ 在/ 没有/ 达到/ 最大/ 处理/ 能力/ 之前/ ,/ 尤其/ 是/ 在/ 数据处理/ 速度/ 跟上/ 数据/ 到达/ 速度/ 后/ ,/ 仍然/ 可以/ 增大/ 批/ ./ 当/ 处理速度/ 开/ Page8/ 始/ 下降时/ ,/ 则/ 应该/ 减小/ 批/ ./ 阶段/ 内批/ 调整/ 算法/ 如下/ ./ 算法/ 1/ ./ 批/ 控制算法/ ./ 输入/ :/ 数据/ 到达/ 速度/ λ/ 输出/ :/ 阶段/ 处理速度/ μ/ 1/ ./ λ/ =/ 0/ ,/ μ/ =/ 0/ ,/ β/ =/ 1/ ;/ 2/ ./ 每/ 批处理/ 结束/ 后/ ,/ 计算/ 数据/ 到达/ 速度/ λ/ 、/ 阶段/ 处理/ 速/ 3/ ./ if/ μ/ </ μ/ 4/ ./ elseif/ μ/ >/ μ/ ∧/ μ/ </ λ/ 5/ ./ elseif/ μ/ >/ μ/ ∧/ μ/ >/ λ/ 6/ ./ λ/ =/ λ/ ,/ μ/ =/ μ/ ;/ 7/ ./ 转步/ 2/ ;/ 在/ 算法/ 1/ 中/ ,/ 首先/ 初始化/ 数据/ 到达/ 速度/ 、/ 阶段/ 处理速度/ 和/ 批/ 大小/ ./ 之后/ 在/ 每/ 批处理/ 结束/ 后/ ,/ 观察/ 数据/ 到达/ 速度/ 、/ 阶段/ 处理速度/ ,/ 若/ 处理速度/ 开始/ 下降/ ,/ 则/ 减小/ 批/ ;/ 若/ 处理速度/ 增加/ 但/ 仍/ 小于/ 数据/ 到达/ 速度/ ,/ 则/ 根据/ 已/ 接收数据/ 增大/ 批/ ;/ 若/ 处理速度/ 增加/ 且/ 已经/ 跟上/ 数据/ 接收/ 速率/ ,/ 则/ 根据/ 调整/ 因子/ 增大/ 批/ ,/ 批/ 的/ 调整/ 因子/ 设为/ 5/ %/ ./ 4.2/ 阶段/ 间/ 控制/ 在/ 阶段/ 控制/ 的/ 基础/ 上/ ,/ 阶段/ 间/ 控制器/ 通过/ 调整/ 各/ 阶段/ 的/ 工作/ 线程/ 以/ 充分利用/ CPU/ 、/ 提高/ 整体/ 吞吐量/ ./ 阶段/ 间/ 线程/ 资源/ 调整/ 同样/ 采用/ 反馈/ 控制/ 方式/ ,/ 现有/ 的/ SEDA/ 方法/ 通过观察/ 阶段/ 输入/ 缓冲区/ 内/ 的/ 数据/ 规模/ 调整/ 线程/ 池/ 大小/ ,/ 当/ 缓冲区/ 数据/ 超过/ 阈值/ 时/ 增加/ 线程/ ,/ 反之/ ,/ 减少/ 线程/ ./ 这种/ 方法/ 没有/ 综合/ 考虑/ 系统/ CPU/ 使用/ 信息/ 进行/ 各/ 阶段/ 间/ 的/ 全局/ 控制/ ,/ 造成/ CPU/ 利用率/ 的/ 提高/ 无法/ 转化/ 为/ 全局性/ 能/ 优化/ ./ 根据/ 全局/ 的/ CPU/ 信息/ ,/ 造成/ CPU/ 空闲/ (/ 利用率/ 低/ )/ 的/ 原因/ 一是/ 系统/ 负载/ 低/ ,/ 二是/ 频繁/ 发生/ 读写/ 文件/ 等/ 阻塞/ 操作/ ./ 区别/ 这/ 两种/ 情况/ 的/ 方法/ 是/ 判断/ 数据处理/ 速度/ 是否/ 跟上/ 数据/ 到达/ 速度/ ,/ 若/ 处理速度/ 不/ 低于/ 数据/ 到达/ 速度/ ,/ 则/ 属于/ 前者/ ./ 反之/ ,/ 属于/ 后者/ ./ 阶段/ 间/ 的/ 工作/ 线程/ 调整/ 主要/ 针对/ 第二种/ 情况/ ./ 下面/ 首先/ 给出/ 阶段/ 过载/ 的/ 定义/ ./ 定义/ 5/ ./ 若/ 阶段/ 的/ 数据处理/ 速度/ 低于/ 数据/ 到达/ 速度/ ,/ 则/ 称此/ 阶段/ 过载/ ./ 在/ 阶段/ 过载/ 时/ ,/ 若/ CPU/ 利用率/ 不足/ ,/ 应该/ 通过/ 增加/ 线程/ 来/ 提高/ CPU/ 利用率/ ,/ 从而/ 提高/ 阶段/ 处理速度/ ./ 然而/ ,/ 当/ CPU/ 利用率/ 到达/ 一定/ 程度/ 后/ ,/ 如果/ 继续/ 增加/ 线程/ ,/ 会/ 因为/ 频繁/ 的/ 线程/ 切换/ 导致系统/ 开销/ 增加/ ,/ 处理速度/ 降低/ ./ 文献/ [/ 7/ ]/ 指出/ ,/ CPU/ 利用率/ 在/ 75/ %/ 以下/ 时/ 线程/ 的/ 切换/ 开销/ 成/ 线性/ 增长/ ,/ 而/ 在/ 75/ %/ 以上/ 时则/ 成/ 指数/ 增长/ ./ 因此/ ,/ 为了/ 减少/ 多线程/ 的/ 系统/ 开销/ ,/ 将/ 75/ %/ 作为/ 判断/ 是否/ 可以/ 增加/ 线程/ 的/ 标准/ ./ 在/ 一个/ 阶段/ 过载/ 而/ 另/ 一个/ 阶段/ 非/ 过载/ 时/ ,/ 若/ CPU/ 利用率/ 小于/ 75/ %/ ,/ 增加/ 过载/ 阶段/ 的/ 线程/ 数/ ,/ 若/ CPU/ 利用率/ 大于/ 75/ %/ ,/ 则/ 移动/ 非/ 过载/ 阶段/ 的/ 线程/ 到/ 过载/ 阶段/ ./ 如果/ 两个/ 阶段/ 都/ 过载/ ,/ 由于/ 系统/ 吞吐量/ 是/ 由/ Reduce/ 阶段/ 决定/ 的/ ,/ 所以/ 应该/ 优先/ 向/ Reduce/ 阶段/ 增加/ 或/ 移动/ 线程/ ./ 在/ 确定/ 了/ 调整/ 方法/ 后/ ,/ 还/ 应该/ 确定/ 调整/ 目标/ ,/ 即/ 系统/ 何时/ 达到/ 吞吐量/ 最大/ ,/ 下面/ 定义/ 了/ 平衡/ 系统/ 的/ 概念/ ./ 定义/ 6/ ./ Map/ 和/ Reduce/ 阶段/ 的/ 数据/ 到达/ 速度/ 分别/ 为/ λ/ M/ ,/ λ/ R/ ,/ 处理速度/ 分别/ 为/ μ/ M/ ,/ μ/ R/ ,/ CPU/ 利用率/ 为/ u/ ./ 若/ 系统/ 存在/ 下列/ 情况/ 之一/ ,/ 则/ 称/ 系统/ 是/ 平衡/ 的/ ./ (/ 1/ )/ λ/ R/ / μ/ R/ ,/ λ/ M/ / μ/ M/ ./ (/ 2/ )/ u/ / 0.75/ ,/ λ/ M/ >/ μ/ M/ ,/ λ/ R/ =/ μ/ R/ ./ 定理/ 4/ ./ 平衡/ 系统/ 的/ 吞吐量/ 最大/ ./ 证明/ ./ RTMR/ 阶段/ 化/ 流水线/ 可以/ 看作/ 一个/ 由/ 数据流/ 接收/ 、/ Map/ 和/ Reduce/ 三个/ 组件/ 组成/ 的/ 串联/ 系统/ ,/ 系统/ 吞吐量/ 由/ 最小/ 输出/ 速度/ 的/ 组件/ 决定/ ./ 若/ λ/ R/ / μ/ R/ 并且/ λ/ M/ / μ/ M/ ,/ 即/ Map/ 阶段/ 和/ Reduce/ 阶段/ 的/ 处理速度/ 都/ 大于/ 数据/ 到达/ 速度/ ,/ 此时/ 的/ 系统/ 吞吐量/ 由/ 数据流/ 速度/ 决定/ ./ 当/ CPU/ 不/ 低于/ 75/ %/ 时/ ,/ 若/ λ/ M/ >/ μ/ M/ 并且/ λ/ R/ =/ μ/ R/ ,/ 即/ Map/ 阶段/ 的/ 数据处理/ 速度/ 低于/ 到达/ 速度/ ,/ 输出/ 速度/ (/ Reduce/ 阶段/ 的/ 数据/ 到达/ 速度/ )/ 与/ Reduce/ 阶段/ 的/ 处理速度/ 相等/ ./ 此时/ 由于/ CPU/ 繁忙/ ,/ 阶段/ 间/ 控制/ 不能/ 再/ 增加/ 线程/ ,/ 只能/ 通过/ 移动/ 线程/ 进行/ 调整/ ./ 若/ 移动/ Map/ 阶段/ 的/ 工作/ 线程/ 到/ Reduce/ 阶段/ ,/ 由于/ Map/ 阶段/ 的/ 处理速度/ 降低/ ,/ 造成/ λ/ R/ 降低/ ,/ 系统/ 的/ 吞吐量/ 也/ 就/ 随之/ 降低/ ;/ 若/ 移动/ Reduce/ 阶段/ 的/ 工作/ 线程/ 到/ Map/ 阶段/ ,/ 虽然/ λ/ R/ 增加/ ,/ 但/ 由于/ Reduce/ 阶段/ 处理/ 能力/ 下降/ 造成/ 系统/ 吞吐量/ 降低/ ./ 实际上/ ,/ 此时/ 的/ 系统/ 处于/ 过载/ 平衡/ 状态/ ./ 定理/ 4/ 表明/ 阶段/ 间/ 线程/ 调整/ 的/ 目标/ 是/ 达到/ 平衡/ 状态/ ./ 阶段/ 间/ 工作/ 线程/ 调整/ 算法/ 如下/ ./ 算法/ 2/ ./ 线程/ 池/ 调整/ 算法/ ./ 输入/ :/ Map/ 和/ Reduce/ 阶段/ 的/ 数据/ 到达/ 速度/ λ/ M/ ,/ λ/ R/ ,/ 输出/ :/ Map/ 和/ Reduce/ 阶段/ 的/ 处理速度/ μ/ M/ ,/ μ/ R1/ ./ 每/ 5/ 秒/ 观察/ Map/ 和/ Reduce/ 阶段/ 的/ 数据/ 到达/ 速度/ λ/ M/ ,/ λ/ R/ ,/ 处理速度/ μ/ M/ ,/ μ/ R/ 以及/ 全局/ CPU/ 利用率/ u/ ;/ 2/ ./ if/ λ/ R/ =/ μ/ R/ ∧/ u/ / 0.753/ ./ elseif/ λ/ R/ / μ/ R/ ∧/ λ/ M/ / μ/ MPage94/ ./ elseif/ λ/ R/ >/ μ/ R5/ ./ elseif/ λ/ M/ >/ μ/ M6/ ./ 转步/ 1/ ./ 在/ 算法/ 2/ 中/ ,/ 首先/ 向/ 过载/ 阶段/ 增加/ 或/ 移动/ 工作/ 线程/ ,/ 当/ 两个/ 阶段/ 都/ 过载/ 时/ ,/ 优先/ 考虑/ 向/ Reduce/ 阶段/ 增加/ 或/ 移动/ 工作/ 线程/ ,/ 直至/ 达到/ 平衡/ 状态/ ./ 算法/ 的/ 调整/ 周期/ 设定/ 为/ 5s/ ,/ 这样/ 能够/ 保证/ 阶段/ 内/ 的/ 批/ 控制/ 方法/ 能够/ 有/ 充足/ 的/ 时间/ 适应/ 线程/ 池/ 的/ 变化/ ./ 在/ 系统/ 达到/ 平衡/ 状态/ 后/ ,/ 若/ 系统/ 非/ 过载/ 且/ CPU/ 利用率/ 小于/ 75/ %/ ,/ 说明/ CPU/ 没有/ 被/ 充分利用/ 就/ 已经/ 能够/ 跟上/ 数据流/ 速度/ ,/ 则/ 线程/ 太/ 多只/ 会/ 增加/ 开销/ ;/ 若/ CPU/ 利用率/ 高于/ 75/ %/ ,/ 则/ 会/ 由于/ 线程/ 太/ 多/ 造成/ 开销/ 急剧/ 增加/ ;/ 在/ 系统/ 过载/ 情况/ 下/ ,/ CPU/ 利用率/ 肯定/ 大于/ 75/ %/ ,/ 此时/ 也/ 会/ 由于/ 线程/ 太/ 多/ 导致/ 开销/ 增加/ ./ 因此/ ,/ 在/ 系统/ 达到/ 平衡/ 状态/ 后/ ,/ 无论/ 系统/ 是否/ 过载/ ,/ 都/ 可以/ 试图/ 通过/ 减少/ 线程/ 降低/ 系统/ 开销/ ./ 具体/ 的/ 调整/ 方法/ 为/ 依次/ 减少/ Map/ 和/ Reduce/ 阶段/ 的/ 线程/ 直到/ 阶段/ 处理速度/ 开始/ 降低/ 或/ 重新/ 达到/ 不/ 平衡/ 状态/ ./ 5/ 评价/ 本节/ 以物/ 联网/ 环境/ 下/ 城市/ 车辆/ 实时/ 数据处理/ 应用/ 中/ 具有/ 代表性/ 的/ 套牌车/ 计算/ 作为/ 基准/ 测试/ 验证/ RTMR/ 方法/ ./ 5.1/ 基准/ 测试/ 套牌车/ 主要/ 根据/ 车辆/ 时空/ 矛盾/ 来/ 判定/ ,/ 针对/ 每/ 一条/ 出现/ 在/ 特定/ 监控/ 地点/ 的/ 车辆/ 实时/ 数据/ ,/ 检索/ 该/ 车牌/ 出现/ 在/ 所有/ 其他/ 监控点/ 且/ 在/ 最大/ 套牌/ 时间/ 阈值/ 内/ 的/ 历史数据/ ,/ 如果/ 二者/ 的/ 时间差/ 小于/ 该/ 两点/ 之间/ 的/ 套牌/ 时间/ 阈值/ ,/ 则/ 认为/ 该/ 车辆/ 有/ 套牌/ 嫌疑/ ./ 根据/ 前期/ 物/ 联网/ 建设/ 工作/ 统计数据/ ,/ 若/ 在/ 某/ 大型/ 城市/ 全面/ 捕获/ 车辆/ 数据/ ,/ 数据流/ 速度/ 将会/ 达到/ 1MB/ // s/ (/ 每条/ 数据/ 按/ 200B/ 计/ ,/ 约/ 5000/ 条/ // s/ )/ ,/ 同时/ ,/ 在/ 车辆/ 数据/ 保存/ 一个月/ 的/ 情况/ 下/ ,/ 历史数据/ 的/ 存储量/ 将/ 达到/ 1TB/ ./ 套牌车/ 计算/ 可以/ 使用/ 如下/ RTMR/ 算法/ :/ 针对/ 某/ 车牌号/ ,/ Map/ 阶段/ 在/ 所有/ 车牌号/ 的/ Hash/ 表中/ 找到/ 其/ 所在/ 分组/ 表项/ ,/ Reduce/ 阶段/ 在/ B/ +/ 树中/ 找到/ 其/ 链表/ 所在位置/ ,/ 依次/ 与/ 每条/ 历史数据/ 比较/ 套牌/ 时间/ 阈值/ 并/ 更新/ 链表/ ./ 在/ 某/ 城市/ 的/ 车牌/ 数量/ 达到/ 107/ 的/ 情况/ 下/ ,/ 可以/ 采用/ 输出/ 为/ 20/ 位/ 二进制/ 数/ 的/ Hash/ 函数/ 进行/ 分组/ ,/ 存储/ 中间/ 结果/ 的/ Hash/ 表/ 共有/ 220/ 个/ 表项/ ,/ 平均/ 每个/ Hash/ 表项/ 存储/ 107/ // 220/ ≈/ 10/ 个/ 车牌/ 的/ 数据/ ./ 因为/ 在/ 持久/ 化/ 历史数据/ 中/ 可能/ 只有/ 部分/ 数据/ 与/ 计算/ 相关/ ,/ 例如/ 在/ 套牌车/ 计算/ 中/ 只有/ 套牌/ 阈值/ 范围/ 内/ 的/ 历史数据/ 相关/ ,/ 所以/ 以/ 预处理/ 的/ 历史数据/ 中间/ 结果/ 规模/ 来/ 衡量/ 流/ 处理/ 架构/ 处理/ 能力/ ./ 数据流/ 处理/ 集群/ 搭建/ 在/ 2/ ×/ 6/ 核/ 2.0/ GHzCPU/ 、/ 32GB/ 内存/ 、/ 250GB/ 硬盘/ 的/ 服务器/ 集群/ 上/ ;/ 使用/ Oracle10g/ 作为/ 持久/ 化/ 存储/ ,/ 搭建/ 在/ 一台/ 2/ ×/ 4/ 核/ 2.4/ GHzCPU/ ,/ 16GB/ 内存/ 服务器/ 和/ 20TBRAID5/ 磁盘阵列/ 上/ ;/ 网络连接/ 采用/ 1Gbps/ 以太网/ 光纤/ 和/ 交换机/ ;/ 在/ 1/ 台/ 双核/ 3.0/ GHzCPU/ 、/ 4GB/ 内存/ 服务器/ 上/ 使用/ LoadRunner9/ ./ 0/ 模拟/ 数据流/ ./ 为了/ 测试/ 数据流/ 处理/ 架构/ 的/ 伸缩/ 能力/ ,/ 在/ 集群/ 节点/ 上/ 均匀/ 划分/ 历史数据/ 区间/ ,/ 并/ 在/ 车辆/ 数据流/ 随机性/ 和/ 局部性/ 特点/ 基础/ 上/ ,/ 模拟/ 在/ 集群/ 节点/ 上/ 均匀分布/ 的/ 数据流/ ,/ 具体方法/ 为/ :/ 以/ 十进制/ 区间/ (/ 0/ ,/ 107/ ]/ 内/ 的/ 数/ 模拟/ 车牌号/ ,/ 若/ 存在/ n/ 个/ 节点/ ,/ 在/ 各/ 节点/ 的/ 历史数据/ 划分/ 区间/ 中/ 选取/ 一个/ 子集/ P1/ ,/ P2/ ,/ …/ ,/ Pn/ ,/ 使得/ |/ P1/ |/ +/ |/ P2/ |/ +/ …/ +/ |/ Pn/ |/ =/ 105/ ,/ 循环/ 的/ 为/ n/ 个/ 节点/ 产生/ 负载/ ,/ 对于/ 节点/ i/ ,/ 在/ Pi/ 中/ 选取/ 一个/ 随机/ 表项/ t/ ,/ 在/ 区间/ (/ 0/ ,/ 10/ )/ 内/ 选取/ 一个/ 随机数/ x/ ,/ 以/ 220x/ +/ t/ 作为/ 该条/ 模拟/ 数据/ 的/ 车牌号/ ,/ 随机/ 设定/ 监控点/ ,/ 记录/ 系统/ 时间/ 添加/ 时间/ 戳/ 并/ 控制/ 数据流/ 速度/ ./ 本文/ 在/ 测试/ 单个/ 方法/ 优化/ 效果/ 时/ ,/ 采用/ 面向/ 方面/ 编程/ (/ Aspect/ -/ OrientedProgramming/ ,/ AOP/ )/ 思想/ ,/ 禁用/ 其他/ 优化/ 方法/ ,/ 将/ 测试代码/ 插入/ 测试/ 目标/ 方法/ ,/ 作为/ 比较/ 对象/ 的/ 方法/ 使用/ 同样/ 的/ 集群/ 配置/ 同时/ 接收/ 和/ 处理/ 数据流/ 负载/ ,/ 分别/ 计算/ 性能指标/ ./ 5.2/ 中间/ 结果/ 存储/ 性能/ 分析/ 首先/ 验证/ RTMR/ 对/ 中间/ 结果/ 本地/ 存储/ 的/ 优化/ 效果/ ./ 实验/ 使用/ 单个/ 节点/ ,/ 数据流/ 速度/ 固定/ 为/ 1MB/ // s/ (/ 每条/ 数据/ 200B/ ,/ 约/ 5000/ 条/ // s/ )/ ,/ 中间/ 结果/ 数据/ 规模/ 为/ 50GB/ ,/ 每/ 项/ 测试/ 进行/ 10/ 次/ ,/ 每次/ 10min/ ,/ 取/ 平均值/ 计算/ 实验/ 结果/ ./ 表/ 1/ 显示/ 了/ 对/ 中间/ 结果/ 本地/ 存储/ 进行/ 优化/ 前后/ 的/ 性能/ 对比/ ,/ 可以/ 看到/ ,/ RTMR/ 通过/ 建立/ 缓冲区/ 消除/ 读写/ 同步/ ,/ 使/ 中间/ 结果/ 的/ 内存/ 读写/ Page10/ 性能/ 提高/ 了/ 12.1/ %/ ,/ RTMR/ 通过/ 利用/ 缓冲区/ 信息/ 指导/ 读写/ 策略/ 和/ 替换算法/ ,/ 使/ 外存/ 读写/ 性能/ 和/ 内外/ 存/ 命中率/ 分别/ 提高/ 了/ 15.5/ %/ 和/ 9.3/ %/ ./ 综合/ 3/ 种/ 方法/ ,/ 将/ 中间/ 结果/ 本地/ 读写/ 性能/ (/ 单位/ 时间/ 内/ 读写/ 次数/ )/ 提升/ 了/ 近/ 1/ // 4/ ./ 性能指标/ 测试方法/ 实验/ 结果/ 效果/ // %/ 内存/ 读写/ 性能/ 读写/ 同步/ 75385.2/ 外存/ 读写/ 性能/ BigTable4425/ ./ 5/ 次/ // s/ 内存/ 命中率/ LRU/ 整体/ 读写/ 性能/ 改进/ 前/ 73901.4/ 次/ // s/ 在/ 上述/ 实验/ 的/ 基础/ 上/ ,/ 保持数据/ 规模/ 不变/ ,/ 逐步提高/ 数据流/ 速度/ ,/ 测试/ RTMR/ 方法/ 外存/ 读写/ 性能/ 和/ 命中率/ 的/ 变化/ 情况/ ./ 由图/ 9/ 和/ 图/ 10/ 可知/ ,/ 随着/ 数据流/ 速度/ 的/ 提高/ ,/ 由于/ 缓冲区/ 队列/ 不断/ 变/ 大/ ,/ 能够/ 为/ 外存/ 读写/ 策略/ 和/ 替换算法/ 提供/ 更为/ 充足/ 的/ 将要/ 访问/ 表项/ 信息/ ,/ 因而/ 读写/ 性能/ 和/ 命中率/ 不断/ 提高/ ./ 但/ 当/ 数据流/ 速度/ 提高/ 到/ 一定/ 程度/ 时/ ,/ 缓冲区/ 数据/ 规模/ 的/ 扩大/ 将/ 不会/ 再/ 引起/ 读写/ 性能/ 和/ 命中率/ 的/ 提高/ ,/ 反而/ 因为/ 检索/ 开销/ 加大/ ,/ 以及/ 占用/ 过多/ 内存/ 资源/ 引发/ 了/ 额外/ 的/ 内外/ 替换/ 和/ 读写操作/ ,/ 造成/ 读写/ 性能/ 和/ 命中率/ 急剧下降/ ./ 针对/ 上述/ 规律/ ,/ 在/ RTMR/ 内外/ 存/ 结构/ 、/ 读写/ 策略/ 和/ 替换算法/ 的/ 基础/ 上/ ,/ 下/ 一步/ 的/ 工作/ 是/ 对/ 数据流/ 速度/ 、/ 缓冲/ 队列/ 大小/ 与/ 读写/ 性能/ 、/ 命中率/ 的/ 关系/ 进行/ 进一步/ 分析/ ,/ 以/ 指导/ 缓冲区/ 大小/ 的/ 动态变化/ 以及/ 负载/ 丢弃/ 策略/ ./ 5.3/ 阶段/ 化/ 流水线/ 性能/ 分析/ 与/ 5.2/ 节/ 实验/ 类似/ ,/ 验证/ 阶段/ 化/ 流水线/ 优化/ 效果/ 的/ 实验/ 使用/ 单个/ 节点/ ,/ 数据流/ 速度/ 固定/ 为/ 1MB/ // s/ ,/ 中间/ 结果/ 数据/ 规模/ 为/ 50GB/ ,/ 每/ 项/ 测试/ 进行/ 10/ 次/ ,/ 每次/ 10min/ ,/ 取/ 平均值/ 计算/ 实验/ 结果/ ./ 表/ 2/ 显示/ 了/ 对/ 本地/ 阶段/ 化/ 流水线/ 进行/ 优化/ 前后/ 的/ 性能/ 对比/ ./ 可以/ 看到/ ,/ 由于/ RTMR/ 利用/ 阶段/ 数据/ 到达/ 速度/ 和/ 处理速度/ 进行/ 控制/ ,/ 比/ 利用/ 吞吐量/ 进行/ 控制/ 更能/ 充分利用/ CPUCache/ ,/ 因此/ Reduce/ 阶段/ 处理速度/ 提高/ 了/ 14.8/ %/ ;/ 由于/ RTMR/ 根据/ CPU/ 信息/ 进行/ 各/ 阶段/ 间/ 的/ 全局/ 控制/ ,/ 更能/ 将/ CPU/ 利用率/ 充分/ 转化/ 为/ 性能/ 提升/ ,/ 因此/ 系统/ 吞吐量/ 提高/ 了/ 10.7/ %/ ./ 综合/ 两种/ 方法/ ,/ 将/ 阶段/ 化/ 流水线/ 的/ 整体/ 性能/ (/ 吞吐量/ )/ 提升/ 了/ 近/ 1/ // 5/ ./ 性能指标/ 测试方法/ 实验/ 结果/ // (/ 条/ ·/ s/ -/ 1/ )/ 效果/ // %/ 阶段/ 处理速度/ SEDA7848/ ./ 8/ 吞吐量/ SEDA4804/ ./ 8/ 流水线/ 性能/ SEDA4920/ ./ 7/ 在/ 上述/ 实验/ 基础/ 上/ ,/ 保持数据/ 规模/ 不变/ ,/ 分别/ 以/ Reduce/ 阶段/ 处理速度/ 和/ 系统/ 吞吐量/ 为/ 测试/ 目标/ ,/ 采用/ 变化/ 的/ 数据流/ 比较/ RTMR/ 与/ SEDA/ 的/ 批/ 控制/ 和/ 线程/ 池/ 控制/ 效果/ ./ 实验/ 进行/ 10/ 次/ ,/ 记录/ 60s/ 内/ 阶段/ 处理速度/ 和/ 系统/ 吞吐量/ 的/ 变化/ ,/ 取/ 平均值/ 计算/ 实验/ 结果/ ./ SEDA/ 控制/ 方法/ 的/ 配置/ 取/ 实验/ 最优/ 值/ ,/ RTMR/ 线程/ 池/ 控制/ 周期/ 配置/ 为/ 与/ SEDA/ 相同/ 的/ 500ms/ ./ 图/ 10/ 和/ 图/ 11/ 中/ 黑线/ 所示/ 为/ 实际/ 数据流/ 负载/ 对应/ 的/ 阶段/ 处理速度/ 和/ 吞吐量/ 参考值/ ./ 由图/ 11/ 可知/ ,/ SEDA/ 批/ 控制/ 方法/ 在/ 吞吐量/ 降低/ 的/ 情况/ 下/ 增大/ 批/ (/ 阶段/ 处理速度/ 提高/ )/ ,/ 在/ 吞吐量/ 增大/ 的/ 情况/ 下/ 减小/ 批/ (/ 阶段/ 处理速度/ 降低/ )/ ,/ 造成/ 在/ 数据流/ 速度/ 提高/ 的/ 情况/ 下/ 需要/ 较长/ 的/ 调整/ 时间/ ,/ 而/ 在/ 数据流/ 速度/ 降低/ 情况/ 下/ 衰减/ 又/ 太快/ ,/ 并且/ 由于/ 未能/ Page11/ 充分利用/ CPUCache/ 等/ 阶段/ 优化/ 机制/ ,/ 制约/ 了/ 阶段/ 处理速度/ ./ 而/ RTMR/ 方法/ 通过观察/ 阶段/ 数据/ 到达/ 速度/ 和/ 处理速度/ 持续/ 增大/ 批/ ,/ 能够/ 在/ 短时间/ 内/ 达到/ 更/ 高/ 的/ 阶段/ 处理速度/ 并/ 在/ 数据流/ 速度/ 降低/ 的/ 情况/ 下/ 缓慢/ 衰减/ ./ 由图/ 12/ 可知/ ,/ SEDA/ 方法/ 根据/ 缓冲/ 数据/ 规模/ 变化/ 调整/ 线程/ 池/ ,/ 需要/ 较/ 多次/ 调整/ 才能/ 适应/ 数据流/ ,/ 并且/ 由于/ 没有/ 考虑/ 整个/ 系统/ 的/ 瓶颈/ ,/ 单个/ 阶段/ 线程/ 池/ 的/ 调整/ 无法/ 转化/ 为/ 全局/ 吞吐量/ 提升/ ,/ 而/ RTMR/ 方法/ 根据/ CPU/ 信息/ 进行/ 全局/ 调整/ ,/ 使得/ CPU/ 得到/ 了/ 充分/ 有效/ 利用/ ,/ 因而/ 在/ 调整/ 稳定/ 后/ 吞吐量/ 更高/ ./ 5.4/ 实时性/ 分析/ 在/ 实时性/ 分析/ 实验/ 中/ 对比/ S4/ 、/ HOP/ 和/ RTMR3/ 种/ 处理/ 架构/ ./ 由于/ S4/ 、/ HOP/ 不/ 支持/ 预处理/ ,/ 每次/ 处理/ 数据流/ 时/ 都/ 要/ 重新/ 进行/ 历史数据/ 加载/ 和/ 处理/ ,/ 大量/ 无谓/ 开销/ 制约/ 了/ 系统/ 吞吐量/ ./ 因此/ ,/ 为了/ 比较/ 面向/ 大规模/ 数据/ 的/ 数据流/ 处理/ 能力/ ,/ 在/ 基准/ 测试/ 的/ S4/ 和/ HOP/ 实现/ 中/ 加入/ 了/ 预处理/ 逻辑/ ,/ 也/ 就是/ 先/ 将/ 相关/ 历史数据/ 进行/ 一次/ 流/ 处理/ ./ 各种/ 数据流/ 处理/ 架构/ 都/ 搭建/ 在/ 两个/ 节点/ 上/ ,/ 数据流/ 速度/ 固定/ 为/ 1MB/ // s/ ,/ 每种/ 数据/ 规模/ 测试/ 10/ 次/ ,/ 每次/ 10min/ ,/ 取/ 平均值/ 计算/ 实验/ 结果/ ./ 由图/ 13/ 和/ 图/ 14/ 可知/ ,/ 当/ 中间/ 结果/ 规模/ 小于/ 32GB/ 时/ ,/ 因为/ 一个/ 节点/ 的/ 内存/ 就/ 可以/ 容纳/ 全部/ 中间/ 结果/ ,/ 所以/ HOP/ 和/ S4/ 也/ 具有/ 很/ 高/ 的/ 吞吐量/ (/ 大于/ 4500/ 条/ // s/ )/ ,/ 但/ RTMR/ 由于/ 采用/ 了/ 本地/ 阶段/ 化/ 流水线/ 和/ 内存/ 读写/ 优化/ ,/ 吞吐量/ 更高/ ;/ 当/ 中间/ 结果/ 规模/ 超过/ 32GB/ 时/ ,/ 中间/ 结果/ 分布/ 到/ 两个/ 节点/ 的/ 内存/ 中/ ,/ HOP/ 和/ S4/ 由于/ 节点/ 间/ 的/ 数据传输/ 和/ 同步/ 开销/ 增加/ 造成/ 吞吐量/ 下降/ 较/ 快/ ,/ 而/ RTMR/ 由于/ 采用/ 本地化/ 技术/ 避免/ 了/ 数据传输/ ,/ 吞吐量/ 依然/ 很/ 高/ ;/ 当/ 中间/ 结果/ 规模/ 超过/ 64GB/ 时/ ,/ 由于/ 已经/ 超出/ 了/ S4/ 和/ HOP/ 的/ 中间/ 结果/ 缓存/ 能力/ ,/ 其/ 吞吐量/ 趋于稳定/ ,/ 但/ 错误率/ 随/ 数据/ 规模/ 增加/ 而/ 变大/ ,/ 而/ RTMR/ 由于/ 利用/ 本地/ 外存/ 对/ 中间/ 结果/ 缓存/ 能力/ 进行/ 了/ 扩展/ 和/ 优化/ ,/ 能够/ 在/ 降低/ 错误率/ 的/ 同时/ (/ 低于/ 5/ %/ )/ 保持/ 较/ 高/ 的/ 吞吐量/ (/ 大于/ 4300/ 条/ // s/ )/ ./ 5.5/ 可伸缩性/ 分析/ 在/ 伸缩性/ 分析/ 中/ 进行/ 两组/ 实验/ ,/ 分别/ 测试/ RTMR/ 针对/ 历史数据/ 规模/ 和/ 数据流/ 速度/ 的/ 伸缩/ 能力/ ./ 在/ 第/ 1/ 组/ 实验/ 中/ 固定/ 数据流/ 速度/ 为/ 1MB/ // s/ ,/ 测试/ 在/ 节点/ 数量/ 增加/ 情况/ 下/ RTMR/ 所能/ 处理/ 的/ 历史/ Page12/ 数据/ 规模/ ./ 由图/ 15/ 左/ y/ 轴/ 曲线/ 可知/ ,/ 节点/ 增加/ 时/ RTMR/ 处理/ 能力/ 的/ 提升/ 是/ 近似/ 线性/ 的/ ,/ 这是/ 由于/ RTMR/ 通过/ 划分/ 历史数据/ 中间/ 结果/ 和/ 本地化/ 处理/ ,/ 使/ 节点/ 之间/ 不会/ 产生/ 制约/ 并行/ 吞吐量/ 提升/ 的/ 数据传输/ 和/ 同步/ 开销/ ./ 而/ 之所以/ 未能/ 达到/ 线性/ 伸缩/ ,/ 是因为/ 在/ 历史数据/ 规模/ 扩大/ 的/ 情况/ 下/ 本地/ 存储/ 文件/ 读写/ 开销/ 增加/ ./ 在/ 第/ 2/ 组/ 实验/ 中/ 固定/ 每个/ 节点/ 中间/ 结果/ 数据/ 规模/ 为/ 50GB/ ,/ 测试/ 在/ 节点/ 数量/ 增加/ 情况/ 下/ RTMR/ 所能/ 处理/ 的/ 数据流/ ./ 由图/ 15/ 右/ y/ 轴/ 曲线/ 可知/ ,/ 在/ 数据流/ 速度/ 低于/ 15MB/ // s/ 的/ 情况/ 下/ ,/ 节点/ 增加/ 时/ RTMR/ 处理/ 能力/ 的/ 提升/ 是/ 近似/ 线性/ 的/ ,/ 在/ 数据流/ 速度/ 超过/ 15MB/ // s/ 的/ 情况/ 下/ ,/ 节点/ 增加/ 时/ RTMR/ 处理/ 能力/ 的/ 提升/ 变缓/ ./ 这/ 是因为/ 随着/ 数据流/ 速度/ 的/ 提高/ ,/ RTMR/ 每个/ 节点/ 接收/ 冗余/ 数据流/ 和/ 进行/ Map/ 阶段/ 的/ CPU/ 开销/ 增加/ ,/ 同时/ RTMR/ 方法/ 的/ 中间/ 结果/ 读写/ 性能/ 和/ 替换/ 命中率/ 开始/ 下降/ ,/ 所以/ 影响/ 了/ 吞吐量/ ./ 从/ 利用/ RTMR/ 方法/ 解决/ 车辆/ 监管/ 问题/ 的/ 经验/ 来看/ ,/ 现阶段/ 物/ 联网/ 环境/ 下/ 的/ 数据流/ 处理/ 应用/ ,/ 受/ 采集/ 端/ 带宽/ 等/ 因素/ 影响/ ,/ 数据流/ 速度/ 远达/ 不到/ 15MB/ // s/ ,/ 只/ 需/ 占用/ 节点/ 多核/ CPU/ 的/ 很小/ 一部分/ 就/ 可以/ 完成/ 接收/ 和/ 分组/ 操作/ ,/ 并且/ RTMR/ 方法/ 能够/ 有效/ 提高/ 中间/ 结果/ 的/ 并发/ 读写/ 性能/ ,/ 在/ 历史数据/ 规模/ 不断扩大/ 的/ 情况/ 下/ ,/ RTMR/ 具有/ 很/ 好/ 的/ 伸缩性/ ./ 6/ 相关/ 工作/ 编程/ 模型/ 是/ 连接/ 特定/ 问题/ 与/ 特定/ 硬件/ 实现/ 的/ 桥梁/ ,/ 并行/ 编程/ 模型/ 更是/ 建立/ 大规模/ 数据处理/ 环境/ 的/ 重要/ 基础/ ./ 典型/ 的/ 并行/ 编程/ 模型/ 有/ OpenMP/ 、/ MPI/ 、/ MapReduce/ 和/ Dryad/ [/ 12/ ]/ 等/ ,/ 其中/ OpenMP/ 和/ MPI/ 是/ 抽象层次/ 比较/ 低/ 的/ 模型/ ,/ 需要/ 程序员/ 显式/ 处理/ 任务/ 管理/ 和/ 数据管理/ 等/ 细节/ ;/ Dryad/ 侧重于/ 构造/ 一个/ 完整/ 的/ 计算/ 流程/ ;/ 而/ MapReduce/ 则/ 侧重于/ 构造/ 一个/ 计算/ 算子/ ./ 对于/ 可/ 划分/ 的/ 大规模/ 数据处理/ 任务/ ,/ MapRe/ -/ duce/ 能够/ 提供/ 充分/ 的/ 并行计算/ 语义/ ,/ 因而/ 基于/ 批处理/ 方式/ 的/ MapReduce/ 得到/ 了/ 广泛应用/ ,/ 已有/ 在/ 多/ 核/ 系统/ 、/ 多核/ 集群/ 系统/ 上/ 的/ 多种/ 实现/ ./ 然而/ ,/ 以/ 批处理/ 方式/ 处理/ 持续/ 到达/ 的/ 数据流/ ,/ 无法/ 满足/ 实时/ 需求/ ./ 针对/ MapReduce/ 的/ 实时性/ 改进/ 已经/ 成为/ 研究/ 热点/ ,/ 增量/ 处理/ Percolator/ [/ 13/ ]/ 、/ DryadInc/ [/ 14/ ]/ 和/ 迭代/ 处理/ Twister/ [/ 15/ ]/ 、/ Spark/ [/ 16/ ]/ 等/ 工作/ 通过/ 随机/ 访问/ 存储/ 、/ 缓存/ 和/ 复用/ 中间/ 结果/ 提高/ 了/ 大规模/ 数据处理/ 的/ 实时性/ ./ 然而/ ,/ 上述/ 方法/ 仍属/ 对/ 静态数据/ 增量/ 的/ 批处理/ 方式/ ./ HOP/ [/ 17/ ]/ 和/ S4/ [/ 18/ ]/ 分别/ 利用/ 流水线/ 和/ 分布/ 处理单元/ 技术/ 扩展/ 了/ MapReduce/ 的/ 实时处理/ 能力/ ,/ 但/ S4/ 和/ HOP/ 依然/ 不是/ 以/ 面向/ 大规模/ 历史数据/ 的/ 数据流/ 处理/ 为/ 目标/ 的/ ,/ 表现/ 在/ 编程/ 模型/ 中/ 缺乏/ 对/ 历史数据/ 预处理/ 和/ 同步/ 方法/ 的/ 支持/ ,/ 也/ 没有/ 充分利用/ 中间/ 结果/ 缓存/ 和/ 本地/ 阶段/ 化/ 处理/ 等/ 技术/ 优化/ MapRe/ -/ duce/ 的/ 数据流/ 处理/ 能力/ ./ 本文/ 基于/ MapReduce/ 模型/ 提出/ 了/ 一种/ 支持/ 此类/ 数据处理/ 的/ 方法/ RTMR/ ,/ 并/ 对/ 其中/ 的/ 关键技术/ 瓶颈/ 进行/ 了/ 改进/ ./ 虽然/ S4/ 和/ HOP/ 都/ 采用/ 了/ 流水线/ 技术/ ,/ 但/ S4/ 需要/ 在/ 节点/ 间/ 传输/ 大量/ 中间/ 结果/ ,/ HOP/ 需要/ 在/ Reduce/ 阶段/ 进行/ 前/ 完成/ 多个/ Map/ 节点/ 结果/ 的/ 同步/ 合并/ ,/ 都/ 没有/ 充分利用/ 多核/ 计算资源/ 本地化/ MapReduce/ 处理/ ,/ 实时处理/ 能力/ 受限于/ 节点/ 之间/ 的/ 数据传输/ 和/ 同步/ ./ Phoenix/ [/ 6/ ]/ 和/ Metis/ [/ 8/ ]/ 实现/ 了/ 多/ 核/ 架构/ 上/ 的/ MapReduce/ ,/ 但/ 仍/ 属于/ 批处理/ 方式/ ./ 文献/ [/ 7/ ]/ 提出/ 的/ 阶段/ 化/ 事件驱动/ 架构/ SEDA/ 能够/ 利用/ 线程/ 池/ 技术/ 减少/ 每次/ 处理/ 的/ 初始化/ 开销/ ,/ 并/ 通过/ 在/ 阶段/ 间/ 异步/ 传递数据/ 消除/ 阶段/ 间/ 的/ 同步/ ;/ 还/ 可以/ 通过/ 控制/ 阶段/ 内/ 每次/ 处理/ 的/ 批/ 大小/ 和/ 阶段/ 间/ 的/ 资源/ 调整/ 提高/ 实时处理/ 能力/ ./ 本文/ 基于/ SEDA/ 构建/ 了/ RTMR/ 本地/ 阶段/ 化/ 流水线/ ./ 然而/ ,/ 现有/ 的/ SEDA/ 控制器/ [/ 7/ ]/ 依赖于/ 经验/ 或/ 实验/ 方式/ ,/ 没有/ 充分利用/ 各种/ 系统/ 参数/ 进行/ 自动控制/ ,/ 往往/ 花废/ 大量/ 时间/ 仍/ 不能/ 达到/ 最优/ 的/ 控制/ 效果/ ,/ 造成/ CPU/ (/ 包括/ CPUCache/ )/ 无法/ 得到/ 有效/ 利用/ ,/ 从而/ 制约/ 了/ 数据流/ 处理/ 能力/ ./ 系统控制/ 方法/ 可以/ 分为/ 准入/ 控制/ 和/ 反馈/ 控制/ 两种/ ,/ 准入/ 控制/ 方法/ 简单/ ,/ 但/ 需要/ 较/ 多/ 的/ 人工/ 参与/ 并且/ 控制策略/ 固定/ 、/ 调整/ 速度慢/ ./ 现有/ 的/ SEDA/ 线程/ 池/ 控制/ 方法/ 就/ 属于/ 此类/ ./ 反馈/ 控制/ 的/ 优势/ 在于/ 自动/ 调整/ 能力/ ,/ 文献/ [/ 19/ ]/ 通过/ PI/ 控制/ 适应性/ 的/ 调整/ 线程/ 池/ ,/ 以/ 提高/ 资源/ 利用率/ 、/ 优化/ 性能/ ,/ 文献/ [/ 20/ ]/ 基于/ 自动/ agent/ ,/ 通过/ 附加/ 调整/ 参数/ 对/ MIMO/ 系统/ 进行/ 优化/ 控制/ ./ 本文/ 以/ 反馈/ 控制/ 方式/ 改造/ 了/ SEDA/ 控制/ 方法/ ,/ 与/ 上述/ Page13/ 工作/ 相比/ ,/ 通过/ 分析/ 系统/ 输入输出/ 参数/ 与/ 控制参数/ 的/ 关系/ ,/ 确定/ 控制目标/ 和/ 控制/ 方式/ ,/ 使得/ 对批/ 大小/ 和/ 线程/ 池/ 的/ 控制/ 更为/ 准确/ ./ 此外/ ,/ 本/ 工作/ 在线/ 程池/ 控制/ 中/ 利用/ CPU/ 使用/ 信息/ 进行/ 各个/ 阶段/ 的/ 全局/ 控制/ ,/ 使/ CPU/ 得到/ 了/ 充分/ 有效/ 利用/ ,/ 提高/ 了/ 数据流/ 处理/ 能力/ ./ 数据流/ 处理/ 系统/ S4/ ,/ 迭代/ 系统/ Twister/ 、/ Spark/ 和/ 增量/ 处理/ 系统/ DryadInc/ 将/ 中间/ 结果/ 以/ 对象/ 或/ 键值/ 形式/ 缓存/ 在/ 本地/ 内存/ 中/ ,/ 通过/ 复用/ 提高/ 实时处理/ 能力/ ./ 然而/ ,/ 上述/ 工作/ 都/ 没有/ 着重/ 解决/ 中间/ 结果/ 内存/ 结构/ 的/ 高/ 并发/ 读写/ 性能/ 问题/ ./ Metis/ 采用/ HashB/ +/ 树结构/ 存储/ 中间/ 结果/ ./ 与/ 对象/ 、/ Hash/ 表和树/ 等/ 结构/ 相比/ ,/ HashB/ +/ 树/ 针对/ 各种/ 负载/ 类型/ 都/ 有/ 很/ 高/ 的/ 读写/ 性能/ ./ 本文/ 在/ HashB/ +/ 树/ 基础/ 上/ ,/ 通过/ 消除/ 阶段/ 化/ 流水线/ 中/ Map/ 和/ Reduce/ 线程/ 间/ 的/ 读写/ 同步/ 进一步/ 优化/ 中间/ 结果/ 的/ 并发/ 读写/ 性能/ ./ 此外/ ,/ 上述/ 工作/ 的/ 中间/ 结果/ 规模/ 受制于/ 内存容量/ ,/ 没有/ 充分利用/ 本地/ 存储/ (/ 包括/ 外存/ )/ 的/ 数据/ 存储/ 能力/ ,/ 文献/ [/ 21/ ]/ 在/ 外存/ 上/ 建立/ 了/ 历史数据/ 中间/ 结果/ 存储/ ,/ 但/ 由于/ 采用/ 抽样/ 方法/ 丢失/ 了/ 部分/ 历史数据/ ,/ 所以/ 主要/ 用于/ 针对/ 历史数据/ 的/ 聚集/ 查询/ ,/ 不/ 支持/ 数据流/ 同/ 历史数据/ 实时/ 计算所/ 需/ 的/ 随机/ 查询/ ./ 本文/ 基于/ SSTable/ 结构/ 建立/ 了/ 键值/ 类型/ 历史数据/ 中间/ 结果/ 的/ 外存/ 文件/ ./ 然而/ ,/ 现有/ 基于/ SSTable/ 的/ 文件/ 读写/ 策略/ [/ 9/ ]/ 只是/ 对/ 写/ 操作/ 进行/ 优化/ ,/ 读/ 开销/ 较大/ ,/ 应对/ 频繁/ 发生/ 并且/ 比例/ 均衡/ 的/ 中间/ 结果/ 读取/ 和/ 写入/ 操作/ ,/ 具有/ 一定/ 盲目性/ ./ 另外/ ,/ 从/ 提高/ 内外/ 存/ 替换/ 命中率/ 角度/ ,/ 现有/ 的/ LRU/ 、/ clock/ 等/ 替换算法/ [/ 11/ ]/ 没有/ 充分利用/ 阶段/ 化/ 流水线/ 缓冲区/ 中/ 包含/ 的/ 将要/ 访问/ 的/ 表项/ 信息/ ,/ 制约/ 了/ 替换/ 命中率/ ./ 本文/ 利用/ 读写/ 开销/ 估算/ 和/ 缓冲区/ 信息/ 改造/ 外存/ 文件/ 读写/ 策略/ 和/ 内外/ 存/ 替换算法/ ,/ 进一步/ 优化/ 了/ 中间/ 结果/ 的/ 高/ 并发/ 读写/ 性能/ ./ 7/ 结束语/ 物/ 联网/ 环境/ 下/ 针对/ 高速/ 数据流/ 的/ 大规模/ 数据处理/ 难点/ 在于/ 伸缩性/ 和/ 实时性/ 两/ 方面/ 的/ 需求/ ,/ 本文/ 提出/ 了/ 一种/ 支持/ 此类/ 数据处理/ 的/ RTMR/ 方法/ ,/ 其/ 创新性/ 主要/ 表现/ 在/ :/ (/ 1/ )/ 通过/ 中间/ 结果/ 分布/ 缓存/ 和/ 本地/ 阶段/ 化/ 流水线/ 技术/ ,/ 改进/ 了/ MapReudce/ 的/ 数据流/ 实时处理/ 能力/ ./ (/ 2/ )/ 根据/ 系统/ 参数/ 控制/ 本地/ 阶段/ 化/ 流水线/ ,/ 使/ CPU/ 得到/ 了/ 充分/ 、/ 有效/ 利用/ ,/ 提高/ 了/ 实时处理/ 能力/ ./ (/ 3/ )/ 通过/ 改造/ 内外/ 存/ 数据结构/ 、/ 读写/ 策略/ 和/ 替换算法/ ,/ 优化/ 了/ 本地/ 中间/ 结果/ 的/ 高/ 并发/ 读写/ 性能/ ./ 基于/ 实际/ 物/ 联网/ 环境/ 的/ 基准/ 测试表明/ RTMR/ 方法/ 能够/ 保障/ 大规模/ 历史数据/ 上/ 数据流/ 处理/ 的/ 实时性/ 和/ 可伸缩性/ ,/ 具有/ 很/ 高/ 的/ 应用/ 价值/ ./ 在/ RTMR/ 方法/ 中/ ,/ 单个/ 节点/ 处理/ 能力/ 的/ 提升/ 是/ 集群/ 可伸缩性/ 的/ 基础/ ,/ 因此/ 本文/ 主要/ 解决/ 本地/ 优化/ 问题/ ./ 下/ 一步/ 工作/ 主要/ 针对/ RTMR/ 可伸缩性/ 保障/ 中/ 的/ 关键问题/ —/ —/ —/ 负载/ 均衡/ ,/ 包括/ 异构/ 工作/ 节点/ 上/ 的/ 中间/ 结果/ 数据分布/ 和/ 动态/ 负载/ 调度/ ./ 

