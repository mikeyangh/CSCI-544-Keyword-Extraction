Page1Nimble/ :/ 一种/ 适用/ 于/ OpenFlow/ 网络/ 的/ 快速/ 流/ 调度/ 策略/ 李龙/ 1/ )/ ,/ 2/ )/ 付斌章/ 2/ )/ 陈明宇/ 1/ )/ ,/ 2/ )/ 张/ 立新/ 1/ )/ ,/ 2/ )/ 1/ )/ (/ 中国科学院/ 大学/ 北京/ 100049/ )/ 2/ )/ (/ 中国科学院计算技术研究所/ 计算机/ 体系结构/ 国家/ 重点/ 实验室/ 北京/ 100190/ )/ 摘要/ 突发/ 流量/ 是/ 导致/ 网络/ 拥塞/ 和/ 丢/ 包/ 的/ 重要/ 原因/ 之一/ ./ 减少/ 网络/ 拥塞/ 的/ 一种/ 方法/ 是/ 在/ 多条/ 可/ 达/ 路径/ 间/ 均衡/ 网络流量/ ,/ 如/ 等价/ 多路径/ (/ Equal/ -/ CostMulti/ -/ Path/ ,/ ECMP/ )/ 路由/ ./ 然而/ ,/ 大多数/ 等价/ 多路径/ 路由/ 或者/ 静态/ 地/ 将/ 不同/ 的/ 流/ // 数据包/ 哈希/ 到/ 不同/ 的/ 路径/ ,/ 或者/ 依赖于/ 局部/ 的/ // 过时/ 的/ 路径/ 状态/ 信息/ ./ OpenFlow/ 技术/ 利用/ 集中式/ 控制器/ 控制/ 网络/ 行为/ ,/ 为/ 控制器/ 根据/ 全局/ 网络/ 状态/ 信息/ 进行/ 动态/ 的/ 数据流/ 优化/ 提供/ 了/ 可能/ ./ 然而/ ,/ 采用/ 基于/ 轮询/ 的/ 网络/ 状态/ 探测/ 机制/ 在/ 处理/ 突发/ 流量/ 问题/ 上/ 面临/ 诸多困难/ ./ 文中/ 提出/ 一种/ 用于/ OpenFlow/ 网络/ 的/ 快速/ 流/ 调度/ 策略/ ,/ 称为/ Nimble/ ./ Nimble/ 架构/ 扩展/ 了/ OpenFlow/ 协议/ 的/ packet/ -/ in/ 消息/ ,/ 由/ 网络设备/ 自主/ 监测/ 设备/ 状态/ ,/ 并/ 在/ 网络/ 出现/ 拥塞/ 时/ 通过/ 扩展/ 的/ packet/ -/ in/ 消息/ 主动/ 向/ 控制器/ 通告/ 拥塞/ 信息/ ./ 模拟/ 结果显示/ Nimble/ 策略/ 能够/ 以/ 近于零/ 的/ 时延/ 检测/ 网络/ 链路/ 拥塞/ ,/ 从而/ 有效/ 提高/ 网络/ 性能/ ./ 关键词/ 数据中心/ 网络/ ;/ OpenFlow/ ;/ 流/ 调度/ ;/ 负载/ 均衡/ 1/ 引言/ 近年来/ ,/ 以/ Web/ 搜索/ 、/ 社交/ 网络/ 、/ 电子商务/ 、/ 云/ 存储/ 和/ 云/ 计算/ 等/ 为/ 代表/ 的/ 网络应用/ 正/ 处于/ 高速/ 发展/ 阶段/ ./ 网络应用/ 的/ 发展/ 、/ 壮大/ 推动/ 网络应用/ 服务提供商/ 在/ 全球/ 范围/ 内/ 建立/ 数量/ 众多/ 的/ 数据中心/ ./ 当今/ ,/ 数据中心/ 中/ 通常/ 包含/ 数百万/ 服务器/ 节点/ [/ 1/ ]/ ,/ 并且/ 通过/ 数据中心/ 网络/ 实现/ 服务器/ 节点/ 间/ 的/ 通信/ ./ 为了/ 高效/ 地/ 互连/ 数量/ 庞大/ 的/ 服务器/ 节点/ ,/ 研究/ 人员/ 提出/ 了/ 许多/ 新/ 的/ 网络/ 架构/ ,/ 如/ FatTree/ [/ 1/ ]/ 、/ Drag/ -/ onfly/ [/ 2/ ]/ 、/ BCube/ [/ 3/ ]/ 、/ Jellyfish/ [/ 4/ ]/ 、/ VL2/ [/ 5/ ]/ 以及/ DCell/ [/ 6/ ]/ 等/ ./ 这些/ 网络/ 架构/ 在/ 网络/ 核心/ 提供/ 多条/ 可/ 达/ 路径/ ./ 也就是说/ ,/ 服务器/ 通信/ 对间/ 存在/ 多条/ 可/ 达/ 路径/ ./ 利用网络/ 架构/ 的/ 多路径/ ,/ 数据中心/ 网络管理员/ 通过/ 在/ 多条/ 可/ 达/ 路径/ 间/ 均衡/ 网络/ 负载/ 的/ 方式/ 提高/ 网络/ 性能/ ./ 按照/ 路由/ 算法/ 在/ 进行/ 路由/ 决策/ 时/ 是否/ 考虑/ 当前/ 的/ 网络/ 状态/ ,/ 多路径/ 路由/ 算法/ 可以/ 分为/ 两大类/ :/ 无类/ 路由/ 算法/ (/ obliviousrouting/ )/ 和/ 自/ 适应/ 路由/ 算法/ (/ adaptiverouting/ )/ ./ 无类/ 路由/ 算法/ 在/ 进行/ 路由/ 决策/ 时/ 不/ 考虑/ 当前/ 的/ 网络/ 状态/ ,/ 如/ 最/ 短/ 路径/ 算法/ 等/ ./ 与/ 之/ 相反/ ,/ 自/ 适应/ 路由/ 算法/ 在/ 对/ 数据包/ 进行/ 路由/ 决策/ 时/ ,/ 会/ 根据/ 当前/ 的/ 网络/ 状态/ 动态/ 地/ 调整/ 数据包/ 的/ 路由/ 路径/ [/ 7/ ]/ ./ 由于/ 大多数/ 多路径/ 路由/ 算法/ 对/ 数据包/ 的/ 包头/ 信息/ 执行/ 静态/ 的/ 哈希/ 计算/ ,/ 并/ 根据/ 计算/ 出/ 的/ 哈希/ 值/ 进行/ 路由/ 选择/ ①/ ,/ 而/ 不/ 考虑/ 路由/ 决策/ 时/ 的/ 网络/ 状态/ 信息/ ,/ 所以/ 此类/ 路由/ 算法/ 属于/ 无类/ 路由/ 算法/ ./ 例如/ ,/ 等价/ 多路径/ 路由/ 协议/ 对/ 数据包/ 的/ 包头/ 信息/ (/ 源/ IP地址/ 、/ 目的/ IP地址/ 、/ 源/ 端口号/ 、/ 目的/ 端口号/ 和/ 协议/ 类型/ )/ 执行/ 哈希/ 计算/ ,/ 并/ 将/ 计算/ 得到/ 的/ 哈希/ 值/ 作为/ 输出/ 端口/ 的/ 索引/ 进行/ 路由/ 选择/ ./ 对于/ 均匀/ 流量/ (/ uniformtraffic/ )/ ,/ 无类/ 路由/ 可以/ 充分利用网络/ 流量/ 的/ 均衡/ 特性/ 取得/ 较/ 好/ 的/ 网络/ 性能/ ./ 然而/ ,/ 对于/ 非/ 均匀/ 流量/ ,/ 由于/ 网络流量/ 在/ 不同/ 路径/ 上/ 的/ 非/ 均匀分布/ ,/ 无类/ 路由/ 可能/ 导致/ 严重/ 的/ 网络/ 性能/ 降低/ ./ 例如/ ,/ 将/ 网络/ 中/ 的/ 多个/ 大/ 流/ (/ elephantflow/ )/ 路由/ 到/ 相交/ 的/ 路径/ 上/ ,/ 那么/ 同一/ 链路/ 上/ 的/ 大流/ 冲突/ 会/ 导致/ 网络/ 性能/ 急剧下降/ [/ 8/ ]/ ./ 为了/ 解决/ 无类/ 路由/ 导致/ 的/ 性能/ 损失/ 问题/ ,/ 研究/ 人员/ 提出/ 最小/ 负载/ 路由/ ./ 最小/ 负载/ 路由/ 算法/ 在/ 进行/ 路由/ 决策/ 时/ ,/ 首先/ 检测/ 网络设备/ 各/ 输出/ 端口/ 的/ 负载/ 信息/ ,/ 并/ 将/ 数据包/ 通过/ 负载/ 最小/ 的/ 端口/ 转发/ ./ 因为/ 最小/ 负载/ 路由/ 根据/ 当前/ 的/ 网络/ 状态/ 进行/ 路由/ 决策/ ,/ 所以/ 最小/ 负载/ 路由/ 属于/ 自/ 适应/ 路由/ 的/ 范畴/ ./ 然而/ ,/ 由于/ 网络流量/ 的/ 突发/ 特性/ ,/ 精确/ 地/ 获取/ 每条/ 路径/ 的/ 最新/ 负载/ 信息/ 几乎/ 是/ 不可/ 实现/ 的/ ./ 因此/ ,/ 自/ 适应/ 路由/ 算法/ 通常/ 利用/ 局部/ 负载/ 信息/ 进行/ 路由/ 决策/ ./ 但是/ ,/ 利用/ 局部/ 负载/ 信息/ 所/ 做/ 的/ 路由/ 决策/ 通常/ 会/ 导致/ 全局/ 网络流量/ 分布/ 不/ 均衡/ ./ 与/ 标准/ 网络协议/ (/ 如/ 等价/ 多路径/ 路由/ 协议/ ECMP/ )/ 不同/ ,/ 软件/ 定义/ 网络/ 为/ 该/ 问题/ 提供/ 了/ 新/ 的/ 解决/ 途径/ ./ 在/ 软件/ 定义/ 网络/ 中/ ,/ 网络/ 行为/ 由/ 网络/ 控制器/ 集中控制/ ./ 网络/ 控制器/ 根据/ 全局/ 网络/ 状态/ 信息/ 调度/ 数据流/ ,/ 以/ 达到/ 优化/ 网络/ 性能/ 的/ 目的/ ./ 基于/ 软件/ 定义/ 网络/ ,/ UCSD/ 的/ 研究/ 人员/ 提出/ Hedera/ 网络/ 架构/ [/ 8/ ]/ ./ Hedera/ 利用/ 集中/ 控制器/ 检测/ 网络/ 中/ 出现/ 的/ 大流/ ,/ 同时/ 评估/ 其/ 带宽/ 需求/ ,/ 并/ 将/ 大流/ 重新/ 调度/ 到/ 满足/ 其/ 带宽/ 需求/ 的/ 低/ 负载/ 链路/ ./ 为了/ 降低/ 大/ 流/ 检测/ 的/ 开销/ ,/ Hedera/ 采用/ 基于/ 轮询/ 的/ 检测/ 策略/ ./ 例如/ ,/ Hedera/ 控制器/ 每/ 5s/ 向/ 网络设备/ 发送/ 一次/ 请求/ 消息/ ,/ 并/ 接收/ 来自/ 网络设备/ 的/ 响应/ ./ 然而/ ,/ 由于/ 周期性/ 的/ 拥塞/ 检测/ 方案/ 在/ 检测/ 链路/ 拥塞/ 时/ 存在/ 时延/ ,/ 所以/ 其/ 检测/ 由/ 突发/ 流量/ 导致/ 的/ 拥塞/ 时/ 效率/ 低下/ :/ (/ 1/ )/ 当/ 网络/ 中/ 发生/ 链路/ 拥塞/ 时/ ,/ 由于/ 尚未/ 达到/ 检测/ 周期/ ,/ 所以/ 一直/ 延迟/ 到/ 检测/ 周期/ 到达/ 时/ 才能/ 检测/ 到/ 链路/ 拥塞/ ;/ (/ 2/ )/ 由于/ 网络流量/ 的/ 突发/ 特性/ ,/ 当/ 到达/ 拥塞/ 检测/ 周期/ 时/ ,/ 链路/ 的/ 拥塞/ 状态/ 可能/ 已经/ 发生/ 改变/ ./ 为了/ 解决/ 上述/ 基于/ 周期性/ 检测/ 的/ 策略/ 在/ 应对/ 突发/ 流量/ 时/ 的/ 低效/ 性/ 问题/ ,/ 本文/ 提出/ 一种/ 适用/ 于/ OpenFlow/ (/ 软件/ 定义/ 网络/ 的/ 一种/ 典型/ 实现/ )/ 网络/ 的/ 快速/ 流/ 调度/ 策略/ ,/ 称为/ Nimble/ ./ Nimble/ 采用/ 基于/ 陷入/ 的/ 方式/ 由/ 交换机/ ②/ 主动/ 通告/ 拥塞/ 信息/ 给/ 控制器/ ./ Nimble/ 架构/ 中/ ,/ 由/ 交换机/ 主动/ 检测/ 链路/ 是否/ 发生/ 拥塞/ ./ 当/ 交换机/ 检测/ 到/ 网络/ 链路/ 拥塞/ 时/ ,/ 交换机/ 通过/ OpenFlow/ 协议/ 中/ 的/ packet/ -/ in/ 消息/ 向/ 控制器发送/ 拥塞/ 通告/ ./ 控制器接收/ 该/ 消息/ ,/ 并/ 解析/ 消息/ 得到/ 以下/ 信息/ :/ (/ 1/ )/ 拥塞/ 发生/ 的/ 地点/ ;/ (/ 2/ )/ 导致/ 拥塞/ 的/ 网络/ 流/ ./ 通过/ 交换机/ 自主/ 检测/ 拥塞/ 并/ 主动/ 通告/ 拥塞/ 的/ 方式/ ,/ Nimble/ 可以/ 快速/ 检测/ 网络/ 拥塞/ ,/ 使/ 其/ 成为/ 解决/ 网络/ 拥塞/ ,/ 尤其/ 是/ 由/ 突发/ 流量/ 导致/ 的/ 拥塞/ 的/ 有效/ 方案/ ./ Nimble/ 架构/ 扩展/ 了/ 交换机/ 的/ 基本功能/ ,/ 以/ 支持/ 交换机/ 端的/ 拥塞/ 检测/ ./ 同时/ ,/ Nimble/ 通过/ 扩展/ OpenFlow/ 协议/ 消息/ 的/ 方式/ 实现/ 由/ 交换机/ 向/ 控制器/ 的/ 拥塞/ 信息/ 通告/ ./ Nimble/ 架构/ 中/ ,/ 交换机/ 的/ 每个/ 输出/ 端口/ 队列/ ①/ ②/ Page3/ 策略/ ;/ 关联/ 一个/ 计数器/ ,/ 用于/ 记录/ 当前/ 的/ 队列/ 长度/ ./ 当/ 计数器/ 值/ 超过/ 某个/ 既定/ 阈值/ 时/ ,/ 交换机/ 产生/ 中断/ ./ 该/ 中断/ 触发/ 拥塞/ 处理/ 例程/ ./ 拥塞/ 处理/ 例程/ 通过/ 扩展/ 的/ OpenFlow/ 消息/ 向/ 控制器/ 通告/ 拥塞/ 信息/ ./ 控制器接收/ 源自/ 交换机/ 的/ 消息/ ,/ 解析/ 消息/ 内容/ ./ 当/ 控制器/ 解析/ 该/ 消息/ 为/ 拥塞/ 通告/ 消息/ 时/ ,/ 控制器/ 为/ 拥塞/ 链路/ 上/ 的/ 大流/ 计算/ 低/ 负载/ 链路/ ,/ 并/ 将/ 其/ 调度/ 到/ 上述/ 低/ 负载/ 链路/ ./ 采用/ 由/ 交换机/ 自主/ 检测/ 链路/ 拥塞/ ,/ 并/ 主动/ 通告/ 拥塞/ 信息/ 的/ 方式/ ,/ Nimble/ 能够/ 快速/ 响应/ 网络/ 拥塞/ ,/ 并且/ 有效/ 地/ 解决/ 网络/ 中/ 由/ 突发/ 数据流/ 引发/ 的/ 链路/ 拥塞/ ./ 本文/ 的/ 主要/ 贡献/ 如下/ :/ (/ 1/ )/ 提出/ 一种/ 快速/ 解决/ 网络/ 拥塞/ 的/ 网络/ 流/ 调度/ (/ 2/ )/ 提出/ 一种/ 基于/ 陷入/ 的/ 拥塞/ 通知/ 技术/ ,/ 该/ 技术/ 通过/ 扩展/ 的/ packet/ -/ in/ 消息/ 将/ 拥塞/ 信息/ 通告/ 给/ 控制器/ ;/ (/ 3/ )/ 提出/ 一种/ 分布式/ 的/ 、/ 完全/ 可控/ 的/ 大流/ 检测/ (/ 4/ )/ 提出/ 一种/ 保证/ 路径/ 更新/ 一致性/ 的/ 方案/ ./ 本文/ 第/ 2/ 节/ 介绍/ 与/ 本文/ 相关/ 的/ 背景/ 知识/ ;/ 第/ 3/ 节/ 描述/ Nimble/ 总体/ 架构/ 并/ 讨论/ Nimble/ 的/ 具体/ 实现/ 细节/ ;/ 第/ 4/ 节/ 讨论/ Nimble/ 实现/ 过程/ 中/ 遇到/ 的/ 实践性/ 问题/ ;/ 第/ 5/ 节对/ Nimble/ 架构/ 进行/ 实验/ 评估/ ;/ 第/ 6/ 节/ 介绍/ 本文/ 的/ 相关/ 工作/ ;/ 第/ 7/ 节/ 展望/ 本文/ 的/ 未来/ 工作/ ;/ 第/ 8/ 节/ 总结/ 全文/ ./ 2/ 背景/ 介绍/ 方案/ ;/ 随着/ 网络/ 技术/ 的/ 发展/ ,/ 网络设备/ 复杂度/ 急剧/ 增加/ ./ 这/ 给/ 网络/ 的/ 维护/ 、/ 管理/ 和/ 开发/ 带来/ 极大/ 的/ 挑战/ ./ 软件/ 定义/ 网络/ 的/ 出现/ 和/ 发展/ ,/ 给/ 网络/ 操作/ 人员/ 带来/ 新/ 的/ 曙光/ ./ 同时/ ,/ 大/ 数据/ 以及/ 新/ 的/ 应用/ 框架/ 的/ 出现/ (/ 如/ MapReduce/ )/ 改变/ 了/ 数据中心/ 网络/ 的/ 负载/ 特征/ ./ 本节/ ,/ 我们/ 首先/ 回顾/ 软件/ 定义/ 网络/ 以及/ OpenFlow/ 的/ 基本概念/ ./ 随后/ ,/ 我们/ 讨论/ 数据中心/ 网络/ 负载/ 的/ 基本特征/ ,/ 并/ 基于/ 此/ 阐述/ Nimble/ 方案/ 的/ 可行性/ ./ 2.1/ OpenFlow/ 网络/ 随着/ 网络/ 技术/ 的/ 不断/ 发展/ ,/ 网络设备/ 需要/ 完成/ 越来越/ 多/ 的/ 复杂/ 功能/ ,/ 如/ 防火墙/ 、/ 网络地址/ 转换/ (/ NAT/ )/ 、/ 渗透/ 检测/ 等/ ./ 这/ 不仅/ 使得/ 网络设备/ 变得/ 越来越/ “/ 臃肿/ ”/ ,/ 同时/ 给/ 网络/ 的/ 操作/ 、/ 维护/ 和/ 开发/ 带来/ 极大/ 的/ 挑战/ ./ 首先/ ,/ 网络设备/ 的/ 复杂性/ 增加/ 了/ 硬件/ 设计/ 的/ 复杂度/ 以及/ 网络/ 操作/ 人员/ 的/ 操作/ 成本/ ./ 其次/ ,/ 传统/ 的/ 网络设备/ 采用/ 闭源/ 方式/ ,/ 不/ 公开/ 其/ 操作系统/ API/ ./ 网络设备/ 的/ 闭源性/ ,/ 使得/ 网络/ 开发人员/ 不能/ 按照/ 自己/ 的/ 意志/ “/ 随心所欲/ ”/ 地/ 控制/ 网络/ 行为/ ./ 最后/ ,/ 不同/ 的/ 网络设备/ 提供商/ 提供/ 互不/ 兼容/ 的/ 操作命令/ 接口/ ,/ 增加/ 了/ 网络/ 操作/ 人员/ 的/ 学习/ 复杂度/ ./ 软件/ 定义/ 网络/ (/ Software/ -/ DefinedNetworking/ ,/ SDN/ )/ 采用/ 控制/ 平面/ (/ controlplane/ )/ 和/ 数据/ 平面/ (/ dataplane/ )/ 相/ 分离/ 的/ 实现/ 方案/ ,/ 给/ 用户/ 开发/ 自定义/ 网络/ 控制程序/ 提供/ 了/ 足够/ 的/ 灵活性/ 和/ 便利性/ ,/ 并且/ 有效/ 地/ 降低/ 了/ 网络设备/ 开发/ 以及/ 网络/ 维护/ 的/ 难度/ ./ 这种/ 灵活性/ 和/ 便利性/ 促使/ 越来越/ 多/ 的/ 研究/ 人员/ 参与/ 到/ 软件/ 定义/ 网络/ 的/ 研究/ 领域/ ./ OpenFlow/ 网络/ [/ 9/ ]/ ,/ 是/ 由/ 斯坦福大学/ 提出/ 的/ 一种/ 软件/ 定义/ 网络/ 典型/ 实现/ 方案/ ./ OpenFlow/ 网络/ 由/ 一个/ 或/ 多个/ 控制器/ 以及/ 大量/ 的/ OpenFlow/ 交换机/ 组成/ ./ OpenFlow/ 网络/ 中/ ,/ 交换机/ 仅/ 实现/ 转发/ 平面/ 的/ 功能/ ,/ 同时/ 将/ 复杂/ 的/ 控制/ 功能/ 转移/ 到/ 软件/ 控制器/ 实现/ ,/ 极大/ 地/ 简化/ 了/ 设备/ 实现/ 的/ 复杂度/ ./ 由于/ Open/ -/ Flow/ 网络/ 中/ ,/ 网络/ 的/ 控制/ 功能/ 由/ 软件/ 实现/ ,/ 所以/ 可以/ 采用/ 各种/ 成熟/ 的/ 软件工程学/ 方法/ 进行/ 软件开发/ ,/ 从而/ 简化/ 网络/ 开发/ 、/ 管理/ 的/ 复杂度/ ./ 同时/ ,/ OpenFlow/ 网络/ 采用/ OpenFlow/ 协议/ 实现/ 控制器/ 和/ 交换机/ 之间/ 的/ 交互/ ,/ 为/ 上层/ 网络/ 开发人员/ 提供/ 统一/ 的/ 编程/ 接口/ ./ 根据/ OpenFlow/ 交换机/ 规范/ ①/ ,/ OpenFlow/ 交换机/ 由流表/ 、/ 安全/ 信道/ 和/ OpenFlow/ 协议/ 3/ 个/ 主要/ 部分/ 组成/ ./ 图/ 1/ 展示/ 了/ OpenFlow/ 网络/ 的/ 基本/ 组成/ ./ OpenFlow/ 控制器/ 用于/ 实现/ 管理网络/ 行为/ 的/ 各种/ 应用/ ,/ 如/ 拓扑/ 收集/ 、/ 路由/ 、/ 防火墙/ 、/ NAT/ 等/ ./ OpenFlow/ 交换机/ 的/ 软件/ 层/ 主要/ 实现/ 安全/ 信道/ 和/ OpenFlow/ 协议/ ./ OpenFlow/ 控制器/ 使用/ OpenFlow/ 协议/ 并/ 通过/ 安全/ 信道/ 同/ 交换机/ 交互/ 信息/ ./ 交换机/ 硬件/ 主要/ 实现/ 数据/ 包转发/ ./ OpenFlow/ 交换机/ 的/ 流表由流/ 表项/ 组成/ ./ 每个/ 流/ 表项/ 包含/ 头域/ 、/ 相关/ 的/ 计数器/ 以及/ 作用/ 于/ 匹配/ 该流/ 表项/ 的/ 数据包/ 的/ 动作/ ./ 如图/ 1/ 所示/ ,/ 头域/ 为/ 十元/ 组/ 信息/ ②/ ,/ 用于/ 匹配/ 特定/ 的/ 数据包/ ./ 流/ 表项/ 中/ 的/ 计数器/ 统计/ 匹配/ 该/ 表项/ 的/ 数据包/ 数目/ 以及/ 总/ 字节数/ ./ 操作/ 域/ 指示/ 作用/ 于/ 匹配/ 该/ 表项/ 的/ 数据包/ 的/ 行为/ ,/ 如/ 转发/ 数据包/ 到/ 指定/ 端口/ 、/ 转发/ 数据包/ 到/ 控制器/ 、/ 丢弃/ 数据包/ 、/ 按照/ 常规/ 二/ 层交换机/ 功能/ 处理/ 等等/ ./ 控制器/ 通过/ 增加/ 、/ 修改/ 、/ 删除/ 流/ 表项/ 控制/ 交换机/ 的/ 行为/ ./ ①/ ②/ Page4OpenFlow/ 协议/ 支持/ 3/ 种/ 类型/ 的/ 消息/ :/ (/ 1/ )/ 控制器/ 到/ 交换机/ 的/ 消息/ ;/ (/ 2/ )/ 异步/ 消息/ ;/ (/ 3/ )/ 对称/ 消息/ ./ 控制器/ 到/ 交换机/ 的/ 消息/ 是/ 由/ 控制器发送/ 到/ 交换机/ 的/ 消息/ ,/ 通常/ 用于/ 查询/ OpenFlow/ 交换机/ 的/ 状态/ 信息/ ./ 异步/ 消息/ 由/ OpenFlow/ 交换机/ 发送到/ 控制器/ ,/ 主要/ 用于/ 更新/ 交换机/ 的/ 状态/ 信息/ ,/ 如/ 交换机/ 端口/ 状态/ 改变/ 消息/ 等/ ./ 对称/ 消息/ 可以/ 由/ OpenFlow/ 交换机/ 或者/ 控制器/ 发出/ ./ 控制器/ 通过/ OpenFlow/ 协议/ 发送/ 消息/ ,/ 从而/ 实现/ 控制/ 交换机/ 行为/ 的/ 目的/ ./ 这种/ 由/ 控制器/ 控制/ 整个/ 网络/ 行为/ 的/ 结构/ 使得/ 网络/ 的/ 管理/ 、/ 控制/ 变得/ 更加/ 简单/ 、/ 灵活/ ./ 2.2/ 数据中心/ 流量/ 特征/ 通过/ 对/ 真实/ 数据中心/ 网络流量/ 的/ 分析/ ,/ Greenberg/ 等/ 人/ [/ 5/ ]/ 和/ McKeown/ 等/ 人/ [/ 9/ ]/ 的/ 研究/ ,/ 均/ 表明/ 数据中心/ 流量/ 同/ 传统/ 的/ 局域网/ 和/ 广域网/ 流量/ 有着/ 极大/ 的/ 不同/ ./ 不同于/ 传统/ 的/ 南北/ 流量/ 模式/ ,/ 数据中心/ 网络/ 中/ ,/ 内部/ 节点/ 间/ 的/ 东西/ 流量/ (/ 数据中心/ 内部/ 节点/ 间/ 的/ 通信/ 流量/ )/ ,/ 在/ 数据中心/ 网络/ 所有/ 流量/ 中/ 占/ 主导地位/ ./ Greenberg/ 等/ 人/ [/ 5/ ]/ 指出/ ,/ 数据中心/ 中/ 80/ %/ 的/ 数据/ 流量/ 为/ 数据中心/ 内部/ 的/ 流量/ ./ 为了/ 满足/ 数据中心/ 内/ 急剧/ 增长/ 的/ 东西/ 流量/ 需求/ ,/ 当今/ 的/ 数据中心/ 网络/ ,/ 如胖树/ (/ FatTree/ )/ 网络/ [/ 1/ ]/ ,/ 通常/ 在/ 网络拓扑/ 中为/ 通信/ 节点/ 对/ 提供/ 多条/ 可/ 达/ 路径/ ,/ 以/ 增加/ 网络/ 的/ 对/ 剖/ 带宽/ (/ bisectionalbandwidth/ )/ ,/ 提高/ 网络/ 吞吐量/ ./ 不幸/ 的/ 是/ ,/ 尽管/ 数据中心/ 网络/ 采用/ 多路径/ 的/ 方法/ 提高/ 网络/ 性能/ ,/ 但是/ 由于/ 缺乏/ 有效/ 的/ 多路径/ 路由/ 协议/ ,/ 数据中心/ 网络/ 中/ 仍然/ 存在/ 链路/ 拥塞/ ,/ 特别/ 是/ 网络/ 的/ 核心层/ 链路/ [/ 10/ ]/ ./ 然而/ ,/ 尽管/ 一些/ 核心层/ 链路/ 拥塞/ 严重/ ,/ 网络/ 中/ 仍然/ 存在/ 大量/ 空闲/ 的/ 核心层/ 链路/ ./ 例如/ ,/ Benson/ 等/ 人/ [/ 10/ ]/ 指出/ ,/ 75/ %/ 的/ 核心层/ 链路/ 处于/ 未/ 充分利用/ 状态/ ./ 上述事实/ 表明/ :/ (/ 1/ )/ 解决/ 数据中心/ 网络/ 中/ 的/ 拥塞/ 问题/ 仍然/ 十分/ 重要/ ;/ (/ 2/ )/ 数据中心/ 网络/ 中/ 存在/ 大量/ 低/ 负载/ 链路/ 可以/ 用来/ 均衡/ 网络/ 负载/ ,/ 以/ 提高/ 数据中心/ 网络/ 的/ 性能/ ./ 由于/ 网络/ 中/ 存在/ 大量/ 空闲/ 链路/ ,/ 所以/ ,/ 当/ 网络/ 出现/ 拥塞/ 时/ ,/ 通过/ 将/ 拥塞/ 链路/ 上/ 的/ 数据流/ 重新/ 调度/ 到/ 低/ 负载/ 链路/ ,/ 可以/ 有效/ 地/ 解决/ 链路/ 拥塞/ 问题/ ./ 基于/ 上述/ 观察/ ,/ Nimble/ 通过/ 重新/ 调度/ 拥塞/ 链路/ 上/ 的/ 数据流/ 的/ 方法/ 解决/ 网络/ 拥塞/ 问题/ ./ 2.3/ 大流/ 标识/ 数据中心/ 网络/ 中/ ,/ 同时/ 存在/ 着/ 大流/ 和/ 小流/ ./ 通常/ 来讲/ ,/ 小流/ (/ 如/ 搜索引擎/ 的/ 查询/ 请求/ 等/ )/ 包含/ 的/ 数据量/ 小/ ,/ 带宽/ 需求/ 也/ 相对/ 较/ 小/ ./ 然而/ ,/ 其/ 对/ 网络/ 延迟/ 较为/ 敏感/ ./ 与/ 之/ 相反/ ,/ 大/ 流/ (/ 如/ 文件/ 备份/ 、/ 传输/ 等/ )/ 通常/ 包含/ 较大/ 的/ 数据量/ ,/ 并且/ 对/ 网络带宽/ 有/ 较/ 高/ 的/ 需求/ ./ 然而/ ,/ 大/ 流/ 通常/ 对/ 网络/ 延迟/ 信息/ 不/ 敏感/ ./ 为了/ 有效/ 地/ 均衡/ 大小/ 流对/ 网络带宽/ 和/ 网络/ 延迟/ 的/ 不同/ 需求/ ,/ 需要/ 进行/ 大/ 流/ 检测/ ./ 案/ [/ 11/ ]/ :/ 为了/ 检测/ 网络/ 中/ 的/ 大流/ ,/ 通常/ 可以/ 采用/ 以下/ 方/ (/ 1/ )/ 基于/ 采样/ 的/ 检测/ ./ 此/ 方案/ 中/ ,/ 集中式/ 的/ 大流/ 检测/ 程序/ 周期性地/ 向/ 交换机/ 发送/ 请求/ 信息/ ,/ 以/ 获取/ 交换机/ 所有/ 端口/ 的/ 采样/ 信息/ ./ 采样/ 信息/ 可以/ 通过/ 简单/ 网络管理/ 协议/ (/ SNMP/ )/ 获得/ ./ 采用/ 此种/ 方式/ ,/ 只/ 需要/ 采样/ 部分/ 数据包/ (/ 如/ 每/ 5min/ 执行/ 一次/ 数据包/ 采样/ )/ ,/ 并且/ 只/ 需要/ 传输/ 必要/ 的/ 包头/ 信息/ ./ 当对/ 某个/ 数据流/ 检测/ 到/ 足够/ 的/ 字节/ 后/ ,/ 将/ 该流/ 标记/ 为大流/ ./ 然而/ ,/ 基于/ 采样/ 的/ 大流/ 检测/ 策略/ 准确度/ 较/ 低/ ./ 同时/ ,/ 由于/ 采用/ 集中式/ 的/ 处理/ 策略/ ,/ 大/ 流/ 检测/ 的/ 开销/ 较大/ ./ (/ 2/ )/ 基于/ 应用/ 的/ 检测/ ./ 由于/ 开发者/ 对/ 应用程序/ 的/ 特征/ 具有/ 最为/ 准确/ 的/ 理解/ ,/ 所以/ ,/ 基于/ 应用/ 的/ 大流/ 检测/ 方案/ 准确度/ 最高/ ./ 然而/ ,/ 传统/ 的/ 应用/ 自身/ 并/ 没有/ 实现/ 大/ 流/ 检测/ 逻辑/ ./ 所以/ ,/ 为了/ 实现/ 基于/ 应用/ 的/ 大流/ 检测/ ,/ 需要/ 对/ 数据中心/ 中/ 部署/ 的/ 应用/ 进行/ 修改/ ./ 但是/ ,/ 数据中心/ 中/ 部署/ 的/ 应用/ 种类/ 繁多/ ,/ 并且/ 许多/ 应用/ 无法/ 获取/ 其/ 源代码/ ./ 所以/ ,/ 对/ 应用/ 进行/ 修改/ 以/ 支持/ 大/ 流/ 检测/ 无法/ 兼容/ 大量/ 现存/ 应用/ ./ (/ 3/ )/ 基于/ 统计/ 的/ 检测/ ./ 不同于/ 基于/ 采样/ 的/ 大流/ 检测/ 方案/ ,/ 基于/ 统计/ 的/ 检测/ 方案/ 为/ 每个/ 数据流/ 维护/ 精确/ 的/ 数据/ 统计/ ./ 该种/ 策略/ 下/ ,/ 控制器/ 周期性地/ 向/ 边缘/ 层交换机/ 发送数据/ 流/ 统计/ 请求/ ,/ 并/ 接收/ 来自/ 交换机/ 的/ 响应/ ,/ 从而/ 获取/ 各条/ 数据流/ 的/ 精确/ 数据/ 统计/ ./ Hedera/ [/ 8/ ]/ 是/ 基于/ 统计/ 的/ 大流/ 检测/ 实例/ 之一/ ./ 然而/ ,/ 基于/ 统计/ 的/ 大流/ 检测/ 策略/ 采用/ 集中式/ 方案/ ,/ 无法/ 扩展/ 到/ 大规模/ 网络/ ./ 同时/ ,/ 基于/ 统计/ 的/ 检测/ 方案/ ,/ 需要/ 交换机/ 为/ 经由/ 该/ 设备/ 的/ 每条/ 数据流/ 维护/ 一条/ 表项/ ,/ Page5/ 记录/ 该流/ 的/ 数据/ 统计/ 值/ ./ 但是/ ,/ 流/ 表表/ 项是/ 交换机/ 的/ 稀缺资源/ ,/ 为/ 每个/ 数据流/ 记录/ 统计/ 信息/ 需要/ 消耗/ 大量/ 的/ 交换机/ 资源/ ./ 另外/ ,/ 采用/ 基于/ 统计/ 的/ 大流/ 检测/ 策略/ ,/ 交换机/ 和/ 控制器/ 间/ 产生/ 大量/ 的/ 请求/ // 响应/ 消息/ ./ 在/ 带宽/ 受限/ 的/ 网络/ 中/ ,/ 这/ 需要/ 消耗/ 大量/ 的/ 带宽/ 资源/ ,/ 进而/ 加剧/ 网络/ 拥塞/ ./ 最后/ ,/ 基于/ 统计/ 的/ 大流/ 检测/ 策略/ 只有/ 到达/ 检测/ 周期/ 时/ 才能/ 检测/ 到/ 大流/ ,/ 这会/ 增加/ 大/ 流/ 检测/ 的/ 时延/ ./ 3Nimble/ 架构/ 本/ 节/ ,/ 我们/ 首先/ 介绍/ Nimble/ 的/ 总体/ 结构/ ./ 然/ 基于/ 轮询/ 的/ 拥塞/ 检测/ 机制/ ,/ 周期性地/ 向/ 交换机/ 发送/ 统计/ 请求/ 信息/ ,/ 并/ 根据/ 收到/ 的/ 响应/ 消息/ 计算/ 链路/ 负载/ ./ 然而/ ,/ 基于/ 轮询/ 的/ 拥塞/ 检测/ 策略/ 在/ 检测/ 拥塞/ 时/ 存在/ 时延/ ./ 与/ 之/ 不同/ ,/ Nimble/ 架构/ 由/ 交换机/ 自主/ 检测/ 拥塞/ ,/ 并/ 在/ 检测/ 到/ 拥塞/ 时/ 主动/ 通告/ 控制器/ ./ 控制器接收/ 到/ 拥塞/ 通告/ 后/ ,/ 将/ 拥塞/ 链路/ 上/ 的/ 数据流/ 调度/ 到/ 低/ 负载/ 链路/ ./ 后/ ,/ 讨论/ Nimble/ 的/ 具体/ 实现/ 细节/ ./ 3.1/ 总体/ 结构图/ 2/ 展示/ 了/ Nimble/ 的/ 总体/ 结构图/ ./ 如图所示/ ,/ Nimble/ 主要/ 包括/ 三个/ 模块/ :/ 拥塞/ 通知/ 模块/ 、/ 网络/ 状态/ 维护/ 模块/ (/ A/ )/ 和/ 调度/ 模块/ (/ B/ )/ ./ 拥塞/ 通知/ 模块/ 的/ 主要/ 功能/ 是/ 检测/ 网络/ 中/ 的/ 拥塞/ 状况/ ,/ 并/ 将/ 拥塞/ 信息/ 通告/ 给/ 网络/ 控制器/ ./ Nimble/ 架构/ 中/ ,/ 拥塞/ 通知/ 模块/ 实现/ 在/ OpenFlow/ 交换机/ 中/ (/ 图中/ 没有/ 单独/ 列出/ )/ ./ 不同于/ 周期性/ 轮询/ 的/ 拥塞/ 检测/ 机制/ ,/ Nimble/ 使用/ 基于/ 陷入/ 的/ 拥塞/ 检测/ 策略/ 检测/ 拥塞/ 信息/ ./ 一旦/ 检测/ 到/ 链路/ 拥塞/ ,/ 拥塞/ 通知/ 模块/ 立即/ 将/ 拥塞/ 信息/ 通告/ 给/ 网络/ 控制器/ ./ 拥塞/ 通告/ 通过/ Nimble/ 中/ 扩展/ 的/ OpenFlow/ 协议/ 消息/ 实现/ ./ OpenFlow/ 控制器/ 维护/ 当前/ 网络/ 的/ 所有/ 状态/ 信息/ ,/ 如/ 网络拓扑/ 、/ 物理/ 链路/ 利用率/ 等/ ./ 状态/ 信息/ 的/ 更新/ 和/ 维护/ 由/ 位于/ 控制器/ 中/ 的/ 网络/ 状态/ 维护/ 模块/ 完成/ ./ 接收/ 到/ 拥塞/ 通知/ 消息/ 后/ ,/ 网络/ 状态/ 维护/ 模块/ 更新/ 其/ 自身/ 的/ 状态/ 信息/ ,/ 并/ 将/ 拥塞/ 信息/ 转发/ 到/ 调度/ 模块/ ./ 调度/ 模块/ 从/ 网络/ 状态/ 维护/ 模块/ 中/ 查询/ 网络/ 状态/ 信息/ ,/ 获取/ 拥塞/ 链路/ 上/ 的/ 大流/ 信息/ ,/ 并/ 为/ 这些/ 大/ 流/ 计算/ 低/ 负载/ 路径/ ./ 最后/ ,/ 调度/ 模块/ 通过/ OpenFlow/ 协议/ 修改/ 交换机/ 表项/ ,/ 将/ 新/ 的/ 路由/ 路径/ 分发/ 到/ 相应/ 的/ 交换机/ ./ 之后/ ,/ 拥塞/ 数据流/ 的/ 后续/ 数据包/ 将/ 按照/ 新/ 的/ 路径/ 路由/ ./ 为了/ 提高/ 网络/ 性能/ ,/ 研究/ 人员/ 提出/ 许多/ 具有/ 多路径/ 的/ 网络拓扑/ ./ 数据中心/ 采用/ 此类/ 拓扑/ 提供/ 更/ 高/ 的/ 网络/ 对剖/ 带宽/ (/ bisectionalbandwidth/ )/ ./ 为了/ 简化/ 设计/ ,/ 本文/ 将/ Nimble/ 实现/ 于/ 胖树/ 拓扑/ ./ 图/ 3/ 给出/ 了/ 一个/ 具有/ 16/ 台/ 服务器/ 节点/ 的/ 胖树/ 拓扑/ 实例/ ./ 胖树/ 拓扑/ 中/ ,/ 网络设备/ 可以/ 划分/ 为/ 不同/ 的/ Pod/ ./ 图/ 3/ 中将/ 汇聚/ 层/ 和/ 边缘/ 层交换机/ 划分/ 为/ 4/ 个/ Pod/ ./ Nimble/ 架构/ 中/ ,/ 网络/ 中/ 所有/ 的/ 交换机/ 均/ 兼容/ OpenFlow/ 功能/ ./ Nimble/ 架构/ 实现/ 了/ OpenFlow/ 控制器/ ,/ 以/ 实现/ Nimble/ 的/ 管理/ 功能/ ./ 该/ 控制器/ 可以/ 运行/ 于/ 一台/ 独立/ 于/ 网络拓扑/ 的/ 服务器/ 节点/ 中/ ,/ 也/ 可以/ 运行/ 于/ 网络拓扑/ 中/ 的/ 某台/ 服务器/ 节点/ 或者/ 虚拟机/ 中/ ./ 控制器/ 维护/ 当前/ 网络/ 的/ 所有/ 信息/ ,/ 比如/ 网络拓扑/ 结构/ 、/ 链路/ 容量/ 、/ 数据流/ 路由/ 路径/ 以及/ 链路/ 利用率/ 等/ ./ 另外/ ,/ 控制器/ 决定/ 数据包/ 的/ 路由/ 路径/ ./ 对于/ 使用/ 具有/ K/ 个/ 端口/ 的/ 交换机/ 构成/ 的/ 胖树/ 拓扑/ ,/ 网络/ 中/ 包含/ K2/ // 4/ 台/ 核心/ 交换机/ [/ 1/ ]/ ./ 胖树/ 拓扑/ 中/ ,/ 任意/ 位于/ 不同/ Pod/ 的/ 源/ 、/ 目的/ 服务器/ 节点/ 间/ 存在/ K2/ // 4/ 条可达/ 路径/ ./ 每条/ 路径/ 经由/ 唯一/ 一台/ 核心/ 层交换机/ ./ 所以/ ,/ 在/ 胖树/ 拓扑/ 中/ ,/ 任意/ 通信/ 节点/ 对间/ 的/ 路径/ 可以/ 通过/ 简单/ 的/ 计算/ 获得/ ,/ 因为/ 一旦/ 确定/ 了/ Page6/ 核心/ 层交换机/ ,/ 通信/ 对间/ 的/ 路径/ 便是/ 确定/ 的/ (/ 5.1/ 节/ 评估/ 了/ 胖树/ 拓扑/ 的/ 路径/ 计算/ 开销/ )/ ./ 当/ 网络/ 规模/ 过大时/ (/ 如/ 数十万/ 服务器/ 节点/ )/ ,/ 网络/ 的/ 性能/ 受限于/ 单个/ 控制器/ 的/ 处理/ 能力/ ./ 考虑/ 到/ 扩展性/ 问题/ ,/ Nimble/ 架构/ 中/ 的/ OpenFlow/ 控制器/ 可以/ 采用/ 分布式/ 策略/ 实现/ ,/ 如/ HyperFlow/ [/ 12/ ]/ 和/ Onix/ [/ 13/ ]/ 等/ ./ 3.2/ 拥塞/ 通知/ 为了/ 实现/ 拥塞/ 通告/ ,/ 首要/ 的/ 任务/ 是/ 检测/ 网络/ 拥塞/ ./ 传统/ 的/ 网络协议/ ,/ 如/ 传输层/ 控制协议/ (/ TCP/ )/ ,/ 利用/ 终端/ 节点/ 检测/ 拥塞/ 信息/ ./ 这种/ 拥塞/ 检测/ 方案/ 存在/ 如下/ 缺点/ :/ 当/ 终端/ 节点/ 检测/ 到/ 拥塞/ 时/ ,/ 网络/ 中/ 已经/ 出现/ 拥塞/ ,/ 甚至/ 是/ 数据包/ 丢失/ ./ 更为/ 糟糕/ 的/ 是/ ,/ 网络流量/ 的/ 突发/ 特性/ 导致/ 当/ 终端/ 节点/ 检测/ 到/ 链路/ 拥塞/ 时/ ,/ 链路/ 状态/ 可能/ 已经/ 发生/ 改变/ ./ DCTCP/ [/ 14/ ]/ 在/ 交换机/ 出口/ 队列/ 长度/ 超过/ 某个/ 阈值/ (/ 比如说/ ,/ 队列/ 容量/ 的/ 80/ %/ )/ 时/ 提前/ 预测/ 拥塞/ ./ Nimble/ 采用/ 同样/ 的/ 方式/ 执行/ 拥塞/ 预测/ ,/ 如/ 过程/ 1/ 所示/ ./ 基于/ 阈值/ 检测/ 链路/ 拥塞/ 的/ 优势/ 是/ ,/ 交换机/ 不/ 需要/ 在/ 每个/ 数据包/ 到来/ 时/ 都/ 执行/ 拥塞/ 检测/ ./ 当/ 某个/ 队列/ 的/ 长度/ 超过/ 给定/ 阈值/ 时/ ,/ 交换机/ 将/ 此/ 信息/ 通告/ 给/ 控制器/ ./ 控制器接收/ 到/ 来自/ 交换机/ 的/ 通告/ 后/ ,/ 即可/ 获知/ 在/ 该/ 交换机/ 的/ 某个/ 端口/ 上/ 发生/ 了/ 拥塞/ ./ 拥塞/ 通告/ 消息/ 中/ 包含/ 导致/ 拥塞/ 的/ 端口/ 信息/ ,/ 控制器/ 可以/ 根据/ 发生/ 拥塞/ 的/ 端口/ 信息/ 计算/ 出/ 发生/ 拥塞/ 的/ 链路/ ./ 由于/ 网络/ 控制器/ 维护/ 了/ 网络/ 的/ 所有/ 信息/ ,/ 控制器/ 可以/ 推测/ 出/ 经过/ 该/ 拥塞/ 链路/ 的/ 所有/ 数据流/ ./ 为了/ 实现/ 基于/ 阈值/ 的/ 拥塞/ 通告/ 机制/ ,/ Nimble/ 扩展/ 了/ OpenFlow/ 标准/ 交换机/ 的/ 功能/ ./ Nimble/ 架构/ 中/ ,/ 为/ 交换机/ 的/ 每个/ 物理/ 端口/ 队列/ 关联/ 一个/ 计数器/ ./ 如/ 过程/ 1/ 所示/ ,/ 当/ 数据包/ 进入/ 交换机/ 的/ 某个/ 端口/ 队列/ 时/ ,/ 交换机/ 依据/ 数据包/ 的/ 大小/ 更新/ 计数器/ 值/ ./ 当/ 交换机/ 检测/ 到/ 队列/ 计/ 数值/ 超过/ 给定/ 阈值/ 时/ ,/ 产生/ 拥塞/ 信号/ ./ 拥塞/ 信号/ 触发/ 交换机/ 发送/ 本文/ 扩展/ 的/ OpenFlow/ 协议/ 消息/ 向/ 控制器/ 通告/ 拥塞/ 信息/ ./ 过程/ 1/ ./ 交换机/ 拥塞/ 通知/ 流程/ ./ 数据包/ P/ 进/ 交换机/ 端口/ 队列/ M/ // // 判断/ 数据包/ 进/ 队列/ 后/ 队列/ 长度/ 是否/ 超过/ 阈值/ // // size/ (/ )/ 函数/ 求得/ 数据包/ 的/ 字节/ 总数/ // // CurrentCount/ 表示/ 当前/ 的/ 队列/ 计数器/ 值/ CurrentCount/ +/ =/ size/ (/ P/ )/ ;/ IFCurrentCount/ >/ =/ Threshold/ // // 产生/ 拥塞/ 通知/ 消息/ OpenFlow/ 协议/ 中/ ,/ 没有/ 向/ 控制器/ 通告/ 拥塞/ 信息/ 的/ 消息/ 类型/ ./ 一种/ 简单/ 的/ 拥塞/ 信息/ 通告/ 实现/ 方式/ 是/ 定义/ 一种/ 新/ 的/ 交换机/ 和/ 控制器/ 间/ 的/ 消息/ 类型/ ./ 然而/ ,/ 定义新/ 的/ 消息/ 类型/ 需要/ OpenFlow/ 控制器/ 开发人员/ 更新/ 控制器/ 程序/ 以/ 支持/ 新/ 定义/ 的/ 消息/ 类型/ ./ 鉴于/ 此/ ,/ Nimble/ 通过/ 扩展/ OpenFlow/ 协议/ 消息/ 的/ 方式/ 实现/ 拥塞/ 信息/ 通告/ ./ OpenFlow/ 规范/ 中/ ,/ 存在/ 由/ 交换机/ 产生/ 并发/ 送到/ 控制器/ 的/ 称为/ OFPT/ _/ PACKET/ _/ IN/ 的/ 消息/ (/ 以下/ 简称/ packet/ -/ in/ 消息/ )/ ./ Packet/ -/ in/ 消息/ 用于/ 由/ 交换机/ 向/ 控制器/ 通告/ 消息/ ,/ 比如/ 流/ 表项/ 匹配/ 缺失/ 等/ ./ OFPT/ _/ PACKET/ _/ IN/ 结构/ 体中/ ,/ reason/ 域/ 用来/ 指示/ 发送/ 消息/ 的/ 原因/ ./ OpenFlow/ 协议/ 中/ ,/ reason/ 域/ 可以/ 取/ 以下/ 两种/ 值/ :/ (/ 1/ )/ OFPR/ _/ NO/ _/ MATCH/ ;/ (/ 2/ )/ OFPR/ _/ ACTION/ ./ 概括/ 地/ 讲/ ,/ OFPR/ _/ NO/ _/ MATCH/ 值/ 表明/ 数据包/ 到达/ 交换机/ ,/ 但是/ 交换机/ 的/ 流表中/ 没有/ 可以/ 同该/ 数据包/ 相匹配/ 的/ 流/ 表项/ ./ OFPR/ _/ ACTION/ 值/ 表明/ 流/ 表项/ 的/ 操作/ 域/ 指示/ 将/ 该/ 数据包/ 发送到/ 控制器/ ./ 本文/ 中/ ,/ Nimble/ 通过/ 在/ reason/ 域/ 中/ 定义新/ 的/ 取值/ OFPR/ _/ CONGESTION/ 的/ 方式/ 扩展/ 标准/ 的/ packet/ -/ in/ 消息/ ./ 图/ 4/ 显示/ 了/ 扩展/ 的/ packet/ -/ in/ 消息/ 的/ reason/ 域/ ./ 当/ 交换机/ 检测/ 到/ 拥塞/ 时/ ,/ 其/ 发送/ packet/ -/ in/ 消息/ 给/ 控制器/ ./ 该/ 消息/ 的/ reason/ 域/ 赋值/ 为/ OFPR/ _/ CONGESTION/ ,/ 表明/ 发送/ 该/ 消息/ 的/ 原因/ 是/ 链路/ 发生/ 拥塞/ ./ 控制器接收/ 到/ 该/ 消息/ 后/ ,/ 通过/ 解析/ 消息/ 的/ reason/ 域/ ,/ 可以/ 获知/ 网络/ 中/ 相应/ 的/ 链路/ 出现/ 拥塞/ ./ 之后/ ,/ 控制器/ 可以/ 根据/ 其/ 维护/ 的/ 网络/ 信息/ 推测/ 出该/ 拥塞/ 的/ 所有/ 相关/ 信息/ ,/ 包括/ 拥塞/ 发生/ 的/ 地点/ 以及/ 该/ 拥塞/ 链路/ 上/ 的/ 数据流/ 等等/ ./ 采用/ 扩展/ 协议/ 的/ 方式/ ,/ 只/ 需要/ 更改/ 拥塞/ 处理程序/ ,/ 增加/ 解析/ 、/ 处理/ 该/ reason/ 域/ 的/ 逻辑/ ,/ 而/ 不/ 需要/ 对/ 控制器/ 底层/ 代码/ 进行/ 修改/ ./ 3.3/ 流/ 调度/ 如/ 3.1/ 节/ 所述/ ,/ 对于/ 包含/ K/ 个/ Pod/ 的/ 胖树/ 网络/ ,/ 网络/ 中/ 存在/ K2/ // 4/ 台/ 核心/ 交换机/ ./ 其中/ ,/ 每个/ 核心/ 层交换机/ 对应/ 于/ 服务器/ 节点/ 对间/ 的/ 一条/ 通信/ 路径/ ./ 也就是说/ ,/ 对于/ 有/ K/ 个/ pod/ 的/ 胖树/ 拓扑/ ,/ 不同/ 的/ 通信/ 节点/ 对间/ 存在/ K2/ // 4/ 条可达/ 路径/ (/ 针对/ 源/ 、/ 目的/ 节点/ 位于/ 不同/ Pod/ 的/ 通信/ 对/ )/ ./ 胖树/ 网络/ 的/ 路径/ 多样性/ ,/ 给/ 我们/ 将/ 拥塞/ 链路/ 上/ 的/ 数据流/ 重新/ 调度/ 到/ 新/ Page7/ 的/ 低/ 负载/ 链路/ 提供/ 了/ 理论/ 支持/ ./ 为了/ 实现/ Nimble/ 的/ 拥塞/ 数据流/ 重/ 调度/ 功能/ ,/ 需要/ 解决/ 两大/ 主要/ 难题/ :/ (/ 1/ )/ 拥塞/ 发生/ 时/ 对/ 哪条/ 数据流/ 进行/ 重新/ 调度/ ;/ (/ 2/ )/ 如何/ 调度/ 这些/ 数据流/ ./ 考虑/ 到/ 数据中心/ 网络/ 中/ 存在/ 大量/ 的/ 网络/ 数据流/ (/ 如/ 数以百万计/ 的/ 数据流/ )/ ,/ 对/ 拥塞/ 链路/ 上/ 的/ 所有/ 数据流/ 进行/ 重/ 调度/ 的/ 开销/ 极大/ ./ Curtis/ 等/ 人/ [/ 11/ ]/ 在/ Mahout/ 中/ 指出/ ,/ 一种/ 可行/ 的/ 方案/ 是/ 只/ 对/ 数据中心/ 中/ 的/ 大流/ 进行/ 重/ 调度/ ./ Hedera/ 将/ 发送数据/ 量/ 超过/ 链路/ 容量/ 10/ %/ 的/ 数据流/ 认为/ 是/ 大流/ ./ Hedera/ 架构/ 中/ ,/ 控制器/ 周期性地/ 向/ 边缘/ 层交换机/ 发送/ 流/ 统计/ 请求/ ,/ 并/ 从/ 交换机/ 接收/ 响应/ ./ 通过/ 解析/ 响应/ 消息/ ,/ 控制器/ 可以/ 获得/ 边缘/ 交换机/ 中/ 某/ 条流/ 发送/ 的/ 数据量/ 信息/ ,/ 从而/ 检测/ 出大流/ ./ 不同于/ Hedera/ ,/ Mahout/ 通过/ 检测/ 终端/ 节点/ TCP/ 缓存/ 的/ 方式/ 检测/ 大/ 流/ [/ 11/ ]/ ./ 本文/ 中/ ,/ 我们/ 采取/ 3.4/ 节/ 所述/ 的/ 方式/ 检测/ 大流/ ./ 检测/ 到/ 大流/ 后/ ,/ 下/ 一步/ 工作/ 是/ 为/ 这些/ 大/ 流/ 选择/ 新/ 的/ 低/ 负载/ 链路/ ./ Nimble/ 采用/ 全局/ 最先/ 适应/ (/ GlobalFirstFit/ )/ 算法/ [/ 8/ ]/ 解决/ 大流重/ 调度/ 问题/ ./ 如/ 算法/ 1/ 所示/ ,/ 全局/ 最先/ 适应/ 算法/ 通过/ 迭代/ 源/ 、/ 目的/ 通信/ 对间/ 的/ 所有/ 路径/ 以/ 寻找/ 能够/ 满足/ 数据流/ 带宽/ 需求/ 的/ 路径/ ./ 如果/ 找到/ 满足/ 需求/ 的/ 路径/ ,/ 数据流/ 采用/ 该/ 路径/ 作为/ 新/ 的/ 传输/ 路径/ ./ 否则/ ,/ 数据流/ 仍然/ 在/ 原始/ 路径/ 路由/ ./ 在/ 采用/ 新/ 路径/ 的/ 情形/ 下/ ,/ 控制器/ 将/ 新/ 的/ 路由/ 路径/ 安装/ 到/ 相应/ 交换机/ 的/ 流表中/ ./ Nimble/ 通过/ 4.1/ 节中/ 描述/ 的/ 方案/ 解决/ 路径/ 一致性/ 问题/ ./ 算法/ 1/ ./ 全局/ 最先/ 适应/ 算法/ ./ 输入/ :/ 网络拓扑/ Topo/ 以及/ 数据流/ F/ 输出/ :/ 满足/ 流/ F/ 需求/ 的/ 路径/ PFORALLswitch/ 属于/ 核心/ 层交换机/ // // 利用/ switch/ 计算/ 源/ 、/ 目的/ 节点/ 对间/ 的/ 路径/ path/ =/ computPath/ (/ switch/ ,/ Topo/ ,/ F/ )/ ;/ Found/ =/ True/ ;/ FORALLlink/ 属于/ 路径/ pathIF/ (/ Found/ )/ RETURNNULL/ ;/ 3.4/ 大流/ 检测/ 如/ 3.3/ 节/ 所述/ ,/ 可行/ 的/ 流/ 调度/ 方案/ 是/ 仅/ 对/ 网络/ 中/ 的/ 大流/ 进行/ 重/ 调度/ ./ 这/ 就/ 要求/ Nimble/ 能够/ 有效/ 地/ 检测/ 大流/ ./ 集中式/ 大/ 流/ 检测/ 方案/ 实现/ 简单/ ,/ 但是/ 当/ 网络/ 规模/ 较大/ 时/ ,/ 其/ 扩展性/ 较差/ ./ 现有/ 的/ 体系/ 中/ ,/ 数据中心/ 通常/ 为/ 单个/ 组织/ 所/ 拥有/ ./ 所以/ ,/ 数据中心/ 管理员/ 对/ 其/ 内部/ 采用/ 的/ 操作系统/ // 虚拟机/ 管理软件/ (/ Hypervisor/ ,/ 如/ Xen/ 、/ KVM/ 等/ )/ 拥有/ 完全/ 的/ 自主/ 控制权/ ./ 为了/ 有效/ 地/ 利用/ 资源/ ,/ 当今/ 的/ 数据中心/ 通常/ 采用/ 虚拟化/ 技术/ 提高/ 资源/ 利用率/ ./ 采用/ 虚拟化/ 技术/ 后/ ,/ 用户/ 可以/ 自主/ 选择/ 其/ 运行/ 系统/ 的/ 协议/ 栈/ 版本/ ,/ 甚至/ 是/ 自主/ 选择/ 其所/ 运行/ 的/ 操作系统/ ./ 所以/ ,/ 采用/ 在/ 操作系统/ 或者/ 利用/ 协议/ 栈/ 检测/ 大流/ 的/ 方式/ ,/ 恶意/ 用户/ 可以/ 改变/ 大/ 流/ 检测/ 的/ 原有/ 行为/ ./ 考虑/ 到/ 以上/ 因素/ ,/ 本文/ 提出/ 一种/ 新/ 的/ 大流/ 检测/ 方案/ ./ 该/ 方案/ 中/ ,/ 大/ 流/ 检测/ 逻辑/ 作为/ 虚拟机/ 管理软件/ (/ Hypervisor/ )/ 的/ 模块/ 实现/ ./ 对于/ 不/ 采用/ 虚拟/ 技术/ 的/ 数据中心/ ,/ 该大流/ 检测/ 逻辑/ 可以/ 作为/ 操作系统/ 的/ 内核模块/ 实现/ ./ 由于/ 数据中心/ 所有者/ 对/ 其/ 所/ 采用/ 的/ 虚拟机/ 管理软件/ 有着/ 完全/ 的/ 控制权/ ,/ 所以/ ,/ 将/ 大流/ 检测/ 逻辑/ 实现/ 于/ 虚拟机/ 管理软件/ 可以/ 保证/ 数据中心/ 所有者/ 对大流/ 检测/ 的/ 完全/ 控制/ ,/ 以/ 避免/ 恶意/ 用户/ 的/ 破坏/ ./ 同时/ ,/ 采用/ 分布式/ 的/ 实现/ 方案/ ,/ 保证/ 其/ 可以/ 扩展/ 到/ 具有/ 数十万/ 台/ 服务器/ 节点/ 的/ 网络/ ./ 本文/ 采用/ 的/ 大流/ 检测/ 算法/ 如/ 算法/ 2/ 所示/ ./ 算法/ 2/ ./ 大流/ 检测/ 算法/ ./ 输入/ :/ 数据包/ pkt/ 输出/ :/ 数据包/ pkt/ 所属/ 的/ 流/ 是否/ 为大流/ ret/ =/ FALSE/ ;/ bucket/ =/ hashValue/ (/ pkt/ )/ ;/ flow/ =/ findIndex/ (/ bucket/ ,/ pkt/ )/ ;/ flow/ -/ >/ bytes/ +/ =/ size/ (/ pkt/ )/ ;/ IFflow/ -/ >/ bytes/ >/ =/ THRESHOLDret/ =/ TRUE/ ;/ now/ =/ kernel/ _/ now/ (/ )/ ;/ IFnow/ -/ flow/ -/ >/ time/ >/ =/ dtflow/ -/ >/ time/ =/ now/ ;/ flow/ -/ >/ bytes/ =/ 0/ ;/ RETURNret/ ;/ 如/ 算法/ 2/ 所示/ ,/ 对于/ 接收/ 到/ 的/ 数据包/ ,/ 大/ 流/ 检测/ 算法/ 计算/ 该/ 数据包/ 的/ 哈希/ 值/ ,/ 并/ 根据/ 计算/ 得到/ 的/ 哈希/ 值/ 在/ 对应/ 的/ 哈希/ 链中/ 查找/ 数据包/ 所属/ 的/ 数据流/ 信息/ ./ 之后/ ,/ 更新/ 该流/ 收到/ 的/ 字节/ 计/ 数值/ ./ 如果/ 该/ 周期/ 内/ ,/ 该流/ 发送/ 的/ 字节/ 总数/ 超过/ 给定/ 阈值/ THRESHOLD/ ,/ 则/ 标记/ 该流/ 为/ 大流/ ,/ 并/ 设置/ 函数/ 的/ 返回值/ 为/ 真/ ./ 最后/ ,/ 获取/ 系统/ 的/ 当前/ 时间/ ,/ 并/ 将/ 当前/ 时间/ 和/ 该/ 流/ 的/ 检测/ 周期/ 起始/ 时间/ 进行/ 比较/ ,/ 若/ 当前/ 时间/ 和/ 该/ 流/ 的/ 周期/ 起始/ 时间/ 之间/ 的/ 差值/ 大于/ 既定/ 值/ dt/ ,/ 则/ 将/ 该/ 流/ 的/ 周期/ 起始/ 时间/ 设/ 为/ 当前/ 时间/ ,/ 并/ 清空/ 该流/ 的/ 字节/ 统计/ ./ Page8/ 终端/ 节点/ 检测/ 到/ 大流/ 后/ ,/ 需要/ 将/ 大流/ 信息/ 通告/ 给/ 控制器/ ./ 一种/ 简单/ 的/ 实现/ 方式/ 是/ 由/ 终端/ 节点/ 直接/ 将/ 大流/ 信息/ 通告/ 给/ 控制器/ ./ 大/ 流通/ 告/ 信息/ 中/ ,/ 只/ 需要/ 包含/ 能够/ 识别/ 大流/ 的/ 必要/ 信息/ (/ 比如/ ,/ 如果/ 使用/ 数据包/ 的/ 五元/ 组/ 信息/ 标识/ 数据流/ ,/ 则/ 只/ 需/ 将/ 标识/ 该流/ 的/ 五元/ 组/ 信息/ 发送给/ 控制器/ )/ ./ 然而/ ,/ 终端/ 节点/ 将/ 大流/ 直接/ 通告/ 给/ 控制器/ 的/ 方式/ ,/ 面临/ 以下/ 问题/ :/ (/ 1/ )/ 破坏/ 了/ 控制器/ 只/ 和/ 交换机/ 交互/ 的/ 工作/ 方式/ ;/ (/ 2/ )/ 在/ 某些/ 网络/ 中/ ,/ 终端/ 节点/ 可能/ 和/ 控制器/ 之间/ 没有/ 逻辑/ 相连/ 链路/ ./ 为了/ 解决/ 以上/ 两个/ 问题/ ,/ 本文/ 采用/ 图/ 5/ 大流/ 检测/ 表项/ 实例/ (/ 图中/ xx/ 表示/ 该域/ 可以/ 匹配/ 任意/ 值/ )/ 当/ 终端/ 通过/ 大/ 流/ 检测/ 算法/ 检测/ 到/ 某条/ 流为/ 大流时/ ,/ 大/ 流/ 检测/ 模块/ 构造/ 一个/ 新/ 的/ 数据包/ ,/ 并/ 将/ 其/ 发送到/ 与/ 之/ 相连/ 的/ 边缘/ 层交换机/ ./ 该/ 数据包/ 的/ 源/ 端口号/ 置/ 为/ 零/ ./ 由于/ 零值源/ 端口号/ 为/ 保留值/ ,/ 所以/ ,/ 网络/ 中/ 不会/ 出现/ 源/ 端口号/ 为/ 零/ 的/ 正常/ 数据包/ ./ 为了/ 能够/ 得到/ 该/ 数据流/ 的/ 标识/ 信息/ ,/ 数据包/ 负载/ 中/ 包含/ 标识/ 该流/ 的/ 完备/ 信息/ (/ 如该/ 流/ 的/ 五元/ 组/ 信息/ )/ ./ 交换机/ 匹配/ 该/ 数据包/ 后/ ,/ 按照/ 该/ 表项/ 对应/ 的/ 操作/ 域/ 信息/ ,/ 将/ 数据包/ 发送到/ 控制器/ ./ 控制器接收/ 到/ 该/ 数据包/ 后/ ,/ 解析/ 数据包/ ,/ 并/ 从/ 数据包/ 的/ 负载/ 信息/ 中/ 解析/ 该流/ 的/ 完整/ 标识/ 信息/ ./ 进而/ ,/ 控制器/ 可以/ 检测/ 出/ 网络/ 中/ 的/ 大流/ ./ 4/ 实践/ 分析/ 除了/ 上述/ Nimble/ 实现/ 的/ 技术/ 方案/ 外/ ,/ Nimble/ 实现/ 过程/ 中/ 还/ 存在/ 一些/ 实践性/ 问题/ ,/ 包括/ 路径/ 更新/ 一致性/ 问题/ 和/ 可行性/ 分析/ ./ 本节/ ,/ 我们/ 首先/ 分析/ Nimble/ 实现/ 过程/ 中/ 遇到/ 的/ 这些/ 实践性/ 问题/ ./ 然后/ ,/ 在/ 本节/ 结束/ ,/ 我们/ 将/ 通过/ 一个/ 具体/ 的/ 工作/ 实例/ ,/ 更加/ 清晰/ 的/ 展示/ Nimble/ 处理/ 链路/ 拥塞/ 的/ 流程/ ./ 4.1/ 路径/ 更新/ 如/ 3.1/ 节/ 所述/ ,/ 当/ 网络/ 中/ 出现/ 拥塞/ 时/ ,/ Nimble/ 控制器/ 需要/ 对/ 拥塞/ 链路/ 上/ 的/ 大流/ 进行/ 重新/ 的/ 路由/ 计算/ ,/ 并/ 将/ 新/ 的/ 路由/ 路径/ 安装/ 到/ 相应/ 的/ 交换机/ 流表中/ ./ 然而/ ,/ 控制器/ 对/ 交换机/ 流表/ 的/ 修改/ 是/ 异步/ 的/ ,/ 即/ 控制器/ 只/ 负责/ 发出/ 流表/ 修改/ 消息/ ,/ 并/ 不/ 保证/ 流表/ 信息/ 已/ 了/ Curtis/ 等/ 人/ [/ 11/ ]/ 提出/ 的/ 方案/ ,/ 由/ OpenFlow/ 交换机/ 向/ 控制器/ 通告/ 大/ 流/ 信息/ ./ 该/ 方式/ 下/ ,/ 缺省/ 地为/ 所有/ 边缘/ 层交换机/ 安装/ 具有/ 最/ 低优先级/ 的/ 默认/ 表项/ ,/ 如图/ 5/ 所示/ ./ Curtis/ 等/ 人/ 的/ 方案/ 通过/ 匹配/ IP/ 包头/ 中/ 的/ tos/ 域/ 检测/ 大/ 流通/ 告/ 数据包/ ./ 与/ 之/ 不同/ ,/ 本文/ 通过/ 匹配/ 数据包/ 的/ 源/ 端口/ 是否/ 为/ 零/ 检测/ 大/ 流通/ 告/ 数据包/ ./ 根据/ OpenFlow/ 规范/ 说明/ ,/ tos/ 域/ 并/ 不是/ OpenFlow/ 流表/ 必须/ 支持/ 的/ 匹配/ 项/ ./ 为了/ 达到/ 普遍/ 适用性/ 的/ 目的/ ,/ 本文/ 中/ 采用/ 匹配/ 源/ 端口/ 是否/ 为/ 零/ 的/ 方式/ 检测/ 大/ 流通/ 告/ 数据包/ ,/ 如图/ 5/ 所示/ ./ 经/ 被/ 交换机/ 正确处理/ ./ 所以/ 在/ 交换机/ 流表/ 更新过程/ 中/ ,/ 可能/ 会/ 产生/ 流/ 表项/ 重复/ 缺失/ 的/ 问题/ ./ 如图/ 6/ 所示/ ,/ 路径/ S/ -/ 1/ -/ 2/ -/ 3/ -/ 4/ -/ 5/ -/ D/ 为/ 原始/ 路径/ ,/ 路径/ S/ -/ 1/ -/ 6/ -/ 7/ -/ 8/ -/ 5/ -/ D/ 为/ 更新/ 后/ 的/ 路径/ ./ 假设/ 新/ 路径/ 计算出来/ 后/ ,/ 控制器/ 按照/ 1/ -/ 6/ -/ 7/ -/ 8/ 的/ 顺序/ 安装/ 路由表/ 项/ ./ 当/ 交换机/ 和/ 控制器/ 之间/ 的/ 延迟/ 较大/ 时/ ,/ 控制器/ 首先/ 更新/ 交换机/ 1/ 上/ 的/ 流表/ 信息/ ,/ 将流/ 的/ 下/ 一/ 跳/ 更/ 改为/ 交换机/ 6/ ./ 之后/ ,/ 数据包/ 被/ 路由/ 到/ 交换机/ 6/ ,/ 但/ 此时/ 交换机/ 6/ 上/ 的/ 流表/ 信息/ 还/ 没有/ 得到/ 及时/ 的/ 更新/ ,/ 所以/ 产生/ 流/ 表项/ 缺失/ ./ 这会/ 触发/ 交换机/ 6/ 向/ 控制器/ 询问/ 路由/ 信息/ ./ 同样/ 地/ ,/ 交换机/ 7/ 、/ 8/ 也/ 会/ 向/ 控制器/ 询问/ 该流/ 的/ 路由/ 信息/ ,/ 从而/ 产生/ 重复/ 的/ 表项/ 缺失/ ./ 更为/ 糟糕/ 的/ 是/ ,/ 如果/ 交换机/ 6/ 上/ 存在/ 该流/ 的/ “/ 古老/ ”/ 的/ 路径/ 信息/ ,/ 该/ 流会/ 按照/ 交换机/ 6/ 上/ 的/ “/ 古老/ ”/ 流表/ 信息/ 进行/ 路由/ ,/ 从而/ 将/ 数据包/ 路由/ 到/ 错误/ 的/ 路径/ ./ 为了/ 解决/ 路由/ 更新/ 的/ 一致性/ 问题/ ,/ 本文/ 提出/ 一种/ 简单/ 的/ 逆向/ 路径/ 更新/ 方案/ ./ 逆向/ 路径/ 更新/ 方案/ 的/ 基本/ 过程/ 描述/ 如下/ :/ 首先/ 寻找/ 两条/ 路径/ 之间/ 不/ 相交/ 的/ 交换机/ ;/ 其后/ ,/ 按照/ 由/ 目的/ 节点/ 到源/ 节点/ 的/ 逆向/ 顺序/ 向/ 新/ 路径/ 上/ 的/ 交换机/ 安装/ 路由/ 信息/ ./ 以图/ 6/ 为例/ ,/ Page9/ 源/ 节点/ S/ 和/ 目的/ 节点/ D/ 间/ 的/ 新/ 、/ 老/ 路径/ 间/ 的/ 不/ 相交/ 交换机/ 为/ 2/ -/ 3/ -/ 4/ 和/ 6/ -/ 7/ -/ 8/ ./ 按照/ 逆向/ 路径/ 更新/ 方案/ ,/ 依次/ 在/ 交换机/ 8/ 、/ 7/ 、/ 6/ 上/ 安装/ 路由/ 信息/ ./ 最后/ ,/ 修改/ 交换机/ 1/ 中/ 的/ 表项/ 信息/ ,/ 将流/ 的/ 下/ 一/ 跳/ 交换机/ 更/ 改为/ 6/ ./ 之后/ ,/ 数据包/ 到达/ 交换机/ 1/ 时/ ,/ 按照/ 新/ 的/ 流表/ 信息/ ,/ 数据包/ 被/ 转发/ 到/ 交换机/ 6/ ./ 由于/ 后继/ 交换机/ 7/ 、/ 8/ 上/ 已经/ 安装/ 了/ 最新/ 的/ 路由/ 信息/ ,/ 该流/ 将/ 按照/ 新/ 的/ 路由/ 路径/ 转发/ ./ 4.2/ 可行性/ 分析/ Nimble/ 架构/ 采用/ 基于/ 阈值/ 的/ 方式/ 预测/ 链路/ 拥塞/ ,/ 下面/ 我们/ 分析/ 这种/ 方案/ 在/ 现有/ 网络设备/ 上/ 实现/ 的/ 可行性/ ./ 随机/ 早期/ 检测/ [/ 15/ ]/ (/ RandomEarlyDetection/ ,/ RED/ )/ 是/ 一种/ 主动/ 队列/ 管理/ (/ ActiveQueueManage/ -/ ment/ ,/ AMQ/ )/ 机制/ ./ 简单/ 地/ 讲/ ,/ 随机/ 早期/ 检测/ 方案/ 中/ ,/ 交换机/ 为/ 每个/ 端口/ 队列/ 关联/ 两个/ 阈值/ :/ Thres1/ 和/ Thres2/ ./ 交换机/ 动态/ 地/ 计算/ 队列/ 的/ 平均/ 长度/ ,/ 当/ 交换机/ 平均/ 队列/ 长度/ 超过/ Thres1/ 时/ ,/ 交换机/ 按照/ 一定/ 的/ 概率/ 丢弃/ 到达/ 该/ 队列/ 的/ 数据包/ ./ 当/ 交换机/ 平均/ 队列/ 长度/ 超过/ Thres2/ 时/ ,/ 所有/ 到达/ 该/ 队列/ 的/ 数据包/ 都/ 将/ 被/ 丢弃/ ./ 与/ 之/ 不同/ ,/ Nimble/ 架构/ 只/ 采用/ 了/ 一个/ 阈值/ ./ 另外/ ,/ 不同于/ 随机/ 早期/ 检测/ 方案/ ,/ Nimble/ 架构/ 采用/ 的/ 是/ 即时/ 队列/ 长度/ [/ 14/ ]/ ,/ 而/ 不是/ 平均/ 队列/ 长度/ ./ 随机/ 早期/ 检测/ 方案/ 采用/ 式/ (/ 1/ )/ 计算/ 队列/ 的/ 平均/ 长度/ ./ 其中/ Wq/ 为/ 公式/ 计算/ 的/ 权重/ ,/ q/ 为/ 监测/ 的/ 当前/ 队列/ 长度/ ,/ avgQ/ 为/ 计算/ 得到/ 的/ 平均/ 队列/ 长度/ ./ 由式/ (/ 1/ )/ 可以/ 得知/ ,/ 将/ 随机/ 早期/ 检测/ 方案/ 中/ 的/ 权重/ 值/ 设置/ 为/ 1/ ,/ 则/ 为/ 计算/ 队列/ 即时/ 长度/ ./ 综上所述/ ,/ Nimble/ 策略/ 在/ 当今/ 交换机/ 的/ 工程/ 实现/ 中/ ,/ 是/ 可行/ 的/ ./ 4.3/ 工作/ 实例/ 本节/ 中/ ,/ 我们/ 将/ 以/ 一个/ 具体/ 的/ 实例/ 描述/ Nimble/ 的/ 工作/ 过程/ ./ 如图/ 2/ 所示/ ,/ 假设/ 服务器/ 节点/ S/ 和/ 服务器/ 节点/ R/ 之间/ 存在/ 一条/ 大流/ F/ ./ 流/ F/ 的/ 当前/ 路径/ 为/ P/ ,/ 如图/ 中点/ 划线/ 所示/ ./ Nimble/ 的/ 拥塞/ 控制/ 流程/ 如下/ 所示/ :/ (/ 1/ )/ 时刻/ T/ ,/ 属于/ 流/ F/ 的/ 数据包/ 到达/ 标记/ 为/ 1/ 的/ 交换机/ ./ 数据包/ 进/ 队列/ 后/ ,/ 交换机/ 检测/ 到/ 对应/ 的/ 队列/ 长度/ 超过/ 指定/ 的/ 阈值/ ;/ (/ 2/ )/ 交换机/ 通过/ 3.2/ 节/ 描述/ 的/ 拥塞/ 通知/ 模块/ 给/ (/ 3/ )/ 网络/ 状态/ 维护/ 模块/ 根据上述/ 收到/ 的/ 拥塞/ 通/ 控制器发送/ 消息/ ,/ 通告/ 拥塞/ 的/ 发生/ ;/ 告/ 消息/ 更新/ 自身/ 的/ 信息/ ./ 同时/ ,/ 网络/ 状态/ 维护/ 模块/ 通过/ 3.4/ 节/ 描述/ 的/ 机制/ ,/ 检测/ 流/ F/ 为大流/ ,/ 并/ 调用/ 调度/ 模块/ ;/ (/ 4/ )/ 调度/ 模块/ 为流/ F/ 重新/ 计算/ 一条/ 新/ 的/ 路径/ P/ (/ 5/ )/ Nimble/ 控制器/ 在/ 所有/ 相关/ 的/ 交换机/ 中/ 安装/ 经过/ 上述/ 所有/ 操作/ 之后/ ,/ 该/ 数据包/ 以及/ 流/ F/ 的/ (/ 图中/ 粗/ 实线/ 所示/ )/ ,/ 并/ 通告/ 网络/ 状态/ 维护/ 模块/ ;/ 新/ 的/ 流/ 表项/ ./ 所有/ 后续/ 数据包/ 都/ 将/ 经过/ 新/ 路径/ P/ 路由/ ./ 5/ 实验/ 评估/ 由于/ 缺乏/ 物理/ OpenFlow/ 交换机/ ,/ 并且/ 需要/ 对/ 交换机/ 硬件/ 和/ 协议/ 进行/ 拓展/ ,/ 以/ 支持/ Nimble/ 的/ 功能/ ,/ 所以/ 本文/ 使用/ NS3/ 模拟器/ 对/ Nimble/ 方案/ 进行/ 模拟/ 评估/ ./ 本节/ 中/ ,/ 我们/ 阐述/ 本文/ 实验所/ 采用/ 的/ 实验/ 环境/ 以及/ 相应/ 的/ 实验/ 结果/ ./ 5.1/ 路径/ 计算/ 开销/ 当/ 网络/ 出现/ 拥塞/ 并/ 通告/ 控制器/ 后/ ,/ 控制器/ 需要/ 遍历/ 对应/ 节点/ 对间/ 的/ 所有/ 路径/ 以/ 找到/ 满足/ 通信/ 带宽/ 需求/ 的/ 路径/ ./ 然而/ ,/ 路径/ 计算/ 需要/ 时间/ 开销/ ./ 当/ 采用/ 诸如/ Dijkstra/ 算法/ 等/ 图/ 的/ 路径/ 计算/ 算法/ 时/ ,/ 路径/ 计算/ 的/ 时间/ 开销/ 极大/ ./ 例如/ ,/ 在/ 服务器/ 节点/ 数目/ 为/ 27648/ 的/ 胖树/ 拓扑/ 中/ ,/ 采用/ Dijkstra/ 算法/ 计算/ 20/ 条/ 路径/ 的/ 时间/ 约/ 为/ 60s/ ./ 这/ 将/ 严重/ 制约/ Nimble/ 方案/ 的/ 可行性/ ./ 然而/ ,/ 如/ 3.3/ 节/ 所述/ ,/ 由于/ 胖树/ 网络/ 是/ 规则/ 网络/ ,/ 所以/ 胖树/ 网络/ 中/ 任意/ 通信/ 节点/ 对间/ 的/ 路由/ 路径/ 可以/ 通过/ 简单/ 的/ 线性/ 计算/ 获得/ ./ 这样/ ,/ 在/ 胖树/ 网络/ 中/ 计算/ 可行/ 路径/ 的/ 开销/ 极小/ ,/ 确保/ Nimble/ 可以/ 快速/ 地/ 响应/ 网络/ 拥塞/ 并/ 执行/ 路径/ 更新/ ./ 本节/ 对/ 胖树/ 网络/ 中路/ 由/ 路径/ 计算/ 的/ 开销/ 进行/ 评估/ ./ 图/ 7/ 展示/ 了/ 胖树/ 拓扑/ 的/ 路径/ 计算/ 开销/ ./ 横坐标/ 为/ 胖树/ 网络/ 中/ 服务器/ 节点/ 的/ 数目/ ,/ 纵坐标/ 为/ 路径/ 计算/ 的/ 开销/ ,/ 时间/ 为/ μ/ s/ ./ 图中/ ,/ 路径/ 数目/ 表示/ 任意/ 位于/ 不同/ pod/ 的/ 节点/ 对间/ 的/ 路径/ 数目/ ./ 即/ 核心/ 层交换机/ 的/ 数目/ ./ 其中/ 最好/ 情况/ 下/ 的/ 时间/ 对应/ 于/ 第一条/ 路径/ 即/ 满足/ 数据流/ 需求/ 的/ 情形/ ;/ 最坏/ 情况/ 的/ 计算/ 时间/ 指/ 的/ 是/ 需要/ 迭代/ 所有/ 的/ 可达/ 路径/ 才能/ 找到/ 满足/ 数据流/ 需求/ 路径/ 的/ 计算/ 时间/ ./ 从/ 最好/ 情况/ 曲线/ 可以/ 看出/ ,/ 不论/ 网络/ 规模/ 为/ 多/ 大/ ,/ 迭代/ 单条/ 路径/ 的/ 时间/ 开销/ 是/ 相同/ 的/ (/ 实验/ 中约/ 为/ 20/ μ/ s/ )/ ./ 同时/ ,/ 由于/ 迭代/ 单条/ 路径/ 的/ 开销/ 是/ 相当/ 的/ ,/ 所以/ ,/ 路径/ 迭代/ 的/ 开销/ 正比/ 于/ 所要/ 迭代/ 的/ 路径/ 数目/ ./ 最后/ ,/ 从图/ 中/ 我们/ 可以/ 看出/ ,/ 在/ 胖树/ 网络/ 中/ ,/ 计算/ 路由/ 路径/ 的/ 开销/ 是/ 极小/ 的/ (/ 除了/ Page1027648/ 台/ 服务器/ 节点/ 的/ 最坏/ 情形/ 外/ ,/ 路径/ 可以/ 在/ 微秒/ 级/ 时间/ 内/ 计算/ 得到/ )/ ./ 胖树/ 拓扑/ 路径/ 计算/ 的/ 极小/ 开销/ ,/ 保证/ Nimble/ 可以/ 快速/ 地/ 处理/ 网络/ 拥塞/ ./ 5.2/ 实验/ 设置/ 本/ 节/ 通过/ 模拟实验/ 比较/ Nimble/ 同/ ECMP/ 以及/ Hedera/ 的/ 性能/ ./ 本文/ 中/ 所有/ 的/ 实验/ 结果/ 均/ 由/ 网络/ 模拟器/ NS3/ [/ 16/ ]/ 获得/ ./ NS3/ 中将/ OpenFlow/ 协议/ 作为/ 单独/ 的/ 模块/ 集成/ 到/ 模拟器/ 中/ ,/ 集成/ 协议/ 版本/ 为/ 0.8/ ./ 9/ ./ 尽管/ 当前/ 最新/ 的/ OpenFlow/ 协议/ 版本/ 为/ 1.3/ ./ 1/ ,/ OpenFlow/ 协议/ 的/ 基本功能/ 没有/ 改变/ ./ 实验/ 中/ ,/ 我们/ 使用/ 胖树/ 拓扑/ 作为/ 基准/ 网络拓扑/ ,/ 交换机/ 采用/ 16/ 端口/ 交换机/ ./ 默认/ 配置/ 情形/ 下/ ,/ 网络/ 中/ 包含/ 128/ 台/ 服务器/ 节点/ ./ 相比/ 于/ 真实/ 的/ 数据中心/ 规模/ ,/ 实验/ 模拟/ 的/ 网络/ 规模/ 相对/ 较/ 小/ ./ 之所以/ 采用/ 这种/ 小规模/ 的/ 实验/ 配置/ ,/ 主要/ 有/ 以下/ 原因/ :/ 首先/ ,/ NS3/ 模拟器/ 为/ 数据包/ 级/ 模拟器/ ,/ 因此/ ,/ 对于/ 大规模/ 的/ 网络/ 模拟/ 需要/ 消耗/ 非常/ 长/ 的/ 时间/ (/ 比如/ ,/ 对于/ 我们/ 的/ 小规模/ 实验/ ,/ 需要/ 超过/ 24h/ 的/ 墙上/ 时间/ 来/ 模拟/ 20s/ 的/ 模拟/ 时间/ )/ ;/ 其次/ ,/ 模拟器/ 主要/ 用来/ 验证/ Nimble/ 架构/ 是否/ 能够/ 快速/ 有效/ 地/ 处理/ 突发/ 数据流/ 导致/ 的/ 链路/ 拥塞/ ,/ 因此/ ,/ 上述/ 实验/ 规模/ 已经/ 足够/ 用来/ 验证/ 突发/ 数据流/ 导致/ 的/ 拥塞/ 问题/ ./ 实验/ 中/ ,/ 我们/ 使用/ NS3/ 环境/ 中/ 的/ 一个/ 或/ 多个/ 应用/ 来/ 模拟/ 服务器/ 节点/ ./ 模拟/ 拓扑/ 下/ 所有/ 链路/ 的/ 带宽/ 均/ 配置/ 为/ 1000Mbps/ ./ 为了/ 聚焦/ 由/ 突发/ 流量/ 导致/ 的/ 拥塞/ 问题/ ,/ 本文/ 中/ 模拟实验/ 采用/ 合成/ 流量/ 驱动/ 模拟器/ 执行/ ./ 由于/ 没有/ 公开/ 可以/ 得到/ 的/ 真实/ 数据中心/ 网络/ trace/ 及/ 对应/ 的/ 拓扑/ 说明/ ,/ 本文/ 中/ 没有/ 使用/ 真实/ 的/ 数据中心/ 网络/ trace/ 进行/ 实验/ 验证/ ./ 实验/ 采用/ 的/ 流量/ 模式/ 如下/ :/ (/ 1/ )/ 每个/ 服务器/ 节点/ 和/ 具有/ 固定/ 偏移/ 的/ 服务器/ 节点/ 建立/ TCP/ 连接/ (/ 实验/ 中/ ,/ 偏移/ 值为/ 16/ ./ 采用/ 此/ 偏移/ 值/ ,/ 所有/ 的/ 目的/ 服务器/ 节点/ 和源/ 服务器/ 节点/ 位于/ 不同/ 的/ pod/ 中/ )/ 作为/ 背景/ 数据流/ ./ 背景/ 数据流/ 的/ 速率/ 为/ 5Mbps/ ;/ (/ 2/ )/ 除了/ 背景/ 数据流/ ,/ 另外/ 的/ 35/ 台/ 服务器/ 节点/ 向/ 其/ 目的/ 服务器/ 节点/ 发送/ 块/ 数据/ ./ 实验/ 中/ ,/ 数据/ 块/ 的/ 大小/ 为/ 125MB/ ./ 为了/ 测试/ ECMP/ 、/ Hedera/ 以及/ Nimble/ 的/ 性能/ ,/ 实验/ 中/ ,/ 分别/ 在/ 4s/ 、/ 8s/ 和/ 12s/ 发送/ 块/ 数据/ ./ 5.3/ 模拟实验/ 结果/ 本/ 实验/ ,/ 我们/ 比较/ 了/ ECMP/ 、/ Hedera/ 以及/ Nimble/ 的/ 网络/ 性能/ ./ 实验/ 结果/ 如图/ 8/ 所示/ ./ 图中/ ,/ 横坐标/ 代表/ 模拟/ 时间/ ,/ 间隔/ 为/ 0.1/ s/ ./ 纵坐标/ 代表/ 网络/ 的/ 聚合/ 吞吐量/ (/ 由于/ 每个/ 数据/ 块/ 发送/ 周期/ 的/ 网络/ 行为/ 类似/ ,/ 图中/ 只/ 列出/ 了/ 两个/ 数据/ 块/ 发送/ 周期/ 对应/ 的/ 情形/ )/ ./ 性能/ 较差/ ;/ 由/ 实验/ 结果/ ,/ 我们/ 可以/ 得到/ 以下/ 结论/ :/ (/ 1/ )/ 由于/ 存在/ 大/ 流/ 冲突/ ,/ 采用/ ECMP/ 方案/ 网络/ (/ 2/ )/ 尽管/ Hedera/ 和/ Nimble/ 都/ 可以/ 取得/ 比/ ECMP/ 更/ 高/ 的/ 网络/ 聚合/ 吞吐量/ ,/ 然而/ 同/ Nimble/ 相比/ ,/ Hedera/ 需要/ 经过/ 一段时间/ 的/ 延迟/ 才能/ 响应/ 拥塞/ 以/ 取得/ 较/ 高/ 的/ 聚合/ 吞吐量/ ./ Hedera/ 的/ 响应/ 延迟/ ,/ 是/ 由于/ Hedera/ 采用/ 的/ 是/ 基于/ 轮询/ 的/ 周期性/ 检测/ 方案/ (/ 实验/ 中/ ,/ 检测/ 周期/ 为/ 4s/ )/ ./ 尽管/ Hedera/ 可以/ 采用/ 更/ 小/ 的/ 时间/ 粒度/ 作为/ 检测/ 周期/ ,/ 但是/ 更/ 小/ 的/ 时间/ 粒度/ 会/ 急剧/ 增加/ 拥塞/ 检测/ 的/ 开销/ ;/ (/ 3/ )/ Nimble/ 采用/ 交换机/ 主动/ 检测/ 并/ 通告/ 拥塞/ 的/ 方式/ 检测/ 链路/ 拥塞/ ,/ 极大/ 的/ 降低/ 了/ 拥塞/ 检测/ 和/ 响应/ 的/ 时间/ ./ 由/ 上述/ 结果/ 得出/ ,/ Nimble/ 可以/ 快速/ 地/ 响应/ 网络/ 拥塞/ 并/ 极大/ 提高/ 网络/ 的/ 聚合/ 吞吐量/ ./ 注意/ 到/ ,/ 在/ 块/ 数据传输/ 的/ 结束/ 阶段/ ,/ Nimble/ 的/ 聚合/ 吞吐量/ 会/ 呈现/ 下降/ 趋势/ ,/ 如图/ 8/ 所示/ ./ 造成/ 这一/ 现象/ 的/ 原因/ 是/ ,/ 部分/ 服务器/ 节点/ 已经/ 完成/ 数据通信/ ,/ 此时/ 网络/ 中/ 只有/ 部分/ 服务器/ 节点/ 仍然/ 在/ 发送数据/ ./ 为了/ 验证/ 不同/ 的/ 队列/ 阈值/ 对/ 网络/ 性能/ 的/ 影响/ ,/ 我们/ 采用/ 不同/ 的/ 阈值/ 进行/ 了/ 一系列/ 实验/ ,/ 实验/ 结果/ 如图/ 9/ 所示/ ./ 采用/ 带内/ 通信/ 的/ 方式/ ,/ 大量/ 的/ 拥塞/ 通告/ 消息/ 会/ 加剧/ 网络/ 负载/ ,/ 进而/ 降低/ 网络/ 性能/ ./ 即使/ 使用/ 带外/ 通信/ ,/ 大量/ 的/ 拥塞/ 通告/ 消息/ 也/ 会/ 极大/ 地/ 增加/ 控制器/ 的/ CPU/ 负载/ ./ Page11/ 图/ 9/ 中/ ,/ 横坐标/ 代表/ 不同/ 的/ 队列/ 长度/ 阈值/ ,/ 纵坐标/ 代表/ 控制器/ 从/ 交换机/ 收到/ 的/ 拥塞/ 通知/ 消息/ 的/ 数目/ ./ 从图/ 中/ 可以/ 得出/ ,/ 阈值/ 为/ 0.7/ 时/ 发送/ 消息/ 的/ 数目/ 最少/ ./ 造成/ 这一/ 现象/ 的/ 主要/ 原因/ 如下/ :/ (/ 1/ )/ 当/ 阈值/ 较/ 小时/ ,/ 队列/ 长度/ 很/ 容易/ 达到/ 阈值/ ,/ 从而/ 认为/ 出现/ 链路/ 拥塞/ ,/ 致使/ 交换机/ 发送/ 拥塞/ 通告/ 消息/ ;/ (/ 2/ )/ 当/ 阈值/ 较大/ 时/ ,/ 链路/ 拥塞/ 更为严重/ ,/ 需要/ 调度/ 链路/ 上/ 的/ 更/ 多数据流/ 才能/ 解决/ 拥塞/ 问题/ ,/ 进而/ 产生/ 更/ 多/ 的/ 拥塞/ 通告/ 消息/ ./ 模拟实验/ 中/ ,/ 不同/ 的/ 阈值/ 所/ 获得/ 的/ 网络/ 性能/ 相近/ ,/ 故此/ 不再/ 单独/ 列出/ ./ 由/ 上面/ 分析/ 可以/ 得出/ ,/ 较大/ 的/ 阈值/ 可以/ 在/ 取得/ 较/ 好/ 的/ 网络/ 性能/ 的/ 同时/ 降低/ 拥塞/ 通告/ 消息/ 的/ 数目/ ./ 根据/ 实验/ 结果/ ,/ 我们/ 建议/ 的/ 阈值/ 为/ 0.7/ ,/ 也/ 就是/ 将/ 阈值/ 设置/ 为/ 交换机/ 端口/ 队列/ 容量/ 的/ 70/ %/ ./ 最后/ ,/ 我们/ 讨论/ Nimble/ 和/ Hedera/ 的/ 网络/ 开销/ ./ 假设/ 实验/ 中/ 每台/ 服务器/ 节点/ 建立/ 10/ 条/ 数据流/ [/ 17/ ]/ ,/ 则/ 本/ 实验/ 中/ 总/ 的/ 网络/ 流/ 数目/ 为/ 1280/ (/ 128/ ×/ 10/ )/ ./ Open/ -/ Flow/ 协议/ 中/ ,/ 流/ 统计/ 请求/ 消息/ 的/ 大小/ 为/ 56/ 字节/ ,/ 响应/ 消息/ 的/ 大小/ 为/ 100/ 字节/ ./ 所以/ ,/ 每次/ 请求/ 、/ 响应/ 消息/ 的/ 大小/ 总计/ 为/ 156/ 字节/ ①/ ./ 实验/ 中/ ,/ 总计/ 执行/ 了/ 3/ 次流/ 统计/ 请求/ // 响应/ ,/ 因此/ Hedera/ 机制/ 的/ 总开销/ 为/ 599040/ (/ 1280/ ×/ 156/ ×/ 3/ )/ 字节/ ./ 对于/ Nimble/ ,/ 实验/ 中/ 发送/ 的/ 拥塞/ 通知/ 消息/ 的/ 数目/ 为/ 6170/ (/ 阈值/ 为/ 0.7/ 时/ )/ ./ 由于/ 拥塞/ 通知/ 消息/ 的/ 大小/ 为/ 20/ 字节/ ,/ 所以/ Nimble/ 拥塞/ 通知/ 的/ 总开销/ 为/ 123400/ 字节/ ,/ 约/ 为/ Hedera/ 消息/ 总/ 大小/ 的/ 20/ %/ ./ 在/ 最坏/ 情形/ 下/ ,/ 即/ 阈值/ 为/ 0.5/ 时/ ,/ Nimble/ 拥塞/ 通知/ 的/ 总开销/ 为/ 234500/ ,/ 约/ 为/ Hedera/ 开销/ 的/ 40/ %/ ./ 从/ 以上/ 分析/ ,/ 我们/ 得出/ 如下/ 结论/ :/ 相比/ 于/ Hedera/ ,/ Nimble/ 的/ 拥塞/ 通知/ 机制/ 极大/ 地/ 降低/ 了/ 拥塞/ 通告/ 的/ 开销/ ./ 6/ 相关/ 工作/ 近年来/ ,/ 科研人员/ 提出/ 许多/ 方案/ 以/ 提高/ 数据中心/ 网络/ 的/ 带宽/ ./ 为了/ 在/ 基础设施/ 上/ 提供/ 对/ 高带宽/ 的/ 支持/ ,/ 文献/ [/ 1/ -/ 6/ ]/ 提出/ 了/ 在/ 服务器/ 节点/ 对间/ 提供/ 多条/ 可/ 达/ 路径/ 的/ 网络拓扑/ 结构/ ./ ECMP/ 协议/ 是/ 利用网络/ 多路径/ 提高/ 应用/ 性能/ 的/ 典型/ 协议/ 之一/ ./ ECMP/ 通过/ 基于/ 哈希/ 算法/ 的/ 方式/ 将/ 数据流/ 分发/ 到/ 不同/ 的/ 可达/ 路径/ ,/ 以此/ 实现/ 均衡/ 网络/ 负载/ 、/ 提高/ 网络/ 吞吐量/ 的/ 目的/ ./ 然而/ ,/ ECMP/ 算法/ 存在/ 大/ 流/ 冲突/ 问题/ [/ 8/ ]/ ./ Dixit/ 等/ 人/ [/ 18/ ]/ 提出/ 基于/ 数据包/ 的/ 负载/ 均衡/ 策略/ 以/ 提高/ 网络/ 吞吐量/ ./ Sen/ 等/ 人/ [/ 19/ ]/ 则/ 提出/ 依据/ 交换机/ 端口/ 负载/ 信息/ 均衡/ 网络/ 负载/ 的/ 方案/ ./ 上述/ 方案/ 均/ 是/ 通过/ 均衡/ 网络/ 负载/ 的/ 方式/ 提高/ 网络/ 吞吐量/ ,/ 然而/ 这些/ 方案/ 无法/ 避免/ 网络/ 拥塞/ ./ 与/ 之/ 不同/ ,/ Nimble/ 通过/ 快速/ 地/ 检测/ 网络/ 拥塞/ 并/ 调度/ 拥塞/ 链路/ 上/ 数据流/ 到/ 低/ 负载/ 链路/ 的/ 方式/ 实现/ 提高/ 网络/ 吞吐量/ 的/ 目的/ ./ 为了/ 降低/ 大/ 流/ 冲突/ 对/ 网络/ 性能/ 的/ 影响/ ,/ 需要/ 检测/ 网络/ 中/ 的/ 大流/ ,/ 并/ 将/ 其/ 调度/ 到/ 低/ 负载/ 链路/ ./ Al/ -/ Fares/ 等/ 人/ [/ 8/ ]/ 使用/ Hedera/ 架构/ 实现/ 更加/ 有效/ 地/ 利用网络/ 多路径/ 的/ 目的/ ./ Hedera/ 架构/ 中/ ,/ 控制器/ 周期性地/ 向/ 交换机/ 发送/ 流/ 统计/ 请求/ 消息/ 以/ 检测/ 网络/ 中/ 的/ 大流/ ,/ 并/ 将/ 大流/ 调度/ 到/ 低/ 负载/ 链路/ ./ 然而/ ,/ 由于/ 采用/ 集中式/ 的/ 检测/ 策略/ ,/ 制约/ 了/ Hedera/ 的/ 可扩展性/ ./ Curtis/ 等/ 人/ [/ 11/ ]/ 提出/ 一种/ 新/ 的/ 大流/ 检测/ 机制/ ,/ 称为/ Mahout/ ./ Mahout/ 采用/ 分布式/ 思想/ 在/ 终端/ 节点/ 检测/ 大/ 流/ ,/ 极大/ 减小/ 了/ 其/ 实现/ 开销/ 和/ 资源/ 需求/ ./ Xi/ 等/ 人/ [/ 20/ ]/ 提出/ 一种/ 通过/ 动态/ 改变/ 数据流/ 的/ ECMP/ 哈希/ 值/ ,/ 将/ 数据流/ 由/ 高/ 负载/ 链路/ 调度/ 到/ 低/ 负载/ 链路/ 的/ 机制/ ./ XCo/ [/ 21/ ]/ 通过/ 集中式/ 控制/ 程序控制/ 拥塞/ 链路/ 上/ 发送/ 端的/ 发送/ 速率/ 以/ 避免/ 网络/ 拥塞/ ./ 与/ 之/ 不同/ ,/ Nimble/ 利用/ packet/ -/ in/ 消息/ 向/ 控制器/ 通告/ 拥塞/ 信息/ ./ 同/ 以上/ 工作/ 相比/ ,/ Nimble/ 的/ 主要/ 优势/ 是/ 其/ 可以/ 快速/ 地/ 检测/ 和/ 响应/ 链路/ 拥塞/ ./ 为了/ 充分利用网络/ 资源/ ,/ GRIN/ [/ 22/ ]/ 通过/ 利用网络/ 空闲/ 资源/ (/ 如/ 端口/ 、/ 链路/ 等/ )/ 的/ 方式/ 提高/ 网络资源/ 利用率/ ,/ 同时/ 提高/ 网络/ 吞吐量/ ./ 鉴于/ 应用/ 的/ 不同/ 特征/ ,/ Webb/ 等/ 人/ [/ 23/ ]/ 提出/ 为/ 不同/ 应用/ 建立/ 虚拟/ 拓扑/ 的/ 方案/ ,/ 优化/ 应用/ 的/ 网络/ 性能/ ./ MicroTE/ [/ 24/ ]/ 则/ 通过/ 检测/ 应用/ 的/ 网络/ 特征/ ,/ 预测/ 应用/ 的/ 流量/ 矩阵/ ./ 同时/ ,/ 其/ 通过/ 调整/ 网络资源/ 分配/ 的/ 方式/ 提高/ 网络/ 吞吐量/ ./ Nimble/ 则/ 通过/ 拥塞/ 检测/ 和/ 数据流/ 重/ 调度/ 的/ 方式/ 提高/ 网络/ 性能/ ,/ 所以/ Nimble/ 可以/ 和/ 上述/ 方案/ 协同工作/ ,/ 以/ 进一步提高/ 网络/ 吞吐量/ ./ 7/ 未来/ 工作/ 尽管/ Nimble/ 可以/ 将/ 拥塞/ 链路/ 上/ 的/ 数据流/ 调度/ ①/ 请求/ 消息/ 和/ 响应/ 消息/ 的/ 大小/ 基于/ OpenFlow/ 规范/ 1.0/ ./ 0/ 得/ Page12/ 到/ 网络/ 中/ 的/ 低/ 负载/ 链路/ ,/ 然而/ 为了/ 实现/ 更加/ 智能/ 的/ 调度/ 策略/ ,/ Nimble/ 架构/ 需要/ 集成/ 更加/ 有效/ 的/ 调度/ 模块/ ./ 胖树/ 拓扑/ 具有/ 良好/ 的/ 路由/ 特性/ ./ 因此/ ,/ 对于/ 任意/ 通信/ 节点/ 对/ ,/ 只要/ 确定/ 其/ 通信/ 路径/ 上/ 的/ 核心/ 层交换机/ ,/ 该/ 节点/ 对间/ 的/ 路由/ 路径/ 便/ 随之/ 确定/ ./ 所以/ Nimble/ 计算/ 新路/ 由/ 路径/ 的/ 时间/ 开销/ 极小/ ./ 对于/ 非胖树/ 网络/ ,/ 只要/ 确定/ 了/ 选用/ 的/ 路由/ 算法/ ,/ Nimble/ 可以/ 适用/ 于/ 任意/ 网络拓扑/ ./ 然而/ ,/ 对于/ 非/ 结构化/ 拓扑/ ,/ 如/ Jellyfish/ 等/ ,/ Nimble/ 计算/ 新/ 路径/ 的/ 时间/ 开销/ 较大/ ./ 为此/ ,/ Nimble/ 需要/ 更加/ 智能/ 的/ 策略/ 以/ 减少/ 非/ 结构化/ 拓扑/ 的/ 路径/ 计算/ 开销/ ./ 一种/ 可能/ 的/ 方案/ 是/ 为/ 每/ 一对/ 通信/ 节点/ 维护/ 一个/ 低/ 负载/ 路径/ 池/ ./ 当/ 需要/ 计算/ 新/ 的/ 路由/ 路径/ 时/ ,/ 控制器/ 仅仅/ 从/ 路径/ 池中/ 获取/ 一条/ 新/ 的/ 路径/ ./ 总地/ 来讲/ ,/ 更加/ 智能/ 的/ 调度/ 模块/ 以及/ 路径/ 池/ 策略/ 是/ 我们/ 未来/ 需要/ 面对/ 的/ 两个/ 主要/ 挑战/ ./ 8/ 总结/ OpenFlow/ 网络/ 可以/ 通过/ 将/ 拥塞/ 链路/ 上/ 的/ 大流/ 调度/ 到/ 低/ 负载/ 链路/ 的/ 方式/ 解决/ 链路/ 拥塞/ 问题/ ./ 然而/ ,/ 由于/ 当前/ 的/ 解决方案/ 采用/ 基于/ 轮询/ 的/ 方式/ 检测/ 链路/ 状态/ ,/ 致使/ 它们/ 不能/ 有效/ 地处/ 理由/ 突发/ 流量/ 导致/ 的/ 链路/ 拥塞/ 问题/ ./ 为了/ 解决/ 突发/ 流量/ 导致/ 的/ 链路/ 拥塞/ 问题/ ,/ 本文/ 提出/ Nimble/ 架构/ ./ 首先/ ,/ Nimble/ 架构/ 中/ ,/ 交换/ 设备/ 自主/ 检测/ 链路/ 拥塞/ ./ 因此/ ,/ Nimble/ 可以/ 快速/ 地/ 检测/ 网络/ 拥塞/ ./ 其次/ ,/ Nimble/ 通过/ 扩展/ 的/ packet/ -/ in/ 消息/ 实现/ 拥塞/ 信息/ 通告/ ./ 最后/ ,/ 文中/ 提出/ 一种/ 分布式/ 的/ 大流/ 检测/ 方案/ ./ 由于/ Nimble/ 架构/ 采用/ 异步/ 消息/ 实现/ 拥塞/ 通告/ ,/ 拥塞/ 通知/ 的/ 延迟/ 和/ 开销/ 得到/ 极大/ 减小/ ./ 文中/ ,/ 我们/ 通过/ 模拟实验/ 比较/ 了/ Nimble/ 和/ ECMP/ 、/ Hedera/ 的/ 网络/ 性能/ ./ 实验/ 结果表明/ ,/ 较之/ ECMP/ ,/ Nimble/ 的/ 网络/ 性能/ 得到/ 极大/ 提高/ ./ 同时/ ,/ 与/ Hedera/ 相比/ ,/ Nimble/ 的/ 处理/ 拥塞/ 的/ 响应/ 时间/ 得到/ 极大/ 减小/ ./ 致谢/ 审稿/ 专家/ 和/ 本报/ 编辑/ 为/ 本文/ 提出/ 了/ 许多/ 宝贵/ 的/ 意见/ 和/ 建议/ ,/ 作者/ 在/ 此/ 表示/ 衷心/ 的/ 感谢/ !/ 

